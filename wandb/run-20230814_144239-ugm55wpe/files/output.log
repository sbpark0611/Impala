[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
2023-08-14 14:42:40,665	INFO tensorboardx.py:48 -- pip install "ray[tune]" to see TensorBoard files.
2023-08-14 14:42:40,665	WARNING unified.py:56 -- Could not instantiate TBXLogger: No module named 'tensorboardX'.
[36m(pid=41433)[39m lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.
[36m(pid=41433)[39m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,580	WARNING env.py:162 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,585	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,585	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,589	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.AttentionWrapper` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,589	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,589	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,609	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.GTrXLNet` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,622	WARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,622	WARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,622	WARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,622	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=41433)[39m 2023-08-14 14:42:43,697	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/catalog.py:790: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  prep = cls(observation_space, options)
2023-08-14 14:42:43,739	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,740	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,743	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.AttentionWrapper` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,743	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,743	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/torch/attention_net.py:281: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  super().__init__(obs_space, action_space, None, model_config, name)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/torch/attention_net.py:281: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  super().__init__(obs_space, action_space, None, model_config, name)
2023-08-14 14:42:43,748	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.GTrXLNet` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,753	WARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,753	WARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,753	WARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,753	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/modelv2.py:440: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  prep = get_preprocessor(space)(space)
2023-08-14 14:42:43,773	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/connectors/agent/obs_preproc.py:40: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  self._preprocessor = get_preprocessor(obs_space)(
2023-08-14 14:42:43,793	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.multi_gpu_learner_thread.MultiGPULearnerThread` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,794	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.minibatch_buffer.MinibatchBuffer` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,794	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.learner_thread.LearnerThread` has been deprecated. This will raise an error in the future!
2023-08-14 14:42:43,795	WARNING util.py:68 -- Install gputil for GPU system monitoring.
2023-08-14 14:42:43,899	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.replay_ops.SimpleReplayBuffer` has been deprecated. This will raise an error in the future!
train step: 1
agent_timesteps_total: 7400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034448607214565934
  StateBufferConnector_ms: 0.006100638159390153
  ViewRequirementAgentConnector_ms: 0.1994659160745555
counters:
  num_agent_steps_sampled: 7400
  num_agent_steps_trained: 2500
  num_env_steps_sampled: 7400
  num_env_steps_trained: 2500
  num_samples_added_to_queue: 7000
  num_training_step_calls_since_last_synch_worker_weights: 1439
  num_weight_broadcasts: 145
custom_metrics: {}
date: 2023-08-14_14-42-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 1.4482758620689655
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 58
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 4.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.5817731618881226
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 73.624755859375
        total_loss: 87.78915405273438
        var_gnorm: 63.31722640991211
        vf_explained_var: -0.35489630699157715
        vf_loss: 44.14653015136719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5.0
  learner_queue:
    size_count: 9
    size_mean: 0.0
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 0.0]
    size_std: 0.0
  num_agent_steps_sampled: 7400
  num_agent_steps_trained: 2500
  num_env_steps_sampled: 7400
  num_env_steps_trained: 2500
  num_samples_added_to_queue: 7000
  num_training_step_calls_since_last_synch_worker_weights: 1439
  num_weight_broadcasts: 145
  timing_breakdown:
    learner_dequeue_time_ms: 512.892
    learner_grad_time_ms: 1052.064
    learner_load_time_ms: 90.268
    learner_load_wait_time_ms: 68.691
iterations_since_restore: 1
node_ip: 127.0.0.1
num_agent_steps_sampled: 7400
num_agent_steps_trained: 2500
num_env_steps_sampled: 7400
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9927488083897
num_env_steps_trained: 2500
num_env_steps_trained_this_iter: 2500
num_env_steps_trained_throughput_per_sec: 249.99755027310462
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 2500
perf:
  cpu_util_percent: 47.9
  ram_util_percent: 79.03333333333333
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10840574774858795
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03948966881627316
  mean_inference_ms: 1.9891604847796365
  mean_raw_obs_processing_ms: 0.45248641054494165
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034448607214565934
    StateBufferConnector_ms: 0.006100638159390153
    ViewRequirementAgentConnector_ms: 0.1994659160745555
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 1.4482758620689655
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 2.0,
      1.0, 0.0, 2.0, 1.0, 8.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 3.0, 1.0, 3.0,
      1.0, 3.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 1.0, 0.0, 4.0, 1.0, 3.0, 1.0, 0.0,
      2.0, 2.0, 3.0, 3.0, 2.0, 0.0, 1.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10840574774858795
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03948966881627316
    mean_inference_ms: 1.9891604847796365
    mean_raw_obs_processing_ms: 0.45248641054494165
time_since_restore: 10.158238887786865
time_this_iter_s: 10.158238887786865
time_total_s: 10.158238887786865
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1691991773
timesteps_total: 7400
training_iteration: 1
trial_id: default
train step: 2
agent_timesteps_total: 15200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03471946716308594
  StateBufferConnector_ms: 0.006091117858886719
  ViewRequirementAgentConnector_ms: 0.20017266273498535
counters:
  num_agent_steps_sampled: 15200
  num_agent_steps_trained: 7000
  num_env_steps_sampled: 15200
  num_env_steps_trained: 7000
  num_samples_added_to_queue: 15000
  num_training_step_calls_since_last_synch_worker_weights: 1225
  num_weight_broadcasts: 298
custom_metrics: {}
date: 2023-08-14_14-43-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.56
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 120
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 9.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.5719445943832397
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -92.26390838623047
        total_loss: -87.97027587890625
        var_gnorm: 63.31568145751953
        vf_explained_var: 0.2688782811164856
        vf_loss: 24.306716918945312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 14.0
  learner_queue:
    size_count: 18
    size_mean: 0.0
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 0.0]
    size_std: 0.0
  num_agent_steps_sampled: 15200
  num_agent_steps_trained: 7000
  num_env_steps_sampled: 15200
  num_env_steps_trained: 7000
  num_samples_added_to_queue: 15000
  num_training_step_calls_since_last_synch_worker_weights: 1225
  num_weight_broadcasts: 298
  timing_breakdown:
    learner_dequeue_time_ms: 5617.087
    learner_grad_time_ms: 996.186
    learner_load_time_ms: 46.213
    learner_load_wait_time_ms: 22.062
iterations_since_restore: 2
node_ip: 127.0.0.1
num_agent_steps_sampled: 15200
num_agent_steps_trained: 7000
num_env_steps_sampled: 15200
num_env_steps_sampled_this_iter: 7800
num_env_steps_sampled_throughput_per_sec: 779.9953136725653
num_env_steps_trained: 7000
num_env_steps_trained_this_iter: 4500
num_env_steps_trained_throughput_per_sec: 449.9972963495569
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 4500
perf:
  cpu_util_percent: 52.20714285714286
  ram_util_percent: 79.77142857142857
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10786871161836306
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03885271070571278
  mean_inference_ms: 1.968927250985638
  mean_raw_obs_processing_ms: 0.4483684551411136
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03471946716308594
    StateBufferConnector_ms: 0.006091117858886719
    ViewRequirementAgentConnector_ms: 0.20017266273498535
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.56
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 1.0, 0.0, 3.0, 0.0, 3.0, 1.0, 3.0, 1.0, 3.0, 0.0, 1.0,
      1.0, 0.0, 3.0, 2.0, 2.0, 1.0, 0.0, 4.0, 1.0, 3.0, 1.0, 0.0, 2.0, 2.0, 3.0, 3.0,
      2.0, 0.0, 1.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 5.0, 1.0, 0.0, 3.0,
      0.0, 1.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 3.0, 2.0,
      3.0, 1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0,
      3.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 0.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0,
      1.0, 3.0, 1.0, 3.0, 2.0, 2.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10786871161836306
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03885271070571278
    mean_inference_ms: 1.968927250985638
    mean_raw_obs_processing_ms: 0.4483684551411136
time_since_restore: 20.294188976287842
time_this_iter_s: 10.135950088500977
time_total_s: 20.294188976287842
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691991784
timesteps_total: 15200
training_iteration: 2
trial_id: default
train step: 3
agent_timesteps_total: 23200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03416752815246582
  StateBufferConnector_ms: 0.005891561508178711
  ViewRequirementAgentConnector_ms: 0.19904446601867676
counters:
  num_agent_steps_sampled: 23200
  num_agent_steps_trained: 12000
  num_env_steps_sampled: 23200
  num_env_steps_trained: 12000
  num_samples_added_to_queue: 23000
  num_training_step_calls_since_last_synch_worker_weights: 78
  num_weight_broadcasts: 453
custom_metrics: {}
date: 2023-08-14_14-43-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 1.77
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 182
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 11.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.5161404609680176
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.7828216552734375
        total_loss: 1.1509556770324707
        var_gnorm: 63.31448745727539
        vf_explained_var: 0.5114014148712158
        vf_loss: 11.897672653198242
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 24.0
  learner_queue:
    size_count: 31
    size_mean: 0.8064516129032258
    size_quantiles: [0.0, 0.0, 0.0, 3.0, 5.0]
    size_std: 1.5328521768408672
  num_agent_steps_sampled: 23200
  num_agent_steps_trained: 12000
  num_env_steps_sampled: 23200
  num_env_steps_trained: 12000
  num_samples_added_to_queue: 23000
  num_training_step_calls_since_last_synch_worker_weights: 78
  num_weight_broadcasts: 453
  timing_breakdown:
    learner_dequeue_time_ms: 4224.891
    learner_grad_time_ms: 599.598
    learner_load_time_ms: 46.213
    learner_load_wait_time_ms: 8.337
iterations_since_restore: 3
node_ip: 127.0.0.1
num_agent_steps_sampled: 23200
num_agent_steps_trained: 12000
num_env_steps_sampled: 23200
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9971962073364
num_env_steps_trained: 12000
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.99824762958525
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 51.13999999999999
  ram_util_percent: 79.48666666666668
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10659314768432994
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03817927768778602
  mean_inference_ms: 1.943138299788724
  mean_raw_obs_processing_ms: 0.44265455453037705
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03416752815246582
    StateBufferConnector_ms: 0.005891561508178711
    ViewRequirementAgentConnector_ms: 0.19904446601867676
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 1.77
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 3.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0,
      2.0, 2.0, 3.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 0.0, 2.0, 1.0, 2.0, 1.0,
      2.0, 0.0, 1.0, 3.0, 1.0, 3.0, 2.0, 2.0, 4.0, 2.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0,
      2.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 1.0, 3.0, 0.0, 4.0, 1.0,
      0.0, 3.0, 0.0, 3.0, 1.0, 2.0, 3.0, 4.0, 1.0, 3.0, 1.0, 6.0, 1.0, 1.0, 1.0, 3.0,
      2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0,
      2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10659314768432994
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03817927768778602
    mean_inference_ms: 1.943138299788724
    mean_raw_obs_processing_ms: 0.44265455453037705
time_since_restore: 30.57494807243347
time_this_iter_s: 10.28075909614563
time_total_s: 30.57494807243347
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.09
timestamp: 1691991794
timesteps_total: 23200
training_iteration: 3
trial_id: default
train step: 4
agent_timesteps_total: 30350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035071611404418945
  StateBufferConnector_ms: 0.0060079097747802734
  ViewRequirementAgentConnector_ms: 0.20490622520446777
counters:
  num_agent_steps_sampled: 30350
  num_agent_steps_trained: 18000
  num_env_steps_sampled: 30350
  num_env_steps_trained: 18000
  num_samples_added_to_queue: 30000
  num_training_step_calls_since_last_synch_worker_weights: 58
  num_weight_broadcasts: 593
custom_metrics: {}
date: 2023-08-14_14-43-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 1.94
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 238
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 15.5
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3651459217071533
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 6.084522247314453
        total_loss: 10.774738311767578
        var_gnorm: 63.31520080566406
        vf_explained_var: 0.532328724861145
        vf_loss: 23.031888961791992
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 36.0
  learner_queue:
    size_count: 43
    size_mean: 1.6744186046511629
    size_quantiles: [0.0, 0.0, 0.0, 5.0, 7.0]
    size_std: 2.2487301867225247
  num_agent_steps_sampled: 30350
  num_agent_steps_trained: 18000
  num_env_steps_sampled: 30350
  num_env_steps_trained: 18000
  num_samples_added_to_queue: 30000
  num_training_step_calls_since_last_synch_worker_weights: 58
  num_weight_broadcasts: 593
  timing_breakdown:
    learner_dequeue_time_ms: 3200.953
    learner_grad_time_ms: 666.912
    learner_load_time_ms: 32.975
    learner_load_wait_time_ms: 16.287
iterations_since_restore: 4
node_ip: 127.0.0.1
num_agent_steps_sampled: 30350
num_agent_steps_trained: 18000
num_env_steps_sampled: 30350
num_env_steps_sampled_this_iter: 7150
num_env_steps_sampled_throughput_per_sec: 714.9951246117201
num_env_steps_trained: 18000
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9959087650798
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 54.885714285714286
  ram_util_percent: 79.7
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10728040217801038
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03872071492964504
  mean_inference_ms: 1.9621469323329155
  mean_raw_obs_processing_ms: 0.44592323191214484
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035071611404418945
    StateBufferConnector_ms: 0.0060079097747802734
    ViewRequirementAgentConnector_ms: 0.20490622520446777
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 1.94
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 3.0, 0.0, 4.0, 1.0, 0.0, 3.0, 0.0, 3.0, 1.0, 2.0, 3.0, 4.0,
      1.0, 3.0, 1.0, 6.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 0.0,
      2.0, 1.0, 0.0, 2.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 3.0,
      1.0, 3.0, 2.0, 3.0, 3.0, 1.0, 3.0, 5.0, 1.0, 3.0, 4.0, 7.0, 0.0, 0.0, 4.0, 3.0,
      0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 4.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0,
      2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 3.0, 1.0, 4.0, 0.0, 4.0, 3.0, 2.0, 4.0,
      3.0, 3.0, 2.0, 1.0, 0.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10728040217801038
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03872071492964504
    mean_inference_ms: 1.9621469323329155
    mean_raw_obs_processing_ms: 0.44592323191214484
time_since_restore: 40.89486503601074
time_this_iter_s: 10.31991696357727
time_total_s: 40.89486503601074
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1691991804
timesteps_total: 30350
training_iteration: 4
trial_id: default
train step: 5
agent_timesteps_total: 38200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03314495086669922
  StateBufferConnector_ms: 0.005916118621826172
  ViewRequirementAgentConnector_ms: 0.19842290878295898
counters:
  num_agent_steps_sampled: 38200
  num_agent_steps_trained: 24500
  num_env_steps_sampled: 38200
  num_env_steps_trained: 24500
  num_samples_added_to_queue: 38000
  num_training_step_calls_since_last_synch_worker_weights: 61
  num_weight_broadcasts: 747
custom_metrics: {}
date: 2023-08-14_14-43-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 1.97
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 299
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 17.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3862642049789429
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 27.531713485717773
        total_loss: 28.632972717285156
        var_gnorm: 63.31545639038086
        vf_explained_var: 0.5623331069946289
        vf_loss: 16.065155029296875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 49.0
  learner_queue:
    size_count: 55
    size_mean: 3.04
    size_quantiles: [0.0, 0.0, 2.5, 7.100000000000001, 10.0]
    size_std: 3.078701024783017
  num_agent_steps_sampled: 38200
  num_agent_steps_trained: 24500
  num_env_steps_sampled: 38200
  num_env_steps_trained: 24500
  num_samples_added_to_queue: 38000
  num_training_step_calls_since_last_synch_worker_weights: 61
  num_weight_broadcasts: 747
  timing_breakdown:
    learner_dequeue_time_ms: 2560.763
    learner_grad_time_ms: 760.983
    learner_load_time_ms: 25.615
    learner_load_wait_time_ms: 2.99
iterations_since_restore: 5
node_ip: 127.0.0.1
num_agent_steps_sampled: 38200
num_agent_steps_trained: 24500
num_env_steps_sampled: 38200
num_env_steps_sampled_this_iter: 7850
num_env_steps_sampled_throughput_per_sec: 784.9949654663632
num_env_steps_trained: 24500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9958312778804
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 51.60714285714285
  ram_util_percent: 79.59285714285714
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10766843992490607
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039022180610624055
  mean_inference_ms: 1.9750745923807829
  mean_raw_obs_processing_ms: 0.4496710235751611
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03314495086669922
    StateBufferConnector_ms: 0.005916118621826172
    ViewRequirementAgentConnector_ms: 0.19842290878295898
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 1.97
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 4.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0,
      1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 3.0, 1.0, 4.0, 0.0, 4.0,
      3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 1.0, 0.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 1.0, 5.0,
      3.0, 0.0, 3.0, 4.0, 3.0, 4.0, 6.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0,
      1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 4.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0,
      6.0, 1.0, 3.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0,
      2.0, 2.0, 4.0, 4.0, 0.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10766843992490607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039022180610624055
    mean_inference_ms: 1.9750745923807829
    mean_raw_obs_processing_ms: 0.4496710235751611
time_since_restore: 51.12255883216858
time_this_iter_s: 10.227693796157837
time_total_s: 51.12255883216858
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.073
timestamp: 1691991814
timesteps_total: 38200
training_iteration: 5
trial_id: default
train step: 6
agent_timesteps_total: 46400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03183794021606445
  StateBufferConnector_ms: 0.005831480026245117
  ViewRequirementAgentConnector_ms: 0.1903529167175293
counters:
  num_agent_steps_sampled: 46400
  num_agent_steps_trained: 30500
  num_env_steps_sampled: 46400
  num_env_steps_trained: 30500
  num_samples_added_to_queue: 46000
  num_training_step_calls_since_last_synch_worker_weights: 101
  num_weight_broadcasts: 907
custom_metrics: {}
date: 2023-08-14_14-43-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.05
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 363
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 24.299999999999997
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3745217323303223
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -31.411453247070312
        total_loss: -27.542041778564453
        var_gnorm: 63.31697082519531
        vf_explained_var: 0.6041879653930664
        vf_loss: 21.484037399291992
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 61.0
  learner_queue:
    size_count: 68
    size_mean: 5.66
    size_quantiles: [0.0, 0.0, 5.0, 11.0, 14.0]
    size_std: 3.8398437468209563
  num_agent_steps_sampled: 46400
  num_agent_steps_trained: 30500
  num_env_steps_sampled: 46400
  num_env_steps_trained: 30500
  num_samples_added_to_queue: 46000
  num_training_step_calls_since_last_synch_worker_weights: 101
  num_weight_broadcasts: 907
  timing_breakdown:
    learner_dequeue_time_ms: 2133.971
    learner_grad_time_ms: 633.645
    learner_load_time_ms: 21.054
    learner_load_wait_time_ms: 24.355
iterations_since_restore: 6
node_ip: 127.0.0.1
num_agent_steps_sampled: 46400
num_agent_steps_trained: 30500
num_env_steps_sampled: 46400
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9958162521201
num_env_steps_trained: 30500
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9969387210634
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 49.559999999999995
  ram_util_percent: 78.78666666666668
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1066473721290726
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.038526256105883346
  mean_inference_ms: 1.959247292700998
  mean_raw_obs_processing_ms: 0.446104075464592
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03183794021606445
    StateBufferConnector_ms: 0.005831480026245117
    ViewRequirementAgentConnector_ms: 0.1903529167175293
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.05
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 0.0, 1.0, 4.0, 0.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0,
      6.0, 1.0, 3.0, 1.0, 0.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 0.0, 0.0, 1.0, 2.0, 2.0,
      2.0, 2.0, 4.0, 4.0, 0.0, 2.0, 1.0, 7.0, 2.0, 2.0, 4.0, 2.0, 0.0, 0.0, 0.0, 4.0,
      1.0, 1.0, 2.0, 3.0, 1.0, 4.0, 0.0, 1.0, 2.0, 4.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0,
      5.0, 2.0, 3.0, 1.0, 4.0, 2.0, 5.0, 2.0, 2.0, 0.0, 4.0, 2.0, 0.0, 4.0, 4.0, 3.0,
      2.0, 3.0, 1.0, 3.0, 1.0, 0.0, 2.0, 4.0, 2.0, 5.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0,
      1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1066473721290726
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.038526256105883346
    mean_inference_ms: 1.959247292700998
    mean_raw_obs_processing_ms: 0.446104075464592
time_since_restore: 61.43483901023865
time_this_iter_s: 10.312280178070068
time_total_s: 61.43483901023865
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691991825
timesteps_total: 46400
training_iteration: 6
trial_id: default
train step: 7
agent_timesteps_total: 53200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03539323806762695
  StateBufferConnector_ms: 0.006551265716552734
  ViewRequirementAgentConnector_ms: 0.20930266380310059
counters:
  num_agent_steps_sampled: 53200
  num_agent_steps_trained: 36500
  num_env_steps_sampled: 53200
  num_env_steps_trained: 36500
  num_samples_added_to_queue: 53000
  num_training_step_calls_since_last_synch_worker_weights: 2116
  num_weight_broadcasts: 1040
custom_metrics: {}
date: 2023-08-14_14-43-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.54
episode_reward_min: 0.0
episodes_this_iter: 53
episodes_total: 416
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 24.9
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3541799783706665
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.053924560546875
        total_loss: 12.115533828735352
        var_gnorm: 63.31763458251953
        vf_explained_var: 0.3944593667984009
        vf_loss: 21.665016174316406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 73.0
  learner_queue:
    size_count: 78
    size_mean: 7.74
    size_quantiles: [0.0, 1.9000000000000004, 8.0, 13.100000000000001, 16.0]
    size_std: 4.330404138183872
  num_agent_steps_sampled: 53200
  num_agent_steps_trained: 36500
  num_env_steps_sampled: 53200
  num_env_steps_trained: 36500
  num_samples_added_to_queue: 53000
  num_training_step_calls_since_last_synch_worker_weights: 2116
  num_weight_broadcasts: 1040
  timing_breakdown:
    learner_dequeue_time_ms: 2133.971
    learner_grad_time_ms: 1014.84
    learner_load_time_ms: 21.054
    learner_load_wait_time_ms: 13.996
iterations_since_restore: 7
node_ip: 127.0.0.1
num_agent_steps_sampled: 53200
num_agent_steps_trained: 36500
num_env_steps_sampled: 53200
num_env_steps_sampled_this_iter: 6800
num_env_steps_sampled_throughput_per_sec: 679.9946337169704
num_env_steps_trained: 36500
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9952650443856
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 57.778571428571425
  ram_util_percent: 79.80714285714285
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10724737965272536
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03886900733136784
  mean_inference_ms: 1.9713906511221955
  mean_raw_obs_processing_ms: 0.4488377943244957
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03539323806762695
    StateBufferConnector_ms: 0.006551265716552734
    ViewRequirementAgentConnector_ms: 0.20930266380310059
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.54
  episode_reward_min: 0.0
  episodes_this_iter: 53
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 4.0, 2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 5.0, 2.0, 3.0, 1.0, 4.0,
      2.0, 5.0, 2.0, 2.0, 0.0, 4.0, 2.0, 0.0, 4.0, 4.0, 3.0, 2.0, 3.0, 1.0, 3.0, 1.0,
      0.0, 2.0, 4.0, 2.0, 5.0, 3.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0,
      3.0, 2.0, 3.0, 0.0, 4.0, 1.0, 5.0, 1.0, 2.0, 2.0, 0.0, 5.0, 3.0, 3.0, 1.0, 0.0,
      3.0, 3.0, 3.0, 3.0, 3.0, 7.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 6.0, 5.0, 1.0, 3.0,
      4.0, 4.0, 6.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 5.0, 2.0, 1.0, 3.0, 4.0, 3.0, 4.0,
      6.0, 4.0, 1.0, 0.0, 5.0, 0.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10724737965272536
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03886900733136784
    mean_inference_ms: 1.9713906511221955
    mean_raw_obs_processing_ms: 0.4488377943244957
time_since_restore: 71.69652199745178
time_this_iter_s: 10.261682987213135
time_total_s: 71.69652199745178
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1691991835
timesteps_total: 53200
training_iteration: 7
trial_id: default
train step: 8
agent_timesteps_total: 60200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0384211540222168
  StateBufferConnector_ms: 0.0071108341217041016
  ViewRequirementAgentConnector_ms: 0.23276782035827637
counters:
  num_agent_steps_sampled: 60200
  num_agent_steps_trained: 43500
  num_env_steps_sampled: 60200
  num_env_steps_trained: 43500
  num_samples_added_to_queue: 60000
  num_training_step_calls_since_last_synch_worker_weights: 685
  num_weight_broadcasts: 1177
custom_metrics: {}
date: 2023-08-14_14-44-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.83
episode_reward_min: 0.0
episodes_this_iter: 55
episodes_total: 471
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 27.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3444865942001343
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -24.02193832397461
        total_loss: -13.847606658935547
        var_gnorm: 63.320003509521484
        vf_explained_var: 0.506139874458313
        vf_loss: 33.79352951049805
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 87.0
  learner_queue:
    size_count: 93
    size_mean: 11.2
    size_quantiles: [3.0, 5.9, 11.5, 16.0, 16.0]
    size_std: 3.773592452822642
  num_agent_steps_sampled: 60200
  num_agent_steps_trained: 43500
  num_env_steps_sampled: 60200
  num_env_steps_trained: 43500
  num_samples_added_to_queue: 60000
  num_training_step_calls_since_last_synch_worker_weights: 685
  num_weight_broadcasts: 1177
  timing_breakdown:
    learner_dequeue_time_ms: 1829.119
    learner_grad_time_ms: 343.265
    learner_load_time_ms: 20.308
    learner_load_wait_time_ms: 3.172
iterations_since_restore: 8
node_ip: 127.0.0.1
num_agent_steps_sampled: 60200
num_agent_steps_trained: 43500
num_env_steps_sampled: 60200
num_env_steps_sampled_this_iter: 7000
num_env_steps_sampled_throughput_per_sec: 699.9932075205932
num_env_steps_trained: 43500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9932075205932
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 58.80666666666666
  ram_util_percent: 81.6
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10879641830245401
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039654306666762514
  mean_inference_ms: 2.001803362187762
  mean_raw_obs_processing_ms: 0.45515684511009824
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0384211540222168
    StateBufferConnector_ms: 0.0071108341217041016
    ViewRequirementAgentConnector_ms: 0.23276782035827637
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.83
  episode_reward_min: 0.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 5.0, 3.0, 3.0, 1.0, 0.0, 3.0, 3.0, 3.0, 3.0, 3.0, 7.0, 4.0,
      3.0, 2.0, 4.0, 2.0, 3.0, 6.0, 5.0, 1.0, 3.0, 4.0, 4.0, 6.0, 1.0, 1.0, 1.0, 3.0,
      3.0, 2.0, 5.0, 2.0, 1.0, 3.0, 4.0, 3.0, 4.0, 6.0, 4.0, 1.0, 0.0, 5.0, 0.0, 2.0,
      3.0, 3.0, 0.0, 3.0, 7.0, 3.0, 4.0, 2.0, 4.0, 4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0,
      4.0, 3.0, 5.0, 2.0, 3.0, 5.0, 2.0, 7.0, 2.0, 1.0, 2.0, 7.0, 1.0, 3.0, 6.0, 2.0,
      3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 4.0, 1.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 1.0, 0.0,
      1.0, 1.0, 4.0, 3.0, 5.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10879641830245401
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039654306666762514
    mean_inference_ms: 2.001803362187762
    mean_raw_obs_processing_ms: 0.45515684511009824
time_since_restore: 82.07169103622437
time_this_iter_s: 10.375169038772583
time_total_s: 82.07169103622437
timers:
  sample_time_ms: 0.038
  synch_weights_time_ms: 0.012
  training_iteration_time_ms: 0.111
timestamp: 1691991845
timesteps_total: 60200
training_iteration: 8
trial_id: default
train step: 9
agent_timesteps_total: 67100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.038510799407958984
  StateBufferConnector_ms: 0.007463693618774414
  ViewRequirementAgentConnector_ms: 0.22907781600952148
counters:
  num_agent_steps_sampled: 67100
  num_agent_steps_trained: 50500
  num_env_steps_sampled: 67100
  num_env_steps_trained: 50500
  num_samples_added_to_queue: 67000
  num_training_step_calls_since_last_synch_worker_weights: 1139
  num_weight_broadcasts: 1306
custom_metrics: {}
date: 2023-08-14_14-44-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.71
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 525
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 29.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.2812200784683228
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -4.479469299316406
        total_loss: 7.173569679260254
        var_gnorm: 63.32398223876953
        vf_explained_var: 0.49587827920913696
        vf_loss: 36.11827850341797
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 101.0
  learner_queue:
    size_count: 105
    size_mean: 13.14
    size_quantiles: [5.0, 9.0, 13.5, 16.0, 16.0]
    size_std: 2.8072050156695
  num_agent_steps_sampled: 67100
  num_agent_steps_trained: 50500
  num_env_steps_sampled: 67100
  num_env_steps_trained: 50500
  num_samples_added_to_queue: 67000
  num_training_step_calls_since_last_synch_worker_weights: 1139
  num_weight_broadcasts: 1306
  timing_breakdown:
    learner_dequeue_time_ms: 1600.48
    learner_grad_time_ms: 779.149
    learner_load_time_ms: 34.48
    learner_load_wait_time_ms: 14.887
iterations_since_restore: 9
node_ip: 127.0.0.1
num_agent_steps_sampled: 67100
num_agent_steps_trained: 50500
num_env_steps_sampled: 67100
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 689.9949660668465
num_env_steps_trained: 50500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9948931112935
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 60.98571428571429
  ram_util_percent: 81.54285714285713
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11001789438616313
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04012756682728684
  mean_inference_ms: 2.0236361934621936
  mean_raw_obs_processing_ms: 0.45950523604868576
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.038510799407958984
    StateBufferConnector_ms: 0.007463693618774414
    ViewRequirementAgentConnector_ms: 0.22907781600952148
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.71
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 1.0, 4.0, 3.0, 5.0, 2.0, 3.0, 5.0,
      2.0, 7.0, 2.0, 1.0, 2.0, 7.0, 1.0, 3.0, 6.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0,
      4.0, 1.0, 2.0, 2.0, 2.0, 1.0, 4.0, 2.0, 1.0, 0.0, 1.0, 1.0, 4.0, 3.0, 5.0, 1.0,
      3.0, 5.0, 2.0, 4.0, 3.0, 4.0, 0.0, 2.0, 5.0, 2.0, 2.0, 1.0, 6.0, 4.0, 4.0, 1.0,
      3.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 2.0, 4.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 4.0,
      3.0, 5.0, 1.0, 5.0, 3.0, 4.0, 1.0, 6.0, 4.0, 3.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0,
      4.0, 2.0, 4.0, 0.0, 1.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11001789438616313
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04012756682728684
    mean_inference_ms: 2.0236361934621936
    mean_raw_obs_processing_ms: 0.45950523604868576
time_since_restore: 92.32025194168091
time_this_iter_s: 10.248560905456543
time_total_s: 92.32025194168091
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.077
timestamp: 1691991856
timesteps_total: 67100
training_iteration: 9
trial_id: default
train step: 10
agent_timesteps_total: 73800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0410153865814209
  StateBufferConnector_ms: 0.008031129837036133
  ViewRequirementAgentConnector_ms: 0.2383124828338623
counters:
  num_agent_steps_sampled: 73800
  num_agent_steps_trained: 57000
  num_env_steps_sampled: 73800
  num_env_steps_trained: 57000
  num_samples_added_to_queue: 73500
  num_training_step_calls_since_last_synch_worker_weights: 785
  num_weight_broadcasts: 1437
custom_metrics: {}
date: 2023-08-14_14-44-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.61
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 577
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.2657884359359741
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -44.529571533203125
        total_loss: -38.149627685546875
        var_gnorm: 63.3287239074707
        vf_explained_var: 0.537451982498169
        vf_loss: 25.417768478393555
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 114.0
  learner_queue:
    size_count: 119
    size_mean: 14.54
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7229045243425414
  num_agent_steps_sampled: 73800
  num_agent_steps_trained: 57000
  num_env_steps_sampled: 73800
  num_env_steps_trained: 57000
  num_samples_added_to_queue: 73500
  num_training_step_calls_since_last_synch_worker_weights: 785
  num_weight_broadcasts: 1437
  timing_breakdown:
    learner_dequeue_time_ms: 1422.649
    learner_grad_time_ms: 453.303
    learner_load_time_ms: 30.454
    learner_load_wait_time_ms: 3.093
iterations_since_restore: 10
node_ip: 127.0.0.1
num_agent_steps_sampled: 73800
num_agent_steps_trained: 57000
num_env_steps_sampled: 73800
num_env_steps_sampled_this_iter: 6700
num_env_steps_sampled_throughput_per_sec: 669.998785974795
num_env_steps_trained: 57000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9988222143534
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 58.56666666666668
  ram_util_percent: 82.74666666666666
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11111397015082597
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04059301483385285
  mean_inference_ms: 2.0438167000243634
  mean_raw_obs_processing_ms: 0.46375917636293806
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0410153865814209
    StateBufferConnector_ms: 0.008031129837036133
    ViewRequirementAgentConnector_ms: 0.2383124828338623
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.61
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 5.0, 2.0, 2.0, 1.0, 6.0, 4.0, 4.0, 1.0, 3.0, 3.0, 2.0, 3.0,
      2.0, 4.0, 1.0, 2.0, 4.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 4.0, 3.0, 5.0, 1.0, 5.0,
      3.0, 4.0, 1.0, 6.0, 4.0, 3.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 0.0,
      1.0, 3.0, 2.0, 2.0, 2.0, 1.0, 2.0, 7.0, 3.0, 2.0, 3.0, 3.0, 5.0, 2.0, 3.0, 6.0,
      3.0, 0.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 4.0, 1.0,
      6.0, 4.0, 2.0, 4.0, 2.0, 6.0, 1.0, 0.0, 2.0, 0.0, 4.0, 2.0, 5.0, 4.0, 2.0, 1.0,
      3.0, 1.0, 2.0, 0.0, 2.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11111397015082597
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04059301483385285
    mean_inference_ms: 2.0438167000243634
    mean_raw_obs_processing_ms: 0.46375917636293806
time_since_restore: 102.54969668388367
time_this_iter_s: 10.229444742202759
time_total_s: 102.54969668388367
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.074
timestamp: 1691991866
timesteps_total: 73800
training_iteration: 10
trial_id: default
train step: 11
agent_timesteps_total: 80700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03948330879211426
  StateBufferConnector_ms: 0.007445573806762695
  ViewRequirementAgentConnector_ms: 0.23033785820007324
counters:
  num_agent_steps_sampled: 80700
  num_agent_steps_trained: 64000
  num_env_steps_sampled: 80700
  num_env_steps_trained: 64000
  num_samples_added_to_queue: 80500
  num_training_step_calls_since_last_synch_worker_weights: 324
  num_weight_broadcasts: 1572
custom_metrics: {}
date: 2023-08-14_14-44-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.0
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 631
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.400000000000006
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.2196612358093262
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -18.403751373291016
        total_loss: -3.0083365440368652
        var_gnorm: 63.33369827270508
        vf_explained_var: 0.5679618716239929
        vf_loss: 42.98744201660156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 128.0
  learner_queue:
    size_count: 134
    size_mean: 14.7
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6401219466856725
  num_agent_steps_sampled: 80700
  num_agent_steps_trained: 64000
  num_env_steps_sampled: 80700
  num_env_steps_trained: 64000
  num_samples_added_to_queue: 80500
  num_training_step_calls_since_last_synch_worker_weights: 324
  num_weight_broadcasts: 1572
  timing_breakdown:
    learner_dequeue_time_ms: 1280.385
    learner_grad_time_ms: 401.914
    learner_load_time_ms: 27.363
    learner_load_wait_time_ms: 3.051
iterations_since_restore: 11
node_ip: 127.0.0.1
num_agent_steps_sampled: 80700
num_agent_steps_trained: 64000
num_env_steps_sampled: 80700
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 689.9996380807868
num_env_steps_trained: 64000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9996328355808
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 57.457142857142856
  ram_util_percent: 82.38571428571429
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.111972016235454
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04106186256146053
  mean_inference_ms: 2.061780990928747
  mean_raw_obs_processing_ms: 0.4673480494469586
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03948330879211426
    StateBufferConnector_ms: 0.007445573806762695
    ViewRequirementAgentConnector_ms: 0.23033785820007324
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.0
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 3.0, 5.0, 2.0, 3.0, 6.0, 3.0, 0.0, 0.0, 1.0, 3.0, 1.0,
      2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0, 4.0, 1.0, 6.0, 4.0, 2.0, 4.0, 2.0, 6.0,
      1.0, 0.0, 2.0, 0.0, 4.0, 2.0, 5.0, 4.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 4.0,
      4.0, 3.0, 4.0, 7.0, 3.0, 6.0, 2.0, 2.0, 4.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 4.0,
      1.0, 2.0, 4.0, 6.0, 2.0, 6.0, 3.0, 4.0, 4.0, 3.0, 4.0, 1.0, 5.0, 0.0, 8.0, 1.0,
      5.0, 4.0, 3.0, 5.0, 1.0, 0.0, 6.0, 1.0, 5.0, 4.0, 5.0, 2.0, 2.0, 5.0, 3.0, 1.0,
      3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.111972016235454
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04106186256146053
    mean_inference_ms: 2.061780990928747
    mean_raw_obs_processing_ms: 0.4673480494469586
time_since_restore: 112.84570860862732
time_this_iter_s: 10.296011924743652
time_total_s: 112.84570860862732
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.089
timestamp: 1691991876
timesteps_total: 80700
training_iteration: 11
trial_id: default
train step: 12
agent_timesteps_total: 85800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.042395591735839844
  StateBufferConnector_ms: 0.007776021957397461
  ViewRequirementAgentConnector_ms: 0.24352622032165527
counters:
  num_agent_steps_sampled: 85800
  num_agent_steps_trained: 69000
  num_env_steps_sampled: 85800
  num_env_steps_trained: 69000
  num_samples_added_to_queue: 85500
  num_training_step_calls_since_last_synch_worker_weights: 716
  num_weight_broadcasts: 1669
custom_metrics: {}
date: 2023-08-14_14-44-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.94
episode_reward_min: 0.0
episodes_this_iter: 40
episodes_total: 671
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.267900824546814
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 4.335756301879883
        total_loss: 14.585126876831055
        var_gnorm: 63.3377571105957
        vf_explained_var: 0.6612421274185181
        vf_loss: 33.17774963378906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 138.0
  learner_queue:
    size_count: 143
    size_mean: 14.62
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.6357261384473871
  num_agent_steps_sampled: 85800
  num_agent_steps_trained: 69000
  num_env_steps_sampled: 85800
  num_env_steps_trained: 69000
  num_samples_added_to_queue: 85500
  num_training_step_calls_since_last_synch_worker_weights: 716
  num_weight_broadcasts: 1669
  timing_breakdown:
    learner_dequeue_time_ms: 1280.385
    learner_grad_time_ms: 1036.593
    learner_load_time_ms: 27.363
    learner_load_wait_time_ms: 6.719
iterations_since_restore: 12
node_ip: 127.0.0.1
num_agent_steps_sampled: 85800
num_agent_steps_trained: 69000
num_env_steps_sampled: 85800
num_env_steps_sampled_this_iter: 5100
num_env_steps_sampled_throughput_per_sec: 509.9989786168527
num_env_steps_trained: 69000
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.9989986439732
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 66.87999999999998
  ram_util_percent: 81.65333333333335
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11352341727251282
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041761811532962
  mean_inference_ms: 2.0906634831816913
  mean_raw_obs_processing_ms: 0.472925144674569
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.042395591735839844
    StateBufferConnector_ms: 0.007776021957397461
    ViewRequirementAgentConnector_ms: 0.24352622032165527
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.94
  episode_reward_min: 0.0
  episodes_this_iter: 40
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 0.0, 2.0, 4.0, 4.0, 3.0, 4.0, 7.0, 3.0, 6.0, 2.0, 2.0,
      4.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 4.0, 1.0, 2.0, 4.0, 6.0, 2.0, 6.0, 3.0, 4.0,
      4.0, 3.0, 4.0, 1.0, 5.0, 0.0, 8.0, 1.0, 5.0, 4.0, 3.0, 5.0, 1.0, 0.0, 6.0, 1.0,
      5.0, 4.0, 5.0, 2.0, 2.0, 5.0, 3.0, 1.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 3.0,
      5.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 6.0, 1.0, 2.0, 3.0, 6.0, 1.0, 1.0,
      3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 5.0, 1.0, 5.0, 4.0, 2.0, 3.0, 3.0, 4.0,
      1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11352341727251282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041761811532962
    mean_inference_ms: 2.0906634831816913
    mean_raw_obs_processing_ms: 0.472925144674569
time_since_restore: 123.23726439476013
time_this_iter_s: 10.391555786132812
time_total_s: 123.23726439476013
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691991887
timesteps_total: 85800
training_iteration: 12
trial_id: default
train step: 13
agent_timesteps_total: 92350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0420074462890625
  StateBufferConnector_ms: 0.007605314254760742
  ViewRequirementAgentConnector_ms: 0.24085378646850586
counters:
  num_agent_steps_sampled: 92350
  num_agent_steps_trained: 75500
  num_env_steps_sampled: 92350
  num_env_steps_trained: 75500
  num_samples_added_to_queue: 92000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 1795
custom_metrics: {}
date: 2023-08-14_14-44-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.65
episode_reward_min: 0.0
episodes_this_iter: 50
episodes_total: 721
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 30.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.2591584920883179
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 37.72784423828125
        total_loss: 48.0701789855957
        var_gnorm: 63.34354782104492
        vf_explained_var: 0.726304292678833
        vf_loss: 33.27625274658203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 151.0
  learner_queue:
    size_count: 154
    size_mean: 14.68
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.5929846201391902
  num_agent_steps_sampled: 92350
  num_agent_steps_trained: 75500
  num_env_steps_sampled: 92350
  num_env_steps_trained: 75500
  num_samples_added_to_queue: 92000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 1795
  timing_breakdown:
    learner_dequeue_time_ms: 1229.097
    learner_grad_time_ms: 924.566
    learner_load_time_ms: 25.722
    learner_load_wait_time_ms: 11.265
iterations_since_restore: 13
node_ip: 127.0.0.1
num_agent_steps_sampled: 92350
num_agent_steps_trained: 75500
num_env_steps_sampled: 92350
num_env_steps_sampled_this_iter: 6550
num_env_steps_sampled_throughput_per_sec: 654.8865663789572
num_env_steps_trained: 75500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.8874322844614
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 61.373333333333335
  ram_util_percent: 82.61333333333332
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11556207389505502
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042686463943063406
  mean_inference_ms: 2.1273551031036786
  mean_raw_obs_processing_ms: 0.48015785334204764
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0420074462890625
    StateBufferConnector_ms: 0.007605314254760742
    ViewRequirementAgentConnector_ms: 0.24085378646850586
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.65
  episode_reward_min: 0.0
  episodes_this_iter: 50
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 3.0, 1.0, 3.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 3.0, 5.0, 3.0,
      1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 6.0, 1.0, 2.0, 3.0, 6.0, 1.0, 1.0, 3.0, 3.0,
      1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 5.0, 1.0, 5.0, 4.0, 2.0, 3.0, 3.0, 4.0, 1.0, 2.0,
      1.0, 3.0, 0.0, 0.0, 0.0, 1.0, 3.0, 1.0, 3.0, 4.0, 6.0, 2.0, 1.0, 1.0, 2.0, 2.0,
      1.0, 2.0, 3.0, 0.0, 4.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 3.0, 5.0, 1.0, 1.0, 1.0,
      2.0, 3.0, 6.0, 3.0, 4.0, 5.0, 4.0, 7.0, 5.0, 4.0, 4.0, 1.0, 2.0, 6.0, 3.0, 2.0,
      4.0, 3.0, 1.0, 3.0, 2.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11556207389505502
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042686463943063406
    mean_inference_ms: 2.1273551031036786
    mean_raw_obs_processing_ms: 0.48015785334204764
time_since_restore: 133.36922430992126
time_this_iter_s: 10.131959915161133
time_total_s: 133.36922430992126
timers:
  sample_time_ms: 0.052
  synch_weights_time_ms: 0.434
  training_iteration_time_ms: 0.592
timestamp: 1691991897
timesteps_total: 92350
training_iteration: 13
trial_id: default
train step: 14
agent_timesteps_total: 99400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035318851470947266
  StateBufferConnector_ms: 0.006253719329833984
  ViewRequirementAgentConnector_ms: 0.20811820030212402
counters:
  num_agent_steps_sampled: 99400
  num_agent_steps_trained: 82500
  num_env_steps_sampled: 99400
  num_env_steps_trained: 82500
  num_samples_added_to_queue: 99000
  num_training_step_calls_since_last_synch_worker_weights: 1932
  num_weight_broadcasts: 1933
custom_metrics: {}
date: 2023-08-14_14-45-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.95
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 777
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 29.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1586623191833496
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -50.25075149536133
        total_loss: -39.01478576660156
        var_gnorm: 63.35208511352539
        vf_explained_var: 0.7604401111602783
        vf_loss: 34.05855178833008
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 165.0
  learner_queue:
    size_count: 169
    size_mean: 14.86
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5363593329686906
  num_agent_steps_sampled: 99400
  num_agent_steps_trained: 82500
  num_env_steps_sampled: 99400
  num_env_steps_trained: 82500
  num_samples_added_to_queue: 99000
  num_training_step_calls_since_last_synch_worker_weights: 1932
  num_weight_broadcasts: 1933
  timing_breakdown:
    learner_dequeue_time_ms: 156.969
    learner_grad_time_ms: 498.464
    learner_load_time_ms: 16.93
    learner_load_wait_time_ms: 5.094
iterations_since_restore: 14
node_ip: 127.0.0.1
num_agent_steps_sampled: 99400
num_agent_steps_trained: 82500
num_env_steps_sampled: 99400
num_env_steps_sampled_this_iter: 7050
num_env_steps_sampled_throughput_per_sec: 704.995898747461
num_env_steps_trained: 82500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9959278343584
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 58.01428571428571
  ram_util_percent: 81.41428571428571
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11618073968198118
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.043033995866245005
  mean_inference_ms: 2.1410474443440575
  mean_raw_obs_processing_ms: 0.4823535378898638
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035318851470947266
    StateBufferConnector_ms: 0.006253719329833984
    ViewRequirementAgentConnector_ms: 0.20811820030212402
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.95
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 0.0, 4.0, 1.0, 2.0, 3.0,
      1.0, 2.0, 0.0, 3.0, 5.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 3.0, 4.0, 5.0, 4.0, 7.0,
      5.0, 4.0, 4.0, 1.0, 2.0, 6.0, 3.0, 2.0, 4.0, 3.0, 1.0, 3.0, 2.0, 5.0, 4.0, 3.0,
      5.0, 4.0, 3.0, 7.0, 3.0, 4.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 4.0, 1.0, 1.0,
      3.0, 5.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 5.0, 3.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0,
      2.0, 5.0, 3.0, 2.0, 2.0, 8.0, 4.0, 7.0, 7.0, 2.0, 0.0, 3.0, 2.0, 4.0, 1.0, 2.0,
      2.0, 3.0, 4.0, 4.0, 1.0, 1.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11618073968198118
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.043033995866245005
    mean_inference_ms: 2.1410474443440575
    mean_raw_obs_processing_ms: 0.4823535378898638
time_since_restore: 143.6621654033661
time_this_iter_s: 10.292941093444824
time_total_s: 143.6621654033661
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.105
timestamp: 1691991907
timesteps_total: 99400
training_iteration: 14
trial_id: default
train step: 15
agent_timesteps_total: 106700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0358424186706543
  StateBufferConnector_ms: 0.006333827972412109
  ViewRequirementAgentConnector_ms: 0.20929980278015137
counters:
  num_agent_steps_sampled: 106700
  num_agent_steps_trained: 90000
  num_env_steps_sampled: 106700
  num_env_steps_trained: 90000
  num_samples_added_to_queue: 106500
  num_training_step_calls_since_last_synch_worker_weights: 310
  num_weight_broadcasts: 2075
custom_metrics: {}
date: 2023-08-14_14-45-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.93
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 834
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.165982723236084
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 85.80320739746094
        total_loss: 103.28755187988281
        var_gnorm: 63.35314178466797
        vf_explained_var: 0.5973670482635498
        vf_loss: 46.628501892089844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 180.0
  learner_queue:
    size_count: 186
    size_mean: 15.06
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3770983988081607
  num_agent_steps_sampled: 106700
  num_agent_steps_trained: 90000
  num_env_steps_sampled: 106700
  num_env_steps_trained: 90000
  num_samples_added_to_queue: 106500
  num_training_step_calls_since_last_synch_worker_weights: 310
  num_weight_broadcasts: 2075
  timing_breakdown:
    learner_dequeue_time_ms: 12.921
    learner_grad_time_ms: 290.134
    learner_load_time_ms: 16.943
    learner_load_wait_time_ms: 2.617
iterations_since_restore: 15
node_ip: 127.0.0.1
num_agent_steps_sampled: 106700
num_agent_steps_trained: 90000
num_env_steps_sampled: 106700
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9944479887746
num_env_steps_trained: 90000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.994295878878
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.38666666666667
  ram_util_percent: 82.08666666666666
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11612202195712738
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042980037581627446
  mean_inference_ms: 2.1396000679394422
  mean_raw_obs_processing_ms: 0.4815898089850931
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0358424186706543
    StateBufferConnector_ms: 0.006333827972412109
    ViewRequirementAgentConnector_ms: 0.20929980278015137
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.93
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 1.0, 1.0, 3.0, 5.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 5.0,
      3.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 2.0, 8.0, 4.0, 7.0, 7.0,
      2.0, 0.0, 3.0, 2.0, 4.0, 1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 1.0, 1.0, 2.0, 5.0, 2.0,
      4.0, 1.0, 3.0, 4.0, 1.0, 1.0, 1.0, 5.0, 3.0, 3.0, 2.0, 1.0, 3.0, 0.0, 1.0, 2.0,
      4.0, 5.0, 4.0, 3.0, 4.0, 4.0, 3.0, 5.0, 4.0, 1.0, 3.0, 1.0, 3.0, 2.0, 0.0, 8.0,
      4.0, 5.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 5.0, 6.0, 2.0, 6.0, 2.0, 1.0, 2.0,
      1.0, 3.0, 1.0, 7.0, 2.0, 7.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11612202195712738
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042980037581627446
    mean_inference_ms: 2.1396000679394422
    mean_raw_obs_processing_ms: 0.4815898089850931
time_since_restore: 153.88572525978088
time_this_iter_s: 10.223559856414795
time_total_s: 153.88572525978088
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691991917
timesteps_total: 106700
training_iteration: 15
trial_id: default
train step: 16
agent_timesteps_total: 114600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034548044204711914
  StateBufferConnector_ms: 0.006309986114501953
  ViewRequirementAgentConnector_ms: 0.20631909370422363
counters:
  num_agent_steps_sampled: 114600
  num_agent_steps_trained: 98000
  num_env_steps_sampled: 114600
  num_env_steps_trained: 98000
  num_samples_added_to_queue: 114500
  num_training_step_calls_since_last_synch_worker_weights: 1014
  num_weight_broadcasts: 2228
custom_metrics: {}
date: 2023-08-14_14-45-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.36
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 896
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.2183570861816406
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -27.507091522216797
        total_loss: -21.132373809814453
        var_gnorm: 63.35072708129883
        vf_explained_var: 0.8174533843994141
        vf_loss: 24.933006286621094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 196.0
  learner_queue:
    size_count: 200
    size_mean: 15.16
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3169662106523463
  num_agent_steps_sampled: 114600
  num_agent_steps_trained: 98000
  num_env_steps_sampled: 114600
  num_env_steps_trained: 98000
  num_samples_added_to_queue: 114500
  num_training_step_calls_since_last_synch_worker_weights: 1014
  num_weight_broadcasts: 2228
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 439.618
    learner_load_time_ms: 16.52
    learner_load_wait_time_ms: 2.836
iterations_since_restore: 16
node_ip: 127.0.0.1
num_agent_steps_sampled: 114600
num_agent_steps_trained: 98000
num_env_steps_sampled: 114600
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.9955926187355
num_env_steps_trained: 98000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9955368290993
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 53.75
  ram_util_percent: 80.9357142857143
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11556277726259095
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042689678608987744
  mean_inference_ms: 2.1279474181487616
  mean_raw_obs_processing_ms: 0.4793659823919741
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034548044204711914
    StateBufferConnector_ms: 0.006309986114501953
    ViewRequirementAgentConnector_ms: 0.20631909370422363
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.36
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 4.0, 3.0, 4.0, 4.0, 3.0, 5.0, 4.0, 1.0, 3.0, 1.0, 3.0, 2.0,
      0.0, 8.0, 4.0, 5.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 5.0, 6.0, 2.0, 6.0, 2.0,
      1.0, 2.0, 1.0, 3.0, 1.0, 7.0, 2.0, 7.0, 0.0, 6.0, 0.0, 2.0, 6.0, 3.0, 4.0, 4.0,
      5.0, 9.0, 1.0, 5.0, 3.0, 3.0, 2.0, 2.0, 6.0, 0.0, 4.0, 6.0, 3.0, 2.0, 4.0, 2.0,
      4.0, 4.0, 2.0, 2.0, 3.0, 4.0, 3.0, 3.0, 2.0, 2.0, 3.0, 5.0, 5.0, 4.0, 6.0, 4.0,
      2.0, 2.0, 1.0, 7.0, 2.0, 7.0, 4.0, 4.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 6.0, 6.0,
      7.0, 5.0, 6.0, 4.0, 1.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11556277726259095
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042689678608987744
    mean_inference_ms: 2.1279474181487616
    mean_raw_obs_processing_ms: 0.4793659823919741
time_since_restore: 164.05946826934814
time_this_iter_s: 10.17374300956726
time_total_s: 164.05946826934814
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.078
timestamp: 1691991928
timesteps_total: 114600
training_iteration: 16
trial_id: default
train step: 17
agent_timesteps_total: 121600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03626298904418945
  StateBufferConnector_ms: 0.006340980529785156
  ViewRequirementAgentConnector_ms: 0.2169954776763916
counters:
  num_agent_steps_sampled: 121600
  num_agent_steps_trained: 105000
  num_env_steps_sampled: 121600
  num_env_steps_trained: 105000
  num_samples_added_to_queue: 121500
  num_training_step_calls_since_last_synch_worker_weights: 1388
  num_weight_broadcasts: 2365
custom_metrics: {}
date: 2023-08-14_14-45-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 3.28
episode_reward_min: 0.0
episodes_this_iter: 55
episodes_total: 951
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1420791149139404
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -15.648208618164062
        total_loss: -15.981842041015625
        var_gnorm: 63.35432434082031
        vf_explained_var: 0.9033752679824829
        vf_loss: 10.753522872924805
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 210.0
  learner_queue:
    size_count: 214
    size_mean: 15.08
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3392535234226566
  num_agent_steps_sampled: 121600
  num_agent_steps_trained: 105000
  num_env_steps_sampled: 121600
  num_env_steps_trained: 105000
  num_samples_added_to_queue: 121500
  num_training_step_calls_since_last_synch_worker_weights: 1388
  num_weight_broadcasts: 2365
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 516.935
    learner_load_time_ms: 16.455
    learner_load_wait_time_ms: 3.25
iterations_since_restore: 17
node_ip: 127.0.0.1
num_agent_steps_sampled: 121600
num_agent_steps_trained: 105000
num_env_steps_sampled: 121600
num_env_steps_sampled_this_iter: 7000
num_env_steps_sampled_throughput_per_sec: 699.998047357284
num_env_steps_trained: 105000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.998047357284
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 58.128571428571426
  ram_util_percent: 79.84285714285714
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11522600177940522
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04260323096539919
  mean_inference_ms: 2.1236854227613544
  mean_raw_obs_processing_ms: 0.47837072353457716
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03626298904418945
    StateBufferConnector_ms: 0.006340980529785156
    ViewRequirementAgentConnector_ms: 0.2169954776763916
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 3.28
  episode_reward_min: 0.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 6.0, 3.0, 2.0, 4.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 4.0, 3.0,
      3.0, 2.0, 2.0, 3.0, 5.0, 5.0, 4.0, 6.0, 4.0, 2.0, 2.0, 1.0, 7.0, 2.0, 7.0, 4.0,
      4.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 6.0, 6.0, 7.0, 5.0, 6.0, 4.0, 1.0, 3.0, 3.0,
      0.0, 4.0, 3.0, 2.0, 5.0, 4.0, 2.0, 0.0, 4.0, 1.0, 6.0, 3.0, 4.0, 3.0, 5.0, 1.0,
      4.0, 5.0, 3.0, 2.0, 0.0, 4.0, 6.0, 2.0, 4.0, 4.0, 1.0, 0.0, 5.0, 4.0, 2.0, 5.0,
      1.0, 7.0, 4.0, 2.0, 5.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 2.0, 6.0, 2.0,
      5.0, 3.0, 5.0, 2.0, 5.0, 1.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11522600177940522
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04260323096539919
    mean_inference_ms: 2.1236854227613544
    mean_raw_obs_processing_ms: 0.47837072353457716
time_since_restore: 174.2943103313446
time_this_iter_s: 10.23484206199646
time_total_s: 174.2943103313446
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1691991938
timesteps_total: 121600
training_iteration: 17
trial_id: default
train step: 18
agent_timesteps_total: 128700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03825092315673828
  StateBufferConnector_ms: 0.006781101226806641
  ViewRequirementAgentConnector_ms: 0.2203984260559082
counters:
  num_agent_steps_sampled: 128700
  num_agent_steps_trained: 112000
  num_env_steps_sampled: 128700
  num_env_steps_trained: 112000
  num_samples_added_to_queue: 128500
  num_training_step_calls_since_last_synch_worker_weights: 337
  num_weight_broadcasts: 2504
custom_metrics: {}
date: 2023-08-14_14-45-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.25
episode_reward_min: 0.0
episodes_this_iter: 55
episodes_total: 1006
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9895249605178833
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -46.804290771484375
        total_loss: -43.5965576171875
        var_gnorm: 63.35757827758789
        vf_explained_var: 0.8790649771690369
        vf_loss: 16.310718536376953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 224.0
  learner_queue:
    size_count: 230
    size_mean: 14.92
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4810806865258894
  num_agent_steps_sampled: 128700
  num_agent_steps_trained: 112000
  num_env_steps_sampled: 128700
  num_env_steps_trained: 112000
  num_samples_added_to_queue: 128500
  num_training_step_calls_since_last_synch_worker_weights: 337
  num_weight_broadcasts: 2504
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 318.615
    learner_load_time_ms: 16.401
    learner_load_wait_time_ms: 2.596
iterations_since_restore: 18
node_ip: 127.0.0.1
num_agent_steps_sampled: 128700
num_agent_steps_trained: 112000
num_env_steps_sampled: 128700
num_env_steps_sampled_this_iter: 7100
num_env_steps_sampled_throughput_per_sec: 709.9968006755036
num_env_steps_trained: 112000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.996845736412
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 56.08666666666667
  ram_util_percent: 79.70000000000002
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11520019121137803
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04268536424360266
  mean_inference_ms: 2.1254248842629515
  mean_raw_obs_processing_ms: 0.47877614017670567
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03825092315673828
    StateBufferConnector_ms: 0.006781101226806641
    ViewRequirementAgentConnector_ms: 0.2203984260559082
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.25
  episode_reward_min: 0.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 3.0, 4.0, 3.0, 5.0, 1.0, 4.0, 5.0, 3.0, 2.0, 0.0, 4.0, 6.0,
      2.0, 4.0, 4.0, 1.0, 0.0, 5.0, 4.0, 2.0, 5.0, 1.0, 7.0, 4.0, 2.0, 5.0, 2.0, 3.0,
      1.0, 2.0, 4.0, 4.0, 3.0, 2.0, 2.0, 6.0, 2.0, 5.0, 3.0, 5.0, 2.0, 5.0, 1.0, 2.0,
      3.0, 3.0, 4.0, 5.0, 3.0, 1.0, 3.0, 5.0, 3.0, 4.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0,
      2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 4.0, 9.0, 5.0, 0.0, 7.0, 3.0, 2.0,
      6.0, 0.0, 3.0, 5.0, 3.0, 3.0, 3.0, 9.0, 4.0, 3.0, 3.0, 5.0, 1.0, 2.0, 2.0, 4.0,
      5.0, 1.0, 5.0, 4.0, 2.0, 4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11520019121137803
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04268536424360266
    mean_inference_ms: 2.1254248842629515
    mean_raw_obs_processing_ms: 0.47877614017670567
time_since_restore: 184.52789855003357
time_this_iter_s: 10.233588218688965
time_total_s: 184.52789855003357
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.078
timestamp: 1691991948
timesteps_total: 128700
training_iteration: 18
trial_id: default
train step: 19
agent_timesteps_total: 135350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03854012489318848
  StateBufferConnector_ms: 0.00666499137878418
  ViewRequirementAgentConnector_ms: 0.22124218940734863
counters:
  num_agent_steps_sampled: 135350
  num_agent_steps_trained: 118500
  num_env_steps_sampled: 135350
  num_env_steps_trained: 118500
  num_samples_added_to_queue: 135000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 2634
custom_metrics: {}
date: 2023-08-14_14-45-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.15
episode_reward_min: 0.0
episodes_this_iter: 51
episodes_total: 1057
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9134210348129272
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -31.79737091064453
        total_loss: -24.588233947753906
        var_gnorm: 63.36309051513672
        vf_explained_var: 0.8442198634147644
        vf_loss: 23.55248260498047
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 237.0
  learner_queue:
    size_count: 240
    size_mean: 15.16
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.286234815265082
  num_agent_steps_sampled: 135350
  num_agent_steps_trained: 118500
  num_env_steps_sampled: 135350
  num_env_steps_trained: 118500
  num_samples_added_to_queue: 135000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 2634
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 988.823
    learner_load_time_ms: 14.972
    learner_load_wait_time_ms: 24.257
iterations_since_restore: 19
node_ip: 127.0.0.1
num_agent_steps_sampled: 135350
num_agent_steps_trained: 118500
num_env_steps_sampled: 135350
num_env_steps_sampled_this_iter: 6650
num_env_steps_sampled_throughput_per_sec: 664.9041871808214
num_env_steps_trained: 118500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9063483722315
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 58.71428571428571
  ram_util_percent: 78.20714285714284
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1153716615172971
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04283211579442268
  mean_inference_ms: 2.1297746254466983
  mean_raw_obs_processing_ms: 0.4796389577231158
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03854012489318848
    StateBufferConnector_ms: 0.00666499137878418
    ViewRequirementAgentConnector_ms: 0.22124218940734863
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.15
  episode_reward_min: 0.0
  episodes_this_iter: 51
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 3.0, 4.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0,
      3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 4.0, 9.0, 5.0, 0.0, 7.0, 3.0, 2.0, 6.0, 0.0, 3.0,
      5.0, 3.0, 3.0, 3.0, 9.0, 4.0, 3.0, 3.0, 5.0, 1.0, 2.0, 2.0, 4.0, 5.0, 1.0, 5.0,
      4.0, 2.0, 4.0, 7.0, 3.0, 3.0, 1.0, 2.0, 3.0, 7.0, 3.0, 1.0, 2.0, 3.0, 0.0, 2.0,
      3.0, 1.0, 1.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 5.0, 4.0,
      2.0, 6.0, 2.0, 5.0, 3.0, 2.0, 6.0, 7.0, 3.0, 2.0, 2.0, 4.0, 5.0, 4.0, 1.0, 4.0,
      6.0, 3.0, 3.0, 1.0, 2.0, 5.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1153716615172971
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04283211579442268
    mean_inference_ms: 2.1297746254466983
    mean_raw_obs_processing_ms: 0.4796389577231158
time_since_restore: 194.66043949127197
time_this_iter_s: 10.132540941238403
time_total_s: 194.66043949127197
timers:
  sample_time_ms: 0.117
  synch_weights_time_ms: 0.391
  training_iteration_time_ms: 0.617
timestamp: 1691991958
timesteps_total: 135350
training_iteration: 19
trial_id: default
train step: 20
agent_timesteps_total: 143300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0353090763092041
  StateBufferConnector_ms: 0.006227731704711914
  ViewRequirementAgentConnector_ms: 0.20548701286315918
counters:
  num_agent_steps_sampled: 143300
  num_agent_steps_trained: 126500
  num_env_steps_sampled: 143300
  num_env_steps_trained: 126500
  num_samples_added_to_queue: 143000
  num_training_step_calls_since_last_synch_worker_weights: 639
  num_weight_broadcasts: 2791
custom_metrics: {}
date: 2023-08-14_14-46-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.1
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 1120
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9493422508239746
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -49.76222229003906
        total_loss: -46.30458450317383
        var_gnorm: 63.36594009399414
        vf_explained_var: 0.8440724611282349
        vf_loss: 16.4086971282959
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 253.0
  learner_queue:
    size_count: 258
    size_mean: 15.1
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3601470508735443
  num_agent_steps_sampled: 143300
  num_agent_steps_trained: 126500
  num_env_steps_sampled: 143300
  num_env_steps_trained: 126500
  num_samples_added_to_queue: 143000
  num_training_step_calls_since_last_synch_worker_weights: 639
  num_weight_broadcasts: 2791
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 384.349
    learner_load_time_ms: 3.244
    learner_load_wait_time_ms: 2.534
iterations_since_restore: 20
node_ip: 127.0.0.1
num_agent_steps_sampled: 143300
num_agent_steps_trained: 126500
num_env_steps_sampled: 143300
num_env_steps_sampled_this_iter: 7950
num_env_steps_sampled_throughput_per_sec: 794.995792172769
num_env_steps_trained: 126500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9957657084468
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.833333333333336
  ram_util_percent: 75.36666666666666
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11518441074003352
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04271067498775958
  mean_inference_ms: 2.125139567348665
  mean_raw_obs_processing_ms: 0.47859597833645895
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0353090763092041
    StateBufferConnector_ms: 0.006227731704711914
    ViewRequirementAgentConnector_ms: 0.20548701286315918
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.1
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 5.0,
      4.0, 2.0, 6.0, 2.0, 5.0, 3.0, 2.0, 6.0, 7.0, 3.0, 2.0, 2.0, 4.0, 5.0, 4.0, 1.0,
      4.0, 6.0, 3.0, 3.0, 1.0, 2.0, 5.0, 3.0, 5.0, 2.0, 5.0, 3.0, 0.0, 2.0, 5.0, 2.0,
      3.0, 1.0, 2.0, 3.0, 4.0, 9.0, 3.0, 3.0, 3.0, 3.0, 6.0, 1.0, 4.0, 1.0, 3.0, 1.0,
      5.0, 4.0, 0.0, 6.0, 4.0, 10.0, 4.0, 3.0, 5.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0,
      1.0, 1.0, 3.0, 2.0, 4.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 0.0, 2.0, 3.0, 2.0,
      1.0, 7.0, 3.0, 3.0, 3.0, 2.0, 6.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11518441074003352
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04271067498775958
    mean_inference_ms: 2.125139567348665
    mean_raw_obs_processing_ms: 0.47859597833645895
time_since_restore: 204.85858869552612
time_this_iter_s: 10.19814920425415
time_total_s: 204.85858869552612
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691991968
timesteps_total: 143300
training_iteration: 20
trial_id: default
train step: 21
agent_timesteps_total: 151400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.032975196838378906
  StateBufferConnector_ms: 0.0058307647705078125
  ViewRequirementAgentConnector_ms: 0.1992049217224121
counters:
  num_agent_steps_sampled: 151400
  num_agent_steps_trained: 134500
  num_env_steps_sampled: 151400
  num_env_steps_trained: 134500
  num_samples_added_to_queue: 151000
  num_training_step_calls_since_last_synch_worker_weights: 79
  num_weight_broadcasts: 2948
custom_metrics: {}
date: 2023-08-14_14-46-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.48
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 1183
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0368537902832031
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -71.62055206298828
        total_loss: -66.64299011230469
        var_gnorm: 63.370296478271484
        vf_explained_var: 0.8188360929489136
        vf_loss: 20.32366180419922
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 269.0
  learner_queue:
    size_count: 276
    size_mean: 14.76
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7153425313913253
  num_agent_steps_sampled: 151400
  num_agent_steps_trained: 134500
  num_env_steps_sampled: 151400
  num_env_steps_trained: 134500
  num_samples_added_to_queue: 151000
  num_training_step_calls_since_last_synch_worker_weights: 79
  num_weight_broadcasts: 2948
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 258.071
    learner_load_time_ms: 3.272
    learner_load_wait_time_ms: 2.689
iterations_since_restore: 21
node_ip: 127.0.0.1
num_agent_steps_sampled: 151400
num_agent_steps_trained: 134500
num_env_steps_sampled: 151400
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9972384070136
num_env_steps_trained: 134500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9972725007542
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.72857142857142
  ram_util_percent: 75.54285714285716
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11459743680687297
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04236129799935243
  mean_inference_ms: 2.112265389965925
  mean_raw_obs_processing_ms: 0.47587945538056736
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.032975196838378906
    StateBufferConnector_ms: 0.0058307647705078125
    ViewRequirementAgentConnector_ms: 0.1992049217224121
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.48
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 6.0, 4.0, 10.0, 4.0, 3.0, 5.0, 2.0, 3.0, 2.0, 3.0, 5.0,
      2.0, 1.0, 1.0, 3.0, 2.0, 4.0, 1.0, 2.0, 4.0, 2.0, 2.0, 2.0, 1.0, 0.0, 2.0, 3.0,
      2.0, 1.0, 7.0, 3.0, 3.0, 3.0, 2.0, 6.0, 0.0, 2.0, 4.0, 5.0, 4.0, 7.0, 4.0, 4.0,
      7.0, 4.0, 4.0, 2.0, 4.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 3.0, 4.0, 2.0, 2.0, 1.0,
      2.0, 3.0, 3.0, 3.0, 4.0, 6.0, 6.0, 3.0, 4.0, 4.0, 5.0, 5.0, 5.0, 4.0, 6.0, 6.0,
      0.0, 3.0, 1.0, 3.0, 3.0, 5.0, 7.0, 1.0, 3.0, 6.0, 3.0, 6.0, 7.0, 2.0, 3.0, 7.0,
      2.0, 3.0, 6.0, 2.0, 2.0, 6.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11459743680687297
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04236129799935243
    mean_inference_ms: 2.112265389965925
    mean_raw_obs_processing_ms: 0.47587945538056736
time_since_restore: 215.1505115032196
time_this_iter_s: 10.291922807693481
time_total_s: 215.1505115032196
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.088
timestamp: 1691991979
timesteps_total: 151400
training_iteration: 21
trial_id: default
train step: 22
agent_timesteps_total: 159500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031844377517700195
  StateBufferConnector_ms: 0.0055234432220458984
  ViewRequirementAgentConnector_ms: 0.18958449363708496
counters:
  num_agent_steps_sampled: 159500
  num_agent_steps_trained: 143000
  num_env_steps_sampled: 159500
  num_env_steps_trained: 143000
  num_samples_added_to_queue: 159500
  num_training_step_calls_since_last_synch_worker_weights: 950
  num_weight_broadcasts: 3107
custom_metrics: {}
date: 2023-08-14_14-46-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.77
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 1247
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1067277193069458
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 50.34453201293945
        total_loss: 59.573204040527344
        var_gnorm: 63.373130798339844
        vf_explained_var: 0.7101073265075684
        vf_loss: 29.52462387084961
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 286.0
  learner_queue:
    size_count: 289
    size_mean: 14.98
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5683111936092275
  num_agent_steps_sampled: 159500
  num_agent_steps_trained: 143000
  num_env_steps_sampled: 159500
  num_env_steps_trained: 143000
  num_samples_added_to_queue: 159500
  num_training_step_calls_since_last_synch_worker_weights: 950
  num_weight_broadcasts: 3107
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 526.137
    learner_load_time_ms: 3.228
    learner_load_wait_time_ms: 2.702
iterations_since_restore: 22
node_ip: 127.0.0.1
num_agent_steps_sampled: 159500
num_agent_steps_trained: 143000
num_env_steps_sampled: 159500
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9892047890311
num_env_steps_trained: 143000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9886716921932
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 50.528571428571425
  ram_util_percent: 75.0
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11387135195281001
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042052680072163014
  mean_inference_ms: 2.099506040754249
  mean_raw_obs_processing_ms: 0.4732127369944747
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031844377517700195
    StateBufferConnector_ms: 0.0055234432220458984
    ViewRequirementAgentConnector_ms: 0.18958449363708496
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.77
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 6.0, 6.0, 3.0, 4.0, 4.0, 5.0, 5.0, 5.0, 4.0, 6.0, 6.0, 0.0,
      3.0, 1.0, 3.0, 3.0, 5.0, 7.0, 1.0, 3.0, 6.0, 3.0, 6.0, 7.0, 2.0, 3.0, 7.0, 2.0,
      3.0, 6.0, 2.0, 2.0, 6.0, 3.0, 4.0, 7.0, 1.0, 4.0, 3.0, 5.0, 1.0, 6.0, 3.0, 5.0,
      4.0, 5.0, 6.0, 5.0, 4.0, 4.0, 6.0, 1.0, 4.0, 8.0, 2.0, 3.0, 2.0, 7.0, 5.0, 3.0,
      3.0, 4.0, 4.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 4.0, 6.0, 3.0, 3.0,
      2.0, 2.0, 3.0, 1.0, 4.0, 3.0, 5.0, 6.0, 3.0, 2.0, 5.0, 3.0, 0.0, 1.0, 3.0, 8.0,
      3.0, 2.0, 2.0, 6.0, 4.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11387135195281001
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042052680072163014
    mean_inference_ms: 2.099506040754249
    mean_raw_obs_processing_ms: 0.4732127369944747
time_since_restore: 225.29501175880432
time_this_iter_s: 10.144500255584717
time_total_s: 225.29501175880432
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.082
timestamp: 1691991989
timesteps_total: 159500
training_iteration: 22
trial_id: default
train step: 23
agent_timesteps_total: 167100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03323101997375488
  StateBufferConnector_ms: 0.005870342254638672
  ViewRequirementAgentConnector_ms: 0.19788002967834473
counters:
  num_agent_steps_sampled: 167100
  num_agent_steps_trained: 150500
  num_env_steps_sampled: 167100
  num_env_steps_trained: 150500
  num_samples_added_to_queue: 167000
  num_training_step_calls_since_last_synch_worker_weights: 135
  num_weight_broadcasts: 3256
custom_metrics: {}
date: 2023-08-14_14-46-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.27
episode_reward_min: 0.0
episodes_this_iter: 59
episodes_total: 1306
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.142103672027588
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.21465826034545898
        total_loss: 7.403993606567383
        var_gnorm: 63.377960205078125
        vf_explained_var: 0.8369463682174683
        vf_loss: 25.799705505371094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 301.0
  learner_queue:
    size_count: 307
    size_mean: 14.82
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6933989488599548
  num_agent_steps_sampled: 167100
  num_agent_steps_trained: 150500
  num_env_steps_sampled: 167100
  num_env_steps_trained: 150500
  num_samples_added_to_queue: 167000
  num_training_step_calls_since_last_synch_worker_weights: 135
  num_weight_broadcasts: 3256
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 348.978
    learner_load_time_ms: 2.352
    learner_load_wait_time_ms: 2.575
iterations_since_restore: 23
node_ip: 127.0.0.1
num_agent_steps_sampled: 167100
num_agent_steps_trained: 150500
num_env_steps_sampled: 167100
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9955969111908
num_env_steps_trained: 150500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9956548465698
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.519999999999996
  ram_util_percent: 75.22000000000001
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1134715425399797
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041878788710913814
  mean_inference_ms: 2.0924839757416733
  mean_raw_obs_processing_ms: 0.4717164599607056
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03323101997375488
    StateBufferConnector_ms: 0.005870342254638672
    ViewRequirementAgentConnector_ms: 0.19788002967834473
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.27
  episode_reward_min: 0.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 1.0, 3.0,
      4.0, 4.0, 6.0, 3.0, 3.0, 2.0, 2.0, 3.0, 1.0, 4.0, 3.0, 5.0, 6.0, 3.0, 2.0, 5.0,
      3.0, 0.0, 1.0, 3.0, 8.0, 3.0, 2.0, 2.0, 6.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 4.0,
      4.0, 0.0, 1.0, 1.0, 5.0, 3.0, 2.0, 6.0, 4.0, 4.0, 3.0, 3.0, 2.0, 2.0, 1.0, 5.0,
      4.0, 3.0, 3.0, 3.0, 6.0, 1.0, 2.0, 1.0, 5.0, 5.0, 2.0, 6.0, 2.0, 3.0, 3.0, 7.0,
      2.0, 4.0, 4.0, 2.0, 4.0, 5.0, 2.0, 2.0, 4.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 1.0,
      3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1134715425399797
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041878788710913814
    mean_inference_ms: 2.0924839757416733
    mean_raw_obs_processing_ms: 0.4717164599607056
time_since_restore: 235.54555869102478
time_this_iter_s: 10.250546932220459
time_total_s: 235.54555869102478
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1691991999
timesteps_total: 167100
training_iteration: 23
trial_id: default
train step: 24
agent_timesteps_total: 174400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035540103912353516
  StateBufferConnector_ms: 0.006348848342895508
  ViewRequirementAgentConnector_ms: 0.2113027572631836
counters:
  num_agent_steps_sampled: 174400
  num_agent_steps_trained: 157500
  num_env_steps_sampled: 174400
  num_env_steps_trained: 157500
  num_samples_added_to_queue: 174000
  num_training_step_calls_since_last_synch_worker_weights: 733
  num_weight_broadcasts: 3399
custom_metrics: {}
date: 2023-08-14_14-46-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 3.39
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 1363
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1268815994262695
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.092057228088379
        total_loss: 18.34539031982422
        var_gnorm: 63.384212493896484
        vf_explained_var: 0.7700366973876953
        vf_loss: 31.775482177734375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 315.0
  learner_queue:
    size_count: 320
    size_mean: 14.62
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.730780170905595
  num_agent_steps_sampled: 174400
  num_agent_steps_trained: 157500
  num_env_steps_sampled: 174400
  num_env_steps_trained: 157500
  num_samples_added_to_queue: 174000
  num_training_step_calls_since_last_synch_worker_weights: 733
  num_weight_broadcasts: 3399
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 620.8
    learner_load_time_ms: 2.37
    learner_load_wait_time_ms: 3.152
iterations_since_restore: 24
node_ip: 127.0.0.1
num_agent_steps_sampled: 174400
num_agent_steps_trained: 157500
num_env_steps_sampled: 174400
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9995822908884
num_env_steps_trained: 157500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9995994570163
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 55.31428571428571
  ram_util_percent: 75.45714285714284
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11326419612602838
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04184841445320682
  mean_inference_ms: 2.0903881696654105
  mean_raw_obs_processing_ms: 0.4712929615073422
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035540103912353516
    StateBufferConnector_ms: 0.006348848342895508
    ViewRequirementAgentConnector_ms: 0.2113027572631836
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 3.39
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 1.0, 5.0, 4.0, 3.0, 3.0, 3.0, 6.0, 1.0, 2.0, 1.0, 5.0,
      5.0, 2.0, 6.0, 2.0, 3.0, 3.0, 7.0, 2.0, 4.0, 4.0, 2.0, 4.0, 5.0, 2.0, 2.0, 4.0,
      4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 1.0, 3.0, 4.0, 2.0, 2.0, 3.0, 3.0, 7.0, 6.0, 3.0,
      1.0, 2.0, 3.0, 4.0, 3.0, 5.0, 2.0, 6.0, 4.0, 4.0, 3.0, 4.0, 7.0, 6.0, 3.0, 5.0,
      5.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 5.0, 6.0, 2.0, 0.0, 3.0, 4.0, 3.0,
      1.0, 4.0, 3.0, 5.0, 2.0, 3.0, 7.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 3.0, 4.0,
      6.0, 1.0, 2.0, 6.0, 3.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11326419612602838
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04184841445320682
    mean_inference_ms: 2.0903881696654105
    mean_raw_obs_processing_ms: 0.4712929615073422
time_since_restore: 245.7565746307373
time_this_iter_s: 10.211015939712524
time_total_s: 245.7565746307373
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.089
timestamp: 1691992009
timesteps_total: 174400
training_iteration: 24
trial_id: default
train step: 25
agent_timesteps_total: 182000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03566145896911621
  StateBufferConnector_ms: 0.006309986114501953
  ViewRequirementAgentConnector_ms: 0.20987200736999512
counters:
  num_agent_steps_sampled: 182000
  num_agent_steps_trained: 165500
  num_env_steps_sampled: 182000
  num_env_steps_trained: 165500
  num_samples_added_to_queue: 182000
  num_training_step_calls_since_last_synch_worker_weights: 49
  num_weight_broadcasts: 3546
custom_metrics: {}
date: 2023-08-14_14-47-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.33
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 1423
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0694109201431274
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -17.105758666992188
        total_loss: -8.718791007995605
        var_gnorm: 63.38933563232422
        vf_explained_var: 0.7772051095962524
        vf_loss: 27.46804428100586
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 331.0
  learner_queue:
    size_count: 337
    size_mean: 14.8
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5874507866387544
  num_agent_steps_sampled: 182000
  num_agent_steps_trained: 165500
  num_env_steps_sampled: 182000
  num_env_steps_trained: 165500
  num_samples_added_to_queue: 182000
  num_training_step_calls_since_last_synch_worker_weights: 49
  num_weight_broadcasts: 3546
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 296.635
    learner_load_time_ms: 2.404
    learner_load_wait_time_ms: 2.762
iterations_since_restore: 25
node_ip: 127.0.0.1
num_agent_steps_sampled: 182000
num_agent_steps_trained: 165500
num_env_steps_sampled: 182000
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9945097366226
num_env_steps_trained: 165500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9942207753921
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 54.45333333333333
  ram_util_percent: 75.70666666666666
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11310070192268878
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04178894866627567
  mean_inference_ms: 2.088068937727667
  mean_raw_obs_processing_ms: 0.47079561561462063
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03566145896911621
    StateBufferConnector_ms: 0.006309986114501953
    ViewRequirementAgentConnector_ms: 0.20987200736999512
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.33
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 5.0, 1.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 3.0, 5.0, 6.0, 2.0,
      0.0, 3.0, 4.0, 3.0, 1.0, 4.0, 3.0, 5.0, 2.0, 3.0, 7.0, 1.0, 3.0, 2.0, 3.0, 4.0,
      3.0, 4.0, 3.0, 4.0, 6.0, 1.0, 2.0, 6.0, 3.0, 4.0, 4.0, 7.0, 0.0, 2.0, 5.0, 4.0,
      7.0, 4.0, 3.0, 2.0, 2.0, 5.0, 1.0, 1.0, 5.0, 6.0, 3.0, 3.0, 6.0, 3.0, 0.0, 2.0,
      1.0, 5.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 4.0, 1.0, 3.0, 5.0, 5.0, 7.0, 6.0, 0.0,
      3.0, 4.0, 4.0, 3.0, 8.0, 4.0, 1.0, 5.0, 3.0, 2.0, 3.0, 2.0, 5.0, 4.0, 2.0, 5.0,
      2.0, 7.0, 1.0, 2.0, 1.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11310070192268878
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04178894866627567
    mean_inference_ms: 2.088068937727667
    mean_raw_obs_processing_ms: 0.47079561561462063
time_since_restore: 256.02452778816223
time_this_iter_s: 10.267953157424927
time_total_s: 256.02452778816223
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.077
timestamp: 1691992020
timesteps_total: 182000
training_iteration: 25
trial_id: default
train step: 26
agent_timesteps_total: 189700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03444314002990723
  StateBufferConnector_ms: 0.0061070919036865234
  ViewRequirementAgentConnector_ms: 0.20377349853515625
counters:
  num_agent_steps_sampled: 189700
  num_agent_steps_trained: 173000
  num_env_steps_sampled: 189700
  num_env_steps_trained: 173000
  num_samples_added_to_queue: 189500
  num_training_step_calls_since_last_synch_worker_weights: 317
  num_weight_broadcasts: 3697
custom_metrics: {}
date: 2023-08-14_14-47-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.45
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 1483
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9390569925308228
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -27.232913970947266
        total_loss: -20.32736587524414
        var_gnorm: 63.392417907714844
        vf_explained_var: 0.76224285364151
        vf_loss: 23.2016658782959
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 346.0
  learner_queue:
    size_count: 352
    size_mean: 14.5
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7349351572897471
  num_agent_steps_sampled: 189700
  num_agent_steps_trained: 173000
  num_env_steps_sampled: 189700
  num_env_steps_trained: 173000
  num_samples_added_to_queue: 189500
  num_training_step_calls_since_last_synch_worker_weights: 317
  num_weight_broadcasts: 3697
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 311.56
    learner_load_time_ms: 2.398
    learner_load_wait_time_ms: 2.649
iterations_since_restore: 26
node_ip: 127.0.0.1
num_agent_steps_sampled: 189700
num_agent_steps_trained: 173000
num_env_steps_sampled: 189700
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 769.9957592720892
num_env_steps_trained: 173000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9958694208661
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.74285714285713
  ram_util_percent: 75.47857142857143
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11295665773113484
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04167599021304003
  mean_inference_ms: 2.0840340973865845
  mean_raw_obs_processing_ms: 0.4697491611763817
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03444314002990723
    StateBufferConnector_ms: 0.0061070919036865234
    ViewRequirementAgentConnector_ms: 0.20377349853515625
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.45
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 1.0, 5.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 4.0, 1.0, 3.0, 5.0,
      5.0, 7.0, 6.0, 0.0, 3.0, 4.0, 4.0, 3.0, 8.0, 4.0, 1.0, 5.0, 3.0, 2.0, 3.0, 2.0,
      5.0, 4.0, 2.0, 5.0, 2.0, 7.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 3.0,
      4.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 5.0, 4.0, 2.0, 1.0, 1.0, 6.0, 3.0, 7.0, 5.0,
      2.0, 5.0, 1.0, 3.0, 1.0, 6.0, 3.0, 3.0, 4.0, 6.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0,
      6.0, 5.0, 7.0, 6.0, 4.0, 1.0, 1.0, 6.0, 4.0, 5.0, 3.0, 3.0, 4.0, 5.0, 3.0, 2.0,
      3.0, 4.0, 2.0, 7.0, 3.0, 6.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11295665773113484
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04167599021304003
    mean_inference_ms: 2.0840340973865845
    mean_raw_obs_processing_ms: 0.4697491611763817
time_since_restore: 266.25030970573425
time_this_iter_s: 10.225781917572021
time_total_s: 266.25030970573425
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.074
timestamp: 1691992030
timesteps_total: 189700
training_iteration: 26
trial_id: default
train step: 27
agent_timesteps_total: 196900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035166263580322266
  StateBufferConnector_ms: 0.006308794021606445
  ViewRequirementAgentConnector_ms: 0.20965099334716797
counters:
  num_agent_steps_sampled: 196900
  num_agent_steps_trained: 180000
  num_env_steps_sampled: 196900
  num_env_steps_trained: 180000
  num_samples_added_to_queue: 196500
  num_training_step_calls_since_last_synch_worker_weights: 1862
  num_weight_broadcasts: 3837
custom_metrics: {}
date: 2023-08-14_14-47-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.7
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 1539
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9606894850730896
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.029762268066406
        total_loss: -1.0692400932312012
        var_gnorm: 63.399322509765625
        vf_explained_var: 0.762825071811676
        vf_loss: 27.527938842773438
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 360.0
  learner_queue:
    size_count: 364
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5657586020839867
  num_agent_steps_sampled: 196900
  num_agent_steps_trained: 180000
  num_env_steps_sampled: 196900
  num_env_steps_trained: 180000
  num_samples_added_to_queue: 196500
  num_training_step_calls_since_last_synch_worker_weights: 1862
  num_weight_broadcasts: 3837
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 684.207
    learner_load_time_ms: 2.398
    learner_load_wait_time_ms: 3.239
iterations_since_restore: 27
node_ip: 127.0.0.1
num_agent_steps_sampled: 196900
num_agent_steps_trained: 180000
num_env_steps_sampled: 196900
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 719.9967899465628
num_env_steps_trained: 180000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9968791147138
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 55.192857142857136
  ram_util_percent: 75.74285714285713
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11285166817649202
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04166022739059413
  mean_inference_ms: 2.082609535853407
  mean_raw_obs_processing_ms: 0.4693659357399097
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035166263580322266
    StateBufferConnector_ms: 0.006308794021606445
    ViewRequirementAgentConnector_ms: 0.20965099334716797
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.7
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 6.0, 3.0, 7.0, 5.0, 2.0, 5.0, 1.0, 3.0, 1.0, 6.0, 3.0, 3.0,
      4.0, 6.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 6.0, 5.0, 7.0, 6.0, 4.0, 1.0, 1.0, 6.0,
      4.0, 5.0, 3.0, 3.0, 4.0, 5.0, 3.0, 2.0, 3.0, 4.0, 2.0, 7.0, 3.0, 6.0, 4.0, 5.0,
      4.0, 2.0, 4.0, 3.0, 5.0, 2.0, 1.0, 5.0, 6.0, 7.0, 2.0, 3.0, 2.0, 3.0, 0.0, 5.0,
      2.0, 5.0, 1.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 4.0, 6.0, 4.0, 2.0, 4.0, 1.0, 5.0,
      2.0, 2.0, 9.0, 3.0, 4.0, 1.0, 3.0, 5.0, 5.0, 5.0, 1.0, 4.0, 3.0, 5.0, 5.0, 4.0,
      5.0, 2.0, 2.0, 3.0, 5.0, 2.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11285166817649202
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04166022739059413
    mean_inference_ms: 2.082609535853407
    mean_raw_obs_processing_ms: 0.4693659357399097
time_since_restore: 276.4336836338043
time_this_iter_s: 10.183373928070068
time_total_s: 276.4336836338043
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1691992040
timesteps_total: 196900
training_iteration: 27
trial_id: default
train step: 28
agent_timesteps_total: 204500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03508615493774414
  StateBufferConnector_ms: 0.006335020065307617
  ViewRequirementAgentConnector_ms: 0.21192502975463867
counters:
  num_agent_steps_sampled: 204500
  num_agent_steps_trained: 188000
  num_env_steps_sampled: 204500
  num_env_steps_trained: 188000
  num_samples_added_to_queue: 204500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 3983
custom_metrics: {}
date: 2023-08-14_14-47-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.83
episode_reward_min: 0.0
episodes_this_iter: 59
episodes_total: 1598
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9102262258529663
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -38.618621826171875
        total_loss: -31.860445022583008
        var_gnorm: 63.41280746459961
        vf_explained_var: 0.8356924057006836
        vf_loss: 22.618614196777344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 376.0
  learner_queue:
    size_count: 381
    size_mean: 14.84
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5538339679644027
  num_agent_steps_sampled: 204500
  num_agent_steps_trained: 188000
  num_env_steps_sampled: 204500
  num_env_steps_trained: 188000
  num_samples_added_to_queue: 204500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 3983
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 362.089
    learner_load_time_ms: 2.346
    learner_load_wait_time_ms: 2.695
iterations_since_restore: 28
node_ip: 127.0.0.1
num_agent_steps_sampled: 204500
num_agent_steps_trained: 188000
num_env_steps_sampled: 204500
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.4871931717247
num_env_steps_trained: 188000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.4602033386576
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 55.30666666666666
  ram_util_percent: 75.88666666666667
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11273822116186351
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04163309713690905
  mean_inference_ms: 2.0811753507234405
  mean_raw_obs_processing_ms: 0.46897520937037657
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03508615493774414
    StateBufferConnector_ms: 0.006335020065307617
    ViewRequirementAgentConnector_ms: 0.21192502975463867
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.83
  episode_reward_min: 0.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 5.0, 2.0, 5.0, 1.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 4.0, 6.0,
      4.0, 2.0, 4.0, 1.0, 5.0, 2.0, 2.0, 9.0, 3.0, 4.0, 1.0, 3.0, 5.0, 5.0, 5.0, 1.0,
      4.0, 3.0, 5.0, 5.0, 4.0, 5.0, 2.0, 2.0, 3.0, 5.0, 2.0, 4.0, 4.0, 4.0, 3.0, 3.0,
      5.0, 0.0, 3.0, 8.0, 5.0, 1.0, 2.0, 2.0, 3.0, 6.0, 5.0, 4.0, 5.0, 6.0, 3.0, 1.0,
      7.0, 2.0, 3.0, 3.0, 7.0, 3.0, 5.0, 3.0, 4.0, 6.0, 2.0, 3.0, 3.0, 5.0, 5.0, 5.0,
      3.0, 5.0, 3.0, 5.0, 7.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 2.0, 7.0, 9.0, 5.0, 5.0,
      4.0, 5.0, 2.0, 6.0, 4.0, 5.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11273822116186351
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04163309713690905
    mean_inference_ms: 2.0811753507234405
    mean_raw_obs_processing_ms: 0.46897520937037657
time_since_restore: 286.64316296577454
time_this_iter_s: 10.209479331970215
time_total_s: 286.64316296577454
timers:
  sample_time_ms: 0.061
  synch_weights_time_ms: 0.804
  training_iteration_time_ms: 3.739
timestamp: 1691992050
timesteps_total: 204500
training_iteration: 28
trial_id: default
train step: 29
agent_timesteps_total: 212000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03392338752746582
  StateBufferConnector_ms: 0.0064792633056640625
  ViewRequirementAgentConnector_ms: 0.20719003677368164
counters:
  num_agent_steps_sampled: 212000
  num_agent_steps_trained: 195500
  num_env_steps_sampled: 212000
  num_env_steps_trained: 195500
  num_samples_added_to_queue: 212000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 4130
custom_metrics: {}
date: 2023-08-14_14-47-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.86
episode_reward_min: 0.0
episodes_this_iter: 59
episodes_total: 1657
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0259432792663574
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 14.695807456970215
        total_loss: 21.676620483398438
        var_gnorm: 63.421409606933594
        vf_explained_var: 0.8202424049377441
        vf_loss: 24.221057891845703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 391.0
  learner_queue:
    size_count: 394
    size_mean: 15.08
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3833293172632466
  num_agent_steps_sampled: 212000
  num_agent_steps_trained: 195500
  num_env_steps_sampled: 212000
  num_env_steps_trained: 195500
  num_samples_added_to_queue: 212000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 4130
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 559.751
    learner_load_time_ms: 2.702
    learner_load_wait_time_ms: 3.196
iterations_since_restore: 29
node_ip: 127.0.0.1
num_agent_steps_sampled: 212000
num_agent_steps_trained: 195500
num_env_steps_sampled: 212000
num_env_steps_sampled_this_iter: 7500
num_env_steps_sampled_throughput_per_sec: 749.3118407224505
num_env_steps_trained: 195500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.3118407224505
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.142857142857146
  ram_util_percent: 76.07857142857144
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1126111622245301
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04154205938904905
  mean_inference_ms: 2.078598954943575
  mean_raw_obs_processing_ms: 0.46830948959148827
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03392338752746582
    StateBufferConnector_ms: 0.0064792633056640625
    ViewRequirementAgentConnector_ms: 0.20719003677368164
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.86
  episode_reward_min: 0.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 1.0, 7.0, 2.0, 3.0, 3.0, 7.0, 3.0, 5.0, 3.0, 4.0, 6.0, 2.0,
      3.0, 3.0, 5.0, 5.0, 5.0, 3.0, 5.0, 3.0, 5.0, 7.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0,
      2.0, 7.0, 9.0, 5.0, 5.0, 4.0, 5.0, 2.0, 6.0, 4.0, 5.0, 5.0, 6.0, 6.0, 6.0, 0.0,
      9.0, 2.0, 3.0, 1.0, 3.0, 2.0, 6.0, 4.0, 5.0, 7.0, 3.0, 1.0, 2.0, 4.0, 3.0, 2.0,
      3.0, 3.0, 2.0, 5.0, 4.0, 6.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 5.0, 4.0, 2.0,
      3.0, 4.0, 1.0, 3.0, 5.0, 1.0, 4.0, 6.0, 3.0, 7.0, 4.0, 3.0, 8.0, 2.0, 2.0, 5.0,
      7.0, 2.0, 2.0, 3.0, 4.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1126111622245301
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04154205938904905
    mean_inference_ms: 2.078598954943575
    mean_raw_obs_processing_ms: 0.46830948959148827
time_since_restore: 296.7828938961029
time_this_iter_s: 10.13973093032837
time_total_s: 296.7828938961029
timers:
  sample_time_ms: 0.062
  synch_weights_time_ms: 0.821
  training_iteration_time_ms: 2.407
timestamp: 1691992061
timesteps_total: 212000
training_iteration: 29
trial_id: default
train step: 30
agent_timesteps_total: 218350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.037014007568359375
  StateBufferConnector_ms: 0.007109165191650391
  ViewRequirementAgentConnector_ms: 0.2212841510772705
counters:
  num_agent_steps_sampled: 218350
  num_agent_steps_trained: 201500
  num_env_steps_sampled: 218350
  num_env_steps_trained: 201500
  num_samples_added_to_queue: 218000
  num_training_step_calls_since_last_synch_worker_weights: 1639
  num_weight_broadcasts: 4255
custom_metrics: {}
date: 2023-08-14_14-47-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.51
episode_reward_min: 0.0
episodes_this_iter: 50
episodes_total: 1707
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0351351499557495
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -3.236166477203369
        total_loss: 22.374740600585938
        var_gnorm: 63.428958892822266
        vf_explained_var: 0.6938155293464661
        vf_loss: 61.57316207885742
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 403.0
  learner_queue:
    size_count: 406
    size_mean: 15.4
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0770329614269007
  num_agent_steps_sampled: 218350
  num_agent_steps_trained: 201500
  num_env_steps_sampled: 218350
  num_env_steps_trained: 201500
  num_samples_added_to_queue: 218000
  num_training_step_calls_since_last_synch_worker_weights: 1639
  num_weight_broadcasts: 4255
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 607.734
    learner_load_time_ms: 2.712
    learner_load_wait_time_ms: 3.008
iterations_since_restore: 30
node_ip: 127.0.0.1
num_agent_steps_sampled: 218350
num_agent_steps_trained: 201500
num_env_steps_sampled: 218350
num_env_steps_sampled_this_iter: 6350
num_env_steps_sampled_throughput_per_sec: 634.9933992118346
num_env_steps_trained: 201500
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9937630348043
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 60.07142857142856
  ram_util_percent: 76.82142857142857
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11263323575290737
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04161331398228097
  mean_inference_ms: 2.081973455723705
  mean_raw_obs_processing_ms: 0.4687737758448951
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.037014007568359375
    StateBufferConnector_ms: 0.007109165191650391
    ViewRequirementAgentConnector_ms: 0.2212841510772705
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.51
  episode_reward_min: 0.0
  episodes_this_iter: 50
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 6.0, 4.0, 5.0, 7.0, 3.0, 1.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0,
      2.0, 5.0, 4.0, 6.0, 4.0, 3.0, 2.0, 3.0, 3.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 4.0,
      1.0, 3.0, 5.0, 1.0, 4.0, 6.0, 3.0, 7.0, 4.0, 3.0, 8.0, 2.0, 2.0, 5.0, 7.0, 2.0,
      2.0, 3.0, 4.0, 4.0, 3.0, 4.0, 2.0, 1.0, 2.0, 4.0, 5.0, 3.0, 1.0, 1.0, 4.0, 3.0,
      2.0, 5.0, 2.0, 6.0, 3.0, 2.0, 6.0, 1.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0, 3.0, 2.0,
      5.0, 2.0, 1.0, 4.0, 2.0, 0.0, 5.0, 1.0, 6.0, 5.0, 5.0, 7.0, 4.0, 3.0, 5.0, 5.0,
      2.0, 4.0, 5.0, 5.0, 4.0, 8.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11263323575290737
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04161331398228097
    mean_inference_ms: 2.081973455723705
    mean_raw_obs_processing_ms: 0.4687737758448951
time_since_restore: 306.9309949874878
time_this_iter_s: 10.148101091384888
time_total_s: 306.9309949874878
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1691992071
timesteps_total: 218350
training_iteration: 30
trial_id: default
train step: 31
agent_timesteps_total: 226350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03561258316040039
  StateBufferConnector_ms: 0.006327152252197266
  ViewRequirementAgentConnector_ms: 0.21083736419677734
counters:
  num_agent_steps_sampled: 226350
  num_agent_steps_trained: 209500
  num_env_steps_sampled: 226350
  num_env_steps_trained: 209500
  num_samples_added_to_queue: 226000
  num_training_step_calls_since_last_synch_worker_weights: 1118
  num_weight_broadcasts: 4411
custom_metrics: {}
date: 2023-08-14_14-48-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.99
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 1769
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9200916290283203
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 20.69353485107422
        total_loss: 33.243927001953125
        var_gnorm: 63.44147491455078
        vf_explained_var: 0.8381291031837463
        vf_loss: 34.301692962646484
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 419.0
  learner_queue:
    size_count: 423
    size_mean: 15.38
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0934349546269315
  num_agent_steps_sampled: 226350
  num_agent_steps_trained: 209500
  num_env_steps_sampled: 226350
  num_env_steps_trained: 209500
  num_samples_added_to_queue: 226000
  num_training_step_calls_since_last_synch_worker_weights: 1118
  num_weight_broadcasts: 4411
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 434.06
    learner_load_time_ms: 2.714
    learner_load_wait_time_ms: 2.766
iterations_since_restore: 31
node_ip: 127.0.0.1
num_agent_steps_sampled: 226350
num_agent_steps_trained: 209500
num_env_steps_sampled: 226350
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9954605360125
num_env_steps_trained: 209500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9954605360125
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.96
  ram_util_percent: 77.7
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1126068562573808
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04158935211438381
  mean_inference_ms: 2.081878751108712
  mean_raw_obs_processing_ms: 0.46854455442617643
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03561258316040039
    StateBufferConnector_ms: 0.006327152252197266
    ViewRequirementAgentConnector_ms: 0.21083736419677734
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.99
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 2.0, 6.0, 3.0, 2.0, 6.0, 1.0, 3.0, 3.0, 4.0, 4.0, 2.0, 3.0,
      3.0, 2.0, 5.0, 2.0, 1.0, 4.0, 2.0, 0.0, 5.0, 1.0, 6.0, 5.0, 5.0, 7.0, 4.0, 3.0,
      5.0, 5.0, 2.0, 4.0, 5.0, 5.0, 4.0, 8.0, 0.0, 3.0, 4.0, 2.0, 5.0, 3.0, 7.0, 2.0,
      3.0, 2.0, 4.0, 7.0, 3.0, 5.0, 3.0, 5.0, 7.0, 3.0, 6.0, 4.0, 4.0, 6.0, 3.0, 6.0,
      5.0, 3.0, 2.0, 3.0, 4.0, 6.0, 5.0, 6.0, 3.0, 3.0, 3.0, 2.0, 4.0, 5.0, 5.0, 9.0,
      3.0, 6.0, 4.0, 2.0, 5.0, 4.0, 3.0, 4.0, 5.0, 2.0, 3.0, 7.0, 4.0, 3.0, 0.0, 6.0,
      4.0, 6.0, 3.0, 7.0, 6.0, 3.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1126068562573808
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04158935211438381
    mean_inference_ms: 2.081878751108712
    mean_raw_obs_processing_ms: 0.46854455442617643
time_since_restore: 317.08079385757446
time_this_iter_s: 10.14979887008667
time_total_s: 317.08079385757446
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691992081
timesteps_total: 226350
training_iteration: 31
trial_id: default
train step: 32
agent_timesteps_total: 234650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031670570373535156
  StateBufferConnector_ms: 0.005610942840576172
  ViewRequirementAgentConnector_ms: 0.185943603515625
counters:
  num_agent_steps_sampled: 234650
  num_agent_steps_trained: 218000
  num_env_steps_sampled: 234650
  num_env_steps_trained: 218000
  num_samples_added_to_queue: 234500
  num_training_step_calls_since_last_synch_worker_weights: 2
  num_weight_broadcasts: 4574
custom_metrics: {}
date: 2023-08-14_14-48-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.08
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 1833
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9590820670127869
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 29.449939727783203
        total_loss: 38.428375244140625
        var_gnorm: 63.44956970214844
        vf_explained_var: 0.7921450734138489
        vf_loss: 27.547687530517578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 436.0
  learner_queue:
    size_count: 442
    size_mean: 15.38
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1469960767151735
  num_agent_steps_sampled: 234650
  num_agent_steps_trained: 218000
  num_env_steps_sampled: 234650
  num_env_steps_trained: 218000
  num_samples_added_to_queue: 234500
  num_training_step_calls_since_last_synch_worker_weights: 2
  num_weight_broadcasts: 4574
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 277.331
    learner_load_time_ms: 2.684
    learner_load_wait_time_ms: 2.74
iterations_since_restore: 32
node_ip: 127.0.0.1
num_agent_steps_sampled: 234650
num_agent_steps_trained: 218000
num_env_steps_sampled: 234650
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9997427464328
num_env_steps_trained: 218000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9997365475517
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 49.58571428571429
  ram_util_percent: 77.26428571428572
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11232409223614537
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04135810471436433
  mean_inference_ms: 2.073789244446035
  mean_raw_obs_processing_ms: 0.46677752615773566
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031670570373535156
    StateBufferConnector_ms: 0.005610942840576172
    ViewRequirementAgentConnector_ms: 0.185943603515625
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.08
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 6.0, 5.0, 6.0, 3.0, 3.0, 3.0, 2.0, 4.0, 5.0, 5.0, 9.0,
      3.0, 6.0, 4.0, 2.0, 5.0, 4.0, 3.0, 4.0, 5.0, 2.0, 3.0, 7.0, 4.0, 3.0, 0.0, 6.0,
      4.0, 6.0, 3.0, 7.0, 6.0, 3.0, 7.0, 0.0, 5.0, 3.0, 3.0, 6.0, 3.0, 4.0, 4.0, 4.0,
      4.0, 4.0, 2.0, 6.0, 4.0, 0.0, 5.0, 4.0, 6.0, 4.0, 4.0, 4.0, 2.0, 3.0, 2.0, 5.0,
      5.0, 5.0, 6.0, 5.0, 3.0, 2.0, 2.0, 4.0, 4.0, 3.0, 5.0, 5.0, 7.0, 7.0, 4.0, 3.0,
      5.0, 6.0, 3.0, 2.0, 8.0, 5.0, 6.0, 5.0, 4.0, 4.0, 4.0, 5.0, 3.0, 5.0, 5.0, 2.0,
      1.0, 3.0, 3.0, 6.0, 2.0, 1.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11232409223614537
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04135810471436433
    mean_inference_ms: 2.073789244446035
    mean_raw_obs_processing_ms: 0.46677752615773566
time_since_restore: 327.36481380462646
time_this_iter_s: 10.284019947052002
time_total_s: 327.36481380462646
timers:
  sample_time_ms: 0.133
  synch_weights_time_ms: 0.427
  training_iteration_time_ms: 0.687
timestamp: 1691992091
timesteps_total: 234650
training_iteration: 32
trial_id: default
train step: 33
agent_timesteps_total: 242850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030971765518188477
  StateBufferConnector_ms: 0.005547761917114258
  ViewRequirementAgentConnector_ms: 0.18512630462646484
counters:
  num_agent_steps_sampled: 242850
  num_agent_steps_trained: 226000
  num_env_steps_sampled: 242850
  num_env_steps_trained: 226000
  num_samples_added_to_queue: 242500
  num_training_step_calls_since_last_synch_worker_weights: 1199
  num_weight_broadcasts: 4732
custom_metrics: {}
date: 2023-08-14_14-48-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.96
episode_reward_min: 0.0
episodes_this_iter: 65
episodes_total: 1898
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9202256202697754
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.586727142333984
        total_loss: 40.54708480834961
        var_gnorm: 63.457115173339844
        vf_explained_var: 0.7349419593811035
        vf_loss: 53.12297058105469
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 452.0
  learner_queue:
    size_count: 456
    size_mean: 15.16
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.474584687293341
  num_agent_steps_sampled: 242850
  num_agent_steps_trained: 226000
  num_env_steps_sampled: 242850
  num_env_steps_trained: 226000
  num_samples_added_to_queue: 242500
  num_training_step_calls_since_last_synch_worker_weights: 1199
  num_weight_broadcasts: 4732
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 467.491
    learner_load_time_ms: 2.698
    learner_load_wait_time_ms: 14.931
iterations_since_restore: 33
node_ip: 127.0.0.1
num_agent_steps_sampled: 242850
num_agent_steps_trained: 226000
num_env_steps_sampled: 242850
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9962463550735
num_env_steps_trained: 226000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9963379073887
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 49.559999999999995
  ram_util_percent: 76.83333333333333
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11188571700541373
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04115007551588905
  mean_inference_ms: 2.06561993759672
  mean_raw_obs_processing_ms: 0.4649742482462885
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030971765518188477
    StateBufferConnector_ms: 0.005547761917114258
    ViewRequirementAgentConnector_ms: 0.18512630462646484
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.96
  episode_reward_min: 0.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 2.0, 4.0, 4.0, 3.0, 5.0, 5.0, 7.0, 7.0, 4.0, 3.0, 5.0,
      6.0, 3.0, 2.0, 8.0, 5.0, 6.0, 5.0, 4.0, 4.0, 4.0, 5.0, 3.0, 5.0, 5.0, 2.0, 1.0,
      3.0, 3.0, 6.0, 2.0, 1.0, 4.0, 4.0, 4.0, 3.0, 4.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0,
      5.0, 3.0, 4.0, 5.0, 2.0, 6.0, 0.0, 9.0, 5.0, 0.0, 6.0, 2.0, 8.0, 4.0, 2.0, 0.0,
      4.0, 2.0, 3.0, 2.0, 6.0, 5.0, 3.0, 2.0, 2.0, 3.0, 5.0, 4.0, 2.0, 4.0, 3.0, 4.0,
      7.0, 3.0, 1.0, 1.0, 5.0, 8.0, 4.0, 5.0, 6.0, 1.0, 5.0, 5.0, 4.0, 9.0, 3.0, 8.0,
      1.0, 6.0, 2.0, 3.0, 6.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11188571700541373
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04115007551588905
    mean_inference_ms: 2.06561993759672
    mean_raw_obs_processing_ms: 0.4649742482462885
time_since_restore: 337.5101315975189
time_this_iter_s: 10.145317792892456
time_total_s: 337.5101315975189
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.072
timestamp: 1691992101
timesteps_total: 242850
training_iteration: 33
trial_id: default
train step: 34
agent_timesteps_total: 251150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030614376068115234
  StateBufferConnector_ms: 0.005548000335693359
  ViewRequirementAgentConnector_ms: 0.18245887756347656
counters:
  num_agent_steps_sampled: 251150
  num_agent_steps_trained: 234500
  num_env_steps_sampled: 251150
  num_env_steps_trained: 234500
  num_samples_added_to_queue: 251000
  num_training_step_calls_since_last_synch_worker_weights: 510
  num_weight_broadcasts: 4892
custom_metrics: {}
date: 2023-08-14_14-48-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.17
episode_reward_min: 0.0
episodes_this_iter: 65
episodes_total: 1963
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9366494417190552
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -41.8090934753418
        total_loss: -37.91733932495117
        var_gnorm: 63.46524429321289
        vf_explained_var: 0.8752239942550659
        vf_loss: 17.149999618530273
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 469.0
  learner_queue:
    size_count: 474
    size_mean: 15.12
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5315351775261319
  num_agent_steps_sampled: 251150
  num_agent_steps_trained: 234500
  num_env_steps_sampled: 251150
  num_env_steps_trained: 234500
  num_samples_added_to_queue: 251000
  num_training_step_calls_since_last_synch_worker_weights: 510
  num_weight_broadcasts: 4892
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 337.729
    learner_load_time_ms: 2.701
    learner_load_wait_time_ms: 2.564
iterations_since_restore: 34
node_ip: 127.0.0.1
num_agent_steps_sampled: 251150
num_agent_steps_trained: 234500
num_env_steps_sampled: 251150
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9948549589565
num_env_steps_trained: 234500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9947309820639
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 49.135714285714286
  ram_util_percent: 76.66428571428571
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11146648357626489
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040951680709762336
  mean_inference_ms: 2.0577981799271687
  mean_raw_obs_processing_ms: 0.46322944058621346
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030614376068115234
    StateBufferConnector_ms: 0.005548000335693359
    ViewRequirementAgentConnector_ms: 0.18245887756347656
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.17
  episode_reward_min: 0.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 5.0, 3.0, 2.0, 2.0, 3.0, 5.0, 4.0, 2.0, 4.0, 3.0, 4.0, 7.0,
      3.0, 1.0, 1.0, 5.0, 8.0, 4.0, 5.0, 6.0, 1.0, 5.0, 5.0, 4.0, 9.0, 3.0, 8.0, 1.0,
      6.0, 2.0, 3.0, 6.0, 4.0, 4.0, 7.0, 2.0, 6.0, 3.0, 1.0, 2.0, 4.0, 4.0, 6.0, 3.0,
      6.0, 4.0, 7.0, 6.0, 7.0, 3.0, 3.0, 3.0, 3.0, 4.0, 9.0, 3.0, 5.0, 3.0, 7.0, 4.0,
      2.0, 6.0, 2.0, 3.0, 4.0, 4.0, 3.0, 1.0, 4.0, 4.0, 5.0, 5.0, 0.0, 1.0, 5.0, 6.0,
      0.0, 4.0, 4.0, 3.0, 6.0, 7.0, 5.0, 5.0, 3.0, 6.0, 7.0, 3.0, 2.0, 4.0, 3.0, 7.0,
      6.0, 2.0, 7.0, 3.0, 2.0, 4.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11146648357626489
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040951680709762336
    mean_inference_ms: 2.0577981799271687
    mean_raw_obs_processing_ms: 0.46322944058621346
time_since_restore: 347.7140545845032
time_this_iter_s: 10.203922986984253
time_total_s: 347.7140545845032
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691992112
timesteps_total: 251150
training_iteration: 34
trial_id: default
train step: 35
agent_timesteps_total: 259450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03076910972595215
  StateBufferConnector_ms: 0.005599260330200195
  ViewRequirementAgentConnector_ms: 0.18442368507385254
counters:
  num_agent_steps_sampled: 259450
  num_agent_steps_trained: 242500
  num_env_steps_sampled: 259450
  num_env_steps_trained: 242500
  num_samples_added_to_queue: 259000
  num_training_step_calls_since_last_synch_worker_weights: 843
  num_weight_broadcasts: 5055
custom_metrics: {}
date: 2023-08-14_14-48-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.14
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 2027
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8476353883743286
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -3.1929080486297607
        total_loss: 17.547958374023438
        var_gnorm: 63.47664260864258
        vf_explained_var: 0.7546731233596802
        vf_loss: 49.95808410644531
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 485.0
  learner_queue:
    size_count: 490
    size_mean: 14.92
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6351146748775756
  num_agent_steps_sampled: 259450
  num_agent_steps_trained: 242500
  num_env_steps_sampled: 259450
  num_env_steps_trained: 242500
  num_samples_added_to_queue: 259000
  num_training_step_calls_since_last_synch_worker_weights: 843
  num_weight_broadcasts: 5055
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 376.183
    learner_load_time_ms: 2.667
    learner_load_wait_time_ms: 2.832
iterations_since_restore: 35
node_ip: 127.0.0.1
num_agent_steps_sampled: 259450
num_agent_steps_trained: 242500
num_env_steps_sampled: 259450
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9980013418642
num_env_steps_trained: 242500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9980735825197
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 49.057142857142864
  ram_util_percent: 76.74285714285715
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11104293948949082
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04076452007358431
  mean_inference_ms: 2.0502396166462007
  mean_raw_obs_processing_ms: 0.46159939799919797
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03076910972595215
    StateBufferConnector_ms: 0.005599260330200195
    ViewRequirementAgentConnector_ms: 0.18442368507385254
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.14
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 4.0, 3.0, 1.0, 4.0, 4.0, 5.0, 5.0, 0.0, 1.0, 5.0, 6.0,
      0.0, 4.0, 4.0, 3.0, 6.0, 7.0, 5.0, 5.0, 3.0, 6.0, 7.0, 3.0, 2.0, 4.0, 3.0, 7.0,
      6.0, 2.0, 7.0, 3.0, 2.0, 4.0, 10.0, 3.0, 4.0, 4.0, 6.0, 3.0, 6.0, 3.0, 1.0,
      5.0, 3.0, 1.0, 3.0, 7.0, 3.0, 4.0, 5.0, 3.0, 4.0, 2.0, 4.0, 5.0, 0.0, 7.0, 4.0,
      5.0, 9.0, 2.0, 1.0, 2.0, 7.0, 6.0, 1.0, 4.0, 7.0, 4.0, 6.0, 4.0, 7.0, 9.0, 1.0,
      2.0, 2.0, 4.0, 4.0, 5.0, 6.0, 5.0, 3.0, 3.0, 4.0, 6.0, 4.0, 6.0, 4.0, 5.0, 1.0,
      4.0, 3.0, 5.0, 2.0, 7.0, 7.0, 6.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11104293948949082
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04076452007358431
    mean_inference_ms: 2.0502396166462007
    mean_raw_obs_processing_ms: 0.46159939799919797
time_since_restore: 357.89279556274414
time_this_iter_s: 10.178740978240967
time_total_s: 357.89279556274414
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.073
timestamp: 1691992122
timesteps_total: 259450
training_iteration: 35
trial_id: default
train step: 36
agent_timesteps_total: 267650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031108379364013672
  StateBufferConnector_ms: 0.005665779113769531
  ViewRequirementAgentConnector_ms: 0.18676257133483887
counters:
  num_agent_steps_sampled: 267650
  num_agent_steps_trained: 251000
  num_env_steps_sampled: 267650
  num_env_steps_trained: 251000
  num_samples_added_to_queue: 267500
  num_training_step_calls_since_last_synch_worker_weights: 101
  num_weight_broadcasts: 5215
custom_metrics: {}
date: 2023-08-14_14-48-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.4
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 2091
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8893650770187378
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -49.82911682128906
        total_loss: -31.249359130859375
        var_gnorm: 63.48716354370117
        vf_explained_var: 0.7123000621795654
        vf_loss: 46.053165435791016
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 502.0
  learner_queue:
    size_count: 508
    size_mean: 15.14
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4284257068535275
  num_agent_steps_sampled: 267650
  num_agent_steps_trained: 251000
  num_env_steps_sampled: 267650
  num_env_steps_trained: 251000
  num_samples_added_to_queue: 267500
  num_training_step_calls_since_last_synch_worker_weights: 101
  num_weight_broadcasts: 5215
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 280.062
    learner_load_time_ms: 2.621
    learner_load_wait_time_ms: 2.517
iterations_since_restore: 36
node_ip: 127.0.0.1
num_agent_steps_sampled: 267650
num_agent_steps_trained: 251000
num_env_steps_sampled: 267650
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9939198944786
num_env_steps_trained: 251000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9936974515937
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 49.65999999999999
  ram_util_percent: 76.75333333333334
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11065846207384869
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04060968159932894
  mean_inference_ms: 2.0436908018922413
  mean_raw_obs_processing_ms: 0.46023849953796997
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031108379364013672
    StateBufferConnector_ms: 0.005665779113769531
    ViewRequirementAgentConnector_ms: 0.18676257133483887
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.4
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 7.0, 6.0, 1.0, 4.0, 7.0, 4.0, 6.0, 4.0, 7.0, 9.0, 1.0, 2.0,
      2.0, 4.0, 4.0, 5.0, 6.0, 5.0, 3.0, 3.0, 4.0, 6.0, 4.0, 6.0, 4.0, 5.0, 1.0, 4.0,
      3.0, 5.0, 2.0, 7.0, 7.0, 6.0, 3.0, 3.0, 5.0, 0.0, 2.0, 4.0, 4.0, 3.0, 5.0, 4.0,
      7.0, 3.0, 2.0, 1.0, 3.0, 4.0, 6.0, 2.0, 6.0, 6.0, 8.0, 5.0, 5.0, 6.0, 3.0, 4.0,
      5.0, 3.0, 4.0, 8.0, 2.0, 3.0, 5.0, 6.0, 0.0, 5.0, 1.0, 7.0, 5.0, 4.0, 7.0, 4.0,
      6.0, 1.0, 4.0, 5.0, 7.0, 5.0, 3.0, 6.0, 6.0, 5.0, 7.0, 3.0, 8.0, 6.0, 2.0, 4.0,
      5.0, 5.0, 4.0, 5.0, 5.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11065846207384869
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04060968159932894
    mean_inference_ms: 2.0436908018922413
    mean_raw_obs_processing_ms: 0.46023849953796997
time_since_restore: 368.13185954093933
time_this_iter_s: 10.23906397819519
time_total_s: 368.13185954093933
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.089
timestamp: 1691992132
timesteps_total: 267650
training_iteration: 36
trial_id: default
train step: 37
agent_timesteps_total: 275950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03140687942504883
  StateBufferConnector_ms: 0.005497932434082031
  ViewRequirementAgentConnector_ms: 0.1862490177154541
counters:
  num_agent_steps_sampled: 275950
  num_agent_steps_trained: 259000
  num_env_steps_sampled: 275950
  num_env_steps_trained: 259000
  num_samples_added_to_queue: 275500
  num_training_step_calls_since_last_synch_worker_weights: 984
  num_weight_broadcasts: 5378
custom_metrics: {}
date: 2023-08-14_14-49-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 4.21
episode_reward_min: 0.0
episodes_this_iter: 66
episodes_total: 2157
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.941230058670044
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 58.39226531982422
        total_loss: 111.54316711425781
        var_gnorm: 63.494102478027344
        vf_explained_var: 0.5665891170501709
        vf_loss: 115.7140884399414
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 518.0
  learner_queue:
    size_count: 522
    size_mean: 14.92
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5210522673465234
  num_agent_steps_sampled: 275950
  num_agent_steps_trained: 259000
  num_env_steps_sampled: 275950
  num_env_steps_trained: 259000
  num_samples_added_to_queue: 275500
  num_training_step_calls_since_last_synch_worker_weights: 984
  num_weight_broadcasts: 5378
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 446.757
    learner_load_time_ms: 4.449
    learner_load_wait_time_ms: 2.707
iterations_since_restore: 37
node_ip: 127.0.0.1
num_agent_steps_sampled: 275950
num_agent_steps_trained: 259000
num_env_steps_sampled: 275950
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9937863815087
num_env_steps_trained: 259000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9940109701289
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 48.78571428571428
  ram_util_percent: 76.8
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11031804795368357
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040443521696767536
  mean_inference_ms: 2.037211644164915
  mean_raw_obs_processing_ms: 0.458870697134574
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03140687942504883
    StateBufferConnector_ms: 0.005497932434082031
    ViewRequirementAgentConnector_ms: 0.1862490177154541
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 4.21
  episode_reward_min: 0.0
  episodes_this_iter: 66
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 6.0, 0.0, 5.0, 1.0, 7.0, 5.0, 4.0, 7.0, 4.0, 6.0, 1.0,
      4.0, 5.0, 7.0, 5.0, 3.0, 6.0, 6.0, 5.0, 7.0, 3.0, 8.0, 6.0, 2.0, 4.0, 5.0, 5.0,
      4.0, 5.0, 5.0, 5.0, 4.0, 3.0, 7.0, 5.0, 6.0, 2.0, 3.0, 4.0, 8.0, 5.0, 4.0, 2.0,
      3.0, 1.0, 6.0, 4.0, 2.0, 1.0, 5.0, 1.0, 5.0, 6.0, 4.0, 1.0, 2.0, 3.0, 4.0, 1.0,
      4.0, 3.0, 5.0, 7.0, 8.0, 6.0, 6.0, 4.0, 3.0, 4.0, 5.0, 4.0, 3.0, 4.0, 4.0, 4.0,
      7.0, 1.0, 6.0, 4.0, 1.0, 1.0, 4.0, 4.0, 6.0, 1.0, 3.0, 1.0, 2.0, 2.0, 6.0, 8.0,
      6.0, 7.0, 7.0, 3.0, 1.0, 4.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11031804795368357
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040443521696767536
    mean_inference_ms: 2.037211644164915
    mean_raw_obs_processing_ms: 0.458870697134574
time_since_restore: 378.3259644508362
time_this_iter_s: 10.19410490989685
time_total_s: 378.3259644508362
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1691992142
timesteps_total: 275950
training_iteration: 37
trial_id: default
train step: 38
agent_timesteps_total: 284250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030216455459594727
  StateBufferConnector_ms: 0.005422115325927734
  ViewRequirementAgentConnector_ms: 0.18297839164733887
counters:
  num_agent_steps_sampled: 284250
  num_agent_steps_trained: 267500
  num_env_steps_sampled: 284250
  num_env_steps_trained: 267500
  num_samples_added_to_queue: 284000
  num_training_step_calls_since_last_synch_worker_weights: 961
  num_weight_broadcasts: 5540
custom_metrics: {}
date: 2023-08-14_14-49-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 4.1
episode_reward_min: 1.0
episodes_this_iter: 64
episodes_total: 2221
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9883760809898376
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.135223388671875
        total_loss: 0.04006481170654297
        var_gnorm: 63.49882888793945
        vf_explained_var: 0.7851441502571106
        vf_loss: 42.234336853027344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 535.0
  learner_queue:
    size_count: 539
    size_mean: 15.08
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.44
  num_agent_steps_sampled: 284250
  num_agent_steps_trained: 267500
  num_env_steps_sampled: 284250
  num_env_steps_trained: 267500
  num_samples_added_to_queue: 284000
  num_training_step_calls_since_last_synch_worker_weights: 961
  num_weight_broadcasts: 5540
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 405.142
    learner_load_time_ms: 4.435
    learner_load_wait_time_ms: 2.551
iterations_since_restore: 38
node_ip: 127.0.0.1
num_agent_steps_sampled: 284250
num_agent_steps_trained: 267500
num_env_steps_sampled: 284250
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9937072277331
num_env_steps_trained: 267500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9935555946665
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 45.42142857142857
  ram_util_percent: 76.8
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10996172527371073
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04028971276142255
  mean_inference_ms: 2.030934461910889
  mean_raw_obs_processing_ms: 0.45748795512235974
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030216455459594727
    StateBufferConnector_ms: 0.005422115325927734
    ViewRequirementAgentConnector_ms: 0.18297839164733887
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 4.1
  episode_reward_min: 1.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 8.0, 6.0, 6.0, 4.0, 3.0, 4.0, 5.0, 4.0, 3.0, 4.0, 4.0, 4.0,
      7.0, 1.0, 6.0, 4.0, 1.0, 1.0, 4.0, 4.0, 6.0, 1.0, 3.0, 1.0, 2.0, 2.0, 6.0, 8.0,
      6.0, 7.0, 7.0, 3.0, 1.0, 4.0, 6.0, 2.0, 4.0, 4.0, 4.0, 3.0, 6.0, 4.0, 7.0, 2.0,
      5.0, 1.0, 7.0, 3.0, 5.0, 4.0, 5.0, 3.0, 6.0, 3.0, 5.0, 4.0, 4.0, 1.0, 7.0, 7.0,
      4.0, 4.0, 6.0, 4.0, 3.0, 3.0, 7.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 3.0, 3.0, 6.0,
      4.0, 4.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 8.0, 3.0, 5.0, 3.0, 2.0, 4.0, 2.0, 4.0,
      1.0, 2.0, 3.0, 7.0, 4.0, 4.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10996172527371073
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04028971276142255
    mean_inference_ms: 2.030934461910889
    mean_raw_obs_processing_ms: 0.45748795512235974
time_since_restore: 388.48875427246094
time_this_iter_s: 10.162789821624756
time_total_s: 388.48875427246094
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1691992152
timesteps_total: 284250
training_iteration: 38
trial_id: default
train step: 39
agent_timesteps_total: 292550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031084775924682617
  StateBufferConnector_ms: 0.005681753158569336
  ViewRequirementAgentConnector_ms: 0.1880950927734375
counters:
  num_agent_steps_sampled: 292550
  num_agent_steps_trained: 276000
  num_env_steps_sampled: 292550
  num_env_steps_trained: 276000
  num_samples_added_to_queue: 292500
  num_training_step_calls_since_last_synch_worker_weights: 17
  num_weight_broadcasts: 5700
custom_metrics: {}
date: 2023-08-14_14-49-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.26
episode_reward_min: 0.0
episodes_this_iter: 65
episodes_total: 2286
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0619488954544067
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 29.071393966674805
        total_loss: 40.945404052734375
        var_gnorm: 63.51044464111328
        vf_explained_var: 0.8296974301338196
        vf_loss: 34.367515563964844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 552.0
  learner_queue:
    size_count: 558
    size_mean: 15.12
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3948476619330155
  num_agent_steps_sampled: 292550
  num_agent_steps_trained: 276000
  num_env_steps_sampled: 292550
  num_env_steps_trained: 276000
  num_samples_added_to_queue: 292500
  num_training_step_calls_since_last_synch_worker_weights: 17
  num_weight_broadcasts: 5700
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 267.192
    learner_load_time_ms: 4.069
    learner_load_wait_time_ms: 2.504
iterations_since_restore: 39
node_ip: 127.0.0.1
num_agent_steps_sampled: 292550
num_agent_steps_trained: 276000
num_env_steps_sampled: 292550
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9972691625799
num_env_steps_trained: 276000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9972033592686
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 49.16666666666666
  ram_util_percent: 76.82666666666668
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1095967590316718
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0401465748048829
  mean_inference_ms: 2.0249900590070804
  mean_raw_obs_processing_ms: 0.45619059824199965
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031084775924682617
    StateBufferConnector_ms: 0.005681753158569336
    ViewRequirementAgentConnector_ms: 0.1880950927734375
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.26
  episode_reward_min: 0.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 7.0, 4.0, 5.0, 4.0, 4.0, 4.0, 5.0, 3.0, 3.0, 6.0, 4.0,
      4.0, 2.0, 3.0, 3.0, 1.0, 3.0, 4.0, 8.0, 3.0, 5.0, 3.0, 2.0, 4.0, 2.0, 4.0, 1.0,
      2.0, 3.0, 7.0, 4.0, 4.0, 6.0, 0.0, 5.0, 3.0, 6.0, 1.0, 2.0, 6.0, 5.0, 7.0, 0.0,
      6.0, 4.0, 4.0, 2.0, 3.0, 5.0, 6.0, 1.0, 6.0, 3.0, 6.0, 9.0, 6.0, 6.0, 3.0, 2.0,
      3.0, 6.0, 8.0, 6.0, 1.0, 5.0, 8.0, 7.0, 1.0, 2.0, 4.0, 2.0, 6.0, 2.0, 5.0, 3.0,
      5.0, 6.0, 3.0, 4.0, 8.0, 2.0, 3.0, 6.0, 9.0, 3.0, 6.0, 9.0, 5.0, 6.0, 5.0, 3.0,
      4.0, 2.0, 8.0, 7.0, 5.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1095967590316718
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0401465748048829
    mean_inference_ms: 2.0249900590070804
    mean_raw_obs_processing_ms: 0.45619059824199965
time_since_restore: 398.7161593437195
time_this_iter_s: 10.227405071258545
time_total_s: 398.7161593437195
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.075
timestamp: 1691992163
timesteps_total: 292550
training_iteration: 39
trial_id: default
train step: 40
agent_timesteps_total: 300850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03113555908203125
  StateBufferConnector_ms: 0.005510807037353516
  ViewRequirementAgentConnector_ms: 0.1862955093383789
counters:
  num_agent_steps_sampled: 300850
  num_agent_steps_trained: 284000
  num_env_steps_sampled: 300850
  num_env_steps_trained: 284000
  num_samples_added_to_queue: 300500
  num_training_step_calls_since_last_synch_worker_weights: 570
  num_weight_broadcasts: 5863
custom_metrics: {}
date: 2023-08-14_14-49-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.65
episode_reward_min: 1.0
episodes_this_iter: 65
episodes_total: 2351
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0544015169143677
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -22.713668823242188
        total_loss: -13.097785949707031
        var_gnorm: 63.52158737182617
        vf_explained_var: 0.8053492903709412
        vf_loss: 29.775779724121094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 568.0
  learner_queue:
    size_count: 573
    size_mean: 15.18
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3370115930686615
  num_agent_steps_sampled: 300850
  num_agent_steps_trained: 284000
  num_env_steps_sampled: 300850
  num_env_steps_trained: 284000
  num_samples_added_to_queue: 300500
  num_training_step_calls_since_last_synch_worker_weights: 570
  num_weight_broadcasts: 5863
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 364.843
    learner_load_time_ms: 4.33
    learner_load_wait_time_ms: 2.578
iterations_since_restore: 40
node_ip: 127.0.0.1
num_agent_steps_sampled: 300850
num_agent_steps_trained: 284000
num_env_steps_sampled: 300850
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9984960583281
num_env_steps_trained: 284000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9985504176657
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 49.01428571428572
  ram_util_percent: 76.87857142857142
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1093071013105012
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040006598763535586
  mean_inference_ms: 2.019473515169851
  mean_raw_obs_processing_ms: 0.4549926579750877
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03113555908203125
    StateBufferConnector_ms: 0.005510807037353516
    ViewRequirementAgentConnector_ms: 0.1862955093383789
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.65
  episode_reward_min: 1.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 5.0, 8.0, 7.0, 1.0, 2.0, 4.0, 2.0, 6.0, 2.0, 5.0, 3.0, 5.0,
      6.0, 3.0, 4.0, 8.0, 2.0, 3.0, 6.0, 9.0, 3.0, 6.0, 9.0, 5.0, 6.0, 5.0, 3.0, 4.0,
      2.0, 8.0, 7.0, 5.0, 3.0, 5.0, 3.0, 2.0, 7.0, 2.0, 6.0, 4.0, 4.0, 4.0, 3.0, 6.0,
      6.0, 6.0, 2.0, 4.0, 8.0, 4.0, 3.0, 5.0, 5.0, 4.0, 5.0, 8.0, 6.0, 3.0, 6.0, 6.0,
      4.0, 5.0, 4.0, 7.0, 2.0, 11.0, 4.0, 6.0, 8.0, 4.0, 6.0, 7.0, 6.0, 2.0, 5.0,
      5.0, 6.0, 4.0, 6.0, 6.0, 6.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 5.0, 4.0, 6.0, 2.0,
      1.0, 3.0, 4.0, 4.0, 3.0, 5.0, 3.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1093071013105012
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040006598763535586
    mean_inference_ms: 2.019473515169851
    mean_raw_obs_processing_ms: 0.4549926579750877
time_since_restore: 408.91263723373413
time_this_iter_s: 10.196477890014648
time_total_s: 408.91263723373413
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.074
timestamp: 1691992173
timesteps_total: 300850
training_iteration: 40
trial_id: default
train step: 41
agent_timesteps_total: 308250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033380746841430664
  StateBufferConnector_ms: 0.005856990814208984
  ViewRequirementAgentConnector_ms: 0.19815754890441895
counters:
  num_agent_steps_sampled: 308250
  num_agent_steps_trained: 291500
  num_env_steps_sampled: 308250
  num_env_steps_trained: 291500
  num_samples_added_to_queue: 308000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 6007
custom_metrics: {}
date: 2023-08-14_14-49-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.64
episode_reward_min: 1.0
episodes_this_iter: 58
episodes_total: 2409
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1005545854568481
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 13.033418655395508
        total_loss: 39.93546676635742
        var_gnorm: 63.532169342041016
        vf_explained_var: 0.7610374689102173
        vf_loss: 64.80964660644531
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 583.0
  learner_queue:
    size_count: 590
    size_mean: 14.86
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6614451540752104
  num_agent_steps_sampled: 308250
  num_agent_steps_trained: 291500
  num_env_steps_sampled: 308250
  num_env_steps_trained: 291500
  num_samples_added_to_queue: 308000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 6007
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 264.22
    learner_load_time_ms: 9.036
    learner_load_wait_time_ms: 2.987
iterations_since_restore: 41
node_ip: 127.0.0.1
num_agent_steps_sampled: 308250
num_agent_steps_trained: 291500
num_env_steps_sampled: 308250
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9809813619158
num_env_steps_trained: 291500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9807243532931
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 57.873333333333335
  ram_util_percent: 77.03333333333333
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10916782709163739
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039982505858675785
  mean_inference_ms: 2.0183409194575677
  mean_raw_obs_processing_ms: 0.45477480733622244
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033380746841430664
    StateBufferConnector_ms: 0.005856990814208984
    ViewRequirementAgentConnector_ms: 0.19815754890441895
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.64
  episode_reward_min: 1.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 6.0, 6.0, 4.0, 5.0, 4.0, 7.0, 2.0, 11.0, 4.0, 6.0, 8.0,
      4.0, 6.0, 7.0, 6.0, 2.0, 5.0, 5.0, 6.0, 4.0, 6.0, 6.0, 6.0, 3.0, 4.0, 3.0, 4.0,
      3.0, 3.0, 5.0, 4.0, 6.0, 2.0, 1.0, 3.0, 4.0, 4.0, 3.0, 5.0, 3.0, 6.0, 6.0, 5.0,
      6.0, 4.0, 4.0, 2.0, 6.0, 3.0, 2.0, 4.0, 7.0, 2.0, 4.0, 7.0, 5.0, 3.0, 4.0, 2.0,
      5.0, 6.0, 8.0, 6.0, 7.0, 4.0, 2.0, 4.0, 5.0, 8.0, 5.0, 7.0, 7.0, 4.0, 4.0, 6.0,
      4.0, 3.0, 5.0, 4.0, 8.0, 5.0, 5.0, 5.0, 2.0, 8.0, 7.0, 4.0, 3.0, 6.0, 1.0, 6.0,
      3.0, 4.0, 3.0, 4.0, 2.0, 3.0, 4.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10916782709163739
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039982505858675785
    mean_inference_ms: 2.0183409194575677
    mean_raw_obs_processing_ms: 0.45477480733622244
time_since_restore: 419.2407603263855
time_this_iter_s: 10.328123092651367
time_total_s: 419.2407603263855
timers:
  sample_time_ms: 0.132
  synch_weights_time_ms: 0.803
  training_iteration_time_ms: 1.143
timestamp: 1691992183
timesteps_total: 308250
training_iteration: 41
trial_id: default
train step: 42
agent_timesteps_total: 314500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03904604911804199
  StateBufferConnector_ms: 0.006987333297729492
  ViewRequirementAgentConnector_ms: 0.23277759552001953
counters:
  num_agent_steps_sampled: 314500
  num_agent_steps_trained: 298000
  num_env_steps_sampled: 314500
  num_env_steps_trained: 298000
  num_samples_added_to_queue: 314500
  num_training_step_calls_since_last_synch_worker_weights: 411
  num_weight_broadcasts: 6130
custom_metrics: {}
date: 2023-08-14_14-49-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.54
episode_reward_min: 0.0
episodes_this_iter: 48
episodes_total: 2457
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0104314088821411
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -34.707767486572266
        total_loss: -14.768972396850586
        var_gnorm: 63.541893005371094
        vf_explained_var: 0.7978567481040955
        vf_loss: 49.981903076171875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 596.0
  learner_queue:
    size_count: 601
    size_mean: 14.48
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7577258034175864
  num_agent_steps_sampled: 314500
  num_agent_steps_trained: 298000
  num_env_steps_sampled: 314500
  num_env_steps_trained: 298000
  num_samples_added_to_queue: 314500
  num_training_step_calls_since_last_synch_worker_weights: 411
  num_weight_broadcasts: 6130
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 877.631
    learner_load_time_ms: 9.71
    learner_load_wait_time_ms: 6.591
iterations_since_restore: 42
node_ip: 127.0.0.1
num_agent_steps_sampled: 314500
num_agent_steps_trained: 298000
num_env_steps_sampled: 314500
num_env_steps_sampled_this_iter: 6250
num_env_steps_sampled_throughput_per_sec: 624.9959469104396
num_env_steps_trained: 298000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.995784786857
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 65.13571428571429
  ram_util_percent: 79.19285714285714
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1091981288815536
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04012058735041011
  mean_inference_ms: 2.0227397869198422
  mean_raw_obs_processing_ms: 0.4558350274314605
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03904604911804199
    StateBufferConnector_ms: 0.006987333297729492
    ViewRequirementAgentConnector_ms: 0.23277759552001953
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.54
  episode_reward_min: 0.0
  episodes_this_iter: 48
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 3.0, 2.0, 4.0, 7.0, 2.0, 4.0, 7.0, 5.0, 3.0, 4.0, 2.0, 5.0,
      6.0, 8.0, 6.0, 7.0, 4.0, 2.0, 4.0, 5.0, 8.0, 5.0, 7.0, 7.0, 4.0, 4.0, 6.0, 4.0,
      3.0, 5.0, 4.0, 8.0, 5.0, 5.0, 5.0, 2.0, 8.0, 7.0, 4.0, 3.0, 6.0, 1.0, 6.0, 3.0,
      4.0, 3.0, 4.0, 2.0, 3.0, 4.0, 6.0, 5.0, 4.0, 5.0, 4.0, 5.0, 6.0, 5.0, 3.0, 5.0,
      3.0, 5.0, 4.0, 6.0, 6.0, 1.0, 2.0, 6.0, 6.0, 2.0, 10.0, 3.0, 5.0, 6.0, 6.0,
      4.0, 5.0, 2.0, 3.0, 6.0, 6.0, 2.0, 0.0, 5.0, 5.0, 3.0, 3.0, 3.0, 2.0, 7.0, 5.0,
      6.0, 6.0, 4.0, 8.0, 3.0, 2.0, 3.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1091981288815536
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04012058735041011
    mean_inference_ms: 2.0227397869198422
    mean_raw_obs_processing_ms: 0.4558350274314605
time_since_restore: 429.5090193748474
time_this_iter_s: 10.268259048461914
time_total_s: 429.5090193748474
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.083
timestamp: 1691992193
timesteps_total: 314500
training_iteration: 42
trial_id: default
train step: 43
agent_timesteps_total: 321300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04099321365356445
  StateBufferConnector_ms: 0.0074787139892578125
  ViewRequirementAgentConnector_ms: 0.2414262294769287
counters:
  num_agent_steps_sampled: 321300
  num_agent_steps_trained: 304500
  num_env_steps_sampled: 321300
  num_env_steps_trained: 304500
  num_samples_added_to_queue: 321000
  num_training_step_calls_since_last_synch_worker_weights: 1094
  num_weight_broadcasts: 6262
custom_metrics: {}
date: 2023-08-14_14-50-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.46
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 2511
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0673471689224243
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.278461456298828
        total_loss: 41.066261291503906
        var_gnorm: 63.54553985595703
        vf_explained_var: 0.7804253101348877
        vf_loss: 56.24906921386719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 609.0
  learner_queue:
    size_count: 613
    size_mean: 14.66
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.668652150689292
  num_agent_steps_sampled: 321300
  num_agent_steps_trained: 304500
  num_env_steps_sampled: 321300
  num_env_steps_trained: 304500
  num_samples_added_to_queue: 321000
  num_training_step_calls_since_last_synch_worker_weights: 1094
  num_weight_broadcasts: 6262
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 675.379
    learner_load_time_ms: 9.789
    learner_load_wait_time_ms: 4.328
iterations_since_restore: 43
node_ip: 127.0.0.1
num_agent_steps_sampled: 321300
num_agent_steps_trained: 304500
num_env_steps_sampled: 321300
num_env_steps_sampled_this_iter: 6800
num_env_steps_sampled_throughput_per_sec: 679.9977626874148
num_env_steps_trained: 304500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9978613923819
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 57.733333333333334
  ram_util_percent: 79.80666666666666
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10950986272690492
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04029133851173681
  mean_inference_ms: 2.029160644516126
  mean_raw_obs_processing_ms: 0.4572137691438147
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04099321365356445
    StateBufferConnector_ms: 0.0074787139892578125
    ViewRequirementAgentConnector_ms: 0.2414262294769287
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.46
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 4.0, 5.0, 6.0, 5.0, 3.0, 5.0, 3.0, 5.0, 4.0, 6.0, 6.0, 1.0,
      2.0, 6.0, 6.0, 2.0, 10.0, 3.0, 5.0, 6.0, 6.0, 4.0, 5.0, 2.0, 3.0, 6.0, 6.0,
      2.0, 0.0, 5.0, 5.0, 3.0, 3.0, 3.0, 2.0, 7.0, 5.0, 6.0, 6.0, 4.0, 8.0, 3.0, 2.0,
      3.0, 6.0, 5.0, 5.0, 5.0, 1.0, 4.0, 6.0, 2.0, 4.0, 7.0, 4.0, 6.0, 7.0, 4.0, 7.0,
      6.0, 6.0, 5.0, 6.0, 4.0, 3.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0, 11.0, 5.0, 6.0,
      3.0, 4.0, 5.0, 3.0, 3.0, 6.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0, 4.0, 4.0, 5.0, 6.0,
      5.0, 4.0, 3.0, 4.0, 4.0, 3.0, 3.0, 7.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10950986272690492
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04029133851173681
    mean_inference_ms: 2.029160644516126
    mean_raw_obs_processing_ms: 0.4572137691438147
time_since_restore: 439.6673002243042
time_this_iter_s: 10.158280849456787
time_total_s: 439.6673002243042
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1691992204
timesteps_total: 321300
training_iteration: 43
trial_id: default
train step: 44
agent_timesteps_total: 329000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03681206703186035
  StateBufferConnector_ms: 0.006623506546020508
  ViewRequirementAgentConnector_ms: 0.21742653846740723
counters:
  num_agent_steps_sampled: 329000
  num_agent_steps_trained: 312500
  num_env_steps_sampled: 329000
  num_env_steps_trained: 312500
  num_samples_added_to_queue: 329000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 6412
custom_metrics: {}
date: 2023-08-14_14-50-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.76
episode_reward_min: 0.0
episodes_this_iter: 59
episodes_total: 2570
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.200000000000045
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0440034866333008
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 11.314260482788086
        total_loss: 32.035064697265625
        var_gnorm: 63.554752349853516
        vf_explained_var: 0.8024523258209229
        vf_loss: 51.88163757324219
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 625.0
  learner_queue:
    size_count: 630
    size_mean: 14.7
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6522711641858305
  num_agent_steps_sampled: 329000
  num_agent_steps_trained: 312500
  num_env_steps_sampled: 329000
  num_env_steps_trained: 312500
  num_samples_added_to_queue: 329000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 6412
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 357.578
    learner_load_time_ms: 9.791
    learner_load_wait_time_ms: 2.651
iterations_since_restore: 44
node_ip: 127.0.0.1
num_agent_steps_sampled: 329000
num_agent_steps_trained: 312500
num_env_steps_sampled: 329000
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 768.9091411008548
num_env_steps_trained: 312500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 798.8666401047841
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.45
  ram_util_percent: 78.32142857142856
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10971806003133969
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040305673036954606
  mean_inference_ms: 2.0303913878420534
  mean_raw_obs_processing_ms: 0.457328164473655
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03681206703186035
    StateBufferConnector_ms: 0.006623506546020508
    ViewRequirementAgentConnector_ms: 0.21742653846740723
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.76
  episode_reward_min: 0.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 6.0, 6.0, 5.0, 6.0, 4.0, 3.0, 1.0, 1.0, 2.0, 5.0, 3.0, 4.0,
      11.0, 5.0, 6.0, 3.0, 4.0, 5.0, 3.0, 3.0, 6.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0,
      4.0, 4.0, 5.0, 6.0, 5.0, 4.0, 3.0, 4.0, 4.0, 3.0, 3.0, 7.0, 7.0, 6.0, 6.0, 5.0,
      6.0, 4.0, 2.0, 4.0, 8.0, 2.0, 7.0, 5.0, 2.0, 0.0, 7.0, 4.0, 3.0, 5.0, 4.0, 5.0,
      6.0, 9.0, 7.0, 7.0, 2.0, 0.0, 5.0, 5.0, 5.0, 8.0, 4.0, 8.0, 9.0, 4.0, 6.0, 8.0,
      4.0, 4.0, 5.0, 2.0, 5.0, 9.0, 3.0, 3.0, 5.0, 6.0, 4.0, 8.0, 4.0, 5.0, 3.0, 1.0,
      2.0, 7.0, 4.0, 5.0, 7.0, 7.0, 6.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10971806003133969
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040305673036954606
    mean_inference_ms: 2.0303913878420534
    mean_raw_obs_processing_ms: 0.457328164473655
time_since_restore: 449.9028673171997
time_this_iter_s: 10.235567092895508
time_total_s: 449.9028673171997
timers:
  sample_time_ms: 0.132
  synch_weights_time_ms: 1.173
  training_iteration_time_ms: 3.979
timestamp: 1691992214
timesteps_total: 329000
training_iteration: 44
trial_id: default
train step: 45
agent_timesteps_total: 335850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03673863410949707
  StateBufferConnector_ms: 0.0066530704498291016
  ViewRequirementAgentConnector_ms: 0.22252845764160156
counters:
  num_agent_steps_sampled: 335850
  num_agent_steps_trained: 319000
  num_env_steps_sampled: 335850
  num_env_steps_trained: 319000
  num_samples_added_to_queue: 335500
  num_training_step_calls_since_last_synch_worker_weights: 508
  num_weight_broadcasts: 6546
custom_metrics: {}
date: 2023-08-14_14-50-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.91
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 2624
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0179152488708496
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 30.545154571533203
        total_loss: 43.3673095703125
        var_gnorm: 63.56760787963867
        vf_explained_var: 0.8842930197715759
        vf_loss: 35.82346725463867
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 638.0
  learner_queue:
    size_count: 644
    size_mean: 14.8
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5491933384829668
  num_agent_steps_sampled: 335850
  num_agent_steps_trained: 319000
  num_env_steps_sampled: 335850
  num_env_steps_trained: 319000
  num_samples_added_to_queue: 335500
  num_training_step_calls_since_last_synch_worker_weights: 508
  num_weight_broadcasts: 6546
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 485.055
    learner_load_time_ms: 9.806
    learner_load_wait_time_ms: 3.378
iterations_since_restore: 45
node_ip: 127.0.0.1
num_agent_steps_sampled: 335850
num_agent_steps_trained: 319000
num_env_steps_sampled: 335850
num_env_steps_sampled_this_iter: 6850
num_env_steps_sampled_throughput_per_sec: 684.9960967524737
num_env_steps_trained: 319000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9962961884787
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 57.857142857142854
  ram_util_percent: 78.69285714285715
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10977359516383434
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0404285885235733
  mean_inference_ms: 2.031838817245886
  mean_raw_obs_processing_ms: 0.4575758158429585
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03673863410949707
    StateBufferConnector_ms: 0.0066530704498291016
    ViewRequirementAgentConnector_ms: 0.22252845764160156
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.91
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 4.0, 3.0, 5.0, 4.0, 5.0, 6.0, 9.0, 7.0, 7.0, 2.0, 0.0, 5.0,
      5.0, 5.0, 8.0, 4.0, 8.0, 9.0, 4.0, 6.0, 8.0, 4.0, 4.0, 5.0, 2.0, 5.0, 9.0, 3.0,
      3.0, 5.0, 6.0, 4.0, 8.0, 4.0, 5.0, 3.0, 1.0, 2.0, 7.0, 4.0, 5.0, 7.0, 7.0, 6.0,
      6.0, 1.0, 3.0, 5.0, 6.0, 5.0, 9.0, 4.0, 3.0, 7.0, 5.0, 6.0, 7.0, 8.0, 6.0, 5.0,
      7.0, 3.0, 1.0, 5.0, 2.0, 4.0, 3.0, 4.0, 3.0, 3.0, 2.0, 7.0, 5.0, 6.0, 5.0, 8.0,
      4.0, 7.0, 7.0, 6.0, 5.0, 5.0, 4.0, 4.0, 5.0, 3.0, 2.0, 4.0, 6.0, 7.0, 5.0, 9.0,
      6.0, 2.0, 3.0, 5.0, 2.0, 1.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10977359516383434
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0404285885235733
    mean_inference_ms: 2.031838817245886
    mean_raw_obs_processing_ms: 0.4575758158429585
time_since_restore: 460.14956641197205
time_this_iter_s: 10.246699094772339
time_total_s: 460.14956641197205
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.078
timestamp: 1691992224
timesteps_total: 335850
training_iteration: 45
trial_id: default
train step: 46
agent_timesteps_total: 343050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.037241458892822266
  StateBufferConnector_ms: 0.006693124771118164
  ViewRequirementAgentConnector_ms: 0.22530579566955566
counters:
  num_agent_steps_sampled: 343050
  num_agent_steps_trained: 326500
  num_env_steps_sampled: 343050
  num_env_steps_trained: 326500
  num_samples_added_to_queue: 343000
  num_training_step_calls_since_last_synch_worker_weights: 156
  num_weight_broadcasts: 6687
custom_metrics: {}
date: 2023-08-14_14-50-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.88
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 2681
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.95744389295578
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 34.94225311279297
        total_loss: 52.2915153503418
        var_gnorm: 63.57696533203125
        vf_explained_var: 0.8509896993637085
        vf_loss: 44.2729606628418
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 653.0
  learner_queue:
    size_count: 659
    size_mean: 14.64
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6584329953302306
  num_agent_steps_sampled: 343050
  num_agent_steps_trained: 326500
  num_env_steps_sampled: 343050
  num_env_steps_trained: 326500
  num_samples_added_to_queue: 343000
  num_training_step_calls_since_last_synch_worker_weights: 156
  num_weight_broadcasts: 6687
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 279.782
    learner_load_time_ms: 9.817
    learner_load_wait_time_ms: 2.792
iterations_since_restore: 46
node_ip: 127.0.0.1
num_agent_steps_sampled: 343050
num_agent_steps_trained: 326500
num_env_steps_sampled: 343050
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 719.9968414445203
num_env_steps_trained: 326500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.996709838042
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 57.31333333333335
  ram_util_percent: 79.06666666666666
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10985707689160058
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04059069240627398
  mean_inference_ms: 2.034557927990181
  mean_raw_obs_processing_ms: 0.45811395482947376
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.037241458892822266
    StateBufferConnector_ms: 0.006693124771118164
    ViewRequirementAgentConnector_ms: 0.22530579566955566
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.88
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 8.0, 6.0, 5.0, 7.0, 3.0, 1.0, 5.0, 2.0, 4.0, 3.0, 4.0, 3.0,
      3.0, 2.0, 7.0, 5.0, 6.0, 5.0, 8.0, 4.0, 7.0, 7.0, 6.0, 5.0, 5.0, 4.0, 4.0, 5.0,
      3.0, 2.0, 4.0, 6.0, 7.0, 5.0, 9.0, 6.0, 2.0, 3.0, 5.0, 2.0, 1.0, 5.0, 7.0, 7.0,
      6.0, 6.0, 6.0, 1.0, 9.0, 8.0, 3.0, 6.0, 3.0, 3.0, 3.0, 0.0, 4.0, 8.0, 6.0, 5.0,
      7.0, 9.0, 7.0, 9.0, 5.0, 2.0, 4.0, 4.0, 4.0, 5.0, 2.0, 4.0, 2.0, 3.0, 6.0, 8.0,
      6.0, 6.0, 7.0, 4.0, 4.0, 4.0, 3.0, 6.0, 6.0, 3.0, 5.0, 8.0, 2.0, 7.0, 2.0, 2.0,
      7.0, 7.0, 6.0, 5.0, 3.0, 5.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10985707689160058
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04059069240627398
    mean_inference_ms: 2.034557927990181
    mean_raw_obs_processing_ms: 0.45811395482947376
time_since_restore: 470.417512178421
time_this_iter_s: 10.267945766448975
time_total_s: 470.417512178421
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.076
timestamp: 1691992234
timesteps_total: 343050
training_iteration: 46
trial_id: default
train step: 47
agent_timesteps_total: 350350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03585696220397949
  StateBufferConnector_ms: 0.006453275680541992
  ViewRequirementAgentConnector_ms: 0.21102666854858398
counters:
  num_agent_steps_sampled: 350350
  num_agent_steps_trained: 333500
  num_env_steps_sampled: 350350
  num_env_steps_trained: 333500
  num_samples_added_to_queue: 350000
  num_training_step_calls_since_last_synch_worker_weights: 1218
  num_weight_broadcasts: 6830
custom_metrics: {}
date: 2023-08-14_14-50-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 5.12
episode_reward_min: 1.0
episodes_this_iter: 57
episodes_total: 2738
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.89999999999998
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.053277850151062
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -29.824203491210938
        total_loss: -17.07827377319336
        var_gnorm: 63.582881927490234
        vf_explained_var: 0.8997265100479126
        vf_loss: 36.02463912963867
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 667.0
  learner_queue:
    size_count: 671
    size_mean: 14.58
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6981166037701887
  num_agent_steps_sampled: 350350
  num_agent_steps_trained: 333500
  num_env_steps_sampled: 350350
  num_env_steps_trained: 333500
  num_samples_added_to_queue: 350000
  num_training_step_calls_since_last_synch_worker_weights: 1218
  num_weight_broadcasts: 6830
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 696.73
    learner_load_time_ms: 9.817
    learner_load_wait_time_ms: 3.347
iterations_since_restore: 47
node_ip: 127.0.0.1
num_agent_steps_sampled: 350350
num_agent_steps_trained: 333500
num_env_steps_sampled: 350350
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9942913501844
num_env_steps_trained: 333500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9945259522316
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 56.13571428571429
  ram_util_percent: 79.4857142857143
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10997887818912577
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04062918054902988
  mean_inference_ms: 2.035976498536664
  mean_raw_obs_processing_ms: 0.45835547547115607
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03585696220397949
    StateBufferConnector_ms: 0.006453275680541992
    ViewRequirementAgentConnector_ms: 0.21102666854858398
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 5.12
  episode_reward_min: 1.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 8.0, 6.0, 5.0, 7.0, 9.0, 7.0, 9.0, 5.0, 2.0, 4.0, 4.0, 4.0,
      5.0, 2.0, 4.0, 2.0, 3.0, 6.0, 8.0, 6.0, 6.0, 7.0, 4.0, 4.0, 4.0, 3.0, 6.0, 6.0,
      3.0, 5.0, 8.0, 2.0, 7.0, 2.0, 2.0, 7.0, 7.0, 6.0, 5.0, 3.0, 5.0, 7.0, 6.0, 5.0,
      3.0, 5.0, 4.0, 6.0, 4.0, 6.0, 7.0, 7.0, 14.0, 7.0, 5.0, 5.0, 6.0, 4.0, 5.0,
      2.0, 4.0, 7.0, 5.0, 6.0, 3.0, 5.0, 6.0, 3.0, 8.0, 2.0, 4.0, 1.0, 3.0, 4.0, 7.0,
      2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 7.0, 3.0, 8.0, 10.0, 4.0, 9.0, 4.0, 6.0, 5.0,
      10.0, 6.0, 3.0, 4.0, 4.0, 8.0, 9.0, 5.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10997887818912577
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04062918054902988
    mean_inference_ms: 2.035976498536664
    mean_raw_obs_processing_ms: 0.45835547547115607
time_since_restore: 480.65634512901306
time_this_iter_s: 10.238832950592041
time_total_s: 480.65634512901306
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.089
timestamp: 1691992245
timesteps_total: 350350
training_iteration: 47
trial_id: default
train step: 48
agent_timesteps_total: 355650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04204893112182617
  StateBufferConnector_ms: 0.007543802261352539
  ViewRequirementAgentConnector_ms: 0.2422924041748047
counters:
  num_agent_steps_sampled: 355650
  num_agent_steps_trained: 339000
  num_env_steps_sampled: 355650
  num_env_steps_trained: 339000
  num_samples_added_to_queue: 355500
  num_training_step_calls_since_last_synch_worker_weights: 808
  num_weight_broadcasts: 6931
custom_metrics: {}
date: 2023-08-14_14-50-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 5.08
episode_reward_min: 0.0
episodes_this_iter: 41
episodes_total: 2779
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1224919557571411
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.9976158142089844
        total_loss: 5.451663494110107
        var_gnorm: 63.58768844604492
        vf_explained_var: 0.9125902652740479
        vf_loss: 14.133015632629395
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 678.0
  learner_queue:
    size_count: 683
    size_mean: 14.7
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6278820596099706
  num_agent_steps_sampled: 355650
  num_agent_steps_trained: 339000
  num_env_steps_sampled: 355650
  num_env_steps_trained: 339000
  num_samples_added_to_queue: 355500
  num_training_step_calls_since_last_synch_worker_weights: 808
  num_weight_broadcasts: 6931
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 753.727
    learner_load_time_ms: 8.647
    learner_load_wait_time_ms: 23.693
iterations_since_restore: 48
node_ip: 127.0.0.1
num_agent_steps_sampled: 355650
num_agent_steps_trained: 339000
num_env_steps_sampled: 355650
num_env_steps_sampled_this_iter: 5300
num_env_steps_sampled_throughput_per_sec: 517.9000811523471
num_env_steps_trained: 339000
num_env_steps_trained_this_iter: 5500
num_env_steps_trained_throughput_per_sec: 537.4434804411148
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5500
perf:
  cpu_util_percent: 66.18
  ram_util_percent: 79.96000000000001
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11010889435693798
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04076694019196087
  mean_inference_ms: 2.042337612119199
  mean_raw_obs_processing_ms: 0.45951827743266904
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04204893112182617
    StateBufferConnector_ms: 0.007543802261352539
    ViewRequirementAgentConnector_ms: 0.2422924041748047
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 5.08
  episode_reward_min: 0.0
  episodes_this_iter: 41
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 7.0, 6.0, 5.0, 3.0, 5.0, 4.0, 6.0, 4.0, 6.0, 7.0, 7.0, 14.0,
      7.0, 5.0, 5.0, 6.0, 4.0, 5.0, 2.0, 4.0, 7.0, 5.0, 6.0, 3.0, 5.0, 6.0, 3.0, 8.0,
      2.0, 4.0, 1.0, 3.0, 4.0, 7.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 7.0, 3.0, 8.0, 10.0,
      4.0, 9.0, 4.0, 6.0, 5.0, 10.0, 6.0, 3.0, 4.0, 4.0, 8.0, 9.0, 5.0, 2.0, 6.0,
      5.0, 5.0, 1.0, 5.0, 5.0, 8.0, 7.0, 3.0, 7.0, 7.0, 5.0, 4.0, 8.0, 3.0, 4.0, 4.0,
      5.0, 9.0, 2.0, 3.0, 7.0, 3.0, 5.0, 3.0, 8.0, 7.0, 0.0, 8.0, 7.0, 6.0, 8.0, 4.0,
      3.0, 5.0, 3.0, 5.0, 5.0, 1.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11010889435693798
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04076694019196087
    mean_inference_ms: 2.042337612119199
    mean_raw_obs_processing_ms: 0.45951827743266904
time_since_restore: 491.1919529438019
time_this_iter_s: 10.535607814788818
time_total_s: 491.1919529438019
timers:
  sample_time_ms: 36.709
  synch_weights_time_ms: 0.012
  training_iteration_time_ms: 36.775
timestamp: 1691992255
timesteps_total: 355650
training_iteration: 48
trial_id: default
train step: 49
agent_timesteps_total: 362250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04604482650756836
  StateBufferConnector_ms: 0.00800943374633789
  ViewRequirementAgentConnector_ms: 0.2582859992980957
counters:
  num_agent_steps_sampled: 362250
  num_agent_steps_trained: 345500
  num_env_steps_sampled: 362250
  num_env_steps_trained: 345500
  num_samples_added_to_queue: 362000
  num_training_step_calls_since_last_synch_worker_weights: 781
  num_weight_broadcasts: 7059
custom_metrics: {}
date: 2023-08-14_14-51-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.9
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 2831
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 30.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1554218530654907
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.899145126342773
        total_loss: 26.196840286254883
        var_gnorm: 63.594608306884766
        vf_explained_var: 0.8859796524047852
        vf_loss: 26.14961051940918
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 691.0
  learner_queue:
    size_count: 696
    size_mean: 14.8
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5231546211727816
  num_agent_steps_sampled: 362250
  num_agent_steps_trained: 345500
  num_env_steps_sampled: 362250
  num_env_steps_trained: 345500
  num_samples_added_to_queue: 362000
  num_training_step_calls_since_last_synch_worker_weights: 781
  num_weight_broadcasts: 7059
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 518.778
    learner_load_time_ms: 8.75
    learner_load_wait_time_ms: 3.061
iterations_since_restore: 49
node_ip: 127.0.0.1
num_agent_steps_sampled: 362250
num_agent_steps_trained: 345500
num_env_steps_sampled: 362250
num_env_steps_sampled_this_iter: 6600
num_env_steps_sampled_throughput_per_sec: 659.9941936050071
num_env_steps_trained: 345500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9942815806888
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 58.214285714285715
  ram_util_percent: 78.9857142857143
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11061688157602517
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040991458462575646
  mean_inference_ms: 2.052215218668461
  mean_raw_obs_processing_ms: 0.46128659704844394
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04604482650756836
    StateBufferConnector_ms: 0.00800943374633789
    ViewRequirementAgentConnector_ms: 0.2582859992980957
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.9
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 4.0, 8.0, 9.0, 5.0, 2.0, 6.0, 5.0, 5.0, 1.0, 5.0, 5.0,
      8.0, 7.0, 3.0, 7.0, 7.0, 5.0, 4.0, 8.0, 3.0, 4.0, 4.0, 5.0, 9.0, 2.0, 3.0, 7.0,
      3.0, 5.0, 3.0, 8.0, 7.0, 0.0, 8.0, 7.0, 6.0, 8.0, 4.0, 3.0, 5.0, 3.0, 5.0, 5.0,
      1.0, 5.0, 4.0, 5.0, 4.0, 5.0, 5.0, 6.0, 5.0, 5.0, 4.0, 3.0, 4.0, 8.0, 4.0, 7.0,
      9.0, 2.0, 6.0, 4.0, 5.0, 2.0, 7.0, 4.0, 5.0, 7.0, 5.0, 10.0, 3.0, 8.0, 5.0,
      1.0, 6.0, 5.0, 3.0, 3.0, 5.0, 3.0, 3.0, 5.0, 2.0, 5.0, 3.0, 7.0, 6.0, 2.0, 5.0,
      6.0, 5.0, 5.0, 4.0, 4.0, 6.0, 4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11061688157602517
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040991458462575646
    mean_inference_ms: 2.052215218668461
    mean_raw_obs_processing_ms: 0.46128659704844394
time_since_restore: 501.4015100002289
time_this_iter_s: 10.209557056427002
time_total_s: 501.4015100002289
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1691992265
timesteps_total: 362250
training_iteration: 49
trial_id: default
train step: 50
agent_timesteps_total: 369050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.040341854095458984
  StateBufferConnector_ms: 0.00697016716003418
  ViewRequirementAgentConnector_ms: 0.22964167594909668
counters:
  num_agent_steps_sampled: 369050
  num_agent_steps_trained: 352500
  num_env_steps_sampled: 369050
  num_env_steps_trained: 352500
  num_samples_added_to_queue: 369000
  num_training_step_calls_since_last_synch_worker_weights: 886
  num_weight_broadcasts: 7192
custom_metrics: {}
date: 2023-08-14_14-51-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 5.46
episode_reward_min: 1.0
episodes_this_iter: 53
episodes_total: 2884
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.399999999999977
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.110280990600586
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -12.016879081726074
        total_loss: 3.230135917663574
        var_gnorm: 63.604087829589844
        vf_explained_var: 0.8070235252380371
        vf_loss: 41.596839904785156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 705.0
  learner_queue:
    size_count: 708
    size_mean: 14.88
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.4783774890061063
  num_agent_steps_sampled: 369050
  num_agent_steps_trained: 352500
  num_env_steps_sampled: 369050
  num_env_steps_trained: 352500
  num_samples_added_to_queue: 369000
  num_training_step_calls_since_last_synch_worker_weights: 886
  num_weight_broadcasts: 7192
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 683.002
    learner_load_time_ms: 8.756
    learner_load_wait_time_ms: 2.826
iterations_since_restore: 50
node_ip: 127.0.0.1
num_agent_steps_sampled: 369050
num_agent_steps_trained: 352500
num_env_steps_sampled: 369050
num_env_steps_sampled_this_iter: 6800
num_env_steps_sampled_throughput_per_sec: 679.995638875321
num_env_steps_trained: 352500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9955106069481
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 56.18666666666666
  ram_util_percent: 79.42000000000002
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1108737664870643
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041118728007441624
  mean_inference_ms: 2.0570710801739307
  mean_raw_obs_processing_ms: 0.46225314220013514
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.040341854095458984
    StateBufferConnector_ms: 0.00697016716003418
    ViewRequirementAgentConnector_ms: 0.22964167594909668
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 5.46
  episode_reward_min: 1.0
  episodes_this_iter: 53
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 5.0, 4.0, 3.0, 4.0, 8.0, 4.0, 7.0, 9.0, 2.0, 6.0, 4.0, 5.0,
      2.0, 7.0, 4.0, 5.0, 7.0, 5.0, 10.0, 3.0, 8.0, 5.0, 1.0, 6.0, 5.0, 3.0, 3.0,
      5.0, 3.0, 3.0, 5.0, 2.0, 5.0, 3.0, 7.0, 6.0, 2.0, 5.0, 6.0, 5.0, 5.0, 4.0, 4.0,
      6.0, 4.0, 7.0, 11.0, 5.0, 6.0, 7.0, 5.0, 7.0, 6.0, 2.0, 6.0, 8.0, 2.0, 5.0,
      9.0, 13.0, 6.0, 6.0, 5.0, 6.0, 7.0, 5.0, 8.0, 9.0, 6.0, 3.0, 10.0, 4.0, 5.0,
      11.0, 6.0, 6.0, 2.0, 8.0, 4.0, 4.0, 2.0, 9.0, 3.0, 12.0, 3.0, 5.0, 7.0, 2.0,
      9.0, 4.0, 5.0, 6.0, 2.0, 8.0, 5.0, 3.0, 9.0, 7.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1108737664870643
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041118728007441624
    mean_inference_ms: 2.0570710801739307
    mean_raw_obs_processing_ms: 0.46225314220013514
time_since_restore: 511.5511770248413
time_this_iter_s: 10.149667024612427
time_total_s: 511.5511770248413
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1691992276
timesteps_total: 369050
training_iteration: 50
trial_id: default
train step: 51
agent_timesteps_total: 376450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03760266304016113
  StateBufferConnector_ms: 0.006715536117553711
  ViewRequirementAgentConnector_ms: 0.22591257095336914
counters:
  num_agent_steps_sampled: 376450
  num_agent_steps_trained: 359500
  num_env_steps_sampled: 376450
  num_env_steps_trained: 359500
  num_samples_added_to_queue: 376000
  num_training_step_calls_since_last_synch_worker_weights: 258
  num_weight_broadcasts: 7337
custom_metrics: {}
date: 2023-08-14_14-51-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.23
episode_reward_min: 2.0
episodes_this_iter: 58
episodes_total: 2942
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.10000000000002
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.069277048110962
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 11.178338050842285
        total_loss: 17.942157745361328
        var_gnorm: 63.61335372924805
        vf_explained_var: 0.8982752561569214
        vf_loss: 24.220413208007812
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 719.0
  learner_queue:
    size_count: 725
    size_mean: 14.94
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4478950238190613
  num_agent_steps_sampled: 376450
  num_agent_steps_trained: 359500
  num_env_steps_sampled: 376450
  num_env_steps_trained: 359500
  num_samples_added_to_queue: 376000
  num_training_step_calls_since_last_synch_worker_weights: 258
  num_weight_broadcasts: 7337
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 371.602
    learner_load_time_ms: 8.487
    learner_load_wait_time_ms: 2.982
iterations_since_restore: 51
node_ip: 127.0.0.1
num_agent_steps_sampled: 376450
num_agent_steps_trained: 359500
num_env_steps_sampled: 376450
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9953422839556
num_env_steps_trained: 359500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9955940523903
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 50.92142857142858
  ram_util_percent: 79.07857142857142
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11103220374847812
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04116620215842048
  mean_inference_ms: 2.0586045935634343
  mean_raw_obs_processing_ms: 0.4625483390531629
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03760266304016113
    StateBufferConnector_ms: 0.006715536117553711
    ViewRequirementAgentConnector_ms: 0.22591257095336914
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.23
  episode_reward_min: 2.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 9.0, 13.0, 6.0, 6.0, 5.0, 6.0, 7.0, 5.0, 8.0, 9.0, 6.0,
      3.0, 10.0, 4.0, 5.0, 11.0, 6.0, 6.0, 2.0, 8.0, 4.0, 4.0, 2.0, 9.0, 3.0, 12.0,
      3.0, 5.0, 7.0, 2.0, 9.0, 4.0, 5.0, 6.0, 2.0, 8.0, 5.0, 3.0, 9.0, 7.0, 5.0, 5.0,
      6.0, 5.0, 9.0, 10.0, 8.0, 7.0, 5.0, 4.0, 3.0, 5.0, 9.0, 5.0, 8.0, 7.0, 11.0,
      6.0, 4.0, 5.0, 14.0, 5.0, 3.0, 5.0, 8.0, 10.0, 5.0, 6.0, 9.0, 9.0, 5.0, 3.0,
      3.0, 10.0, 5.0, 8.0, 4.0, 2.0, 2.0, 6.0, 5.0, 3.0, 10.0, 7.0, 5.0, 6.0, 8.0,
      7.0, 8.0, 6.0, 7.0, 6.0, 5.0, 8.0, 10.0, 6.0, 7.0, 9.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11103220374847812
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04116620215842048
    mean_inference_ms: 2.0586045935634343
    mean_raw_obs_processing_ms: 0.4625483390531629
time_since_restore: 521.8468148708344
time_this_iter_s: 10.295637845993042
time_total_s: 521.8468148708344
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691992286
timesteps_total: 376450
training_iteration: 51
trial_id: default
train step: 52
agent_timesteps_total: 383850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03737020492553711
  StateBufferConnector_ms: 0.006423473358154297
  ViewRequirementAgentConnector_ms: 0.22100496292114258
counters:
  num_agent_steps_sampled: 383850
  num_agent_steps_trained: 367000
  num_env_steps_sampled: 383850
  num_env_steps_trained: 367000
  num_samples_added_to_queue: 383500
  num_training_step_calls_since_last_synch_worker_weights: 825
  num_weight_broadcasts: 7482
custom_metrics: {}
date: 2023-08-14_14-51-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.36
episode_reward_min: 2.0
episodes_this_iter: 58
episodes_total: 3000
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0788464546203613
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 6.9467267990112305
        total_loss: 44.00075149536133
        var_gnorm: 63.625457763671875
        vf_explained_var: 0.7106336355209351
        vf_loss: 84.89651489257812
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 734.0
  learner_queue:
    size_count: 740
    size_mean: 14.82
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5580757362849855
  num_agent_steps_sampled: 383850
  num_agent_steps_trained: 367000
  num_env_steps_sampled: 383850
  num_env_steps_trained: 367000
  num_samples_added_to_queue: 383500
  num_training_step_calls_since_last_synch_worker_weights: 825
  num_weight_broadcasts: 7482
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 364.865
    learner_load_time_ms: 3.815
    learner_load_wait_time_ms: 2.797
iterations_since_restore: 52
node_ip: 127.0.0.1
num_agent_steps_sampled: 383850
num_agent_steps_trained: 367000
num_env_steps_sampled: 383850
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9935603702179
num_env_steps_trained: 367000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9934733481938
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.59333333333333
  ram_util_percent: 78.55333333333333
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1110834298318115
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041178705496879235
  mean_inference_ms: 2.0586891250476027
  mean_raw_obs_processing_ms: 0.46253908857927734
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03737020492553711
    StateBufferConnector_ms: 0.006423473358154297
    ViewRequirementAgentConnector_ms: 0.22100496292114258
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.36
  episode_reward_min: 2.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 4.0, 5.0, 14.0, 5.0, 3.0, 5.0, 8.0, 10.0, 5.0, 6.0, 9.0,
      9.0, 5.0, 3.0, 3.0, 10.0, 5.0, 8.0, 4.0, 2.0, 2.0, 6.0, 5.0, 3.0, 10.0, 7.0,
      5.0, 6.0, 8.0, 7.0, 8.0, 6.0, 7.0, 6.0, 5.0, 8.0, 10.0, 6.0, 7.0, 9.0, 2.0,
      9.0, 5.0, 8.0, 5.0, 4.0, 7.0, 6.0, 10.0, 8.0, 7.0, 3.0, 6.0, 12.0, 4.0, 9.0,
      8.0, 5.0, 3.0, 8.0, 6.0, 8.0, 8.0, 6.0, 7.0, 5.0, 5.0, 8.0, 7.0, 6.0, 5.0, 4.0,
      3.0, 4.0, 5.0, 5.0, 6.0, 8.0, 6.0, 5.0, 11.0, 14.0, 6.0, 3.0, 6.0, 9.0, 10.0,
      5.0, 6.0, 5.0, 6.0, 2.0, 7.0, 8.0, 8.0, 7.0, 4.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1110834298318115
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041178705496879235
    mean_inference_ms: 2.0586891250476027
    mean_raw_obs_processing_ms: 0.46253908857927734
time_since_restore: 532.1061656475067
time_this_iter_s: 10.259350776672363
time_total_s: 532.1061656475067
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1691992296
timesteps_total: 383850
training_iteration: 52
trial_id: default
train step: 53
agent_timesteps_total: 391550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035100698471069336
  StateBufferConnector_ms: 0.006136894226074219
  ViewRequirementAgentConnector_ms: 0.20482969284057617
counters:
  num_agent_steps_sampled: 391550
  num_agent_steps_trained: 375000
  num_env_steps_sampled: 391550
  num_env_steps_trained: 375000
  num_samples_added_to_queue: 391500
  num_training_step_calls_since_last_synch_worker_weights: 99
  num_weight_broadcasts: 7633
custom_metrics: {}
date: 2023-08-14_14-51-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.37
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 3060
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1402308940887451
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.0305233001709
        total_loss: -1.4366145133972168
        var_gnorm: 63.634708404541016
        vf_explained_var: 0.8593962788581848
        vf_loss: 46.590126037597656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 750.0
  learner_queue:
    size_count: 755
    size_mean: 14.8
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5620499351813308
  num_agent_steps_sampled: 391550
  num_agent_steps_trained: 375000
  num_env_steps_sampled: 391550
  num_env_steps_trained: 375000
  num_samples_added_to_queue: 391500
  num_training_step_calls_since_last_synch_worker_weights: 99
  num_weight_broadcasts: 7633
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 347.936
    learner_load_time_ms: 3.141
    learner_load_wait_time_ms: 2.654
iterations_since_restore: 53
node_ip: 127.0.0.1
num_agent_steps_sampled: 391550
num_agent_steps_trained: 375000
num_env_steps_sampled: 391550
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 769.995997926532
num_env_steps_trained: 375000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9958420015918
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 49.58571428571429
  ram_util_percent: 77.86428571428573
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11105504135465438
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04116108947183105
  mean_inference_ms: 2.057710861044832
  mean_raw_obs_processing_ms: 0.46229875588186886
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035100698471069336
    StateBufferConnector_ms: 0.006136894226074219
    ViewRequirementAgentConnector_ms: 0.20482969284057617
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.37
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 6.0, 8.0, 8.0, 6.0, 7.0, 5.0, 5.0, 8.0, 7.0, 6.0, 5.0, 4.0,
      3.0, 4.0, 5.0, 5.0, 6.0, 8.0, 6.0, 5.0, 11.0, 14.0, 6.0, 3.0, 6.0, 9.0, 10.0,
      5.0, 6.0, 5.0, 6.0, 2.0, 7.0, 8.0, 8.0, 7.0, 4.0, 7.0, 6.0, 9.0, 4.0, 3.0, 7.0,
      8.0, 12.0, 7.0, 4.0, 7.0, 5.0, 10.0, 8.0, 8.0, 5.0, 3.0, 3.0, 4.0, 9.0, 8.0,
      4.0, 8.0, 3.0, 3.0, 7.0, 6.0, 11.0, 4.0, 3.0, 2.0, 7.0, 7.0, 6.0, 8.0, 6.0,
      6.0, 8.0, 2.0, 7.0, 2.0, 9.0, 4.0, 6.0, 7.0, 5.0, 12.0, 9.0, 11.0, 0.0, 7.0,
      7.0, 5.0, 6.0, 7.0, 7.0, 8.0, 4.0, 7.0, 7.0, 13.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11105504135465438
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04116108947183105
    mean_inference_ms: 2.057710861044832
    mean_raw_obs_processing_ms: 0.46229875588186886
time_since_restore: 542.3284828662872
time_this_iter_s: 10.222317218780518
time_total_s: 542.3284828662872
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.074
timestamp: 1691992306
timesteps_total: 391550
training_iteration: 53
trial_id: default
train step: 54
agent_timesteps_total: 398450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034774065017700195
  StateBufferConnector_ms: 0.006217241287231445
  ViewRequirementAgentConnector_ms: 0.20503616333007812
counters:
  num_agent_steps_sampled: 398450
  num_agent_steps_trained: 381500
  num_env_steps_sampled: 398450
  num_env_steps_trained: 381500
  num_samples_added_to_queue: 398000
  num_training_step_calls_since_last_synch_worker_weights: 1391
  num_weight_broadcasts: 7768
custom_metrics: {}
date: 2023-08-14_14-51-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.44
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 3114
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1458741426467896
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -34.280357360839844
        total_loss: -19.94400978088379
        var_gnorm: 63.641727447509766
        vf_explained_var: 0.8820366263389587
        vf_loss: 40.13143539428711
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 763.0
  learner_queue:
    size_count: 767
    size_mean: 14.68
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.5929846201391902
  num_agent_steps_sampled: 398450
  num_agent_steps_trained: 381500
  num_env_steps_sampled: 398450
  num_env_steps_trained: 381500
  num_samples_added_to_queue: 398000
  num_training_step_calls_since_last_synch_worker_weights: 1391
  num_weight_broadcasts: 7768
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 755.706
    learner_load_time_ms: 3.141
    learner_load_wait_time_ms: 3.409
iterations_since_restore: 54
node_ip: 127.0.0.1
num_agent_steps_sampled: 398450
num_agent_steps_trained: 381500
num_env_steps_sampled: 398450
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 689.9944889985605
num_env_steps_trained: 381500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9948084769048
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 58.028571428571425
  ram_util_percent: 77.49285714285715
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1110301908140512
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041191930482961776
  mean_inference_ms: 2.0584379806678657
  mean_raw_obs_processing_ms: 0.46244377015566734
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034774065017700195
    StateBufferConnector_ms: 0.006217241287231445
    ViewRequirementAgentConnector_ms: 0.20503616333007812
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.44
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 4.0, 9.0, 8.0, 4.0, 8.0, 3.0, 3.0, 7.0, 6.0, 11.0,
      4.0, 3.0, 2.0, 7.0, 7.0, 6.0, 8.0, 6.0, 6.0, 8.0, 2.0, 7.0, 2.0, 9.0, 4.0, 6.0,
      7.0, 5.0, 12.0, 9.0, 11.0, 0.0, 7.0, 7.0, 5.0, 6.0, 7.0, 7.0, 8.0, 4.0, 7.0,
      7.0, 13.0, 7.0, 6.0, 5.0, 7.0, 5.0, 9.0, 9.0, 7.0, 7.0, 8.0, 7.0, 6.0, 10.0,
      4.0, 9.0, 3.0, 7.0, 5.0, 4.0, 7.0, 7.0, 8.0, 5.0, 10.0, 5.0, 9.0, 3.0, 8.0,
      4.0, 9.0, 10.0, 6.0, 6.0, 9.0, 7.0, 7.0, 0.0, 10.0, 2.0, 6.0, 7.0, 11.0, 4.0,
      7.0, 7.0, 6.0, 5.0, 9.0, 7.0, 7.0, 6.0, 7.0, 7.0, 4.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1110301908140512
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041191930482961776
    mean_inference_ms: 2.0584379806678657
    mean_raw_obs_processing_ms: 0.46244377015566734
time_since_restore: 552.5371227264404
time_this_iter_s: 10.208639860153198
time_total_s: 552.5371227264404
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.092
timestamp: 1691992317
timesteps_total: 398450
training_iteration: 54
trial_id: default
train step: 55
agent_timesteps_total: 405450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.037114620208740234
  StateBufferConnector_ms: 0.006567239761352539
  ViewRequirementAgentConnector_ms: 0.21615815162658691
counters:
  num_agent_steps_sampled: 405450
  num_agent_steps_trained: 388500
  num_env_steps_sampled: 405450
  num_env_steps_trained: 388500
  num_samples_added_to_queue: 405000
  num_training_step_calls_since_last_synch_worker_weights: 912
  num_weight_broadcasts: 7904
custom_metrics: {}
date: 2023-08-14_14-52-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.93
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 3168
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1066256761550903
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 67.01365661621094
        total_loss: 111.48548889160156
        var_gnorm: 63.6517333984375
        vf_explained_var: 0.8148655891418457
        vf_loss: 100.00991821289062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 777.0
  learner_queue:
    size_count: 782
    size_mean: 14.88
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4510685717773644
  num_agent_steps_sampled: 405450
  num_agent_steps_trained: 388500
  num_env_steps_sampled: 405450
  num_env_steps_trained: 388500
  num_samples_added_to_queue: 405000
  num_training_step_calls_since_last_synch_worker_weights: 912
  num_weight_broadcasts: 7904
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 434.096
    learner_load_time_ms: 18.27
    learner_load_wait_time_ms: 2.869
iterations_since_restore: 55
node_ip: 127.0.0.1
num_agent_steps_sampled: 405450
num_agent_steps_trained: 388500
num_env_steps_sampled: 405450
num_env_steps_sampled_this_iter: 7000
num_env_steps_sampled_throughput_per_sec: 699.995710876043
num_env_steps_trained: 388500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.995710876043
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 54.36666666666667
  ram_util_percent: 77.78666666666665
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11106893801981371
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041267986383149935
  mean_inference_ms: 2.0607350671142974
  mean_raw_obs_processing_ms: 0.46294350511726307
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.037114620208740234
    StateBufferConnector_ms: 0.006567239761352539
    ViewRequirementAgentConnector_ms: 0.21615815162658691
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.93
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 6.0, 10.0, 4.0, 9.0, 3.0, 7.0, 5.0, 4.0, 7.0, 7.0,
      8.0, 5.0, 10.0, 5.0, 9.0, 3.0, 8.0, 4.0, 9.0, 10.0, 6.0, 6.0, 9.0, 7.0, 7.0,
      0.0, 10.0, 2.0, 6.0, 7.0, 11.0, 4.0, 7.0, 7.0, 6.0, 5.0, 9.0, 7.0, 7.0, 6.0,
      7.0, 7.0, 4.0, 9.0, 10.0, 7.0, 5.0, 6.0, 3.0, 6.0, 9.0, 5.0, 7.0, 6.0, 5.0,
      12.0, 8.0, 4.0, 6.0, 5.0, 13.0, 4.0, 6.0, 5.0, 6.0, 4.0, 7.0, 10.0, 5.0, 5.0,
      8.0, 11.0, 9.0, 3.0, 10.0, 9.0, 11.0, 10.0, 11.0, 7.0, 6.0, 4.0, 7.0, 10.0,
      5.0, 9.0, 7.0, 7.0, 7.0, 7.0, 11.0, 9.0, 7.0, 6.0, 7.0, 7.0, 5.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11106893801981371
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041267986383149935
    mean_inference_ms: 2.0607350671142974
    mean_raw_obs_processing_ms: 0.46294350511726307
time_since_restore: 562.7915437221527
time_this_iter_s: 10.25442099571228
time_total_s: 562.7915437221527
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.088
timestamp: 1691992327
timesteps_total: 405450
training_iteration: 55
trial_id: default
train step: 56
agent_timesteps_total: 409650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04516434669494629
  StateBufferConnector_ms: 0.0077478885650634766
  ViewRequirementAgentConnector_ms: 0.2667837142944336
counters:
  num_agent_steps_sampled: 409650
  num_agent_steps_trained: 393000
  num_env_steps_sampled: 409650
  num_env_steps_trained: 393000
  num_samples_added_to_queue: 409500
  num_training_step_calls_since_last_synch_worker_weights: 773
  num_weight_broadcasts: 7984
custom_metrics: {}
date: 2023-08-14_14-52-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.83
episode_reward_min: 2.0
episodes_this_iter: 33
episodes_total: 3201
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 29.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0731816291809082
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -59.286285400390625
        total_loss: -5.718691349029541
        var_gnorm: 63.65768814086914
        vf_explained_var: 0.8325887322425842
        vf_loss: 117.86700439453125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 786.0
  learner_queue:
    size_count: 792
    size_mean: 14.92
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4260434775980708
  num_agent_steps_sampled: 409650
  num_agent_steps_trained: 393000
  num_env_steps_sampled: 409650
  num_env_steps_trained: 393000
  num_samples_added_to_queue: 409500
  num_training_step_calls_since_last_synch_worker_weights: 773
  num_weight_broadcasts: 7984
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 1023.584
    learner_load_time_ms: 20.182
    learner_load_wait_time_ms: 17.715
iterations_since_restore: 56
node_ip: 127.0.0.1
num_agent_steps_sampled: 409650
num_agent_steps_trained: 393000
num_env_steps_sampled: 409650
num_env_steps_sampled_this_iter: 4200
num_env_steps_sampled_throughput_per_sec: 419.99890852258136
num_env_steps_trained: 393000
num_env_steps_trained_this_iter: 4500
num_env_steps_trained_throughput_per_sec: 449.9988305599086
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 4500
perf:
  cpu_util_percent: 73.64
  ram_util_percent: 78.30666666666667
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11144804914840006
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04143952222212993
  mean_inference_ms: 2.0669964180454645
  mean_raw_obs_processing_ms: 0.46421828801741505
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04516434669494629
    StateBufferConnector_ms: 0.0077478885650634766
    ViewRequirementAgentConnector_ms: 0.2667837142944336
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.83
  episode_reward_min: 2.0
  episodes_this_iter: 33
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 7.0, 7.0, 6.0, 5.0, 9.0, 7.0, 7.0, 6.0, 7.0, 7.0, 4.0, 9.0,
      10.0, 7.0, 5.0, 6.0, 3.0, 6.0, 9.0, 5.0, 7.0, 6.0, 5.0, 12.0, 8.0, 4.0, 6.0,
      5.0, 13.0, 4.0, 6.0, 5.0, 6.0, 4.0, 7.0, 10.0, 5.0, 5.0, 8.0, 11.0, 9.0, 3.0,
      10.0, 9.0, 11.0, 10.0, 11.0, 7.0, 6.0, 4.0, 7.0, 10.0, 5.0, 9.0, 7.0, 7.0, 7.0,
      7.0, 11.0, 9.0, 7.0, 6.0, 7.0, 7.0, 5.0, 10.0, 8.0, 10.0, 3.0, 12.0, 8.0, 7.0,
      5.0, 7.0, 3.0, 10.0, 6.0, 3.0, 8.0, 5.0, 8.0, 6.0, 2.0, 6.0, 7.0, 11.0, 7.0,
      4.0, 2.0, 3.0, 8.0, 7.0, 6.0, 6.0, 7.0, 8.0, 5.0, 3.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11144804914840006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04143952222212993
    mean_inference_ms: 2.0669964180454645
    mean_raw_obs_processing_ms: 0.46421828801741505
time_since_restore: 573.218258857727
time_this_iter_s: 10.42671513557434
time_total_s: 573.218258857727
timers:
  sample_time_ms: 0.038
  synch_weights_time_ms: 0.01
  training_iteration_time_ms: 0.109
timestamp: 1691992337
timesteps_total: 409650
training_iteration: 56
trial_id: default
train step: 57
agent_timesteps_total: 414950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04985952377319336
  StateBufferConnector_ms: 0.008583545684814453
  ViewRequirementAgentConnector_ms: 0.29366111755371094
counters:
  num_agent_steps_sampled: 414950
  num_agent_steps_trained: 398000
  num_env_steps_sampled: 414950
  num_env_steps_trained: 398000
  num_samples_added_to_queue: 414500
  num_training_step_calls_since_last_synch_worker_weights: 314
  num_weight_broadcasts: 8087
custom_metrics: {}
date: 2023-08-14_14-52-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 7.05
episode_reward_min: 2.0
episodes_this_iter: 41
episodes_total: 3242
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0613696575164795
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -52.25988006591797
        total_loss: -22.163713455200195
        var_gnorm: 63.66230392456055
        vf_explained_var: 0.8649389743804932
        vf_loss: 70.8060302734375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 796.0
  learner_queue:
    size_count: 802
    size_mean: 14.46
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.6150541786577934
  num_agent_steps_sampled: 414950
  num_agent_steps_trained: 398000
  num_env_steps_sampled: 414950
  num_env_steps_trained: 398000
  num_samples_added_to_queue: 414500
  num_training_step_calls_since_last_synch_worker_weights: 314
  num_weight_broadcasts: 8087
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 1015.199
    learner_load_time_ms: 20.18
    learner_load_wait_time_ms: 13.401
iterations_since_restore: 57
node_ip: 127.0.0.1
num_agent_steps_sampled: 414950
num_agent_steps_trained: 398000
num_env_steps_sampled: 414950
num_env_steps_sampled_this_iter: 5300
num_env_steps_sampled_throughput_per_sec: 529.9963481677861
num_env_steps_trained: 398000
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.9965548752699
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 66.22857142857144
  ram_util_percent: 79.5642857142857
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11221483346902979
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04173753044083126
  mean_inference_ms: 2.0783527488842957
  mean_raw_obs_processing_ms: 0.46650857771964943
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04985952377319336
    StateBufferConnector_ms: 0.008583545684814453
    ViewRequirementAgentConnector_ms: 0.29366111755371094
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 7.05
  episode_reward_min: 2.0
  episodes_this_iter: 41
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 3.0, 10.0, 9.0, 11.0, 10.0, 11.0, 7.0, 6.0, 4.0, 7.0, 10.0,
      5.0, 9.0, 7.0, 7.0, 7.0, 7.0, 11.0, 9.0, 7.0, 6.0, 7.0, 7.0, 5.0, 10.0, 8.0,
      10.0, 3.0, 12.0, 8.0, 7.0, 5.0, 7.0, 3.0, 10.0, 6.0, 3.0, 8.0, 5.0, 8.0, 6.0,
      2.0, 6.0, 7.0, 11.0, 7.0, 4.0, 2.0, 3.0, 8.0, 7.0, 6.0, 6.0, 7.0, 8.0, 5.0,
      3.0, 8.0, 7.0, 8.0, 5.0, 8.0, 8.0, 9.0, 8.0, 11.0, 8.0, 8.0, 8.0, 5.0, 8.0,
      6.0, 9.0, 6.0, 9.0, 7.0, 8.0, 2.0, 8.0, 8.0, 4.0, 7.0, 11.0, 8.0, 6.0, 11.0,
      5.0, 9.0, 3.0, 11.0, 5.0, 9.0, 8.0, 8.0, 7.0, 5.0, 3.0, 7.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11221483346902979
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04173753044083126
    mean_inference_ms: 2.0783527488842957
    mean_raw_obs_processing_ms: 0.46650857771964943
time_since_restore: 583.4469790458679
time_this_iter_s: 10.22872018814087
time_total_s: 583.4469790458679
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1691992348
timesteps_total: 414950
training_iteration: 57
trial_id: default
train step: 58
agent_timesteps_total: 421750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.043881893157958984
  StateBufferConnector_ms: 0.007811069488525391
  ViewRequirementAgentConnector_ms: 0.2610602378845215
counters:
  num_agent_steps_sampled: 421750
  num_agent_steps_trained: 405000
  num_env_steps_sampled: 421750
  num_env_steps_trained: 405000
  num_samples_added_to_queue: 421500
  num_training_step_calls_since_last_synch_worker_weights: 224
  num_weight_broadcasts: 8220
custom_metrics: {}
date: 2023-08-14_14-52-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.69
episode_reward_min: 2.0
episodes_this_iter: 54
episodes_total: 3296
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0878947973251343
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.733909606933594
        total_loss: 25.624723434448242
        var_gnorm: 63.66777801513672
        vf_explained_var: 0.8609696626663208
        vf_loss: 81.5962142944336
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 810.0
  learner_queue:
    size_count: 816
    size_mean: 14.46
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.6758281534811377
  num_agent_steps_sampled: 421750
  num_agent_steps_trained: 405000
  num_env_steps_sampled: 421750
  num_env_steps_trained: 405000
  num_samples_added_to_queue: 421500
  num_training_step_calls_since_last_synch_worker_weights: 224
  num_weight_broadcasts: 8220
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 339.514
    learner_load_time_ms: 20.246
    learner_load_wait_time_ms: 3.037
iterations_since_restore: 58
node_ip: 127.0.0.1
num_agent_steps_sampled: 421750
num_agent_steps_trained: 405000
num_env_steps_sampled: 421750
num_env_steps_sampled_this_iter: 6800
num_env_steps_sampled_throughput_per_sec: 679.998573306216
num_env_steps_trained: 405000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9985313446341
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 57.580000000000005
  ram_util_percent: 79.62666666666668
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11255363186035307
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042026213773420945
  mean_inference_ms: 2.0897425396986558
  mean_raw_obs_processing_ms: 0.46906475271569176
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.043881893157958984
    StateBufferConnector_ms: 0.007811069488525391
    ViewRequirementAgentConnector_ms: 0.2610602378845215
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.69
  episode_reward_min: 2.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 8.0, 5.0, 3.0, 8.0, 7.0, 8.0, 5.0, 8.0, 8.0, 9.0, 8.0, 11.0,
      8.0, 8.0, 8.0, 5.0, 8.0, 6.0, 9.0, 6.0, 9.0, 7.0, 8.0, 2.0, 8.0, 8.0, 4.0, 7.0,
      11.0, 8.0, 6.0, 11.0, 5.0, 9.0, 3.0, 11.0, 5.0, 9.0, 8.0, 8.0, 7.0, 5.0, 3.0,
      7.0, 4.0, 3.0, 7.0, 5.0, 9.0, 9.0, 7.0, 4.0, 6.0, 4.0, 6.0, 6.0, 8.0, 7.0, 7.0,
      4.0, 7.0, 8.0, 3.0, 5.0, 4.0, 2.0, 4.0, 10.0, 6.0, 5.0, 7.0, 6.0, 5.0, 7.0,
      7.0, 6.0, 7.0, 9.0, 13.0, 4.0, 6.0, 6.0, 6.0, 9.0, 3.0, 4.0, 7.0, 8.0, 10.0,
      4.0, 2.0, 4.0, 7.0, 7.0, 12.0, 8.0, 8.0, 6.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11255363186035307
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042026213773420945
    mean_inference_ms: 2.0897425396986558
    mean_raw_obs_processing_ms: 0.46906475271569176
time_since_restore: 593.7397072315216
time_this_iter_s: 10.292728185653687
time_total_s: 593.7397072315216
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1691992358
timesteps_total: 421750
training_iteration: 58
trial_id: default
train step: 59
agent_timesteps_total: 429150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03619980812072754
  StateBufferConnector_ms: 0.006517887115478516
  ViewRequirementAgentConnector_ms: 0.21584296226501465
counters:
  num_agent_steps_sampled: 429150
  num_agent_steps_trained: 412500
  num_env_steps_sampled: 429150
  num_env_steps_trained: 412500
  num_samples_added_to_queue: 429000
  num_training_step_calls_since_last_synch_worker_weights: 21
  num_weight_broadcasts: 8364
custom_metrics: {}
date: 2023-08-14_14-52-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.54
episode_reward_min: 1.0
episodes_this_iter: 57
episodes_total: 3353
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 30.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0316952466964722
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -13.19083023071289
        total_loss: 15.223611831665039
        var_gnorm: 63.675418853759766
        vf_explained_var: 0.8977162837982178
        vf_loss: 67.14583587646484
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 825.0
  learner_queue:
    size_count: 831
    size_mean: 14.26
    size_quantiles: [11.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.7641995352000295
  num_agent_steps_sampled: 429150
  num_agent_steps_trained: 412500
  num_env_steps_sampled: 429150
  num_env_steps_trained: 412500
  num_samples_added_to_queue: 429000
  num_training_step_calls_since_last_synch_worker_weights: 21
  num_weight_broadcasts: 8364
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 276.313
    learner_load_time_ms: 20.246
    learner_load_wait_time_ms: 2.726
iterations_since_restore: 59
node_ip: 127.0.0.1
num_agent_steps_sampled: 429150
num_agent_steps_trained: 412500
num_env_steps_sampled: 429150
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9954834260045
num_env_steps_trained: 412500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9954223912208
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.90714285714285
  ram_util_percent: 79.72142857142856
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11266606618932024
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042070654211602845
  mean_inference_ms: 2.0911469319032205
  mean_raw_obs_processing_ms: 0.4693737122932991
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03619980812072754
    StateBufferConnector_ms: 0.006517887115478516
    ViewRequirementAgentConnector_ms: 0.21584296226501465
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.54
  episode_reward_min: 1.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 7.0, 4.0, 7.0, 8.0, 3.0, 5.0, 4.0, 2.0, 4.0, 10.0,
      6.0, 5.0, 7.0, 6.0, 5.0, 7.0, 7.0, 6.0, 7.0, 9.0, 13.0, 4.0, 6.0, 6.0, 6.0,
      9.0, 3.0, 4.0, 7.0, 8.0, 10.0, 4.0, 2.0, 4.0, 7.0, 7.0, 12.0, 8.0, 8.0, 6.0,
      9.0, 11.0, 10.0, 5.0, 8.0, 8.0, 5.0, 6.0, 6.0, 8.0, 10.0, 4.0, 7.0, 6.0, 4.0,
      10.0, 12.0, 6.0, 7.0, 3.0, 6.0, 1.0, 9.0, 8.0, 7.0, 10.0, 11.0, 2.0, 6.0, 5.0,
      11.0, 7.0, 5.0, 6.0, 6.0, 7.0, 5.0, 7.0, 4.0, 6.0, 10.0, 9.0, 6.0, 5.0, 4.0,
      5.0, 9.0, 4.0, 14.0, 3.0, 6.0, 4.0, 8.0, 6.0, 4.0, 4.0, 6.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11266606618932024
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042070654211602845
    mean_inference_ms: 2.0911469319032205
    mean_raw_obs_processing_ms: 0.4693737122932991
time_since_restore: 603.9934804439545
time_this_iter_s: 10.253773212432861
time_total_s: 603.9934804439545
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.076
timestamp: 1691992368
timesteps_total: 429150
training_iteration: 59
trial_id: default
train step: 60
agent_timesteps_total: 435350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04060530662536621
  StateBufferConnector_ms: 0.00701141357421875
  ViewRequirementAgentConnector_ms: 0.23429226875305176
counters:
  num_agent_steps_sampled: 435350
  num_agent_steps_trained: 418500
  num_env_steps_sampled: 435350
  num_env_steps_trained: 418500
  num_samples_added_to_queue: 435000
  num_training_step_calls_since_last_synch_worker_weights: 207
  num_weight_broadcasts: 8484
custom_metrics: {}
date: 2023-08-14_14-52-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.88
episode_reward_min: 1.0
episodes_this_iter: 49
episodes_total: 3402
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0717724561691284
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.79533576965332
        total_loss: 20.950420379638672
        var_gnorm: 63.680137634277344
        vf_explained_var: 0.9046338200569153
        vf_loss: 68.20923614501953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 837.0
  learner_queue:
    size_count: 843
    size_mean: 14.32
    size_quantiles: [11.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.7599999999999998
  num_agent_steps_sampled: 435350
  num_agent_steps_trained: 418500
  num_env_steps_sampled: 435350
  num_env_steps_trained: 418500
  num_samples_added_to_queue: 435000
  num_training_step_calls_since_last_synch_worker_weights: 207
  num_weight_broadcasts: 8484
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 721.474
    learner_load_time_ms: 20.184
    learner_load_wait_time_ms: 4.485
iterations_since_restore: 60
node_ip: 127.0.0.1
num_agent_steps_sampled: 435350
num_agent_steps_trained: 418500
num_env_steps_sampled: 435350
num_env_steps_sampled_this_iter: 6200
num_env_steps_sampled_throughput_per_sec: 619.9957280453347
num_env_steps_trained: 418500
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9958658503239
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 61.82
  ram_util_percent: 80.03999999999999
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11274940336814254
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04213508163885847
  mean_inference_ms: 2.093470808580574
  mean_raw_obs_processing_ms: 0.4699479308447046
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04060530662536621
    StateBufferConnector_ms: 0.00701141357421875
    ViewRequirementAgentConnector_ms: 0.23429226875305176
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.88
  episode_reward_min: 1.0
  episodes_this_iter: 49
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 6.0, 8.0, 10.0, 4.0, 7.0, 6.0, 4.0, 10.0, 12.0, 6.0, 7.0,
      3.0, 6.0, 1.0, 9.0, 8.0, 7.0, 10.0, 11.0, 2.0, 6.0, 5.0, 11.0, 7.0, 5.0, 6.0,
      6.0, 7.0, 5.0, 7.0, 4.0, 6.0, 10.0, 9.0, 6.0, 5.0, 4.0, 5.0, 9.0, 4.0, 14.0,
      3.0, 6.0, 4.0, 8.0, 6.0, 4.0, 4.0, 6.0, 5.0, 7.0, 5.0, 12.0, 6.0, 7.0, 8.0,
      9.0, 8.0, 2.0, 9.0, 7.0, 10.0, 3.0, 11.0, 10.0, 5.0, 5.0, 8.0, 6.0, 8.0, 7.0,
      7.0, 2.0, 7.0, 6.0, 5.0, 6.0, 7.0, 7.0, 11.0, 8.0, 7.0, 9.0, 6.0, 7.0, 7.0,
      7.0, 10.0, 7.0, 4.0, 3.0, 6.0, 6.0, 9.0, 14.0, 7.0, 9.0, 10.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11274940336814254
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04213508163885847
    mean_inference_ms: 2.093470808580574
    mean_raw_obs_processing_ms: 0.4699479308447046
time_since_restore: 614.2450215816498
time_this_iter_s: 10.251541137695312
time_total_s: 614.2450215816498
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1691992379
timesteps_total: 435350
training_iteration: 60
trial_id: default
train step: 61
agent_timesteps_total: 443000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03874635696411133
  StateBufferConnector_ms: 0.006728649139404297
  ViewRequirementAgentConnector_ms: 0.22694730758666992
counters:
  num_agent_steps_sampled: 443000
  num_agent_steps_trained: 426500
  num_env_steps_sampled: 443000
  num_env_steps_trained: 426500
  num_samples_added_to_queue: 443000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 8634
custom_metrics: {}
date: 2023-08-14_14-53-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.29
episode_reward_min: 1.0
episodes_this_iter: 59
episodes_total: 3461
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.036523699760437
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.7404913902282715
        total_loss: 11.188572883605957
        var_gnorm: 63.68368911743164
        vf_explained_var: 0.904739260673523
        vf_loss: 48.223365783691406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 853.0
  learner_queue:
    size_count: 855
    size_mean: 14.62
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.7191858538273286
  num_agent_steps_sampled: 443000
  num_agent_steps_trained: 426500
  num_env_steps_sampled: 443000
  num_env_steps_trained: 426500
  num_samples_added_to_queue: 443000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 8634
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 732.061
    learner_load_time_ms: 20.089
    learner_load_wait_time_ms: 8.858
iterations_since_restore: 61
node_ip: 127.0.0.1
num_agent_steps_sampled: 443000
num_agent_steps_trained: 426500
num_env_steps_sampled: 443000
num_env_steps_sampled_this_iter: 7650
num_env_steps_sampled_throughput_per_sec: 763.8176253566377
num_env_steps_trained: 426500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 798.7635297847191
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 54.50714285714286
  ram_util_percent: 79.63571428571427
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.112859354979908
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042181917099793236
  mean_inference_ms: 2.094919554981204
  mean_raw_obs_processing_ms: 0.47030798690858666
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03874635696411133
    StateBufferConnector_ms: 0.006728649139404297
    ViewRequirementAgentConnector_ms: 0.22694730758666992
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.29
  episode_reward_min: 1.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 9.0, 7.0, 10.0, 3.0, 11.0, 10.0, 5.0, 5.0, 8.0, 6.0, 8.0,
      7.0, 7.0, 2.0, 7.0, 6.0, 5.0, 6.0, 7.0, 7.0, 11.0, 8.0, 7.0, 9.0, 6.0, 7.0,
      7.0, 7.0, 10.0, 7.0, 4.0, 3.0, 6.0, 6.0, 9.0, 14.0, 7.0, 9.0, 10.0, 11.0, 9.0,
      7.0, 5.0, 4.0, 10.0, 10.0, 4.0, 9.0, 10.0, 7.0, 6.0, 1.0, 9.0, 7.0, 6.0, 12.0,
      5.0, 7.0, 7.0, 4.0, 10.0, 6.0, 4.0, 7.0, 7.0, 7.0, 6.0, 6.0, 9.0, 12.0, 9.0,
      8.0, 11.0, 11.0, 7.0, 5.0, 13.0, 6.0, 8.0, 8.0, 7.0, 8.0, 6.0, 2.0, 10.0, 5.0,
      9.0, 7.0, 5.0, 7.0, 10.0, 7.0, 8.0, 10.0, 7.0, 9.0, 6.0, 8.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.112859354979908
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042181917099793236
    mean_inference_ms: 2.094919554981204
    mean_raw_obs_processing_ms: 0.47030798690858666
time_since_restore: 624.3713748455048
time_this_iter_s: 10.12635326385498
time_total_s: 624.3713748455048
timers:
  sample_time_ms: 0.055
  synch_weights_time_ms: 0.697
  training_iteration_time_ms: 3.353
timestamp: 1691992389
timesteps_total: 443000
training_iteration: 61
trial_id: default
train step: 62
agent_timesteps_total: 449050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03787565231323242
  StateBufferConnector_ms: 0.006520509719848633
  ViewRequirementAgentConnector_ms: 0.22868776321411133
counters:
  num_agent_steps_sampled: 449050
  num_agent_steps_trained: 432500
  num_env_steps_sampled: 449050
  num_env_steps_trained: 432500
  num_samples_added_to_queue: 449000
  num_training_step_calls_since_last_synch_worker_weights: 391
  num_weight_broadcasts: 8753
custom_metrics: {}
date: 2023-08-14_14-53-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.55
episode_reward_min: 1.0
episodes_this_iter: 48
episodes_total: 3509
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0084182024002075
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -44.725093841552734
        total_loss: -7.385688304901123
        var_gnorm: 63.688777923583984
        vf_explained_var: 0.843793511390686
        vf_loss: 84.76299285888672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 865.0
  learner_queue:
    size_count: 870
    size_mean: 14.82
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6209873534361703
  num_agent_steps_sampled: 449050
  num_agent_steps_trained: 432500
  num_env_steps_sampled: 449050
  num_env_steps_trained: 432500
  num_samples_added_to_queue: 449000
  num_training_step_calls_since_last_synch_worker_weights: 391
  num_weight_broadcasts: 8753
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 405.539
    learner_load_time_ms: 20.09
    learner_load_wait_time_ms: 3.047
iterations_since_restore: 62
node_ip: 127.0.0.1
num_agent_steps_sampled: 449050
num_agent_steps_trained: 432500
num_env_steps_sampled: 449050
num_env_steps_sampled_this_iter: 6050
num_env_steps_sampled_throughput_per_sec: 604.9949803768833
num_env_steps_trained: 432500
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9950218613718
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 65.37142857142858
  ram_util_percent: 79.63571428571429
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11292831294345863
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04222679041647303
  mean_inference_ms: 2.0967714445801415
  mean_raw_obs_processing_ms: 0.4707135568716492
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03787565231323242
    StateBufferConnector_ms: 0.006520509719848633
    ViewRequirementAgentConnector_ms: 0.22868776321411133
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.55
  episode_reward_min: 1.0
  episodes_this_iter: 48
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 10.0, 7.0, 6.0, 1.0, 9.0, 7.0, 6.0, 12.0, 5.0, 7.0, 7.0,
      4.0, 10.0, 6.0, 4.0, 7.0, 7.0, 7.0, 6.0, 6.0, 9.0, 12.0, 9.0, 8.0, 11.0, 11.0,
      7.0, 5.0, 13.0, 6.0, 8.0, 8.0, 7.0, 8.0, 6.0, 2.0, 10.0, 5.0, 9.0, 7.0, 5.0,
      7.0, 10.0, 7.0, 8.0, 10.0, 7.0, 9.0, 6.0, 8.0, 3.0, 12.0, 10.0, 8.0, 6.0, 13.0,
      8.0, 6.0, 7.0, 4.0, 12.0, 3.0, 10.0, 12.0, 7.0, 14.0, 11.0, 7.0, 6.0, 11.0,
      7.0, 7.0, 9.0, 5.0, 10.0, 3.0, 6.0, 7.0, 6.0, 7.0, 8.0, 7.0, 8.0, 2.0, 6.0,
      5.0, 11.0, 5.0, 7.0, 11.0, 7.0, 6.0, 10.0, 9.0, 9.0, 6.0, 7.0, 8.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11292831294345863
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04222679041647303
    mean_inference_ms: 2.0967714445801415
    mean_raw_obs_processing_ms: 0.4707135568716492
time_since_restore: 634.6086099147797
time_this_iter_s: 10.237235069274902
time_total_s: 634.6086099147797
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1691992399
timesteps_total: 449050
training_iteration: 62
trial_id: default
train step: 63
agent_timesteps_total: 456850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03717160224914551
  StateBufferConnector_ms: 0.006407737731933594
  ViewRequirementAgentConnector_ms: 0.22826671600341797
counters:
  num_agent_steps_sampled: 456850
  num_agent_steps_trained: 440000
  num_env_steps_sampled: 456850
  num_env_steps_trained: 440000
  num_samples_added_to_queue: 456500
  num_training_step_calls_since_last_synch_worker_weights: 375
  num_weight_broadcasts: 8905
custom_metrics: {}
date: 2023-08-14_14-53-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.81
episode_reward_min: 2.0
episodes_this_iter: 61
episodes_total: 3570
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0128229856491089
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.318132400512695
        total_loss: 35.3050651550293
        var_gnorm: 63.69679641723633
        vf_explained_var: 0.9383445978164673
        vf_loss: 44.102088928222656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 880.0
  learner_queue:
    size_count: 886
    size_mean: 14.88
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5702229141112418
  num_agent_steps_sampled: 456850
  num_agent_steps_trained: 440000
  num_env_steps_sampled: 456850
  num_env_steps_trained: 440000
  num_samples_added_to_queue: 456500
  num_training_step_calls_since_last_synch_worker_weights: 375
  num_weight_broadcasts: 8905
  timing_breakdown:
    learner_dequeue_time_ms: 0.017
    learner_grad_time_ms: 305.547
    learner_load_time_ms: 20.11
    learner_load_wait_time_ms: 2.647
iterations_since_restore: 63
node_ip: 127.0.0.1
num_agent_steps_sampled: 456850
num_agent_steps_trained: 440000
num_env_steps_sampled: 456850
num_env_steps_sampled_this_iter: 7800
num_env_steps_sampled_throughput_per_sec: 779.9949417442285
num_env_steps_trained: 440000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9951362925274
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 52.873333333333335
  ram_util_percent: 80.07999999999998
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11304031432034364
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04226456462116971
  mean_inference_ms: 2.0981265582679507
  mean_raw_obs_processing_ms: 0.4709345507391647
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03717160224914551
    StateBufferConnector_ms: 0.006407737731933594
    ViewRequirementAgentConnector_ms: 0.22826671600341797
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.81
  episode_reward_min: 2.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 3.0, 10.0, 12.0, 7.0, 14.0, 11.0, 7.0, 6.0, 11.0, 7.0,
      7.0, 9.0, 5.0, 10.0, 3.0, 6.0, 7.0, 6.0, 7.0, 8.0, 7.0, 8.0, 2.0, 6.0, 5.0,
      11.0, 5.0, 7.0, 11.0, 7.0, 6.0, 10.0, 9.0, 9.0, 6.0, 7.0, 8.0, 5.0, 7.0, 10.0,
      9.0, 8.0, 7.0, 9.0, 10.0, 13.0, 6.0, 6.0, 5.0, 11.0, 9.0, 9.0, 12.0, 4.0, 11.0,
      8.0, 6.0, 10.0, 11.0, 11.0, 9.0, 10.0, 6.0, 5.0, 8.0, 4.0, 9.0, 5.0, 7.0, 11.0,
      5.0, 9.0, 6.0, 6.0, 4.0, 9.0, 7.0, 9.0, 6.0, 5.0, 5.0, 6.0, 8.0, 4.0, 8.0, 11.0,
      9.0, 12.0, 7.0, 9.0, 5.0, 12.0, 10.0, 11.0, 4.0, 9.0, 12.0, 2.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11304031432034364
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04226456462116971
    mean_inference_ms: 2.0981265582679507
    mean_raw_obs_processing_ms: 0.4709345507391647
time_since_restore: 644.8367519378662
time_this_iter_s: 10.228142023086548
time_total_s: 644.8367519378662
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1691992409
timesteps_total: 456850
training_iteration: 63
trial_id: default
train step: 64
agent_timesteps_total: 464550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033913373947143555
  StateBufferConnector_ms: 0.005998373031616211
  ViewRequirementAgentConnector_ms: 0.19979333877563477
counters:
  num_agent_steps_sampled: 464550
  num_agent_steps_trained: 448000
  num_env_steps_sampled: 464550
  num_env_steps_trained: 448000
  num_samples_added_to_queue: 464500
  num_training_step_calls_since_last_synch_worker_weights: 1103
  num_weight_broadcasts: 9056
custom_metrics: {}
date: 2023-08-14_14-53-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.69
episode_reward_min: 2.0
episodes_this_iter: 60
episodes_total: 3630
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9277109503746033
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 9.34716796875
        total_loss: 16.49315643310547
        var_gnorm: 63.70724105834961
        vf_explained_var: 0.9617851972579956
        vf_loss: 23.569087982177734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 896.0
  learner_queue:
    size_count: 901
    size_mean: 15.04
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4416657032752078
  num_agent_steps_sampled: 464550
  num_agent_steps_trained: 448000
  num_env_steps_sampled: 464550
  num_env_steps_trained: 448000
  num_samples_added_to_queue: 464500
  num_training_step_calls_since_last_synch_worker_weights: 1103
  num_weight_broadcasts: 9056
  timing_breakdown:
    learner_dequeue_time_ms: 0.019
    learner_grad_time_ms: 364.517
    learner_load_time_ms: 20.07
    learner_load_wait_time_ms: 2.751
iterations_since_restore: 64
node_ip: 127.0.0.1
num_agent_steps_sampled: 464550
num_agent_steps_trained: 448000
num_env_steps_sampled: 464550
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 769.9976868698943
num_env_steps_trained: 448000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9975967479422
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.99285714285715
  ram_util_percent: 79.6857142857143
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11305470440066821
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04221483851827467
  mean_inference_ms: 2.0957847238432157
  mean_raw_obs_processing_ms: 0.4704134989695497
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033913373947143555
    StateBufferConnector_ms: 0.005998373031616211
    ViewRequirementAgentConnector_ms: 0.19979333877563477
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.69
  episode_reward_min: 2.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 9.0, 10.0, 6.0, 5.0, 8.0, 4.0, 9.0, 5.0, 7.0, 11.0, 5.0,
      9.0, 6.0, 6.0, 4.0, 9.0, 7.0, 9.0, 6.0, 5.0, 5.0, 6.0, 8.0, 4.0, 8.0, 11.0,
      9.0, 12.0, 7.0, 9.0, 5.0, 12.0, 10.0, 11.0, 4.0, 9.0, 12.0, 2.0, 8.0, 9.0, 9.0,
      11.0, 9.0, 11.0, 5.0, 11.0, 6.0, 3.0, 13.0, 7.0, 6.0, 2.0, 8.0, 7.0, 9.0, 3.0,
      7.0, 4.0, 6.0, 6.0, 11.0, 12.0, 11.0, 9.0, 11.0, 4.0, 5.0, 5.0, 9.0, 7.0, 6.0,
      7.0, 12.0, 8.0, 6.0, 7.0, 7.0, 10.0, 10.0, 6.0, 6.0, 9.0, 12.0, 5.0, 10.0, 5.0,
      3.0, 10.0, 10.0, 7.0, 8.0, 7.0, 10.0, 8.0, 8.0, 5.0, 11.0, 5.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11305470440066821
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04221483851827467
    mean_inference_ms: 2.0957847238432157
    mean_raw_obs_processing_ms: 0.4704134989695497
time_since_restore: 655.049201965332
time_this_iter_s: 10.21245002746582
time_total_s: 655.049201965332
timers:
  sample_time_ms: 0.032
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.091
timestamp: 1691992419
timesteps_total: 464550
training_iteration: 64
trial_id: default
train step: 65
agent_timesteps_total: 472150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035195350646972656
  StateBufferConnector_ms: 0.0063076019287109375
  ViewRequirementAgentConnector_ms: 0.2067852020263672
counters:
  num_agent_steps_sampled: 472150
  num_agent_steps_trained: 455500
  num_env_steps_sampled: 472150
  num_env_steps_trained: 455500
  num_samples_added_to_queue: 472000
  num_training_step_calls_since_last_synch_worker_weights: 473
  num_weight_broadcasts: 9204
custom_metrics: {}
date: 2023-08-14_14-53-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.52
episode_reward_min: 0.0
episodes_this_iter: 59
episodes_total: 3689
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7094382643699646
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.601703643798828
        total_loss: 10.347190856933594
        var_gnorm: 63.72158432006836
        vf_explained_var: 0.9589648842811584
        vf_loss: 50.99217224121094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 911.0
  learner_queue:
    size_count: 917
    size_mean: 14.74
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6100931650062986
  num_agent_steps_sampled: 472150
  num_agent_steps_trained: 455500
  num_env_steps_sampled: 472150
  num_env_steps_trained: 455500
  num_samples_added_to_queue: 472000
  num_training_step_calls_since_last_synch_worker_weights: 473
  num_weight_broadcasts: 9204
  timing_breakdown:
    learner_dequeue_time_ms: 0.019
    learner_grad_time_ms: 307.592
    learner_load_time_ms: 20.099
    learner_load_wait_time_ms: 2.902
iterations_since_restore: 65
node_ip: 127.0.0.1
num_agent_steps_sampled: 472150
num_agent_steps_trained: 455500
num_env_steps_sampled: 472150
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9962129781601
num_env_steps_trained: 455500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9962628073948
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.25714285714286
  ram_util_percent: 79.84285714285713
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11292051121215146
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04217326734620144
  mean_inference_ms: 2.094055967046741
  mean_raw_obs_processing_ms: 0.47014912019344446
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035195350646972656
    StateBufferConnector_ms: 0.0063076019287109375
    ViewRequirementAgentConnector_ms: 0.2067852020263672
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.52
  episode_reward_min: 0.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 6.0, 11.0, 12.0, 11.0, 9.0, 11.0, 4.0, 5.0, 5.0, 9.0, 7.0,
      6.0, 7.0, 12.0, 8.0, 6.0, 7.0, 7.0, 10.0, 10.0, 6.0, 6.0, 9.0, 12.0, 5.0, 10.0,
      5.0, 3.0, 10.0, 10.0, 7.0, 8.0, 7.0, 10.0, 8.0, 8.0, 5.0, 11.0, 5.0, 12.0, 8.0,
      6.0, 7.0, 7.0, 4.0, 9.0, 6.0, 8.0, 5.0, 7.0, 3.0, 3.0, 4.0, 5.0, 4.0, 3.0, 2.0,
      1.0, 10.0, 4.0, 8.0, 3.0, 9.0, 7.0, 3.0, 6.0, 2.0, 4.0, 7.0, 4.0, 9.0, 3.0,
      9.0, 4.0, 7.0, 1.0, 5.0, 3.0, 8.0, 2.0, 8.0, 10.0, 4.0, 7.0, 12.0, 7.0, 5.0,
      6.0, 4.0, 5.0, 8.0, 4.0, 7.0, 6.0, 5.0, 7.0, 4.0, 7.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11292051121215146
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04217326734620144
    mean_inference_ms: 2.094055967046741
    mean_raw_obs_processing_ms: 0.47014912019344446
time_since_restore: 665.3106777667999
time_this_iter_s: 10.261475801467896
time_total_s: 665.3106777667999
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.01
  training_iteration_time_ms: 0.09
timestamp: 1691992430
timesteps_total: 472150
training_iteration: 65
trial_id: default
train step: 66
agent_timesteps_total: 479750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03453826904296875
  StateBufferConnector_ms: 0.006347179412841797
  ViewRequirementAgentConnector_ms: 0.2074873447418213
counters:
  num_agent_steps_sampled: 479750
  num_agent_steps_trained: 463000
  num_env_steps_sampled: 479750
  num_env_steps_trained: 463000
  num_samples_added_to_queue: 479500
  num_training_step_calls_since_last_synch_worker_weights: 1242
  num_weight_broadcasts: 9353
custom_metrics: {}
date: 2023-08-14_14-54-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.96
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 3749
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5023014545440674
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.4405250549316406
        total_loss: 17.357709884643555
        var_gnorm: 63.73314666748047
        vf_explained_var: 0.9485965371131897
        vf_loss: 34.857383728027344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 926.0
  learner_queue:
    size_count: 930
    size_mean: 14.82
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5321879780235843
  num_agent_steps_sampled: 479750
  num_agent_steps_trained: 463000
  num_env_steps_sampled: 479750
  num_env_steps_trained: 463000
  num_samples_added_to_queue: 479500
  num_training_step_calls_since_last_synch_worker_weights: 1242
  num_weight_broadcasts: 9353
  timing_breakdown:
    learner_dequeue_time_ms: 0.019
    learner_grad_time_ms: 431.872
    learner_load_time_ms: 4.875
    learner_load_wait_time_ms: 2.786
iterations_since_restore: 66
node_ip: 127.0.0.1
num_agent_steps_sampled: 479750
num_agent_steps_trained: 463000
num_env_steps_sampled: 479750
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9968834051145
num_env_steps_trained: 463000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.996924412942
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.55333333333333
  ram_util_percent: 79.20666666666668
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11283496711342092
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0421307440724317
  mean_inference_ms: 2.0923487461526418
  mean_raw_obs_processing_ms: 0.4698736050059273
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03453826904296875
    StateBufferConnector_ms: 0.006347179412841797
    ViewRequirementAgentConnector_ms: 0.2074873447418213
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.96
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 8.0, 3.0, 9.0, 7.0, 3.0, 6.0, 2.0, 4.0, 7.0, 4.0, 9.0, 3.0,
      9.0, 4.0, 7.0, 1.0, 5.0, 3.0, 8.0, 2.0, 8.0, 10.0, 4.0, 7.0, 12.0, 7.0, 5.0,
      6.0, 4.0, 5.0, 8.0, 4.0, 7.0, 6.0, 5.0, 7.0, 4.0, 7.0, 0.0, 7.0, 3.0, 5.0, 3.0,
      4.0, 6.0, 2.0, 5.0, 6.0, 3.0, 2.0, 8.0, 3.0, 5.0, 5.0, 1.0, 8.0, 4.0, 4.0, 4.0,
      1.0, 6.0, 4.0, 6.0, 2.0, 1.0, 4.0, 4.0, 3.0, 3.0, 7.0, 10.0, 3.0, 3.0, 6.0,
      5.0, 6.0, 6.0, 6.0, 4.0, 4.0, 5.0, 4.0, 7.0, 4.0, 5.0, 5.0, 6.0, 5.0, 6.0, 5.0,
      4.0, 4.0, 3.0, 10.0, 3.0, 2.0, 1.0, 8.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11283496711342092
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0421307440724317
    mean_inference_ms: 2.0923487461526418
    mean_raw_obs_processing_ms: 0.4698736050059273
time_since_restore: 675.4582798480988
time_this_iter_s: 10.147602081298828
time_total_s: 675.4582798480988
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.078
timestamp: 1691992440
timesteps_total: 479750
training_iteration: 66
trial_id: default
train step: 67
agent_timesteps_total: 487150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03591275215148926
  StateBufferConnector_ms: 0.006361961364746094
  ViewRequirementAgentConnector_ms: 0.2139427661895752
counters:
  num_agent_steps_sampled: 487150
  num_agent_steps_trained: 470500
  num_env_steps_sampled: 487150
  num_env_steps_trained: 470500
  num_samples_added_to_queue: 487000
  num_training_step_calls_since_last_synch_worker_weights: 866
  num_weight_broadcasts: 9497
custom_metrics: {}
date: 2023-08-14_14-54-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 2.92
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 3806
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5496318936347961
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -12.911410331726074
        total_loss: -2.2194461822509766
        var_gnorm: 63.738834381103516
        vf_explained_var: 0.8959728479385376
        vf_loss: 26.880247116088867
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 941.0
  learner_queue:
    size_count: 947
    size_mean: 14.88
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5184202316881845
  num_agent_steps_sampled: 487150
  num_agent_steps_trained: 470500
  num_env_steps_sampled: 487150
  num_env_steps_trained: 470500
  num_samples_added_to_queue: 487000
  num_training_step_calls_since_last_synch_worker_weights: 866
  num_weight_broadcasts: 9497
  timing_breakdown:
    learner_dequeue_time_ms: 0.018
    learner_grad_time_ms: 367.513
    learner_load_time_ms: 3.17
    learner_load_wait_time_ms: 4.043
iterations_since_restore: 67
node_ip: 127.0.0.1
num_agent_steps_sampled: 487150
num_agent_steps_trained: 470500
num_env_steps_sampled: 487150
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9915667541287
num_env_steps_trained: 470500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9914527913467
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 58.84666666666667
  ram_util_percent: 78.43333333333334
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11279332434227315
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04211105306876561
  mean_inference_ms: 2.0918276111697924
  mean_raw_obs_processing_ms: 0.46977593952512303
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03591275215148926
    StateBufferConnector_ms: 0.006361961364746094
    ViewRequirementAgentConnector_ms: 0.2139427661895752
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 2.92
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 4.0, 4.0, 1.0, 6.0, 4.0, 6.0, 2.0, 1.0, 4.0, 4.0, 3.0, 3.0,
      7.0, 10.0, 3.0, 3.0, 6.0, 5.0, 6.0, 6.0, 6.0, 4.0, 4.0, 5.0, 4.0, 7.0, 4.0,
      5.0, 5.0, 6.0, 5.0, 6.0, 5.0, 4.0, 4.0, 3.0, 10.0, 3.0, 2.0, 1.0, 8.0, 3.0,
      1.0, 0.0, 3.0, 3.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 4.0, 2.0, 0.0, 0.0,
      2.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0,
      2.0, 5.0, 4.0, 5.0, 1.0, 3.0, 3.0, 1.0, 3.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0,
      3.0, 2.0, 1.0, 0.0, 1.0, 4.0, 1.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11279332434227315
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04211105306876561
    mean_inference_ms: 2.0918276111697924
    mean_raw_obs_processing_ms: 0.46977593952512303
time_since_restore: 685.9748861789703
time_this_iter_s: 10.516606330871582
time_total_s: 685.9748861789703
timers:
  sample_time_ms: 0.047
  synch_weights_time_ms: 0.015
  training_iteration_time_ms: 0.148
timestamp: 1691992450
timesteps_total: 487150
training_iteration: 67
trial_id: default
train step: 68
agent_timesteps_total: 493850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03918313980102539
  StateBufferConnector_ms: 0.006744384765625
  ViewRequirementAgentConnector_ms: 0.24024724960327148
counters:
  num_agent_steps_sampled: 493850
  num_agent_steps_trained: 477000
  num_env_steps_sampled: 493850
  num_env_steps_trained: 477000
  num_samples_added_to_queue: 493500
  num_training_step_calls_since_last_synch_worker_weights: 278
  num_weight_broadcasts: 9627
custom_metrics: {}
date: 2023-08-14_14-54-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.51
episode_reward_min: 0.0
episodes_this_iter: 53
episodes_total: 3859
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.200000000000045
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5140814185142517
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 6.580408573150635
        total_loss: 20.456188201904297
        var_gnorm: 63.74269485473633
        vf_explained_var: 0.890781044960022
        vf_loss: 32.89237594604492
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 954.0
  learner_queue:
    size_count: 960
    size_mean: 14.74
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6347476869535553
  num_agent_steps_sampled: 493850
  num_agent_steps_trained: 477000
  num_env_steps_sampled: 493850
  num_env_steps_trained: 477000
  num_samples_added_to_queue: 493500
  num_training_step_calls_since_last_synch_worker_weights: 278
  num_weight_broadcasts: 9627
  timing_breakdown:
    learner_dequeue_time_ms: 0.018
    learner_grad_time_ms: 450.174
    learner_load_time_ms: 3.249
    learner_load_wait_time_ms: 4.863
iterations_since_restore: 68
node_ip: 127.0.0.1
num_agent_steps_sampled: 493850
num_agent_steps_trained: 477000
num_env_steps_sampled: 493850
num_env_steps_sampled_this_iter: 6700
num_env_steps_sampled_throughput_per_sec: 669.9982588336417
num_env_steps_trained: 477000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9983108087569
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 71.14285714285714
  ram_util_percent: 80.67857142857143
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11279372195785693
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042134522442030614
  mean_inference_ms: 2.0935316638545713
  mean_raw_obs_processing_ms: 0.47020846207568723
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03918313980102539
    StateBufferConnector_ms: 0.006744384765625
    ViewRequirementAgentConnector_ms: 0.24024724960327148
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.51
  episode_reward_min: 0.0
  episodes_this_iter: 53
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 4.0, 2.0, 0.0, 0.0, 2.0, 3.0, 0.0, 4.0, 0.0, 0.0, 0.0,
      2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 2.0, 5.0, 4.0, 5.0, 1.0, 3.0, 3.0,
      1.0, 3.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 4.0, 1.0,
      1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0, 4.0, 5.0, 0.0, 0.0,
      0.0, 2.0, 2.0, 1.0, 4.0, 1.0, 3.0, 0.0, 2.0, 4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0,
      0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 5.0, 2.0,
      0.0, 0.0, 3.0, 3.0, 1.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11279372195785693
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042134522442030614
    mean_inference_ms: 2.0935316638545713
    mean_raw_obs_processing_ms: 0.47020846207568723
time_since_restore: 696.3989353179932
time_this_iter_s: 10.424049139022827
time_total_s: 696.3989353179932
timers:
  sample_time_ms: 0.032
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.092
timestamp: 1691992461
timesteps_total: 493850
training_iteration: 68
trial_id: default
train step: 69
agent_timesteps_total: 501850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035547733306884766
  StateBufferConnector_ms: 0.006097078323364258
  ViewRequirementAgentConnector_ms: 0.21881937980651855
counters:
  num_agent_steps_sampled: 501850
  num_agent_steps_trained: 485000
  num_env_steps_sampled: 501850
  num_env_steps_trained: 485000
  num_samples_added_to_queue: 501500
  num_training_step_calls_since_last_synch_worker_weights: 327
  num_weight_broadcasts: 9784
custom_metrics: {}
date: 2023-08-14_14-54-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.97
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 3921
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9608994126319885
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -24.333467483520508
        total_loss: -25.096593856811523
        var_gnorm: 63.7469482421875
        vf_explained_var: 0.9759809374809265
        vf_loss: 8.082740783691406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 970.0
  learner_queue:
    size_count: 976
    size_mean: 14.74
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6347476869535555
  num_agent_steps_sampled: 501850
  num_agent_steps_trained: 485000
  num_env_steps_sampled: 501850
  num_env_steps_trained: 485000
  num_samples_added_to_queue: 501500
  num_training_step_calls_since_last_synch_worker_weights: 327
  num_weight_broadcasts: 9784
  timing_breakdown:
    learner_dequeue_time_ms: 0.017
    learner_grad_time_ms: 308.089
    learner_load_time_ms: 3.214
    learner_load_wait_time_ms: 2.545
iterations_since_restore: 69
node_ip: 127.0.0.1
num_agent_steps_sampled: 501850
num_agent_steps_trained: 485000
num_env_steps_sampled: 501850
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9983215367247
num_env_steps_trained: 485000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9983215367247
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 54.14666666666666
  ram_util_percent: 80.56
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11281725763556867
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04210190099198614
  mean_inference_ms: 2.092929005551081
  mean_raw_obs_processing_ms: 0.4701314438100503
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035547733306884766
    StateBufferConnector_ms: 0.006097078323364258
    ViewRequirementAgentConnector_ms: 0.21881937980651855
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.97
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 1.0, 4.0, 1.0, 3.0, 0.0, 2.0, 4.0, 0.0, 0.0, 1.0, 1.0,
      0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,
      5.0, 2.0, 0.0, 0.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 4.0, 1.0, 1.0, 5.0, 9.0, 1.0,
      3.0, 6.0, 6.0, 2.0, 5.0, 2.0, 8.0, 4.0, 4.0, 4.0, 4.0, 3.0, 7.0, 4.0, 5.0, 3.0,
      2.0, 4.0, 2.0, 5.0, 4.0, 0.0, 4.0, 3.0, 0.0, 3.0, 2.0, 6.0, 6.0, 2.0, 5.0, 2.0,
      7.0, 5.0, 9.0, 3.0, 5.0, 4.0, 2.0, 9.0, 8.0, 5.0, 3.0, 9.0, 1.0, 2.0, 4.0, 2.0,
      5.0, 5.0, 4.0, 1.0, 2.0, 5.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11281725763556867
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04210190099198614
    mean_inference_ms: 2.092929005551081
    mean_raw_obs_processing_ms: 0.4701314438100503
time_since_restore: 706.6203773021698
time_this_iter_s: 10.221441984176636
time_total_s: 706.6203773021698
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.09
timestamp: 1691992471
timesteps_total: 501850
training_iteration: 69
trial_id: default
train step: 70
agent_timesteps_total: 508350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03646349906921387
  StateBufferConnector_ms: 0.006265878677368164
  ViewRequirementAgentConnector_ms: 0.2276477813720703
counters:
  num_agent_steps_sampled: 508350
  num_agent_steps_trained: 491500
  num_env_steps_sampled: 508350
  num_env_steps_trained: 491500
  num_samples_added_to_queue: 508000
  num_training_step_calls_since_last_synch_worker_weights: 1193
  num_weight_broadcasts: 9911
custom_metrics: {}
date: 2023-08-14_14-54-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 5.02
episode_reward_min: 0.0
episodes_this_iter: 51
episodes_total: 3972
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.5
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0396738052368164
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.0358808040618896
        total_loss: 0.8133187294006348
        var_gnorm: 63.74851989746094
        vf_explained_var: 0.9543206691741943
        vf_loss: 7.951613903045654
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 983.0
  learner_queue:
    size_count: 988
    size_mean: 14.6
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6733200530681513
  num_agent_steps_sampled: 508350
  num_agent_steps_trained: 491500
  num_env_steps_sampled: 508350
  num_env_steps_trained: 491500
  num_samples_added_to_queue: 508000
  num_training_step_calls_since_last_synch_worker_weights: 1193
  num_weight_broadcasts: 9911
  timing_breakdown:
    learner_dequeue_time_ms: 0.017
    learner_grad_time_ms: 641.16
    learner_load_time_ms: 3.214
    learner_load_wait_time_ms: 3.645
iterations_since_restore: 70
node_ip: 127.0.0.1
num_agent_steps_sampled: 508350
num_agent_steps_trained: 491500
num_env_steps_sampled: 508350
num_env_steps_sampled_this_iter: 6500
num_env_steps_sampled_throughput_per_sec: 649.994483040906
num_env_steps_trained: 491500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.994483040906
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 59.45
  ram_util_percent: 81.12857142857142
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11284305357759958
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042110056537423474
  mean_inference_ms: 2.093442754315774
  mean_raw_obs_processing_ms: 0.470318572188065
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03646349906921387
    StateBufferConnector_ms: 0.006265878677368164
    ViewRequirementAgentConnector_ms: 0.2276477813720703
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 5.02
  episode_reward_min: 0.0
  episodes_this_iter: 51
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 4.0, 4.0, 4.0, 4.0, 3.0, 7.0, 4.0, 5.0, 3.0, 2.0, 4.0, 2.0,
      5.0, 4.0, 0.0, 4.0, 3.0, 0.0, 3.0, 2.0, 6.0, 6.0, 2.0, 5.0, 2.0, 7.0, 5.0, 9.0,
      3.0, 5.0, 4.0, 2.0, 9.0, 8.0, 5.0, 3.0, 9.0, 1.0, 2.0, 4.0, 2.0, 5.0, 5.0, 4.0,
      1.0, 2.0, 5.0, 8.0, 5.0, 3.0, 8.0, 5.0, 7.0, 6.0, 7.0, 8.0, 7.0, 8.0, 3.0, 6.0,
      7.0, 2.0, 8.0, 6.0, 5.0, 6.0, 7.0, 7.0, 0.0, 4.0, 9.0, 8.0, 6.0, 6.0, 6.0, 5.0,
      6.0, 6.0, 6.0, 6.0, 6.0, 10.0, 4.0, 2.0, 2.0, 5.0, 7.0, 8.0, 2.0, 5.0, 9.0,
      4.0, 3.0, 7.0, 9.0, 9.0, 2.0, 9.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11284305357759958
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042110056537423474
    mean_inference_ms: 2.093442754315774
    mean_raw_obs_processing_ms: 0.470318572188065
time_since_restore: 716.9437193870544
time_this_iter_s: 10.323342084884644
time_total_s: 716.9437193870544
timers:
  sample_time_ms: 0.037
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.109
timestamp: 1691992481
timesteps_total: 508350
training_iteration: 70
trial_id: default
train step: 71
agent_timesteps_total: 515650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03846096992492676
  StateBufferConnector_ms: 0.006690502166748047
  ViewRequirementAgentConnector_ms: 0.23900628089904785
counters:
  num_agent_steps_sampled: 515650
  num_agent_steps_trained: 499000
  num_env_steps_sampled: 515650
  num_env_steps_trained: 499000
  num_samples_added_to_queue: 515500
  num_training_step_calls_since_last_synch_worker_weights: 1251
  num_weight_broadcasts: 10054
custom_metrics: {}
date: 2023-08-14_14-54-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 6.45
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 4029
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0892744064331055
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -13.563614845275879
        total_loss: 4.889736175537109
        var_gnorm: 63.75144577026367
        vf_explained_var: 0.8773013353347778
        vf_loss: 47.79944610595703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 998.0
  learner_queue:
    size_count: 1003
    size_mean: 14.72
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5753094934012173
  num_agent_steps_sampled: 515650
  num_agent_steps_trained: 499000
  num_env_steps_sampled: 515650
  num_env_steps_trained: 499000
  num_samples_added_to_queue: 515500
  num_training_step_calls_since_last_synch_worker_weights: 1251
  num_weight_broadcasts: 10054
  timing_breakdown:
    learner_dequeue_time_ms: 0.018
    learner_grad_time_ms: 413.148
    learner_load_time_ms: 2.638
    learner_load_wait_time_ms: 3.294
iterations_since_restore: 71
node_ip: 127.0.0.1
num_agent_steps_sampled: 515650
num_agent_steps_trained: 499000
num_env_steps_sampled: 515650
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9973545170334
num_env_steps_trained: 499000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9972820380481
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 57.628571428571426
  ram_util_percent: 80.73571428571428
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1128560627151875
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042149478530441764
  mean_inference_ms: 2.0949885744546646
  mean_raw_obs_processing_ms: 0.47078856277672015
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03846096992492676
    StateBufferConnector_ms: 0.006690502166748047
    ViewRequirementAgentConnector_ms: 0.23900628089904785
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 6.45
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 8.0, 3.0, 6.0, 7.0, 2.0, 8.0, 6.0, 5.0, 6.0, 7.0, 7.0, 0.0,
      4.0, 9.0, 8.0, 6.0, 6.0, 6.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 10.0, 4.0, 2.0,
      2.0, 5.0, 7.0, 8.0, 2.0, 5.0, 9.0, 4.0, 3.0, 7.0, 9.0, 9.0, 2.0, 9.0, 6.0, 12.0,
      4.0, 8.0, 5.0, 10.0, 5.0, 6.0, 5.0, 6.0, 4.0, 6.0, 5.0, 9.0, 8.0, 9.0, 2.0,
      10.0, 7.0, 3.0, 7.0, 5.0, 4.0, 12.0, 4.0, 10.0, 5.0, 7.0, 7.0, 7.0, 7.0, 7.0,
      7.0, 5.0, 5.0, 7.0, 6.0, 5.0, 9.0, 8.0, 10.0, 9.0, 7.0, 4.0, 7.0, 16.0, 10.0,
      9.0, 11.0, 5.0, 6.0, 4.0, 6.0, 5.0, 6.0, 5.0, 9.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1128560627151875
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042149478530441764
    mean_inference_ms: 2.0949885744546646
    mean_raw_obs_processing_ms: 0.47078856277672015
time_since_restore: 727.1926102638245
time_this_iter_s: 10.24889087677002
time_total_s: 727.1926102638245
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.106
timestamp: 1691992492
timesteps_total: 515650
training_iteration: 71
trial_id: default
train step: 72
agent_timesteps_total: 523250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034838199615478516
  StateBufferConnector_ms: 0.006044149398803711
  ViewRequirementAgentConnector_ms: 0.20545601844787598
counters:
  num_agent_steps_sampled: 523250
  num_agent_steps_trained: 506500
  num_env_steps_sampled: 523250
  num_env_steps_trained: 506500
  num_samples_added_to_queue: 523000
  num_training_step_calls_since_last_synch_worker_weights: 1198
  num_weight_broadcasts: 10203
custom_metrics: {}
date: 2023-08-14_14-55-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 6.22
episode_reward_min: 1.0
episodes_this_iter: 59
episodes_total: 4088
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0642660856246948
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -20.253189086914062
        total_loss: 7.547398090362549
        var_gnorm: 63.7576904296875
        vf_explained_var: 0.8642680644989014
        vf_loss: 66.24383544921875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1013.0
  learner_queue:
    size_count: 1017
    size_mean: 14.96
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4277254638059798
  num_agent_steps_sampled: 523250
  num_agent_steps_trained: 506500
  num_env_steps_sampled: 523250
  num_env_steps_trained: 506500
  num_samples_added_to_queue: 523000
  num_training_step_calls_since_last_synch_worker_weights: 1198
  num_weight_broadcasts: 10203
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 417.149
    learner_load_time_ms: 2.637
    learner_load_wait_time_ms: 2.862
iterations_since_restore: 72
node_ip: 127.0.0.1
num_agent_steps_sampled: 523250
num_agent_steps_trained: 506500
num_env_steps_sampled: 523250
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9992570884338
num_env_steps_trained: 506500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.999266863586
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.09333333333333
  ram_util_percent: 76.54666666666665
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11288425789377161
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04212171988608827
  mean_inference_ms: 2.0939373680755757
  mean_raw_obs_processing_ms: 0.4705827015585234
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034838199615478516
    StateBufferConnector_ms: 0.006044149398803711
    ViewRequirementAgentConnector_ms: 0.20545601844787598
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 6.22
  episode_reward_min: 1.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 7.0, 3.0, 7.0, 5.0, 4.0, 12.0, 4.0, 10.0, 5.0, 7.0, 7.0,
      7.0, 7.0, 7.0, 7.0, 5.0, 5.0, 7.0, 6.0, 5.0, 9.0, 8.0, 10.0, 9.0, 7.0, 4.0,
      7.0, 16.0, 10.0, 9.0, 11.0, 5.0, 6.0, 4.0, 6.0, 5.0, 6.0, 5.0, 9.0, 9.0, 8.0,
      8.0, 5.0, 4.0, 6.0, 3.0, 5.0, 5.0, 3.0, 5.0, 6.0, 4.0, 7.0, 5.0, 4.0, 9.0, 5.0,
      5.0, 10.0, 2.0, 7.0, 2.0, 7.0, 4.0, 7.0, 5.0, 8.0, 5.0, 6.0, 5.0, 2.0, 5.0,
      1.0, 9.0, 7.0, 7.0, 6.0, 5.0, 10.0, 3.0, 4.0, 7.0, 9.0, 7.0, 1.0, 4.0, 3.0,
      10.0, 7.0, 9.0, 8.0, 5.0, 3.0, 5.0, 3.0, 5.0, 7.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11288425789377161
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04212171988608827
    mean_inference_ms: 2.0939373680755757
    mean_raw_obs_processing_ms: 0.4705827015585234
time_since_restore: 737.3350133895874
time_this_iter_s: 10.14240312576294
time_total_s: 737.3350133895874
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.079
timestamp: 1691992502
timesteps_total: 523250
training_iteration: 72
trial_id: default
train step: 73
agent_timesteps_total: 531350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031899213790893555
  StateBufferConnector_ms: 0.005519390106201172
  ViewRequirementAgentConnector_ms: 0.1906120777130127
counters:
  num_agent_steps_sampled: 531350
  num_agent_steps_trained: 514500
  num_env_steps_sampled: 531350
  num_env_steps_trained: 514500
  num_samples_added_to_queue: 531000
  num_training_step_calls_since_last_synch_worker_weights: 696
  num_weight_broadcasts: 10360
custom_metrics: {}
date: 2023-08-14_14-55-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 6.41
episode_reward_min: 1.0
episodes_this_iter: 64
episodes_total: 4152
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0071407556533813
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 10.78361988067627
        total_loss: 34.221466064453125
        var_gnorm: 63.76974105834961
        vf_explained_var: 0.908321738243103
        vf_loss: 56.947105407714844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1029.0
  learner_queue:
    size_count: 1034
    size_mean: 15.12
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2905812643921342
  num_agent_steps_sampled: 531350
  num_agent_steps_trained: 514500
  num_env_steps_sampled: 531350
  num_env_steps_trained: 514500
  num_samples_added_to_queue: 531000
  num_training_step_calls_since_last_synch_worker_weights: 696
  num_weight_broadcasts: 10360
  timing_breakdown:
    learner_dequeue_time_ms: 0.015
    learner_grad_time_ms: 378.658
    learner_load_time_ms: 2.633
    learner_load_wait_time_ms: 2.591
iterations_since_restore: 73
node_ip: 127.0.0.1
num_agent_steps_sampled: 531350
num_agent_steps_trained: 514500
num_env_steps_sampled: 531350
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9996716977496
num_env_steps_trained: 514500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9996757508638
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.41428571428572
  ram_util_percent: 75.30714285714286
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11281506613412916
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04204813450853541
  mean_inference_ms: 2.0910440669141686
  mean_raw_obs_processing_ms: 0.4699746190188621
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031899213790893555
    StateBufferConnector_ms: 0.005519390106201172
    ViewRequirementAgentConnector_ms: 0.1906120777130127
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 6.41
  episode_reward_min: 1.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 7.0, 5.0, 8.0, 5.0, 6.0, 5.0, 2.0, 5.0, 1.0, 9.0, 7.0, 7.0,
      6.0, 5.0, 10.0, 3.0, 4.0, 7.0, 9.0, 7.0, 1.0, 4.0, 3.0, 10.0, 7.0, 9.0, 8.0,
      5.0, 3.0, 5.0, 3.0, 5.0, 7.0, 6.0, 7.0, 4.0, 9.0, 8.0, 4.0, 6.0, 8.0, 3.0, 8.0,
      7.0, 9.0, 5.0, 4.0, 2.0, 8.0, 3.0, 6.0, 10.0, 7.0, 4.0, 5.0, 11.0, 6.0, 5.0,
      5.0, 6.0, 15.0, 7.0, 4.0, 4.0, 10.0, 8.0, 6.0, 4.0, 9.0, 9.0, 8.0, 11.0, 5.0,
      5.0, 5.0, 3.0, 8.0, 9.0, 9.0, 9.0, 6.0, 7.0, 4.0, 6.0, 11.0, 11.0, 9.0, 9.0,
      9.0, 4.0, 6.0, 9.0, 8.0, 6.0, 5.0, 7.0, 9.0, 3.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11281506613412916
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04204813450853541
    mean_inference_ms: 2.0910440669141686
    mean_raw_obs_processing_ms: 0.4699746190188621
time_since_restore: 747.5276544094086
time_this_iter_s: 10.192641019821167
time_total_s: 747.5276544094086
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691992512
timesteps_total: 531350
training_iteration: 73
trial_id: default
train step: 74
agent_timesteps_total: 539500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03139638900756836
  StateBufferConnector_ms: 0.005556583404541016
  ViewRequirementAgentConnector_ms: 0.18807744979858398
counters:
  num_agent_steps_sampled: 539500
  num_agent_steps_trained: 523000
  num_env_steps_sampled: 539500
  num_env_steps_trained: 523000
  num_samples_added_to_queue: 539500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 10520
custom_metrics: {}
date: 2023-08-14_14-55-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 6.51
episode_reward_min: 2.0
episodes_this_iter: 63
episodes_total: 4215
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9730312824249268
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 12.877062797546387
        total_loss: 22.842824935913086
        var_gnorm: 63.786834716796875
        vf_explained_var: 0.933744490146637
        vf_loss: 29.661836624145508
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1046.0
  learner_queue:
    size_count: 1051
    size_mean: 15.22
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2536347155371854
  num_agent_steps_sampled: 539500
  num_agent_steps_trained: 523000
  num_env_steps_sampled: 539500
  num_env_steps_trained: 523000
  num_samples_added_to_queue: 539500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 10520
  timing_breakdown:
    learner_dequeue_time_ms: 0.017
    learner_grad_time_ms: 326.166
    learner_load_time_ms: 2.6
    learner_load_wait_time_ms: 2.717
iterations_since_restore: 74
node_ip: 127.0.0.1
num_agent_steps_sampled: 539500
num_agent_steps_trained: 523000
num_env_steps_sampled: 539500
num_env_steps_sampled_this_iter: 8150
num_env_steps_sampled_throughput_per_sec: 811.9584930734458
num_env_steps_trained: 523000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 846.8278762115692
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 50.65714285714285
  ram_util_percent: 74.42857142857144
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11264802539893194
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04196155127102312
  mean_inference_ms: 2.0877863292420455
  mean_raw_obs_processing_ms: 0.4692651039946412
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03139638900756836
    StateBufferConnector_ms: 0.005556583404541016
    ViewRequirementAgentConnector_ms: 0.18807744979858398
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 6.51
  episode_reward_min: 2.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 4.0, 10.0, 8.0, 6.0, 4.0, 9.0, 9.0, 8.0, 11.0, 5.0, 5.0,
      5.0, 3.0, 8.0, 9.0, 9.0, 9.0, 6.0, 7.0, 4.0, 6.0, 11.0, 11.0, 9.0, 9.0, 9.0,
      4.0, 6.0, 9.0, 8.0, 6.0, 5.0, 7.0, 9.0, 3.0, 6.0, 2.0, 4.0, 7.0, 7.0, 7.0, 3.0,
      3.0, 7.0, 3.0, 6.0, 8.0, 9.0, 7.0, 7.0, 3.0, 2.0, 5.0, 6.0, 5.0, 6.0, 4.0, 9.0,
      8.0, 8.0, 5.0, 6.0, 8.0, 3.0, 6.0, 10.0, 8.0, 9.0, 7.0, 7.0, 3.0, 10.0, 6.0,
      7.0, 9.0, 8.0, 3.0, 6.0, 5.0, 3.0, 5.0, 7.0, 6.0, 8.0, 9.0, 10.0, 6.0, 3.0,
      9.0, 5.0, 3.0, 8.0, 5.0, 7.0, 5.0, 8.0, 5.0, 9.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11264802539893194
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04196155127102312
    mean_inference_ms: 2.0877863292420455
    mean_raw_obs_processing_ms: 0.4692651039946412
time_since_restore: 757.7950973510742
time_this_iter_s: 10.26744294166565
time_total_s: 757.7950973510742
timers:
  sample_time_ms: 0.1
  synch_weights_time_ms: 1.084
  training_iteration_time_ms: 3.838
timestamp: 1691992522
timesteps_total: 539500
training_iteration: 74
trial_id: default
train step: 75
agent_timesteps_total: 547700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03168177604675293
  StateBufferConnector_ms: 0.005621671676635742
  ViewRequirementAgentConnector_ms: 0.1897294521331787
counters:
  num_agent_steps_sampled: 547700
  num_agent_steps_trained: 531000
  num_env_steps_sampled: 547700
  num_env_steps_trained: 531000
  num_samples_added_to_queue: 547500
  num_training_step_calls_since_last_synch_worker_weights: 323
  num_weight_broadcasts: 10682
custom_metrics: {}
date: 2023-08-14_14-55-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.47
episode_reward_min: 1.0
episodes_this_iter: 65
episodes_total: 4280
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9458001255989075
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -6.181437015533447
        total_loss: 33.283447265625
        var_gnorm: 63.80417251586914
        vf_explained_var: 0.9189435839653015
        vf_loss: 88.38777160644531
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1062.0
  learner_queue:
    size_count: 1068
    size_mean: 15.06
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4887578715157141
  num_agent_steps_sampled: 547700
  num_agent_steps_trained: 531000
  num_env_steps_sampled: 547700
  num_env_steps_trained: 531000
  num_samples_added_to_queue: 547500
  num_training_step_calls_since_last_synch_worker_weights: 323
  num_weight_broadcasts: 10682
  timing_breakdown:
    learner_dequeue_time_ms: 0.017
    learner_grad_time_ms: 290.778
    learner_load_time_ms: 2.598
    learner_load_wait_time_ms: 2.586
iterations_since_restore: 75
node_ip: 127.0.0.1
num_agent_steps_sampled: 547700
num_agent_steps_trained: 531000
num_env_steps_sampled: 547700
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9931965438748
num_env_steps_trained: 531000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9933624818291
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.13333333333334
  ram_util_percent: 73.86666666666666
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.112470339829089
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04187067699810019
  mean_inference_ms: 2.084142747297885
  mean_raw_obs_processing_ms: 0.46848194555051065
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03168177604675293
    StateBufferConnector_ms: 0.005621671676635742
    ViewRequirementAgentConnector_ms: 0.1897294521331787
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.47
  episode_reward_min: 1.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 10.0, 8.0, 9.0, 7.0, 7.0, 3.0, 10.0, 6.0, 7.0, 9.0, 8.0,
      3.0, 6.0, 5.0, 3.0, 5.0, 7.0, 6.0, 8.0, 9.0, 10.0, 6.0, 3.0, 9.0, 5.0, 3.0,
      8.0, 5.0, 7.0, 5.0, 8.0, 5.0, 9.0, 7.0, 5.0, 4.0, 5.0, 6.0, 8.0, 9.0, 4.0, 8.0,
      11.0, 6.0, 5.0, 5.0, 3.0, 6.0, 8.0, 3.0, 9.0, 6.0, 8.0, 3.0, 7.0, 8.0, 8.0,
      3.0, 5.0, 12.0, 6.0, 3.0, 7.0, 10.0, 9.0, 6.0, 4.0, 3.0, 9.0, 5.0, 10.0, 1.0,
      10.0, 5.0, 10.0, 6.0, 7.0, 12.0, 7.0, 8.0, 2.0, 5.0, 6.0, 5.0, 7.0, 6.0, 10.0,
      7.0, 5.0, 5.0, 8.0, 6.0, 9.0, 6.0, 6.0, 7.0, 4.0, 5.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.112470339829089
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04187067699810019
    mean_inference_ms: 2.084142747297885
    mean_raw_obs_processing_ms: 0.46848194555051065
time_since_restore: 768.0225560665131
time_this_iter_s: 10.227458715438843
time_total_s: 768.0225560665131
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.083
timestamp: 1691992533
timesteps_total: 547700
training_iteration: 75
trial_id: default
train step: 76
agent_timesteps_total: 555950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03135323524475098
  StateBufferConnector_ms: 0.005469799041748047
  ViewRequirementAgentConnector_ms: 0.18625187873840332
counters:
  num_agent_steps_sampled: 555950
  num_agent_steps_trained: 539000
  num_env_steps_sampled: 555950
  num_env_steps_trained: 539000
  num_samples_added_to_queue: 555500
  num_training_step_calls_since_last_synch_worker_weights: 489
  num_weight_broadcasts: 10844
custom_metrics: {}
date: 2023-08-14_14-55-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.28
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 4344
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0466278791427612
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 17.174610137939453
        total_loss: 57.25346755981445
        var_gnorm: 63.813804626464844
        vf_explained_var: 0.9305428266525269
        vf_loss: 90.62399291992188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1078.0
  learner_queue:
    size_count: 1083
    size_mean: 14.86
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5875767697972907
  num_agent_steps_sampled: 555950
  num_agent_steps_trained: 539000
  num_env_steps_sampled: 555950
  num_env_steps_trained: 539000
  num_samples_added_to_queue: 555500
  num_training_step_calls_since_last_synch_worker_weights: 489
  num_weight_broadcasts: 10844
  timing_breakdown:
    learner_dequeue_time_ms: 0.018
    learner_grad_time_ms: 379.313
    learner_load_time_ms: 2.602
    learner_load_wait_time_ms: 2.504
iterations_since_restore: 76
node_ip: 127.0.0.1
num_agent_steps_sampled: 555950
num_agent_steps_trained: 539000
num_env_steps_sampled: 555950
num_env_steps_sampled_this_iter: 8250
num_env_steps_sampled_throughput_per_sec: 824.9957710721307
num_env_steps_trained: 539000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.99589922146
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.38571428571429
  ram_util_percent: 73.58571428571429
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1122966734851928
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04178112413209698
  mean_inference_ms: 2.080400286326869
  mean_raw_obs_processing_ms: 0.46772455711511596
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03135323524475098
    StateBufferConnector_ms: 0.005469799041748047
    ViewRequirementAgentConnector_ms: 0.18625187873840332
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.28
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 9.0, 6.0, 4.0, 3.0, 9.0, 5.0, 10.0, 1.0, 10.0, 5.0, 10.0,
      6.0, 7.0, 12.0, 7.0, 8.0, 2.0, 5.0, 6.0, 5.0, 7.0, 6.0, 10.0, 7.0, 5.0, 5.0,
      8.0, 6.0, 9.0, 6.0, 6.0, 7.0, 4.0, 5.0, 3.0, 0.0, 6.0, 4.0, 6.0, 3.0, 4.0, 3.0,
      6.0, 6.0, 11.0, 3.0, 3.0, 2.0, 6.0, 3.0, 5.0, 7.0, 6.0, 3.0, 10.0, 11.0, 11.0,
      3.0, 8.0, 7.0, 11.0, 12.0, 6.0, 5.0, 11.0, 7.0, 7.0, 5.0, 3.0, 8.0, 6.0, 5.0,
      3.0, 5.0, 4.0, 3.0, 3.0, 6.0, 6.0, 10.0, 3.0, 8.0, 4.0, 7.0, 8.0, 6.0, 4.0,
      8.0, 12.0, 6.0, 8.0, 4.0, 10.0, 7.0, 9.0, 8.0, 6.0, 5.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1122966734851928
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04178112413209698
    mean_inference_ms: 2.080400286326869
    mean_raw_obs_processing_ms: 0.46772455711511596
time_since_restore: 778.2314319610596
time_this_iter_s: 10.208875894546509
time_total_s: 778.2314319610596
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.074
timestamp: 1691992543
timesteps_total: 555950
training_iteration: 76
trial_id: default
train step: 77
agent_timesteps_total: 564050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031896352767944336
  StateBufferConnector_ms: 0.005677938461303711
  ViewRequirementAgentConnector_ms: 0.1901075839996338
counters:
  num_agent_steps_sampled: 564050
  num_agent_steps_trained: 547500
  num_env_steps_sampled: 564050
  num_env_steps_trained: 547500
  num_samples_added_to_queue: 564000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 11003
custom_metrics: {}
date: 2023-08-14_14-55-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.3
episode_reward_min: 1.0
episodes_this_iter: 63
episodes_total: 4407
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9865164160728455
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.230992317199707
        total_loss: 10.349119186401367
        var_gnorm: 63.83099365234375
        vf_explained_var: 0.9752079248428345
        vf_loss: 41.025386810302734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1095.0
  learner_queue:
    size_count: 1100
    size_mean: 14.8
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6370705543744901
  num_agent_steps_sampled: 564050
  num_agent_steps_trained: 547500
  num_env_steps_sampled: 564050
  num_env_steps_trained: 547500
  num_samples_added_to_queue: 564000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 11003
  timing_breakdown:
    learner_dequeue_time_ms: 0.018
    learner_grad_time_ms: 350.842
    learner_load_time_ms: 2.601
    learner_load_wait_time_ms: 2.633
iterations_since_restore: 77
node_ip: 127.0.0.1
num_agent_steps_sampled: 564050
num_agent_steps_trained: 547500
num_env_steps_sampled: 564050
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.8651481105231
num_env_steps_trained: 547500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.8584887579564
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 50.980000000000004
  ram_util_percent: 73.68666666666668
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11211220103646431
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041708010176670134
  mean_inference_ms: 2.0772673774021597
  mean_raw_obs_processing_ms: 0.467092363857261
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031896352767944336
    StateBufferConnector_ms: 0.005677938461303711
    ViewRequirementAgentConnector_ms: 0.1901075839996338
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.3
  episode_reward_min: 1.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 5.0, 11.0, 7.0, 7.0, 5.0, 3.0, 8.0, 6.0, 5.0, 3.0, 5.0,
      4.0, 3.0, 3.0, 6.0, 6.0, 10.0, 3.0, 8.0, 4.0, 7.0, 8.0, 6.0, 4.0, 8.0, 12.0,
      6.0, 8.0, 4.0, 10.0, 7.0, 9.0, 8.0, 6.0, 5.0, 8.0, 4.0, 4.0, 7.0, 8.0, 7.0,
      11.0, 10.0, 6.0, 9.0, 5.0, 6.0, 8.0, 6.0, 4.0, 4.0, 4.0, 7.0, 6.0, 6.0, 6.0,
      6.0, 8.0, 4.0, 8.0, 7.0, 4.0, 3.0, 8.0, 8.0, 5.0, 2.0, 6.0, 3.0, 1.0, 6.0, 5.0,
      7.0, 4.0, 7.0, 7.0, 10.0, 11.0, 5.0, 12.0, 7.0, 9.0, 4.0, 7.0, 8.0, 4.0, 7.0,
      8.0, 6.0, 3.0, 5.0, 8.0, 5.0, 3.0, 7.0, 7.0, 10.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11211220103646431
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041708010176670134
    mean_inference_ms: 2.0772673774021597
    mean_raw_obs_processing_ms: 0.467092363857261
time_since_restore: 788.4769999980927
time_this_iter_s: 10.245568037033081
time_total_s: 788.4769999980927
timers:
  sample_time_ms: 0.354
  synch_weights_time_ms: 0.381
  training_iteration_time_ms: 0.845
timestamp: 1691992553
timesteps_total: 564050
training_iteration: 77
trial_id: default
train step: 78
agent_timesteps_total: 571300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03410530090332031
  StateBufferConnector_ms: 0.006209135055541992
  ViewRequirementAgentConnector_ms: 0.20465826988220215
counters:
  num_agent_steps_sampled: 571300
  num_agent_steps_trained: 554500
  num_env_steps_sampled: 571300
  num_env_steps_trained: 554500
  num_samples_added_to_queue: 571000
  num_training_step_calls_since_last_synch_worker_weights: 640
  num_weight_broadcasts: 11146
custom_metrics: {}
date: 2023-08-14_14-56-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.39
episode_reward_min: 1.0
episodes_this_iter: 57
episodes_total: 4464
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.855650782585144
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -24.198707580566406
        total_loss: 16.147245407104492
        var_gnorm: 63.84139633178711
        vf_explained_var: 0.9068684577941895
        vf_loss: 89.2484130859375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1109.0
  learner_queue:
    size_count: 1115
    size_mean: 14.68
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6666133324799728
  num_agent_steps_sampled: 571300
  num_agent_steps_trained: 554500
  num_env_steps_sampled: 571300
  num_env_steps_trained: 554500
  num_samples_added_to_queue: 571000
  num_training_step_calls_since_last_synch_worker_weights: 640
  num_weight_broadcasts: 11146
  timing_breakdown:
    learner_dequeue_time_ms: 0.018
    learner_grad_time_ms: 332.546
    learner_load_time_ms: 2.426
    learner_load_wait_time_ms: 2.88
iterations_since_restore: 78
node_ip: 127.0.0.1
num_agent_steps_sampled: 571300
num_agent_steps_trained: 554500
num_env_steps_sampled: 571300
num_env_steps_sampled_this_iter: 7250
num_env_steps_sampled_throughput_per_sec: 724.993690903254
num_env_steps_trained: 554500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9939084583142
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 54.65
  ram_util_percent: 75.45714285714287
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11197523680810287
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04169255316898386
  mean_inference_ms: 2.0763492616722807
  mean_raw_obs_processing_ms: 0.46695760808048187
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03410530090332031
    StateBufferConnector_ms: 0.006209135055541992
    ViewRequirementAgentConnector_ms: 0.20465826988220215
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.39
  episode_reward_min: 1.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 8.0, 4.0, 8.0, 7.0, 4.0, 3.0, 8.0, 8.0, 5.0, 2.0, 6.0, 3.0,
      1.0, 6.0, 5.0, 7.0, 4.0, 7.0, 7.0, 10.0, 11.0, 5.0, 12.0, 7.0, 9.0, 4.0, 7.0,
      8.0, 4.0, 7.0, 8.0, 6.0, 3.0, 5.0, 8.0, 5.0, 3.0, 7.0, 7.0, 10.0, 7.0, 6.0,
      3.0, 4.0, 4.0, 4.0, 4.0, 6.0, 3.0, 4.0, 5.0, 9.0, 6.0, 3.0, 6.0, 4.0, 6.0, 5.0,
      7.0, 2.0, 6.0, 4.0, 2.0, 3.0, 2.0, 4.0, 6.0, 5.0, 6.0, 3.0, 3.0, 7.0, 3.0, 4.0,
      7.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0, 6.0, 6.0, 4.0, 7.0, 6.0, 3.0, 2.0, 7.0, 4.0,
      4.0, 7.0, 4.0, 4.0, 6.0, 4.0, 4.0, 7.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11197523680810287
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04169255316898386
    mean_inference_ms: 2.0763492616722807
    mean_raw_obs_processing_ms: 0.46695760808048187
time_since_restore: 798.7349977493286
time_this_iter_s: 10.257997751235962
time_total_s: 798.7349977493286
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1691992563
timesteps_total: 571300
training_iteration: 78
trial_id: default
train step: 79
agent_timesteps_total: 578700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0361332893371582
  StateBufferConnector_ms: 0.006482124328613281
  ViewRequirementAgentConnector_ms: 0.21094846725463867
counters:
  num_agent_steps_sampled: 578700
  num_agent_steps_trained: 562000
  num_env_steps_sampled: 578700
  num_env_steps_trained: 562000
  num_samples_added_to_queue: 578500
  num_training_step_calls_since_last_synch_worker_weights: 829
  num_weight_broadcasts: 11291
custom_metrics: {}
date: 2023-08-14_14-56-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.88
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 4521
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9932886958122253
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -31.010326385498047
        total_loss: -15.803762435913086
        var_gnorm: 63.84770202636719
        vf_explained_var: 0.9214667677879333
        vf_loss: 40.34601593017578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1124.0
  learner_queue:
    size_count: 1129
    size_mean: 14.76
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5435025105259792
  num_agent_steps_sampled: 578700
  num_agent_steps_trained: 562000
  num_env_steps_sampled: 578700
  num_env_steps_trained: 562000
  num_samples_added_to_queue: 578500
  num_training_step_calls_since_last_synch_worker_weights: 829
  num_weight_broadcasts: 11291
  timing_breakdown:
    learner_dequeue_time_ms: 0.018
    learner_grad_time_ms: 395.105
    learner_load_time_ms: 2.372
    learner_load_wait_time_ms: 3.271
iterations_since_restore: 79
node_ip: 127.0.0.1
num_agent_steps_sampled: 578700
num_agent_steps_trained: 562000
num_env_steps_sampled: 578700
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9978652062014
num_env_steps_trained: 562000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9978363576365
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.660000000000004
  ram_util_percent: 75.65333333333334
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11191373352423055
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04169544712751242
  mean_inference_ms: 2.076347855789545
  mean_raw_obs_processing_ms: 0.4670116675132857
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0361332893371582
    StateBufferConnector_ms: 0.006482124328613281
    ViewRequirementAgentConnector_ms: 0.21094846725463867
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.88
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 5.0, 7.0, 2.0, 6.0, 4.0, 2.0, 3.0, 2.0, 4.0, 6.0, 5.0, 6.0,
      3.0, 3.0, 7.0, 3.0, 4.0, 7.0, 4.0, 5.0, 4.0, 4.0, 5.0, 4.0, 6.0, 6.0, 4.0, 7.0,
      6.0, 3.0, 2.0, 7.0, 4.0, 4.0, 7.0, 4.0, 4.0, 6.0, 4.0, 4.0, 7.0, 10.0, 3.0,
      5.0, 7.0, 2.0, 6.0, 4.0, 3.0, 5.0, 6.0, 9.0, 4.0, 3.0, 10.0, 8.0, 1.0, 1.0,
      3.0, 0.0, 6.0, 4.0, 3.0, 4.0, 8.0, 7.0, 7.0, 7.0, 7.0, 3.0, 8.0, 10.0, 7.0,
      6.0, 4.0, 3.0, 4.0, 7.0, 4.0, 4.0, 2.0, 4.0, 5.0, 6.0, 2.0, 2.0, 4.0, 4.0, 5.0,
      7.0, 6.0, 7.0, 4.0, 4.0, 4.0, 9.0, 3.0, 6.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11191373352423055
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04169544712751242
    mean_inference_ms: 2.076347855789545
    mean_raw_obs_processing_ms: 0.4670116675132857
time_since_restore: 809.031229019165
time_this_iter_s: 10.296231269836426
time_total_s: 809.031229019165
timers:
  sample_time_ms: 0.037
  synch_weights_time_ms: 0.01
  training_iteration_time_ms: 0.108
timestamp: 1691992574
timesteps_total: 578700
training_iteration: 79
trial_id: default
train step: 80
agent_timesteps_total: 586050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03583812713623047
  StateBufferConnector_ms: 0.006341218948364258
  ViewRequirementAgentConnector_ms: 0.21113276481628418
counters:
  num_agent_steps_sampled: 586050
  num_agent_steps_trained: 569500
  num_env_steps_sampled: 586050
  num_env_steps_trained: 569500
  num_samples_added_to_queue: 586000
  num_training_step_calls_since_last_synch_worker_weights: 621
  num_weight_broadcasts: 11435
custom_metrics: {}
date: 2023-08-14_14-56-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 5.1
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 4579
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9211382269859314
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 4.152588844299316
        total_loss: 21.66741180419922
        var_gnorm: 63.85054016113281
        vf_explained_var: 0.949099600315094
        vf_loss: 44.241024017333984
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1139.0
  learner_queue:
    size_count: 1145
    size_mean: 14.66
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.62
  num_agent_steps_sampled: 586050
  num_agent_steps_trained: 569500
  num_env_steps_sampled: 586050
  num_env_steps_trained: 569500
  num_samples_added_to_queue: 586000
  num_training_step_calls_since_last_synch_worker_weights: 621
  num_weight_broadcasts: 11435
  timing_breakdown:
    learner_dequeue_time_ms: 0.018
    learner_grad_time_ms: 326.198
    learner_load_time_ms: 2.331
    learner_load_wait_time_ms: 2.78
iterations_since_restore: 80
node_ip: 127.0.0.1
num_agent_steps_sampled: 586050
num_agent_steps_trained: 569500
num_env_steps_sampled: 586050
num_env_steps_sampled_this_iter: 7350
num_env_steps_sampled_throughput_per_sec: 734.9944099613004
num_env_steps_trained: 569500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.994295878878
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 52.957142857142856
  ram_util_percent: 75.98571428571428
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1119364904916047
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04169275058344698
  mean_inference_ms: 2.0762118578207733
  mean_raw_obs_processing_ms: 0.4670000341699301
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03583812713623047
    StateBufferConnector_ms: 0.006341218948364258
    ViewRequirementAgentConnector_ms: 0.21113276481628418
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 5.1
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 3.0, 0.0, 6.0, 4.0, 3.0, 4.0, 8.0, 7.0, 7.0, 7.0, 7.0, 3.0,
      8.0, 10.0, 7.0, 6.0, 4.0, 3.0, 4.0, 7.0, 4.0, 4.0, 2.0, 4.0, 5.0, 6.0, 2.0,
      2.0, 4.0, 4.0, 5.0, 7.0, 6.0, 7.0, 4.0, 4.0, 4.0, 9.0, 3.0, 6.0, 5.0, 4.0, 5.0,
      3.0, 9.0, 6.0, 3.0, 3.0, 9.0, 10.0, 1.0, 6.0, 4.0, 7.0, 7.0, 7.0, 4.0, 4.0,
      4.0, 5.0, 4.0, 4.0, 4.0, 7.0, 8.0, 7.0, 3.0, 8.0, 0.0, 4.0, 2.0, 7.0, 6.0, 3.0,
      4.0, 8.0, 8.0, 1.0, 3.0, 7.0, 8.0, 5.0, 6.0, 9.0, 7.0, 3.0, 7.0, 3.0, 3.0, 6.0,
      6.0, 6.0, 2.0, 7.0, 3.0, 7.0, 6.0, 6.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1119364904916047
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04169275058344698
    mean_inference_ms: 2.0762118578207733
    mean_raw_obs_processing_ms: 0.4670000341699301
time_since_restore: 819.3259899616241
time_this_iter_s: 10.294760942459106
time_total_s: 819.3259899616241
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.088
timestamp: 1691992584
timesteps_total: 586050
training_iteration: 80
trial_id: default
train step: 81
agent_timesteps_total: 592950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0356595516204834
  StateBufferConnector_ms: 0.006416797637939453
  ViewRequirementAgentConnector_ms: 0.21336793899536133
counters:
  num_agent_steps_sampled: 592950
  num_agent_steps_trained: 576000
  num_env_steps_sampled: 592950
  num_env_steps_trained: 576000
  num_samples_added_to_queue: 592500
  num_training_step_calls_since_last_synch_worker_weights: 1177
  num_weight_broadcasts: 11570
custom_metrics: {}
date: 2023-08-14_14-56-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 5.26
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 4633
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9742390513420105
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -49.02822494506836
        total_loss: -17.45930290222168
        var_gnorm: 63.85597610473633
        vf_explained_var: 0.9432791471481323
        vf_loss: 72.88023376464844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1152.0
  learner_queue:
    size_count: 1156
    size_mean: 14.72
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6004999218994045
  num_agent_steps_sampled: 592950
  num_agent_steps_trained: 576000
  num_env_steps_sampled: 592950
  num_env_steps_trained: 576000
  num_samples_added_to_queue: 592500
  num_training_step_calls_since_last_synch_worker_weights: 1177
  num_weight_broadcasts: 11570
  timing_breakdown:
    learner_dequeue_time_ms: 0.018
    learner_grad_time_ms: 838.814
    learner_load_time_ms: 2.363
    learner_load_wait_time_ms: 14.369
iterations_since_restore: 81
node_ip: 127.0.0.1
num_agent_steps_sampled: 592950
num_agent_steps_trained: 576000
num_env_steps_sampled: 592950
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 689.9983549157264
num_env_steps_trained: 576000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9984502829307
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 57.32142857142856
  ram_util_percent: 76.8142857142857
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11192687664821444
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04171576811454239
  mean_inference_ms: 2.076915635100052
  mean_raw_obs_processing_ms: 0.46718123740709844
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0356595516204834
    StateBufferConnector_ms: 0.006416797637939453
    ViewRequirementAgentConnector_ms: 0.21336793899536133
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 5.26
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 7.0, 7.0, 4.0, 4.0, 4.0, 5.0, 4.0, 4.0, 4.0, 7.0, 8.0, 7.0,
      3.0, 8.0, 0.0, 4.0, 2.0, 7.0, 6.0, 3.0, 4.0, 8.0, 8.0, 1.0, 3.0, 7.0, 8.0, 5.0,
      6.0, 9.0, 7.0, 3.0, 7.0, 3.0, 3.0, 6.0, 6.0, 6.0, 2.0, 7.0, 3.0, 7.0, 6.0, 6.0,
      5.0, 3.0, 0.0, 5.0, 4.0, 7.0, 2.0, 6.0, 6.0, 3.0, 4.0, 5.0, 5.0, 6.0, 2.0, 6.0,
      8.0, 9.0, 5.0, 6.0, 4.0, 4.0, 4.0, 6.0, 5.0, 9.0, 6.0, 5.0, 6.0, 7.0, 7.0, 3.0,
      5.0, 8.0, 8.0, 5.0, 4.0, 4.0, 7.0, 8.0, 5.0, 3.0, 3.0, 3.0, 4.0, 5.0, 6.0, 7.0,
      8.0, 6.0, 5.0, 6.0, 8.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11192687664821444
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04171576811454239
    mean_inference_ms: 2.076915635100052
    mean_raw_obs_processing_ms: 0.46718123740709844
time_since_restore: 829.4787127971649
time_this_iter_s: 10.152722835540771
time_total_s: 829.4787127971649
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1691992594
timesteps_total: 592950
training_iteration: 81
trial_id: default
train step: 82
agent_timesteps_total: 599450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.036917924880981445
  StateBufferConnector_ms: 0.006652116775512695
  ViewRequirementAgentConnector_ms: 0.22417616844177246
counters:
  num_agent_steps_sampled: 599450
  num_agent_steps_trained: 582500
  num_env_steps_sampled: 599450
  num_env_steps_trained: 582500
  num_samples_added_to_queue: 599000
  num_training_step_calls_since_last_synch_worker_weights: 216
  num_weight_broadcasts: 11696
custom_metrics: {}
date: 2023-08-14_14-56-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 5.39
episode_reward_min: 1.0
episodes_this_iter: 50
episodes_total: 4683
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.90000000000009
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9862368106842041
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 30.678926467895508
        total_loss: 42.696407318115234
        var_gnorm: 63.86213302612305
        vf_explained_var: 0.9383984804153442
        vf_loss: 33.8973274230957
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1165.0
  learner_queue:
    size_count: 1171
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5911002482559042
  num_agent_steps_sampled: 599450
  num_agent_steps_trained: 582500
  num_env_steps_sampled: 599450
  num_env_steps_trained: 582500
  num_samples_added_to_queue: 599000
  num_training_step_calls_since_last_synch_worker_weights: 216
  num_weight_broadcasts: 11696
  timing_breakdown:
    learner_dequeue_time_ms: 0.018
    learner_grad_time_ms: 383.869
    learner_load_time_ms: 2.415
    learner_load_wait_time_ms: 3.036
iterations_since_restore: 82
node_ip: 127.0.0.1
num_agent_steps_sampled: 599450
num_agent_steps_trained: 582500
num_env_steps_sampled: 599450
num_env_steps_sampled_this_iter: 6500
num_env_steps_sampled_throughput_per_sec: 649.9986982371652
num_env_steps_trained: 582500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9986982371652
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 57.66
  ram_util_percent: 76.42666666666666
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1119520831055381
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041776539694291376
  mean_inference_ms: 2.0790835002656727
  mean_raw_obs_processing_ms: 0.4676589971976369
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.036917924880981445
    StateBufferConnector_ms: 0.006652116775512695
    ViewRequirementAgentConnector_ms: 0.22417616844177246
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 5.39
  episode_reward_min: 1.0
  episodes_this_iter: 50
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 2.0, 6.0, 6.0, 3.0, 4.0, 5.0, 5.0, 6.0, 2.0, 6.0, 8.0, 9.0,
      5.0, 6.0, 4.0, 4.0, 4.0, 6.0, 5.0, 9.0, 6.0, 5.0, 6.0, 7.0, 7.0, 3.0, 5.0, 8.0,
      8.0, 5.0, 4.0, 4.0, 7.0, 8.0, 5.0, 3.0, 3.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0, 6.0,
      5.0, 6.0, 8.0, 5.0, 4.0, 4.0, 1.0, 6.0, 4.0, 4.0, 6.0, 5.0, 8.0, 6.0, 2.0, 4.0,
      9.0, 9.0, 6.0, 4.0, 8.0, 2.0, 2.0, 6.0, 7.0, 8.0, 9.0, 4.0, 5.0, 7.0, 4.0, 8.0,
      6.0, 4.0, 5.0, 3.0, 6.0, 5.0, 8.0, 7.0, 7.0, 3.0, 4.0, 7.0, 2.0, 5.0, 9.0, 7.0,
      4.0, 5.0, 6.0, 4.0, 3.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1119520831055381
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041776539694291376
    mean_inference_ms: 2.0790835002656727
    mean_raw_obs_processing_ms: 0.4676589971976369
time_since_restore: 839.7450587749481
time_this_iter_s: 10.266345977783203
time_total_s: 839.7450587749481
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1691992604
timesteps_total: 599450
training_iteration: 82
trial_id: default
train step: 83
agent_timesteps_total: 606050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03856015205383301
  StateBufferConnector_ms: 0.006913185119628906
  ViewRequirementAgentConnector_ms: 0.22960305213928223
counters:
  num_agent_steps_sampled: 606050
  num_agent_steps_trained: 589500
  num_env_steps_sampled: 606050
  num_env_steps_trained: 589500
  num_samples_added_to_queue: 606000
  num_training_step_calls_since_last_synch_worker_weights: 256
  num_weight_broadcasts: 11825
custom_metrics: {}
date: 2023-08-14_14-56-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.56
episode_reward_min: 2.0
episodes_this_iter: 52
episodes_total: 4735
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8804084062576294
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.655355453491211
        total_loss: 10.691247940063477
        var_gnorm: 63.86872863769531
        vf_explained_var: 0.9513742923736572
        vf_loss: 24.875869750976562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1179.0
  learner_queue:
    size_count: 1184
    size_mean: 14.74
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5976232346833217
  num_agent_steps_sampled: 606050
  num_agent_steps_trained: 589500
  num_env_steps_sampled: 606050
  num_env_steps_trained: 589500
  num_samples_added_to_queue: 606000
  num_training_step_calls_since_last_synch_worker_weights: 256
  num_weight_broadcasts: 11825
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 467.463
    learner_load_time_ms: 2.415
    learner_load_wait_time_ms: 2.783
iterations_since_restore: 83
node_ip: 127.0.0.1
num_agent_steps_sampled: 606050
num_agent_steps_trained: 589500
num_env_steps_sampled: 606050
num_env_steps_sampled_this_iter: 6600
num_env_steps_sampled_throughput_per_sec: 659.9953108167023
num_env_steps_trained: 589500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9950266237752
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 57.6
  ram_util_percent: 75.57142857142857
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1120883596549602
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041856060124097726
  mean_inference_ms: 2.081865548593774
  mean_raw_obs_processing_ms: 0.46826814878029505
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03856015205383301
    StateBufferConnector_ms: 0.006913185119628906
    ViewRequirementAgentConnector_ms: 0.22960305213928223
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.56
  episode_reward_min: 2.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 4.0, 4.0, 6.0, 5.0, 8.0, 6.0, 2.0, 4.0, 9.0, 9.0, 6.0, 4.0,
      8.0, 2.0, 2.0, 6.0, 7.0, 8.0, 9.0, 4.0, 5.0, 7.0, 4.0, 8.0, 6.0, 4.0, 5.0, 3.0,
      6.0, 5.0, 8.0, 7.0, 7.0, 3.0, 4.0, 7.0, 2.0, 5.0, 9.0, 7.0, 4.0, 5.0, 6.0, 4.0,
      3.0, 3.0, 5.0, 3.0, 5.0, 4.0, 8.0, 4.0, 8.0, 6.0, 5.0, 4.0, 9.0, 6.0, 6.0, 4.0,
      8.0, 4.0, 4.0, 9.0, 4.0, 3.0, 3.0, 6.0, 3.0, 4.0, 5.0, 7.0, 6.0, 3.0, 9.0, 7.0,
      9.0, 7.0, 11.0, 5.0, 5.0, 5.0, 6.0, 3.0, 12.0, 3.0, 2.0, 7.0, 5.0, 6.0, 9.0,
      3.0, 5.0, 6.0, 3.0, 5.0, 10.0, 7.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1120883596549602
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041856060124097726
    mean_inference_ms: 2.081865548593774
    mean_raw_obs_processing_ms: 0.46826814878029505
time_since_restore: 849.9881076812744
time_this_iter_s: 10.243048906326294
time_total_s: 849.9881076812744
timers:
  sample_time_ms: 0.034
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.093
timestamp: 1691992615
timesteps_total: 606050
training_iteration: 83
trial_id: default
train step: 84
agent_timesteps_total: 610850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04543924331665039
  StateBufferConnector_ms: 0.008216381072998047
  ViewRequirementAgentConnector_ms: 0.2607731819152832
counters:
  num_agent_steps_sampled: 610850
  num_agent_steps_trained: 594000
  num_env_steps_sampled: 610850
  num_env_steps_trained: 594000
  num_samples_added_to_queue: 610500
  num_training_step_calls_since_last_synch_worker_weights: 1046
  num_weight_broadcasts: 11918
custom_metrics: {}
date: 2023-08-14_14-57-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.51
episode_reward_min: 1.0
episodes_this_iter: 38
episodes_total: 4773
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.92603999376297
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.44588851928711
        total_loss: 8.022136688232422
        var_gnorm: 63.872222900390625
        vf_explained_var: 0.9243717193603516
        vf_loss: 42.196449279785156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1188.0
  learner_queue:
    size_count: 1193
    size_mean: 14.48
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.6880758276807353
  num_agent_steps_sampled: 610850
  num_agent_steps_trained: 594000
  num_env_steps_sampled: 610850
  num_env_steps_trained: 594000
  num_samples_added_to_queue: 610500
  num_training_step_calls_since_last_synch_worker_weights: 1046
  num_weight_broadcasts: 11918
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 966.054
    learner_load_time_ms: 2.415
    learner_load_wait_time_ms: 66.325
iterations_since_restore: 84
node_ip: 127.0.0.1
num_agent_steps_sampled: 610850
num_agent_steps_trained: 594000
num_env_steps_sampled: 610850
num_env_steps_sampled_this_iter: 4800
num_env_steps_sampled_throughput_per_sec: 479.9984092765119
num_env_steps_trained: 594000
num_env_steps_trained_this_iter: 4500
num_env_steps_trained_throughput_per_sec: 449.9985086967299
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 4500
perf:
  cpu_util_percent: 67.79333333333332
  ram_util_percent: 76.14000000000003
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11243516198298115
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041965162483866475
  mean_inference_ms: 2.0860600284340847
  mean_raw_obs_processing_ms: 0.4691195374192228
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04543924331665039
    StateBufferConnector_ms: 0.008216381072998047
    ViewRequirementAgentConnector_ms: 0.2607731819152832
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.51
  episode_reward_min: 1.0
  episodes_this_iter: 38
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 9.0, 7.0, 4.0, 5.0, 6.0, 4.0, 3.0, 3.0, 5.0, 3.0, 5.0, 4.0,
      8.0, 4.0, 8.0, 6.0, 5.0, 4.0, 9.0, 6.0, 6.0, 4.0, 8.0, 4.0, 4.0, 9.0, 4.0, 3.0,
      3.0, 6.0, 3.0, 4.0, 5.0, 7.0, 6.0, 3.0, 9.0, 7.0, 9.0, 7.0, 11.0, 5.0, 5.0,
      5.0, 6.0, 3.0, 12.0, 3.0, 2.0, 7.0, 5.0, 6.0, 9.0, 3.0, 5.0, 6.0, 3.0, 5.0,
      10.0, 7.0, 4.0, 5.0, 8.0, 3.0, 5.0, 5.0, 4.0, 7.0, 9.0, 2.0, 4.0, 2.0, 2.0,
      1.0, 9.0, 3.0, 8.0, 8.0, 6.0, 7.0, 8.0, 7.0, 7.0, 4.0, 6.0, 3.0, 5.0, 9.0, 8.0,
      8.0, 8.0, 2.0, 3.0, 8.0, 2.0, 3.0, 9.0, 2.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11243516198298115
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041965162483866475
    mean_inference_ms: 2.0860600284340847
    mean_raw_obs_processing_ms: 0.4691195374192228
time_since_restore: 860.2822616100311
time_this_iter_s: 10.294153928756714
time_total_s: 860.2822616100311
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.108
timestamp: 1691992625
timesteps_total: 610850
training_iteration: 84
trial_id: default
train step: 85
agent_timesteps_total: 616650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04994368553161621
  StateBufferConnector_ms: 0.009014368057250977
  ViewRequirementAgentConnector_ms: 0.28966474533081055
counters:
  num_agent_steps_sampled: 616650
  num_agent_steps_trained: 600000
  num_env_steps_sampled: 616650
  num_env_steps_trained: 600000
  num_samples_added_to_queue: 616500
  num_training_step_calls_since_last_synch_worker_weights: 1313
  num_weight_broadcasts: 12031
custom_metrics: {}
date: 2023-08-14_14-57-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.24
episode_reward_min: 1.0
episodes_this_iter: 45
episodes_total: 4818
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 29.799999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0817748308181763
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 29.82777214050293
        total_loss: 51.38494110107422
        var_gnorm: 63.87926483154297
        vf_explained_var: 0.9170903563499451
        vf_loss: 53.93208312988281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1200.0
  learner_queue:
    size_count: 1204
    size_mean: 14.54
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.6273905493150682
  num_agent_steps_sampled: 616650
  num_agent_steps_trained: 600000
  num_env_steps_sampled: 616650
  num_env_steps_trained: 600000
  num_samples_added_to_queue: 616500
  num_training_step_calls_since_last_synch_worker_weights: 1313
  num_weight_broadcasts: 12031
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 1015.0
    learner_load_time_ms: 2.435
    learner_load_wait_time_ms: 4.131
iterations_since_restore: 85
node_ip: 127.0.0.1
num_agent_steps_sampled: 616650
num_agent_steps_trained: 600000
num_env_steps_sampled: 616650
num_env_steps_sampled_this_iter: 5800
num_env_steps_sampled_throughput_per_sec: 579.9984235806396
num_env_steps_trained: 600000
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9983692213514
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 62.44285714285716
  ram_util_percent: 76.21428571428571
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11289647559639285
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04212265088064091
  mean_inference_ms: 2.0924370648199524
  mean_raw_obs_processing_ms: 0.47040875268337606
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04994368553161621
    StateBufferConnector_ms: 0.009014368057250977
    ViewRequirementAgentConnector_ms: 0.28966474533081055
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.24
  episode_reward_min: 1.0
  episodes_this_iter: 45
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 3.0, 12.0, 3.0, 2.0, 7.0, 5.0, 6.0, 9.0, 3.0, 5.0, 6.0,
      3.0, 5.0, 10.0, 7.0, 4.0, 5.0, 8.0, 3.0, 5.0, 5.0, 4.0, 7.0, 9.0, 2.0, 4.0,
      2.0, 2.0, 1.0, 9.0, 3.0, 8.0, 8.0, 6.0, 7.0, 8.0, 7.0, 7.0, 4.0, 6.0, 3.0, 5.0,
      9.0, 8.0, 8.0, 8.0, 2.0, 3.0, 8.0, 2.0, 3.0, 9.0, 2.0, 5.0, 5.0, 5.0, 4.0, 4.0,
      6.0, 5.0, 5.0, 4.0, 6.0, 3.0, 7.0, 6.0, 7.0, 7.0, 1.0, 7.0, 5.0, 5.0, 2.0, 5.0,
      3.0, 6.0, 3.0, 1.0, 4.0, 5.0, 4.0, 2.0, 7.0, 9.0, 7.0, 4.0, 6.0, 4.0, 5.0, 5.0,
      7.0, 7.0, 5.0, 6.0, 6.0, 6.0, 2.0, 5.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11289647559639285
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04212265088064091
    mean_inference_ms: 2.0924370648199524
    mean_raw_obs_processing_ms: 0.47040875268337606
time_since_restore: 870.4954288005829
time_this_iter_s: 10.213167190551758
time_total_s: 870.4954288005829
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.088
timestamp: 1691992635
timesteps_total: 616650
training_iteration: 85
trial_id: default
train step: 86
agent_timesteps_total: 623100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04571223258972168
  StateBufferConnector_ms: 0.008058786392211914
  ViewRequirementAgentConnector_ms: 0.2823367118835449
counters:
  num_agent_steps_sampled: 623100
  num_agent_steps_trained: 606500
  num_env_steps_sampled: 623100
  num_env_steps_trained: 606500
  num_samples_added_to_queue: 623000
  num_training_step_calls_since_last_synch_worker_weights: 199
  num_weight_broadcasts: 12157
custom_metrics: {}
date: 2023-08-14_14-57-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.03
episode_reward_min: 1.0
episodes_this_iter: 50
episodes_total: 4868
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 30.799999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1062114238739014
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.3863601684570312
        total_loss: 21.014402389526367
        var_gnorm: 63.88859558105469
        vf_explained_var: 0.9236689209938049
        vf_loss: 48.318199157714844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1213.0
  learner_queue:
    size_count: 1219
    size_mean: 14.44
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7223240113288791
  num_agent_steps_sampled: 623100
  num_agent_steps_trained: 606500
  num_env_steps_sampled: 623100
  num_env_steps_trained: 606500
  num_samples_added_to_queue: 623000
  num_training_step_calls_since_last_synch_worker_weights: 199
  num_weight_broadcasts: 12157
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 365.89
    learner_load_time_ms: 2.477
    learner_load_wait_time_ms: 2.643
iterations_since_restore: 86
node_ip: 127.0.0.1
num_agent_steps_sampled: 623100
num_agent_steps_trained: 606500
num_env_steps_sampled: 623100
num_env_steps_sampled_this_iter: 6450
num_env_steps_sampled_throughput_per_sec: 644.997293483647
num_env_steps_trained: 606500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9972725029002
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 57.88666666666667
  ram_util_percent: 76.00666666666666
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11306355014770883
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04226234171027958
  mean_inference_ms: 2.097866005404729
  mean_raw_obs_processing_ms: 0.4715973929027035
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04571223258972168
    StateBufferConnector_ms: 0.008058786392211914
    ViewRequirementAgentConnector_ms: 0.2823367118835449
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.03
  episode_reward_min: 1.0
  episodes_this_iter: 50
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 9.0, 2.0, 5.0, 5.0, 5.0, 4.0, 4.0, 6.0, 5.0, 5.0, 4.0,
      6.0, 3.0, 7.0, 6.0, 7.0, 7.0, 1.0, 7.0, 5.0, 5.0, 2.0, 5.0, 3.0, 6.0, 3.0, 1.0,
      4.0, 5.0, 4.0, 2.0, 7.0, 9.0, 7.0, 4.0, 6.0, 4.0, 5.0, 5.0, 7.0, 7.0, 5.0, 6.0,
      6.0, 6.0, 2.0, 5.0, 5.0, 8.0, 9.0, 8.0, 7.0, 4.0, 6.0, 5.0, 7.0, 10.0, 5.0,
      8.0, 6.0, 8.0, 6.0, 5.0, 12.0, 9.0, 6.0, 3.0, 6.0, 8.0, 5.0, 8.0, 8.0, 8.0,
      10.0, 7.0, 7.0, 9.0, 10.0, 4.0, 3.0, 8.0, 9.0, 5.0, 9.0, 11.0, 4.0, 10.0, 9.0,
      7.0, 7.0, 10.0, 6.0, 8.0, 3.0, 7.0, 5.0, 6.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11306355014770883
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04226234171027958
    mean_inference_ms: 2.097866005404729
    mean_raw_obs_processing_ms: 0.4715973929027035
time_since_restore: 880.7503616809845
time_this_iter_s: 10.254932880401611
time_total_s: 880.7503616809845
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1691992645
timesteps_total: 623100
training_iteration: 86
trial_id: default
train step: 87
agent_timesteps_total: 630250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0399632453918457
  StateBufferConnector_ms: 0.007160186767578125
  ViewRequirementAgentConnector_ms: 0.24656367301940918
counters:
  num_agent_steps_sampled: 630250
  num_agent_steps_trained: 613500
  num_env_steps_sampled: 630250
  num_env_steps_trained: 613500
  num_samples_added_to_queue: 630000
  num_training_step_calls_since_last_synch_worker_weights: 320
  num_weight_broadcasts: 12297
custom_metrics: {}
date: 2023-08-14_14-57-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.73
episode_reward_min: 2.0
episodes_this_iter: 56
episodes_total: 4924
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8817234635353088
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 19.640838623046875
        total_loss: 42.752708435058594
        var_gnorm: 63.8989143371582
        vf_explained_var: 0.9428996443748474
        vf_loss: 55.04096984863281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1227.0
  learner_queue:
    size_count: 1233
    size_mean: 14.38
    size_quantiles: [11.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.776400855662933
  num_agent_steps_sampled: 630250
  num_agent_steps_trained: 613500
  num_env_steps_sampled: 630250
  num_env_steps_trained: 613500
  num_samples_added_to_queue: 630000
  num_training_step_calls_since_last_synch_worker_weights: 320
  num_weight_broadcasts: 12297
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 344.876
    learner_load_time_ms: 2.434
    learner_load_wait_time_ms: 2.646
iterations_since_restore: 87
node_ip: 127.0.0.1
num_agent_steps_sampled: 630250
num_agent_steps_trained: 613500
num_env_steps_sampled: 630250
num_env_steps_sampled_this_iter: 7150
num_env_steps_sampled_throughput_per_sec: 714.9987044357887
num_env_steps_trained: 613500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9987316154575
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 55.471428571428575
  ram_util_percent: 75.68571428571428
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11317716580142999
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04231783976698698
  mean_inference_ms: 2.099519876075952
  mean_raw_obs_processing_ms: 0.47198086733895755
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0399632453918457
    StateBufferConnector_ms: 0.007160186767578125
    ViewRequirementAgentConnector_ms: 0.24656367301940918
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.73
  episode_reward_min: 2.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 7.0, 10.0, 5.0, 8.0, 6.0, 8.0, 6.0, 5.0, 12.0, 9.0, 6.0,
      3.0, 6.0, 8.0, 5.0, 8.0, 8.0, 8.0, 10.0, 7.0, 7.0, 9.0, 10.0, 4.0, 3.0, 8.0,
      9.0, 5.0, 9.0, 11.0, 4.0, 10.0, 9.0, 7.0, 7.0, 10.0, 6.0, 8.0, 3.0, 7.0, 5.0,
      6.0, 10.0, 8.0, 9.0, 7.0, 7.0, 9.0, 9.0, 2.0, 4.0, 8.0, 12.0, 8.0, 6.0, 6.0,
      5.0, 8.0, 11.0, 10.0, 7.0, 3.0, 2.0, 4.0, 10.0, 2.0, 4.0, 10.0, 3.0, 4.0, 4.0,
      6.0, 11.0, 7.0, 8.0, 4.0, 6.0, 9.0, 7.0, 9.0, 9.0, 4.0, 4.0, 5.0, 3.0, 7.0,
      4.0, 8.0, 8.0, 6.0, 3.0, 5.0, 4.0, 5.0, 6.0, 7.0, 7.0, 2.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11317716580142999
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04231783976698698
    mean_inference_ms: 2.099519876075952
    mean_raw_obs_processing_ms: 0.47198086733895755
time_since_restore: 890.9712913036346
time_this_iter_s: 10.220929622650146
time_total_s: 890.9712913036346
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1691992656
timesteps_total: 630250
training_iteration: 87
trial_id: default
train step: 88
agent_timesteps_total: 638450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033675432205200195
  StateBufferConnector_ms: 0.005823850631713867
  ViewRequirementAgentConnector_ms: 0.1981971263885498
counters:
  num_agent_steps_sampled: 638450
  num_agent_steps_trained: 621500
  num_env_steps_sampled: 638450
  num_env_steps_trained: 621500
  num_samples_added_to_queue: 638000
  num_training_step_calls_since_last_synch_worker_weights: 1210
  num_weight_broadcasts: 12457
custom_metrics: {}
date: 2023-08-14_14-57-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.25
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 4988
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.2896248996257782
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.429911613464355
        total_loss: 7.751795291900635
        var_gnorm: 63.915897369384766
        vf_explained_var: 0.9175112247467041
        vf_loss: 47.25966262817383
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1243.0
  learner_queue:
    size_count: 1247
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6283734215467902
  num_agent_steps_sampled: 638450
  num_agent_steps_trained: 621500
  num_env_steps_sampled: 638450
  num_env_steps_trained: 621500
  num_samples_added_to_queue: 638000
  num_training_step_calls_since_last_synch_worker_weights: 1210
  num_weight_broadcasts: 12457
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 449.833
    learner_load_time_ms: 2.434
    learner_load_wait_time_ms: 2.746
iterations_since_restore: 88
node_ip: 127.0.0.1
num_agent_steps_sampled: 638450
num_agent_steps_trained: 621500
num_env_steps_sampled: 638450
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9951710985359
num_env_steps_trained: 621500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9952888766205
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.31333333333334
  ram_util_percent: 75.78666666666665
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11324976468102829
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04225948738770022
  mean_inference_ms: 2.0972629337661544
  mean_raw_obs_processing_ms: 0.47150507740235503
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033675432205200195
    StateBufferConnector_ms: 0.005823850631713867
    ViewRequirementAgentConnector_ms: 0.1981971263885498
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.25
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 10.0, 2.0, 4.0, 10.0, 3.0, 4.0, 4.0, 6.0, 11.0, 7.0, 8.0,
      4.0, 6.0, 9.0, 7.0, 9.0, 9.0, 4.0, 4.0, 5.0, 3.0, 7.0, 4.0, 8.0, 8.0, 6.0, 3.0,
      5.0, 4.0, 5.0, 6.0, 7.0, 7.0, 2.0, 10.0, 10.0, 2.0, 5.0, 5.0, 6.0, 7.0, 6.0,
      1.0, 5.0, 4.0, 4.0, 3.0, 2.0, 4.0, 3.0, 5.0, 1.0, 2.0, 2.0, 4.0, 3.0, 0.0, 0.0,
      3.0, 2.0, 7.0, 0.0, 4.0, 0.0, 2.0, 0.0, 6.0, 4.0, 7.0, 3.0, 4.0, 4.0, 1.0, 2.0,
      4.0, 4.0, 3.0, 9.0, 2.0, 4.0, 6.0, 4.0, 3.0, 4.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0,
      6.0, 3.0, 2.0, 0.0, 0.0, 6.0, 3.0, 0.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11324976468102829
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04225948738770022
    mean_inference_ms: 2.0972629337661544
    mean_raw_obs_processing_ms: 0.47150507740235503
time_since_restore: 901.1339023113251
time_this_iter_s: 10.16261100769043
time_total_s: 901.1339023113251
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.086
timestamp: 1691992666
timesteps_total: 638450
training_iteration: 88
trial_id: default
train step: 89
agent_timesteps_total: 645850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034531354904174805
  StateBufferConnector_ms: 0.005878925323486328
  ViewRequirementAgentConnector_ms: 0.20033860206604004
counters:
  num_agent_steps_sampled: 645850
  num_agent_steps_trained: 629000
  num_env_steps_sampled: 645850
  num_env_steps_trained: 629000
  num_samples_added_to_queue: 645500
  num_training_step_calls_since_last_synch_worker_weights: 1085
  num_weight_broadcasts: 12602
custom_metrics: {}
date: 2023-08-14_14-57-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 1.64
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 5046
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.29080072045326233
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -12.54767894744873
        total_loss: 2.7982842922210693
        var_gnorm: 63.934024810791016
        vf_explained_var: 0.9464501142501831
        vf_loss: 33.59993362426758
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1258.0
  learner_queue:
    size_count: 1264
    size_mean: 14.62
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.730780170905595
  num_agent_steps_sampled: 645850
  num_agent_steps_trained: 629000
  num_env_steps_sampled: 645850
  num_env_steps_trained: 629000
  num_samples_added_to_queue: 645500
  num_training_step_calls_since_last_synch_worker_weights: 1085
  num_weight_broadcasts: 12602
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 394.301
    learner_load_time_ms: 3.029
    learner_load_wait_time_ms: 2.556
iterations_since_restore: 89
node_ip: 127.0.0.1
num_agent_steps_sampled: 645850
num_agent_steps_trained: 629000
num_env_steps_sampled: 645850
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9972653490036
num_env_steps_trained: 629000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9972283942603
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.23571428571429
  ram_util_percent: 75.18571428571428
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11319737752676001
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042214812736804726
  mean_inference_ms: 2.0957583098321484
  mean_raw_obs_processing_ms: 0.47120180369406334
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034531354904174805
    StateBufferConnector_ms: 0.005878925323486328
    ViewRequirementAgentConnector_ms: 0.20033860206604004
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 1.64
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 3.0, 2.0, 7.0, 0.0, 4.0, 0.0, 2.0, 0.0, 6.0, 4.0, 7.0, 3.0,
      4.0, 4.0, 1.0, 2.0, 4.0, 4.0, 3.0, 9.0, 2.0, 4.0, 6.0, 4.0, 3.0, 4.0, 3.0, 1.0,
      2.0, 2.0, 2.0, 3.0, 6.0, 3.0, 2.0, 0.0, 0.0, 6.0, 3.0, 0.0, 1.0, 5.0, 1.0, 1.0,
      0.0, 1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 1.0,
      0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0,
      1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11319737752676001
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042214812736804726
    mean_inference_ms: 2.0957583098321484
    mean_raw_obs_processing_ms: 0.47120180369406334
time_since_restore: 911.3896942138672
time_this_iter_s: 10.255791902542114
time_total_s: 911.3896942138672
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1691992676
timesteps_total: 645850
training_iteration: 89
trial_id: default
train step: 90
agent_timesteps_total: 653550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03543806076049805
  StateBufferConnector_ms: 0.006154537200927734
  ViewRequirementAgentConnector_ms: 0.2070176601409912
counters:
  num_agent_steps_sampled: 653550
  num_agent_steps_trained: 637000
  num_env_steps_sampled: 653550
  num_env_steps_trained: 637000
  num_samples_added_to_queue: 653500
  num_training_step_calls_since_last_synch_worker_weights: 747
  num_weight_broadcasts: 12753
custom_metrics: {}
date: 2023-08-14_14-58-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 1.08
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 5106
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5908675789833069
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 90.65794372558594
        total_loss: 170.20352172851562
        var_gnorm: 63.947731018066406
        vf_explained_var: 0.7498669624328613
        vf_loss: 164.99981689453125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1274.0
  learner_queue:
    size_count: 1278
    size_mean: 14.88
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5315351775261319
  num_agent_steps_sampled: 653550
  num_agent_steps_trained: 637000
  num_env_steps_sampled: 653550
  num_env_steps_trained: 637000
  num_samples_added_to_queue: 653500
  num_training_step_calls_since_last_synch_worker_weights: 747
  num_weight_broadcasts: 12753
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 381.953
    learner_load_time_ms: 3.029
    learner_load_wait_time_ms: 2.782
iterations_since_restore: 90
node_ip: 127.0.0.1
num_agent_steps_sampled: 653550
num_agent_steps_trained: 637000
num_env_steps_sampled: 653550
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 769.9969158296142
num_env_steps_trained: 637000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9967956671317
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 53.778571428571425
  ram_util_percent: 75.22142857142856
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11308688151899889
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04217839038745442
  mean_inference_ms: 2.0946364693523147
  mean_raw_obs_processing_ms: 0.47099740532786216
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03543806076049805
    StateBufferConnector_ms: 0.006154537200927734
    ViewRequirementAgentConnector_ms: 0.2070176601409912
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 1.08
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0,
      0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0,
      1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 3.0, 1.0, 2.0, 1.0, 0.0, 1.0, 1.0,
      1.0, 0.0, 0.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 5.0, 2.0, 2.0, 3.0, 2.0,
      1.0, 6.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0,
      1.0, 2.0, 1.0, 0.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 0.0,
      0.0, 8.0, 3.0, 3.0, 3.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11308688151899889
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04217839038745442
    mean_inference_ms: 2.0946364693523147
    mean_raw_obs_processing_ms: 0.47099740532786216
time_since_restore: 921.5559992790222
time_this_iter_s: 10.16630506515503
time_total_s: 921.5559992790222
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1691992686
timesteps_total: 653550
training_iteration: 90
trial_id: default
train step: 91
agent_timesteps_total: 661850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031699419021606445
  StateBufferConnector_ms: 0.005540370941162109
  ViewRequirementAgentConnector_ms: 0.19026827812194824
counters:
  num_agent_steps_sampled: 661850
  num_agent_steps_trained: 645000
  num_env_steps_sampled: 661850
  num_env_steps_trained: 645000
  num_samples_added_to_queue: 661500
  num_training_step_calls_since_last_synch_worker_weights: 475
  num_weight_broadcasts: 12916
custom_metrics: {}
date: 2023-08-14_14-58-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.28
episode_reward_min: 0.0
episodes_this_iter: 66
episodes_total: 5172
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0679428577423096
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.4228617548942566
        total_loss: 0.4330892562866211
        var_gnorm: 63.95174789428711
        vf_explained_var: 0.973296582698822
        vf_loss: 12.391329765319824
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1290.0
  learner_queue:
    size_count: 1296
    size_mean: 14.98
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5031965939290843
  num_agent_steps_sampled: 661850
  num_agent_steps_trained: 645000
  num_env_steps_sampled: 661850
  num_env_steps_trained: 645000
  num_samples_added_to_queue: 661500
  num_training_step_calls_since_last_synch_worker_weights: 475
  num_weight_broadcasts: 12916
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 303.205
    learner_load_time_ms: 3.281
    learner_load_wait_time_ms: 2.339
iterations_since_restore: 91
node_ip: 127.0.0.1
num_agent_steps_sampled: 661850
num_agent_steps_trained: 645000
num_env_steps_sampled: 661850
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9968536019392
num_env_steps_trained: 645000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9969673271703
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 49.93333333333333
  ram_util_percent: 75.14
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1130341094221069
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042094934144170516
  mean_inference_ms: 2.091648790999674
  mean_raw_obs_processing_ms: 0.47037756763503524
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031699419021606445
    StateBufferConnector_ms: 0.005540370941162109
    ViewRequirementAgentConnector_ms: 0.19026827812194824
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.28
  episode_reward_min: 0.0
  episodes_this_iter: 66
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 2.0,
      1.0, 0.0, 3.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 0.0, 0.0, 8.0,
      3.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 0.0, 4.0,
      1.0, 2.0, 3.0, 2.0, 6.0, 2.0, 1.0, 2.0, 2.0, 5.0, 3.0, 1.0, 1.0, 4.0, 2.0, 2.0,
      9.0, 4.0, 2.0, 5.0, 3.0, 4.0, 2.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 4.0, 1.0, 1.0,
      3.0, 2.0, 1.0, 2.0, 0.0, 4.0, 2.0, 2.0, 4.0, 5.0, 3.0, 5.0, 0.0, 0.0, 3.0, 6.0,
      3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1130341094221069
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042094934144170516
    mean_inference_ms: 2.091648790999674
    mean_raw_obs_processing_ms: 0.47037756763503524
time_since_restore: 931.7710523605347
time_this_iter_s: 10.215053081512451
time_total_s: 931.7710523605347
timers:
  sample_time_ms: 0.032
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.09
timestamp: 1691992697
timesteps_total: 661850
training_iteration: 91
trial_id: default
train step: 92
agent_timesteps_total: 669250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03339815139770508
  StateBufferConnector_ms: 0.0058362483978271484
  ViewRequirementAgentConnector_ms: 0.19965124130249023
counters:
  num_agent_steps_sampled: 669250
  num_agent_steps_trained: 652500
  num_env_steps_sampled: 669250
  num_env_steps_trained: 652500
  num_samples_added_to_queue: 669000
  num_training_step_calls_since_last_synch_worker_weights: 140
  num_weight_broadcasts: 13061
custom_metrics: {}
date: 2023-08-14_14-58-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.91
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 5230
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0558862686157227
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.18610477447509766
        total_loss: 5.911544322967529
        var_gnorm: 63.951568603515625
        vf_explained_var: 0.9237342476844788
        vf_loss: 22.009740829467773
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1305.0
  learner_queue:
    size_count: 1311
    size_mean: 14.74
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6469365500832145
  num_agent_steps_sampled: 669250
  num_agent_steps_trained: 652500
  num_env_steps_sampled: 669250
  num_env_steps_trained: 652500
  num_samples_added_to_queue: 669000
  num_training_step_calls_since_last_synch_worker_weights: 140
  num_weight_broadcasts: 13061
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 357.156
    learner_load_time_ms: 3.281
    learner_load_wait_time_ms: 2.753
iterations_since_restore: 92
node_ip: 127.0.0.1
num_agent_steps_sampled: 669250
num_agent_steps_trained: 652500
num_env_steps_sampled: 669250
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9943190057106
num_env_steps_trained: 652500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9942422355175
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.11428571428572
  ram_util_percent: 75.04285714285713
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1129418150395518
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0420624942934539
  mean_inference_ms: 2.0902875798407403
  mean_raw_obs_processing_ms: 0.4701418361650436
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03339815139770508
    StateBufferConnector_ms: 0.0058362483978271484
    ViewRequirementAgentConnector_ms: 0.19965124130249023
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.91
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 2.0, 2.0, 9.0, 4.0, 2.0, 5.0, 3.0, 4.0, 2.0, 0.0, 3.0, 4.0,
      1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 0.0, 4.0, 2.0, 2.0, 4.0, 5.0,
      3.0, 5.0, 0.0, 0.0, 3.0, 6.0, 3.0, 4.0, 2.0, 5.0, 3.0, 6.0, 3.0, 7.0, 6.0, 4.0,
      6.0, 0.0, 4.0, 2.0, 8.0, 3.0, 2.0, 5.0, 3.0, 6.0, 3.0, 3.0, 5.0, 5.0, 9.0, 5.0,
      1.0, 5.0, 6.0, 4.0, 7.0, 3.0, 6.0, 5.0, 5.0, 3.0, 4.0, 2.0, 3.0, 6.0, 5.0, 6.0,
      7.0, 4.0, 1.0, 8.0, 3.0, 2.0, 6.0, 8.0, 3.0, 5.0, 6.0, 6.0, 4.0, 9.0, 4.0, 1.0,
      6.0, 4.0, 5.0, 5.0, 4.0, 6.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1129418150395518
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0420624942934539
    mean_inference_ms: 2.0902875798407403
    mean_raw_obs_processing_ms: 0.4701418361650436
time_since_restore: 942.0321321487427
time_this_iter_s: 10.261079788208008
time_total_s: 942.0321321487427
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1691992707
timesteps_total: 669250
training_iteration: 92
trial_id: default
train step: 93
agent_timesteps_total: 675650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03812742233276367
  StateBufferConnector_ms: 0.006865262985229492
  ViewRequirementAgentConnector_ms: 0.2268526554107666
counters:
  num_agent_steps_sampled: 675650
  num_agent_steps_trained: 659000
  num_env_steps_sampled: 675650
  num_env_steps_trained: 659000
  num_samples_added_to_queue: 675500
  num_training_step_calls_since_last_synch_worker_weights: 99
  num_weight_broadcasts: 13185
custom_metrics: {}
date: 2023-08-14_14-58-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.71
episode_reward_min: 1.0
episodes_this_iter: 50
episodes_total: 5280
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9003618955612183
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 4.225708961486816
        total_loss: 21.748077392578125
        var_gnorm: 63.952274322509766
        vf_explained_var: 0.923629641532898
        vf_loss: 44.0483512878418
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1318.0
  learner_queue:
    size_count: 1324
    size_mean: 14.62
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.683923988783342
  num_agent_steps_sampled: 675650
  num_agent_steps_trained: 659000
  num_env_steps_sampled: 675650
  num_env_steps_trained: 659000
  num_samples_added_to_queue: 675500
  num_training_step_calls_since_last_synch_worker_weights: 99
  num_weight_broadcasts: 13185
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 589.6
    learner_load_time_ms: 3.406
    learner_load_wait_time_ms: 3.079
iterations_since_restore: 93
node_ip: 127.0.0.1
num_agent_steps_sampled: 675650
num_agent_steps_trained: 659000
num_env_steps_sampled: 675650
num_env_steps_sampled_this_iter: 6400
num_env_steps_sampled_throughput_per_sec: 639.9937134406581
num_env_steps_trained: 659000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9936152131685
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 59.52
  ram_util_percent: 75.7
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11283412800019602
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04210841255616252
  mean_inference_ms: 2.091782689964335
  mean_raw_obs_processing_ms: 0.47053128424745644
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03812742233276367
    StateBufferConnector_ms: 0.006865262985229492
    ViewRequirementAgentConnector_ms: 0.2268526554107666
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.71
  episode_reward_min: 1.0
  episodes_this_iter: 50
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 5.0, 3.0, 6.0, 3.0, 3.0, 5.0, 5.0, 9.0, 5.0, 1.0, 5.0,
      6.0, 4.0, 7.0, 3.0, 6.0, 5.0, 5.0, 3.0, 4.0, 2.0, 3.0, 6.0, 5.0, 6.0, 7.0, 4.0,
      1.0, 8.0, 3.0, 2.0, 6.0, 8.0, 3.0, 5.0, 6.0, 6.0, 4.0, 9.0, 4.0, 1.0, 6.0, 4.0,
      5.0, 5.0, 4.0, 6.0, 5.0, 4.0, 5.0, 2.0, 4.0, 4.0, 6.0, 5.0, 7.0, 2.0, 1.0, 5.0,
      5.0, 4.0, 7.0, 5.0, 3.0, 3.0, 3.0, 6.0, 1.0, 7.0, 6.0, 5.0, 4.0, 4.0, 5.0, 6.0,
      5.0, 5.0, 7.0, 6.0, 3.0, 3.0, 6.0, 4.0, 2.0, 5.0, 1.0, 8.0, 6.0, 2.0, 4.0, 12.0,
      10.0, 4.0, 5.0, 5.0, 6.0, 3.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11283412800019602
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04210841255616252
    mean_inference_ms: 2.091782689964335
    mean_raw_obs_processing_ms: 0.47053128424745644
time_since_restore: 952.3576233386993
time_this_iter_s: 10.325491189956665
time_total_s: 952.3576233386993
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.09
timestamp: 1691992717
timesteps_total: 675650
training_iteration: 93
trial_id: default
train step: 94
agent_timesteps_total: 681000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.047492265701293945
  StateBufferConnector_ms: 0.008484125137329102
  ViewRequirementAgentConnector_ms: 0.27863121032714844
counters:
  num_agent_steps_sampled: 681000
  num_agent_steps_trained: 664500
  num_env_steps_sampled: 681000
  num_env_steps_trained: 664500
  num_samples_added_to_queue: 681000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 13289
custom_metrics: {}
date: 2023-08-14_14-58-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.7
episode_reward_min: 1.0
episodes_this_iter: 40
episodes_total: 5320
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8391075730323792
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.487675189971924
        total_loss: 10.192392349243164
        var_gnorm: 63.95269012451172
        vf_explained_var: 0.9263571500778198
        vf_loss: 39.7512092590332
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1329.0
  learner_queue:
    size_count: 1332
    size_mean: 14.52
    size_quantiles: [10.0, 11.9, 15.5, 16.0, 16.0]
    size_std: 1.8137254478007416
  num_agent_steps_sampled: 681000
  num_agent_steps_trained: 664500
  num_env_steps_sampled: 681000
  num_env_steps_trained: 664500
  num_samples_added_to_queue: 681000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 13289
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 1009.564
    learner_load_time_ms: 4.543
    learner_load_wait_time_ms: 25.76
iterations_since_restore: 94
node_ip: 127.0.0.1
num_agent_steps_sampled: 681000
num_agent_steps_trained: 664500
num_env_steps_sampled: 681000
num_env_steps_sampled_this_iter: 5350
num_env_steps_sampled_throughput_per_sec: 534.5256142267233
num_env_steps_trained: 664500
num_env_steps_trained_this_iter: 5500
num_env_steps_trained_throughput_per_sec: 549.5123136910239
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5500
perf:
  cpu_util_percent: 70.88571428571429
  ram_util_percent: 77.00714285714287
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11305653667719617
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042197640784353015
  mean_inference_ms: 2.0953577211913053
  mean_raw_obs_processing_ms: 0.4712629679136574
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.047492265701293945
    StateBufferConnector_ms: 0.008484125137329102
    ViewRequirementAgentConnector_ms: 0.27863121032714844
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.7
  episode_reward_min: 1.0
  episodes_this_iter: 40
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 4.0, 1.0, 6.0, 4.0, 5.0, 5.0, 4.0, 6.0, 5.0, 4.0, 5.0, 2.0,
      4.0, 4.0, 6.0, 5.0, 7.0, 2.0, 1.0, 5.0, 5.0, 4.0, 7.0, 5.0, 3.0, 3.0, 3.0, 6.0,
      1.0, 7.0, 6.0, 5.0, 4.0, 4.0, 5.0, 6.0, 5.0, 5.0, 7.0, 6.0, 3.0, 3.0, 6.0, 4.0,
      2.0, 5.0, 1.0, 8.0, 6.0, 2.0, 4.0, 12.0, 10.0, 4.0, 5.0, 5.0, 6.0, 3.0, 8.0,
      2.0, 7.0, 2.0, 4.0, 6.0, 6.0, 3.0, 5.0, 1.0, 4.0, 5.0, 2.0, 5.0, 4.0, 4.0, 5.0,
      4.0, 10.0, 5.0, 6.0, 4.0, 7.0, 10.0, 5.0, 2.0, 6.0, 4.0, 1.0, 3.0, 3.0, 3.0,
      5.0, 7.0, 5.0, 1.0, 3.0, 7.0, 2.0, 6.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11305653667719617
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042197640784353015
    mean_inference_ms: 2.0953577211913053
    mean_raw_obs_processing_ms: 0.4712629679136574
time_since_restore: 962.5508601665497
time_this_iter_s: 10.193236827850342
time_total_s: 962.5508601665497
timers:
  sample_time_ms: 0.13
  synch_weights_time_ms: 1.135
  training_iteration_time_ms: 4.977
timestamp: 1691992727
timesteps_total: 681000
training_iteration: 94
trial_id: default
train step: 95
agent_timesteps_total: 687050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.05131101608276367
  StateBufferConnector_ms: 0.008902788162231445
  ViewRequirementAgentConnector_ms: 0.28771495819091797
counters:
  num_agent_steps_sampled: 687050
  num_agent_steps_trained: 670500
  num_env_steps_sampled: 687050
  num_env_steps_trained: 670500
  num_samples_added_to_queue: 687000
  num_training_step_calls_since_last_synch_worker_weights: 805
  num_weight_broadcasts: 13407
custom_metrics: {}
date: 2023-08-14_14-58-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.8
episode_reward_min: 1.0
episodes_this_iter: 48
episodes_total: 5368
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 28.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0150318145751953
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.5924267768859863
        total_loss: 17.32703971862793
        var_gnorm: 63.95309829711914
        vf_explained_var: 0.9068717360496521
        vf_loss: 37.619544982910156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1341.0
  learner_queue:
    size_count: 1345
    size_mean: 14.58
    size_quantiles: [10.0, 11.9, 15.5, 16.0, 16.0]
    size_std: 1.778651174345324
  num_agent_steps_sampled: 687050
  num_agent_steps_trained: 670500
  num_env_steps_sampled: 687050
  num_env_steps_trained: 670500
  num_samples_added_to_queue: 687000
  num_training_step_calls_since_last_synch_worker_weights: 805
  num_weight_broadcasts: 13407
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 443.775
    learner_load_time_ms: 4.583
    learner_load_wait_time_ms: 3.103
iterations_since_restore: 95
node_ip: 127.0.0.1
num_agent_steps_sampled: 687050
num_agent_steps_trained: 670500
num_env_steps_sampled: 687050
num_env_steps_sampled_this_iter: 6050
num_env_steps_sampled_throughput_per_sec: 604.9976488443193
num_env_steps_trained: 670500
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.997668275358
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 63.4
  ram_util_percent: 79.06
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11334312975441682
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042316168367230275
  mean_inference_ms: 2.1001874531022735
  mean_raw_obs_processing_ms: 0.472293149081861
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.05131101608276367
    StateBufferConnector_ms: 0.008902788162231445
    ViewRequirementAgentConnector_ms: 0.28771495819091797
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.8
  episode_reward_min: 1.0
  episodes_this_iter: 48
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 6.0, 2.0, 4.0, 12.0, 10.0, 4.0, 5.0, 5.0, 6.0, 3.0, 8.0,
      2.0, 7.0, 2.0, 4.0, 6.0, 6.0, 3.0, 5.0, 1.0, 4.0, 5.0, 2.0, 5.0, 4.0, 4.0, 5.0,
      4.0, 10.0, 5.0, 6.0, 4.0, 7.0, 10.0, 5.0, 2.0, 6.0, 4.0, 1.0, 3.0, 3.0, 3.0,
      5.0, 7.0, 5.0, 1.0, 3.0, 7.0, 2.0, 6.0, 8.0, 6.0, 4.0, 2.0, 4.0, 4.0, 4.0, 2.0,
      5.0, 7.0, 7.0, 6.0, 5.0, 1.0, 2.0, 4.0, 4.0, 3.0, 10.0, 7.0, 3.0, 6.0, 9.0,
      3.0, 5.0, 4.0, 7.0, 4.0, 5.0, 5.0, 1.0, 4.0, 3.0, 2.0, 8.0, 5.0, 6.0, 6.0, 6.0,
      3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 7.0, 7.0, 10.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11334312975441682
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042316168367230275
    mean_inference_ms: 2.1001874531022735
    mean_raw_obs_processing_ms: 0.472293149081861
time_since_restore: 972.7712020874023
time_this_iter_s: 10.220341920852661
time_total_s: 972.7712020874023
timers:
  sample_time_ms: 0.032
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.09
timestamp: 1691992738
timesteps_total: 687050
training_iteration: 95
trial_id: default
train step: 96
agent_timesteps_total: 694750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.037619590759277344
  StateBufferConnector_ms: 0.006693601608276367
  ViewRequirementAgentConnector_ms: 0.21832990646362305
counters:
  num_agent_steps_sampled: 694750
  num_agent_steps_trained: 678000
  num_env_steps_sampled: 694750
  num_env_steps_trained: 678000
  num_samples_added_to_queue: 694500
  num_training_step_calls_since_last_synch_worker_weights: 314
  num_weight_broadcasts: 13555
custom_metrics: {}
date: 2023-08-14_14-59-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.64
episode_reward_min: 1.0
episodes_this_iter: 60
episodes_total: 5428
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 29.200000000000045
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0567734241485596
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -46.81743240356445
        total_loss: -29.972944259643555
        var_gnorm: 63.95667266845703
        vf_explained_var: 0.933890700340271
        vf_loss: 44.256710052490234
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1356.0
  learner_queue:
    size_count: 1362
    size_mean: 14.76
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6438978070427614
  num_agent_steps_sampled: 694750
  num_agent_steps_trained: 678000
  num_env_steps_sampled: 694750
  num_env_steps_trained: 678000
  num_samples_added_to_queue: 694500
  num_training_step_calls_since_last_synch_worker_weights: 314
  num_weight_broadcasts: 13555
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 309.695
    learner_load_time_ms: 4.579
    learner_load_wait_time_ms: 2.757
iterations_since_restore: 96
node_ip: 127.0.0.1
num_agent_steps_sampled: 694750
num_agent_steps_trained: 678000
num_env_steps_sampled: 694750
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 769.9953186796603
num_env_steps_trained: 678000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9954402723963
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.82142857142857
  ram_util_percent: 79.17142857142858
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11339452353219659
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042362208315214735
  mean_inference_ms: 2.1019529452807144
  mean_raw_obs_processing_ms: 0.47272421990410196
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.037619590759277344
    StateBufferConnector_ms: 0.006693601608276367
    ViewRequirementAgentConnector_ms: 0.21832990646362305
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.64
  episode_reward_min: 1.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 7.0, 6.0, 5.0, 1.0, 2.0, 4.0, 4.0, 3.0, 10.0, 7.0, 3.0,
      6.0, 9.0, 3.0, 5.0, 4.0, 7.0, 4.0, 5.0, 5.0, 1.0, 4.0, 3.0, 2.0, 8.0, 5.0, 6.0,
      6.0, 6.0, 3.0, 4.0, 3.0, 4.0, 3.0, 3.0, 7.0, 7.0, 10.0, 2.0, 5.0, 7.0, 10.0,
      4.0, 9.0, 8.0, 6.0, 5.0, 4.0, 9.0, 5.0, 7.0, 10.0, 10.0, 4.0, 7.0, 5.0, 3.0,
      4.0, 8.0, 2.0, 10.0, 4.0, 5.0, 7.0, 4.0, 4.0, 6.0, 4.0, 6.0, 5.0, 5.0, 5.0,
      12.0, 9.0, 6.0, 2.0, 4.0, 7.0, 7.0, 3.0, 6.0, 2.0, 5.0, 7.0, 8.0, 7.0, 10.0,
      10.0, 8.0, 9.0, 7.0, 7.0, 5.0, 5.0, 8.0, 5.0, 3.0, 5.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11339452353219659
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042362208315214735
    mean_inference_ms: 2.1019529452807144
    mean_raw_obs_processing_ms: 0.47272421990410196
time_since_restore: 983.0553631782532
time_this_iter_s: 10.28416109085083
time_total_s: 983.0553631782532
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.076
timestamp: 1691992748
timesteps_total: 694750
training_iteration: 96
trial_id: default
train step: 97
agent_timesteps_total: 702350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033701419830322266
  StateBufferConnector_ms: 0.006223917007446289
  ViewRequirementAgentConnector_ms: 0.20503973960876465
counters:
  num_agent_steps_sampled: 702350
  num_agent_steps_trained: 685500
  num_env_steps_sampled: 702350
  num_env_steps_trained: 685500
  num_samples_added_to_queue: 702000
  num_training_step_calls_since_last_synch_worker_weights: 787
  num_weight_broadcasts: 13703
custom_metrics: {}
date: 2023-08-14_14-59-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.61
episode_reward_min: 2.0
episodes_this_iter: 60
episodes_total: 5488
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9596409797668457
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 11.084539413452148
        total_loss: 17.792402267456055
        var_gnorm: 63.96055221557617
        vf_explained_var: 0.9507759809494019
        vf_loss: 23.012134552001953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1371.0
  learner_queue:
    size_count: 1377
    size_mean: 14.92
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.547126368465097
  num_agent_steps_sampled: 702350
  num_agent_steps_trained: 685500
  num_env_steps_sampled: 702350
  num_env_steps_trained: 685500
  num_samples_added_to_queue: 702000
  num_training_step_calls_since_last_synch_worker_weights: 787
  num_weight_broadcasts: 13703
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 347.259
    learner_load_time_ms: 4.566
    learner_load_wait_time_ms: 3.008
iterations_since_restore: 97
node_ip: 127.0.0.1
num_agent_steps_sampled: 702350
num_agent_steps_trained: 685500
num_env_steps_sampled: 702350
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.998713495525
num_env_steps_trained: 685500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9987304232154
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.786666666666655
  ram_util_percent: 78.44000000000001
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11348705856496652
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04233872778329733
  mean_inference_ms: 2.1007543307192913
  mean_raw_obs_processing_ms: 0.47239256908416083
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033701419830322266
    StateBufferConnector_ms: 0.006223917007446289
    ViewRequirementAgentConnector_ms: 0.20503973960876465
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.61
  episode_reward_min: 2.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 10.0, 4.0, 5.0, 7.0, 4.0, 4.0, 6.0, 4.0, 6.0, 5.0, 5.0,
      5.0, 12.0, 9.0, 6.0, 2.0, 4.0, 7.0, 7.0, 3.0, 6.0, 2.0, 5.0, 7.0, 8.0, 7.0,
      10.0, 10.0, 8.0, 9.0, 7.0, 7.0, 5.0, 5.0, 8.0, 5.0, 3.0, 5.0, 6.0, 9.0, 8.0,
      7.0, 6.0, 6.0, 5.0, 6.0, 8.0, 4.0, 9.0, 6.0, 5.0, 8.0, 8.0, 7.0, 11.0, 6.0,
      8.0, 9.0, 5.0, 9.0, 9.0, 5.0, 6.0, 8.0, 7.0, 4.0, 8.0, 6.0, 5.0, 7.0, 8.0, 11.0,
      8.0, 6.0, 8.0, 6.0, 5.0, 8.0, 8.0, 3.0, 7.0, 8.0, 6.0, 5.0, 5.0, 6.0, 6.0, 3.0,
      6.0, 9.0, 4.0, 10.0, 13.0, 8.0, 9.0, 10.0, 7.0, 8.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11348705856496652
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04233872778329733
    mean_inference_ms: 2.1007543307192913
    mean_raw_obs_processing_ms: 0.47239256908416083
time_since_restore: 993.3658211231232
time_this_iter_s: 10.310457944869995
time_total_s: 993.3658211231232
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.106
timestamp: 1691992758
timesteps_total: 702350
training_iteration: 97
trial_id: default
train step: 98
agent_timesteps_total: 709350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03604578971862793
  StateBufferConnector_ms: 0.006972074508666992
  ViewRequirementAgentConnector_ms: 0.21634149551391602
counters:
  num_agent_steps_sampled: 709350
  num_agent_steps_trained: 692500
  num_env_steps_sampled: 709350
  num_env_steps_trained: 692500
  num_samples_added_to_queue: 709000
  num_training_step_calls_since_last_synch_worker_weights: 356
  num_weight_broadcasts: 13838
custom_metrics: {}
date: 2023-08-14_14-59-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.16
episode_reward_min: 3.0
episodes_this_iter: 54
episodes_total: 5542
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9848883748054504
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.446533203125
        total_loss: 15.216796875
        var_gnorm: 63.970245361328125
        vf_explained_var: 0.9108927249908447
        vf_loss: 73.17554473876953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1385.0
  learner_queue:
    size_count: 1391
    size_mean: 14.52
    size_quantiles: [11.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.746310396235446
  num_agent_steps_sampled: 709350
  num_agent_steps_trained: 692500
  num_env_steps_sampled: 709350
  num_env_steps_trained: 692500
  num_samples_added_to_queue: 709000
  num_training_step_calls_since_last_synch_worker_weights: 356
  num_weight_broadcasts: 13838
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 327.699
    learner_load_time_ms: 4.566
    learner_load_wait_time_ms: 2.702
iterations_since_restore: 98
node_ip: 127.0.0.1
num_agent_steps_sampled: 709350
num_agent_steps_trained: 692500
num_env_steps_sampled: 709350
num_env_steps_sampled_this_iter: 7000
num_env_steps_sampled_throughput_per_sec: 699.996445197038
num_env_steps_trained: 692500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.996445197038
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 57.26428571428572
  ram_util_percent: 78.92857142857143
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11342088855238136
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042350497758747226
  mean_inference_ms: 2.100830049236632
  mean_raw_obs_processing_ms: 0.4724348861932001
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03604578971862793
    StateBufferConnector_ms: 0.006972074508666992
    ViewRequirementAgentConnector_ms: 0.21634149551391602
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.16
  episode_reward_min: 3.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 11.0, 6.0, 8.0, 9.0, 5.0, 9.0, 9.0, 5.0, 6.0, 8.0, 7.0,
      4.0, 8.0, 6.0, 5.0, 7.0, 8.0, 11.0, 8.0, 6.0, 8.0, 6.0, 5.0, 8.0, 8.0, 3.0,
      7.0, 8.0, 6.0, 5.0, 5.0, 6.0, 6.0, 3.0, 6.0, 9.0, 4.0, 10.0, 13.0, 8.0, 9.0,
      10.0, 7.0, 8.0, 5.0, 8.0, 8.0, 12.0, 9.0, 9.0, 6.0, 5.0, 7.0, 4.0, 8.0, 7.0,
      5.0, 4.0, 7.0, 9.0, 3.0, 10.0, 7.0, 6.0, 6.0, 7.0, 6.0, 9.0, 6.0, 6.0, 8.0,
      10.0, 6.0, 6.0, 11.0, 5.0, 12.0, 6.0, 9.0, 9.0, 6.0, 11.0, 5.0, 4.0, 8.0, 10.0,
      11.0, 4.0, 8.0, 8.0, 5.0, 9.0, 7.0, 6.0, 7.0, 10.0, 6.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11342088855238136
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042350497758747226
    mean_inference_ms: 2.100830049236632
    mean_raw_obs_processing_ms: 0.4724348861932001
time_since_restore: 1003.6022250652313
time_this_iter_s: 10.236403942108154
time_total_s: 1003.6022250652313
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.072
timestamp: 1691992769
timesteps_total: 709350
training_iteration: 98
trial_id: default
train step: 99
agent_timesteps_total: 715400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04060196876525879
  StateBufferConnector_ms: 0.007572650909423828
  ViewRequirementAgentConnector_ms: 0.2389216423034668
counters:
  num_agent_steps_sampled: 715400
  num_agent_steps_trained: 698500
  num_env_steps_sampled: 715400
  num_env_steps_trained: 698500
  num_samples_added_to_queue: 715000
  num_training_step_calls_since_last_synch_worker_weights: 24
  num_weight_broadcasts: 13956
custom_metrics: {}
date: 2023-08-14_14-59-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.99
episode_reward_min: 1.0
episodes_this_iter: 48
episodes_total: 5590
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.90000000000009
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9246769547462463
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -39.356136322021484
        total_loss: -5.755407333374023
        var_gnorm: 63.9747314453125
        vf_explained_var: 0.8931044340133667
        vf_loss: 76.44822692871094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1397.0
  learner_queue:
    size_count: 1404
    size_mean: 14.24
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.903260360539251
  num_agent_steps_sampled: 715400
  num_agent_steps_trained: 698500
  num_env_steps_sampled: 715400
  num_env_steps_trained: 698500
  num_samples_added_to_queue: 715000
  num_training_step_calls_since_last_synch_worker_weights: 24
  num_weight_broadcasts: 13956
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 388.623
    learner_load_time_ms: 5.226
    learner_load_wait_time_ms: 3.425
iterations_since_restore: 99
node_ip: 127.0.0.1
num_agent_steps_sampled: 715400
num_agent_steps_trained: 698500
num_env_steps_sampled: 715400
num_env_steps_sampled_this_iter: 6050
num_env_steps_sampled_throughput_per_sec: 604.9943168697155
num_env_steps_trained: 698500
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9943638377345
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 63.35333333333333
  ram_util_percent: 78.91333333333333
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11337763427852275
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042405688804884975
  mean_inference_ms: 2.1030151992193966
  mean_raw_obs_processing_ms: 0.473073012350177
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04060196876525879
    StateBufferConnector_ms: 0.007572650909423828
    ViewRequirementAgentConnector_ms: 0.2389216423034668
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.99
  episode_reward_min: 1.0
  episodes_this_iter: 48
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 9.0, 9.0, 6.0, 5.0, 7.0, 4.0, 8.0, 7.0, 5.0, 4.0, 7.0,
      9.0, 3.0, 10.0, 7.0, 6.0, 6.0, 7.0, 6.0, 9.0, 6.0, 6.0, 8.0, 10.0, 6.0, 6.0,
      11.0, 5.0, 12.0, 6.0, 9.0, 9.0, 6.0, 11.0, 5.0, 4.0, 8.0, 10.0, 11.0, 4.0, 8.0,
      8.0, 5.0, 9.0, 7.0, 6.0, 7.0, 10.0, 6.0, 5.0, 4.0, 9.0, 12.0, 4.0, 6.0, 12.0,
      8.0, 4.0, 7.0, 11.0, 6.0, 5.0, 8.0, 3.0, 8.0, 5.0, 9.0, 8.0, 10.0, 6.0, 4.0,
      5.0, 9.0, 5.0, 2.0, 8.0, 2.0, 9.0, 5.0, 9.0, 12.0, 8.0, 6.0, 6.0, 4.0, 7.0,
      1.0, 7.0, 6.0, 5.0, 5.0, 6.0, 12.0, 7.0, 5.0, 10.0, 5.0, 9.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11337763427852275
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042405688804884975
    mean_inference_ms: 2.1030151992193966
    mean_raw_obs_processing_ms: 0.473073012350177
time_since_restore: 1014.014358997345
time_this_iter_s: 10.412133932113647
time_total_s: 1014.014358997345
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.107
timestamp: 1691992779
timesteps_total: 715400
training_iteration: 99
trial_id: default
train step: 100
agent_timesteps_total: 720800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04565072059631348
  StateBufferConnector_ms: 0.00798177719116211
  ViewRequirementAgentConnector_ms: 0.26662492752075195
counters:
  num_agent_steps_sampled: 720800
  num_agent_steps_trained: 704000
  num_env_steps_sampled: 720800
  num_env_steps_trained: 704000
  num_samples_added_to_queue: 720500
  num_training_step_calls_since_last_synch_worker_weights: 1160
  num_weight_broadcasts: 14061
custom_metrics: {}
date: 2023-08-14_14-59-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 7.15
episode_reward_min: 1.0
episodes_this_iter: 42
episodes_total: 5632
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 29.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9043821692466736
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 60.938377380371094
        total_loss: 102.30562591552734
        var_gnorm: 63.97928237915039
        vf_explained_var: 0.8710564374923706
        vf_loss: 91.7783203125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1408.0
  learner_queue:
    size_count: 1412
    size_mean: 14.24
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.8714700104463335
  num_agent_steps_sampled: 720800
  num_agent_steps_trained: 704000
  num_env_steps_sampled: 720800
  num_env_steps_trained: 704000
  num_samples_added_to_queue: 720500
  num_training_step_calls_since_last_synch_worker_weights: 1160
  num_weight_broadcasts: 14061
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 998.827
    learner_load_time_ms: 4.635
    learner_load_wait_time_ms: 32.958
iterations_since_restore: 100
node_ip: 127.0.0.1
num_agent_steps_sampled: 720800
num_agent_steps_trained: 704000
num_env_steps_sampled: 720800
num_env_steps_sampled_this_iter: 5400
num_env_steps_sampled_throughput_per_sec: 539.9963178885719
num_env_steps_trained: 704000
num_env_steps_trained_this_iter: 5500
num_env_steps_trained_throughput_per_sec: 549.9962497013231
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5500
perf:
  cpu_util_percent: 67.35
  ram_util_percent: 80.42142857142858
pid: 41384
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1136679397097328
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04249159323643733
  mean_inference_ms: 2.1066832441678494
  mean_raw_obs_processing_ms: 0.47392009620403946
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04565072059631348
    StateBufferConnector_ms: 0.00798177719116211
    ViewRequirementAgentConnector_ms: 0.26662492752075195
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 7.15
  episode_reward_min: 1.0
  episodes_this_iter: 42
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 5.0, 9.0, 7.0, 6.0, 7.0, 10.0, 6.0, 5.0, 4.0, 9.0, 12.0,
      4.0, 6.0, 12.0, 8.0, 4.0, 7.0, 11.0, 6.0, 5.0, 8.0, 3.0, 8.0, 5.0, 9.0, 8.0,
      10.0, 6.0, 4.0, 5.0, 9.0, 5.0, 2.0, 8.0, 2.0, 9.0, 5.0, 9.0, 12.0, 8.0, 6.0,
      6.0, 4.0, 7.0, 1.0, 7.0, 6.0, 5.0, 5.0, 6.0, 12.0, 7.0, 5.0, 10.0, 5.0, 9.0,
      5.0, 4.0, 6.0, 4.0, 4.0, 12.0, 5.0, 9.0, 10.0, 8.0, 10.0, 8.0, 8.0, 9.0, 8.0,
      10.0, 9.0, 7.0, 8.0, 6.0, 12.0, 5.0, 6.0, 8.0, 11.0, 8.0, 8.0, 6.0, 11.0, 8.0,
      10.0, 10.0, 4.0, 12.0, 10.0, 5.0, 7.0, 6.0, 9.0, 5.0, 3.0, 7.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1136679397097328
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04249159323643733
    mean_inference_ms: 2.1066832441678494
    mean_raw_obs_processing_ms: 0.47392009620403946
time_since_restore: 1024.219733953476
time_this_iter_s: 10.205374956130981
time_total_s: 1024.219733953476
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1691992789
timesteps_total: 720800
training_iteration: 100
trial_id: default
Drawing graph: episode 0
Drawing graph: episode 1
Drawing graph: episode 2
Drawing graph: episode 3
Drawing graph: episode 4
Drawing graph: episode 5
Drawing graph: episode 6
Drawing graph: episode 7
Drawing graph: episode 8
[36m(pid=41434)[39m lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.
[36m(pid=41434)[39m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
Drawing graph: episode 9
Drawing graph finished
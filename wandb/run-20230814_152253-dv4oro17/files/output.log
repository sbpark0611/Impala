[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
2023-08-14 15:22:54,259	INFO tensorboardx.py:48 -- pip install "ray[tune]" to see TensorBoard files.
2023-08-14 15:22:54,259	WARNING unified.py:56 -- Could not instantiate TBXLogger: No module named 'tensorboardX'.
[36m(pid=42587)[39m lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.
[36m(pid=42587)[39m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,498	WARNING env.py:162 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,503	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,503	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,506	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.AttentionWrapper` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,506	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,506	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,527	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.GTrXLNet` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,540	WARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,540	WARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,540	WARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,541	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/catalog.py:790: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  prep = cls(observation_space, options)
2023-08-14 15:22:57,639	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
2023-08-14 15:22:57,639	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
2023-08-14 15:22:57,643	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.AttentionWrapper` has been deprecated. This will raise an error in the future!
2023-08-14 15:22:57,643	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
2023-08-14 15:22:57,643	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/torch/attention_net.py:281: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  super().__init__(obs_space, action_space, None, model_config, name)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/torch/attention_net.py:281: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  super().__init__(obs_space, action_space, None, model_config, name)
2023-08-14 15:22:57,649	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.GTrXLNet` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=42586)[39m 2023-08-14 15:22:57,597	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!2023-08-14 15:22:57,653	WARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!
2023-08-14 15:22:57,654	WARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!
2023-08-14 15:22:57,654	WARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!
2023-08-14 15:22:57,654	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/modelv2.py:440: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  prep = get_preprocessor(space)(space)
2023-08-14 15:22:57,679	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/connectors/agent/obs_preproc.py:40: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  self._preprocessor = get_preprocessor(obs_space)(
2023-08-14 15:22:57,701	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.multi_gpu_learner_thread.MultiGPULearnerThread` has been deprecated. This will raise an error in the future!
2023-08-14 15:22:57,701	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.minibatch_buffer.MinibatchBuffer` has been deprecated. This will raise an error in the future!
2023-08-14 15:22:57,701	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.learner_thread.LearnerThread` has been deprecated. This will raise an error in the future!
2023-08-14 15:22:57,705	WARNING util.py:68 -- Install gputil for GPU system monitoring.
2023-08-14 15:22:57,811	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.replay_ops.SimpleReplayBuffer` has been deprecated. This will raise an error in the future!
train step: 1
agent_timesteps_total: 5900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.044144754824431046
  StateBufferConnector_ms: 0.008457121641739555
  ViewRequirementAgentConnector_ms: 0.25412310724673065
counters:
  num_agent_steps_sampled: 5900
  num_agent_steps_trained: 1500
  num_env_steps_sampled: 5900
  num_env_steps_trained: 1500
  num_samples_added_to_queue: 5500
  num_training_step_calls_since_last_synch_worker_weights: 584
  num_weight_broadcasts: 117
custom_metrics: {}
date: 2023-08-14_15-23-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 3.0
episode_reward_mean: 0.8695652173913043
episode_reward_min: 0.0
episodes_this_iter: 46
episodes_total: 46
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 2.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.57049560546875
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 21.836706161499023
        total_loss: 30.498416900634766
        var_gnorm: 63.329856872558594
        vf_explained_var: 0.24393552541732788
        vf_loss: 33.028377532958984
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3.0
  learner_queue:
    size_count: 9
    size_mean: 0.0
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 0.0]
    size_std: 0.0
  num_agent_steps_sampled: 5900
  num_agent_steps_trained: 1500
  num_env_steps_sampled: 5900
  num_env_steps_trained: 1500
  num_samples_added_to_queue: 5500
  num_training_step_calls_since_last_synch_worker_weights: 584
  num_weight_broadcasts: 117
  timing_breakdown:
    learner_dequeue_time_ms: 569.033
    learner_grad_time_ms: 1058.421
    learner_load_time_ms: 39.41
    learner_load_wait_time_ms: 68.823
iterations_since_restore: 1
node_ip: 127.0.0.1
num_agent_steps_sampled: 5900
num_agent_steps_trained: 1500
num_env_steps_sampled: 5900
num_env_steps_sampled_this_iter: 5900
num_env_steps_sampled_throughput_per_sec: 589.9988605998109
num_env_steps_trained: 1500
num_env_steps_trained_this_iter: 1500
num_env_steps_trained_throughput_per_sec: 149.99971032198582
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 1500
perf:
  cpu_util_percent: 62.1
  ram_util_percent: 80.05333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.13588925183151476
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.05294451436930821
  mean_inference_ms: 2.5073026524571578
  mean_raw_obs_processing_ms: 0.5529438695216795
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.044144754824431046
    StateBufferConnector_ms: 0.008457121641739555
    ViewRequirementAgentConnector_ms: 0.25412310724673065
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 3.0
  episode_reward_mean: 0.8695652173913043
  episode_reward_min: 0.0
  episodes_this_iter: 46
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128]
    episode_reward: [0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0,
      1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0,
      2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0,
      0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.13588925183151476
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.05294451436930821
    mean_inference_ms: 2.5073026524571578
    mean_raw_obs_processing_ms: 0.5529438695216795
time_since_restore: 10.225826025009155
time_this_iter_s: 10.225826025009155
time_total_s: 10.225826025009155
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.076
timestamp: 1691994187
timesteps_total: 5900
training_iteration: 1
trial_id: default
train step: 2
agent_timesteps_total: 12500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04209401656170281
  StateBufferConnector_ms: 0.007922795354103555
  ViewRequirementAgentConnector_ms: 0.24553075128672075
counters:
  num_agent_steps_sampled: 12500
  num_agent_steps_trained: 6500
  num_env_steps_sampled: 12500
  num_env_steps_trained: 6500
  num_samples_added_to_queue: 12500
  num_training_step_calls_since_last_synch_worker_weights: 1216
  num_weight_broadcasts: 245
custom_metrics: {}
date: 2023-08-14_15-23-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 4.0
episode_reward_mean: 1.2040816326530612
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 98
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 4.2
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.5746039152145386
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 188.255859375
        total_loss: 202.64788818359375
        var_gnorm: 63.329097747802734
        vf_explained_var: 0.15106332302093506
        vf_loss: 44.53007888793945
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 13.0
  learner_queue:
    size_count: 18
    size_mean: 0.0
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 0.0]
    size_std: 0.0
  num_agent_steps_sampled: 12500
  num_agent_steps_trained: 6500
  num_env_steps_sampled: 12500
  num_env_steps_trained: 6500
  num_samples_added_to_queue: 12500
  num_training_step_calls_since_last_synch_worker_weights: 1216
  num_weight_broadcasts: 245
  timing_breakdown:
    learner_dequeue_time_ms: 7246.456
    learner_grad_time_ms: 983.169
    learner_load_time_ms: 21.023
    learner_load_wait_time_ms: 42.237
iterations_since_restore: 2
node_ip: 127.0.0.1
num_agent_steps_sampled: 12500
num_agent_steps_trained: 6500
num_env_steps_sampled: 12500
num_env_steps_sampled_this_iter: 6600
num_env_steps_sampled_throughput_per_sec: 659.9972305414062
num_env_steps_trained: 6500
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.99790192530776
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 59.65714285714285
  ram_util_percent: 80.10714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.13209571548583507
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0511700827406073
  mean_inference_ms: 2.450200726722043
  mean_raw_obs_processing_ms: 0.5420880017178551
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04209401656170281
    StateBufferConnector_ms: 0.007922795354103555
    ViewRequirementAgentConnector_ms: 0.24553075128672075
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 4.0
  episode_reward_mean: 1.2040816326530612
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 1.0, 1.0, 2.0, 3.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0,
      1.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0,
      2.0, 3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0,
      0.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0,
      3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0,
      0.0, 0.0, 0.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 1.0, 2.0, 2.0, 0.0,
      1.0, 0.0, 0.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.13209571548583507
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0511700827406073
    mean_inference_ms: 2.450200726722043
    mean_raw_obs_processing_ms: 0.5420880017178551
time_since_restore: 20.424407958984375
time_this_iter_s: 10.19858193397522
time_total_s: 20.424407958984375
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1691994198
timesteps_total: 12500
training_iteration: 2
trial_id: default
train step: 3
agent_timesteps_total: 19000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04136371612548828
  StateBufferConnector_ms: 0.007731914520263672
  ViewRequirementAgentConnector_ms: 0.24008703231811523
counters:
  num_agent_steps_sampled: 19000
  num_agent_steps_trained: 11500
  num_env_steps_sampled: 19000
  num_env_steps_trained: 11500
  num_samples_added_to_queue: 19000
  num_training_step_calls_since_last_synch_worker_weights: 191
  num_weight_broadcasts: 369
custom_metrics: {}
date: 2023-08-14_15-23-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 1.44
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 150
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 10.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.5664268732070923
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.073762893676758
        total_loss: 29.84048080444336
        var_gnorm: 63.328636169433594
        vf_explained_var: 0.15756887197494507
        vf_loss: 39.19770812988281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 23.0
  learner_queue:
    size_count: 29
    size_mean: 0.0
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 0.0]
    size_std: 0.0
  num_agent_steps_sampled: 19000
  num_agent_steps_trained: 11500
  num_env_steps_sampled: 19000
  num_env_steps_trained: 11500
  num_samples_added_to_queue: 19000
  num_training_step_calls_since_last_synch_worker_weights: 191
  num_weight_broadcasts: 369
  timing_breakdown:
    learner_dequeue_time_ms: 6795.283
    learner_grad_time_ms: 849.4
    learner_load_time_ms: 21.023
    learner_load_wait_time_ms: 28.276
iterations_since_restore: 3
node_ip: 127.0.0.1
num_agent_steps_sampled: 19000
num_agent_steps_trained: 11500
num_env_steps_sampled: 19000
num_env_steps_sampled_this_iter: 6500
num_env_steps_sampled_throughput_per_sec: 649.9971950175214
num_env_steps_trained: 11500
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.9978423211703
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 60.806666666666665
  ram_util_percent: 79.97333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.12821373503044917
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04927256018955885
  mean_inference_ms: 2.391169126235859
  mean_raw_obs_processing_ms: 0.530570615424397
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04136371612548828
    StateBufferConnector_ms: 0.007731914520263672
    ViewRequirementAgentConnector_ms: 0.24008703231811523
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 1.44
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 3.0, 2.0,
      1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0,
      0.0, 1.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0,
      0.0, 3.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 4.0, 3.0, 7.0, 1.0, 1.0, 2.0, 1.0,
      0.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 2.0, 1.0, 0.0,
      2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0,
      2.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12821373503044917
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04927256018955885
    mean_inference_ms: 2.391169126235859
    mean_raw_obs_processing_ms: 0.530570615424397
time_since_restore: 30.671642780303955
time_this_iter_s: 10.24723482131958
time_total_s: 30.671642780303955
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691994208
timesteps_total: 19000
training_iteration: 3
trial_id: default
train step: 4
agent_timesteps_total: 27100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03585958480834961
  StateBufferConnector_ms: 0.006664752960205078
  ViewRequirementAgentConnector_ms: 0.20979094505310059
counters:
  num_agent_steps_sampled: 27100
  num_agent_steps_trained: 17500
  num_env_steps_sampled: 27100
  num_env_steps_trained: 17500
  num_samples_added_to_queue: 27000
  num_training_step_calls_since_last_synch_worker_weights: 1326
  num_weight_broadcasts: 526
custom_metrics: {}
date: 2023-08-14_15-23-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 1.83
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 212
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 13.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.429978609085083
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 9.745423316955566
        total_loss: 8.5257568359375
        var_gnorm: 63.328975677490234
        vf_explained_var: 0.4254071116447449
        vf_loss: 11.860453605651855
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 35.0
  learner_queue:
    size_count: 39
    size_mean: 0.10256410256410256
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 2.0]
    size_std: 0.3785852066726513
  num_agent_steps_sampled: 27100
  num_agent_steps_trained: 17500
  num_env_steps_sampled: 27100
  num_env_steps_trained: 17500
  num_samples_added_to_queue: 27000
  num_training_step_calls_since_last_synch_worker_weights: 1326
  num_weight_broadcasts: 526
  timing_breakdown:
    learner_dequeue_time_ms: 5796.403
    learner_grad_time_ms: 1014.59
    learner_load_time_ms: 15.181
    learner_load_wait_time_ms: 4.019
iterations_since_restore: 4
node_ip: 127.0.0.1
num_agent_steps_sampled: 27100
num_agent_steps_trained: 17500
num_env_steps_sampled: 27100
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9951527408758
num_env_steps_trained: 17500
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9964094376858
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 51.45714285714286
  ram_util_percent: 80.05714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.12253319340765648
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04652747236495966
  mean_inference_ms: 2.2873501928550684
  mean_raw_obs_processing_ms: 0.509191659425791
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03585958480834961
    StateBufferConnector_ms: 0.006664752960205078
    ViewRequirementAgentConnector_ms: 0.20979094505310059
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 1.83
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 1.0, 1.0, 3.0, 0.0, 1.0, 2.0,
      1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 1.0, 2.0, 4.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0,
      0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 4.0, 4.0, 1.0, 1.0,
      2.0, 2.0, 4.0, 3.0, 7.0, 2.0, 2.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0,
      1.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 0.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0,
      1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 2.0, 1.0,
      2.0, 1.0, 4.0, 3.0, 2.0, 3.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.12253319340765648
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04652747236495966
    mean_inference_ms: 2.2873501928550684
    mean_raw_obs_processing_ms: 0.509191659425791
time_since_restore: 40.82757568359375
time_this_iter_s: 10.155932903289795
time_total_s: 40.82757568359375
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1691994218
timesteps_total: 27100
training_iteration: 4
trial_id: default
train step: 5
agent_timesteps_total: 34100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033627986907958984
  StateBufferConnector_ms: 0.006142377853393555
  ViewRequirementAgentConnector_ms: 0.1996619701385498
counters:
  num_agent_steps_sampled: 34100
  num_agent_steps_trained: 22000
  num_env_steps_sampled: 34100
  num_env_steps_trained: 22000
  num_samples_added_to_queue: 34000
  num_training_step_calls_since_last_synch_worker_weights: 1114
  num_weight_broadcasts: 662
custom_metrics: {}
date: 2023-08-14_15-23-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.26
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 266
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 12.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.371427297592163
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 42.09812927246094
        total_loss: 49.91854476928711
        var_gnorm: 63.33066177368164
        vf_explained_var: 0.392633318901062
        vf_loss: 29.355100631713867
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 44.0
  learner_queue:
    size_count: 48
    size_mean: 0.8958333333333334
    size_quantiles: [0.0, 0.0, 0.0, 4.300000000000004, 7.0]
    size_std: 1.9390674663066494
  num_agent_steps_sampled: 34100
  num_agent_steps_trained: 22000
  num_env_steps_sampled: 34100
  num_env_steps_trained: 22000
  num_samples_added_to_queue: 34000
  num_training_step_calls_since_last_synch_worker_weights: 1114
  num_weight_broadcasts: 662
  timing_breakdown:
    learner_dequeue_time_ms: 4637.123
    learner_grad_time_ms: 990.691
    learner_load_time_ms: 11.98
    learner_load_wait_time_ms: 29.467
iterations_since_restore: 5
node_ip: 127.0.0.1
num_agent_steps_sampled: 34100
num_agent_steps_trained: 22000
num_env_steps_sampled: 34100
num_env_steps_sampled_this_iter: 7000
num_env_steps_sampled_throughput_per_sec: 699.992723540605
num_env_steps_trained: 22000
num_env_steps_trained_this_iter: 4500
num_env_steps_trained_throughput_per_sec: 449.9953222761032
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 4500
perf:
  cpu_util_percent: 57.633333333333326
  ram_util_percent: 80.47333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1188751589876415
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04480253255163627
  mean_inference_ms: 2.220818715092694
  mean_raw_obs_processing_ms: 0.4960969640830201
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033627986907958984
    StateBufferConnector_ms: 0.006142377853393555
    ViewRequirementAgentConnector_ms: 0.1996619701385498
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.26
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 1.0, 2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 4.0, 4.0, 2.0, 2.0, 3.0,
      2.0, 3.0, 3.0, 0.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0,
      1.0, 2.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 4.0, 3.0, 2.0, 3.0,
      0.0, 2.0, 3.0, 3.0, 4.0, 3.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 4.0, 5.0, 4.0, 2.0,
      1.0, 2.0, 4.0, 0.0, 2.0, 0.0, 2.0, 1.0, 4.0, 3.0, 4.0, 3.0, 6.0, 0.0, 3.0, 5.0,
      2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 1.0, 6.0,
      2.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1188751589876415
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04480253255163627
    mean_inference_ms: 2.220818715092694
    mean_raw_obs_processing_ms: 0.4960969640830201
time_since_restore: 50.987828969955444
time_this_iter_s: 10.160253286361694
time_total_s: 50.987828969955444
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1691994228
timesteps_total: 34100
training_iteration: 5
trial_id: default
train step: 6
agent_timesteps_total: 41750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03426074981689453
  StateBufferConnector_ms: 0.0063054561614990234
  ViewRequirementAgentConnector_ms: 0.20488619804382324
counters:
  num_agent_steps_sampled: 41750
  num_agent_steps_trained: 27000
  num_env_steps_sampled: 41750
  num_env_steps_trained: 27000
  num_samples_added_to_queue: 41500
  num_training_step_calls_since_last_synch_worker_weights: 880
  num_weight_broadcasts: 812
custom_metrics: {}
date: 2023-08-14_15-23-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.19
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 327
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 18.299999999999997
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3657736778259277
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.19387149810791
        total_loss: -4.074488639831543
        var_gnorm: 63.330780029296875
        vf_explained_var: 0.5111331343650818
        vf_loss: 15.896502494812012
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 54.0
  learner_queue:
    size_count: 59
    size_mean: 2.9
    size_quantiles: [0.0, 0.0, 0.0, 10.0, 13.0]
    size_std: 4.036087214122113
  num_agent_steps_sampled: 41750
  num_agent_steps_trained: 27000
  num_env_steps_sampled: 41750
  num_env_steps_trained: 27000
  num_samples_added_to_queue: 41500
  num_training_step_calls_since_last_synch_worker_weights: 880
  num_weight_broadcasts: 812
  timing_breakdown:
    learner_dequeue_time_ms: 4637.123
    learner_grad_time_ms: 924.795
    learner_load_time_ms: 11.98
    learner_load_wait_time_ms: 17.047
iterations_since_restore: 6
node_ip: 127.0.0.1
num_agent_steps_sampled: 41750
num_agent_steps_trained: 27000
num_env_steps_sampled: 41750
num_env_steps_sampled_this_iter: 7650
num_env_steps_sampled_throughput_per_sec: 764.9943277064343
num_env_steps_trained: 27000
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.9962926185845
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 54.28571428571429
  ram_util_percent: 80.42857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11692910170998141
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04386431347211177
  mean_inference_ms: 2.189859978936017
  mean_raw_obs_processing_ms: 0.489726199784365
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03426074981689453
    StateBufferConnector_ms: 0.0063054561614990234
    ViewRequirementAgentConnector_ms: 0.20488619804382324
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.19
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 4.0, 0.0, 2.0, 0.0, 2.0, 1.0, 4.0, 3.0, 4.0, 3.0, 6.0,
      0.0, 3.0, 5.0, 2.0, 4.0, 2.0, 1.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0,
      4.0, 1.0, 6.0, 2.0, 1.0, 5.0, 1.0, 1.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0,
      2.0, 3.0, 3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 4.0, 2.0, 2.0, 0.0, 2.0, 2.0, 1.0,
      2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0,
      2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0, 4.0,
      1.0, 1.0, 3.0, 4.0, 1.0, 7.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11692910170998141
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04386431347211177
    mean_inference_ms: 2.189859978936017
    mean_raw_obs_processing_ms: 0.489726199784365
time_since_restore: 61.25048494338989
time_this_iter_s: 10.262655973434448
time_total_s: 61.25048494338989
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1691994239
timesteps_total: 41750
training_iteration: 6
trial_id: default
train step: 7
agent_timesteps_total: 47750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03725028038024902
  StateBufferConnector_ms: 0.006799459457397461
  ViewRequirementAgentConnector_ms: 0.2210679054260254
counters:
  num_agent_steps_sampled: 47750
  num_agent_steps_trained: 32000
  num_env_steps_sampled: 47750
  num_env_steps_trained: 32000
  num_samples_added_to_queue: 47500
  num_training_step_calls_since_last_synch_worker_weights: 409
  num_weight_broadcasts: 928
custom_metrics: {}
date: 2023-08-14_15-24-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.3
episode_reward_min: 0.0
episodes_this_iter: 47
episodes_total: 374
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 21.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3233932256698608
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -44.25347900390625
        total_loss: -37.295196533203125
        var_gnorm: 63.33245086669922
        vf_explained_var: 0.39361631870269775
        vf_loss: 27.150497436523438
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 64.0
  learner_queue:
    size_count: 69
    size_mean: 5.26
    size_quantiles: [0.0, 0.0, 4.5, 12.100000000000001, 15.0]
    size_std: 5.066793858052645
  num_agent_steps_sampled: 47750
  num_agent_steps_trained: 32000
  num_env_steps_sampled: 47750
  num_env_steps_trained: 32000
  num_samples_added_to_queue: 47500
  num_training_step_calls_since_last_synch_worker_weights: 409
  num_weight_broadcasts: 928
  timing_breakdown:
    learner_dequeue_time_ms: 3864.27
    learner_grad_time_ms: 1015.713
    learner_load_time_ms: 18.179
    learner_load_wait_time_ms: 9.372
iterations_since_restore: 7
node_ip: 127.0.0.1
num_agent_steps_sampled: 47750
num_agent_steps_trained: 32000
num_env_steps_sampled: 47750
num_env_steps_sampled_this_iter: 6000
num_env_steps_sampled_throughput_per_sec: 599.9937058155404
num_env_steps_trained: 32000
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.9947548462836
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 65.32142857142857
  ram_util_percent: 82.92857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11694268842590734
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04389641262964203
  mean_inference_ms: 2.1962210174767414
  mean_raw_obs_processing_ms: 0.4908012676702526
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03725028038024902
    StateBufferConnector_ms: 0.006799459457397461
    ViewRequirementAgentConnector_ms: 0.2210679054260254
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.3
  episode_reward_min: 0.0
  episodes_this_iter: 47
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 0.0, 1.0, 0.0, 2.0, 2.0, 4.0, 4.0, 2.0, 2.0, 0.0, 2.0, 2.0,
      1.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 0.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0,
      3.0, 2.0, 1.0, 0.0, 1.0, 3.0, 0.0, 3.0, 2.0, 3.0, 3.0, 2.0, 2.0, 4.0, 3.0, 2.0,
      4.0, 1.0, 1.0, 3.0, 4.0, 1.0, 7.0, 2.0, 5.0, 5.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0,
      2.0, 5.0, 0.0, 2.0, 1.0, 3.0, 1.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0, 4.0, 4.0,
      1.0, 3.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 1.0, 5.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0,
      1.0, 4.0, 5.0, 2.0, 2.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11694268842590734
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04389641262964203
    mean_inference_ms: 2.1962210174767414
    mean_raw_obs_processing_ms: 0.4908012676702526
time_since_restore: 71.49479413032532
time_this_iter_s: 10.244309186935425
time_total_s: 71.49479413032532
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1691994249
timesteps_total: 47750
training_iteration: 7
trial_id: default
train step: 8
agent_timesteps_total: 54550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.041335105895996094
  StateBufferConnector_ms: 0.00759577751159668
  ViewRequirementAgentConnector_ms: 0.24008536338806152
counters:
  num_agent_steps_sampled: 54550
  num_agent_steps_trained: 38000
  num_env_steps_sampled: 54550
  num_env_steps_trained: 38000
  num_samples_added_to_queue: 54500
  num_training_step_calls_since_last_synch_worker_weights: 603
  num_weight_broadcasts: 1060
custom_metrics: {}
date: 2023-08-14_15-24-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 2.51
episode_reward_min: 0.0
episodes_this_iter: 53
episodes_total: 427
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 24.5
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3397979736328125
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 44.71024703979492
        total_loss: 52.98670959472656
        var_gnorm: 63.33294677734375
        vf_explained_var: 0.3108794689178467
        vf_loss: 29.950908660888672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 76.0
  learner_queue:
    size_count: 83
    size_mean: 9.0
    size_quantiles: [0.0, 1.0, 10.0, 15.0, 16.0]
    size_std: 4.862098312457287
  num_agent_steps_sampled: 54550
  num_agent_steps_trained: 38000
  num_env_steps_sampled: 54550
  num_env_steps_trained: 38000
  num_samples_added_to_queue: 54500
  num_training_step_calls_since_last_synch_worker_weights: 603
  num_weight_broadcasts: 1060
  timing_breakdown:
    learner_dequeue_time_ms: 3312.233
    learner_grad_time_ms: 458.782
    learner_load_time_ms: 15.746
    learner_load_wait_time_ms: 14.659
iterations_since_restore: 8
node_ip: 127.0.0.1
num_agent_steps_sampled: 54550
num_agent_steps_trained: 38000
num_env_steps_sampled: 54550
num_env_steps_sampled_this_iter: 6800
num_env_steps_sampled_throughput_per_sec: 679.9953308426075
num_env_steps_trained: 38000
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9958801552418
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 57.233333333333334
  ram_util_percent: 81.77999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11841648307739736
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04453266961669218
  mean_inference_ms: 2.2235595631488807
  mean_raw_obs_processing_ms: 0.4968343439558076
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.041335105895996094
    StateBufferConnector_ms: 0.00759577751159668
    ViewRequirementAgentConnector_ms: 0.24008536338806152
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 2.51
  episode_reward_min: 0.0
  episodes_this_iter: 53
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 5.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 5.0, 0.0, 2.0, 1.0,
      3.0, 1.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0, 4.0, 4.0, 1.0, 3.0, 2.0, 4.0, 1.0,
      1.0, 2.0, 3.0, 1.0, 5.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 1.0, 4.0, 5.0, 2.0, 2.0,
      3.0, 5.0, 1.0, 3.0, 3.0, 4.0, 3.0, 3.0, 5.0, 2.0, 4.0, 2.0, 2.0, 5.0, 3.0, 2.0,
      2.0, 1.0, 5.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 2.0,
      5.0, 3.0, 1.0, 3.0, 3.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0, 0.0, 1.0, 3.0, 2.0,
      3.0, 2.0, 0.0, 4.0, 3.0, 3.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11841648307739736
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04453266961669218
    mean_inference_ms: 2.2235595631488807
    mean_raw_obs_processing_ms: 0.4968343439558076
time_since_restore: 81.86097407341003
time_this_iter_s: 10.366179943084717
time_total_s: 81.86097407341003
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.109
timestamp: 1691994259
timesteps_total: 54550
training_iteration: 8
trial_id: default
train step: 9
agent_timesteps_total: 62050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03786826133728027
  StateBufferConnector_ms: 0.006955862045288086
  ViewRequirementAgentConnector_ms: 0.21963214874267578
counters:
  num_agent_steps_sampled: 62050
  num_agent_steps_trained: 45500
  num_env_steps_sampled: 62050
  num_env_steps_trained: 45500
  num_samples_added_to_queue: 62000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 1207
custom_metrics: {}
date: 2023-08-14_15-24-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.36
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 485
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 28.4
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.4063503742218018
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -49.782188415527344
        total_loss: -48.75379180908203
        var_gnorm: 63.33325958251953
        vf_explained_var: 0.6832903623580933
        vf_loss: 16.12029457092285
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 91.0
  learner_queue:
    size_count: 97
    size_mean: 12.22
    size_quantiles: [4.0, 8.0, 12.5, 16.0, 16.0]
    size_std: 3.0613069104550754
  num_agent_steps_sampled: 62050
  num_agent_steps_trained: 45500
  num_env_steps_sampled: 62050
  num_env_steps_trained: 45500
  num_samples_added_to_queue: 62000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 1207
  timing_breakdown:
    learner_dequeue_time_ms: 2898.204
    learner_grad_time_ms: 341.451
    learner_load_time_ms: 13.821
    learner_load_wait_time_ms: 2.759
iterations_since_restore: 9
node_ip: 127.0.0.1
num_agent_steps_sampled: 62050
num_agent_steps_trained: 45500
num_env_steps_sampled: 62050
num_env_steps_sampled_this_iter: 7500
num_env_steps_sampled_throughput_per_sec: 749.4803872065644
num_env_steps_trained: 45500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.4803872065644
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.18571428571429
  ram_util_percent: 79.90714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11808024973406342
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04427905277001489
  mean_inference_ms: 2.2115379504068104
  mean_raw_obs_processing_ms: 0.49529947901801646
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03786826133728027
    StateBufferConnector_ms: 0.006955862045288086
    ViewRequirementAgentConnector_ms: 0.21963214874267578
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.36
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 3.0, 2.0, 2.0, 1.0, 5.0, 1.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0,
      3.0, 3.0, 4.0, 3.0, 4.0, 2.0, 5.0, 3.0, 1.0, 3.0, 3.0, 0.0, 3.0, 1.0, 2.0, 2.0,
      2.0, 3.0, 0.0, 1.0, 3.0, 2.0, 3.0, 2.0, 0.0, 4.0, 3.0, 3.0, 0.0, 2.0, 2.0, 5.0,
      2.0, 3.0, 2.0, 5.0, 5.0, 0.0, 2.0, 4.0, 2.0, 2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0,
      3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0,
      0.0, 2.0, 0.0, 1.0, 2.0, 5.0, 3.0, 1.0, 6.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 6.0,
      3.0, 0.0, 3.0, 6.0, 1.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11808024973406342
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04427905277001489
    mean_inference_ms: 2.2115379504068104
    mean_raw_obs_processing_ms: 0.49529947901801646
time_since_restore: 92.10958909988403
time_this_iter_s: 10.248615026473999
time_total_s: 92.10958909988403
timers:
  sample_time_ms: 0.474
  synch_weights_time_ms: 0.926
  training_iteration_time_ms: 4.601
timestamp: 1691994269
timesteps_total: 62050
training_iteration: 9
trial_id: default
train step: 10
agent_timesteps_total: 69000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03710055351257324
  StateBufferConnector_ms: 0.006866931915283203
  ViewRequirementAgentConnector_ms: 0.21815800666809082
counters:
  num_agent_steps_sampled: 69000
  num_agent_steps_trained: 52500
  num_env_steps_sampled: 69000
  num_env_steps_trained: 52500
  num_samples_added_to_queue: 69000
  num_training_step_calls_since_last_synch_worker_weights: 59
  num_weight_broadcasts: 1343
custom_metrics: {}
date: 2023-08-14_15-24-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.4
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 539
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.099999999999994
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.396060585975647
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -41.55674743652344
        total_loss: -40.65837097167969
        var_gnorm: 63.333744049072266
        vf_explained_var: 0.6567263603210449
        vf_loss: 15.757357597351074
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 105.0
  learner_queue:
    size_count: 111
    size_mean: 13.68
    size_quantiles: [10.0, 11.0, 14.0, 16.0, 16.0]
    size_std: 2.014348529922267
  num_agent_steps_sampled: 69000
  num_agent_steps_trained: 52500
  num_env_steps_sampled: 69000
  num_env_steps_trained: 52500
  num_samples_added_to_queue: 69000
  num_training_step_calls_since_last_synch_worker_weights: 59
  num_weight_broadcasts: 1343
  timing_breakdown:
    learner_dequeue_time_ms: 2898.204
    learner_grad_time_ms: 418.462
    learner_load_time_ms: 13.821
    learner_load_wait_time_ms: 3.302
iterations_since_restore: 10
node_ip: 127.0.0.1
num_agent_steps_sampled: 69000
num_agent_steps_trained: 52500
num_env_steps_sampled: 69000
num_env_steps_sampled_this_iter: 6950
num_env_steps_sampled_throughput_per_sec: 694.9939022599212
num_env_steps_trained: 52500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9938583912876
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 58.99333333333334
  ram_util_percent: 81.00666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1174928545553557
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04400821832124405
  mean_inference_ms: 2.1998676419791723
  mean_raw_obs_processing_ms: 0.49338842693893176
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03710055351257324
    StateBufferConnector_ms: 0.006866931915283203
    ViewRequirementAgentConnector_ms: 0.21815800666809082
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.4
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0,
      3.0, 4.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 5.0,
      3.0, 1.0, 6.0, 2.0, 1.0, 1.0, 3.0, 2.0, 0.0, 6.0, 3.0, 0.0, 3.0, 6.0, 1.0, 3.0,
      3.0, 3.0, 1.0, 0.0, 0.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 0.0, 6.0, 3.0, 3.0,
      1.0, 1.0, 1.0, 5.0, 4.0, 2.0, 4.0, 3.0, 8.0, 1.0, 1.0, 3.0, 3.0, 2.0, 3.0, 2.0,
      3.0, 2.0, 6.0, 2.0, 4.0, 2.0, 6.0, 3.0, 0.0, 5.0, 3.0, 6.0, 5.0, 3.0, 2.0, 3.0,
      0.0, 3.0, 1.0, 2.0, 2.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1174928545553557
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04400821832124405
    mean_inference_ms: 2.1998676419791723
    mean_raw_obs_processing_ms: 0.49338842693893176
time_since_restore: 102.3459222316742
time_this_iter_s: 10.236333131790161
time_total_s: 102.3459222316742
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.09
timestamp: 1691994280
timesteps_total: 69000
training_iteration: 10
trial_id: default
train step: 11
agent_timesteps_total: 76650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03542947769165039
  StateBufferConnector_ms: 0.006594181060791016
  ViewRequirementAgentConnector_ms: 0.21082663536071777
counters:
  num_agent_steps_sampled: 76650
  num_agent_steps_trained: 60000
  num_env_steps_sampled: 76650
  num_env_steps_trained: 60000
  num_samples_added_to_queue: 76500
  num_training_step_calls_since_last_synch_worker_weights: 887
  num_weight_broadcasts: 1492
custom_metrics: {}
date: 2023-08-14_15-24-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.68
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 599
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.2656546831130981
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 16.562002182006836
        total_loss: 18.238834381103516
        var_gnorm: 63.33726119995117
        vf_explained_var: 0.5518242716789246
        vf_loss: 16.01021385192871
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 120.0
  learner_queue:
    size_count: 125
    size_mean: 14.22
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.8685823503394223
  num_agent_steps_sampled: 76650
  num_agent_steps_trained: 60000
  num_env_steps_sampled: 76650
  num_env_steps_trained: 60000
  num_samples_added_to_queue: 76500
  num_training_step_calls_since_last_synch_worker_weights: 887
  num_weight_broadcasts: 1492
  timing_breakdown:
    learner_dequeue_time_ms: 2576.182
    learner_grad_time_ms: 378.55
    learner_load_time_ms: 13.018
    learner_load_wait_time_ms: 3.219
iterations_since_restore: 11
node_ip: 127.0.0.1
num_agent_steps_sampled: 76650
num_agent_steps_trained: 60000
num_env_steps_sampled: 76650
num_env_steps_sampled_this_iter: 7650
num_env_steps_sampled_throughput_per_sec: 764.9974647844409
num_env_steps_trained: 60000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9975144945499
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 56.978571428571435
  ram_util_percent: 79.48571428571427
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11676165010940558
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04365666116764768
  mean_inference_ms: 2.1850779308323958
  mean_raw_obs_processing_ms: 0.49055230486089235
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03542947769165039
    StateBufferConnector_ms: 0.006594181060791016
    ViewRequirementAgentConnector_ms: 0.21082663536071777
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.68
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 1.0, 1.0, 1.0, 5.0, 4.0, 2.0, 4.0, 3.0, 8.0, 1.0, 1.0, 3.0,
      3.0, 2.0, 3.0, 2.0, 3.0, 2.0, 6.0, 2.0, 4.0, 2.0, 6.0, 3.0, 0.0, 5.0, 3.0, 6.0,
      5.0, 3.0, 2.0, 3.0, 0.0, 3.0, 1.0, 2.0, 2.0, 4.0, 2.0, 4.0, 0.0, 4.0, 1.0, 5.0,
      4.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 3.0, 3.0, 3.0, 4.0, 5.0, 1.0, 1.0, 1.0, 3.0,
      1.0, 3.0, 2.0, 3.0, 4.0, 0.0, 2.0, 2.0, 1.0, 4.0, 2.0, 4.0, 0.0, 1.0, 0.0, 3.0,
      1.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 8.0, 4.0, 3.0, 2.0, 2.0, 2.0,
      3.0, 4.0, 4.0, 2.0, 4.0, 7.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11676165010940558
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04365666116764768
    mean_inference_ms: 2.1850779308323958
    mean_raw_obs_processing_ms: 0.49055230486089235
time_since_restore: 112.55886435508728
time_this_iter_s: 10.212942123413086
time_total_s: 112.55886435508728
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691994290
timesteps_total: 76650
training_iteration: 11
trial_id: default
train step: 12
agent_timesteps_total: 83750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03503298759460449
  StateBufferConnector_ms: 0.006713390350341797
  ViewRequirementAgentConnector_ms: 0.20782804489135742
counters:
  num_agent_steps_sampled: 83750
  num_agent_steps_trained: 67000
  num_env_steps_sampled: 83750
  num_env_steps_trained: 67000
  num_samples_added_to_queue: 83500
  num_training_step_calls_since_last_synch_worker_weights: 338
  num_weight_broadcasts: 1631
custom_metrics: {}
date: 2023-08-14_15-25-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.61
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 655
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.067087173461914
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 12.105362892150879
        total_loss: 20.35344696044922
        var_gnorm: 63.342350006103516
        vf_explained_var: 0.6624785661697388
        vf_loss: 27.16703987121582
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 134.0
  learner_queue:
    size_count: 140
    size_mean: 14.44
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7338973441354595
  num_agent_steps_sampled: 83750
  num_agent_steps_trained: 67000
  num_env_steps_sampled: 83750
  num_env_steps_trained: 67000
  num_samples_added_to_queue: 83500
  num_training_step_calls_since_last_synch_worker_weights: 338
  num_weight_broadcasts: 1631
  timing_breakdown:
    learner_dequeue_time_ms: 2318.566
    learner_grad_time_ms: 340.489
    learner_load_time_ms: 11.821
    learner_load_wait_time_ms: 2.649
iterations_since_restore: 12
node_ip: 127.0.0.1
num_agent_steps_sampled: 83750
num_agent_steps_trained: 67000
num_env_steps_sampled: 83750
num_env_steps_sampled_this_iter: 7100
num_env_steps_sampled_throughput_per_sec: 709.9952433427959
num_env_steps_trained: 67000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9953103379678
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 63.21333333333333
  ram_util_percent: 79.44666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11622589975577276
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04340519706595914
  mean_inference_ms: 2.174737611148022
  mean_raw_obs_processing_ms: 0.48833127059825077
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03503298759460449
    StateBufferConnector_ms: 0.006713390350341797
    ViewRequirementAgentConnector_ms: 0.20782804489135742
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.61
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 1.0, 1.0, 1.0, 3.0, 1.0, 3.0, 2.0, 3.0, 4.0, 0.0, 2.0, 2.0,
      1.0, 4.0, 2.0, 4.0, 0.0, 1.0, 0.0, 3.0, 1.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0,
      4.0, 2.0, 8.0, 4.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 4.0, 7.0, 3.0, 1.0,
      3.0, 3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 4.0, 4.0, 6.0, 4.0, 3.0, 5.0, 4.0,
      3.0, 5.0, 3.0, 6.0, 3.0, 1.0, 4.0, 2.0, 3.0, 0.0, 2.0, 3.0, 3.0, 2.0, 3.0, 4.0,
      3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 4.0, 3.0, 2.0,
      1.0, 0.0, 2.0, 0.0, 5.0, 5.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11622589975577276
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04340519706595914
    mean_inference_ms: 2.174737611148022
    mean_raw_obs_processing_ms: 0.48833127059825077
time_since_restore: 122.81753945350647
time_this_iter_s: 10.25867509841919
time_total_s: 122.81753945350647
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.076
timestamp: 1691994300
timesteps_total: 83750
training_iteration: 12
trial_id: default
train step: 13
agent_timesteps_total: 89650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03932929039001465
  StateBufferConnector_ms: 0.007385969161987305
  ViewRequirementAgentConnector_ms: 0.2310466766357422
counters:
  num_agent_steps_sampled: 89650
  num_agent_steps_trained: 73000
  num_env_steps_sampled: 89650
  num_env_steps_trained: 73000
  num_samples_added_to_queue: 89500
  num_training_step_calls_since_last_synch_worker_weights: 124
  num_weight_broadcasts: 1746
custom_metrics: {}
date: 2023-08-14_15-25-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.88
episode_reward_min: 0.0
episodes_this_iter: 46
episodes_total: 701
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.07398521900177
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.4186912775039673
        total_loss: 12.002416610717773
        var_gnorm: 63.34574890136719
        vf_explained_var: 0.5455264449119568
        vf_loss: 33.90730285644531
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 146.0
  learner_queue:
    size_count: 152
    size_mean: 14.46
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7459667808981933
  num_agent_steps_sampled: 89650
  num_agent_steps_trained: 73000
  num_env_steps_sampled: 89650
  num_env_steps_trained: 73000
  num_samples_added_to_queue: 89500
  num_training_step_calls_since_last_synch_worker_weights: 124
  num_weight_broadcasts: 1746
  timing_breakdown:
    learner_dequeue_time_ms: 2261.665
    learner_grad_time_ms: 682.093
    learner_load_time_ms: 24.266
    learner_load_wait_time_ms: 16.964
iterations_since_restore: 13
node_ip: 127.0.0.1
num_agent_steps_sampled: 89650
num_agent_steps_trained: 73000
num_env_steps_sampled: 89650
num_env_steps_sampled_this_iter: 5900
num_env_steps_sampled_throughput_per_sec: 589.9929808021207
num_env_steps_trained: 73000
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9928618326651
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 72.21428571428571
  ram_util_percent: 80.39999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11674925037226704
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04364150978241673
  mean_inference_ms: 2.1872752942674873
  mean_raw_obs_processing_ms: 0.49077748229199253
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03932929039001465
    StateBufferConnector_ms: 0.007385969161987305
    ViewRequirementAgentConnector_ms: 0.2310466766357422
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.88
  episode_reward_min: 0.0
  episodes_this_iter: 46
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 4.0, 4.0, 6.0, 4.0, 3.0,
      5.0, 4.0, 3.0, 5.0, 3.0, 6.0, 3.0, 1.0, 4.0, 2.0, 3.0, 0.0, 2.0, 3.0, 3.0, 2.0,
      3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 4.0,
      3.0, 2.0, 1.0, 0.0, 2.0, 0.0, 5.0, 5.0, 2.0, 5.0, 2.0, 6.0, 1.0, 2.0, 4.0, 4.0,
      4.0, 4.0, 3.0, 6.0, 2.0, 2.0, 2.0, 6.0, 4.0, 1.0, 4.0, 1.0, 4.0, 1.0, 4.0, 4.0,
      3.0, 2.0, 2.0, 4.0, 4.0, 1.0, 5.0, 2.0, 3.0, 4.0, 3.0, 2.0, 4.0, 4.0, 2.0, 3.0,
      3.0, 2.0, 2.0, 2.0, 1.0, 6.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11674925037226704
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04364150978241673
    mean_inference_ms: 2.1872752942674873
    mean_raw_obs_processing_ms: 0.49077748229199253
time_since_restore: 133.12091851234436
time_this_iter_s: 10.30337905883789
time_total_s: 133.12091851234436
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.106
timestamp: 1691994311
timesteps_total: 89650
training_iteration: 13
trial_id: default
train step: 14
agent_timesteps_total: 96150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04139447212219238
  StateBufferConnector_ms: 0.007378816604614258
  ViewRequirementAgentConnector_ms: 0.24440741539001465
counters:
  num_agent_steps_sampled: 96150
  num_agent_steps_trained: 79500
  num_env_steps_sampled: 96150
  num_env_steps_trained: 79500
  num_samples_added_to_queue: 96000
  num_training_step_calls_since_last_synch_worker_weights: 904
  num_weight_broadcasts: 1873
custom_metrics: {}
date: 2023-08-14_15-25-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 3.05
episode_reward_min: 0.0
episodes_this_iter: 50
episodes_total: 751
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1473795175552368
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.02218246459961
        total_loss: -7.637265205383301
        var_gnorm: 63.34670639038086
        vf_explained_var: 0.7149222493171692
        vf_loss: 24.243629455566406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 159.0
  learner_queue:
    size_count: 163
    size_mean: 14.52
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7690675509996785
  num_agent_steps_sampled: 96150
  num_agent_steps_trained: 79500
  num_env_steps_sampled: 96150
  num_env_steps_trained: 79500
  num_samples_added_to_queue: 96000
  num_training_step_calls_since_last_synch_worker_weights: 904
  num_weight_broadcasts: 1873
  timing_breakdown:
    learner_dequeue_time_ms: 869.278
    learner_grad_time_ms: 975.259
    learner_load_time_ms: 20.61
    learner_load_wait_time_ms: 26.384
iterations_since_restore: 14
node_ip: 127.0.0.1
num_agent_steps_sampled: 96150
num_agent_steps_trained: 79500
num_env_steps_sampled: 96150
num_env_steps_sampled_this_iter: 6500
num_env_steps_sampled_throughput_per_sec: 649.9951339132298
num_env_steps_trained: 79500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9951339132298
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 62.03333333333333
  ram_util_percent: 80.22
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11773615203772239
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.044076162841305215
  mean_inference_ms: 2.2056213619170846
  mean_raw_obs_processing_ms: 0.49475409202470333
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04139447212219238
    StateBufferConnector_ms: 0.007378816604614258
    ViewRequirementAgentConnector_ms: 0.24440741539001465
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 3.05
  episode_reward_min: 0.0
  episodes_this_iter: 50
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 5.0, 5.0, 2.0, 5.0, 2.0, 6.0, 1.0, 2.0, 4.0, 4.0, 4.0, 4.0,
      3.0, 6.0, 2.0, 2.0, 2.0, 6.0, 4.0, 1.0, 4.0, 1.0, 4.0, 1.0, 4.0, 4.0, 3.0, 2.0,
      2.0, 4.0, 4.0, 1.0, 5.0, 2.0, 3.0, 4.0, 3.0, 2.0, 4.0, 4.0, 2.0, 3.0, 3.0, 2.0,
      2.0, 2.0, 1.0, 6.0, 3.0, 3.0, 6.0, 1.0, 2.0, 6.0, 3.0, 7.0, 4.0, 3.0, 3.0, 0.0,
      4.0, 2.0, 0.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 4.0, 2.0, 1.0, 4.0,
      1.0, 3.0, 6.0, 2.0, 4.0, 1.0, 5.0, 1.0, 5.0, 3.0, 1.0, 3.0, 3.0, 3.0, 5.0, 5.0,
      3.0, 4.0, 2.0, 4.0, 3.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11773615203772239
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.044076162841305215
    mean_inference_ms: 2.2056213619170846
    mean_raw_obs_processing_ms: 0.49475409202470333
time_since_restore: 143.32731437683105
time_this_iter_s: 10.206395864486694
time_total_s: 143.32731437683105
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1691994321
timesteps_total: 96150
training_iteration: 14
trial_id: default
train step: 15
agent_timesteps_total: 102800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04010272026062012
  StateBufferConnector_ms: 0.0071256160736083984
  ViewRequirementAgentConnector_ms: 0.2336430549621582
counters:
  num_agent_steps_sampled: 102800
  num_agent_steps_trained: 86000
  num_env_steps_sampled: 102800
  num_env_steps_trained: 86000
  num_samples_added_to_queue: 102500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 2002
custom_metrics: {}
date: 2023-08-14_15-25-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.26
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 803
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 29.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1680021286010742
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.1547825336456299
        total_loss: 4.818332195281982
        var_gnorm: 63.35206604003906
        vf_explained_var: 0.7615919709205627
        vf_loss: 23.626249313354492
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 172.0
  learner_queue:
    size_count: 176
    size_mean: 14.56
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.768162888424028
  num_agent_steps_sampled: 102800
  num_agent_steps_trained: 86000
  num_env_steps_sampled: 102800
  num_env_steps_trained: 86000
  num_samples_added_to_queue: 102500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 2002
  timing_breakdown:
    learner_dequeue_time_ms: 279.985
    learner_grad_time_ms: 461.363
    learner_load_time_ms: 20.573
    learner_load_wait_time_ms: 2.951
iterations_since_restore: 15
node_ip: 127.0.0.1
num_agent_steps_sampled: 102800
num_agent_steps_trained: 86000
num_env_steps_sampled: 102800
num_env_steps_sampled_this_iter: 6650
num_env_steps_sampled_throughput_per_sec: 664.8581294951682
num_env_steps_trained: 86000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.8613295817433
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 69.04285714285716
  ram_util_percent: 78.87142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11813197591765352
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04420211198340098
  mean_inference_ms: 2.213320644150203
  mean_raw_obs_processing_ms: 0.4970969310752858
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04010272026062012
    StateBufferConnector_ms: 0.0071256160736083984
    ViewRequirementAgentConnector_ms: 0.2336430549621582
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.26
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 6.0, 3.0, 7.0, 4.0, 3.0, 3.0, 0.0, 4.0, 2.0, 0.0, 2.0,
      3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0, 4.0, 2.0, 1.0, 4.0, 1.0, 3.0, 6.0, 2.0,
      4.0, 1.0, 5.0, 1.0, 5.0, 3.0, 1.0, 3.0, 3.0, 3.0, 5.0, 5.0, 3.0, 4.0, 2.0, 4.0,
      3.0, 3.0, 1.0, 4.0, 5.0, 3.0, 4.0, 1.0, 0.0, 6.0, 3.0, 4.0, 8.0, 4.0, 4.0, 3.0,
      1.0, 3.0, 2.0, 3.0, 5.0, 8.0, 7.0, 3.0, 6.0, 2.0, 3.0, 6.0, 2.0, 8.0, 4.0, 2.0,
      3.0, 6.0, 2.0, 3.0, 3.0, 1.0, 4.0, 4.0, 4.0, 3.0, 6.0, 4.0, 3.0, 1.0, 2.0, 3.0,
      1.0, 2.0, 2.0, 2.0, 5.0, 2.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11813197591765352
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04420211198340098
    mean_inference_ms: 2.213320644150203
    mean_raw_obs_processing_ms: 0.4970969310752858
time_since_restore: 153.48723340034485
time_this_iter_s: 10.159919023513794
time_total_s: 153.48723340034485
timers:
  sample_time_ms: 0.093
  synch_weights_time_ms: 0.357
  training_iteration_time_ms: 0.552
timestamp: 1691994331
timesteps_total: 102800
training_iteration: 15
trial_id: default
train step: 16
agent_timesteps_total: 109900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03713250160217285
  StateBufferConnector_ms: 0.0065441131591796875
  ViewRequirementAgentConnector_ms: 0.2198486328125
counters:
  num_agent_steps_sampled: 109900
  num_agent_steps_trained: 93000
  num_env_steps_sampled: 109900
  num_env_steps_trained: 93000
  num_samples_added_to_queue: 109500
  num_training_step_calls_since_last_synch_worker_weights: 34
  num_weight_broadcasts: 2142
custom_metrics: {}
date: 2023-08-14_15-25-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.48
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 859
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 30.69999999999999
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.068097710609436
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -3.887178421020508
        total_loss: 1.3332219123840332
        var_gnorm: 63.36054611206055
        vf_explained_var: 0.797417402267456
        vf_loss: 21.121776580810547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 186.0
  learner_queue:
    size_count: 193
    size_mean: 14.66
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7956614380222125
  num_agent_steps_sampled: 109900
  num_agent_steps_trained: 93000
  num_env_steps_sampled: 109900
  num_env_steps_trained: 93000
  num_samples_added_to_queue: 109500
  num_training_step_calls_since_last_synch_worker_weights: 34
  num_weight_broadcasts: 2142
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 322.784
    learner_load_time_ms: 20.447
    learner_load_wait_time_ms: 3.06
iterations_since_restore: 16
node_ip: 127.0.0.1
num_agent_steps_sampled: 109900
num_agent_steps_trained: 93000
num_env_steps_sampled: 109900
num_env_steps_sampled_this_iter: 7100
num_env_steps_sampled_throughput_per_sec: 709.9958188780007
num_env_steps_trained: 93000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9958777670429
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 56.02142857142856
  ram_util_percent: 77.79285714285716
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11810640876716055
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0441684182272658
  mean_inference_ms: 2.2120962236385715
  mean_raw_obs_processing_ms: 0.49739717678545575
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03713250160217285
    StateBufferConnector_ms: 0.0065441131591796875
    ViewRequirementAgentConnector_ms: 0.2198486328125
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.48
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 8.0, 4.0, 4.0, 3.0, 1.0, 3.0, 2.0, 3.0, 5.0, 8.0, 7.0, 3.0,
      6.0, 2.0, 3.0, 6.0, 2.0, 8.0, 4.0, 2.0, 3.0, 6.0, 2.0, 3.0, 3.0, 1.0, 4.0, 4.0,
      4.0, 3.0, 6.0, 4.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 5.0, 2.0, 5.0, 3.0,
      0.0, 3.0, 2.0, 2.0, 5.0, 4.0, 2.0, 2.0, 3.0, 1.0, 2.0, 4.0, 5.0, 4.0, 3.0, 3.0,
      4.0, 4.0, 5.0, 5.0, 4.0, 6.0, 2.0, 3.0, 4.0, 5.0, 5.0, 3.0, 3.0, 7.0, 6.0, 2.0,
      1.0, 4.0, 4.0, 1.0, 5.0, 3.0, 3.0, 8.0, 1.0, 4.0, 4.0, 1.0, 1.0, 3.0, 4.0, 5.0,
      6.0, 1.0, 4.0, 2.0, 4.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11810640876716055
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0441684182272658
    mean_inference_ms: 2.2120962236385715
    mean_raw_obs_processing_ms: 0.49739717678545575
time_since_restore: 163.77663731575012
time_this_iter_s: 10.289403915405273
time_total_s: 163.77663731575012
timers:
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.088
timestamp: 1691994341
timesteps_total: 109900
training_iteration: 16
trial_id: default
train step: 17
agent_timesteps_total: 117700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0349273681640625
  StateBufferConnector_ms: 0.006283760070800781
  ViewRequirementAgentConnector_ms: 0.2102491855621338
counters:
  num_agent_steps_sampled: 117700
  num_agent_steps_trained: 101000
  num_env_steps_sampled: 117700
  num_env_steps_trained: 101000
  num_samples_added_to_queue: 117500
  num_training_step_calls_since_last_synch_worker_weights: 121
  num_weight_broadcasts: 2295
custom_metrics: {}
date: 2023-08-14_15-25-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.47
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 920
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.020483374595642
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 21.38279151916504
        total_loss: 28.981094360351562
        var_gnorm: 63.37247848510742
        vf_explained_var: 0.8746247887611389
        vf_loss: 25.401437759399414
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 202.0
  learner_queue:
    size_count: 209
    size_mean: 14.62
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.798777362543792
  num_agent_steps_sampled: 117700
  num_agent_steps_trained: 101000
  num_env_steps_sampled: 117700
  num_env_steps_trained: 101000
  num_samples_added_to_queue: 117500
  num_training_step_calls_since_last_synch_worker_weights: 121
  num_weight_broadcasts: 2295
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 230.907
    learner_load_time_ms: 20.488
    learner_load_wait_time_ms: 2.702
iterations_since_restore: 17
node_ip: 127.0.0.1
num_agent_steps_sampled: 117700
num_agent_steps_trained: 101000
num_env_steps_sampled: 117700
num_env_steps_sampled_this_iter: 7800
num_env_steps_sampled_throughput_per_sec: 779.9971175300308
num_env_steps_trained: 101000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9970436205444
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 53.980000000000004
  ram_util_percent: 77.74666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11748645090396562
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.043915317044659286
  mean_inference_ms: 2.1989394900467856
  mean_raw_obs_processing_ms: 0.49457535992568147
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0349273681640625
    StateBufferConnector_ms: 0.006283760070800781
    ViewRequirementAgentConnector_ms: 0.2102491855621338
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.47
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 4.0, 5.0, 5.0, 4.0, 6.0, 2.0, 3.0, 4.0, 5.0, 5.0, 3.0, 3.0,
      7.0, 6.0, 2.0, 1.0, 4.0, 4.0, 1.0, 5.0, 3.0, 3.0, 8.0, 1.0, 4.0, 4.0, 1.0, 1.0,
      3.0, 4.0, 5.0, 6.0, 1.0, 4.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 1.0, 2.0,
      4.0, 2.0, 5.0, 3.0, 5.0, 4.0, 3.0, 6.0, 4.0, 3.0, 4.0, 3.0, 4.0, 4.0, 5.0, 4.0,
      2.0, 3.0, 0.0, 5.0, 1.0, 0.0, 1.0, 2.0, 6.0, 2.0, 2.0, 1.0, 4.0, 3.0, 2.0, 8.0,
      6.0, 1.0, 5.0, 1.0, 3.0, 3.0, 4.0, 8.0, 7.0, 3.0, 2.0, 1.0, 2.0, 7.0, 3.0, 3.0,
      2.0, 3.0, 4.0, 4.0, 0.0, 6.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11748645090396562
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.043915317044659286
    mean_inference_ms: 2.1989394900467856
    mean_raw_obs_processing_ms: 0.49457535992568147
time_since_restore: 174.05535221099854
time_this_iter_s: 10.278714895248413
time_total_s: 174.05535221099854
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1691994352
timesteps_total: 117700
training_iteration: 17
trial_id: default
train step: 18
agent_timesteps_total: 122700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04082965850830078
  StateBufferConnector_ms: 0.007754087448120117
  ViewRequirementAgentConnector_ms: 0.24140000343322754
counters:
  num_agent_steps_sampled: 122700
  num_agent_steps_trained: 106000
  num_env_steps_sampled: 122700
  num_env_steps_trained: 106000
  num_samples_added_to_queue: 122500
  num_training_step_calls_since_last_synch_worker_weights: 534
  num_weight_broadcasts: 2392
custom_metrics: {}
date: 2023-08-14_15-26-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.14
episode_reward_min: 0.0
episodes_this_iter: 39
episodes_total: 959
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9470083713531494
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -15.287195205688477
        total_loss: -4.268675804138184
        var_gnorm: 63.381038665771484
        vf_explained_var: 0.8589134216308594
        vf_loss: 31.507122039794922
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 212.0
  learner_queue:
    size_count: 218
    size_mean: 14.38
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.9067249408344142
  num_agent_steps_sampled: 122700
  num_agent_steps_trained: 106000
  num_env_steps_sampled: 122700
  num_env_steps_trained: 106000
  num_samples_added_to_queue: 122500
  num_training_step_calls_since_last_synch_worker_weights: 534
  num_weight_broadcasts: 2392
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 990.814
    learner_load_time_ms: 20.488
    learner_load_wait_time_ms: 38.306
iterations_since_restore: 18
node_ip: 127.0.0.1
num_agent_steps_sampled: 122700
num_agent_steps_trained: 106000
num_env_steps_sampled: 122700
num_env_steps_sampled_this_iter: 5000
num_env_steps_sampled_throughput_per_sec: 499.99719859739133
num_env_steps_trained: 106000
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.99719859739133
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 66.55714285714285
  ram_util_percent: 80.55
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11778356439761356
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04404859400374375
  mean_inference_ms: 2.206958736680872
  mean_raw_obs_processing_ms: 0.49599036305167543
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04082965850830078
    StateBufferConnector_ms: 0.007754087448120117
    ViewRequirementAgentConnector_ms: 0.24140000343322754
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.14
  episode_reward_min: 0.0
  episodes_this_iter: 39
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 4.0, 4.0, 1.0, 2.0, 4.0, 2.0, 5.0, 3.0, 5.0, 4.0, 3.0,
      6.0, 4.0, 3.0, 4.0, 3.0, 4.0, 4.0, 5.0, 4.0, 2.0, 3.0, 0.0, 5.0, 1.0, 0.0, 1.0,
      2.0, 6.0, 2.0, 2.0, 1.0, 4.0, 3.0, 2.0, 8.0, 6.0, 1.0, 5.0, 1.0, 3.0, 3.0, 4.0,
      8.0, 7.0, 3.0, 2.0, 1.0, 2.0, 7.0, 3.0, 3.0, 2.0, 3.0, 4.0, 4.0, 0.0, 6.0, 5.0,
      3.0, 6.0, 2.0, 2.0, 3.0, 5.0, 1.0, 3.0, 0.0, 3.0, 5.0, 2.0, 6.0, 1.0, 1.0, 3.0,
      2.0, 3.0, 3.0, 1.0, 0.0, 4.0, 2.0, 2.0, 5.0, 6.0, 2.0, 3.0, 4.0, 4.0, 3.0, 2.0,
      1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11778356439761356
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04404859400374375
    mean_inference_ms: 2.206958736680872
    mean_raw_obs_processing_ms: 0.49599036305167543
time_since_restore: 184.27813029289246
time_this_iter_s: 10.222778081893921
time_total_s: 184.27813029289246
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1691994362
timesteps_total: 122700
training_iteration: 18
trial_id: default
train step: 19
agent_timesteps_total: 130600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.040518760681152344
  StateBufferConnector_ms: 0.007698774337768555
  ViewRequirementAgentConnector_ms: 0.24134373664855957
counters:
  num_agent_steps_sampled: 130600
  num_agent_steps_trained: 114000
  num_env_steps_sampled: 130600
  num_env_steps_trained: 114000
  num_samples_added_to_queue: 130500
  num_training_step_calls_since_last_synch_worker_weights: 741
  num_weight_broadcasts: 2546
custom_metrics: {}
date: 2023-08-14_15-26-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.98
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 1021
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.80000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6926359534263611
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 13.906664848327637
        total_loss: 27.091747283935547
        var_gnorm: 63.38556671142578
        vf_explained_var: 0.850695788860321
        vf_loss: 33.29652404785156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 228.0
  learner_queue:
    size_count: 233
    size_mean: 14.16
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.9220822042774341
  num_agent_steps_sampled: 130600
  num_agent_steps_trained: 114000
  num_env_steps_sampled: 130600
  num_env_steps_trained: 114000
  num_samples_added_to_queue: 130500
  num_training_step_calls_since_last_synch_worker_weights: 741
  num_weight_broadcasts: 2546
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 351.133
    learner_load_time_ms: 16.469
    learner_load_wait_time_ms: 3.012
iterations_since_restore: 19
node_ip: 127.0.0.1
num_agent_steps_sampled: 130600
num_agent_steps_trained: 114000
num_env_steps_sampled: 130600
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.999453783413
num_env_steps_trained: 114000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9994468692789
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.58
  ram_util_percent: 77.75333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11834341018271094
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0442883853674602
  mean_inference_ms: 2.217251815194197
  mean_raw_obs_processing_ms: 0.4978150033090008
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.040518760681152344
    StateBufferConnector_ms: 0.007698774337768555
    ViewRequirementAgentConnector_ms: 0.24134373664855957
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.98
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 2.0, 2.0, 3.0, 5.0, 1.0, 3.0, 0.0, 3.0, 5.0, 2.0, 6.0, 1.0,
      1.0, 3.0, 2.0, 3.0, 3.0, 1.0, 0.0, 4.0, 2.0, 2.0, 5.0, 6.0, 2.0, 3.0, 4.0, 4.0,
      3.0, 2.0, 1.0, 2.0, 1.0, 4.0, 2.0, 4.0, 2.0, 3.0, 3.0, 4.0, 3.0, 6.0, 5.0, 2.0,
      3.0, 2.0, 7.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 6.0, 2.0, 2.0, 5.0, 0.0, 8.0, 1.0,
      2.0, 2.0, 3.0, 3.0, 4.0, 5.0, 6.0, 1.0, 1.0, 3.0, 2.0, 0.0, 4.0, 4.0, 0.0, 6.0,
      1.0, 1.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 4.0, 6.0, 5.0, 2.0, 4.0,
      1.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11834341018271094
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0442883853674602
    mean_inference_ms: 2.217251815194197
    mean_raw_obs_processing_ms: 0.4978150033090008
time_since_restore: 194.5274474620819
time_this_iter_s: 10.249317169189453
time_total_s: 194.5274474620819
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.089
timestamp: 1691994372
timesteps_total: 130600
training_iteration: 19
trial_id: default
train step: 20
agent_timesteps_total: 138200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0330810546875
  StateBufferConnector_ms: 0.006100893020629883
  ViewRequirementAgentConnector_ms: 0.20158863067626953
counters:
  num_agent_steps_sampled: 138200
  num_agent_steps_trained: 121500
  num_env_steps_sampled: 138200
  num_env_steps_trained: 121500
  num_samples_added_to_queue: 138000
  num_training_step_calls_since_last_synch_worker_weights: 538
  num_weight_broadcasts: 2695
custom_metrics: {}
date: 2023-08-14_15-26-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.43
episode_reward_min: 0.0
episodes_this_iter: 59
episodes_total: 1080
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7174959778785706
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.277179718017578
        total_loss: -17.338258743286133
        var_gnorm: 63.38998031616211
        vf_explained_var: 0.9530534744262695
        vf_loss: 5.052802085876465
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 243.0
  learner_queue:
    size_count: 248
    size_mean: 14.36
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8304097901836083
  num_agent_steps_sampled: 138200
  num_agent_steps_trained: 121500
  num_env_steps_sampled: 138200
  num_env_steps_trained: 121500
  num_samples_added_to_queue: 138000
  num_training_step_calls_since_last_synch_worker_weights: 538
  num_weight_broadcasts: 2695
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 367.099
    learner_load_time_ms: 16.372
    learner_load_wait_time_ms: 2.647
iterations_since_restore: 20
node_ip: 127.0.0.1
num_agent_steps_sampled: 138200
num_agent_steps_trained: 121500
num_env_steps_sampled: 138200
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9987859745345
num_env_steps_trained: 121500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9988019485538
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.114285714285714
  ram_util_percent: 76.5
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11772859835132515
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04400096537603493
  mean_inference_ms: 2.2023079940966634
  mean_raw_obs_processing_ms: 0.49471257561201043
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0330810546875
    StateBufferConnector_ms: 0.006100893020629883
    ViewRequirementAgentConnector_ms: 0.20158863067626953
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.43
  episode_reward_min: 0.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 5.0, 6.0, 1.0, 1.0, 3.0, 2.0,
      0.0, 4.0, 4.0, 0.0, 6.0, 1.0, 1.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0,
      4.0, 6.0, 5.0, 2.0, 4.0, 1.0, 3.0, 2.0, 4.0, 3.0, 2.0, 2.0, 1.0, 2.0, 4.0, 5.0,
      4.0, 4.0, 1.0, 2.0, 8.0, 2.0, 6.0, 5.0, 2.0, 3.0, 4.0, 7.0, 4.0, 4.0, 6.0, 6.0,
      2.0, 4.0, 5.0, 5.0, 4.0, 3.0, 3.0, 5.0, 3.0, 2.0, 2.0, 5.0, 5.0, 3.0, 2.0, 2.0,
      5.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 6.0, 3.0, 3.0, 5.0, 5.0, 2.0, 5.0, 5.0,
      5.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11772859835132515
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04400096537603493
    mean_inference_ms: 2.2023079940966634
    mean_raw_obs_processing_ms: 0.49471257561201043
time_since_restore: 204.7298617362976
time_this_iter_s: 10.202414274215698
time_total_s: 204.7298617362976
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.075
timestamp: 1691994382
timesteps_total: 138200
training_iteration: 20
trial_id: default
train step: 21
agent_timesteps_total: 146400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03156614303588867
  StateBufferConnector_ms: 0.005780458450317383
  ViewRequirementAgentConnector_ms: 0.19051504135131836
counters:
  num_agent_steps_sampled: 146400
  num_agent_steps_trained: 129500
  num_env_steps_sampled: 146400
  num_env_steps_trained: 129500
  num_samples_added_to_queue: 146000
  num_training_step_calls_since_last_synch_worker_weights: 300
  num_weight_broadcasts: 2855
custom_metrics: {}
date: 2023-08-14_15-26-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 4.1
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 1144
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8205953240394592
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.598237991333008
        total_loss: -5.663069248199463
        var_gnorm: 63.388031005859375
        vf_explained_var: 0.8567107319831848
        vf_loss: 14.07629108428955
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 259.0
  learner_queue:
    size_count: 265
    size_mean: 14.52
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7463103962354458
  num_agent_steps_sampled: 146400
  num_agent_steps_trained: 129500
  num_env_steps_sampled: 146400
  num_env_steps_trained: 129500
  num_samples_added_to_queue: 146000
  num_training_step_calls_since_last_synch_worker_weights: 300
  num_weight_broadcasts: 2855
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 312.121
    learner_load_time_ms: 16.367
    learner_load_wait_time_ms: 2.758
iterations_since_restore: 21
node_ip: 127.0.0.1
num_agent_steps_sampled: 146400
num_agent_steps_trained: 129500
num_env_steps_sampled: 146400
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9972825140412
num_env_steps_trained: 129500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9973487941866
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.053333333333335
  ram_util_percent: 77.46666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11680830804190993
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04359195322965597
  mean_inference_ms: 2.184986567223744
  mean_raw_obs_processing_ms: 0.49104557745947597
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03156614303588867
    StateBufferConnector_ms: 0.005780458450317383
    ViewRequirementAgentConnector_ms: 0.19051504135131836
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 4.1
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 4.0, 3.0, 3.0, 5.0, 3.0, 2.0, 2.0, 5.0, 5.0, 3.0, 2.0, 2.0,
      5.0, 3.0, 5.0, 2.0, 2.0, 2.0, 2.0, 3.0, 6.0, 3.0, 3.0, 5.0, 5.0, 2.0, 5.0, 5.0,
      5.0, 4.0, 3.0, 4.0, 3.0, 5.0, 5.0, 7.0, 7.0, 3.0, 3.0, 6.0, 6.0, 5.0, 5.0, 6.0,
      5.0, 8.0, 5.0, 3.0, 3.0, 3.0, 1.0, 5.0, 1.0, 1.0, 4.0, 0.0, 4.0, 3.0, 3.0, 8.0,
      3.0, 3.0, 3.0, 8.0, 1.0, 4.0, 4.0, 3.0, 7.0, 6.0, 4.0, 7.0, 2.0, 6.0, 4.0, 5.0,
      6.0, 2.0, 4.0, 3.0, 4.0, 5.0, 8.0, 1.0, 3.0, 8.0, 3.0, 4.0, 6.0, 6.0, 8.0, 2.0,
      4.0, 3.0, 6.0, 3.0, 5.0, 3.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11680830804190993
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04359195322965597
    mean_inference_ms: 2.184986567223744
    mean_raw_obs_processing_ms: 0.49104557745947597
time_since_restore: 214.95432090759277
time_this_iter_s: 10.224459171295166
time_total_s: 214.95432090759277
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.074
timestamp: 1691994392
timesteps_total: 146400
training_iteration: 21
trial_id: default
train step: 22
agent_timesteps_total: 153800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033071041107177734
  StateBufferConnector_ms: 0.0059812068939208984
  ViewRequirementAgentConnector_ms: 0.19739055633544922
counters:
  num_agent_steps_sampled: 153800
  num_agent_steps_trained: 137000
  num_env_steps_sampled: 153800
  num_env_steps_trained: 137000
  num_samples_added_to_queue: 153500
  num_training_step_calls_since_last_synch_worker_weights: 367
  num_weight_broadcasts: 3000
custom_metrics: {}
date: 2023-08-14_15-26-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.14
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 1202
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9225227236747742
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.550199508666992
        total_loss: 10.761964797973633
        var_gnorm: 63.38992691040039
        vf_explained_var: 0.8501595258712769
        vf_loss: 25.648757934570312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 274.0
  learner_queue:
    size_count: 281
    size_mean: 14.4
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8439088914585775
  num_agent_steps_sampled: 153800
  num_agent_steps_trained: 137000
  num_env_steps_sampled: 153800
  num_env_steps_trained: 137000
  num_samples_added_to_queue: 153500
  num_training_step_calls_since_last_synch_worker_weights: 367
  num_weight_broadcasts: 3000
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 283.25
    learner_load_time_ms: 15.905
    learner_load_wait_time_ms: 3.699
iterations_since_restore: 22
node_ip: 127.0.0.1
num_agent_steps_sampled: 153800
num_agent_steps_trained: 137000
num_env_steps_sampled: 153800
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.998288635397
num_env_steps_trained: 137000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9982655088484
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 57.135714285714286
  ram_util_percent: 76.60714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11626345411526362
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.043356884260731796
  mean_inference_ms: 2.1756028639726623
  mean_raw_obs_processing_ms: 0.48897897138606494
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033071041107177734
    StateBufferConnector_ms: 0.0059812068939208984
    ViewRequirementAgentConnector_ms: 0.19739055633544922
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.14
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 8.0, 3.0, 3.0, 3.0, 8.0, 1.0, 4.0, 4.0, 3.0, 7.0, 6.0,
      4.0, 7.0, 2.0, 6.0, 4.0, 5.0, 6.0, 2.0, 4.0, 3.0, 4.0, 5.0, 8.0, 1.0, 3.0, 8.0,
      3.0, 4.0, 6.0, 6.0, 8.0, 2.0, 4.0, 3.0, 6.0, 3.0, 5.0, 3.0, 7.0, 2.0, 2.0, 3.0,
      4.0, 3.0, 5.0, 3.0, 4.0, 8.0, 5.0, 7.0, 4.0, 3.0, 3.0, 3.0, 4.0, 4.0, 1.0, 2.0,
      6.0, 4.0, 6.0, 5.0, 3.0, 7.0, 4.0, 2.0, 3.0, 4.0, 3.0, 8.0, 6.0, 5.0, 4.0, 4.0,
      5.0, 3.0, 4.0, 2.0, 10.0, 5.0, 3.0, 3.0, 5.0, 1.0, 4.0, 1.0, 2.0, 5.0, 3.0,
      5.0, 4.0, 3.0, 4.0, 0.0, 0.0, 4.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11626345411526362
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.043356884260731796
    mean_inference_ms: 2.1756028639726623
    mean_raw_obs_processing_ms: 0.48897897138606494
time_since_restore: 225.3447070121765
time_this_iter_s: 10.39038610458374
time_total_s: 225.3447070121765
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.088
timestamp: 1691994403
timesteps_total: 153800
training_iteration: 22
trial_id: default
train step: 23
agent_timesteps_total: 161100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03653407096862793
  StateBufferConnector_ms: 0.006410121917724609
  ViewRequirementAgentConnector_ms: 0.2135310173034668
counters:
  num_agent_steps_sampled: 161100
  num_agent_steps_trained: 144500
  num_env_steps_sampled: 161100
  num_env_steps_trained: 144500
  num_samples_added_to_queue: 161000
  num_training_step_calls_since_last_synch_worker_weights: 1014
  num_weight_broadcasts: 3143
custom_metrics: {}
date: 2023-08-14_15-26-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.56
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 1259
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9932676553726196
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.721502304077148
        total_loss: 12.216076850891113
        var_gnorm: 63.40095138549805
        vf_explained_var: 0.9173128604888916
        vf_loss: 16.921825408935547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 289.0
  learner_queue:
    size_count: 294
    size_mean: 14.38
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.776400855662933
  num_agent_steps_sampled: 161100
  num_agent_steps_trained: 144500
  num_env_steps_sampled: 161100
  num_env_steps_trained: 144500
  num_samples_added_to_queue: 161000
  num_training_step_calls_since_last_synch_worker_weights: 1014
  num_weight_broadcasts: 3143
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 423.261
    learner_load_time_ms: 15.947
    learner_load_wait_time_ms: 2.98
iterations_since_restore: 23
node_ip: 127.0.0.1
num_agent_steps_sampled: 161100
num_agent_steps_trained: 144500
num_env_steps_sampled: 161100
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9962754439606
num_env_steps_trained: 144500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9961734013293
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 56.62142857142857
  ram_util_percent: 79.39999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11599074234714771
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.043255622308275295
  mean_inference_ms: 2.1717336180261477
  mean_raw_obs_processing_ms: 0.48801501558442767
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03653407096862793
    StateBufferConnector_ms: 0.006410121917724609
    ViewRequirementAgentConnector_ms: 0.2135310173034668
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.56
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 4.0, 1.0, 2.0, 6.0, 4.0, 6.0, 5.0, 3.0, 7.0, 4.0, 2.0, 3.0,
      4.0, 3.0, 8.0, 6.0, 5.0, 4.0, 4.0, 5.0, 3.0, 4.0, 2.0, 10.0, 5.0, 3.0, 3.0,
      5.0, 1.0, 4.0, 1.0, 2.0, 5.0, 3.0, 5.0, 4.0, 3.0, 4.0, 0.0, 0.0, 4.0, 6.0, 9.0,
      2.0, 4.0, 1.0, 3.0, 3.0, 3.0, 1.0, 5.0, 2.0, 2.0, 1.0, 1.0, 5.0, 5.0, 5.0, 3.0,
      4.0, 1.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 6.0, 4.0, 4.0, 4.0, 3.0, 3.0, 2.0,
      3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 4.0, 4.0, 1.0, 3.0, 2.0, 3.0, 5.0, 2.0, 5.0, 2.0,
      4.0, 6.0, 6.0, 3.0, 0.0, 4.0, 5.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11599074234714771
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.043255622308275295
    mean_inference_ms: 2.1717336180261477
    mean_raw_obs_processing_ms: 0.48801501558442767
time_since_restore: 235.5506820678711
time_this_iter_s: 10.20597505569458
time_total_s: 235.5506820678711
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.088
timestamp: 1691994413
timesteps_total: 161100
training_iteration: 23
trial_id: default
train step: 24
agent_timesteps_total: 167800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03716707229614258
  StateBufferConnector_ms: 0.006525516510009766
  ViewRequirementAgentConnector_ms: 0.2210550308227539
counters:
  num_agent_steps_sampled: 167800
  num_agent_steps_trained: 151000
  num_env_steps_sampled: 167800
  num_env_steps_trained: 151000
  num_samples_added_to_queue: 167500
  num_training_step_calls_since_last_synch_worker_weights: 1085
  num_weight_broadcasts: 3274
custom_metrics: {}
date: 2023-08-14_15-27-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.52
episode_reward_min: 0.0
episodes_this_iter: 53
episodes_total: 1312
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9958072304725647
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -28.83477020263672
        total_loss: -25.89137840270996
        var_gnorm: 63.4033088684082
        vf_explained_var: 0.8827607035636902
        vf_loss: 15.844857215881348
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 302.0
  learner_queue:
    size_count: 306
    size_mean: 14.58
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.70985379491932
  num_agent_steps_sampled: 167800
  num_agent_steps_trained: 151000
  num_env_steps_sampled: 167800
  num_env_steps_trained: 151000
  num_samples_added_to_queue: 167500
  num_training_step_calls_since_last_synch_worker_weights: 1085
  num_weight_broadcasts: 3274
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 628.748
    learner_load_time_ms: 2.549
    learner_load_wait_time_ms: 13.961
iterations_since_restore: 24
node_ip: 127.0.0.1
num_agent_steps_sampled: 167800
num_agent_steps_trained: 151000
num_env_steps_sampled: 167800
num_env_steps_sampled_this_iter: 6700
num_env_steps_sampled_throughput_per_sec: 669.9947765280741
num_env_steps_trained: 151000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9949324526093
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 58.78
  ram_util_percent: 79.88000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11598317350250546
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04330841447097008
  mean_inference_ms: 2.171950591741364
  mean_raw_obs_processing_ms: 0.48792968434128153
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03716707229614258
    StateBufferConnector_ms: 0.006525516510009766
    ViewRequirementAgentConnector_ms: 0.2210550308227539
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.52
  episode_reward_min: 0.0
  episodes_this_iter: 53
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 1.0, 1.0, 5.0, 5.0, 5.0, 3.0, 4.0, 1.0, 4.0, 4.0, 4.0, 4.0,
      4.0, 3.0, 3.0, 6.0, 4.0, 4.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0,
      4.0, 4.0, 1.0, 3.0, 2.0, 3.0, 5.0, 2.0, 5.0, 2.0, 4.0, 6.0, 6.0, 3.0, 0.0, 4.0,
      5.0, 2.0, 1.0, 1.0, 2.0, 8.0, 2.0, 4.0, 3.0, 4.0, 5.0, 7.0, 3.0, 2.0, 4.0, 7.0,
      4.0, 6.0, 3.0, 5.0, 3.0, 3.0, 8.0, 6.0, 4.0, 3.0, 1.0, 3.0, 1.0, 5.0, 2.0, 7.0,
      1.0, 7.0, 3.0, 4.0, 1.0, 1.0, 3.0, 6.0, 1.0, 5.0, 1.0, 1.0, 3.0, 7.0, 4.0, 6.0,
      3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11598317350250546
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04330841447097008
    mean_inference_ms: 2.171950591741364
    mean_raw_obs_processing_ms: 0.48792968434128153
time_since_restore: 245.71660780906677
time_this_iter_s: 10.165925741195679
time_total_s: 245.71660780906677
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.075
timestamp: 1691994423
timesteps_total: 167800
training_iteration: 24
trial_id: default
train step: 25
agent_timesteps_total: 176200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033421993255615234
  StateBufferConnector_ms: 0.00598907470703125
  ViewRequirementAgentConnector_ms: 0.20015645027160645
counters:
  num_agent_steps_sampled: 176200
  num_agent_steps_trained: 159500
  num_env_steps_sampled: 176200
  num_env_steps_trained: 159500
  num_samples_added_to_queue: 176000
  num_training_step_calls_since_last_synch_worker_weights: 228
  num_weight_broadcasts: 3439
custom_metrics: {}
date: 2023-08-14_15-27-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.06
episode_reward_min: 1.0
episodes_this_iter: 65
episodes_total: 1377
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.69385826587677
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 13.798646926879883
        total_loss: 19.610157012939453
        var_gnorm: 63.40979766845703
        vf_explained_var: 0.8477528095245361
        vf_loss: 18.561601638793945
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 319.0
  learner_queue:
    size_count: 326
    size_mean: 14.56
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.8017769007288333
  num_agent_steps_sampled: 176200
  num_agent_steps_trained: 159500
  num_env_steps_sampled: 176200
  num_env_steps_trained: 159500
  num_samples_added_to_queue: 176000
  num_training_step_calls_since_last_synch_worker_weights: 228
  num_weight_broadcasts: 3439
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 229.15
    learner_load_time_ms: 2.498
    learner_load_wait_time_ms: 2.544
iterations_since_restore: 25
node_ip: 127.0.0.1
num_agent_steps_sampled: 176200
num_agent_steps_trained: 159500
num_env_steps_sampled: 176200
num_env_steps_sampled_this_iter: 8400
num_env_steps_sampled_throughput_per_sec: 839.9942121904535
num_env_steps_trained: 159500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9941432879589
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 48.364285714285714
  ram_util_percent: 78.71428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11548225642743291
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04312074304620934
  mean_inference_ms: 2.161875344906634
  mean_raw_obs_processing_ms: 0.485687093423908
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033421993255615234
    StateBufferConnector_ms: 0.00598907470703125
    ViewRequirementAgentConnector_ms: 0.20015645027160645
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.06
  episode_reward_min: 1.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 8.0, 6.0, 4.0, 3.0, 1.0, 3.0, 1.0, 5.0, 2.0, 7.0, 1.0,
      7.0, 3.0, 4.0, 1.0, 1.0, 3.0, 6.0, 1.0, 5.0, 1.0, 1.0, 3.0, 7.0, 4.0, 6.0, 3.0,
      4.0, 3.0, 4.0, 4.0, 4.0, 3.0, 5.0, 3.0, 8.0, 5.0, 7.0, 6.0, 3.0, 4.0, 5.0, 7.0,
      5.0, 10.0, 2.0, 7.0, 3.0, 5.0, 7.0, 6.0, 2.0, 3.0, 4.0, 3.0, 3.0, 8.0, 6.0,
      1.0, 3.0, 3.0, 3.0, 7.0, 2.0, 7.0, 1.0, 3.0, 3.0, 5.0, 5.0, 3.0, 3.0, 8.0, 2.0,
      5.0, 3.0, 3.0, 6.0, 5.0, 2.0, 2.0, 3.0, 3.0, 3.0, 8.0, 3.0, 5.0, 2.0, 6.0, 5.0,
      3.0, 5.0, 4.0, 2.0, 5.0, 5.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11548225642743291
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04312074304620934
    mean_inference_ms: 2.161875344906634
    mean_raw_obs_processing_ms: 0.485687093423908
time_since_restore: 255.9502818584442
time_this_iter_s: 10.233674049377441
time_total_s: 255.9502818584442
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1691994434
timesteps_total: 176200
training_iteration: 25
trial_id: default
train step: 26
agent_timesteps_total: 185150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02812957763671875
  StateBufferConnector_ms: 0.005067586898803711
  ViewRequirementAgentConnector_ms: 0.16865134239196777
counters:
  num_agent_steps_sampled: 185150
  num_agent_steps_trained: 168500
  num_env_steps_sampled: 185150
  num_env_steps_trained: 168500
  num_samples_added_to_queue: 185000
  num_training_step_calls_since_last_synch_worker_weights: 94
  num_weight_broadcasts: 3614
custom_metrics: {}
date: 2023-08-14_15-27-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.09
episode_reward_min: 0.0
episodes_this_iter: 70
episodes_total: 1447
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 30.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6241302490234375
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.76637077331543
        total_loss: -0.14134788513183594
        var_gnorm: 63.42082214355469
        vf_explained_var: 0.7924861907958984
        vf_loss: 27.491348266601562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 337.0
  learner_queue:
    size_count: 343
    size_mean: 14.74
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7413787640832192
  num_agent_steps_sampled: 185150
  num_agent_steps_trained: 168500
  num_env_steps_sampled: 185150
  num_env_steps_trained: 168500
  num_samples_added_to_queue: 185000
  num_training_step_calls_since_last_synch_worker_weights: 94
  num_weight_broadcasts: 3614
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 188.035
    learner_load_time_ms: 2.396
    learner_load_wait_time_ms: 1.372
iterations_since_restore: 26
node_ip: 127.0.0.1
num_agent_steps_sampled: 185150
num_agent_steps_trained: 168500
num_env_steps_sampled: 185150
num_env_steps_sampled_this_iter: 8950
num_env_steps_sampled_throughput_per_sec: 894.9988263860834
num_env_steps_trained: 168500
num_env_steps_trained_this_iter: 9000
num_env_steps_trained_throughput_per_sec: 899.998819829581
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 9000
perf:
  cpu_util_percent: 55.22857142857142
  ram_util_percent: 78.50714285714285
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11426233041189818
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.042605582780656216
  mean_inference_ms: 2.1398001773449815
  mean_raw_obs_processing_ms: 0.4804220092602575
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02812957763671875
    StateBufferConnector_ms: 0.005067586898803711
    ViewRequirementAgentConnector_ms: 0.16865134239196777
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.09
  episode_reward_min: 0.0
  episodes_this_iter: 70
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 5.0, 3.0, 3.0, 8.0, 2.0, 5.0, 3.0, 3.0, 6.0, 5.0, 2.0, 2.0,
      3.0, 3.0, 3.0, 8.0, 3.0, 5.0, 2.0, 6.0, 5.0, 3.0, 5.0, 4.0, 2.0, 5.0, 5.0, 3.0,
      4.0, 2.0, 5.0, 2.0, 5.0, 6.0, 2.0, 4.0, 2.0, 2.0, 3.0, 1.0, 2.0, 9.0, 7.0, 5.0,
      5.0, 2.0, 3.0, 6.0, 6.0, 6.0, 3.0, 3.0, 5.0, 3.0, 7.0, 1.0, 3.0, 3.0, 2.0, 3.0,
      4.0, 2.0, 6.0, 2.0, 4.0, 3.0, 9.0, 5.0, 8.0, 5.0, 7.0, 3.0, 5.0, 4.0, 6.0, 3.0,
      6.0, 5.0, 6.0, 6.0, 5.0, 5.0, 2.0, 2.0, 6.0, 4.0, 7.0, 0.0, 4.0, 6.0, 0.0, 5.0,
      6.0, 1.0, 0.0, 6.0, 5.0, 5.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11426233041189818
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.042605582780656216
    mean_inference_ms: 2.1398001773449815
    mean_raw_obs_processing_ms: 0.4804220092602575
time_since_restore: 266.086788892746
time_this_iter_s: 10.136507034301758
time_total_s: 266.086788892746
timers:
  sample_time_ms: 0.013
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.038
timestamp: 1691994444
timesteps_total: 185150
training_iteration: 26
trial_id: default
train step: 27
agent_timesteps_total: 199750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01740978475202594
  StateBufferConnector_ms: 0.0029923623068290844
  ViewRequirementAgentConnector_ms: 0.11288366819682874
counters:
  num_agent_steps_sampled: 199750
  num_agent_steps_trained: 183000
  num_env_steps_sampled: 199750
  num_env_steps_trained: 183000
  num_samples_added_to_queue: 199500
  num_training_step_calls_since_last_synch_worker_weights: 148
  num_weight_broadcasts: 3902
custom_metrics: {}
date: 2023-08-14_15-27-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 4.254385964912281
episode_reward_min: 1.0
episodes_this_iter: 114
episodes_total: 1561
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7896729707717896
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.430200576782227
        total_loss: 5.742776393890381
        var_gnorm: 63.42973327636719
        vf_explained_var: 0.8543422222137451
        vf_loss: 34.24268341064453
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 366.0
  learner_queue:
    size_count: 373
    size_mean: 14.5
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.0024984394500787
  num_agent_steps_sampled: 199750
  num_agent_steps_trained: 183000
  num_env_steps_sampled: 199750
  num_env_steps_trained: 183000
  num_samples_added_to_queue: 199500
  num_training_step_calls_since_last_synch_worker_weights: 148
  num_weight_broadcasts: 3902
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 155.342
    learner_load_time_ms: 2.143
    learner_load_wait_time_ms: 1.39
iterations_since_restore: 27
node_ip: 127.0.0.1
num_agent_steps_sampled: 199750
num_agent_steps_trained: 183000
num_env_steps_sampled: 199750
num_env_steps_sampled_this_iter: 14600
num_env_steps_sampled_throughput_per_sec: 1459.9975285571927
num_env_steps_trained: 183000
num_env_steps_trained_this_iter: 14500
num_env_steps_trained_throughput_per_sec: 1449.9975454848832
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14500
perf:
  cpu_util_percent: 57.419999999999995
  ram_util_percent: 79.71333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10933029273100776
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04085933808018159
  mean_inference_ms: 2.0529814902439583
  mean_raw_obs_processing_ms: 0.4607441926830836
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01740978475202594
    StateBufferConnector_ms: 0.0029923623068290844
    ViewRequirementAgentConnector_ms: 0.11288366819682874
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 4.254385964912281
  episode_reward_min: 1.0
  episodes_this_iter: 114
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 3.0, 4.0, 3.0, 3.0, 6.0, 6.0, 4.0, 2.0, 2.0, 3.0, 5.0, 4.0,
      2.0, 2.0, 6.0, 5.0, 7.0, 4.0, 4.0, 2.0, 5.0, 6.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0,
      6.0, 7.0, 4.0, 4.0, 3.0, 5.0, 4.0, 4.0, 3.0, 3.0, 7.0, 4.0, 2.0, 4.0, 1.0, 7.0,
      5.0, 3.0, 5.0, 6.0, 6.0, 4.0, 6.0, 5.0, 4.0, 2.0, 2.0, 7.0, 5.0, 3.0, 2.0, 2.0,
      4.0, 3.0, 4.0, 7.0, 4.0, 3.0, 1.0, 6.0, 6.0, 4.0, 8.0, 6.0, 3.0, 5.0, 5.0, 1.0,
      2.0, 3.0, 8.0, 5.0, 1.0, 6.0, 4.0, 2.0, 5.0, 5.0, 4.0, 3.0, 5.0, 3.0, 6.0, 5.0,
      1.0, 7.0, 6.0, 5.0, 6.0, 3.0, 4.0, 7.0, 8.0, 4.0, 2.0, 3.0, 5.0, 6.0, 5.0, 4.0,
      3.0, 2.0, 6.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10933029273100776
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04085933808018159
    mean_inference_ms: 2.0529814902439583
    mean_raw_obs_processing_ms: 0.4607441926830836
time_since_restore: 276.2242727279663
time_this_iter_s: 10.137483835220337
time_total_s: 276.2242727279663
timers:
  sample_time_ms: 0.012
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.037
timestamp: 1691994454
timesteps_total: 199750
training_iteration: 27
trial_id: default
train step: 28
agent_timesteps_total: 213700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01805266109081583
  StateBufferConnector_ms: 0.0030322906074173954
  ViewRequirementAgentConnector_ms: 0.10822103657853713
counters:
  num_agent_steps_sampled: 213700
  num_agent_steps_trained: 197000
  num_env_steps_sampled: 213700
  num_env_steps_trained: 197000
  num_samples_added_to_queue: 213500
  num_training_step_calls_since_last_synch_worker_weights: 192
  num_weight_broadcasts: 4175
custom_metrics: {}
date: 2023-08-14_15-27-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.5596330275229358
episode_reward_min: 0.0
episodes_this_iter: 109
episodes_total: 1670
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8389872312545776
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 23.100196838378906
        total_loss: 35.557228088378906
        var_gnorm: 63.44123458862305
        vf_explained_var: 0.8516291975975037
        vf_loss: 33.303932189941406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 394.0
  learner_queue:
    size_count: 401
    size_mean: 14.88
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8616122045152153
  num_agent_steps_sampled: 213700
  num_agent_steps_trained: 197000
  num_env_steps_sampled: 213700
  num_env_steps_trained: 197000
  num_samples_added_to_queue: 213500
  num_training_step_calls_since_last_synch_worker_weights: 192
  num_weight_broadcasts: 4175
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 147.818
    learner_load_time_ms: 1.847
    learner_load_wait_time_ms: 1.386
iterations_since_restore: 28
node_ip: 127.0.0.1
num_agent_steps_sampled: 213700
num_agent_steps_trained: 197000
num_env_steps_sampled: 213700
num_env_steps_sampled_this_iter: 13950
num_env_steps_sampled_throughput_per_sec: 1394.9968071056967
num_env_steps_trained: 197000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.996795661631
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 58.40714285714285
  ram_util_percent: 78.95
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10579717817538502
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03962079116917917
  mean_inference_ms: 1.9896398603616166
  mean_raw_obs_processing_ms: 0.4463026233888901
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01805266109081583
    StateBufferConnector_ms: 0.0030322906074173954
    ViewRequirementAgentConnector_ms: 0.10822103657853713
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.5596330275229358
  episode_reward_min: 0.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [3.0, 3.0, 5.0, 0.0, 7.0, 3.0, 3.0, 2.0, 3.0, 3.0, 6.0, 4.0, 3.0,
      4.0, 4.0, 5.0, 3.0, 5.0, 4.0, 1.0, 3.0, 3.0, 3.0, 5.0, 3.0, 4.0, 4.0, 3.0, 2.0,
      6.0, 1.0, 1.0, 5.0, 7.0, 3.0, 6.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0, 1.0, 3.0, 6.0,
      5.0, 3.0, 5.0, 3.0, 5.0, 0.0, 4.0, 7.0, 5.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 5.0,
      4.0, 4.0, 4.0, 3.0, 3.0, 1.0, 3.0, 5.0, 2.0, 6.0, 5.0, 3.0, 3.0, 4.0, 3.0, 2.0,
      3.0, 5.0, 3.0, 2.0, 2.0, 5.0, 3.0, 5.0, 4.0, 3.0, 3.0, 2.0, 1.0, 5.0, 3.0, 4.0,
      5.0, 4.0, 2.0, 5.0, 4.0, 0.0, 9.0, 7.0, 5.0, 3.0, 2.0, 1.0, 2.0, 4.0, 5.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10579717817538502
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03962079116917917
    mean_inference_ms: 1.9896398603616166
    mean_raw_obs_processing_ms: 0.4463026233888901
time_since_restore: 286.3753447532654
time_this_iter_s: 10.151072025299072
time_total_s: 286.3753447532654
timers:
  sample_time_ms: 0.012
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.039
timestamp: 1691994464
timesteps_total: 213700
training_iteration: 28
trial_id: default
train step: 29
agent_timesteps_total: 228000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01767831189291818
  StateBufferConnector_ms: 0.0030240842274257113
  ViewRequirementAgentConnector_ms: 0.10483264923095703
counters:
  num_agent_steps_sampled: 228000
  num_agent_steps_trained: 211500
  num_env_steps_sampled: 228000
  num_env_steps_trained: 211500
  num_samples_added_to_queue: 228000
  num_training_step_calls_since_last_synch_worker_weights: 2531
  num_weight_broadcasts: 4454
custom_metrics: {}
date: 2023-08-14_15-27-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.053571428571429
episode_reward_min: 0.0
episodes_this_iter: 112
episodes_total: 1782
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9174046516418457
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.3364112377166748
        total_loss: 2.540052890777588
        var_gnorm: 63.45490264892578
        vf_explained_var: 0.924845814704895
        vf_loss: 11.581329345703125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 423.0
  learner_queue:
    size_count: 427
    size_mean: 15.28
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4702380759591285
  num_agent_steps_sampled: 228000
  num_agent_steps_trained: 211500
  num_env_steps_sampled: 228000
  num_env_steps_trained: 211500
  num_samples_added_to_queue: 228000
  num_training_step_calls_since_last_synch_worker_weights: 2531
  num_weight_broadcasts: 4454
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 223.212
    learner_load_time_ms: 1.748
    learner_load_wait_time_ms: 1.534
iterations_since_restore: 29
node_ip: 127.0.0.1
num_agent_steps_sampled: 228000
num_agent_steps_trained: 211500
num_env_steps_sampled: 228000
num_env_steps_sampled_this_iter: 14300
num_env_steps_sampled_throughput_per_sec: 1429.9924312038486
num_env_steps_trained: 211500
num_env_steps_trained_this_iter: 14500
num_env_steps_trained_throughput_per_sec: 1449.99232534656
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14500
perf:
  cpu_util_percent: 57.792857142857144
  ram_util_percent: 78.52142857142859
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10256235401800584
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.038496504414406975
  mean_inference_ms: 1.9305849385728506
  mean_raw_obs_processing_ms: 0.4329647512543115
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01767831189291818
    StateBufferConnector_ms: 0.0030240842274257113
    ViewRequirementAgentConnector_ms: 0.10483264923095703
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.053571428571429
  episode_reward_min: 0.0
  episodes_this_iter: 112
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128]
    episode_reward: [5.0, 5.0, 3.0, 8.0, 1.0, 3.0, 7.0, 2.0, 9.0, 5.0, 6.0, 4.0, 4.0,
      11.0, 4.0, 1.0, 3.0, 7.0, 4.0, 3.0, 4.0, 5.0, 4.0, 1.0, 3.0, 7.0, 7.0, 4.0,
      5.0, 4.0, 8.0, 6.0, 4.0, 6.0, 1.0, 2.0, 1.0, 6.0, 5.0, 8.0, 2.0, 3.0, 6.0, 2.0,
      3.0, 2.0, 5.0, 3.0, 3.0, 3.0, 4.0, 0.0, 6.0, 6.0, 3.0, 5.0, 6.0, 0.0, 4.0, 5.0,
      4.0, 5.0, 7.0, 5.0, 3.0, 2.0, 4.0, 5.0, 5.0, 6.0, 4.0, 4.0, 5.0, 1.0, 7.0, 1.0,
      3.0, 5.0, 2.0, 2.0, 2.0, 5.0, 5.0, 2.0, 2.0, 4.0, 5.0, 2.0, 2.0, 3.0, 6.0, 4.0,
      3.0, 7.0, 3.0, 6.0, 5.0, 2.0, 7.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 6.0, 4.0, 6.0,
      8.0, 3.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10256235401800584
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.038496504414406975
    mean_inference_ms: 1.9305849385728506
    mean_raw_obs_processing_ms: 0.4329647512543115
time_since_restore: 296.48075795173645
time_this_iter_s: 10.10541319847107
time_total_s: 296.48075795173645
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691994474
timesteps_total: 228000
training_iteration: 29
trial_id: default
train step: 30
agent_timesteps_total: 240900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02089939495124439
  StateBufferConnector_ms: 0.0036905307580928992
  ViewRequirementAgentConnector_ms: 0.11931905652036762
counters:
  num_agent_steps_sampled: 240900
  num_agent_steps_trained: 224000
  num_env_steps_sampled: 240900
  num_env_steps_trained: 224000
  num_samples_added_to_queue: 240500
  num_training_step_calls_since_last_synch_worker_weights: 65
  num_weight_broadcasts: 4709
custom_metrics: {}
date: 2023-08-14_15-28-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.495049504950495
episode_reward_min: 0.0
episodes_this_iter: 101
episodes_total: 1883
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8139054775238037
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 15.42031192779541
        total_loss: 30.38406753540039
        var_gnorm: 63.473636627197266
        vf_explained_var: 0.7594732642173767
        vf_loss: 38.066566467285156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 448.0
  learner_queue:
    size_count: 455
    size_mean: 15.4
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3564659966250534
  num_agent_steps_sampled: 240900
  num_agent_steps_trained: 224000
  num_env_steps_sampled: 240900
  num_env_steps_trained: 224000
  num_samples_added_to_queue: 240500
  num_training_step_calls_since_last_synch_worker_weights: 65
  num_weight_broadcasts: 4709
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 159.342
    learner_load_time_ms: 1.556
    learner_load_wait_time_ms: 1.533
iterations_since_restore: 30
node_ip: 127.0.0.1
num_agent_steps_sampled: 240900
num_agent_steps_trained: 224000
num_env_steps_sampled: 240900
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9926493586731
num_env_steps_trained: 224000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.992877285536
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 58.71333333333333
  ram_util_percent: 80.06
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10035945045743845
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.037780228616065
  mean_inference_ms: 1.889768368985924
  mean_raw_obs_processing_ms: 0.4235929406409629
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02089939495124439
    StateBufferConnector_ms: 0.0036905307580928992
    ViewRequirementAgentConnector_ms: 0.11931905652036762
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.495049504950495
  episode_reward_min: 0.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 3.0, 2.0, 3.0, 0.0, 5.0, 3.0, 2.0, 3.0, 5.0, 0.0, 3.0,
      2.0, 2.0, 3.0, 4.0, 4.0, 2.0, 3.0, 5.0, 3.0, 6.0, 4.0, 4.0, 2.0, 6.0, 7.0, 4.0,
      4.0, 3.0, 3.0, 3.0, 5.0, 3.0, 2.0, 3.0, 3.0, 4.0, 6.0, 6.0, 4.0, 3.0, 5.0, 5.0,
      7.0, 8.0, 3.0, 5.0, 2.0, 3.0, 4.0, 2.0, 2.0, 1.0, 4.0, 4.0, 5.0, 1.0, 4.0, 5.0,
      4.0, 3.0, 5.0, 2.0, 3.0, 3.0, 2.0, 4.0, 7.0, 2.0, 3.0, 2.0, 2.0, 1.0, 7.0, 4.0,
      4.0, 4.0, 1.0, 5.0, 1.0, 5.0, 3.0, 1.0, 4.0, 3.0, 3.0, 6.0, 3.0, 4.0, 4.0, 6.0,
      2.0, 1.0, 3.0, 6.0, 4.0, 0.0, 6.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10035945045743845
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.037780228616065
    mean_inference_ms: 1.889768368985924
    mean_raw_obs_processing_ms: 0.4235929406409629
time_since_restore: 306.6308579444885
time_this_iter_s: 10.150099992752075
time_total_s: 306.6308579444885
timers:
  sample_time_ms: 0.013
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.041
timestamp: 1691994484
timesteps_total: 240900
training_iteration: 30
trial_id: default
train step: 31
agent_timesteps_total: 254150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019429262401988206
  StateBufferConnector_ms: 0.003479985357488243
  ViewRequirementAgentConnector_ms: 0.1174477697576134
counters:
  num_agent_steps_sampled: 254150
  num_agent_steps_trained: 237500
  num_env_steps_sampled: 254150
  num_env_steps_trained: 237500
  num_samples_added_to_queue: 254000
  num_training_step_calls_since_last_synch_worker_weights: 187
  num_weight_broadcasts: 4970
custom_metrics: {}
date: 2023-08-14_15-28-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.9320388349514563
episode_reward_min: 0.0
episodes_this_iter: 103
episodes_total: 1986
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.958016574382782
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.6461405754089355
        total_loss: 0.21180200576782227
        var_gnorm: 63.485469818115234
        vf_explained_var: 0.8644251227378845
        vf_loss: 25.296051025390625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 475.0
  learner_queue:
    size_count: 481
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6351146748775756
  num_agent_steps_sampled: 254150
  num_agent_steps_trained: 237500
  num_env_steps_sampled: 254150
  num_env_steps_trained: 237500
  num_samples_added_to_queue: 254000
  num_training_step_calls_since_last_synch_worker_weights: 187
  num_weight_broadcasts: 4970
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 185.442
    learner_load_time_ms: 1.339
    learner_load_wait_time_ms: 1.405
iterations_since_restore: 31
node_ip: 127.0.0.1
num_agent_steps_sampled: 254150
num_agent_steps_trained: 237500
num_env_steps_sampled: 254150
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.9972200452003
num_env_steps_trained: 237500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.997167593223
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 57.26428571428572
  ram_util_percent: 81.14285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.09819790731431413
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.037063473447845406
  mean_inference_ms: 1.8503064874785022
  mean_raw_obs_processing_ms: 0.41463344743558883
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019429262401988206
    StateBufferConnector_ms: 0.003479985357488243
    ViewRequirementAgentConnector_ms: 0.1174477697576134
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.9320388349514563
  episode_reward_min: 0.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 2.0, 4.0, 7.0, 2.0, 3.0, 0.0, 7.0, 3.0, 0.0, 1.0, 2.0, 6.0,
      3.0, 4.0, 4.0, 6.0, 6.0, 0.0, 4.0, 3.0, 3.0, 4.0, 4.0, 3.0, 2.0, 3.0, 5.0, 4.0,
      4.0, 3.0, 2.0, 5.0, 6.0, 3.0, 2.0, 6.0, 8.0, 2.0, 6.0, 3.0, 4.0, 6.0, 4.0, 4.0,
      5.0, 4.0, 4.0, 2.0, 7.0, 3.0, 4.0, 0.0, 6.0, 5.0, 2.0, 1.0, 6.0, 3.0, 5.0, 10.0,
      7.0, 8.0, 3.0, 2.0, 1.0, 4.0, 6.0, 4.0, 4.0, 7.0, 0.0, 3.0, 7.0, 6.0, 1.0, 7.0,
      1.0, 4.0, 4.0, 4.0, 5.0, 6.0, 2.0, 0.0, 4.0, 6.0, 5.0, 1.0, 4.0, 6.0, 5.0, 4.0,
      1.0, 2.0, 6.0, 1.0, 6.0, 4.0, 5.0, 7.0, 1.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.09819790731431413
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.037063473447845406
    mean_inference_ms: 1.8503064874785022
    mean_raw_obs_processing_ms: 0.41463344743558883
time_since_restore: 316.77976179122925
time_this_iter_s: 10.148903846740723
time_total_s: 316.77976179122925
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.041
timestamp: 1691994494
timesteps_total: 254150
training_iteration: 31
trial_id: default
train step: 32
agent_timesteps_total: 268650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.017783098053513913
  StateBufferConnector_ms: 0.0031726402148865816
  ViewRequirementAgentConnector_ms: 0.10889956825657894
counters:
  num_agent_steps_sampled: 268650
  num_agent_steps_trained: 252000
  num_env_steps_sampled: 268650
  num_env_steps_trained: 252000
  num_samples_added_to_queue: 268500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 5257
custom_metrics: {}
date: 2023-08-14_15-28-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.587719298245614
episode_reward_min: 0.0
episodes_this_iter: 114
episodes_total: 2100
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8257451057434082
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.411615371704102
        total_loss: -9.215439796447754
        var_gnorm: 63.5059814453125
        vf_explained_var: 0.937735915184021
        vf_loss: 10.649802207946777
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 504.0
  learner_queue:
    size_count: 509
    size_mean: 15.16
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6169106345126192
  num_agent_steps_sampled: 268650
  num_agent_steps_trained: 252000
  num_env_steps_sampled: 268650
  num_env_steps_trained: 252000
  num_samples_added_to_queue: 268500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 5257
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 197.984
    learner_load_time_ms: 1.347
    learner_load_wait_time_ms: 1.416
iterations_since_restore: 32
node_ip: 127.0.0.1
num_agent_steps_sampled: 268650
num_agent_steps_trained: 252000
num_env_steps_sampled: 268650
num_env_steps_sampled_this_iter: 14500
num_env_steps_sampled_throughput_per_sec: 1449.6684391656656
num_env_steps_trained: 252000
num_env_steps_trained_this_iter: 14500
num_env_steps_trained_throughput_per_sec: 1449.6684391656656
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14500
perf:
  cpu_util_percent: 51.22142857142858
  ram_util_percent: 81.58571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.09584993740672182
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03621116301732068
  mean_inference_ms: 1.8064992555425043
  mean_raw_obs_processing_ms: 0.40493590593286566
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.017783098053513913
    StateBufferConnector_ms: 0.0031726402148865816
    ViewRequirementAgentConnector_ms: 0.10889956825657894
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.587719298245614
  episode_reward_min: 0.0
  episodes_this_iter: 114
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 7.0, 3.0, 4.0, 6.0, 4.0, 5.0, 2.0, 1.0, 1.0, 6.0, 8.0, 3.0,
      7.0, 5.0, 4.0, 5.0, 7.0, 6.0, 7.0, 5.0, 5.0, 3.0, 10.0, 3.0, 8.0, 3.0, 5.0,
      1.0, 4.0, 4.0, 6.0, 6.0, 0.0, 4.0, 6.0, 5.0, 4.0, 3.0, 3.0, 4.0, 3.0, 5.0, 4.0,
      3.0, 5.0, 2.0, 3.0, 6.0, 4.0, 5.0, 2.0, 6.0, 3.0, 4.0, 2.0, 6.0, 4.0, 11.0,
      2.0, 2.0, 8.0, 5.0, 5.0, 3.0, 5.0, 3.0, 3.0, 5.0, 7.0, 4.0, 4.0, 5.0, 8.0, 8.0,
      4.0, 6.0, 7.0, 5.0, 2.0, 7.0, 6.0, 4.0, 8.0, 2.0, 3.0, 7.0, 5.0, 4.0, 3.0, 5.0,
      1.0, 3.0, 7.0, 2.0, 5.0, 4.0, 6.0, 7.0, 4.0, 3.0, 1.0, 1.0, 1.0, 8.0, 6.0, 7.0,
      4.0, 6.0, 9.0, 4.0, 5.0, 4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.09584993740672182
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03621116301732068
    mean_inference_ms: 1.8064992555425043
    mean_raw_obs_processing_ms: 0.40493590593286566
time_since_restore: 326.9058609008789
time_this_iter_s: 10.126099109649658
time_total_s: 326.9058609008789
timers:
  sample_time_ms: 0.04
  synch_weights_time_ms: 0.249
  training_iteration_time_ms: 0.352
timestamp: 1691994505
timesteps_total: 268650
training_iteration: 32
trial_id: default
train step: 33
agent_timesteps_total: 281500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02542424201965332
  StateBufferConnector_ms: 0.0038945674896240234
  ViewRequirementAgentConnector_ms: 0.14052414894104004
counters:
  num_agent_steps_sampled: 281500
  num_agent_steps_trained: 265000
  num_env_steps_sampled: 281500
  num_env_steps_trained: 265000
  num_samples_added_to_queue: 281500
  num_training_step_calls_since_last_synch_worker_weights: 279
  num_weight_broadcasts: 5508
custom_metrics: {}
date: 2023-08-14_15-28-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.91
episode_reward_min: 1.0
episodes_this_iter: 100
episodes_total: 2200
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9930369853973389
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.4954488277435303
        total_loss: 16.49264907836914
        var_gnorm: 63.5250244140625
        vf_explained_var: 0.8476131558418274
        vf_loss: 37.92477035522461
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 530.0
  learner_queue:
    size_count: 535
    size_mean: 15.36
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2126005112979295
  num_agent_steps_sampled: 281500
  num_agent_steps_trained: 265000
  num_env_steps_sampled: 281500
  num_env_steps_trained: 265000
  num_samples_added_to_queue: 281500
  num_training_step_calls_since_last_synch_worker_weights: 279
  num_weight_broadcasts: 5508
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 247.751
    learner_load_time_ms: 1.41
    learner_load_wait_time_ms: 1.587
iterations_since_restore: 33
node_ip: 127.0.0.1
num_agent_steps_sampled: 281500
num_agent_steps_trained: 265000
num_env_steps_sampled: 281500
num_env_steps_sampled_this_iter: 12850
num_env_steps_sampled_throughput_per_sec: 1284.9935663068552
num_env_steps_trained: 265000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9934912053786
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 56.87333333333334
  ram_util_percent: 82.94666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.09427254969703455
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03569527096080108
  mean_inference_ms: 1.777119062236169
  mean_raw_obs_processing_ms: 0.39822328540164376
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02542424201965332
    StateBufferConnector_ms: 0.0038945674896240234
    ViewRequirementAgentConnector_ms: 0.14052414894104004
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.91
  episode_reward_min: 1.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 8.0, 8.0, 5.0, 5.0, 6.0, 3.0, 1.0, 2.0, 2.0, 2.0, 5.0, 5.0,
      4.0, 6.0, 5.0, 5.0, 4.0, 3.0, 3.0, 4.0, 7.0, 2.0, 9.0, 4.0, 2.0, 7.0, 5.0, 4.0,
      9.0, 7.0, 5.0, 6.0, 8.0, 7.0, 6.0, 4.0, 4.0, 4.0, 5.0, 5.0, 5.0, 10.0, 4.0,
      3.0, 10.0, 8.0, 4.0, 4.0, 5.0, 3.0, 1.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0,
      4.0, 4.0, 6.0, 5.0, 4.0, 5.0, 5.0, 8.0, 4.0, 4.0, 7.0, 3.0, 1.0, 2.0, 3.0, 5.0,
      4.0, 5.0, 7.0, 7.0, 6.0, 6.0, 8.0, 2.0, 5.0, 7.0, 8.0, 2.0, 4.0, 5.0, 6.0, 8.0,
      9.0, 5.0, 8.0, 7.0, 7.0, 8.0, 3.0, 1.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.09427254969703455
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03569527096080108
    mean_inference_ms: 1.777119062236169
    mean_raw_obs_processing_ms: 0.39822328540164376
time_since_restore: 337.03009700775146
time_this_iter_s: 10.124236106872559
time_total_s: 337.03009700775146
timers:
  sample_time_ms: 0.013
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.04
timestamp: 1691994515
timesteps_total: 281500
training_iteration: 33
trial_id: default
train step: 34
agent_timesteps_total: 294800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019673430002652682
  StateBufferConnector_ms: 0.003350239533644456
  ViewRequirementAgentConnector_ms: 0.11372680847461407
counters:
  num_agent_steps_sampled: 294800
  num_agent_steps_trained: 278000
  num_env_steps_sampled: 294800
  num_env_steps_trained: 278000
  num_samples_added_to_queue: 294500
  num_training_step_calls_since_last_synch_worker_weights: 561
  num_weight_broadcasts: 5771
custom_metrics: {}
date: 2023-08-14_15-28-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 5.403846153846154
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 2304
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9895311594009399
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 20.132564544677734
        total_loss: 31.76987075805664
        var_gnorm: 63.540016174316406
        vf_explained_var: 0.9107030630111694
        vf_loss: 33.169921875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 556.0
  learner_queue:
    size_count: 562
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3152946437965904
  num_agent_steps_sampled: 294800
  num_agent_steps_trained: 278000
  num_env_steps_sampled: 294800
  num_env_steps_trained: 278000
  num_samples_added_to_queue: 294500
  num_training_step_calls_since_last_synch_worker_weights: 561
  num_weight_broadcasts: 5771
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 183.134
    learner_load_time_ms: 1.429
    learner_load_wait_time_ms: 1.465
iterations_since_restore: 34
node_ip: 127.0.0.1
num_agent_steps_sampled: 294800
num_agent_steps_trained: 278000
num_env_steps_sampled: 294800
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9965119453354
num_env_steps_trained: 278000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9965906232603
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 59.50714285714287
  ram_util_percent: 81.88571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.09271482552647418
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03515798930265916
  mean_inference_ms: 1.7475368221724505
  mean_raw_obs_processing_ms: 0.39186589741351074
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019673430002652682
    StateBufferConnector_ms: 0.003350239533644456
    ViewRequirementAgentConnector_ms: 0.11372680847461407
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 5.403846153846154
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 8.0, 2.0, 8.0, 2.0, 2.0, 2.0, 5.0, 5.0, 8.0, 5.0, 1.0, 7.0,
      5.0, 5.0, 1.0, 5.0, 6.0, 2.0, 5.0, 2.0, 5.0, 6.0, 5.0, 3.0, 3.0, 7.0, 8.0, 6.0,
      6.0, 4.0, 4.0, 6.0, 7.0, 8.0, 7.0, 11.0, 5.0, 4.0, 7.0, 3.0, 5.0, 5.0, 5.0,
      4.0, 4.0, 6.0, 14.0, 8.0, 4.0, 8.0, 10.0, 6.0, 3.0, 5.0, 5.0, 1.0, 12.0, 6.0,
      2.0, 6.0, 3.0, 5.0, 7.0, 6.0, 7.0, 3.0, 7.0, 4.0, 10.0, 8.0, 6.0, 3.0, 8.0,
      6.0, 6.0, 5.0, 7.0, 10.0, 5.0, 6.0, 3.0, 3.0, 6.0, 9.0, 6.0, 6.0, 3.0, 5.0,
      1.0, 5.0, 5.0, 7.0, 5.0, 6.0, 3.0, 4.0, 8.0, 6.0, 4.0, 5.0, 4.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.09271482552647418
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03515798930265916
    mean_inference_ms: 1.7475368221724505
    mean_raw_obs_processing_ms: 0.39186589741351074
time_since_restore: 347.17073225975037
time_this_iter_s: 10.140635251998901
time_total_s: 347.17073225975037
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691994525
timesteps_total: 294800
training_iteration: 34
trial_id: default
train step: 35
agent_timesteps_total: 308200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019423778240497295
  StateBufferConnector_ms: 0.003508191842299241
  ViewRequirementAgentConnector_ms: 0.11751789313096267
counters:
  num_agent_steps_sampled: 308200
  num_agent_steps_trained: 291500
  num_env_steps_sampled: 308200
  num_env_steps_trained: 291500
  num_samples_added_to_queue: 308000
  num_training_step_calls_since_last_synch_worker_weights: 117
  num_weight_broadcasts: 6026
custom_metrics: {}
date: 2023-08-14_15-28-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 5.778846153846154
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 2408
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.031564712524414
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -47.146671295166016
        total_loss: -30.44000816345215
        var_gnorm: 63.55935287475586
        vf_explained_var: 0.8626871705055237
        vf_loss: 43.728973388671875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 583.0
  learner_queue:
    size_count: 590
    size_mean: 15.18
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5835403373454051
  num_agent_steps_sampled: 308200
  num_agent_steps_trained: 291500
  num_env_steps_sampled: 308200
  num_env_steps_trained: 291500
  num_samples_added_to_queue: 308000
  num_training_step_calls_since_last_synch_worker_weights: 117
  num_weight_broadcasts: 6026
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 144.112
    learner_load_time_ms: 1.435
    learner_load_wait_time_ms: 1.456
iterations_since_restore: 35
node_ip: 127.0.0.1
num_agent_steps_sampled: 308200
num_agent_steps_trained: 291500
num_env_steps_sampled: 308200
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.992460293278
num_env_steps_trained: 291500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.99240402681
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 55.44285714285714
  ram_util_percent: 80.9642857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.09136494153461301
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0346675412258953
  mean_inference_ms: 1.7203480389290418
  mean_raw_obs_processing_ms: 0.38579394592062116
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019423778240497295
    StateBufferConnector_ms: 0.003508191842299241
    ViewRequirementAgentConnector_ms: 0.11751789313096267
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 5.778846153846154
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 2.0, 5.0, 9.0, 7.0, 6.0, 3.0, 11.0, 1.0, 4.0, 4.0, 10.0,
      2.0, 9.0, 2.0, 7.0, 4.0, 5.0, 4.0, 8.0, 7.0, 5.0, 7.0, 8.0, 4.0, 9.0, 9.0, 4.0,
      6.0, 5.0, 7.0, 1.0, 3.0, 9.0, 9.0, 6.0, 5.0, 7.0, 6.0, 10.0, 6.0, 1.0, 8.0,
      8.0, 7.0, 5.0, 6.0, 5.0, 4.0, 7.0, 5.0, 8.0, 7.0, 4.0, 8.0, 3.0, 6.0, 5.0, 6.0,
      4.0, 6.0, 6.0, 1.0, 7.0, 5.0, 5.0, 11.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 8.0,
      5.0, 6.0, 6.0, 5.0, 4.0, 11.0, 4.0, 5.0, 5.0, 6.0, 5.0, 2.0, 4.0, 7.0, 9.0,
      7.0, 4.0, 8.0, 5.0, 10.0, 5.0, 8.0, 6.0, 10.0, 3.0, 7.0, 9.0, 4.0, 5.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.09136494153461301
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0346675412258953
    mean_inference_ms: 1.7203480389290418
    mean_raw_obs_processing_ms: 0.38579394592062116
time_since_restore: 357.3333230018616
time_this_iter_s: 10.162590742111206
time_total_s: 357.3333230018616
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691994535
timesteps_total: 308200
training_iteration: 35
trial_id: default
train step: 36
agent_timesteps_total: 321400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01959846569941594
  StateBufferConnector_ms: 0.003469219574561486
  ViewRequirementAgentConnector_ms: 0.11780124444227952
counters:
  num_agent_steps_sampled: 321400
  num_agent_steps_trained: 304500
  num_env_steps_sampled: 321400
  num_env_steps_trained: 304500
  num_samples_added_to_queue: 321000
  num_training_step_calls_since_last_synch_worker_weights: 171
  num_weight_broadcasts: 6286
custom_metrics: {}
date: 2023-08-14_15-29-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 6.346153846153846
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 2512
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0178488492965698
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 21.4254150390625
        total_loss: 46.10531234741211
        var_gnorm: 63.57476806640625
        vf_explained_var: 0.8597468733787537
        vf_loss: 59.53828811645508
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 609.0
  learner_queue:
    size_count: 617
    size_mean: 14.76
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.025438224187546
  num_agent_steps_sampled: 321400
  num_agent_steps_trained: 304500
  num_env_steps_sampled: 321400
  num_env_steps_trained: 304500
  num_samples_added_to_queue: 321000
  num_training_step_calls_since_last_synch_worker_weights: 171
  num_weight_broadcasts: 6286
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 114.126
    learner_load_time_ms: 1.402
    learner_load_wait_time_ms: 1.407
iterations_since_restore: 36
node_ip: 127.0.0.1
num_agent_steps_sampled: 321400
num_agent_steps_trained: 304500
num_env_steps_sampled: 321400
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9939575471915
num_env_steps_trained: 304500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9940490995066
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 56.24666666666667
  ram_util_percent: 81.03333333333335
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.09009899650850484
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03423402767881348
  mean_inference_ms: 1.6966099642729293
  mean_raw_obs_processing_ms: 0.3805176024020284
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01959846569941594
    StateBufferConnector_ms: 0.003469219574561486
    ViewRequirementAgentConnector_ms: 0.11780124444227952
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 6.346153846153846
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 5.0, 5.0, 7.0, 7.0, 3.0, 3.0, 9.0, 2.0, 8.0, 5.0, 4.0,
      5.0, 4.0, 6.0, 5.0, 10.0, 5.0, 7.0, 5.0, 8.0, 6.0, 8.0, 2.0, 3.0, 6.0, 6.0,
      9.0, 9.0, 5.0, 10.0, 5.0, 7.0, 6.0, 10.0, 7.0, 8.0, 7.0, 3.0, 7.0, 5.0, 2.0,
      11.0, 5.0, 10.0, 3.0, 4.0, 9.0, 6.0, 5.0, 9.0, 11.0, 5.0, 5.0, 9.0, 8.0, 4.0,
      6.0, 5.0, 8.0, 6.0, 3.0, 5.0, 7.0, 6.0, 6.0, 8.0, 6.0, 5.0, 6.0, 9.0, 7.0, 8.0,
      10.0, 3.0, 5.0, 11.0, 7.0, 5.0, 4.0, 10.0, 6.0, 9.0, 9.0, 6.0, 7.0, 6.0, 11.0,
      5.0, 7.0, 7.0, 7.0, 8.0, 8.0, 5.0, 3.0, 7.0, 8.0, 5.0, 5.0, 5.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.09009899650850484
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03423402767881348
    mean_inference_ms: 1.6966099642729293
    mean_raw_obs_processing_ms: 0.3805176024020284
time_since_restore: 367.52193689346313
time_this_iter_s: 10.188613891601562
time_total_s: 367.52193689346313
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691994545
timesteps_total: 321400
training_iteration: 36
trial_id: default
train step: 37
agent_timesteps_total: 334750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0198288605763362
  StateBufferConnector_ms: 0.003511859820439265
  ViewRequirementAgentConnector_ms: 0.11765590080848107
counters:
  num_agent_steps_sampled: 334750
  num_agent_steps_trained: 318000
  num_env_steps_sampled: 334750
  num_env_steps_trained: 318000
  num_samples_added_to_queue: 334500
  num_training_step_calls_since_last_synch_worker_weights: 62
  num_weight_broadcasts: 6546
custom_metrics: {}
date: 2023-08-14_15-29-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.538461538461538
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 2616
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9196152091026306
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 71.79952239990234
        total_loss: 106.49253845214844
        var_gnorm: 63.593502044677734
        vf_explained_var: 0.8494176268577576
        vf_loss: 78.58218383789062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 636.0
  learner_queue:
    size_count: 643
    size_mean: 14.74
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.047535103484187
  num_agent_steps_sampled: 334750
  num_agent_steps_trained: 318000
  num_env_steps_sampled: 334750
  num_env_steps_trained: 318000
  num_samples_added_to_queue: 334500
  num_training_step_calls_since_last_synch_worker_weights: 62
  num_weight_broadcasts: 6546
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 153.021
    learner_load_time_ms: 1.412
    learner_load_wait_time_ms: 1.683
iterations_since_restore: 37
node_ip: 127.0.0.1
num_agent_steps_sampled: 334750
num_agent_steps_trained: 318000
num_env_steps_sampled: 334750
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9950347131391
num_env_steps_trained: 318000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9949789233992
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.45714285714287
  ram_util_percent: 79.97857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.08888740034663793
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.033809345650655485
  mean_inference_ms: 1.6737535938711272
  mean_raw_obs_processing_ms: 0.3755237992380357
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0198288605763362
    StateBufferConnector_ms: 0.003511859820439265
    ViewRequirementAgentConnector_ms: 0.11765590080848107
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.538461538461538
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 6.0, 8.0, 7.0, 8.0, 9.0, 6.0, 3.0, 6.0, 4.0, 4.0, 7.0, 11.0,
      9.0, 7.0, 7.0, 12.0, 7.0, 6.0, 7.0, 10.0, 10.0, 5.0, 7.0, 6.0, 2.0, 9.0, 8.0,
      8.0, 10.0, 4.0, 11.0, 3.0, 5.0, 7.0, 12.0, 11.0, 8.0, 4.0, 5.0, 4.0, 6.0, 9.0,
      4.0, 3.0, 8.0, 7.0, 5.0, 5.0, 6.0, 8.0, 7.0, 5.0, 6.0, 5.0, 6.0, 1.0, 6.0, 9.0,
      7.0, 6.0, 6.0, 8.0, 6.0, 6.0, 6.0, 6.0, 8.0, 7.0, 6.0, 5.0, 5.0, 11.0, 5.0,
      7.0, 5.0, 5.0, 9.0, 7.0, 7.0, 4.0, 9.0, 6.0, 3.0, 9.0, 6.0, 6.0, 7.0, 6.0, 8.0,
      5.0, 7.0, 7.0, 4.0, 6.0, 7.0, 6.0, 4.0, 5.0, 9.0, 5.0, 4.0, 10.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.08888740034663793
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.033809345650655485
    mean_inference_ms: 1.6737535938711272
    mean_raw_obs_processing_ms: 0.3755237992380357
time_since_restore: 377.71149468421936
time_this_iter_s: 10.189557790756226
time_total_s: 377.71149468421936
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691994555
timesteps_total: 334750
training_iteration: 37
trial_id: default
train step: 38
agent_timesteps_total: 348300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019575981866745723
  StateBufferConnector_ms: 0.0034350440615699405
  ViewRequirementAgentConnector_ms: 0.1168437231154669
counters:
  num_agent_steps_sampled: 348300
  num_agent_steps_trained: 331500
  num_env_steps_sampled: 348300
  num_env_steps_trained: 331500
  num_samples_added_to_queue: 348000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 6811
custom_metrics: {}
date: 2023-08-14_15-29-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.847619047619047
episode_reward_min: 2.0
episodes_this_iter: 105
episodes_total: 2721
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8883481025695801
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -33.26874542236328
        total_loss: -10.852056503295898
        var_gnorm: 63.61091995239258
        vf_explained_var: 0.9159769415855408
        vf_loss: 53.71685791015625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 663.0
  learner_queue:
    size_count: 667
    size_mean: 14.98
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7605680901345453
  num_agent_steps_sampled: 348300
  num_agent_steps_trained: 331500
  num_env_steps_sampled: 348300
  num_env_steps_trained: 331500
  num_samples_added_to_queue: 348000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 6811
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 238.369
    learner_load_time_ms: 1.412
    learner_load_wait_time_ms: 1.461
iterations_since_restore: 38
node_ip: 127.0.0.1
num_agent_steps_sampled: 348300
num_agent_steps_trained: 331500
num_env_steps_sampled: 348300
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.983168930268
num_env_steps_trained: 331500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9832310375364
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.642857142857146
  ram_util_percent: 79.95000000000002
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0877175165499903
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.033397161083260664
  mean_inference_ms: 1.651729044648331
  mean_raw_obs_processing_ms: 0.37070918124147006
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019575981866745723
    StateBufferConnector_ms: 0.0034350440615699405
    ViewRequirementAgentConnector_ms: 0.1168437231154669
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.847619047619047
  episode_reward_min: 2.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 9.0, 5.0, 4.0, 7.0, 6.0, 3.0, 11.0, 5.0, 7.0, 7.0, 8.0,
      3.0, 5.0, 12.0, 5.0, 3.0, 4.0, 2.0, 4.0, 6.0, 4.0, 7.0, 8.0, 6.0, 7.0, 3.0,
      8.0, 6.0, 8.0, 6.0, 8.0, 8.0, 9.0, 8.0, 4.0, 12.0, 10.0, 9.0, 4.0, 6.0, 7.0,
      5.0, 6.0, 9.0, 5.0, 9.0, 7.0, 9.0, 4.0, 8.0, 8.0, 9.0, 8.0, 7.0, 3.0, 8.0, 11.0,
      6.0, 9.0, 8.0, 8.0, 6.0, 8.0, 8.0, 4.0, 4.0, 5.0, 6.0, 8.0, 2.0, 2.0, 4.0, 8.0,
      6.0, 8.0, 9.0, 5.0, 9.0, 11.0, 8.0, 5.0, 5.0, 8.0, 9.0, 5.0, 9.0, 9.0, 8.0,
      4.0, 5.0, 7.0, 9.0, 10.0, 9.0, 12.0, 5.0, 4.0, 2.0, 8.0, 10.0, 13.0, 7.0, 8.0,
      6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0877175165499903
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.033397161083260664
    mean_inference_ms: 1.651729044648331
    mean_raw_obs_processing_ms: 0.37070918124147006
time_since_restore: 387.81877851486206
time_this_iter_s: 10.1072838306427
time_total_s: 387.81877851486206
timers:
  sample_time_ms: 0.046
  synch_weights_time_ms: 0.257
  training_iteration_time_ms: 0.365
timestamp: 1691994566
timesteps_total: 348300
training_iteration: 38
trial_id: default
train step: 39
agent_timesteps_total: 360600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021344661712646484
  StateBufferConnector_ms: 0.003793478012084961
  ViewRequirementAgentConnector_ms: 0.1265106201171875
counters:
  num_agent_steps_sampled: 360600
  num_agent_steps_trained: 344000
  num_env_steps_sampled: 360600
  num_env_steps_trained: 344000
  num_samples_added_to_queue: 360500
  num_training_step_calls_since_last_synch_worker_weights: 811
  num_weight_broadcasts: 7055
custom_metrics: {}
date: 2023-08-14_15-29-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.33
episode_reward_min: 3.0
episodes_this_iter: 96
episodes_total: 2817
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9371769428253174
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 81.62993621826172
        total_loss: 127.50054931640625
        var_gnorm: 63.62205505371094
        vf_explained_var: 0.8683376908302307
        vf_loss: 101.11299896240234
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 688.0
  learner_queue:
    size_count: 696
    size_mean: 15.2
    size_quantiles: [9.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.6492422502470645
  num_agent_steps_sampled: 360600
  num_agent_steps_trained: 344000
  num_env_steps_sampled: 360600
  num_env_steps_trained: 344000
  num_samples_added_to_queue: 360500
  num_training_step_calls_since_last_synch_worker_weights: 811
  num_weight_broadcasts: 7055
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 156.376
    learner_load_time_ms: 1.379
    learner_load_wait_time_ms: 1.871
iterations_since_restore: 39
node_ip: 127.0.0.1
num_agent_steps_sampled: 360600
num_agent_steps_trained: 344000
num_env_steps_sampled: 360600
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.9944575082668
num_env_steps_trained: 344000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.99436738645
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.379999999999995
  ram_util_percent: 80.81333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.08699355790057094
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03318101852105704
  mean_inference_ms: 1.6376839532260126
  mean_raw_obs_processing_ms: 0.36757810927150414
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021344661712646484
    StateBufferConnector_ms: 0.003793478012084961
    ViewRequirementAgentConnector_ms: 0.1265106201171875
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.33
  episode_reward_min: 3.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 7.0, 8.0, 6.0, 11.0, 5.0, 5.0, 4.0, 5.0, 6.0, 6.0, 4.0,
      6.0, 7.0, 11.0, 6.0, 7.0, 7.0, 7.0, 5.0, 4.0, 7.0, 7.0, 6.0, 9.0, 6.0, 11.0,
      13.0, 7.0, 5.0, 5.0, 4.0, 7.0, 12.0, 10.0, 6.0, 6.0, 5.0, 8.0, 16.0, 9.0, 7.0,
      5.0, 7.0, 8.0, 6.0, 8.0, 5.0, 6.0, 7.0, 7.0, 7.0, 8.0, 8.0, 11.0, 4.0, 8.0,
      5.0, 7.0, 6.0, 8.0, 8.0, 9.0, 3.0, 8.0, 10.0, 8.0, 4.0, 11.0, 9.0, 6.0, 9.0,
      13.0, 8.0, 7.0, 11.0, 9.0, 5.0, 7.0, 7.0, 6.0, 6.0, 7.0, 10.0, 7.0, 5.0, 6.0,
      6.0, 7.0, 7.0, 9.0, 6.0, 7.0, 7.0, 8.0, 5.0, 8.0, 9.0, 8.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.08699355790057094
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03318101852105704
    mean_inference_ms: 1.6376839532260126
    mean_raw_obs_processing_ms: 0.36757810927150414
time_since_restore: 398.07958030700684
time_this_iter_s: 10.260801792144775
time_total_s: 398.07958030700684
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691994576
timesteps_total: 360600
training_iteration: 39
trial_id: default
train step: 40
agent_timesteps_total: 372900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022168397903442383
  StateBufferConnector_ms: 0.0038886070251464844
  ViewRequirementAgentConnector_ms: 0.1343371868133545
counters:
  num_agent_steps_sampled: 372900
  num_agent_steps_trained: 356000
  num_env_steps_sampled: 372900
  num_env_steps_trained: 356000
  num_samples_added_to_queue: 372500
  num_training_step_calls_since_last_synch_worker_weights: 1561
  num_weight_broadcasts: 7293
custom_metrics: {}
date: 2023-08-14_15-29-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.42
episode_reward_min: 2.0
episodes_this_iter: 97
episodes_total: 2914
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9278223514556885
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.1551231145858765
        total_loss: 24.840194702148438
        var_gnorm: 63.635562896728516
        vf_explained_var: 0.9105706214904785
        vf_loss: 56.64836883544922
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 712.0
  learner_queue:
    size_count: 717
    size_mean: 14.86
    size_quantiles: [9.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.8762729012593025
  num_agent_steps_sampled: 372900
  num_agent_steps_trained: 356000
  num_env_steps_sampled: 372900
  num_env_steps_trained: 356000
  num_samples_added_to_queue: 372500
  num_training_step_calls_since_last_synch_worker_weights: 1561
  num_weight_broadcasts: 7293
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 249.604
    learner_load_time_ms: 1.386
    learner_load_wait_time_ms: 1.789
iterations_since_restore: 40
node_ip: 127.0.0.1
num_agent_steps_sampled: 372900
num_agent_steps_trained: 356000
num_env_steps_sampled: 372900
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.9985044020718
num_env_steps_trained: 356000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.99854088007
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 56.88571428571429
  ram_util_percent: 81.82142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.08626898249514625
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.032968845515511325
  mean_inference_ms: 1.6237869747802764
  mean_raw_obs_processing_ms: 0.3644802715490657
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022168397903442383
    StateBufferConnector_ms: 0.0038886070251464844
    ViewRequirementAgentConnector_ms: 0.1343371868133545
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.42
  episode_reward_min: 2.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 8.0, 10.0, 6.0, 8.0, 2.0, 9.0, 5.0, 9.0, 2.0, 3.0, 10.0,
      9.0, 7.0, 6.0, 2.0, 11.0, 10.0, 3.0, 10.0, 3.0, 11.0, 6.0, 4.0, 6.0, 6.0, 10.0,
      10.0, 6.0, 8.0, 3.0, 9.0, 6.0, 11.0, 5.0, 9.0, 7.0, 7.0, 7.0, 7.0, 8.0, 10.0,
      9.0, 4.0, 4.0, 5.0, 6.0, 12.0, 7.0, 11.0, 4.0, 3.0, 9.0, 10.0, 7.0, 8.0, 10.0,
      10.0, 8.0, 10.0, 7.0, 7.0, 12.0, 7.0, 7.0, 7.0, 4.0, 11.0, 9.0, 9.0, 11.0, 3.0,
      9.0, 8.0, 2.0, 7.0, 7.0, 10.0, 16.0, 7.0, 6.0, 11.0, 2.0, 9.0, 3.0, 7.0, 8.0,
      10.0, 9.0, 9.0, 5.0, 7.0, 8.0, 10.0, 5.0, 8.0, 9.0, 9.0, 5.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.08626898249514625
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.032968845515511325
    mean_inference_ms: 1.6237869747802764
    mean_raw_obs_processing_ms: 0.3644802715490657
time_since_restore: 408.22043442726135
time_this_iter_s: 10.140854120254517
time_total_s: 408.22043442726135
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691994586
timesteps_total: 372900
training_iteration: 40
trial_id: default
train step: 41
agent_timesteps_total: 384400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024505615234375
  StateBufferConnector_ms: 0.004717111587524414
  ViewRequirementAgentConnector_ms: 0.13383817672729492
counters:
  num_agent_steps_sampled: 384400
  num_agent_steps_trained: 367500
  num_env_steps_sampled: 384400
  num_env_steps_trained: 367500
  num_samples_added_to_queue: 384000
  num_training_step_calls_since_last_synch_worker_weights: 647
  num_weight_broadcasts: 7518
custom_metrics: {}
date: 2023-08-14_15-29-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 7.06
episode_reward_min: 2.0
episodes_this_iter: 89
episodes_total: 3003
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.200000000000045
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8676250576972961
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.634910583496094
        total_loss: 11.584577560424805
        var_gnorm: 63.645267486572266
        vf_explained_var: 0.9330127835273743
        vf_loss: 61.11522674560547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 735.0
  learner_queue:
    size_count: 741
    size_mean: 14.66
    size_quantiles: [9.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9860513588525348
  num_agent_steps_sampled: 384400
  num_agent_steps_trained: 367500
  num_env_steps_sampled: 384400
  num_env_steps_trained: 367500
  num_samples_added_to_queue: 384000
  num_training_step_calls_since_last_synch_worker_weights: 647
  num_weight_broadcasts: 7518
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 203.374
    learner_load_time_ms: 1.412
    learner_load_wait_time_ms: 1.756
iterations_since_restore: 41
node_ip: 127.0.0.1
num_agent_steps_sampled: 384400
num_agent_steps_trained: 367500
num_env_steps_sampled: 384400
num_env_steps_sampled_this_iter: 11500
num_env_steps_sampled_throughput_per_sec: 1149.9953663535855
num_env_steps_trained: 367500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9953663535855
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 64.02000000000001
  ram_util_percent: 82.30666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.08583181026083236
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03286368575666523
  mean_inference_ms: 1.6148707757587004
  mean_raw_obs_processing_ms: 0.36259060384073505
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024505615234375
    StateBufferConnector_ms: 0.004717111587524414
    ViewRequirementAgentConnector_ms: 0.13383817672729492
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 7.06
  episode_reward_min: 2.0
  episodes_this_iter: 89
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 5.0, 7.0, 8.0, 10.0, 5.0, 8.0, 9.0, 9.0, 5.0, 7.0, 11.0,
      8.0, 9.0, 5.0, 9.0, 6.0, 9.0, 5.0, 8.0, 4.0, 3.0, 7.0, 3.0, 7.0, 10.0, 6.0,
      6.0, 12.0, 5.0, 5.0, 3.0, 7.0, 7.0, 6.0, 9.0, 5.0, 2.0, 3.0, 4.0, 12.0, 9.0,
      7.0, 6.0, 10.0, 9.0, 8.0, 4.0, 4.0, 5.0, 5.0, 8.0, 10.0, 7.0, 5.0, 10.0, 8.0,
      8.0, 10.0, 9.0, 6.0, 3.0, 9.0, 7.0, 4.0, 6.0, 10.0, 6.0, 7.0, 10.0, 12.0, 6.0,
      9.0, 10.0, 5.0, 8.0, 6.0, 8.0, 11.0, 8.0, 8.0, 5.0, 12.0, 9.0, 7.0, 5.0, 3.0,
      6.0, 6.0, 9.0, 9.0, 4.0, 2.0, 8.0, 6.0, 4.0, 7.0, 6.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.08583181026083236
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03286368575666523
    mean_inference_ms: 1.6148707757587004
    mean_raw_obs_processing_ms: 0.36259060384073505
time_since_restore: 418.3874864578247
time_this_iter_s: 10.167052030563354
time_total_s: 418.3874864578247
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691994596
timesteps_total: 384400
training_iteration: 41
trial_id: default
train step: 42
agent_timesteps_total: 397050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021030902862548828
  StateBufferConnector_ms: 0.004064083099365234
  ViewRequirementAgentConnector_ms: 0.12594079971313477
counters:
  num_agent_steps_sampled: 397050
  num_agent_steps_trained: 380500
  num_env_steps_sampled: 397050
  num_env_steps_trained: 380500
  num_samples_added_to_queue: 397000
  num_training_step_calls_since_last_synch_worker_weights: 218
  num_weight_broadcasts: 7768
custom_metrics: {}
date: 2023-08-14_15-30-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.75
episode_reward_min: 2.0
episodes_this_iter: 99
episodes_total: 3102
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8608959913253784
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 31.474504470825195
        total_loss: 54.92759704589844
        var_gnorm: 63.646060943603516
        vf_explained_var: 0.9198358058929443
        vf_loss: 55.51514434814453
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 761.0
  learner_queue:
    size_count: 768
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6351146748775753
  num_agent_steps_sampled: 397050
  num_agent_steps_trained: 380500
  num_env_steps_sampled: 397050
  num_env_steps_trained: 380500
  num_samples_added_to_queue: 397000
  num_training_step_calls_since_last_synch_worker_weights: 218
  num_weight_broadcasts: 7768
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 125.284
    learner_load_time_ms: 1.356
    learner_load_wait_time_ms: 1.524
iterations_since_restore: 42
node_ip: 127.0.0.1
num_agent_steps_sampled: 397050
num_agent_steps_trained: 380500
num_env_steps_sampled: 397050
num_env_steps_sampled_this_iter: 12650
num_env_steps_sampled_throughput_per_sec: 1264.9958379405584
num_env_steps_trained: 380500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9957227847638
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.07857142857143
  ram_util_percent: 80.94285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.08501104462243748
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03261511464214659
  mean_inference_ms: 1.600177073165061
  mean_raw_obs_processing_ms: 0.35957470743714026
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021030902862548828
    StateBufferConnector_ms: 0.004064083099365234
    ViewRequirementAgentConnector_ms: 0.12594079971313477
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.75
  episode_reward_min: 2.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 8.0, 8.0, 6.0, 7.0, 7.0, 6.0, 8.0, 6.0, 10.0, 4.0, 5.0,
      8.0, 5.0, 5.0, 3.0, 5.0, 3.0, 5.0, 12.0, 8.0, 3.0, 6.0, 8.0, 4.0, 3.0, 5.0,
      7.0, 9.0, 5.0, 4.0, 3.0, 6.0, 8.0, 3.0, 7.0, 4.0, 7.0, 6.0, 7.0, 7.0, 4.0, 5.0,
      7.0, 6.0, 7.0, 5.0, 6.0, 9.0, 9.0, 9.0, 9.0, 9.0, 6.0, 4.0, 10.0, 10.0, 9.0,
      7.0, 7.0, 5.0, 7.0, 10.0, 12.0, 7.0, 7.0, 10.0, 5.0, 3.0, 11.0, 3.0, 14.0, 7.0,
      4.0, 8.0, 10.0, 7.0, 2.0, 6.0, 7.0, 6.0, 9.0, 7.0, 7.0, 11.0, 8.0, 4.0, 10.0,
      6.0, 4.0, 3.0, 5.0, 8.0, 6.0, 6.0, 9.0, 10.0, 6.0, 9.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.08501104462243748
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03261511464214659
    mean_inference_ms: 1.600177073165061
    mean_raw_obs_processing_ms: 0.35957470743714026
time_since_restore: 428.5439565181732
time_this_iter_s: 10.15647006034851
time_total_s: 428.5439565181732
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.04
timestamp: 1691994606
timesteps_total: 397050
training_iteration: 42
trial_id: default
train step: 43
agent_timesteps_total: 410450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020055316743396577
  StateBufferConnector_ms: 0.0035149710518973215
  ViewRequirementAgentConnector_ms: 0.11919657389322917
counters:
  num_agent_steps_sampled: 410450
  num_agent_steps_trained: 393500
  num_env_steps_sampled: 410450
  num_env_steps_trained: 393500
  num_samples_added_to_queue: 410000
  num_training_step_calls_since_last_synch_worker_weights: 1125
  num_weight_broadcasts: 8031
custom_metrics: {}
date: 2023-08-14_15-30-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.371428571428571
episode_reward_min: 1.0
episodes_this_iter: 105
episodes_total: 3207
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7833930253982544
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.7147064208984375
        total_loss: 11.505435943603516
        var_gnorm: 63.656532287597656
        vf_explained_var: 0.9472686648368835
        vf_loss: 36.27421569824219
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 787.0
  learner_queue:
    size_count: 793
    size_mean: 15.06
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6782133356638542
  num_agent_steps_sampled: 410450
  num_agent_steps_trained: 393500
  num_env_steps_sampled: 410450
  num_env_steps_trained: 393500
  num_samples_added_to_queue: 410000
  num_training_step_calls_since_last_synch_worker_weights: 1125
  num_weight_broadcasts: 8031
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 190.862
    learner_load_time_ms: 1.359
    learner_load_wait_time_ms: 1.729
iterations_since_restore: 43
node_ip: 127.0.0.1
num_agent_steps_sampled: 410450
num_agent_steps_trained: 393500
num_env_steps_sampled: 410450
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9946007946126
num_env_steps_trained: 393500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9947619649226
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.15714285714286
  ram_util_percent: 78.64285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.08417694584202111
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03231344436177156
  mean_inference_ms: 1.5842774453125037
  mean_raw_obs_processing_ms: 0.3560904650392773
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020055316743396577
    StateBufferConnector_ms: 0.0035149710518973215
    ViewRequirementAgentConnector_ms: 0.11919657389322917
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.371428571428571
  episode_reward_min: 1.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 8.0, 9.0, 7.0, 12.0, 3.0, 6.0, 11.0, 9.0, 6.0, 5.0,
      11.0, 4.0, 9.0, 6.0, 11.0, 12.0, 4.0, 7.0, 7.0, 12.0, 10.0, 6.0, 7.0, 8.0, 10.0,
      3.0, 6.0, 9.0, 10.0, 1.0, 10.0, 10.0, 3.0, 9.0, 8.0, 6.0, 4.0, 7.0, 6.0, 4.0,
      6.0, 7.0, 2.0, 6.0, 12.0, 5.0, 6.0, 4.0, 9.0, 3.0, 3.0, 7.0, 9.0, 7.0, 6.0,
      5.0, 5.0, 10.0, 10.0, 4.0, 5.0, 7.0, 4.0, 5.0, 6.0, 11.0, 9.0, 4.0, 9.0, 6.0,
      13.0, 6.0, 8.0, 7.0, 6.0, 5.0, 11.0, 8.0, 9.0, 9.0, 9.0, 8.0, 9.0, 9.0, 4.0,
      9.0, 7.0, 9.0, 7.0, 6.0, 6.0, 16.0, 9.0, 7.0, 9.0, 7.0, 6.0, 4.0, 8.0, 7.0,
      12.0, 8.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.08417694584202111
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03231344436177156
    mean_inference_ms: 1.5842774453125037
    mean_raw_obs_processing_ms: 0.3560904650392773
time_since_restore: 438.6750326156616
time_this_iter_s: 10.131076097488403
time_total_s: 438.6750326156616
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691994616
timesteps_total: 410450
training_iteration: 43
trial_id: default
train step: 44
agent_timesteps_total: 424250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018903944227430556
  StateBufferConnector_ms: 0.0033541961952492042
  ViewRequirementAgentConnector_ms: 0.11456101029007523
counters:
  num_agent_steps_sampled: 424250
  num_agent_steps_trained: 407500
  num_env_steps_sampled: 424250
  num_env_steps_trained: 407500
  num_samples_added_to_queue: 424000
  num_training_step_calls_since_last_synch_worker_weights: 253
  num_weight_broadcasts: 8304
custom_metrics: {}
date: 2023-08-14_15-30-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.805555555555555
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 3315
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8775899410247803
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 9.422647476196289
        total_loss: 39.59635543823242
        var_gnorm: 63.672359466552734
        vf_explained_var: 0.9106809496879578
        vf_loss: 69.12332153320312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 815.0
  learner_queue:
    size_count: 822
    size_mean: 15.2
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.574801574802362
  num_agent_steps_sampled: 424250
  num_agent_steps_trained: 407500
  num_env_steps_sampled: 424250
  num_env_steps_trained: 407500
  num_samples_added_to_queue: 424000
  num_training_step_calls_since_last_synch_worker_weights: 253
  num_weight_broadcasts: 8304
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 147.76
    learner_load_time_ms: 1.366
    learner_load_wait_time_ms: 1.641
iterations_since_restore: 44
node_ip: 127.0.0.1
num_agent_steps_sampled: 424250
num_agent_steps_trained: 407500
num_env_steps_sampled: 424250
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9942093138495
num_env_steps_trained: 407500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9941253908619
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 50.64666666666667
  ram_util_percent: 77.91999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.08334241525618705
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03200794428229607
  mean_inference_ms: 1.568315209196914
  mean_raw_obs_processing_ms: 0.352631644346383
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018903944227430556
    StateBufferConnector_ms: 0.0033541961952492042
    ViewRequirementAgentConnector_ms: 0.11456101029007523
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.805555555555555
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 2.0, 6.0, 7.0, 3.0, 8.0, 8.0, 6.0, 6.0, 7.0, 6.0, 5.0, 1.0,
      7.0, 8.0, 9.0, 6.0, 9.0, 10.0, 10.0, 11.0, 5.0, 10.0, 8.0, 7.0, 6.0, 10.0, 11.0,
      9.0, 13.0, 9.0, 9.0, 3.0, 10.0, 8.0, 9.0, 11.0, 7.0, 5.0, 8.0, 4.0, 7.0, 4.0,
      5.0, 4.0, 9.0, 9.0, 6.0, 10.0, 11.0, 8.0, 6.0, 7.0, 10.0, 7.0, 6.0, 7.0, 7.0,
      6.0, 9.0, 7.0, 8.0, 5.0, 8.0, 9.0, 10.0, 5.0, 11.0, 10.0, 9.0, 10.0, 7.0, 9.0,
      10.0, 9.0, 4.0, 15.0, 6.0, 8.0, 8.0, 10.0, 8.0, 6.0, 4.0, 6.0, 7.0, 8.0, 11.0,
      7.0, 10.0, 7.0, 10.0, 12.0, 14.0, 11.0, 4.0, 7.0, 8.0, 12.0, 8.0, 4.0, 12.0,
      6.0, 7.0, 5.0, 6.0, 12.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.08334241525618705
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03200794428229607
    mean_inference_ms: 1.568315209196914
    mean_raw_obs_processing_ms: 0.352631644346383
time_since_restore: 448.887788772583
time_this_iter_s: 10.212756156921387
time_total_s: 448.887788772583
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.044
timestamp: 1691994627
timesteps_total: 424250
training_iteration: 44
trial_id: default
train step: 45
agent_timesteps_total: 438450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018200144037470087
  StateBufferConnector_ms: 0.0031527098234709317
  ViewRequirementAgentConnector_ms: 0.11109231828569292
counters:
  num_agent_steps_sampled: 438450
  num_agent_steps_trained: 421500
  num_env_steps_sampled: 438450
  num_env_steps_trained: 421500
  num_samples_added_to_queue: 438000
  num_training_step_calls_since_last_synch_worker_weights: 551
  num_weight_broadcasts: 8583
custom_metrics: {}
date: 2023-08-14_15-30-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.387387387387387
episode_reward_min: 0.0
episodes_this_iter: 111
episodes_total: 3426
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.49329841136932373
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.9903564453125
        total_loss: 16.160221099853516
        var_gnorm: 63.70827865600586
        vf_explained_var: 0.9180854558944702
        vf_loss: 71.23413848876953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 843.0
  learner_queue:
    size_count: 850
    size_mean: 14.82
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.9666214684071768
  num_agent_steps_sampled: 438450
  num_agent_steps_trained: 421500
  num_env_steps_sampled: 438450
  num_env_steps_trained: 421500
  num_samples_added_to_queue: 438000
  num_training_step_calls_since_last_synch_worker_weights: 551
  num_weight_broadcasts: 8583
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 147.106
    learner_load_time_ms: 1.338
    learner_load_wait_time_ms: 1.392
iterations_since_restore: 45
node_ip: 127.0.0.1
num_agent_steps_sampled: 438450
num_agent_steps_trained: 421500
num_env_steps_sampled: 438450
num_env_steps_sampled_this_iter: 14200
num_env_steps_sampled_throughput_per_sec: 1419.992314857114
num_env_steps_trained: 421500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9924230985632
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.67142857142857
  ram_util_percent: 78.1642857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.08247442442883904
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03166794191843516
  mean_inference_ms: 1.5517590956544407
  mean_raw_obs_processing_ms: 0.34901672658582855
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018200144037470087
    StateBufferConnector_ms: 0.0031527098234709317
    ViewRequirementAgentConnector_ms: 0.11109231828569292
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.387387387387387
  episode_reward_min: 0.0
  episodes_this_iter: 111
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128]
    episode_reward: [9.0, 8.0, 6.0, 5.0, 2.0, 7.0, 4.0, 6.0, 10.0, 9.0, 6.0, 7.0,
      7.0, 3.0, 5.0, 10.0, 6.0, 4.0, 5.0, 9.0, 5.0, 4.0, 7.0, 5.0, 4.0, 5.0, 7.0,
      9.0, 5.0, 5.0, 5.0, 4.0, 4.0, 10.0, 7.0, 5.0, 8.0, 7.0, 7.0, 7.0, 5.0, 4.0,
      6.0, 7.0, 0.0, 5.0, 3.0, 4.0, 6.0, 5.0, 4.0, 3.0, 3.0, 4.0, 4.0, 7.0, 6.0, 5.0,
      8.0, 6.0, 8.0, 12.0, 6.0, 9.0, 7.0, 5.0, 5.0, 7.0, 5.0, 4.0, 5.0, 8.0, 9.0,
      4.0, 4.0, 2.0, 6.0, 3.0, 8.0, 4.0, 6.0, 6.0, 4.0, 5.0, 6.0, 2.0, 7.0, 5.0, 6.0,
      9.0, 5.0, 4.0, 3.0, 5.0, 5.0, 4.0, 2.0, 2.0, 6.0, 5.0, 6.0, 0.0, 3.0, 1.0, 3.0,
      4.0, 3.0, 7.0, 2.0, 6.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.08247442442883904
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03166794191843516
    mean_inference_ms: 1.5517590956544407
    mean_raw_obs_processing_ms: 0.34901672658582855
time_since_restore: 459.0459578037262
time_this_iter_s: 10.158169031143188
time_total_s: 459.0459578037262
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691994637
timesteps_total: 438450
training_iteration: 45
trial_id: default
train step: 46
agent_timesteps_total: 452350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019031321560895
  StateBufferConnector_ms: 0.0033310166111698855
  ViewRequirementAgentConnector_ms: 0.1156168955343741
counters:
  num_agent_steps_sampled: 452350
  num_agent_steps_trained: 435500
  num_env_steps_sampled: 452350
  num_env_steps_trained: 435500
  num_samples_added_to_queue: 452000
  num_training_step_calls_since_last_synch_worker_weights: 334
  num_weight_broadcasts: 8858
custom_metrics: {}
date: 2023-08-14_15-30-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 3.0
episode_reward_mean: 0.1111111111111111
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 3534
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.004633450880646706
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.32571977376937866
        total_loss: 45.108516693115234
        var_gnorm: 63.7326774597168
        vf_explained_var: 0.7745811939239502
        vf_loss: 90.91480255126953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 871.0
  learner_queue:
    size_count: 879
    size_mean: 14.86
    size_quantiles: [9.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9596938536414306
  num_agent_steps_sampled: 452350
  num_agent_steps_trained: 435500
  num_env_steps_sampled: 452350
  num_env_steps_trained: 435500
  num_samples_added_to_queue: 452000
  num_training_step_calls_since_last_synch_worker_weights: 334
  num_weight_broadcasts: 8858
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 126.093
    learner_load_time_ms: 1.335
    learner_load_wait_time_ms: 1.681
iterations_since_restore: 46
node_ip: 127.0.0.1
num_agent_steps_sampled: 452350
num_agent_steps_trained: 435500
num_env_steps_sampled: 452350
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9939022331712
num_env_steps_trained: 435500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.993858364345
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 50.96666666666666
  ram_util_percent: 78.54666666666665
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0817264986360067
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03136611923698989
  mean_inference_ms: 1.537650467361299
  mean_raw_obs_processing_ms: 0.3459189858865649
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019031321560895
    StateBufferConnector_ms: 0.0033310166111698855
    ViewRequirementAgentConnector_ms: 0.1156168955343741
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 3.0
  episode_reward_mean: 0.1111111111111111
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0,
      1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0817264986360067
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03136611923698989
    mean_inference_ms: 1.537650467361299
    mean_raw_obs_processing_ms: 0.3459189858865649
time_since_restore: 469.31942796707153
time_this_iter_s: 10.273470163345337
time_total_s: 469.31942796707153
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691994647
timesteps_total: 452350
training_iteration: 46
trial_id: default
train step: 47
agent_timesteps_total: 465250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02100656528284054
  StateBufferConnector_ms: 0.003827680455576075
  ViewRequirementAgentConnector_ms: 0.12347320518871345
counters:
  num_agent_steps_sampled: 465250
  num_agent_steps_trained: 448500
  num_env_steps_sampled: 465250
  num_env_steps_trained: 448500
  num_samples_added_to_queue: 465000
  num_training_step_calls_since_last_synch_worker_weights: 1200
  num_weight_broadcasts: 9113
custom_metrics: {}
date: 2023-08-14_15-30-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.009900990099009901
episode_reward_min: 0.0
episodes_this_iter: 101
episodes_total: 3635
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.006377441808581352
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -3.8556132316589355
        total_loss: 493.40887451171875
        var_gnorm: 63.73019027709961
        vf_explained_var: 0.3186783194541931
        vf_loss: 994.5927734375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 897.0
  learner_queue:
    size_count: 902
    size_mean: 14.98
    size_quantiles: [9.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.8164801127455263
  num_agent_steps_sampled: 465250
  num_agent_steps_trained: 448500
  num_env_steps_sampled: 465250
  num_env_steps_trained: 448500
  num_samples_added_to_queue: 465000
  num_training_step_calls_since_last_synch_worker_weights: 1200
  num_weight_broadcasts: 9113
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 245.343
    learner_load_time_ms: 1.43
    learner_load_wait_time_ms: 1.663
iterations_since_restore: 47
node_ip: 127.0.0.1
num_agent_steps_sampled: 465250
num_agent_steps_trained: 448500
num_env_steps_sampled: 465250
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9948330132497
num_env_steps_trained: 448500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.994792959089
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.8
  ram_util_percent: 79.63571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.08118569510214685
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.031165816021930488
  mean_inference_ms: 1.5271959910313844
  mean_raw_obs_processing_ms: 0.3436455273136958
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02100656528284054
    StateBufferConnector_ms: 0.003827680455576075
    ViewRequirementAgentConnector_ms: 0.12347320518871345
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.009900990099009901
  episode_reward_min: 0.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.08118569510214685
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.031165816021930488
    mean_inference_ms: 1.5271959910313844
    mean_raw_obs_processing_ms: 0.3436455273136958
time_since_restore: 479.438658952713
time_this_iter_s: 10.11923098564148
time_total_s: 479.438658952713
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691994657
timesteps_total: 465250
training_iteration: 47
trial_id: default
train step: 48
agent_timesteps_total: 478550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020219729496882513
  StateBufferConnector_ms: 0.0036388635635375977
  ViewRequirementAgentConnector_ms: 0.12072255978217492
counters:
  num_agent_steps_sampled: 478550
  num_agent_steps_trained: 462000
  num_env_steps_sampled: 478550
  num_env_steps_trained: 462000
  num_samples_added_to_queue: 478500
  num_training_step_calls_since_last_synch_worker_weights: 105
  num_weight_broadcasts: 9376
custom_metrics: {}
date: 2023-08-14_15-31-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.009615384615384616
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 3739
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.012431763112545013
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.026697585359215736
        total_loss: 80.70194244384766
        var_gnorm: 63.72969055175781
        vf_explained_var: 0.3924061059951782
        vf_loss: 161.4748077392578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 924.0
  learner_queue:
    size_count: 932
    size_mean: 15.14
    size_quantiles: [9.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.697174121886143
  num_agent_steps_sampled: 478550
  num_agent_steps_trained: 462000
  num_env_steps_sampled: 478550
  num_env_steps_trained: 462000
  num_samples_added_to_queue: 478500
  num_training_step_calls_since_last_synch_worker_weights: 105
  num_weight_broadcasts: 9376
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 90.076
    learner_load_time_ms: 1.439
    learner_load_wait_time_ms: 1.428
iterations_since_restore: 48
node_ip: 127.0.0.1
num_agent_steps_sampled: 478550
num_agent_steps_trained: 462000
num_env_steps_sampled: 478550
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9961631408753
num_env_steps_trained: 462000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9961054437456
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.83571428571429
  ram_util_percent: 80.85000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.08061243037065752
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.030942182631014694
  mean_inference_ms: 1.5161192980497065
  mean_raw_obs_processing_ms: 0.34123677111303496
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020219729496882513
    StateBufferConnector_ms: 0.0036388635635375977
    ViewRequirementAgentConnector_ms: 0.12072255978217492
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.009615384615384616
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.08061243037065752
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.030942182631014694
    mean_inference_ms: 1.5161192980497065
    mean_raw_obs_processing_ms: 0.34123677111303496
time_since_restore: 489.6202218532562
time_this_iter_s: 10.181562900543213
time_total_s: 489.6202218532562
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.041
timestamp: 1691994667
timesteps_total: 478550
training_iteration: 48
trial_id: default
train step: 49
agent_timesteps_total: 490050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022829055786132812
  StateBufferConnector_ms: 0.006241321563720703
  ViewRequirementAgentConnector_ms: 0.13396453857421875
counters:
  num_agent_steps_sampled: 490050
  num_agent_steps_trained: 473500
  num_env_steps_sampled: 490050
  num_env_steps_trained: 473500
  num_samples_added_to_queue: 490000
  num_training_step_calls_since_last_synch_worker_weights: 346
  num_weight_broadcasts: 9603
custom_metrics: {}
date: 2023-08-14_15-31-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 90
episodes_total: 3829
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.010572141967713833
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -6.22007417678833
        total_loss: 18.950754165649414
        var_gnorm: 63.7296142578125
        vf_explained_var: 0.1716066598892212
        vf_loss: 50.4473762512207
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 947.0
  learner_queue:
    size_count: 953
    size_mean: 14.72
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.06920274502041
  num_agent_steps_sampled: 490050
  num_agent_steps_trained: 473500
  num_env_steps_sampled: 490050
  num_env_steps_trained: 473500
  num_samples_added_to_queue: 490000
  num_training_step_calls_since_last_synch_worker_weights: 346
  num_weight_broadcasts: 9603
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 168.029
    learner_load_time_ms: 1.463
    learner_load_wait_time_ms: 1.602
iterations_since_restore: 49
node_ip: 127.0.0.1
num_agent_steps_sampled: 490050
num_agent_steps_trained: 473500
num_env_steps_sampled: 490050
num_env_steps_sampled_this_iter: 11500
num_env_steps_sampled_throughput_per_sec: 1149.993227760142
num_env_steps_trained: 473500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.993227760142
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 72.67333333333333
  ram_util_percent: 81.38666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0804414748015212
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03087643061633289
  mean_inference_ms: 1.511472543882167
  mean_raw_obs_processing_ms: 0.3402841442819746
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022829055786132812
    StateBufferConnector_ms: 0.006241321563720703
    ViewRequirementAgentConnector_ms: 0.13396453857421875
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0804414748015212
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03087643061633289
    mean_inference_ms: 1.511472543882167
    mean_raw_obs_processing_ms: 0.3402841442819746
time_since_restore: 499.76446056365967
time_this_iter_s: 10.144238710403442
time_total_s: 499.76446056365967
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.044
timestamp: 1691994678
timesteps_total: 490050
training_iteration: 49
trial_id: default
train step: 50
agent_timesteps_total: 503400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019782838367280505
  StateBufferConnector_ms: 0.0035306385585239957
  ViewRequirementAgentConnector_ms: 0.12042386191231864
counters:
  num_agent_steps_sampled: 503400
  num_agent_steps_trained: 486500
  num_env_steps_sampled: 503400
  num_env_steps_trained: 486500
  num_samples_added_to_queue: 503000
  num_training_step_calls_since_last_synch_worker_weights: 363
  num_weight_broadcasts: 9867
custom_metrics: {}
date: 2023-08-14_15-31-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.009523809523809525
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 3934
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.012034540064632893
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.6718311309814453
        total_loss: 6.79019021987915
        var_gnorm: 63.73461151123047
        vf_explained_var: 0.38232672214508057
        vf_loss: 19.044387817382812
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 973.0
  learner_queue:
    size_count: 979
    size_mean: 14.42
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.1917116598676936
  num_agent_steps_sampled: 503400
  num_agent_steps_trained: 486500
  num_env_steps_sampled: 503400
  num_env_steps_trained: 486500
  num_samples_added_to_queue: 503000
  num_training_step_calls_since_last_synch_worker_weights: 363
  num_weight_broadcasts: 9867
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 180.691
    learner_load_time_ms: 1.474
    learner_load_wait_time_ms: 1.487
iterations_since_restore: 50
node_ip: 127.0.0.1
num_agent_steps_sampled: 503400
num_agent_steps_trained: 486500
num_env_steps_sampled: 503400
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9985677019226
num_env_steps_trained: 486500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9986052528086
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.08571428571428
  ram_util_percent: 81.83571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07984039342546743
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.030651352861620663
  mean_inference_ms: 1.5007058044663073
  mean_raw_obs_processing_ms: 0.3379561578481163
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019782838367280505
    StateBufferConnector_ms: 0.0035306385585239957
    ViewRequirementAgentConnector_ms: 0.12042386191231864
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.009523809523809525
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07984039342546743
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.030651352861620663
    mean_inference_ms: 1.5007058044663073
    mean_raw_obs_processing_ms: 0.3379561578481163
time_since_restore: 509.8969798088074
time_this_iter_s: 10.132519245147705
time_total_s: 509.8969798088074
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1691994688
timesteps_total: 503400
training_iteration: 50
trial_id: default
train step: 51
agent_timesteps_total: 516050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021393537521362305
  StateBufferConnector_ms: 0.0038182735443115234
  ViewRequirementAgentConnector_ms: 0.12910199165344238
counters:
  num_agent_steps_sampled: 516050
  num_agent_steps_trained: 499500
  num_env_steps_sampled: 516050
  num_env_steps_trained: 499500
  num_samples_added_to_queue: 516000
  num_training_step_calls_since_last_synch_worker_weights: 578
  num_weight_broadcasts: 10117
custom_metrics: {}
date: 2023-08-14_15-31-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.02
episode_reward_min: 0.0
episodes_this_iter: 98
episodes_total: 4032
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.013993674889206886
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.86236572265625
        total_loss: 25.55864715576172
        var_gnorm: 63.73723220825195
        vf_explained_var: 0.09192675352096558
        vf_loss: 33.532501220703125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 999.0
  learner_queue:
    size_count: 1006
    size_mean: 15.14
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6125755796240993
  num_agent_steps_sampled: 516050
  num_agent_steps_trained: 499500
  num_env_steps_sampled: 516050
  num_env_steps_trained: 499500
  num_samples_added_to_queue: 516000
  num_training_step_calls_since_last_synch_worker_weights: 578
  num_weight_broadcasts: 10117
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 150.646
    learner_load_time_ms: 1.483
    learner_load_wait_time_ms: 1.463
iterations_since_restore: 51
node_ip: 127.0.0.1
num_agent_steps_sampled: 516050
num_agent_steps_trained: 499500
num_env_steps_sampled: 516050
num_env_steps_sampled_this_iter: 12650
num_env_steps_sampled_throughput_per_sec: 1264.9978888070054
num_env_steps_trained: 499500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.997830394551
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.050000000000004
  ram_util_percent: 82.85714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07946395542642369
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.030507201930862152
  mean_inference_ms: 1.4932388301946404
  mean_raw_obs_processing_ms: 0.33627734254564196
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021393537521362305
    StateBufferConnector_ms: 0.0038182735443115234
    ViewRequirementAgentConnector_ms: 0.12910199165344238
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.02
  episode_reward_min: 0.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07946395542642369
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.030507201930862152
    mean_inference_ms: 1.4932388301946404
    mean_raw_obs_processing_ms: 0.33627734254564196
time_since_restore: 520.081465959549
time_this_iter_s: 10.184486150741577
time_total_s: 520.081465959549
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691994698
timesteps_total: 516050
training_iteration: 51
trial_id: default
train step: 52
agent_timesteps_total: 528450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022084951400756836
  StateBufferConnector_ms: 0.0040857791900634766
  ViewRequirementAgentConnector_ms: 0.13720107078552246
counters:
  num_agent_steps_sampled: 528450
  num_agent_steps_trained: 511500
  num_env_steps_sampled: 528450
  num_env_steps_trained: 511500
  num_samples_added_to_queue: 528000
  num_training_step_calls_since_last_synch_worker_weights: 387
  num_weight_broadcasts: 10361
custom_metrics: {}
date: 2023-08-14_15-31-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.01
episode_reward_min: 0.0
episodes_this_iter: 97
episodes_total: 4129
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.012767505832016468
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.7953014969825745
        total_loss: 3.9611244201660156
        var_gnorm: 63.73748779296875
        vf_explained_var: -1.0
        vf_loss: 9.64052677154541
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1023.0
  learner_queue:
    size_count: 1029
    size_mean: 14.96
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.72
  num_agent_steps_sampled: 528450
  num_agent_steps_trained: 511500
  num_env_steps_sampled: 528450
  num_env_steps_trained: 511500
  num_samples_added_to_queue: 528000
  num_training_step_calls_since_last_synch_worker_weights: 387
  num_weight_broadcasts: 10361
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 204.276
    learner_load_time_ms: 1.83
    learner_load_wait_time_ms: 1.867
iterations_since_restore: 52
node_ip: 127.0.0.1
num_agent_steps_sampled: 528450
num_agent_steps_trained: 511500
num_env_steps_sampled: 528450
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.9919291067922
num_env_steps_trained: 511500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9921894581862
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 57.806666666666665
  ram_util_percent: 83.55333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07914504041285053
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03038986280895392
  mean_inference_ms: 1.48671068885669
  mean_raw_obs_processing_ms: 0.3349203602845165
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022084951400756836
    StateBufferConnector_ms: 0.0040857791900634766
    ViewRequirementAgentConnector_ms: 0.13720107078552246
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.01
  episode_reward_min: 0.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07914504041285053
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03038986280895392
    mean_inference_ms: 1.48671068885669
    mean_raw_obs_processing_ms: 0.3349203602845165
time_since_restore: 530.288388967514
time_this_iter_s: 10.206923007965088
time_total_s: 530.288388967514
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691994708
timesteps_total: 528450
training_iteration: 52
trial_id: default
train step: 53
agent_timesteps_total: 541150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020943164825439453
  StateBufferConnector_ms: 0.003759145736694336
  ViewRequirementAgentConnector_ms: 0.12492656707763672
counters:
  num_agent_steps_sampled: 541150
  num_agent_steps_trained: 524500
  num_env_steps_sampled: 541150
  num_env_steps_trained: 524500
  num_samples_added_to_queue: 541000
  num_training_step_calls_since_last_synch_worker_weights: 1172
  num_weight_broadcasts: 10612
custom_metrics: {}
date: 2023-08-14_15-31-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.01
episode_reward_min: 0.0
episodes_this_iter: 99
episodes_total: 4228
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.01470537856221199
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.06386461108922958
        total_loss: 1.9557063579559326
        var_gnorm: 63.73838806152344
        vf_explained_var: 0.13976234197616577
        vf_loss: 3.930737018585205
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1049.0
  learner_queue:
    size_count: 1053
    size_mean: 14.84
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8478095139921755
  num_agent_steps_sampled: 541150
  num_agent_steps_trained: 524500
  num_env_steps_sampled: 541150
  num_env_steps_trained: 524500
  num_samples_added_to_queue: 541000
  num_training_step_calls_since_last_synch_worker_weights: 1172
  num_weight_broadcasts: 10612
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 254.572
    learner_load_time_ms: 1.723
    learner_load_wait_time_ms: 1.735
iterations_since_restore: 53
node_ip: 127.0.0.1
num_agent_steps_sampled: 541150
num_agent_steps_trained: 524500
num_env_steps_sampled: 541150
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.9997274876225
num_env_steps_trained: 524500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9997210503223
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.392857142857146
  ram_util_percent: 82.88571428571427
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07874853419833845
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0302460367329604
  mean_inference_ms: 1.4793776912054204
  mean_raw_obs_processing_ms: 0.33330769463883775
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020943164825439453
    StateBufferConnector_ms: 0.003759145736694336
    ViewRequirementAgentConnector_ms: 0.12492656707763672
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.01
  episode_reward_min: 0.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07874853419833845
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0302460367329604
    mean_inference_ms: 1.4793776912054204
    mean_raw_obs_processing_ms: 0.33330769463883775
time_since_restore: 540.3955299854279
time_this_iter_s: 10.107141017913818
time_total_s: 540.3955299854279
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1691994718
timesteps_total: 541150
training_iteration: 53
trial_id: default
train step: 54
agent_timesteps_total: 553650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021069049835205078
  StateBufferConnector_ms: 0.003829479217529297
  ViewRequirementAgentConnector_ms: 0.1226189136505127
counters:
  num_agent_steps_sampled: 553650
  num_agent_steps_trained: 537000
  num_env_steps_sampled: 553650
  num_env_steps_trained: 537000
  num_samples_added_to_queue: 553500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 10857
custom_metrics: {}
date: 2023-08-14_15-32-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.03
episode_reward_min: 0.0
episodes_this_iter: 97
episodes_total: 4325
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.013024935498833656
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.1748710572719574
        total_loss: 6.924997329711914
        var_gnorm: 63.73686981201172
        vf_explained_var: -1.0
        vf_loss: 14.329985618591309
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1074.0
  learner_queue:
    size_count: 1081
    size_mean: 15.34
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3654303350958628
  num_agent_steps_sampled: 553650
  num_agent_steps_trained: 537000
  num_env_steps_sampled: 553650
  num_env_steps_trained: 537000
  num_samples_added_to_queue: 553500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 10857
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 185.291
    learner_load_time_ms: 1.725
    learner_load_wait_time_ms: 1.52
iterations_since_restore: 54
node_ip: 127.0.0.1
num_agent_steps_sampled: 553650
num_agent_steps_trained: 537000
num_env_steps_sampled: 553650
num_env_steps_sampled_this_iter: 12500
num_env_steps_sampled_throughput_per_sec: 1249.8725186673437
num_env_steps_trained: 537000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.8725186673437
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 54.54
  ram_util_percent: 82.29333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0784525709759665
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.030126484240959314
  mean_inference_ms: 1.4731614580486547
  mean_raw_obs_processing_ms: 0.33196866805802644
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021069049835205078
    StateBufferConnector_ms: 0.003829479217529297
    ViewRequirementAgentConnector_ms: 0.1226189136505127
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.03
  episode_reward_min: 0.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0784525709759665
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.030126484240959314
    mean_inference_ms: 1.4731614580486547
    mean_raw_obs_processing_ms: 0.33196866805802644
time_since_restore: 550.5667629241943
time_this_iter_s: 10.17123293876648
time_total_s: 550.5667629241943
timers:
  sample_time_ms: 0.04
  synch_weights_time_ms: 0.272
  training_iteration_time_ms: 0.396
timestamp: 1691994728
timesteps_total: 553650
training_iteration: 54
trial_id: default
train step: 55
agent_timesteps_total: 566600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019973399592380897
  StateBufferConnector_ms: 0.0037146549598843443
  ViewRequirementAgentConnector_ms: 0.12090463264315736
counters:
  num_agent_steps_sampled: 566600
  num_agent_steps_trained: 550000
  num_env_steps_sampled: 566600
  num_env_steps_trained: 550000
  num_samples_added_to_queue: 566500
  num_training_step_calls_since_last_synch_worker_weights: 1810
  num_weight_broadcasts: 11111
custom_metrics: {}
date: 2023-08-14_15-32-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.00980392156862745
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 4427
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.016431473195552826
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.9549753665924072
        total_loss: 2.7990124225616455
        var_gnorm: 63.73631286621094
        vf_explained_var: -0.603213906288147
        vf_loss: 3.852388620376587
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1100.0
  learner_queue:
    size_count: 1104
    size_mean: 15.2
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5491933384829668
  num_agent_steps_sampled: 566600
  num_agent_steps_trained: 550000
  num_env_steps_sampled: 566600
  num_env_steps_trained: 550000
  num_samples_added_to_queue: 566500
  num_training_step_calls_since_last_synch_worker_weights: 1810
  num_weight_broadcasts: 11111
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 266.352
    learner_load_time_ms: 1.713
    learner_load_wait_time_ms: 1.546
iterations_since_restore: 55
node_ip: 127.0.0.1
num_agent_steps_sampled: 566600
num_agent_steps_trained: 550000
num_env_steps_sampled: 566600
num_env_steps_sampled_this_iter: 12950
num_env_steps_sampled_throughput_per_sec: 1294.994041112663
num_env_steps_trained: 550000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.994018105376
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.24999999999999
  ram_util_percent: 82.1857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07803306008514994
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029971548684548273
  mean_inference_ms: 1.4655778190786581
  mean_raw_obs_processing_ms: 0.33032504850768063
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019973399592380897
    StateBufferConnector_ms: 0.0037146549598843443
    ViewRequirementAgentConnector_ms: 0.12090463264315736
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.00980392156862745
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07803306008514994
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029971548684548273
    mean_inference_ms: 1.4655778190786581
    mean_raw_obs_processing_ms: 0.33032504850768063
time_since_restore: 560.6741218566895
time_this_iter_s: 10.107358932495117
time_total_s: 560.6741218566895
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.057
timestamp: 1691994739
timesteps_total: 566600
training_iteration: 55
trial_id: default
train step: 56
agent_timesteps_total: 579700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02019802729288737
  StateBufferConnector_ms: 0.0036216249652937346
  ViewRequirementAgentConnector_ms: 0.11958514942842371
counters:
  num_agent_steps_sampled: 579700
  num_agent_steps_trained: 563000
  num_env_steps_sampled: 579700
  num_env_steps_trained: 563000
  num_samples_added_to_queue: 579500
  num_training_step_calls_since_last_synch_worker_weights: 118
  num_weight_broadcasts: 11368
custom_metrics: {}
date: 2023-08-14_15-32-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.0392156862745098
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 4529
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.02826553024351597
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.6168177723884583
        total_loss: 13.893726348876953
        var_gnorm: 63.73657989501953
        vf_explained_var: -1.0
        vf_loss: 26.83647346496582
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1126.0
  learner_queue:
    size_count: 1133
    size_mean: 15.36
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3676256797823008
  num_agent_steps_sampled: 579700
  num_agent_steps_trained: 563000
  num_env_steps_sampled: 579700
  num_env_steps_trained: 563000
  num_samples_added_to_queue: 579500
  num_training_step_calls_since_last_synch_worker_weights: 118
  num_weight_broadcasts: 11368
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 135.074
    learner_load_time_ms: 1.712
    learner_load_wait_time_ms: 1.523
iterations_since_restore: 56
node_ip: 127.0.0.1
num_agent_steps_sampled: 579700
num_agent_steps_trained: 563000
num_env_steps_sampled: 579700
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9938159280882
num_env_steps_trained: 563000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.993863134744
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.82142857142857
  ram_util_percent: 81.12142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07764289028467279
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029815227019814806
  mean_inference_ms: 1.4584514898880905
  mean_raw_obs_processing_ms: 0.3286813427488127
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02019802729288737
    StateBufferConnector_ms: 0.0036216249652937346
    ViewRequirementAgentConnector_ms: 0.11958514942842371
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.0392156862745098
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07764289028467279
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029815227019814806
    mean_inference_ms: 1.4584514898880905
    mean_raw_obs_processing_ms: 0.3286813427488127
time_since_restore: 570.8277728557587
time_this_iter_s: 10.153650999069214
time_total_s: 570.8277728557587
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691994749
timesteps_total: 579700
training_iteration: 56
trial_id: default
train step: 57
agent_timesteps_total: 592900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020397167939406175
  StateBufferConnector_ms: 0.0038417486044076774
  ViewRequirementAgentConnector_ms: 0.1204006947003878
counters:
  num_agent_steps_sampled: 592900
  num_agent_steps_trained: 576000
  num_env_steps_sampled: 592900
  num_env_steps_trained: 576000
  num_samples_added_to_queue: 592500
  num_training_step_calls_since_last_synch_worker_weights: 353
  num_weight_broadcasts: 11629
custom_metrics: {}
date: 2023-08-14_15-32-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.009615384615384616
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 4633
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.014898599125444889
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.1097451448440552
        total_loss: 11.061820030212402
        var_gnorm: 63.73554229736328
        vf_explained_var: -1.0
        vf_loss: 24.492116928100586
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1152.0
  learner_queue:
    size_count: 1159
    size_mean: 14.94
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8483506160899237
  num_agent_steps_sampled: 592900
  num_agent_steps_trained: 576000
  num_env_steps_sampled: 592900
  num_env_steps_trained: 576000
  num_samples_added_to_queue: 592500
  num_training_step_calls_since_last_synch_worker_weights: 353
  num_weight_broadcasts: 11629
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 162.236
    learner_load_time_ms: 2.955
    learner_load_wait_time_ms: 1.447
iterations_since_restore: 57
node_ip: 127.0.0.1
num_agent_steps_sampled: 592900
num_agent_steps_trained: 576000
num_env_steps_sampled: 592900
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9950275608455
num_env_steps_trained: 576000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9951029008328
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.680000000000014
  ram_util_percent: 81.3733333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07726655014969525
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02966796359893091
  mean_inference_ms: 1.451324648831233
  mean_raw_obs_processing_ms: 0.32713582949661824
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020397167939406175
    StateBufferConnector_ms: 0.0038417486044076774
    ViewRequirementAgentConnector_ms: 0.1204006947003878
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.009615384615384616
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07726655014969525
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02966796359893091
    mean_inference_ms: 1.451324648831233
    mean_raw_obs_processing_ms: 0.32713582949661824
time_since_restore: 580.9992899894714
time_this_iter_s: 10.171517133712769
time_total_s: 580.9992899894714
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691994759
timesteps_total: 592900
training_iteration: 57
trial_id: default
train step: 58
agent_timesteps_total: 603100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024902820587158203
  StateBufferConnector_ms: 0.0044748783111572266
  ViewRequirementAgentConnector_ms: 0.14614629745483398
counters:
  num_agent_steps_sampled: 603100
  num_agent_steps_trained: 586500
  num_env_steps_sampled: 603100
  num_env_steps_trained: 586500
  num_samples_added_to_queue: 603000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 11827
custom_metrics: {}
date: 2023-08-14_15-32-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.01
episode_reward_min: 0.0
episodes_this_iter: 79
episodes_total: 4712
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.02897018939256668
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.317347288131714
        total_loss: 7.569828033447266
        var_gnorm: 63.735328674316406
        vf_explained_var: -1.0
        vf_loss: 20.06405258178711
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1173.0
  learner_queue:
    size_count: 1180
    size_mean: 14.38
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.1155613912151074
  num_agent_steps_sampled: 603100
  num_agent_steps_trained: 586500
  num_env_steps_sampled: 603100
  num_env_steps_trained: 586500
  num_samples_added_to_queue: 603000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 11827
  timing_breakdown:
    learner_dequeue_time_ms: 0.025
    learner_grad_time_ms: 139.088
    learner_load_time_ms: 2.831
    learner_load_wait_time_ms: 1.533
iterations_since_restore: 58
node_ip: 127.0.0.1
num_agent_steps_sampled: 603100
num_agent_steps_trained: 586500
num_env_steps_sampled: 603100
num_env_steps_sampled_this_iter: 10200
num_env_steps_sampled_throughput_per_sec: 1019.9128978729204
num_env_steps_trained: 586500
num_env_steps_trained_this_iter: 10500
num_env_steps_trained_throughput_per_sec: 1049.9103360456534
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10500
perf:
  cpu_util_percent: 65.19285714285714
  ram_util_percent: 85.03571428571426
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07737145240589471
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02971124565430822
  mean_inference_ms: 1.4516562008338227
  mean_raw_obs_processing_ms: 0.327063945928844
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024902820587158203
    StateBufferConnector_ms: 0.0044748783111572266
    ViewRequirementAgentConnector_ms: 0.14614629745483398
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.01
  episode_reward_min: 0.0
  episodes_this_iter: 79
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07737145240589471
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02971124565430822
    mean_inference_ms: 1.4516562008338227
    mean_raw_obs_processing_ms: 0.327063945928844
time_since_restore: 591.1727340221405
time_this_iter_s: 10.173444032669067
time_total_s: 591.1727340221405
timers:
  sample_time_ms: 0.151
  synch_weights_time_ms: 0.834
  training_iteration_time_ms: 1.297
timestamp: 1691994769
timesteps_total: 603100
training_iteration: 58
trial_id: default
train step: 59
agent_timesteps_total: 615150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02147054672241211
  StateBufferConnector_ms: 0.0038416385650634766
  ViewRequirementAgentConnector_ms: 0.12822675704956055
counters:
  num_agent_steps_sampled: 615150
  num_agent_steps_trained: 598500
  num_env_steps_sampled: 615150
  num_env_steps_trained: 598500
  num_samples_added_to_queue: 615000
  num_training_step_calls_since_last_synch_worker_weights: 302
  num_weight_broadcasts: 12062
custom_metrics: {}
date: 2023-08-14_15-32-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.02
episode_reward_min: 0.0
episodes_this_iter: 94
episodes_total: 4806
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.90000000000009
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.027246881276369095
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.2225494384765625
        total_loss: 3.605224132537842
        var_gnorm: 63.73617935180664
        vf_explained_var: -0.5729794502258301
        vf_loss: 5.03781795501709
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1197.0
  learner_queue:
    size_count: 1203
    size_mean: 14.4
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.98997487421324
  num_agent_steps_sampled: 615150
  num_agent_steps_trained: 598500
  num_env_steps_sampled: 615150
  num_env_steps_trained: 598500
  num_samples_added_to_queue: 615000
  num_training_step_calls_since_last_synch_worker_weights: 302
  num_weight_broadcasts: 12062
  timing_breakdown:
    learner_dequeue_time_ms: 0.022
    learner_grad_time_ms: 166.753
    learner_load_time_ms: 3.056
    learner_load_wait_time_ms: 1.755
iterations_since_restore: 59
node_ip: 127.0.0.1
num_agent_steps_sampled: 615150
num_agent_steps_trained: 598500
num_env_steps_sampled: 615150
num_env_steps_sampled_this_iter: 12050
num_env_steps_sampled_throughput_per_sec: 1204.998419882939
num_env_steps_trained: 598500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9984264394413
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 56.1857142857143
  ram_util_percent: 82.13571428571427
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07710045156371978
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029648648377485588
  mean_inference_ms: 1.4481206008206198
  mean_raw_obs_processing_ms: 0.3261752376784481
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02147054672241211
    StateBufferConnector_ms: 0.0038416385650634766
    ViewRequirementAgentConnector_ms: 0.12822675704956055
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.02
  episode_reward_min: 0.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07710045156371978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029648648377485588
    mean_inference_ms: 1.4481206008206198
    mean_raw_obs_processing_ms: 0.3261752376784481
time_since_restore: 601.3196349143982
time_this_iter_s: 10.14690089225769
time_total_s: 601.3196349143982
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691994779
timesteps_total: 615150
training_iteration: 59
trial_id: default
train step: 60
agent_timesteps_total: 628550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01977239336286272
  StateBufferConnector_ms: 0.0034988494146437872
  ViewRequirementAgentConnector_ms: 0.11875879196893602
counters:
  num_agent_steps_sampled: 628550
  num_agent_steps_trained: 612000
  num_env_steps_sampled: 628550
  num_env_steps_trained: 612000
  num_samples_added_to_queue: 628500
  num_training_step_calls_since_last_synch_worker_weights: 8
  num_weight_broadcasts: 12325
custom_metrics: {}
date: 2023-08-14_15-33-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.02857142857142857
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 4911
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.07207564264535904
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.03323093429207802
        total_loss: 0.046581000089645386
        var_gnorm: 63.73478698730469
        vf_explained_var: -1.0
        vf_loss: 0.8803802728652954
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1224.0
  learner_queue:
    size_count: 1230
    size_mean: 15.02
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6430459518832696
  num_agent_steps_sampled: 628550
  num_agent_steps_trained: 612000
  num_env_steps_sampled: 628550
  num_env_steps_trained: 612000
  num_samples_added_to_queue: 628500
  num_training_step_calls_since_last_synch_worker_weights: 8
  num_weight_broadcasts: 12325
  timing_breakdown:
    learner_dequeue_time_ms: 0.022
    learner_grad_time_ms: 154.243
    learner_load_time_ms: 3.053
    learner_load_wait_time_ms: 1.492
iterations_since_restore: 60
node_ip: 127.0.0.1
num_agent_steps_sampled: 628550
num_agent_steps_trained: 612000
num_env_steps_sampled: 628550
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9996166230344
num_env_steps_trained: 612000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9996137620124
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.25333333333333
  ram_util_percent: 81.32666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07669699298731326
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029490401171425238
  mean_inference_ms: 1.440905109541042
  mean_raw_obs_processing_ms: 0.32459948805495825
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01977239336286272
    StateBufferConnector_ms: 0.0034988494146437872
    ViewRequirementAgentConnector_ms: 0.11875879196893602
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.02857142857142857
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07669699298731326
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029490401171425238
    mean_inference_ms: 1.440905109541042
    mean_raw_obs_processing_ms: 0.32459948805495825
time_since_restore: 611.4559416770935
time_this_iter_s: 10.136306762695312
time_total_s: 611.4559416770935
timers:
  sample_time_ms: 0.139
  synch_weights_time_ms: 0.662
  training_iteration_time_ms: 2.415
timestamp: 1691994789
timesteps_total: 628550
training_iteration: 60
trial_id: default
train step: 61
agent_timesteps_total: 641500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02069237208602452
  StateBufferConnector_ms: 0.003625850866336634
  ViewRequirementAgentConnector_ms: 0.12230542626711402
counters:
  num_agent_steps_sampled: 641500
  num_agent_steps_trained: 625000
  num_env_steps_sampled: 641500
  num_env_steps_trained: 625000
  num_samples_added_to_queue: 641500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 12581
custom_metrics: {}
date: 2023-08-14_15-33-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.09900990099009901
episode_reward_min: 0.0
episodes_this_iter: 101
episodes_total: 5012
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.1721949428319931
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.3368539810180664
        total_loss: 1.0678160190582275
        var_gnorm: 63.73401641845703
        vf_explained_var: -0.21144556999206543
        vf_loss: 1.1838737726211548
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1250.0
  learner_queue:
    size_count: 1253
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3892443989449803
  num_agent_steps_sampled: 641500
  num_agent_steps_trained: 625000
  num_env_steps_sampled: 641500
  num_env_steps_trained: 625000
  num_samples_added_to_queue: 641500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 12581
  timing_breakdown:
    learner_dequeue_time_ms: 0.022
    learner_grad_time_ms: 277.303
    learner_load_time_ms: 3.145
    learner_load_wait_time_ms: 1.62
iterations_since_restore: 61
node_ip: 127.0.0.1
num_agent_steps_sampled: 641500
num_agent_steps_trained: 625000
num_env_steps_sampled: 641500
num_env_steps_sampled_this_iter: 12950
num_env_steps_sampled_throughput_per_sec: 1294.8539458747402
num_env_steps_trained: 625000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.8533819591987
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.63571428571428
  ram_util_percent: 82.04285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07638957957672589
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029371998823636607
  mean_inference_ms: 1.4351516737943384
  mean_raw_obs_processing_ms: 0.32336235999414403
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02069237208602452
    StateBufferConnector_ms: 0.003625850866336634
    ViewRequirementAgentConnector_ms: 0.12230542626711402
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.09900990099009901
  episode_reward_min: 0.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07638957957672589
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029371998823636607
    mean_inference_ms: 1.4351516737943384
    mean_raw_obs_processing_ms: 0.32336235999414403
time_since_restore: 621.52561378479
time_this_iter_s: 10.069672107696533
time_total_s: 621.52561378479
timers:
  sample_time_ms: 0.079
  synch_weights_time_ms: 0.431
  training_iteration_time_ms: 1.957
timestamp: 1691994799
timesteps_total: 641500
training_iteration: 61
trial_id: default
train step: 62
agent_timesteps_total: 653950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02129340171813965
  StateBufferConnector_ms: 0.003758668899536133
  ViewRequirementAgentConnector_ms: 0.12592148780822754
counters:
  num_agent_steps_sampled: 653950
  num_agent_steps_trained: 637000
  num_env_steps_sampled: 653950
  num_env_steps_trained: 637000
  num_samples_added_to_queue: 653500
  num_training_step_calls_since_last_synch_worker_weights: 657
  num_weight_broadcasts: 12826
custom_metrics: {}
date: 2023-08-14_15-33-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 0.67
episode_reward_min: 0.0
episodes_this_iter: 98
episodes_total: 5110
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1286802291870117
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.8970571756362915
        total_loss: -6.39518928527832
        var_gnorm: 63.734554290771484
        vf_explained_var: 0.9691537022590637
        vf_loss: 0.29053741693496704
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1274.0
  learner_queue:
    size_count: 1280
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2034949106664308
  num_agent_steps_sampled: 653950
  num_agent_steps_trained: 637000
  num_env_steps_sampled: 653950
  num_env_steps_trained: 637000
  num_samples_added_to_queue: 653500
  num_training_step_calls_since_last_synch_worker_weights: 657
  num_weight_broadcasts: 12826
  timing_breakdown:
    learner_dequeue_time_ms: 0.022
    learner_grad_time_ms: 214.597
    learner_load_time_ms: 3.128
    learner_load_wait_time_ms: 1.601
iterations_since_restore: 62
node_ip: 127.0.0.1
num_agent_steps_sampled: 653950
num_agent_steps_trained: 637000
num_env_steps_sampled: 653950
num_env_steps_sampled_this_iter: 12450
num_env_steps_sampled_throughput_per_sec: 1244.9948945254837
num_env_steps_trained: 637000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9950790607072
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.93571428571429
  ram_util_percent: 82.38571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07617901988531278
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029288115044903938
  mean_inference_ms: 1.4307515232325188
  mean_raw_obs_processing_ms: 0.3223919943699525
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02129340171813965
    StateBufferConnector_ms: 0.003758668899536133
    ViewRequirementAgentConnector_ms: 0.12592148780822754
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 0.67
  episode_reward_min: 0.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,
      0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0,
      1.0, 0.0, 3.0, 3.0, 4.0, 7.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 4.0,
      0.0, 3.0, 0.0, 2.0, 5.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07617901988531278
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029288115044903938
    mean_inference_ms: 1.4307515232325188
    mean_raw_obs_processing_ms: 0.3223919943699525
time_since_restore: 631.6711666584015
time_this_iter_s: 10.14555287361145
time_total_s: 631.6711666584015
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691994810
timesteps_total: 653950
training_iteration: 62
trial_id: default
train step: 63
agent_timesteps_total: 666100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023122549057006836
  StateBufferConnector_ms: 0.004975318908691406
  ViewRequirementAgentConnector_ms: 0.13440728187561035
counters:
  num_agent_steps_sampled: 666100
  num_agent_steps_trained: 649500
  num_env_steps_sampled: 666100
  num_env_steps_trained: 649500
  num_samples_added_to_queue: 666000
  num_training_step_calls_since_last_synch_worker_weights: 106
  num_weight_broadcasts: 13064
custom_metrics: {}
date: 2023-08-14_15-33-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.15
episode_reward_min: 0.0
episodes_this_iter: 95
episodes_total: 5205
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.29213285446167
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.7118091583251953
        total_loss: -1.4705438613891602
        var_gnorm: 63.737770080566406
        vf_explained_var: 0.9217616319656372
        vf_loss: 4.556621551513672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1299.0
  learner_queue:
    size_count: 1307
    size_mean: 15.04
    size_quantiles: [9.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.799555500672319
  num_agent_steps_sampled: 666100
  num_agent_steps_trained: 649500
  num_env_steps_sampled: 666100
  num_env_steps_trained: 649500
  num_samples_added_to_queue: 666000
  num_training_step_calls_since_last_synch_worker_weights: 106
  num_weight_broadcasts: 13064
  timing_breakdown:
    learner_dequeue_time_ms: 0.022
    learner_grad_time_ms: 97.471
    learner_load_time_ms: 1.884
    learner_load_wait_time_ms: 1.646
iterations_since_restore: 63
node_ip: 127.0.0.1
num_agent_steps_sampled: 666100
num_agent_steps_trained: 649500
num_env_steps_sampled: 666100
num_env_steps_sampled_this_iter: 12150
num_env_steps_sampled_throughput_per_sec: 1214.9952492899683
num_env_steps_trained: 649500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9951124382392
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 57.47142857142857
  ram_util_percent: 81.62142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07601582663913761
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029240320986686177
  mean_inference_ms: 1.4272707645790317
  mean_raw_obs_processing_ms: 0.321597296952226
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023122549057006836
    StateBufferConnector_ms: 0.004975318908691406
    ViewRequirementAgentConnector_ms: 0.13440728187561035
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.15
  episode_reward_min: 0.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 2.0, 5.0, 1.0, 1.0, 5.0, 4.0, 4.0, 3.0, 5.0, 5.0, 5.0, 5.0,
      8.0, 4.0, 9.0, 4.0, 6.0, 6.0, 7.0, 3.0, 3.0, 5.0, 5.0, 3.0, 6.0, 3.0, 5.0, 6.0,
      3.0, 1.0, 2.0, 5.0, 0.0, 5.0, 2.0, 5.0, 3.0, 3.0, 3.0, 5.0, 4.0, 1.0, 3.0, 5.0,
      2.0, 3.0, 5.0, 2.0, 0.0, 10.0, 2.0, 3.0, 3.0, 7.0, 5.0, 5.0, 2.0, 6.0, 6.0,
      3.0, 8.0, 6.0, 5.0, 5.0, 5.0, 4.0, 6.0, 5.0, 4.0, 9.0, 5.0, 1.0, 5.0, 5.0, 1.0,
      5.0, 5.0, 4.0, 4.0, 3.0, 3.0, 1.0, 7.0, 7.0, 6.0, 9.0, 5.0, 1.0, 3.0, 4.0, 4.0,
      3.0, 3.0, 3.0, 6.0, 2.0, 5.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07601582663913761
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029240320986686177
    mean_inference_ms: 1.4272707645790317
    mean_raw_obs_processing_ms: 0.321597296952226
time_since_restore: 641.8483505249023
time_this_iter_s: 10.177183866500854
time_total_s: 641.8483505249023
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691994820
timesteps_total: 666100
training_iteration: 63
trial_id: default
train step: 64
agent_timesteps_total: 676650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.026713848114013672
  StateBufferConnector_ms: 0.004846811294555664
  ViewRequirementAgentConnector_ms: 0.152451753616333
counters:
  num_agent_steps_sampled: 676650
  num_agent_steps_trained: 660000
  num_env_steps_sampled: 676650
  num_env_steps_trained: 660000
  num_samples_added_to_queue: 676500
  num_training_step_calls_since_last_synch_worker_weights: 190
  num_weight_broadcasts: 13272
custom_metrics: {}
date: 2023-08-14_15-33-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.73
episode_reward_min: 0.0
episodes_this_iter: 82
episodes_total: 5287
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9503713846206665
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -21.044862747192383
        total_loss: -5.218853950500488
        var_gnorm: 63.73957443237305
        vf_explained_var: 0.6319588422775269
        vf_loss: 41.155731201171875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1320.0
  learner_queue:
    size_count: 1326
    size_mean: 14.52
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.9923855048659636
  num_agent_steps_sampled: 676650
  num_agent_steps_trained: 660000
  num_env_steps_sampled: 676650
  num_env_steps_trained: 660000
  num_samples_added_to_queue: 676500
  num_training_step_calls_since_last_synch_worker_weights: 190
  num_weight_broadcasts: 13272
  timing_breakdown:
    learner_dequeue_time_ms: 0.02
    learner_grad_time_ms: 223.692
    learner_load_time_ms: 3.881
    learner_load_wait_time_ms: 1.968
iterations_since_restore: 64
node_ip: 127.0.0.1
num_agent_steps_sampled: 676650
num_agent_steps_trained: 660000
num_env_steps_sampled: 676650
num_env_steps_sampled_this_iter: 10550
num_env_steps_sampled_throughput_per_sec: 1054.9945920983005
num_env_steps_trained: 660000
num_env_steps_trained_this_iter: 10500
num_env_steps_trained_throughput_per_sec: 1049.9946177281663
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10500
perf:
  cpu_util_percent: 63.266666666666666
  ram_util_percent: 82.04666666666665
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07605545883916508
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029266106554414098
  mean_inference_ms: 1.4269380079208218
  mean_raw_obs_processing_ms: 0.3215160241434243
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.026713848114013672
    StateBufferConnector_ms: 0.004846811294555664
    ViewRequirementAgentConnector_ms: 0.152451753616333
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.73
  episode_reward_min: 0.0
  episodes_this_iter: 82
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 7.0, 7.0, 6.0, 9.0, 5.0, 1.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0,
      6.0, 2.0, 5.0, 4.0, 2.0, 4.0, 3.0, 2.0, 10.0, 2.0, 3.0, 5.0, 4.0, 2.0, 3.0,
      1.0, 5.0, 4.0, 2.0, 1.0, 2.0, 5.0, 4.0, 2.0, 2.0, 4.0, 4.0, 7.0, 4.0, 4.0, 4.0,
      2.0, 4.0, 7.0, 2.0, 5.0, 6.0, 3.0, 4.0, 8.0, 2.0, 9.0, 3.0, 3.0, 4.0, 5.0, 0.0,
      4.0, 3.0, 0.0, 0.0, 4.0, 8.0, 3.0, 4.0, 1.0, 5.0, 2.0, 5.0, 5.0, 2.0, 5.0, 6.0,
      3.0, 5.0, 6.0, 4.0, 2.0, 6.0, 4.0, 1.0, 3.0, 2.0, 5.0, 8.0, 3.0, 2.0, 1.0, 6.0,
      2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07605545883916508
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029266106554414098
    mean_inference_ms: 1.4269380079208218
    mean_raw_obs_processing_ms: 0.3215160241434243
time_since_restore: 652.004697561264
time_this_iter_s: 10.156347036361694
time_total_s: 652.004697561264
timers:
  sample_time_ms: 0.02
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.053
timestamp: 1691994830
timesteps_total: 676650
training_iteration: 64
trial_id: default
train step: 65
agent_timesteps_total: 688100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023432254791259766
  StateBufferConnector_ms: 0.004327297210693359
  ViewRequirementAgentConnector_ms: 0.13761615753173828
counters:
  num_agent_steps_sampled: 688100
  num_agent_steps_trained: 671500
  num_env_steps_sampled: 688100
  num_env_steps_trained: 671500
  num_samples_added_to_queue: 688000
  num_training_step_calls_since_last_synch_worker_weights: 520
  num_weight_broadcasts: 13498
custom_metrics: {}
date: 2023-08-14_15-34-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.93
episode_reward_min: 0.0
episodes_this_iter: 89
episodes_total: 5376
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.799999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.2152563333511353
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.253314971923828
        total_loss: -2.375594139099121
        var_gnorm: 63.74735641479492
        vf_explained_var: 0.7720934748649597
        vf_loss: 25.908004760742188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1343.0
  learner_queue:
    size_count: 1349
    size_mean: 14.32
    size_quantiles: [9.0, 11.0, 15.5, 16.0, 16.0]
    size_std: 2.08269056751117
  num_agent_steps_sampled: 688100
  num_agent_steps_trained: 671500
  num_env_steps_sampled: 688100
  num_env_steps_trained: 671500
  num_samples_added_to_queue: 688000
  num_training_step_calls_since_last_synch_worker_weights: 520
  num_weight_broadcasts: 13498
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 202.447
    learner_load_time_ms: 11.95
    learner_load_wait_time_ms: 1.722
iterations_since_restore: 65
node_ip: 127.0.0.1
num_agent_steps_sampled: 688100
num_agent_steps_trained: 671500
num_env_steps_sampled: 688100
num_env_steps_sampled_this_iter: 11450
num_env_steps_sampled_throughput_per_sec: 1144.995113512866
num_env_steps_trained: 671500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9950921744942
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 59.15714285714285
  ram_util_percent: 82.85714285714288
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0759527601646016
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029265777439051767
  mean_inference_ms: 1.4252206125362286
  mean_raw_obs_processing_ms: 0.3211717202166557
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023432254791259766
    StateBufferConnector_ms: 0.004327297210693359
    ViewRequirementAgentConnector_ms: 0.13761615753173828
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.93
  episode_reward_min: 0.0
  episodes_this_iter: 89
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 1.0, 6.0, 2.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 6.0, 4.0,
      3.0, 2.0, 1.0, 3.0, 7.0, 5.0, 8.0, 5.0, 3.0, 2.0, 5.0, 3.0, 1.0, 6.0, 4.0, 3.0,
      2.0, 2.0, 3.0, 7.0, 3.0, 10.0, 3.0, 7.0, 6.0, 3.0, 8.0, 4.0, 2.0, 8.0, 5.0,
      4.0, 4.0, 7.0, 6.0, 3.0, 2.0, 4.0, 2.0, 4.0, 2.0, 5.0, 1.0, 8.0, 2.0, 5.0, 3.0,
      3.0, 3.0, 1.0, 0.0, 6.0, 7.0, 6.0, 2.0, 9.0, 5.0, 4.0, 2.0, 2.0, 1.0, 4.0, 4.0,
      3.0, 2.0, 1.0, 1.0, 4.0, 7.0, 5.0, 3.0, 3.0, 5.0, 7.0, 2.0, 3.0, 2.0, 9.0, 7.0,
      5.0, 5.0, 3.0, 4.0, 5.0, 6.0, 2.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0759527601646016
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029265777439051767
    mean_inference_ms: 1.4252206125362286
    mean_raw_obs_processing_ms: 0.3211717202166557
time_since_restore: 662.1546356678009
time_this_iter_s: 10.149938106536865
time_total_s: 662.1546356678009
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691994840
timesteps_total: 688100
training_iteration: 65
trial_id: default
train step: 66
agent_timesteps_total: 697750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02796316146850586
  StateBufferConnector_ms: 0.004903316497802734
  ViewRequirementAgentConnector_ms: 0.15799379348754883
counters:
  num_agent_steps_sampled: 697750
  num_agent_steps_trained: 681000
  num_env_steps_sampled: 697750
  num_env_steps_trained: 681000
  num_samples_added_to_queue: 697500
  num_training_step_calls_since_last_synch_worker_weights: 720
  num_weight_broadcasts: 13688
custom_metrics: {}
date: 2023-08-14_15-34-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.74
episode_reward_min: 0.0
episodes_this_iter: 76
episodes_total: 5452
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.59999999999991
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.2185156345367432
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.114761352539062
        total_loss: -7.018360137939453
        var_gnorm: 63.75598907470703
        vf_explained_var: 0.7777539491653442
        vf_loss: 30.377958297729492
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1362.0
  learner_queue:
    size_count: 1367
    size_mean: 14.7
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.8027756377319946
  num_agent_steps_sampled: 697750
  num_agent_steps_trained: 681000
  num_env_steps_sampled: 697750
  num_env_steps_trained: 681000
  num_samples_added_to_queue: 697500
  num_training_step_calls_since_last_synch_worker_weights: 720
  num_weight_broadcasts: 13688
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 315.668
    learner_load_time_ms: 11.956
    learner_load_wait_time_ms: 1.896
iterations_since_restore: 66
node_ip: 127.0.0.1
num_agent_steps_sampled: 697750
num_agent_steps_trained: 681000
num_env_steps_sampled: 697750
num_env_steps_sampled_this_iter: 9650
num_env_steps_sampled_throughput_per_sec: 964.9965258961818
num_env_steps_trained: 681000
num_env_steps_trained_this_iter: 9500
num_env_steps_trained_throughput_per_sec: 949.9965798977955
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 9500
perf:
  cpu_util_percent: 65.02857142857142
  ram_util_percent: 83.83571428571427
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07607598756532875
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029330945020355815
  mean_inference_ms: 1.4262505491989697
  mean_raw_obs_processing_ms: 0.3213942546458945
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02796316146850586
    StateBufferConnector_ms: 0.004903316497802734
    ViewRequirementAgentConnector_ms: 0.15799379348754883
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.74
  episode_reward_min: 0.0
  episodes_this_iter: 76
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 1.0, 1.0, 4.0, 7.0, 5.0, 3.0, 3.0, 5.0, 7.0, 2.0, 3.0,
      2.0, 9.0, 7.0, 5.0, 5.0, 3.0, 4.0, 5.0, 6.0, 2.0, 5.0, 2.0, 4.0, 5.0, 4.0, 4.0,
      8.0, 9.0, 1.0, 9.0, 3.0, 2.0, 6.0, 2.0, 2.0, 1.0, 10.0, 8.0, 2.0, 6.0, 3.0,
      4.0, 4.0, 9.0, 4.0, 8.0, 7.0, 6.0, 5.0, 6.0, 3.0, 4.0, 3.0, 5.0, 7.0, 6.0, 6.0,
      4.0, 10.0, 5.0, 3.0, 3.0, 3.0, 4.0, 7.0, 4.0, 2.0, 7.0, 5.0, 5.0, 3.0, 4.0,
      4.0, 3.0, 8.0, 2.0, 5.0, 0.0, 8.0, 2.0, 5.0, 3.0, 3.0, 4.0, 7.0, 8.0, 8.0, 6.0,
      5.0, 3.0, 4.0, 6.0, 7.0, 11.0, 6.0, 6.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07607598756532875
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029330945020355815
    mean_inference_ms: 1.4262505491989697
    mean_raw_obs_processing_ms: 0.3213942546458945
time_since_restore: 672.2869086265564
time_this_iter_s: 10.132272958755493
time_total_s: 672.2869086265564
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691994850
timesteps_total: 697750
training_iteration: 66
trial_id: default
train step: 67
agent_timesteps_total: 709350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.026737451553344727
  StateBufferConnector_ms: 0.0043468475341796875
  ViewRequirementAgentConnector_ms: 0.1469571590423584
counters:
  num_agent_steps_sampled: 709350
  num_agent_steps_trained: 692500
  num_env_steps_sampled: 709350
  num_env_steps_trained: 692500
  num_samples_added_to_queue: 709000
  num_training_step_calls_since_last_synch_worker_weights: 1150
  num_weight_broadcasts: 13916
custom_metrics: {}
date: 2023-08-14_15-34-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.25
episode_reward_min: 2.0
episodes_this_iter: 90
episodes_total: 5542
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0269553661346436
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.153522491455078
        total_loss: 11.322559356689453
        var_gnorm: 63.769920349121094
        vf_explained_var: 0.8629881739616394
        vf_loss: 26.607627868652344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1385.0
  learner_queue:
    size_count: 1390
    size_mean: 14.92
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5979987484350542
  num_agent_steps_sampled: 709350
  num_agent_steps_trained: 692500
  num_env_steps_sampled: 709350
  num_env_steps_trained: 692500
  num_samples_added_to_queue: 709000
  num_training_step_calls_since_last_synch_worker_weights: 1150
  num_weight_broadcasts: 13916
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 327.125
    learner_load_time_ms: 11.958
    learner_load_wait_time_ms: 1.772
iterations_since_restore: 67
node_ip: 127.0.0.1
num_agent_steps_sampled: 709350
num_agent_steps_trained: 692500
num_env_steps_sampled: 709350
num_env_steps_sampled_this_iter: 11600
num_env_steps_sampled_throughput_per_sec: 1159.9980363879065
num_env_steps_trained: 692500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.998053315597
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 59.2
  ram_util_percent: 82.80666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07595436401128651
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029327074817983228
  mean_inference_ms: 1.424900993941085
  mean_raw_obs_processing_ms: 0.3211813456846267
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.026737451553344727
    StateBufferConnector_ms: 0.0043468475341796875
    ViewRequirementAgentConnector_ms: 0.1469571590423584
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.25
  episode_reward_min: 2.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 5.0, 3.0, 4.0, 6.0, 7.0, 11.0, 6.0, 6.0, 4.0, 6.0, 11.0,
      7.0, 6.0, 3.0, 9.0, 2.0, 4.0, 4.0, 6.0, 5.0, 10.0, 6.0, 5.0, 9.0, 2.0, 5.0,
      10.0, 9.0, 5.0, 4.0, 6.0, 5.0, 6.0, 3.0, 10.0, 3.0, 8.0, 7.0, 4.0, 6.0, 8.0,
      4.0, 8.0, 11.0, 8.0, 5.0, 2.0, 8.0, 8.0, 9.0, 7.0, 5.0, 6.0, 9.0, 4.0, 7.0,
      8.0, 10.0, 3.0, 4.0, 2.0, 6.0, 7.0, 8.0, 8.0, 2.0, 8.0, 8.0, 4.0, 3.0, 4.0,
      4.0, 4.0, 6.0, 3.0, 8.0, 4.0, 5.0, 4.0, 4.0, 6.0, 11.0, 6.0, 8.0, 10.0, 4.0,
      8.0, 5.0, 7.0, 5.0, 11.0, 7.0, 5.0, 13.0, 5.0, 6.0, 9.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07595436401128651
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029327074817983228
    mean_inference_ms: 1.424900993941085
    mean_raw_obs_processing_ms: 0.3211813456846267
time_since_restore: 682.4979205131531
time_this_iter_s: 10.21101188659668
time_total_s: 682.4979205131531
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.044
timestamp: 1691994860
timesteps_total: 709350
training_iteration: 67
trial_id: default
train step: 68
agent_timesteps_total: 720300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024827241897583008
  StateBufferConnector_ms: 0.004764080047607422
  ViewRequirementAgentConnector_ms: 0.16148996353149414
counters:
  num_agent_steps_sampled: 720300
  num_agent_steps_trained: 703500
  num_env_steps_sampled: 720300
  num_env_steps_trained: 703500
  num_samples_added_to_queue: 720000
  num_training_step_calls_since_last_synch_worker_weights: 682
  num_weight_broadcasts: 14132
custom_metrics: {}
date: 2023-08-14_15-34-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.5
episode_reward_min: 2.0
episodes_this_iter: 86
episodes_total: 5628
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9852244853973389
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 14.437679290771484
        total_loss: 33.77482986450195
        var_gnorm: 63.78560256958008
        vf_explained_var: 0.8144417405128479
        vf_loss: 48.52654266357422
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1407.0
  learner_queue:
    size_count: 1413
    size_mean: 15.04
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4691494137765566
  num_agent_steps_sampled: 720300
  num_agent_steps_trained: 703500
  num_env_steps_sampled: 720300
  num_env_steps_trained: 703500
  num_samples_added_to_queue: 720000
  num_training_step_calls_since_last_synch_worker_weights: 682
  num_weight_broadcasts: 14132
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 234.737
    learner_load_time_ms: 12.998
    learner_load_wait_time_ms: 1.633
iterations_since_restore: 68
node_ip: 127.0.0.1
num_agent_steps_sampled: 720300
num_agent_steps_trained: 703500
num_env_steps_sampled: 720300
num_env_steps_sampled_this_iter: 10950
num_env_steps_sampled_throughput_per_sec: 1094.9955096428953
num_env_steps_trained: 703500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9954891389816
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 62.82142857142857
  ram_util_percent: 83.95
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07591119138925868
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029340518632790094
  mean_inference_ms: 1.4238306693883431
  mean_raw_obs_processing_ms: 0.3210354179469791
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024827241897583008
    StateBufferConnector_ms: 0.004764080047607422
    ViewRequirementAgentConnector_ms: 0.16148996353149414
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.5
  episode_reward_min: 2.0
  episodes_this_iter: 86
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 8.0, 5.0, 7.0, 5.0, 11.0, 7.0, 5.0, 13.0, 5.0, 6.0, 9.0,
      9.0, 10.0, 2.0, 7.0, 7.0, 10.0, 7.0, 8.0, 7.0, 7.0, 7.0, 10.0, 8.0, 4.0, 6.0,
      7.0, 4.0, 4.0, 5.0, 12.0, 4.0, 12.0, 9.0, 10.0, 9.0, 8.0, 7.0, 7.0, 10.0, 7.0,
      4.0, 13.0, 7.0, 10.0, 4.0, 5.0, 4.0, 5.0, 6.0, 8.0, 5.0, 5.0, 11.0, 8.0, 11.0,
      10.0, 8.0, 8.0, 7.0, 8.0, 2.0, 9.0, 6.0, 9.0, 10.0, 10.0, 8.0, 4.0, 7.0, 8.0,
      4.0, 9.0, 9.0, 10.0, 5.0, 10.0, 2.0, 7.0, 5.0, 12.0, 9.0, 3.0, 14.0, 12.0, 12.0,
      9.0, 8.0, 5.0, 7.0, 7.0, 7.0, 6.0, 6.0, 7.0, 8.0, 8.0, 12.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07591119138925868
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029340518632790094
    mean_inference_ms: 1.4238306693883431
    mean_raw_obs_processing_ms: 0.3210354179469791
time_since_restore: 692.6516873836517
time_this_iter_s: 10.153766870498657
time_total_s: 692.6516873836517
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691994871
timesteps_total: 720300
training_iteration: 68
trial_id: default
train step: 69
agent_timesteps_total: 733450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02035122473263046
  StateBufferConnector_ms: 0.00371076528308461
  ViewRequirementAgentConnector_ms: 0.12164254790370904
counters:
  num_agent_steps_sampled: 733450
  num_agent_steps_trained: 716500
  num_env_steps_sampled: 733450
  num_env_steps_trained: 716500
  num_samples_added_to_queue: 733000
  num_training_step_calls_since_last_synch_worker_weights: 156
  num_weight_broadcasts: 14392
custom_metrics: {}
date: 2023-08-14_15-34-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.223300970873787
episode_reward_min: 2.0
episodes_this_iter: 103
episodes_total: 5731
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7808717489242554
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 14.284409523010254
        total_loss: 42.99164581298828
        var_gnorm: 63.80707931518555
        vf_explained_var: 0.8274776935577393
        vf_loss: 65.22319030761719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1433.0
  learner_queue:
    size_count: 1440
    size_mean: 15.0
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.697056274847714
  num_agent_steps_sampled: 733450
  num_agent_steps_trained: 716500
  num_env_steps_sampled: 733450
  num_env_steps_trained: 716500
  num_samples_added_to_queue: 733000
  num_training_step_calls_since_last_synch_worker_weights: 156
  num_weight_broadcasts: 14392
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 160.844
    learner_load_time_ms: 13.007
    learner_load_wait_time_ms: 1.537
iterations_since_restore: 69
node_ip: 127.0.0.1
num_agent_steps_sampled: 733450
num_agent_steps_trained: 716500
num_env_steps_sampled: 733450
num_env_steps_sampled_this_iter: 13150
num_env_steps_sampled_throughput_per_sec: 1314.9997178316721
num_env_steps_trained: 716500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9997210503223
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.00000000000001
  ram_util_percent: 81.39999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07559216119689532
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029252647282773096
  mean_inference_ms: 1.4187726626249517
  mean_raw_obs_processing_ms: 0.31997789096365636
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02035122473263046
    StateBufferConnector_ms: 0.00371076528308461
    ViewRequirementAgentConnector_ms: 0.12164254790370904
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.223300970873787
  episode_reward_min: 2.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 4.0, 8.0, 5.0, 2.0, 6.0, 10.0, 7.0, 11.0, 10.0, 10.0, 11.0,
      12.0, 6.0, 8.0, 8.0, 13.0, 6.0, 10.0, 8.0, 8.0, 11.0, 7.0, 7.0, 7.0, 9.0, 9.0,
      9.0, 7.0, 9.0, 11.0, 9.0, 8.0, 9.0, 2.0, 9.0, 9.0, 12.0, 8.0, 5.0, 7.0, 10.0,
      6.0, 8.0, 8.0, 8.0, 11.0, 11.0, 9.0, 11.0, 8.0, 3.0, 7.0, 8.0, 5.0, 11.0, 10.0,
      6.0, 7.0, 7.0, 7.0, 11.0, 2.0, 8.0, 9.0, 9.0, 6.0, 8.0, 11.0, 10.0, 8.0, 6.0,
      7.0, 6.0, 7.0, 6.0, 9.0, 11.0, 6.0, 8.0, 7.0, 8.0, 9.0, 7.0, 8.0, 15.0, 8.0,
      8.0, 13.0, 10.0, 8.0, 6.0, 10.0, 8.0, 14.0, 11.0, 8.0, 10.0, 6.0, 9.0, 9.0,
      5.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07559216119689532
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029252647282773096
    mean_inference_ms: 1.4187726626249517
    mean_raw_obs_processing_ms: 0.31997789096365636
time_since_restore: 702.8141465187073
time_this_iter_s: 10.162459135055542
time_total_s: 702.8141465187073
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691994881
timesteps_total: 733450
training_iteration: 69
trial_id: default
train step: 70
agent_timesteps_total: 746600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0204313035104789
  StateBufferConnector_ms: 0.0035063893187279793
  ViewRequirementAgentConnector_ms: 0.12191931406656902
counters:
  num_agent_steps_sampled: 746600
  num_agent_steps_trained: 730000
  num_env_steps_sampled: 746600
  num_env_steps_trained: 730000
  num_samples_added_to_queue: 746500
  num_training_step_calls_since_last_synch_worker_weights: 472
  num_weight_broadcasts: 14652
custom_metrics: {}
date: 2023-08-14_15-34-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.46078431372549
episode_reward_min: 3.0
episodes_this_iter: 102
episodes_total: 5833
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7753706574440002
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 35.20042037963867
        total_loss: 62.99018096923828
        var_gnorm: 63.8274040222168
        vf_explained_var: 0.9337252974510193
        vf_loss: 63.33323287963867
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1460.0
  learner_queue:
    size_count: 1466
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6326665305566843
  num_agent_steps_sampled: 746600
  num_agent_steps_trained: 730000
  num_env_steps_sampled: 746600
  num_env_steps_trained: 730000
  num_samples_added_to_queue: 746500
  num_training_step_calls_since_last_synch_worker_weights: 472
  num_weight_broadcasts: 14652
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 176.869
    learner_load_time_ms: 13.0
    learner_load_wait_time_ms: 1.487
iterations_since_restore: 70
node_ip: 127.0.0.1
num_agent_steps_sampled: 746600
num_agent_steps_trained: 730000
num_env_steps_sampled: 746600
num_env_steps_sampled_this_iter: 13150
num_env_steps_sampled_throughput_per_sec: 1314.9976486009682
num_env_steps_trained: 730000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.997586016203
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.771428571428565
  ram_util_percent: 80.86428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07533918529252762
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02916446726261156
  mean_inference_ms: 1.4138307793996803
  mean_raw_obs_processing_ms: 0.31895442194874707
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0204313035104789
    StateBufferConnector_ms: 0.0035063893187279793
    ViewRequirementAgentConnector_ms: 0.12191931406656902
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.46078431372549
  episode_reward_min: 3.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 12.0, 7.0, 9.0, 7.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0,
      11.0, 8.0, 9.0, 11.0, 7.0, 7.0, 10.0, 12.0, 6.0, 7.0, 9.0, 9.0, 8.0, 5.0, 12.0,
      4.0, 5.0, 8.0, 6.0, 9.0, 6.0, 5.0, 9.0, 6.0, 6.0, 8.0, 10.0, 8.0, 7.0, 9.0,
      7.0, 6.0, 8.0, 7.0, 5.0, 12.0, 6.0, 10.0, 8.0, 9.0, 14.0, 5.0, 10.0, 3.0, 12.0,
      12.0, 9.0, 6.0, 9.0, 9.0, 11.0, 10.0, 12.0, 8.0, 9.0, 11.0, 10.0, 10.0, 7.0,
      12.0, 8.0, 7.0, 9.0, 7.0, 8.0, 10.0, 10.0, 10.0, 11.0, 6.0, 8.0, 8.0, 7.0, 8.0,
      8.0, 6.0, 4.0, 10.0, 9.0, 8.0, 10.0, 16.0, 8.0, 6.0, 7.0, 13.0, 5.0, 8.0, 9.0,
      4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07533918529252762
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02916446726261156
    mean_inference_ms: 1.4138307793996803
    mean_raw_obs_processing_ms: 0.31895442194874707
time_since_restore: 712.9616055488586
time_this_iter_s: 10.147459030151367
time_total_s: 712.9616055488586
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691994891
timesteps_total: 746600
training_iteration: 70
trial_id: default
train step: 71
agent_timesteps_total: 759550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020389229643578623
  StateBufferConnector_ms: 0.0036277023016237746
  ViewRequirementAgentConnector_ms: 0.12255556443158318
counters:
  num_agent_steps_sampled: 759550
  num_agent_steps_trained: 743000
  num_env_steps_sampled: 759550
  num_env_steps_trained: 743000
  num_samples_added_to_queue: 759500
  num_training_step_calls_since_last_synch_worker_weights: 213
  num_weight_broadcasts: 14907
custom_metrics: {}
date: 2023-08-14_15-35-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.637254901960785
episode_reward_min: 2.0
episodes_this_iter: 102
episodes_total: 5935
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4719400703907013
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.295257568359375
        total_loss: 18.921722412109375
        var_gnorm: 63.84750747680664
        vf_explained_var: 0.9548357725143433
        vf_loss: 63.153358459472656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1486.0
  learner_queue:
    size_count: 1493
    size_mean: 15.04
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.70833252032501
  num_agent_steps_sampled: 759550
  num_agent_steps_trained: 743000
  num_env_steps_sampled: 759550
  num_env_steps_trained: 743000
  num_samples_added_to_queue: 759500
  num_training_step_calls_since_last_synch_worker_weights: 213
  num_weight_broadcasts: 14907
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 142.519
    learner_load_time_ms: 2.519
    learner_load_wait_time_ms: 1.491
iterations_since_restore: 71
node_ip: 127.0.0.1
num_agent_steps_sampled: 759550
num_agent_steps_trained: 743000
num_env_steps_sampled: 759550
num_env_steps_sampled_this_iter: 12950
num_env_steps_sampled_throughput_per_sec: 1294.9978078640852
num_env_steps_trained: 743000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.99779940024
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.642857142857146
  ram_util_percent: 80.57857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07512009375301648
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029089621731624552
  mean_inference_ms: 1.4094841445583954
  mean_raw_obs_processing_ms: 0.3180481920729806
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020389229643578623
    StateBufferConnector_ms: 0.0036277023016237746
    ViewRequirementAgentConnector_ms: 0.12255556443158318
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.637254901960785
  episode_reward_min: 2.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 6.0, 10.0, 5.0, 9.0, 8.0, 9.0, 11.0, 7.0, 8.0, 7.0, 7.0,
      14.0, 3.0, 5.0, 5.0, 9.0, 4.0, 12.0, 5.0, 5.0, 8.0, 8.0, 12.0, 2.0, 7.0, 7.0,
      7.0, 9.0, 7.0, 6.0, 6.0, 3.0, 9.0, 8.0, 4.0, 9.0, 7.0, 8.0, 8.0, 7.0, 8.0, 5.0,
      9.0, 5.0, 8.0, 3.0, 5.0, 8.0, 5.0, 5.0, 8.0, 8.0, 6.0, 3.0, 11.0, 10.0, 6.0,
      8.0, 6.0, 6.0, 10.0, 5.0, 5.0, 12.0, 4.0, 4.0, 6.0, 13.0, 6.0, 4.0, 4.0, 5.0,
      10.0, 5.0, 9.0, 11.0, 7.0, 6.0, 5.0, 6.0, 6.0, 5.0, 7.0, 3.0, 5.0, 9.0, 8.0,
      7.0, 6.0, 6.0, 4.0, 5.0, 4.0, 5.0, 5.0, 6.0, 4.0, 2.0, 4.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07512009375301648
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029089621731624552
    mean_inference_ms: 1.4094841445583954
    mean_raw_obs_processing_ms: 0.3180481920729806
time_since_restore: 723.1465635299683
time_this_iter_s: 10.18495798110962
time_total_s: 723.1465635299683
timers:
  sample_time_ms: 0.022
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.053
timestamp: 1691994901
timesteps_total: 759550
training_iteration: 71
trial_id: default
train step: 72
agent_timesteps_total: 772150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02184915542602539
  StateBufferConnector_ms: 0.0037970542907714844
  ViewRequirementAgentConnector_ms: 0.12816095352172852
counters:
  num_agent_steps_sampled: 772150
  num_agent_steps_trained: 755500
  num_env_steps_sampled: 772150
  num_env_steps_trained: 755500
  num_samples_added_to_queue: 772000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 15156
custom_metrics: {}
date: 2023-08-14_15-35-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 5.04
episode_reward_min: 0.0
episodes_this_iter: 97
episodes_total: 6032
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6405585408210754
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -17.273115158081055
        total_loss: 15.802999496459961
        var_gnorm: 63.855125427246094
        vf_explained_var: 0.9317766427993774
        vf_loss: 72.55781555175781
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1511.0
  learner_queue:
    size_count: 1515
    size_mean: 14.9
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.7916472867168918
  num_agent_steps_sampled: 772150
  num_agent_steps_trained: 755500
  num_env_steps_sampled: 772150
  num_env_steps_trained: 755500
  num_samples_added_to_queue: 772000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 15156
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 262.78
    learner_load_time_ms: 2.51
    learner_load_wait_time_ms: 1.623
iterations_since_restore: 72
node_ip: 127.0.0.1
num_agent_steps_sampled: 772150
num_agent_steps_trained: 755500
num_env_steps_sampled: 772150
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9348750398376
num_env_steps_trained: 755500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.935391904601
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 54.25714285714285
  ram_util_percent: 80.45714285714284
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07496885167870102
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.029037212002101794
  mean_inference_ms: 1.405925472008766
  mean_raw_obs_processing_ms: 0.3172976829745027
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02184915542602539
    StateBufferConnector_ms: 0.0037970542907714844
    ViewRequirementAgentConnector_ms: 0.12816095352172852
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 5.04
  episode_reward_min: 0.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 4.0, 2.0, 8.0, 1.0, 6.0, 5.0, 5.0, 7.0, 9.0, 4.0, 5.0, 8.0,
      5.0, 7.0, 6.0, 9.0, 4.0, 5.0, 5.0, 1.0, 6.0, 7.0, 5.0, 8.0, 6.0, 6.0, 4.0, 3.0,
      4.0, 7.0, 0.0, 5.0, 7.0, 5.0, 10.0, 2.0, 3.0, 0.0, 5.0, 8.0, 2.0, 5.0, 9.0,
      9.0, 1.0, 6.0, 4.0, 8.0, 8.0, 3.0, 5.0, 6.0, 3.0, 2.0, 4.0, 5.0, 5.0, 3.0, 3.0,
      8.0, 3.0, 3.0, 6.0, 3.0, 3.0, 4.0, 4.0, 6.0, 5.0, 6.0, 2.0, 3.0, 7.0, 5.0, 3.0,
      1.0, 5.0, 7.0, 6.0, 7.0, 5.0, 5.0, 3.0, 5.0, 8.0, 5.0, 4.0, 9.0, 6.0, 5.0, 7.0,
      9.0, 4.0, 4.0, 5.0, 3.0, 7.0, 9.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07496885167870102
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.029037212002101794
    mean_inference_ms: 1.405925472008766
    mean_raw_obs_processing_ms: 0.3172976829745027
time_since_restore: 733.2412962913513
time_this_iter_s: 10.094732761383057
time_total_s: 733.2412962913513
timers:
  sample_time_ms: 0.038
  synch_weights_time_ms: 0.258
  training_iteration_time_ms: 0.359
timestamp: 1691994911
timesteps_total: 772150
training_iteration: 72
trial_id: default
train step: 73
agent_timesteps_total: 784850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02066946029663086
  StateBufferConnector_ms: 0.003704071044921875
  ViewRequirementAgentConnector_ms: 0.12333846092224121
counters:
  num_agent_steps_sampled: 784850
  num_agent_steps_trained: 768000
  num_env_steps_sampled: 784850
  num_env_steps_trained: 768000
  num_samples_added_to_queue: 784500
  num_training_step_calls_since_last_synch_worker_weights: 417
  num_weight_broadcasts: 15407
custom_metrics: {}
date: 2023-08-14_15-35-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 5.11
episode_reward_min: 1.0
episodes_this_iter: 100
episodes_total: 6132
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6012193560600281
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.726199150085449
        total_loss: 12.894932746887207
        var_gnorm: 63.854759216308594
        vf_explained_var: 0.9268341660499573
        vf_loss: 24.349660873413086
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1536.0
  learner_queue:
    size_count: 1543
    size_mean: 15.2
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5620499351813308
  num_agent_steps_sampled: 784850
  num_agent_steps_trained: 768000
  num_env_steps_sampled: 784850
  num_env_steps_trained: 768000
  num_samples_added_to_queue: 784500
  num_training_step_calls_since_last_synch_worker_weights: 417
  num_weight_broadcasts: 15407
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 161.946
    learner_load_time_ms: 2.492
    learner_load_wait_time_ms: 1.552
iterations_since_restore: 73
node_ip: 127.0.0.1
num_agent_steps_sampled: 784850
num_agent_steps_trained: 768000
num_env_steps_sampled: 784850
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.993399177527
num_env_steps_trained: 768000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9935031274872
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.92666666666666
  ram_util_percent: 80.46
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07474756816007604
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028966864807474096
  mean_inference_ms: 1.4022333087766194
  mean_raw_obs_processing_ms: 0.3164584497538685
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02066946029663086
    StateBufferConnector_ms: 0.003704071044921875
    ViewRequirementAgentConnector_ms: 0.12333846092224121
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 5.11
  episode_reward_min: 1.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 5.0, 8.0, 5.0, 5.0, 5.0, 6.0, 3.0, 4.0, 8.0, 5.0, 4.0, 8.0,
      3.0, 4.0, 6.0, 6.0, 4.0, 4.0, 2.0, 8.0, 7.0, 6.0, 4.0, 7.0, 4.0, 5.0, 7.0, 3.0,
      9.0, 5.0, 2.0, 1.0, 4.0, 4.0, 6.0, 4.0, 5.0, 6.0, 2.0, 9.0, 5.0, 5.0, 3.0, 4.0,
      4.0, 4.0, 3.0, 2.0, 6.0, 7.0, 4.0, 8.0, 5.0, 5.0, 6.0, 4.0, 1.0, 1.0, 6.0, 8.0,
      5.0, 5.0, 4.0, 5.0, 9.0, 4.0, 8.0, 8.0, 8.0, 7.0, 6.0, 5.0, 3.0, 4.0, 6.0, 4.0,
      6.0, 13.0, 3.0, 7.0, 5.0, 5.0, 5.0, 6.0, 4.0, 3.0, 6.0, 6.0, 4.0, 2.0, 6.0,
      5.0, 6.0, 6.0, 7.0, 1.0, 6.0, 6.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07474756816007604
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028966864807474096
    mean_inference_ms: 1.4022333087766194
    mean_raw_obs_processing_ms: 0.3164584497538685
time_since_restore: 743.4076101779938
time_this_iter_s: 10.166313886642456
time_total_s: 743.4076101779938
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691994921
timesteps_total: 784850
training_iteration: 73
trial_id: default
train step: 74
agent_timesteps_total: 797900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019883408265955308
  StateBufferConnector_ms: 0.0035599166271733304
  ViewRequirementAgentConnector_ms: 0.11998438367656633
counters:
  num_agent_steps_sampled: 797900
  num_agent_steps_trained: 781000
  num_env_steps_sampled: 797900
  num_env_steps_trained: 781000
  num_samples_added_to_queue: 797500
  num_training_step_calls_since_last_synch_worker_weights: 755
  num_weight_broadcasts: 15665
custom_metrics: {}
date: 2023-08-14_15-35-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 5.245098039215686
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 6234
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7915797233581543
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.8864624500274658
        total_loss: 23.176633834838867
        var_gnorm: 63.863040924072266
        vf_explained_var: 0.8499822616577148
        vf_loss: 50.49613952636719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1562.0
  learner_queue:
    size_count: 1569
    size_mean: 15.0
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7776388834631178
  num_agent_steps_sampled: 797900
  num_agent_steps_trained: 781000
  num_env_steps_sampled: 797900
  num_env_steps_trained: 781000
  num_samples_added_to_queue: 797500
  num_training_step_calls_since_last_synch_worker_weights: 755
  num_weight_broadcasts: 15665
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 178.227
    learner_load_time_ms: 1.348
    learner_load_wait_time_ms: 1.514
iterations_since_restore: 74
node_ip: 127.0.0.1
num_agent_steps_sampled: 797900
num_agent_steps_trained: 781000
num_env_steps_sampled: 797900
num_env_steps_sampled_this_iter: 13050
num_env_steps_sampled_throughput_per_sec: 1304.9956129936832
num_env_steps_trained: 781000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9956298021364
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.714285714285715
  ram_util_percent: 79.50714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07453115292253788
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028888777048573594
  mean_inference_ms: 1.3981181344274132
  mean_raw_obs_processing_ms: 0.31557938053986256
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019883408265955308
    StateBufferConnector_ms: 0.0035599166271733304
    ViewRequirementAgentConnector_ms: 0.11998438367656633
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 5.245098039215686
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 4.0, 6.0, 8.0, 7.0, 4.0, 5.0, 5.0, 5.0, 7.0, 4.0, 2.0, 2.0,
      6.0, 4.0, 5.0, 4.0, 3.0, 4.0, 7.0, 5.0, 4.0, 6.0, 3.0, 5.0, 3.0, 2.0, 4.0, 2.0,
      3.0, 2.0, 5.0, 5.0, 3.0, 9.0, 7.0, 10.0, 3.0, 3.0, 6.0, 4.0, 5.0, 11.0, 9.0,
      12.0, 6.0, 9.0, 8.0, 6.0, 5.0, 4.0, 7.0, 5.0, 6.0, 2.0, 4.0, 2.0, 4.0, 3.0,
      2.0, 3.0, 8.0, 6.0, 5.0, 4.0, 3.0, 6.0, 5.0, 4.0, 1.0, 3.0, 2.0, 9.0, 3.0, 9.0,
      4.0, 7.0, 0.0, 4.0, 8.0, 6.0, 2.0, 6.0, 3.0, 6.0, 5.0, 8.0, 5.0, 9.0, 5.0, 10.0,
      9.0, 1.0, 8.0, 6.0, 8.0, 5.0, 5.0, 9.0, 13.0, 9.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07453115292253788
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028888777048573594
    mean_inference_ms: 1.3981181344274132
    mean_raw_obs_processing_ms: 0.31557938053986256
time_since_restore: 753.5698120594025
time_this_iter_s: 10.162201881408691
time_total_s: 753.5698120594025
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691994932
timesteps_total: 797900
training_iteration: 74
trial_id: default
train step: 75
agent_timesteps_total: 811000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020705611960401812
  StateBufferConnector_ms: 0.003776041049401737
  ViewRequirementAgentConnector_ms: 0.12159995662355885
counters:
  num_agent_steps_sampled: 811000
  num_agent_steps_trained: 794500
  num_env_steps_sampled: 811000
  num_env_steps_trained: 794500
  num_samples_added_to_queue: 811000
  num_training_step_calls_since_last_synch_worker_weights: 1494
  num_weight_broadcasts: 15924
custom_metrics: {}
date: 2023-08-14_15-35-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.941747572815534
episode_reward_min: 0.0
episodes_this_iter: 103
episodes_total: 6337
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5555923581123352
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.9956923723220825
        total_loss: 2.9142541885375977
        var_gnorm: 63.87644577026367
        vf_explained_var: 0.9577099084854126
        vf_loss: 13.375816345214844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1589.0
  learner_queue:
    size_count: 1593
    size_mean: 15.14
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.549322432549145
  num_agent_steps_sampled: 811000
  num_agent_steps_trained: 794500
  num_env_steps_sampled: 811000
  num_env_steps_trained: 794500
  num_samples_added_to_queue: 811000
  num_training_step_calls_since_last_synch_worker_weights: 1494
  num_weight_broadcasts: 15924
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 259.976
    learner_load_time_ms: 1.34
    learner_load_wait_time_ms: 1.762
iterations_since_restore: 75
node_ip: 127.0.0.1
num_agent_steps_sampled: 811000
num_agent_steps_trained: 794500
num_env_steps_sampled: 811000
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.994003323349
num_env_steps_trained: 794500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9938202187184
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.82857142857143
  ram_util_percent: 76.17142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07432040233522562
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028808406537082085
  mean_inference_ms: 1.3939913270175168
  mean_raw_obs_processing_ms: 0.31469905261943903
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020705611960401812
    StateBufferConnector_ms: 0.003776041049401737
    ViewRequirementAgentConnector_ms: 0.12159995662355885
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.941747572815534
  episode_reward_min: 0.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 9.0, 6.0, 5.0, 4.0, 9.0, 8.0, 6.0, 1.0, 6.0, 3.0, 7.0,
      5.0, 7.0, 8.0, 4.0, 7.0, 3.0, 4.0, 5.0, 6.0, 9.0, 4.0, 9.0, 3.0, 9.0, 3.0, 7.0,
      8.0, 8.0, 4.0, 5.0, 10.0, 8.0, 5.0, 5.0, 5.0, 11.0, 12.0, 7.0, 13.0, 8.0, 8.0,
      6.0, 12.0, 7.0, 5.0, 13.0, 7.0, 4.0, 4.0, 7.0, 7.0, 8.0, 0.0, 9.0, 12.0, 4.0,
      8.0, 4.0, 7.0, 4.0, 7.0, 8.0, 8.0, 3.0, 5.0, 7.0, 7.0, 7.0, 9.0, 4.0, 8.0, 8.0,
      6.0, 7.0, 7.0, 7.0, 7.0, 9.0, 11.0, 7.0, 9.0, 3.0, 12.0, 9.0, 7.0, 7.0, 5.0,
      9.0, 10.0, 9.0, 11.0, 5.0, 9.0, 9.0, 6.0, 8.0, 9.0, 5.0, 4.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07432040233522562
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028808406537082085
    mean_inference_ms: 1.3939913270175168
    mean_raw_obs_processing_ms: 0.31469905261943903
time_since_restore: 763.7085230350494
time_this_iter_s: 10.138710975646973
time_total_s: 763.7085230350494
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691994942
timesteps_total: 811000
training_iteration: 75
trial_id: default
train step: 76
agent_timesteps_total: 824100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020180262771307255
  StateBufferConnector_ms: 0.003440707337622549
  ViewRequirementAgentConnector_ms: 0.1194145165237726
counters:
  num_agent_steps_sampled: 824100
  num_agent_steps_trained: 807500
  num_env_steps_sampled: 824100
  num_env_steps_trained: 807500
  num_samples_added_to_queue: 824000
  num_training_step_calls_since_last_synch_worker_weights: 432
  num_weight_broadcasts: 16179
custom_metrics: {}
date: 2023-08-14_15-35-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 6.392156862745098
episode_reward_min: 2.0
episodes_this_iter: 102
episodes_total: 6439
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5702272057533264
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -26.47040557861328
        total_loss: -6.819348335266113
        var_gnorm: 63.88915252685547
        vf_explained_var: 0.8873735666275024
        vf_loss: 45.00438690185547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1615.0
  learner_queue:
    size_count: 1622
    size_mean: 15.42
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3577923257994944
  num_agent_steps_sampled: 824100
  num_agent_steps_trained: 807500
  num_env_steps_sampled: 824100
  num_env_steps_trained: 807500
  num_samples_added_to_queue: 824000
  num_training_step_calls_since_last_synch_worker_weights: 432
  num_weight_broadcasts: 16179
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 136.57
    learner_load_time_ms: 1.348
    learner_load_wait_time_ms: 1.572
iterations_since_restore: 76
node_ip: 127.0.0.1
num_agent_steps_sampled: 824100
num_agent_steps_trained: 807500
num_env_steps_sampled: 824100
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9943781140314
num_env_steps_trained: 807500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9944210291915
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.28666666666667
  ram_util_percent: 77.62666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07410959179451398
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028730615518377817
  mean_inference_ms: 1.390054341107962
  mean_raw_obs_processing_ms: 0.31384859830934425
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020180262771307255
    StateBufferConnector_ms: 0.003440707337622549
    ViewRequirementAgentConnector_ms: 0.1194145165237726
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 6.392156862745098
  episode_reward_min: 2.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 8.0, 6.0, 5.0, 7.0, 13.0, 6.0, 4.0, 6.0, 15.0, 6.0, 10.0,
      5.0, 6.0, 7.0, 7.0, 8.0, 4.0, 4.0, 7.0, 9.0, 7.0, 8.0, 7.0, 4.0, 7.0, 7.0, 2.0,
      5.0, 6.0, 6.0, 8.0, 4.0, 7.0, 2.0, 8.0, 6.0, 7.0, 4.0, 4.0, 3.0, 10.0, 2.0,
      8.0, 9.0, 8.0, 9.0, 3.0, 8.0, 7.0, 9.0, 4.0, 5.0, 5.0, 6.0, 3.0, 9.0, 5.0, 9.0,
      6.0, 6.0, 6.0, 3.0, 4.0, 10.0, 7.0, 6.0, 5.0, 5.0, 6.0, 8.0, 9.0, 8.0, 3.0,
      8.0, 8.0, 4.0, 7.0, 5.0, 4.0, 5.0, 3.0, 7.0, 10.0, 9.0, 4.0, 9.0, 7.0, 6.0,
      2.0, 6.0, 9.0, 9.0, 7.0, 5.0, 9.0, 8.0, 2.0, 8.0, 6.0, 9.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07410959179451398
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028730615518377817
    mean_inference_ms: 1.390054341107962
    mean_raw_obs_processing_ms: 0.31384859830934425
time_since_restore: 773.8724610805511
time_this_iter_s: 10.163938045501709
time_total_s: 773.8724610805511
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691994952
timesteps_total: 824100
training_iteration: 76
trial_id: default
train step: 77
agent_timesteps_total: 837500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01973395164196308
  StateBufferConnector_ms: 0.003454776910635141
  ViewRequirementAgentConnector_ms: 0.11818408966064453
counters:
  num_agent_steps_sampled: 837500
  num_agent_steps_trained: 821000
  num_env_steps_sampled: 837500
  num_env_steps_trained: 821000
  num_samples_added_to_queue: 837500
  num_training_step_calls_since_last_synch_worker_weights: 317
  num_weight_broadcasts: 16443
custom_metrics: {}
date: 2023-08-14_15-36-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.317307692307692
episode_reward_min: 4.0
episodes_this_iter: 104
episodes_total: 6543
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6522985696792603
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.27052879333496
        total_loss: -11.999411582946777
        var_gnorm: 63.90127182006836
        vf_explained_var: 0.9828338027000427
        vf_loss: 15.065220832824707
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1642.0
  learner_queue:
    size_count: 1648
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6833300330000647
  num_agent_steps_sampled: 837500
  num_agent_steps_trained: 821000
  num_env_steps_sampled: 837500
  num_env_steps_trained: 821000
  num_samples_added_to_queue: 837500
  num_training_step_calls_since_last_synch_worker_weights: 317
  num_weight_broadcasts: 16443
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 162.452
    learner_load_time_ms: 1.332
    learner_load_wait_time_ms: 1.605
iterations_since_restore: 77
node_ip: 127.0.0.1
num_agent_steps_sampled: 837500
num_agent_steps_trained: 821000
num_env_steps_sampled: 837500
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9961342923104
num_env_steps_trained: 821000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9961054437456
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.82142857142858
  ram_util_percent: 77.60714285714285
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07388079528610675
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02864404347659719
  mean_inference_ms: 1.3857511103702231
  mean_raw_obs_processing_ms: 0.31291197221127093
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01973395164196308
    StateBufferConnector_ms: 0.003454776910635141
    ViewRequirementAgentConnector_ms: 0.11818408966064453
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.317307692307692
  episode_reward_min: 4.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 10.0, 7.0, 8.0, 10.0, 11.0, 9.0, 9.0, 6.0, 8.0, 8.0, 9.0,
      9.0, 7.0, 11.0, 11.0, 4.0, 13.0, 8.0, 8.0, 8.0, 9.0, 5.0, 6.0, 7.0, 14.0, 13.0,
      8.0, 10.0, 5.0, 10.0, 10.0, 11.0, 6.0, 10.0, 11.0, 11.0, 8.0, 8.0, 9.0, 9.0,
      8.0, 10.0, 7.0, 4.0, 6.0, 10.0, 5.0, 4.0, 8.0, 8.0, 14.0, 9.0, 8.0, 9.0, 11.0,
      9.0, 11.0, 4.0, 9.0, 6.0, 6.0, 9.0, 10.0, 11.0, 11.0, 5.0, 10.0, 5.0, 7.0, 9.0,
      9.0, 5.0, 12.0, 7.0, 11.0, 9.0, 9.0, 4.0, 9.0, 8.0, 6.0, 11.0, 11.0, 8.0, 4.0,
      13.0, 9.0, 7.0, 5.0, 8.0, 5.0, 7.0, 8.0, 6.0, 7.0, 7.0, 10.0, 9.0, 4.0, 6.0,
      11.0, 8.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07388079528610675
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02864404347659719
    mean_inference_ms: 1.3857511103702231
    mean_raw_obs_processing_ms: 0.31291197221127093
time_since_restore: 784.0348379611969
time_this_iter_s: 10.162376880645752
time_total_s: 784.0348379611969
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691994962
timesteps_total: 837500
training_iteration: 77
trial_id: default
train step: 78
agent_timesteps_total: 850300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02098560333251953
  StateBufferConnector_ms: 0.0037641525268554688
  ViewRequirementAgentConnector_ms: 0.12671256065368652
counters:
  num_agent_steps_sampled: 850300
  num_agent_steps_trained: 833500
  num_env_steps_sampled: 850300
  num_env_steps_trained: 833500
  num_samples_added_to_queue: 850000
  num_training_step_calls_since_last_synch_worker_weights: 717
  num_weight_broadcasts: 16695
custom_metrics: {}
date: 2023-08-14_15-36-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.11
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 6643
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5633361339569092
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 15.364266395568848
        total_loss: 38.93596649169922
        var_gnorm: 63.922019958496094
        vf_explained_var: 0.9513901472091675
        vf_loss: 52.776763916015625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1667.0
  learner_queue:
    size_count: 1673
    size_mean: 15.1
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5524174696260025
  num_agent_steps_sampled: 850300
  num_agent_steps_trained: 833500
  num_env_steps_sampled: 850300
  num_env_steps_trained: 833500
  num_samples_added_to_queue: 850000
  num_training_step_calls_since_last_synch_worker_weights: 717
  num_weight_broadcasts: 16695
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 198.608
    learner_load_time_ms: 1.331
    learner_load_wait_time_ms: 1.544
iterations_since_restore: 78
node_ip: 127.0.0.1
num_agent_steps_sampled: 850300
num_agent_steps_trained: 833500
num_env_steps_sampled: 850300
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.998840333082
num_env_steps_trained: 833500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9988675127752
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.826666666666675
  ram_util_percent: 78.01333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07371438371241769
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028585437385650173
  mean_inference_ms: 1.3825551726642344
  mean_raw_obs_processing_ms: 0.312237513627367
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02098560333251953
    StateBufferConnector_ms: 0.0037641525268554688
    ViewRequirementAgentConnector_ms: 0.12671256065368652
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.11
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 7.0, 6.0, 4.0, 6.0, 6.0, 8.0, 9.0, 6.0, 5.0, 7.0, 2.0, 6.0,
      5.0, 2.0, 4.0, 1.0, 5.0, 6.0, 6.0, 5.0, 2.0, 1.0, 5.0, 4.0, 5.0, 1.0, 9.0, 6.0,
      0.0, 5.0, 6.0, 5.0, 2.0, 2.0, 4.0, 5.0, 3.0, 7.0, 6.0, 6.0, 7.0, 5.0, 7.0, 5.0,
      2.0, 9.0, 3.0, 5.0, 9.0, 5.0, 10.0, 5.0, 6.0, 5.0, 2.0, 4.0, 4.0, 8.0, 4.0,
      3.0, 2.0, 7.0, 9.0, 5.0, 5.0, 5.0, 12.0, 8.0, 8.0, 3.0, 2.0, 5.0, 4.0, 5.0,
      11.0, 4.0, 6.0, 4.0, 6.0, 3.0, 7.0, 10.0, 6.0, 3.0, 2.0, 8.0, 10.0, 4.0, 4.0,
      9.0, 0.0, 6.0, 1.0, 3.0, 1.0, 7.0, 5.0, 5.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07371438371241769
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028585437385650173
    mean_inference_ms: 1.3825551726642344
    mean_raw_obs_processing_ms: 0.312237513627367
time_since_restore: 794.2008490562439
time_this_iter_s: 10.166011095046997
time_total_s: 794.2008490562439
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691994972
timesteps_total: 850300
training_iteration: 78
trial_id: default
train step: 79
agent_timesteps_total: 863500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020114504373990573
  StateBufferConnector_ms: 0.003529511965238131
  ViewRequirementAgentConnector_ms: 0.12077872569744404
counters:
  num_agent_steps_sampled: 863500
  num_agent_steps_trained: 847000
  num_env_steps_sampled: 863500
  num_env_steps_trained: 847000
  num_samples_added_to_queue: 863500
  num_training_step_calls_since_last_synch_worker_weights: 1251
  num_weight_broadcasts: 16955
custom_metrics: {}
date: 2023-08-14_15-36-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 5.346153846153846
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 6747
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5911863446235657
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -3.8327977657318115
        total_loss: 4.538697242736816
        var_gnorm: 63.939056396484375
        vf_explained_var: 0.9785825610160828
        vf_loss: 22.65485382080078
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1694.0
  learner_queue:
    size_count: 1698
    size_mean: 15.18
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4925146565444507
  num_agent_steps_sampled: 863500
  num_agent_steps_trained: 847000
  num_env_steps_sampled: 863500
  num_env_steps_trained: 847000
  num_samples_added_to_queue: 863500
  num_training_step_calls_since_last_synch_worker_weights: 1251
  num_weight_broadcasts: 16955
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 238.24
    learner_load_time_ms: 1.338
    learner_load_wait_time_ms: 1.478
iterations_since_restore: 79
node_ip: 127.0.0.1
num_agent_steps_sampled: 863500
num_agent_steps_trained: 847000
num_env_steps_sampled: 863500
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9962864026595
num_env_steps_trained: 847000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9962020027199
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.457142857142856
  ram_util_percent: 77.53571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07350855127457663
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028507911908450916
  mean_inference_ms: 1.3786995070109322
  mean_raw_obs_processing_ms: 0.3114269704196365
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020114504373990573
    StateBufferConnector_ms: 0.003529511965238131
    ViewRequirementAgentConnector_ms: 0.12077872569744404
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 5.346153846153846
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 9.0, 6.0, 4.0, 4.0, 8.0, 4.0, 2.0, 7.0, 7.0, 6.0, 5.0, 4.0,
      2.0, 5.0, 6.0, 5.0, 6.0, 9.0, 5.0, 6.0, 4.0, 0.0, 10.0, 4.0, 2.0, 8.0, 2.0,
      6.0, 3.0, 8.0, 4.0, 4.0, 6.0, 8.0, 4.0, 5.0, 10.0, 3.0, 5.0, 2.0, 5.0, 3.0,
      7.0, 7.0, 5.0, 10.0, 6.0, 4.0, 5.0, 4.0, 7.0, 3.0, 5.0, 7.0, 4.0, 5.0, 3.0,
      5.0, 5.0, 7.0, 9.0, 6.0, 6.0, 8.0, 5.0, 3.0, 4.0, 2.0, 8.0, 6.0, 2.0, 6.0, 8.0,
      6.0, 4.0, 6.0, 6.0, 5.0, 2.0, 6.0, 9.0, 7.0, 6.0, 1.0, 7.0, 6.0, 4.0, 4.0, 6.0,
      8.0, 8.0, 4.0, 5.0, 7.0, 4.0, 8.0, 7.0, 6.0, 4.0, 7.0, 7.0, 1.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07350855127457663
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028507911908450916
    mean_inference_ms: 1.3786995070109322
    mean_raw_obs_processing_ms: 0.3114269704196365
time_since_restore: 804.3103470802307
time_this_iter_s: 10.109498023986816
time_total_s: 804.3103470802307
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691994982
timesteps_total: 863500
training_iteration: 79
trial_id: default
train step: 80
agent_timesteps_total: 876000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020467281341552734
  StateBufferConnector_ms: 0.0038781166076660156
  ViewRequirementAgentConnector_ms: 0.1255333423614502
counters:
  num_agent_steps_sampled: 876000
  num_agent_steps_trained: 859500
  num_env_steps_sampled: 876000
  num_env_steps_trained: 859500
  num_samples_added_to_queue: 876000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 17202
custom_metrics: {}
date: 2023-08-14_15-36-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.74
episode_reward_min: 1.0
episodes_this_iter: 97
episodes_total: 6844
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6486524939537048
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -17.957473754882812
        total_loss: 3.537785530090332
        var_gnorm: 63.94065856933594
        vf_explained_var: 0.9505058526992798
        vf_loss: 49.47704315185547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1719.0
  learner_queue:
    size_count: 1725
    size_mean: 15.48
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.135605565326271
  num_agent_steps_sampled: 876000
  num_agent_steps_trained: 859500
  num_env_steps_sampled: 876000
  num_env_steps_trained: 859500
  num_samples_added_to_queue: 876000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 17202
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 198.222
    learner_load_time_ms: 1.338
    learner_load_wait_time_ms: 1.565
iterations_since_restore: 80
node_ip: 127.0.0.1
num_agent_steps_sampled: 876000
num_agent_steps_trained: 859500
num_env_steps_sampled: 876000
num_env_steps_sampled_this_iter: 12500
num_env_steps_sampled_throughput_per_sec: 1248.6820422646747
num_env_steps_trained: 859500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1248.6820422646747
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 54.68571428571429
  ram_util_percent: 77.35714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07339859562761754
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028461144759927972
  mean_inference_ms: 1.376236739308942
  mean_raw_obs_processing_ms: 0.3108822764856588
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020467281341552734
    StateBufferConnector_ms: 0.0038781166076660156
    ViewRequirementAgentConnector_ms: 0.1255333423614502
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.74
  episode_reward_min: 1.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 1.0, 4.0, 4.0, 3.0, 1.0, 5.0, 5.0, 7.0, 3.0, 2.0, 2.0, 4.0,
      6.0, 4.0, 3.0, 2.0, 8.0, 4.0, 6.0, 3.0, 7.0, 5.0, 3.0, 6.0, 4.0, 6.0, 10.0,
      7.0, 10.0, 5.0, 8.0, 6.0, 3.0, 4.0, 9.0, 2.0, 3.0, 7.0, 3.0, 6.0, 3.0, 1.0,
      3.0, 4.0, 5.0, 4.0, 4.0, 3.0, 4.0, 2.0, 4.0, 9.0, 4.0, 3.0, 4.0, 7.0, 4.0, 2.0,
      7.0, 6.0, 6.0, 2.0, 6.0, 6.0, 5.0, 4.0, 5.0, 3.0, 6.0, 4.0, 5.0, 3.0, 8.0, 5.0,
      4.0, 7.0, 4.0, 3.0, 10.0, 4.0, 2.0, 8.0, 2.0, 3.0, 3.0, 3.0, 6.0, 3.0, 5.0,
      5.0, 7.0, 4.0, 5.0, 5.0, 5.0, 3.0, 6.0, 12.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07339859562761754
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028461144759927972
    mean_inference_ms: 1.376236739308942
    mean_raw_obs_processing_ms: 0.3108822764856588
time_since_restore: 814.4778618812561
time_this_iter_s: 10.16751480102539
time_total_s: 814.4778618812561
timers:
  sample_time_ms: 0.105
  synch_weights_time_ms: 0.664
  training_iteration_time_ms: 2.751
timestamp: 1691994993
timesteps_total: 876000
training_iteration: 80
trial_id: default
train step: 81
agent_timesteps_total: 888050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022936582565307617
  StateBufferConnector_ms: 0.003980875015258789
  ViewRequirementAgentConnector_ms: 0.1412498950958252
counters:
  num_agent_steps_sampled: 888050
  num_agent_steps_trained: 871500
  num_env_steps_sampled: 888050
  num_env_steps_trained: 871500
  num_samples_added_to_queue: 888000
  num_training_step_calls_since_last_synch_worker_weights: 524
  num_weight_broadcasts: 17438
custom_metrics: {}
date: 2023-08-14_15-36-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.18
episode_reward_min: 1.0
episodes_this_iter: 95
episodes_total: 6939
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7457283139228821
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.639631748199463
        total_loss: 21.483261108398438
        var_gnorm: 63.93404006958008
        vf_explained_var: 0.8726415038108826
        vf_loss: 53.703067779541016
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1743.0
  learner_queue:
    size_count: 1748
    size_mean: 15.16
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5278743403827424
  num_agent_steps_sampled: 888050
  num_agent_steps_trained: 871500
  num_env_steps_sampled: 888050
  num_env_steps_trained: 871500
  num_samples_added_to_queue: 888000
  num_training_step_calls_since_last_synch_worker_weights: 524
  num_weight_broadcasts: 17438
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 202.944
    learner_load_time_ms: 1.417
    learner_load_wait_time_ms: 1.743
iterations_since_restore: 81
node_ip: 127.0.0.1
num_agent_steps_sampled: 888050
num_agent_steps_trained: 871500
num_env_steps_sampled: 888050
num_env_steps_sampled_this_iter: 12050
num_env_steps_sampled_throughput_per_sec: 1204.9985635297733
num_env_steps_trained: 871500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9985694902307
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 66.18666666666665
  ram_util_percent: 77.73333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07329797675343358
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02843642429159392
  mean_inference_ms: 1.374315492073411
  mean_raw_obs_processing_ms: 0.31050519225624595
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022936582565307617
    StateBufferConnector_ms: 0.003980875015258789
    ViewRequirementAgentConnector_ms: 0.1412498950958252
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.18
  episode_reward_min: 1.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 3.0, 6.0, 12.0, 6.0, 2.0, 3.0, 9.0, 6.0, 3.0, 6.0, 2.0,
      3.0, 2.0, 5.0, 5.0, 4.0, 4.0, 5.0, 4.0, 5.0, 6.0, 4.0, 6.0, 8.0, 9.0, 11.0,
      10.0, 2.0, 6.0, 10.0, 7.0, 10.0, 6.0, 4.0, 10.0, 7.0, 5.0, 6.0, 10.0, 2.0, 6.0,
      4.0, 8.0, 7.0, 6.0, 7.0, 10.0, 3.0, 7.0, 8.0, 6.0, 10.0, 8.0, 2.0, 5.0, 9.0,
      5.0, 7.0, 7.0, 6.0, 12.0, 3.0, 6.0, 7.0, 4.0, 5.0, 6.0, 3.0, 12.0, 6.0, 5.0,
      9.0, 8.0, 4.0, 3.0, 6.0, 1.0, 5.0, 6.0, 4.0, 8.0, 10.0, 7.0, 9.0, 6.0, 7.0,
      4.0, 6.0, 5.0, 7.0, 10.0, 6.0, 10.0, 7.0, 8.0, 4.0, 5.0, 8.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07329797675343358
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02843642429159392
    mean_inference_ms: 1.374315492073411
    mean_raw_obs_processing_ms: 0.31050519225624595
time_since_restore: 824.6136040687561
time_this_iter_s: 10.1357421875
time_total_s: 824.6136040687561
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691995003
timesteps_total: 888050
training_iteration: 81
trial_id: default
train step: 82
agent_timesteps_total: 901350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01991276557628925
  StateBufferConnector_ms: 0.003506816350496732
  ViewRequirementAgentConnector_ms: 0.12010840269235465
counters:
  num_agent_steps_sampled: 901350
  num_agent_steps_trained: 884500
  num_env_steps_sampled: 901350
  num_env_steps_trained: 884500
  num_samples_added_to_queue: 901000
  num_training_step_calls_since_last_synch_worker_weights: 1915
  num_weight_broadcasts: 17700
custom_metrics: {}
date: 2023-08-14_15-36-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.865384615384615
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 7043
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7909696102142334
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.1286824941635132
        total_loss: 5.974206924438477
        var_gnorm: 63.932411193847656
        vf_explained_var: 0.9452576637268066
        vf_loss: 22.115474700927734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1769.0
  learner_queue:
    size_count: 1774
    size_mean: 15.12
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.557433786714543
  num_agent_steps_sampled: 901350
  num_agent_steps_trained: 884500
  num_env_steps_sampled: 901350
  num_env_steps_trained: 884500
  num_samples_added_to_queue: 901000
  num_training_step_calls_since_last_synch_worker_weights: 1915
  num_weight_broadcasts: 17700
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 228.044
    learner_load_time_ms: 1.411
    learner_load_wait_time_ms: 1.458
iterations_since_restore: 82
node_ip: 127.0.0.1
num_agent_steps_sampled: 901350
num_agent_steps_trained: 884500
num_env_steps_sampled: 901350
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.981228139709
num_env_steps_trained: 884500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9816515651291
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 64.77857142857142
  ram_util_percent: 78.36428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07308898258009025
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02836278764789148
  mean_inference_ms: 1.3706441589307456
  mean_raw_obs_processing_ms: 0.30972461051058897
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01991276557628925
    StateBufferConnector_ms: 0.003506816350496732
    ViewRequirementAgentConnector_ms: 0.12010840269235465
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.865384615384615
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 5.0, 2.0, 6.0, 10.0, 5.0, 5.0, 8.0, 5.0, 5.0, 4.0, 8.0,
      6.0, 7.0, 8.0, 2.0, 8.0, 8.0, 3.0, 10.0, 9.0, 12.0, 2.0, 10.0, 8.0, 5.0, 7.0,
      5.0, 2.0, 6.0, 11.0, 7.0, 9.0, 8.0, 8.0, 2.0, 4.0, 3.0, 7.0, 9.0, 10.0, 6.0,
      9.0, 7.0, 14.0, 6.0, 10.0, 8.0, 8.0, 5.0, 4.0, 4.0, 4.0, 4.0, 9.0, 3.0, 6.0,
      3.0, 10.0, 8.0, 5.0, 7.0, 11.0, 5.0, 10.0, 4.0, 3.0, 5.0, 8.0, 3.0, 10.0, 5.0,
      7.0, 6.0, 14.0, 6.0, 7.0, 10.0, 4.0, 6.0, 12.0, 12.0, 6.0, 7.0, 6.0, 7.0, 2.0,
      5.0, 10.0, 7.0, 9.0, 9.0, 4.0, 10.0, 5.0, 11.0, 8.0, 9.0, 11.0, 2.0, 10.0, 2.0,
      10.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07308898258009025
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02836278764789148
    mean_inference_ms: 1.3706441589307456
    mean_raw_obs_processing_ms: 0.30972461051058897
time_since_restore: 834.7707228660583
time_this_iter_s: 10.157118797302246
time_total_s: 834.7707228660583
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691995013
timesteps_total: 901350
training_iteration: 82
trial_id: default
train step: 83
agent_timesteps_total: 912850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023508787155151367
  StateBufferConnector_ms: 0.004154205322265625
  ViewRequirementAgentConnector_ms: 0.13491129875183105
counters:
  num_agent_steps_sampled: 912850
  num_agent_steps_trained: 896000
  num_env_steps_sampled: 912850
  num_env_steps_trained: 896000
  num_samples_added_to_queue: 912500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 17927
custom_metrics: {}
date: 2023-08-14_15-37-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.84
episode_reward_min: 1.0
episodes_this_iter: 89
episodes_total: 7132
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7952072024345398
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.155309677124023
        total_loss: 27.022397994995117
        var_gnorm: 63.945472717285156
        vf_explained_var: 0.8708585500717163
        vf_loss: 82.30748748779297
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1792.0
  learner_queue:
    size_count: 1800
    size_mean: 15.12
    size_quantiles: [9.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.739425192412712
  num_agent_steps_sampled: 912850
  num_agent_steps_trained: 896000
  num_env_steps_sampled: 912850
  num_env_steps_trained: 896000
  num_samples_added_to_queue: 912500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 17927
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 133.596
    learner_load_time_ms: 1.726
    learner_load_wait_time_ms: 1.535
iterations_since_restore: 83
node_ip: 127.0.0.1
num_agent_steps_sampled: 912850
num_agent_steps_trained: 896000
num_env_steps_sampled: 912850
num_env_steps_sampled_this_iter: 11500
num_env_steps_sampled_throughput_per_sec: 1149.9218087911922
num_env_steps_trained: 896000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9218087911922
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 72.53571428571429
  ram_util_percent: 82.60000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07310625428698915
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028374700607584194
  mean_inference_ms: 1.3697344785258503
  mean_raw_obs_processing_ms: 0.30957176277184817
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023508787155151367
    StateBufferConnector_ms: 0.004154205322265625
    ViewRequirementAgentConnector_ms: 0.13491129875183105
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.84
  episode_reward_min: 1.0
  episodes_this_iter: 89
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 5.0, 11.0, 8.0, 9.0, 11.0, 2.0, 10.0, 2.0, 10.0, 9.0, 4.0,
      8.0, 10.0, 11.0, 9.0, 8.0, 9.0, 11.0, 6.0, 12.0, 6.0, 9.0, 8.0, 7.0, 11.0, 6.0,
      10.0, 8.0, 6.0, 5.0, 13.0, 6.0, 6.0, 4.0, 11.0, 3.0, 6.0, 8.0, 9.0, 10.0, 7.0,
      9.0, 4.0, 11.0, 11.0, 10.0, 7.0, 11.0, 9.0, 9.0, 7.0, 11.0, 9.0, 7.0, 11.0,
      5.0, 11.0, 6.0, 5.0, 6.0, 1.0, 9.0, 6.0, 8.0, 10.0, 6.0, 9.0, 5.0, 8.0, 8.0,
      5.0, 4.0, 8.0, 4.0, 11.0, 9.0, 5.0, 11.0, 6.0, 7.0, 6.0, 11.0, 7.0, 12.0, 8.0,
      9.0, 9.0, 5.0, 9.0, 5.0, 5.0, 9.0, 9.0, 7.0, 9.0, 9.0, 11.0, 5.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07310625428698915
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028374700607584194
    mean_inference_ms: 1.3697344785258503
    mean_raw_obs_processing_ms: 0.30957176277184817
time_since_restore: 844.9602336883545
time_this_iter_s: 10.189510822296143
time_total_s: 844.9602336883545
timers:
  sample_time_ms: 0.158
  synch_weights_time_ms: 0.536
  training_iteration_time_ms: 0.823
timestamp: 1691995023
timesteps_total: 912850
training_iteration: 83
trial_id: default
train step: 84
agent_timesteps_total: 925700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020811817433574412
  StateBufferConnector_ms: 0.003651817246238784
  ViewRequirementAgentConnector_ms: 0.12465821634424795
counters:
  num_agent_steps_sampled: 925700
  num_agent_steps_trained: 909000
  num_env_steps_sampled: 925700
  num_env_steps_trained: 909000
  num_samples_added_to_queue: 925500
  num_training_step_calls_since_last_synch_worker_weights: 744
  num_weight_broadcasts: 18182
custom_metrics: {}
date: 2023-08-14_15-37-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.782178217821782
episode_reward_min: 3.0
episodes_this_iter: 101
episodes_total: 7233
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6783052682876587
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 28.800838470458984
        total_loss: 64.4286117553711
        var_gnorm: 63.958106994628906
        vf_explained_var: 0.9152576923370361
        vf_loss: 78.0385971069336
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1818.0
  learner_queue:
    size_count: 1823
    size_mean: 14.64
    size_quantiles: [9.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 2.0664946164943183
  num_agent_steps_sampled: 925700
  num_agent_steps_trained: 909000
  num_env_steps_sampled: 925700
  num_env_steps_trained: 909000
  num_samples_added_to_queue: 925500
  num_training_step_calls_since_last_synch_worker_weights: 744
  num_weight_broadcasts: 18182
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 220.761
    learner_load_time_ms: 1.741
    learner_load_wait_time_ms: 1.556
iterations_since_restore: 84
node_ip: 127.0.0.1
num_agent_steps_sampled: 925700
num_agent_steps_trained: 909000
num_env_steps_sampled: 925700
num_env_steps_sampled_this_iter: 12850
num_env_steps_sampled_throughput_per_sec: 1284.9989889868107
num_env_steps_trained: 909000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9989771851003
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 56.313333333333325
  ram_util_percent: 82.25999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07290640450927774
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028331467007999774
  mean_inference_ms: 1.3668542635008198
  mean_raw_obs_processing_ms: 0.30900946738237783
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020811817433574412
    StateBufferConnector_ms: 0.003651817246238784
    ViewRequirementAgentConnector_ms: 0.12465821634424795
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.782178217821782
  episode_reward_min: 3.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 9.0, 11.0, 4.0, 12.0, 11.0, 9.0, 8.0, 7.0, 7.0, 5.0, 10.0,
      8.0, 12.0, 10.0, 12.0, 11.0, 5.0, 8.0, 8.0, 5.0, 6.0, 6.0, 4.0, 11.0, 7.0, 9.0,
      7.0, 11.0, 5.0, 9.0, 6.0, 6.0, 7.0, 8.0, 4.0, 9.0, 4.0, 8.0, 9.0, 10.0, 9.0,
      10.0, 6.0, 13.0, 6.0, 7.0, 6.0, 7.0, 5.0, 3.0, 7.0, 6.0, 10.0, 14.0, 11.0, 8.0,
      15.0, 4.0, 7.0, 4.0, 6.0, 4.0, 8.0, 7.0, 7.0, 6.0, 10.0, 8.0, 5.0, 10.0, 8.0,
      8.0, 12.0, 4.0, 8.0, 9.0, 4.0, 5.0, 7.0, 4.0, 10.0, 7.0, 6.0, 6.0, 8.0, 11.0,
      8.0, 13.0, 6.0, 9.0, 7.0, 6.0, 7.0, 4.0, 10.0, 10.0, 5.0, 14.0, 10.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07290640450927774
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028331467007999774
    mean_inference_ms: 1.3668542635008198
    mean_raw_obs_processing_ms: 0.30900946738237783
time_since_restore: 855.100403547287
time_this_iter_s: 10.140169858932495
time_total_s: 855.100403547287
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691995033
timesteps_total: 925700
training_iteration: 84
trial_id: default
train step: 85
agent_timesteps_total: 938400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02122354507446289
  StateBufferConnector_ms: 0.0037393569946289062
  ViewRequirementAgentConnector_ms: 0.12683391571044922
counters:
  num_agent_steps_sampled: 938400
  num_agent_steps_trained: 921500
  num_env_steps_sampled: 938400
  num_env_steps_trained: 921500
  num_samples_added_to_queue: 938000
  num_training_step_calls_since_last_synch_worker_weights: 722
  num_weight_broadcasts: 18430
custom_metrics: {}
date: 2023-08-14_15-37-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 8.51
episode_reward_min: 1.0
episodes_this_iter: 99
episodes_total: 7332
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7257340550422668
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -48.2341194152832
        total_loss: -13.362297058105469
        var_gnorm: 63.95652770996094
        vf_explained_var: 0.9057831764221191
        vf_loss: 77.00098419189453
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1843.0
  learner_queue:
    size_count: 1849
    size_mean: 14.82
    size_quantiles: [9.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.9255129186790723
  num_agent_steps_sampled: 938400
  num_agent_steps_trained: 921500
  num_env_steps_sampled: 938400
  num_env_steps_trained: 921500
  num_samples_added_to_queue: 938000
  num_training_step_calls_since_last_synch_worker_weights: 722
  num_weight_broadcasts: 18430
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 204.164
    learner_load_time_ms: 1.823
    learner_load_wait_time_ms: 1.486
iterations_since_restore: 85
node_ip: 127.0.0.1
num_agent_steps_sampled: 938400
num_agent_steps_trained: 921500
num_env_steps_sampled: 938400
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.99897050941
num_env_steps_trained: 921500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.99898672186
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 61.8
  ram_util_percent: 82.55714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07279809885801923
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02829534955974343
  mean_inference_ms: 1.3642771391333175
  mean_raw_obs_processing_ms: 0.3084694371481629
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02122354507446289
    StateBufferConnector_ms: 0.0037393569946289062
    ViewRequirementAgentConnector_ms: 0.12683391571044922
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 8.51
  episode_reward_min: 1.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 11.0, 5.0, 6.0, 8.0, 7.0, 11.0, 12.0, 7.0, 8.0, 8.0,
      11.0, 9.0, 8.0, 7.0, 8.0, 9.0, 11.0, 11.0, 8.0, 8.0, 8.0, 13.0, 9.0, 8.0, 8.0,
      9.0, 11.0, 10.0, 5.0, 8.0, 11.0, 5.0, 11.0, 13.0, 10.0, 9.0, 9.0, 4.0, 12.0,
      8.0, 7.0, 9.0, 3.0, 7.0, 11.0, 6.0, 7.0, 13.0, 12.0, 12.0, 9.0, 5.0, 5.0, 12.0,
      10.0, 7.0, 8.0, 1.0, 7.0, 10.0, 10.0, 9.0, 8.0, 10.0, 10.0, 8.0, 10.0, 8.0,
      11.0, 8.0, 12.0, 7.0, 8.0, 7.0, 6.0, 10.0, 6.0, 8.0, 10.0, 8.0, 8.0, 8.0, 6.0,
      7.0, 12.0, 12.0, 11.0, 5.0, 6.0, 10.0, 6.0, 5.0, 4.0, 6.0, 9.0, 9.0, 9.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07279809885801923
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02829534955974343
    mean_inference_ms: 1.3642771391333175
    mean_raw_obs_processing_ms: 0.3084694371481629
time_since_restore: 865.247302532196
time_this_iter_s: 10.146898984909058
time_total_s: 865.247302532196
timers:
  sample_time_ms: 0.02
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.051
timestamp: 1691995043
timesteps_total: 938400
training_iteration: 85
trial_id: default
train step: 86
agent_timesteps_total: 951000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02204132080078125
  StateBufferConnector_ms: 0.0038704872131347656
  ViewRequirementAgentConnector_ms: 0.12796711921691895
counters:
  num_agent_steps_sampled: 951000
  num_agent_steps_trained: 934500
  num_env_steps_sampled: 951000
  num_env_steps_trained: 934500
  num_samples_added_to_queue: 951000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 18679
custom_metrics: {}
date: 2023-08-14_15-37-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 8.19
episode_reward_min: 3.0
episodes_this_iter: 98
episodes_total: 7430
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.750435471534729
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -50.77532196044922
        total_loss: 8.185128211975098
        var_gnorm: 63.960330963134766
        vf_explained_var: 0.8741636276245117
        vf_loss: 125.42525482177734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1869.0
  learner_queue:
    size_count: 1874
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2745195173083856
  num_agent_steps_sampled: 951000
  num_agent_steps_trained: 934500
  num_env_steps_sampled: 951000
  num_env_steps_trained: 934500
  num_samples_added_to_queue: 951000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 18679
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 203.712
    learner_load_time_ms: 1.811
    learner_load_wait_time_ms: 1.585
iterations_since_restore: 86
node_ip: 127.0.0.1
num_agent_steps_sampled: 951000
num_agent_steps_trained: 934500
num_env_steps_sampled: 951000
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.299959234011
num_env_steps_trained: 934500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.2777357176305
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 60.521428571428565
  ram_util_percent: 82.52857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07269138130645249
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028267079557793274
  mean_inference_ms: 1.361981432183564
  mean_raw_obs_processing_ms: 0.3079913402641213
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02204132080078125
    StateBufferConnector_ms: 0.0038704872131347656
    ViewRequirementAgentConnector_ms: 0.12796711921691895
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 8.19
  episode_reward_min: 3.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 12.0, 3.0, 9.0, 7.0, 10.0, 9.0, 3.0, 7.0, 7.0, 7.0, 9.0,
      8.0, 8.0, 8.0, 7.0, 10.0, 9.0, 11.0, 8.0, 9.0, 5.0, 5.0, 12.0, 11.0, 8.0, 10.0,
      4.0, 9.0, 10.0, 11.0, 12.0, 5.0, 13.0, 8.0, 7.0, 8.0, 11.0, 14.0, 9.0, 7.0,
      10.0, 3.0, 9.0, 9.0, 7.0, 7.0, 8.0, 8.0, 7.0, 9.0, 6.0, 12.0, 13.0, 12.0, 18.0,
      9.0, 5.0, 8.0, 8.0, 6.0, 5.0, 9.0, 6.0, 10.0, 9.0, 8.0, 8.0, 6.0, 8.0, 4.0,
      5.0, 12.0, 9.0, 10.0, 8.0, 4.0, 6.0, 6.0, 6.0, 5.0, 7.0, 10.0, 7.0, 12.0, 12.0,
      10.0, 11.0, 6.0, 3.0, 10.0, 11.0, 7.0, 7.0, 5.0, 8.0, 5.0, 4.0, 10.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07269138130645249
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028267079557793274
    mean_inference_ms: 1.361981432183564
    mean_raw_obs_processing_ms: 0.3079913402641213
time_since_restore: 875.3863384723663
time_this_iter_s: 10.139035940170288
time_total_s: 875.3863384723663
timers:
  sample_time_ms: 0.224
  synch_weights_time_ms: 0.775
  training_iteration_time_ms: 2.901
timestamp: 1691995054
timesteps_total: 951000
training_iteration: 86
trial_id: default
train step: 87
agent_timesteps_total: 963200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02187180519104004
  StateBufferConnector_ms: 0.003912687301635742
  ViewRequirementAgentConnector_ms: 0.13106369972229004
counters:
  num_agent_steps_sampled: 963200
  num_agent_steps_trained: 946500
  num_env_steps_sampled: 963200
  num_env_steps_trained: 946500
  num_samples_added_to_queue: 963000
  num_training_step_calls_since_last_synch_worker_weights: 309
  num_weight_broadcasts: 18919
custom_metrics: {}
date: 2023-08-14_15-37-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 6.95
episode_reward_min: 1.0
episodes_this_iter: 96
episodes_total: 7526
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6581689715385437
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 5.496564865112305
        total_loss: 37.70505905151367
        var_gnorm: 63.972312927246094
        vf_explained_var: 0.9358304738998413
        vf_loss: 70.99867248535156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1893.0
  learner_queue:
    size_count: 1900
    size_mean: 15.26
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4671059948074645
  num_agent_steps_sampled: 963200
  num_agent_steps_trained: 946500
  num_env_steps_sampled: 963200
  num_env_steps_trained: 946500
  num_samples_added_to_queue: 963000
  num_training_step_calls_since_last_synch_worker_weights: 309
  num_weight_broadcasts: 18919
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 147.721
    learner_load_time_ms: 1.771
    learner_load_wait_time_ms: 1.546
iterations_since_restore: 87
node_ip: 127.0.0.1
num_agent_steps_sampled: 963200
num_agent_steps_trained: 946500
num_env_steps_sampled: 963200
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.996073258641
num_env_steps_trained: 946500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9961376314502
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 70.78
  ram_util_percent: 82.18
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07261047001438241
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02823885654714444
  mean_inference_ms: 1.3602095115564767
  mean_raw_obs_processing_ms: 0.30760218751362506
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02187180519104004
    StateBufferConnector_ms: 0.003912687301635742
    ViewRequirementAgentConnector_ms: 0.13106369972229004
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 6.95
  episode_reward_min: 1.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 4.0, 10.0, 7.0, 15.0, 14.0, 6.0, 7.0, 6.0, 7.0, 8.0, 4.0,
      6.0, 8.0, 12.0, 6.0, 4.0, 6.0, 7.0, 8.0, 12.0, 11.0, 7.0, 10.0, 5.0, 6.0, 6.0,
      12.0, 9.0, 9.0, 2.0, 11.0, 10.0, 7.0, 5.0, 8.0, 5.0, 4.0, 8.0, 8.0, 10.0, 4.0,
      6.0, 8.0, 7.0, 10.0, 5.0, 8.0, 4.0, 12.0, 6.0, 3.0, 8.0, 7.0, 5.0, 3.0, 5.0,
      3.0, 8.0, 9.0, 4.0, 5.0, 7.0, 4.0, 11.0, 5.0, 4.0, 1.0, 4.0, 12.0, 10.0, 5.0,
      6.0, 5.0, 7.0, 9.0, 13.0, 8.0, 5.0, 3.0, 5.0, 6.0, 7.0, 7.0, 8.0, 5.0, 7.0,
      5.0, 11.0, 7.0, 10.0, 8.0, 5.0, 12.0, 3.0, 3.0, 8.0, 6.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07261047001438241
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02823885654714444
    mean_inference_ms: 1.3602095115564767
    mean_raw_obs_processing_ms: 0.30760218751362506
time_since_restore: 885.5478675365448
time_this_iter_s: 10.161529064178467
time_total_s: 885.5478675365448
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995064
timesteps_total: 963200
training_iteration: 87
trial_id: default
train step: 88
agent_timesteps_total: 974950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022927522659301758
  StateBufferConnector_ms: 0.004023075103759766
  ViewRequirementAgentConnector_ms: 0.13402295112609863
counters:
  num_agent_steps_sampled: 974950
  num_agent_steps_trained: 958000
  num_env_steps_sampled: 974950
  num_env_steps_trained: 958000
  num_samples_added_to_queue: 974500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 19150
custom_metrics: {}
date: 2023-08-14_15-37-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.3
episode_reward_min: 0.0
episodes_this_iter: 91
episodes_total: 7617
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6587488055229187
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.312137603759766
        total_loss: -2.831393003463745
        var_gnorm: 63.983158111572266
        vf_explained_var: 0.9685618877410889
        vf_loss: 39.54897689819336
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1916.0
  learner_queue:
    size_count: 1920
    size_mean: 15.02
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5683111936092275
  num_agent_steps_sampled: 974950
  num_agent_steps_trained: 958000
  num_env_steps_sampled: 974950
  num_env_steps_trained: 958000
  num_samples_added_to_queue: 974500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 19150
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 317.858
    learner_load_time_ms: 8.619
    learner_load_wait_time_ms: 1.69
iterations_since_restore: 88
node_ip: 127.0.0.1
num_agent_steps_sampled: 974950
num_agent_steps_trained: 958000
num_env_steps_sampled: 974950
num_env_steps_sampled_this_iter: 11750
num_env_steps_sampled_throughput_per_sec: 1174.882492254853
num_env_steps_trained: 958000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.8849924196434
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 59.62142857142857
  ram_util_percent: 81.70714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07258166655785706
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028239156902929614
  mean_inference_ms: 1.359128681373017
  mean_raw_obs_processing_ms: 0.3073914233680081
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022927522659301758
    StateBufferConnector_ms: 0.004023075103759766
    ViewRequirementAgentConnector_ms: 0.13402295112609863
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.3
  episode_reward_min: 0.0
  episodes_this_iter: 91
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 5.0, 12.0, 3.0, 3.0, 8.0, 6.0, 4.0, 4.0, 4.0, 11.0, 6.0,
      5.0, 5.0, 12.0, 5.0, 2.0, 7.0, 6.0, 5.0, 7.0, 5.0, 8.0, 8.0, 5.0, 7.0, 8.0,
      8.0, 5.0, 12.0, 6.0, 5.0, 6.0, 6.0, 7.0, 4.0, 8.0, 6.0, 9.0, 7.0, 9.0, 6.0,
      9.0, 7.0, 8.0, 4.0, 4.0, 9.0, 7.0, 7.0, 5.0, 2.0, 2.0, 4.0, 0.0, 9.0, 9.0, 9.0,
      7.0, 9.0, 7.0, 10.0, 9.0, 3.0, 4.0, 6.0, 6.0, 8.0, 7.0, 10.0, 4.0, 6.0, 4.0,
      9.0, 3.0, 9.0, 8.0, 8.0, 3.0, 7.0, 10.0, 9.0, 3.0, 4.0, 8.0, 9.0, 1.0, 6.0,
      3.0, 8.0, 5.0, 4.0, 4.0, 4.0, 7.0, 4.0, 8.0, 7.0, 7.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07258166655785706
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028239156902929614
    mean_inference_ms: 1.359128681373017
    mean_raw_obs_processing_ms: 0.3073914233680081
time_since_restore: 895.6574816703796
time_this_iter_s: 10.109614133834839
time_total_s: 895.6574816703796
timers:
  sample_time_ms: 0.071
  synch_weights_time_ms: 0.293
  training_iteration_time_ms: 0.432
timestamp: 1691995074
timesteps_total: 974950
training_iteration: 88
trial_id: default
train step: 89
agent_timesteps_total: 985500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02485513687133789
  StateBufferConnector_ms: 0.004359722137451172
  ViewRequirementAgentConnector_ms: 0.14496779441833496
counters:
  num_agent_steps_sampled: 985500
  num_agent_steps_trained: 969000
  num_env_steps_sampled: 985500
  num_env_steps_trained: 969000
  num_samples_added_to_queue: 985500
  num_training_step_calls_since_last_synch_worker_weights: 1111
  num_weight_broadcasts: 19358
custom_metrics: {}
date: 2023-08-14_15-38-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.53
episode_reward_min: 1.0
episodes_this_iter: 83
episodes_total: 7700
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5858902335166931
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -17.325838088989258
        total_loss: 21.14112663269043
        var_gnorm: 63.9830436706543
        vf_explained_var: 0.889531672000885
        vf_loss: 82.79283142089844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1938.0
  learner_queue:
    size_count: 1942
    size_mean: 15.12
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4918444959177213
  num_agent_steps_sampled: 985500
  num_agent_steps_trained: 969000
  num_env_steps_sampled: 985500
  num_env_steps_trained: 969000
  num_samples_added_to_queue: 985500
  num_training_step_calls_since_last_synch_worker_weights: 1111
  num_weight_broadcasts: 19358
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 270.52
    learner_load_time_ms: 8.335
    learner_load_wait_time_ms: 1.915
iterations_since_restore: 89
node_ip: 127.0.0.1
num_agent_steps_sampled: 985500
num_agent_steps_trained: 969000
num_env_steps_sampled: 985500
num_env_steps_sampled_this_iter: 10550
num_env_steps_sampled_throughput_per_sec: 1054.9949442390491
num_env_steps_trained: 969000
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9947285904777
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 73.24999999999999
  ram_util_percent: 81.55714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07265288515118028
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028277260489563413
  mean_inference_ms: 1.3594087030897402
  mean_raw_obs_processing_ms: 0.30743860907628473
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02485513687133789
    StateBufferConnector_ms: 0.004359722137451172
    ViewRequirementAgentConnector_ms: 0.14496779441833496
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.53
  episode_reward_min: 1.0
  episodes_this_iter: 83
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 8.0, 9.0, 1.0, 6.0, 3.0, 8.0, 5.0, 4.0, 4.0, 4.0, 7.0, 4.0,
      8.0, 7.0, 7.0, 4.0, 5.0, 5.0, 5.0, 5.0, 8.0, 4.0, 5.0, 10.0, 12.0, 9.0, 5.0,
      3.0, 6.0, 3.0, 11.0, 2.0, 10.0, 10.0, 8.0, 7.0, 1.0, 7.0, 7.0, 6.0, 7.0, 9.0,
      10.0, 5.0, 3.0, 11.0, 10.0, 8.0, 6.0, 8.0, 5.0, 10.0, 8.0, 10.0, 6.0, 5.0, 6.0,
      6.0, 4.0, 6.0, 6.0, 6.0, 9.0, 8.0, 9.0, 7.0, 3.0, 4.0, 6.0, 5.0, 4.0, 6.0, 8.0,
      4.0, 9.0, 4.0, 7.0, 6.0, 11.0, 7.0, 9.0, 6.0, 9.0, 4.0, 10.0, 7.0, 6.0, 3.0,
      9.0, 5.0, 8.0, 7.0, 5.0, 11.0, 14.0, 4.0, 4.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07265288515118028
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028277260489563413
    mean_inference_ms: 1.3594087030897402
    mean_raw_obs_processing_ms: 0.30743860907628473
time_since_restore: 905.7954998016357
time_this_iter_s: 10.138018131256104
time_total_s: 905.7954998016357
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995084
timesteps_total: 985500
training_iteration: 89
trial_id: default
train step: 90
agent_timesteps_total: 996900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024063825607299805
  StateBufferConnector_ms: 0.004128932952880859
  ViewRequirementAgentConnector_ms: 0.14112329483032227
counters:
  num_agent_steps_sampled: 996900
  num_agent_steps_trained: 980000
  num_env_steps_sampled: 996900
  num_env_steps_trained: 980000
  num_samples_added_to_queue: 996500
  num_training_step_calls_since_last_synch_worker_weights: 92
  num_weight_broadcasts: 19582
custom_metrics: {}
date: 2023-08-14_15-38-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.18
episode_reward_min: 1.0
episodes_this_iter: 89
episodes_total: 7789
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7116736173629761
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 13.22900676727295
        total_loss: 34.98175048828125
        var_gnorm: 63.983253479003906
        vf_explained_var: 0.9099433422088623
        vf_loss: 50.62222671508789
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1960.0
  learner_queue:
    size_count: 1967
    size_mean: 15.16
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4333178293735136
  num_agent_steps_sampled: 996900
  num_agent_steps_trained: 980000
  num_env_steps_sampled: 996900
  num_env_steps_trained: 980000
  num_samples_added_to_queue: 996500
  num_training_step_calls_since_last_synch_worker_weights: 92
  num_weight_broadcasts: 19582
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 196.167
    learner_load_time_ms: 8.321
    learner_load_wait_time_ms: 1.62
iterations_since_restore: 90
node_ip: 127.0.0.1
num_agent_steps_sampled: 996900
num_agent_steps_trained: 980000
num_env_steps_sampled: 996900
num_env_steps_sampled_this_iter: 11400
num_env_steps_sampled_throughput_per_sec: 1139.9941563905807
num_env_steps_trained: 980000
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9943614295075
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 78.3
  ram_util_percent: 81.61999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07261284391183381
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02829460511106796
  mean_inference_ms: 1.359196796222689
  mean_raw_obs_processing_ms: 0.30740106825135954
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024063825607299805
    StateBufferConnector_ms: 0.004128932952880859
    ViewRequirementAgentConnector_ms: 0.14112329483032227
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.18
  episode_reward_min: 1.0
  episodes_this_iter: 89
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 5.0, 8.0, 7.0, 5.0, 11.0, 14.0, 4.0, 4.0, 6.0, 7.0, 3.0,
      7.0, 11.0, 4.0, 4.0, 3.0, 7.0, 8.0, 9.0, 6.0, 10.0, 5.0, 6.0, 4.0, 8.0, 6.0,
      2.0, 7.0, 6.0, 3.0, 6.0, 8.0, 7.0, 6.0, 6.0, 6.0, 7.0, 2.0, 6.0, 7.0, 9.0, 8.0,
      12.0, 10.0, 4.0, 7.0, 9.0, 9.0, 12.0, 7.0, 9.0, 5.0, 10.0, 3.0, 7.0, 8.0, 6.0,
      6.0, 1.0, 12.0, 8.0, 4.0, 5.0, 4.0, 8.0, 6.0, 10.0, 8.0, 6.0, 12.0, 5.0, 4.0,
      8.0, 3.0, 8.0, 6.0, 7.0, 4.0, 7.0, 6.0, 7.0, 13.0, 10.0, 12.0, 11.0, 10.0, 9.0,
      9.0, 14.0, 10.0, 7.0, 9.0, 8.0, 8.0, 9.0, 6.0, 5.0, 9.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07261284391183381
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02829460511106796
    mean_inference_ms: 1.359196796222689
    mean_raw_obs_processing_ms: 0.30740106825135954
time_since_restore: 915.9667088985443
time_this_iter_s: 10.17120909690857
time_total_s: 915.9667088985443
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995094
timesteps_total: 996900
training_iteration: 90
trial_id: default
train step: 91
agent_timesteps_total: 1008900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022874832153320312
  StateBufferConnector_ms: 0.004195451736450195
  ViewRequirementAgentConnector_ms: 0.1386549472808838
counters:
  num_agent_steps_sampled: 1008900
  num_agent_steps_trained: 992000
  num_env_steps_sampled: 1008900
  num_env_steps_trained: 992000
  num_samples_added_to_queue: 1008500
  num_training_step_calls_since_last_synch_worker_weights: 845
  num_weight_broadcasts: 19819
custom_metrics: {}
date: 2023-08-14_15-38-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.56
episode_reward_min: 1.0
episodes_this_iter: 94
episodes_total: 7883
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6941912174224854
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.888921737670898
        total_loss: 9.775010108947754
        var_gnorm: 63.985740661621094
        vf_explained_var: 0.9270915985107422
        vf_loss: 50.269775390625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1984.0
  learner_queue:
    size_count: 1989
    size_mean: 14.96
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5742934923323542
  num_agent_steps_sampled: 1008900
  num_agent_steps_trained: 992000
  num_env_steps_sampled: 1008900
  num_env_steps_trained: 992000
  num_samples_added_to_queue: 1008500
  num_training_step_calls_since_last_synch_worker_weights: 845
  num_weight_broadcasts: 19819
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 236.957
    learner_load_time_ms: 16.207
    learner_load_wait_time_ms: 1.683
iterations_since_restore: 91
node_ip: 127.0.0.1
num_agent_steps_sampled: 1008900
num_agent_steps_trained: 992000
num_env_steps_sampled: 1008900
num_env_steps_sampled_this_iter: 12000
num_env_steps_sampled_throughput_per_sec: 1199.9982261683936
num_env_steps_trained: 992000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9982261683936
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 59.67857142857144
  ram_util_percent: 80.94999999999997
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07253489517468133
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02828137826772391
  mean_inference_ms: 1.357889167728878
  mean_raw_obs_processing_ms: 0.3071614577923565
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022874832153320312
    StateBufferConnector_ms: 0.004195451736450195
    ViewRequirementAgentConnector_ms: 0.1386549472808838
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.56
  episode_reward_min: 1.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 6.0, 5.0, 9.0, 9.0, 10.0, 6.0, 10.0, 2.0, 11.0, 6.0,
      7.0, 8.0, 8.0, 12.0, 12.0, 7.0, 12.0, 8.0, 5.0, 12.0, 7.0, 4.0, 5.0, 8.0, 10.0,
      13.0, 8.0, 7.0, 7.0, 5.0, 12.0, 5.0, 12.0, 7.0, 9.0, 4.0, 4.0, 8.0, 10.0, 9.0,
      7.0, 11.0, 5.0, 10.0, 3.0, 9.0, 5.0, 6.0, 9.0, 5.0, 6.0, 6.0, 12.0, 6.0, 3.0,
      7.0, 3.0, 12.0, 4.0, 4.0, 12.0, 8.0, 8.0, 6.0, 6.0, 5.0, 8.0, 11.0, 1.0, 5.0,
      10.0, 7.0, 8.0, 9.0, 8.0, 4.0, 8.0, 9.0, 9.0, 11.0, 10.0, 5.0, 7.0, 6.0, 8.0,
      9.0, 4.0, 8.0, 8.0, 5.0, 8.0, 10.0, 7.0, 7.0, 9.0, 10.0, 3.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07253489517468133
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02828137826772391
    mean_inference_ms: 1.357889167728878
    mean_raw_obs_processing_ms: 0.3071614577923565
time_since_restore: 926.078608751297
time_this_iter_s: 10.111899852752686
time_total_s: 926.078608751297
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995104
timesteps_total: 1008900
training_iteration: 91
trial_id: default
train step: 92
agent_timesteps_total: 1021500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022293806076049805
  StateBufferConnector_ms: 0.0037012100219726562
  ViewRequirementAgentConnector_ms: 0.12433743476867676
counters:
  num_agent_steps_sampled: 1021500
  num_agent_steps_trained: 1005000
  num_env_steps_sampled: 1021500
  num_env_steps_trained: 1005000
  num_samples_added_to_queue: 1021500
  num_training_step_calls_since_last_synch_worker_weights: 944
  num_weight_broadcasts: 20066
custom_metrics: {}
date: 2023-08-14_15-38-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.58
episode_reward_min: 2.0
episodes_this_iter: 98
episodes_total: 7981
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6369118690490723
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -6.918912887573242
        total_loss: 23.712003707885742
        var_gnorm: 63.99122619628906
        vf_explained_var: 0.8971320390701294
        vf_loss: 67.63095092773438
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2010.0
  learner_queue:
    size_count: 2014
    size_mean: 15.06
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5672906558772053
  num_agent_steps_sampled: 1021500
  num_agent_steps_trained: 1005000
  num_env_steps_sampled: 1021500
  num_env_steps_trained: 1005000
  num_samples_added_to_queue: 1021500
  num_training_step_calls_since_last_synch_worker_weights: 944
  num_weight_broadcasts: 20066
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 285.44
    learner_load_time_ms: 16.224
    learner_load_wait_time_ms: 1.705
iterations_since_restore: 92
node_ip: 127.0.0.1
num_agent_steps_sampled: 1021500
num_agent_steps_trained: 1005000
num_env_steps_sampled: 1021500
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9969658924686
num_env_steps_trained: 1005000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9968695715945
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.95714285714285
  ram_util_percent: 79.94285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07240059052743089
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028237646196075335
  mean_inference_ms: 1.3557947289506478
  mean_raw_obs_processing_ms: 0.30670727413057086
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022293806076049805
    StateBufferConnector_ms: 0.0037012100219726562
    ViewRequirementAgentConnector_ms: 0.12433743476867676
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.58
  episode_reward_min: 2.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 10.0, 8.0, 6.0, 10.0, 11.0, 7.0, 7.0, 6.0, 9.0, 14.0, 12.0,
      7.0, 11.0, 12.0, 16.0, 8.0, 10.0, 5.0, 4.0, 10.0, 11.0, 7.0, 8.0, 7.0, 6.0,
      9.0, 8.0, 7.0, 9.0, 10.0, 12.0, 11.0, 13.0, 12.0, 8.0, 9.0, 5.0, 10.0, 5.0,
      7.0, 7.0, 9.0, 8.0, 7.0, 9.0, 14.0, 8.0, 7.0, 8.0, 9.0, 6.0, 7.0, 11.0, 2.0,
      7.0, 10.0, 8.0, 6.0, 8.0, 8.0, 10.0, 6.0, 9.0, 9.0, 10.0, 6.0, 11.0, 12.0, 6.0,
      5.0, 9.0, 8.0, 8.0, 7.0, 7.0, 7.0, 6.0, 8.0, 7.0, 8.0, 5.0, 11.0, 11.0, 8.0,
      11.0, 14.0, 14.0, 6.0, 6.0, 9.0, 10.0, 9.0, 8.0, 8.0, 10.0, 10.0, 12.0, 10.0,
      8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07240059052743089
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028237646196075335
    mean_inference_ms: 1.3557947289506478
    mean_raw_obs_processing_ms: 0.30670727413057086
time_since_restore: 936.1922647953033
time_this_iter_s: 10.113656044006348
time_total_s: 936.1922647953033
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691995114
timesteps_total: 1021500
training_iteration: 92
trial_id: default
train step: 93
agent_timesteps_total: 1033400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023540496826171875
  StateBufferConnector_ms: 0.004134416580200195
  ViewRequirementAgentConnector_ms: 0.13941144943237305
counters:
  num_agent_steps_sampled: 1033400
  num_agent_steps_trained: 1016500
  num_env_steps_sampled: 1033400
  num_env_steps_trained: 1016500
  num_samples_added_to_queue: 1033000
  num_training_step_calls_since_last_synch_worker_weights: 1002
  num_weight_broadcasts: 20301
custom_metrics: {}
date: 2023-08-14_15-38-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.32
episode_reward_min: 4.0
episodes_this_iter: 93
episodes_total: 8074
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6918354034423828
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -25.080791473388672
        total_loss: 9.786527633666992
        var_gnorm: 63.99538803100586
        vf_explained_var: 0.8741281628608704
        vf_loss: 76.65299224853516
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2033.0
  learner_queue:
    size_count: 2038
    size_mean: 15.4
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.131370849898476
  num_agent_steps_sampled: 1033400
  num_agent_steps_trained: 1016500
  num_env_steps_sampled: 1033400
  num_env_steps_trained: 1016500
  num_samples_added_to_queue: 1033000
  num_training_step_calls_since_last_synch_worker_weights: 1002
  num_weight_broadcasts: 20301
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 273.579
    learner_load_time_ms: 23.681
    learner_load_wait_time_ms: 1.7
iterations_since_restore: 93
node_ip: 127.0.0.1
num_agent_steps_sampled: 1033400
num_agent_steps_trained: 1016500
num_env_steps_sampled: 1033400
num_env_steps_sampled_this_iter: 11900
num_env_steps_sampled_throughput_per_sec: 1189.995942844872
num_env_steps_trained: 1016500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9960792198342
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 56.192857142857136
  ram_util_percent: 80.53571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0723730687956207
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028232905866699232
  mean_inference_ms: 1.3546318850932888
  mean_raw_obs_processing_ms: 0.3064797308191225
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023540496826171875
    StateBufferConnector_ms: 0.004134416580200195
    ViewRequirementAgentConnector_ms: 0.13941144943237305
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.32
  episode_reward_min: 4.0
  episodes_this_iter: 93
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 10.0, 10.0, 12.0, 10.0, 8.0, 6.0, 8.0, 9.0, 11.0, 12.0,
      12.0, 7.0, 8.0, 9.0, 10.0, 7.0, 9.0, 11.0, 13.0, 9.0, 11.0, 7.0, 8.0, 14.0,
      9.0, 9.0, 9.0, 5.0, 12.0, 9.0, 4.0, 11.0, 6.0, 13.0, 13.0, 13.0, 8.0, 4.0, 9.0,
      7.0, 7.0, 15.0, 11.0, 8.0, 8.0, 7.0, 6.0, 10.0, 15.0, 9.0, 12.0, 7.0, 11.0,
      10.0, 12.0, 10.0, 10.0, 14.0, 10.0, 5.0, 12.0, 6.0, 11.0, 10.0, 10.0, 6.0, 9.0,
      11.0, 8.0, 17.0, 7.0, 7.0, 14.0, 8.0, 11.0, 11.0, 9.0, 14.0, 7.0, 6.0, 17.0,
      9.0, 9.0, 9.0, 8.0, 11.0, 7.0, 5.0, 4.0, 9.0, 8.0, 7.0, 4.0, 10.0, 9.0, 9.0,
      10.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0723730687956207
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028232905866699232
    mean_inference_ms: 1.3546318850932888
    mean_raw_obs_processing_ms: 0.3064797308191225
time_since_restore: 946.3507835865021
time_this_iter_s: 10.15851879119873
time_total_s: 946.3507835865021
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.047
timestamp: 1691995125
timesteps_total: 1033400
training_iteration: 93
trial_id: default
train step: 94
agent_timesteps_total: 1044300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.025609254837036133
  StateBufferConnector_ms: 0.004617452621459961
  ViewRequirementAgentConnector_ms: 0.1454479694366455
counters:
  num_agent_steps_sampled: 1044300
  num_agent_steps_trained: 1027500
  num_env_steps_sampled: 1044300
  num_env_steps_trained: 1027500
  num_samples_added_to_queue: 1044000
  num_training_step_calls_since_last_synch_worker_weights: 398
  num_weight_broadcasts: 20515
custom_metrics: {}
date: 2023-08-14_15-38-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.11
episode_reward_min: 2.0
episodes_this_iter: 85
episodes_total: 8159
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7479810118675232
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 35.91814041137695
        total_loss: 71.4654769897461
        var_gnorm: 64.00243377685547
        vf_explained_var: 0.9113723039627075
        vf_loss: 78.57447814941406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2055.0
  learner_queue:
    size_count: 2061
    size_mean: 15.16
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3763720427268205
  num_agent_steps_sampled: 1044300
  num_agent_steps_trained: 1027500
  num_env_steps_sampled: 1044300
  num_env_steps_trained: 1027500
  num_samples_added_to_queue: 1044000
  num_training_step_calls_since_last_synch_worker_weights: 398
  num_weight_broadcasts: 20515
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 256.052
    learner_load_time_ms: 23.672
    learner_load_wait_time_ms: 1.64
iterations_since_restore: 94
node_ip: 127.0.0.1
num_agent_steps_sampled: 1044300
num_agent_steps_trained: 1027500
num_env_steps_sampled: 1044300
num_env_steps_sampled_this_iter: 10900
num_env_steps_sampled_throughput_per_sec: 1089.995530146809
num_env_steps_trained: 1027500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9954891389816
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 62.926666666666655
  ram_util_percent: 80.34666666666665
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07240825826151293
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028253855735613963
  mean_inference_ms: 1.3546392545491526
  mean_raw_obs_processing_ms: 0.3064892420970527
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.025609254837036133
    StateBufferConnector_ms: 0.004617452621459961
    ViewRequirementAgentConnector_ms: 0.1454479694366455
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.11
  episode_reward_min: 2.0
  episodes_this_iter: 85
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 8.0, 11.0, 7.0, 5.0, 4.0, 9.0, 8.0, 7.0, 4.0, 10.0, 9.0,
      9.0, 10.0, 8.0, 8.0, 7.0, 8.0, 7.0, 12.0, 12.0, 8.0, 8.0, 6.0, 7.0, 8.0, 4.0,
      7.0, 8.0, 8.0, 10.0, 7.0, 10.0, 8.0, 7.0, 8.0, 11.0, 11.0, 6.0, 17.0, 5.0, 5.0,
      9.0, 8.0, 13.0, 7.0, 4.0, 12.0, 5.0, 10.0, 8.0, 9.0, 8.0, 9.0, 8.0, 4.0, 10.0,
      10.0, 8.0, 6.0, 8.0, 2.0, 13.0, 4.0, 6.0, 9.0, 3.0, 12.0, 12.0, 11.0, 7.0, 10.0,
      11.0, 7.0, 8.0, 9.0, 10.0, 7.0, 6.0, 9.0, 8.0, 7.0, 7.0, 6.0, 7.0, 9.0, 7.0,
      9.0, 10.0, 6.0, 6.0, 11.0, 11.0, 6.0, 9.0, 8.0, 6.0, 9.0, 7.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07240825826151293
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028253855735613963
    mean_inference_ms: 1.3546392545491526
    mean_raw_obs_processing_ms: 0.3064892420970527
time_since_restore: 956.4872524738312
time_this_iter_s: 10.136468887329102
time_total_s: 956.4872524738312
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995135
timesteps_total: 1044300
training_iteration: 94
trial_id: default
train step: 95
agent_timesteps_total: 1056500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023078441619873047
  StateBufferConnector_ms: 0.004057884216308594
  ViewRequirementAgentConnector_ms: 0.12944483757019043
counters:
  num_agent_steps_sampled: 1056500
  num_agent_steps_trained: 1040000
  num_env_steps_sampled: 1056500
  num_env_steps_trained: 1040000
  num_samples_added_to_queue: 1056500
  num_training_step_calls_since_last_synch_worker_weights: 181
  num_weight_broadcasts: 20756
custom_metrics: {}
date: 2023-08-14_15-39-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 7.18
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 8255
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7436621189117432
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -29.634159088134766
        total_loss: 9.75804615020752
        var_gnorm: 64.01609802246094
        vf_explained_var: 0.9282629489898682
        vf_loss: 86.22103118896484
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2080.0
  learner_queue:
    size_count: 2086
    size_mean: 14.88
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.632666530556684
  num_agent_steps_sampled: 1056500
  num_agent_steps_trained: 1040000
  num_env_steps_sampled: 1056500
  num_env_steps_trained: 1040000
  num_samples_added_to_queue: 1056500
  num_training_step_calls_since_last_synch_worker_weights: 181
  num_weight_broadcasts: 20756
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 187.432
    learner_load_time_ms: 17.262
    learner_load_wait_time_ms: 1.955
iterations_since_restore: 95
node_ip: 127.0.0.1
num_agent_steps_sampled: 1056500
num_agent_steps_trained: 1040000
num_env_steps_sampled: 1056500
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.9950843055428
num_env_steps_trained: 1040000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9949634278103
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 55.278571428571425
  ram_util_percent: 77.40714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07229973532739194
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028247253458504606
  mean_inference_ms: 1.3534946518913702
  mean_raw_obs_processing_ms: 0.30621926428845386
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023078441619873047
    StateBufferConnector_ms: 0.004057884216308594
    ViewRequirementAgentConnector_ms: 0.12944483757019043
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 7.18
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 9.0, 7.0, 9.0, 5.0, 5.0, 5.0, 10.0, 8.0, 10.0, 12.0, 3.0,
      3.0, 9.0, 6.0, 11.0, 6.0, 8.0, 9.0, 9.0, 7.0, 3.0, 2.0, 7.0, 10.0, 9.0, 5.0,
      5.0, 12.0, 8.0, 5.0, 8.0, 9.0, 7.0, 4.0, 9.0, 3.0, 5.0, 11.0, 10.0, 7.0, 9.0,
      6.0, 3.0, 6.0, 6.0, 6.0, 7.0, 8.0, 4.0, 3.0, 4.0, 10.0, 10.0, 11.0, 10.0, 7.0,
      6.0, 2.0, 7.0, 6.0, 5.0, 10.0, 10.0, 6.0, 6.0, 4.0, 5.0, 8.0, 11.0, 4.0, 5.0,
      10.0, 10.0, 9.0, 7.0, 8.0, 6.0, 6.0, 11.0, 5.0, 7.0, 11.0, 7.0, 9.0, 12.0, 9.0,
      6.0, 5.0, 5.0, 11.0, 8.0, 10.0, 6.0, 8.0, 0.0, 7.0, 9.0, 11.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07229973532739194
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028247253458504606
    mean_inference_ms: 1.3534946518913702
    mean_raw_obs_processing_ms: 0.30621926428845386
time_since_restore: 966.6761405467987
time_this_iter_s: 10.18888807296753
time_total_s: 966.6761405467987
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691995145
timesteps_total: 1056500
training_iteration: 95
trial_id: default
train step: 96
agent_timesteps_total: 1069900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01946595998910757
  StateBufferConnector_ms: 0.003435978522667518
  ViewRequirementAgentConnector_ms: 0.11812815299400917
counters:
  num_agent_steps_sampled: 1069900
  num_agent_steps_trained: 1053000
  num_env_steps_sampled: 1069900
  num_env_steps_trained: 1053000
  num_samples_added_to_queue: 1069500
  num_training_step_calls_since_last_synch_worker_weights: 1
  num_weight_broadcasts: 21020
custom_metrics: {}
date: 2023-08-14_15-39-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.423076923076923
episode_reward_min: 3.0
episodes_this_iter: 104
episodes_total: 8359
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7668867111206055
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 27.030506134033203
        total_loss: 52.28097915649414
        var_gnorm: 64.02552795410156
        vf_explained_var: 0.9465180039405823
        vf_loss: 58.16981506347656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2106.0
  learner_queue:
    size_count: 2113
    size_mean: 15.06
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6298466185503468
  num_agent_steps_sampled: 1069900
  num_agent_steps_trained: 1053000
  num_env_steps_sampled: 1069900
  num_env_steps_trained: 1053000
  num_samples_added_to_queue: 1069500
  num_training_step_calls_since_last_synch_worker_weights: 1
  num_weight_broadcasts: 21020
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 157.172
    learner_load_time_ms: 17.234
    learner_load_wait_time_ms: 1.583
iterations_since_restore: 96
node_ip: 127.0.0.1
num_agent_steps_sampled: 1069900
num_agent_steps_trained: 1053000
num_env_steps_sampled: 1069900
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9802883186842
num_env_steps_trained: 1053000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9808767270817
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.96666666666667
  ram_util_percent: 77.35333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07212280224079229
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02818341910042277
  mean_inference_ms: 1.350545942738333
  mean_raw_obs_processing_ms: 0.30559158505209555
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01946595998910757
    StateBufferConnector_ms: 0.003435978522667518
    ViewRequirementAgentConnector_ms: 0.11812815299400917
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.423076923076923
  episode_reward_min: 3.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 5.0, 3.0, 8.0, 8.0, 8.0, 8.0, 4.0, 13.0, 5.0, 9.0,
      3.0, 11.0, 6.0, 9.0, 9.0, 11.0, 7.0, 4.0, 7.0, 7.0, 14.0, 7.0, 5.0, 11.0, 7.0,
      10.0, 7.0, 5.0, 9.0, 9.0, 8.0, 13.0, 7.0, 8.0, 9.0, 6.0, 6.0, 9.0, 6.0, 4.0,
      7.0, 10.0, 7.0, 5.0, 7.0, 8.0, 9.0, 4.0, 3.0, 6.0, 11.0, 10.0, 13.0, 9.0, 5.0,
      7.0, 5.0, 5.0, 3.0, 5.0, 9.0, 6.0, 8.0, 3.0, 8.0, 8.0, 6.0, 6.0, 7.0, 9.0, 12.0,
      5.0, 10.0, 6.0, 5.0, 5.0, 10.0, 13.0, 10.0, 9.0, 14.0, 6.0, 7.0, 5.0, 11.0,
      9.0, 5.0, 8.0, 7.0, 6.0, 9.0, 9.0, 3.0, 5.0, 7.0, 8.0, 9.0, 8.0, 6.0, 6.0, 6.0,
      11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07212280224079229
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02818341910042277
    mean_inference_ms: 1.350545942738333
    mean_raw_obs_processing_ms: 0.30559158505209555
time_since_restore: 976.830230474472
time_this_iter_s: 10.15408992767334
time_total_s: 976.830230474472
timers:
  sample_time_ms: 0.057
  synch_weights_time_ms: 0.235
  training_iteration_time_ms: 0.363
timestamp: 1691995155
timesteps_total: 1069900
training_iteration: 96
trial_id: default
train step: 97
agent_timesteps_total: 1083600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01865703368855414
  StateBufferConnector_ms: 0.0033449903826847254
  ViewRequirementAgentConnector_ms: 0.11441150558329075
counters:
  num_agent_steps_sampled: 1083600
  num_agent_steps_trained: 1067000
  num_env_steps_sampled: 1083600
  num_env_steps_trained: 1067000
  num_samples_added_to_queue: 1083500
  num_training_step_calls_since_last_synch_worker_weights: 1115
  num_weight_broadcasts: 21291
custom_metrics: {}
date: 2023-08-14_15-39-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.579439252336448
episode_reward_min: 2.0
episodes_this_iter: 107
episodes_total: 8466
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6478902101516724
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -32.70093536376953
        total_loss: 1.8689932823181152
        var_gnorm: 64.0358657836914
        vf_explained_var: 0.9360961318016052
        vf_loss: 75.61875915527344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2134.0
  learner_queue:
    size_count: 2138
    size_mean: 15.24
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.5173661390712527
  num_agent_steps_sampled: 1083600
  num_agent_steps_trained: 1067000
  num_env_steps_sampled: 1083600
  num_env_steps_trained: 1067000
  num_samples_added_to_queue: 1083500
  num_training_step_calls_since_last_synch_worker_weights: 1115
  num_weight_broadcasts: 21291
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 238.338
    learner_load_time_ms: 9.271
    learner_load_wait_time_ms: 1.494
iterations_since_restore: 97
node_ip: 127.0.0.1
num_agent_steps_sampled: 1083600
num_agent_steps_trained: 1067000
num_env_steps_sampled: 1083600
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9968643260247
num_env_steps_trained: 1067000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.996795661631
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.878571428571426
  ram_util_percent: 76.95714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07194718402145864
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028104467604185123
  mean_inference_ms: 1.3472041731379132
  mean_raw_obs_processing_ms: 0.3048888678032392
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01865703368855414
    StateBufferConnector_ms: 0.0033449903826847254
    ViewRequirementAgentConnector_ms: 0.11441150558329075
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.579439252336448
  episode_reward_min: 2.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 6.0, 11.0, 12.0, 9.0, 6.0, 7.0, 5.0, 7.0, 9.0, 6.0, 10.0,
      6.0, 6.0, 6.0, 10.0, 7.0, 13.0, 11.0, 7.0, 8.0, 5.0, 7.0, 6.0, 5.0, 7.0, 3.0,
      5.0, 7.0, 5.0, 6.0, 3.0, 10.0, 8.0, 6.0, 11.0, 10.0, 8.0, 5.0, 10.0, 7.0, 12.0,
      6.0, 8.0, 9.0, 8.0, 11.0, 11.0, 3.0, 6.0, 13.0, 12.0, 12.0, 7.0, 12.0, 4.0,
      4.0, 5.0, 7.0, 6.0, 8.0, 7.0, 5.0, 4.0, 11.0, 5.0, 7.0, 7.0, 3.0, 5.0, 5.0,
      5.0, 6.0, 5.0, 2.0, 13.0, 7.0, 7.0, 7.0, 11.0, 3.0, 6.0, 7.0, 7.0, 5.0, 10.0,
      6.0, 11.0, 7.0, 7.0, 12.0, 7.0, 7.0, 9.0, 8.0, 13.0, 11.0, 10.0, 9.0, 14.0,
      8.0, 6.0, 8.0, 9.0, 5.0, 6.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07194718402145864
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028104467604185123
    mean_inference_ms: 1.3472041731379132
    mean_raw_obs_processing_ms: 0.3048888678032392
time_since_restore: 986.9221837520599
time_this_iter_s: 10.09195327758789
time_total_s: 986.9221837520599
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995165
timesteps_total: 1083600
training_iteration: 97
trial_id: default
train step: 98
agent_timesteps_total: 1097200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019171552838019607
  StateBufferConnector_ms: 0.0033994890608877505
  ViewRequirementAgentConnector_ms: 0.11465009653343344
counters:
  num_agent_steps_sampled: 1097200
  num_agent_steps_trained: 1080500
  num_env_steps_sampled: 1097200
  num_env_steps_trained: 1080500
  num_samples_added_to_queue: 1097000
  num_training_step_calls_since_last_synch_worker_weights: 242
  num_weight_broadcasts: 21558
custom_metrics: {}
date: 2023-08-14_15-39-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.7924528301886795
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 8572
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7021260857582092
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 21.16987419128418
        total_loss: 51.073612213134766
        var_gnorm: 64.04483032226562
        vf_explained_var: 0.9204314947128296
        vf_loss: 66.8287353515625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2161.0
  learner_queue:
    size_count: 2167
    size_mean: 15.5
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1357816691600546
  num_agent_steps_sampled: 1097200
  num_agent_steps_trained: 1080500
  num_env_steps_sampled: 1097200
  num_env_steps_trained: 1080500
  num_samples_added_to_queue: 1097000
  num_training_step_calls_since_last_synch_worker_weights: 242
  num_weight_broadcasts: 21558
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 175.887
    learner_load_time_ms: 9.262
    learner_load_wait_time_ms: 1.489
iterations_since_restore: 98
node_ip: 127.0.0.1
num_agent_steps_sampled: 1097200
num_agent_steps_trained: 1080500
num_env_steps_sampled: 1097200
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9991893773142
num_env_steps_trained: 1080500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.999195337775
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.08571428571429
  ram_util_percent: 77.20000000000002
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07178173080780088
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.028034880403880663
  mean_inference_ms: 1.344158951809618
  mean_raw_obs_processing_ms: 0.30423745219684706
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019171552838019607
    StateBufferConnector_ms: 0.0033994890608877505
    ViewRequirementAgentConnector_ms: 0.11465009653343344
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.7924528301886795
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 13.0, 9.0, 5.0, 10.0, 9.0, 6.0, 7.0, 8.0, 4.0, 9.0, 9.0,
      7.0, 6.0, 6.0, 12.0, 7.0, 10.0, 6.0, 13.0, 10.0, 8.0, 7.0, 15.0, 9.0, 8.0, 5.0,
      5.0, 7.0, 12.0, 10.0, 14.0, 6.0, 8.0, 3.0, 9.0, 8.0, 3.0, 6.0, 9.0, 9.0, 9.0,
      5.0, 9.0, 8.0, 4.0, 9.0, 8.0, 9.0, 6.0, 9.0, 4.0, 8.0, 5.0, 8.0, 13.0, 7.0,
      5.0, 7.0, 12.0, 7.0, 7.0, 10.0, 4.0, 6.0, 5.0, 5.0, 7.0, 9.0, 12.0, 9.0, 5.0,
      9.0, 6.0, 8.0, 5.0, 8.0, 6.0, 7.0, 7.0, 7.0, 10.0, 9.0, 6.0, 7.0, 6.0, 6.0,
      5.0, 11.0, 8.0, 8.0, 8.0, 9.0, 10.0, 8.0, 8.0, 7.0, 6.0, 8.0, 7.0, 10.0, 9.0,
      7.0, 9.0, 8.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07178173080780088
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.028034880403880663
    mean_inference_ms: 1.344158951809618
    mean_raw_obs_processing_ms: 0.30423745219684706
time_since_restore: 997.064083814621
time_this_iter_s: 10.141900062561035
time_total_s: 997.064083814621
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995175
timesteps_total: 1097200
training_iteration: 98
trial_id: default
train step: 99
agent_timesteps_total: 1110400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019616347092848558
  StateBufferConnector_ms: 0.0034731168013352612
  ViewRequirementAgentConnector_ms: 0.11824094332181491
counters:
  num_agent_steps_sampled: 1110400
  num_agent_steps_trained: 1093500
  num_env_steps_sampled: 1110400
  num_env_steps_trained: 1093500
  num_samples_added_to_queue: 1110000
  num_training_step_calls_since_last_synch_worker_weights: 929
  num_weight_broadcasts: 21818
custom_metrics: {}
date: 2023-08-14_15-39-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.971153846153847
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 8676
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7379978895187378
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.867194175720215
        total_loss: 3.3686416149139404
        var_gnorm: 64.05207824707031
        vf_explained_var: 0.9479053616523743
        vf_loss: 25.85165023803711
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2187.0
  learner_queue:
    size_count: 2191
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.324990566004151
  num_agent_steps_sampled: 1110400
  num_agent_steps_trained: 1093500
  num_env_steps_sampled: 1110400
  num_env_steps_trained: 1093500
  num_samples_added_to_queue: 1110000
  num_training_step_calls_since_last_synch_worker_weights: 929
  num_weight_broadcasts: 21818
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 260.003
    learner_load_time_ms: 1.819
    learner_load_wait_time_ms: 1.556
iterations_since_restore: 99
node_ip: 127.0.0.1
num_agent_steps_sampled: 1110400
num_agent_steps_trained: 1093500
num_env_steps_sampled: 1110400
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9978914294547
num_env_steps_trained: 1093500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9979233774932
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.91428571428571
  ram_util_percent: 77.15
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07164652658329806
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02797821494119746
  mean_inference_ms: 1.3416201294801984
  mean_raw_obs_processing_ms: 0.30369440653303675
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019616347092848558
    StateBufferConnector_ms: 0.0034731168013352612
    ViewRequirementAgentConnector_ms: 0.11824094332181491
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.971153846153847
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 14.0, 12.0, 4.0, 10.0, 9.0, 8.0, 10.0, 11.0, 11.0, 8.0,
      9.0, 10.0, 6.0, 11.0, 8.0, 10.0, 10.0, 8.0, 11.0, 13.0, 9.0, 9.0, 8.0, 10.0,
      6.0, 7.0, 7.0, 12.0, 13.0, 9.0, 10.0, 8.0, 14.0, 3.0, 11.0, 10.0, 9.0, 7.0,
      8.0, 12.0, 3.0, 8.0, 9.0, 14.0, 10.0, 11.0, 9.0, 10.0, 7.0, 10.0, 11.0, 7.0,
      10.0, 9.0, 9.0, 9.0, 8.0, 7.0, 5.0, 10.0, 9.0, 12.0, 2.0, 9.0, 12.0, 7.0, 7.0,
      10.0, 10.0, 7.0, 6.0, 10.0, 6.0, 9.0, 9.0, 9.0, 11.0, 6.0, 6.0, 8.0, 10.0, 8.0,
      6.0, 16.0, 13.0, 10.0, 15.0, 10.0, 8.0, 11.0, 10.0, 7.0, 9.0, 7.0, 7.0, 5.0,
      8.0, 14.0, 3.0, 9.0, 8.0, 7.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07164652658329806
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02797821494119746
    mean_inference_ms: 1.3416201294801984
    mean_raw_obs_processing_ms: 0.30369440653303675
time_since_restore: 1007.1674938201904
time_this_iter_s: 10.103410005569458
time_total_s: 1007.1674938201904
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995185
timesteps_total: 1110400
training_iteration: 99
trial_id: default
train step: 100
agent_timesteps_total: 1124200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019192472796573816
  StateBufferConnector_ms: 0.003384429717732367
  ViewRequirementAgentConnector_ms: 0.11451489457460208
counters:
  num_agent_steps_sampled: 1124200
  num_agent_steps_trained: 1107500
  num_env_steps_sampled: 1124200
  num_env_steps_trained: 1107500
  num_samples_added_to_queue: 1124000
  num_training_step_calls_since_last_synch_worker_weights: 826
  num_weight_broadcasts: 22091
custom_metrics: {}
date: 2023-08-14_15-39-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.794392523364486
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 8783
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6888831853866577
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.580707550048828
        total_loss: 33.113059997558594
        var_gnorm: 64.06298828125
        vf_explained_var: 0.9191117286682129
        vf_loss: 96.2763671875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2215.0
  learner_queue:
    size_count: 2220
    size_mean: 15.54
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0432641084595982
  num_agent_steps_sampled: 1124200
  num_agent_steps_trained: 1107500
  num_env_steps_sampled: 1124200
  num_env_steps_trained: 1107500
  num_samples_added_to_queue: 1124000
  num_training_step_calls_since_last_synch_worker_weights: 826
  num_weight_broadcasts: 22091
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 209.957
    learner_load_time_ms: 2.44
    learner_load_wait_time_ms: 1.543
iterations_since_restore: 100
node_ip: 127.0.0.1
num_agent_steps_sampled: 1124200
num_agent_steps_trained: 1107500
num_env_steps_sampled: 1124200
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.994472525802
num_env_steps_trained: 1107500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9943924174804
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.88666666666667
  ram_util_percent: 77.45333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07147551756528059
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02790655784667515
  mean_inference_ms: 1.3384352027021835
  mean_raw_obs_processing_ms: 0.30302169378615146
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019192472796573816
    StateBufferConnector_ms: 0.003384429717732367
    ViewRequirementAgentConnector_ms: 0.11451489457460208
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.794392523364486
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 7.0, 6.0, 7.0, 6.0, 10.0, 7.0, 10.0, 10.0, 5.0, 14.0, 7.0,
      10.0, 7.0, 7.0, 10.0, 8.0, 8.0, 7.0, 4.0, 11.0, 9.0, 11.0, 7.0, 9.0, 9.0, 10.0,
      11.0, 5.0, 10.0, 10.0, 10.0, 8.0, 6.0, 9.0, 8.0, 3.0, 7.0, 8.0, 7.0, 5.0, 7.0,
      4.0, 6.0, 9.0, 3.0, 7.0, 11.0, 6.0, 8.0, 4.0, 7.0, 5.0, 3.0, 9.0, 8.0, 7.0,
      7.0, 5.0, 7.0, 11.0, 6.0, 7.0, 9.0, 9.0, 7.0, 7.0, 4.0, 12.0, 6.0, 11.0, 9.0,
      10.0, 15.0, 11.0, 6.0, 11.0, 14.0, 9.0, 7.0, 3.0, 8.0, 10.0, 9.0, 6.0, 4.0,
      4.0, 10.0, 10.0, 16.0, 9.0, 8.0, 7.0, 7.0, 9.0, 6.0, 5.0, 6.0, 8.0, 6.0, 7.0,
      8.0, 8.0, 8.0, 5.0, 8.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07147551756528059
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02790655784667515
    mean_inference_ms: 1.3384352027021835
    mean_raw_obs_processing_ms: 0.30302169378615146
time_since_restore: 1017.2808451652527
time_this_iter_s: 10.113351345062256
time_total_s: 1017.2808451652527
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995196
timesteps_total: 1124200
training_iteration: 100
trial_id: default
train step: 101
agent_timesteps_total: 1136800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02046680450439453
  StateBufferConnector_ms: 0.0036673545837402344
  ViewRequirementAgentConnector_ms: 0.1230008602142334
counters:
  num_agent_steps_sampled: 1136800
  num_agent_steps_trained: 1120000
  num_env_steps_sampled: 1136800
  num_env_steps_trained: 1120000
  num_samples_added_to_queue: 1136500
  num_training_step_calls_since_last_synch_worker_weights: 1408
  num_weight_broadcasts: 22337
custom_metrics: {}
date: 2023-08-14_15-40-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 5.94
episode_reward_min: 0.0
episodes_this_iter: 99
episodes_total: 8882
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6836678385734558
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 10.381633758544922
        total_loss: 57.190486907958984
        var_gnorm: 64.07113647460938
        vf_explained_var: 0.9122013449668884
        vf_loss: 100.45438385009766
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2240.0
  learner_queue:
    size_count: 2244
    size_mean: 15.56
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9830564581955606
  num_agent_steps_sampled: 1136800
  num_agent_steps_trained: 1120000
  num_env_steps_sampled: 1136800
  num_env_steps_trained: 1120000
  num_samples_added_to_queue: 1136500
  num_training_step_calls_since_last_synch_worker_weights: 1408
  num_weight_broadcasts: 22337
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 340.705
    learner_load_time_ms: 2.063
    learner_load_wait_time_ms: 1.819
iterations_since_restore: 101
node_ip: 127.0.0.1
num_agent_steps_sampled: 1136800
num_agent_steps_trained: 1120000
num_env_steps_sampled: 1136800
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9948630542378
num_env_steps_trained: 1120000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9949038236487
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 56.57142857142857
  ram_util_percent: 77.51428571428572
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07141813738903986
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02787083089491155
  mean_inference_ms: 1.3367124050406523
  mean_raw_obs_processing_ms: 0.3026399119678993
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02046680450439453
    StateBufferConnector_ms: 0.0036673545837402344
    ViewRequirementAgentConnector_ms: 0.1230008602142334
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 5.94
  episode_reward_min: 0.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 8.0, 9.0, 9.0, 6.0, 11.0, 8.0, 7.0, 8.0, 10.0, 7.0, 8.0,
      4.0, 5.0, 5.0, 6.0, 5.0, 3.0, 6.0, 8.0, 4.0, 2.0, 4.0, 5.0, 7.0, 4.0, 10.0,
      7.0, 5.0, 4.0, 9.0, 4.0, 8.0, 2.0, 11.0, 5.0, 4.0, 8.0, 7.0, 7.0, 7.0, 6.0,
      10.0, 4.0, 6.0, 5.0, 7.0, 7.0, 2.0, 7.0, 6.0, 5.0, 13.0, 5.0, 3.0, 5.0, 9.0,
      8.0, 13.0, 8.0, 8.0, 2.0, 5.0, 5.0, 5.0, 0.0, 7.0, 7.0, 3.0, 3.0, 7.0, 4.0,
      6.0, 2.0, 6.0, 4.0, 4.0, 6.0, 8.0, 7.0, 5.0, 9.0, 3.0, 5.0, 4.0, 5.0, 4.0, 4.0,
      3.0, 7.0, 7.0, 5.0, 7.0, 5.0, 4.0, 4.0, 6.0, 7.0, 1.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07141813738903986
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02787083089491155
    mean_inference_ms: 1.3367124050406523
    mean_raw_obs_processing_ms: 0.3026399119678993
time_since_restore: 1027.384205341339
time_this_iter_s: 10.103360176086426
time_total_s: 1027.384205341339
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691995206
timesteps_total: 1136800
training_iteration: 101
trial_id: default
train step: 102
agent_timesteps_total: 1147600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02660393714904785
  StateBufferConnector_ms: 0.0048828125
  ViewRequirementAgentConnector_ms: 0.1586627960205078
counters:
  num_agent_steps_sampled: 1147600
  num_agent_steps_trained: 1131000
  num_env_steps_sampled: 1147600
  num_env_steps_trained: 1131000
  num_samples_added_to_queue: 1147500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 22550
custom_metrics: {}
date: 2023-08-14_15-40-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.77
episode_reward_min: 1.0
episodes_this_iter: 84
episodes_total: 8966
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7957739233970642
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -32.02645492553711
        total_loss: -18.753704071044922
        var_gnorm: 64.080322265625
        vf_explained_var: 0.9518766403198242
        vf_loss: 34.503238677978516
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2262.0
  learner_queue:
    size_count: 2263
    size_mean: 15.5
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.004987562112089
  num_agent_steps_sampled: 1147600
  num_agent_steps_trained: 1131000
  num_env_steps_sampled: 1147600
  num_env_steps_trained: 1131000
  num_samples_added_to_queue: 1147500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 22550
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 454.231
    learner_load_time_ms: 2.082
    learner_load_wait_time_ms: 1.968
iterations_since_restore: 102
node_ip: 127.0.0.1
num_agent_steps_sampled: 1147600
num_agent_steps_trained: 1131000
num_env_steps_sampled: 1147600
num_env_steps_sampled_this_iter: 10800
num_env_steps_sampled_throughput_per_sec: 1077.3025467214766
num_env_steps_trained: 1131000
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1097.2525938829854
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 69.0
  ram_util_percent: 78.72857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07148586430376323
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027878912773048947
  mean_inference_ms: 1.3368838886633363
  mean_raw_obs_processing_ms: 0.3026600962657631
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02660393714904785
    StateBufferConnector_ms: 0.0048828125
    ViewRequirementAgentConnector_ms: 0.1586627960205078
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.77
  episode_reward_min: 1.0
  episodes_this_iter: 84
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 4.0, 4.0, 3.0, 7.0, 7.0, 5.0, 7.0, 5.0, 4.0, 4.0, 6.0,
      7.0, 1.0, 9.0, 1.0, 5.0, 5.0, 4.0, 7.0, 4.0, 6.0, 5.0, 5.0, 3.0, 5.0, 7.0, 4.0,
      3.0, 8.0, 8.0, 10.0, 7.0, 5.0, 4.0, 6.0, 4.0, 8.0, 10.0, 4.0, 8.0, 3.0, 4.0,
      3.0, 7.0, 4.0, 3.0, 5.0, 4.0, 6.0, 7.0, 6.0, 6.0, 5.0, 4.0, 7.0, 5.0, 9.0, 9.0,
      7.0, 11.0, 5.0, 3.0, 8.0, 5.0, 7.0, 6.0, 12.0, 3.0, 7.0, 4.0, 8.0, 6.0, 8.0,
      4.0, 4.0, 9.0, 5.0, 6.0, 7.0, 5.0, 8.0, 3.0, 10.0, 4.0, 4.0, 9.0, 8.0, 5.0,
      8.0, 5.0, 8.0, 9.0, 5.0, 6.0, 5.0, 2.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07148586430376323
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027878912773048947
    mean_inference_ms: 1.3368838886633363
    mean_raw_obs_processing_ms: 0.3026600962657631
time_since_restore: 1037.4466404914856
time_this_iter_s: 10.062435150146484
time_total_s: 1037.4466404914856
timers:
  sample_time_ms: 0.073
  synch_weights_time_ms: 12.7
  training_iteration_time_ms: 12.846
timestamp: 1691995216
timesteps_total: 1147600
training_iteration: 102
trial_id: default
train step: 103
agent_timesteps_total: 1160850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020015927461477425
  StateBufferConnector_ms: 0.003593701582688552
  ViewRequirementAgentConnector_ms: 0.11972441123082088
counters:
  num_agent_steps_sampled: 1160850
  num_agent_steps_trained: 1144000
  num_env_steps_sampled: 1160850
  num_env_steps_trained: 1144000
  num_samples_added_to_queue: 1160500
  num_training_step_calls_since_last_synch_worker_weights: 242
  num_weight_broadcasts: 22808
custom_metrics: {}
date: 2023-08-14_15-40-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 5.653846153846154
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 9070
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7570397257804871
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.988077163696289
        total_loss: 11.683412551879883
        var_gnorm: 64.09052276611328
        vf_explained_var: 0.9660199880599976
        vf_loss: 36.91337585449219
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2288.0
  learner_queue:
    size_count: 2295
    size_mean: 15.54
    size_quantiles: [10.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 1.2839003076563227
  num_agent_steps_sampled: 1160850
  num_agent_steps_trained: 1144000
  num_env_steps_sampled: 1160850
  num_env_steps_trained: 1144000
  num_samples_added_to_queue: 1160500
  num_training_step_calls_since_last_synch_worker_weights: 242
  num_weight_broadcasts: 22808
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 151.968
    learner_load_time_ms: 2.11
    learner_load_wait_time_ms: 1.738
iterations_since_restore: 103
node_ip: 127.0.0.1
num_agent_steps_sampled: 1160850
num_agent_steps_trained: 1144000
num_env_steps_sampled: 1160850
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.9981361653797
num_env_steps_trained: 1144000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9981713320706
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 64.40714285714286
  ram_util_percent: 78.91428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07130656023719464
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027839962128193393
  mean_inference_ms: 1.3347680428729878
  mean_raw_obs_processing_ms: 0.302213479113252
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020015927461477425
    StateBufferConnector_ms: 0.003593701582688552
    ViewRequirementAgentConnector_ms: 0.11972441123082088
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 5.653846153846154
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 6.0, 0.0, 2.0, 3.0, 4.0, 9.0, 0.0, 7.0, 3.0, 8.0, 7.0, 8.0,
      5.0, 4.0, 7.0, 6.0, 7.0, 4.0, 4.0, 6.0, 4.0, 2.0, 0.0, 4.0, 0.0, 11.0, 6.0,
      5.0, 5.0, 8.0, 1.0, 6.0, 9.0, 6.0, 2.0, 5.0, 5.0, 10.0, 6.0, 7.0, 9.0, 9.0,
      6.0, 8.0, 10.0, 4.0, 6.0, 5.0, 5.0, 8.0, 9.0, 10.0, 5.0, 4.0, 9.0, 8.0, 4.0,
      6.0, 7.0, 7.0, 1.0, 4.0, 10.0, 1.0, 1.0, 6.0, 2.0, 4.0, 2.0, 4.0, 6.0, 7.0,
      2.0, 5.0, 3.0, 2.0, 5.0, 5.0, 5.0, 4.0, 11.0, 3.0, 7.0, 5.0, 4.0, 6.0, 9.0,
      2.0, 7.0, 7.0, 8.0, 6.0, 9.0, 7.0, 9.0, 10.0, 9.0, 10.0, 5.0, 4.0, 9.0, 8.0,
      8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07130656023719464
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027839962128193393
    mean_inference_ms: 1.3347680428729878
    mean_raw_obs_processing_ms: 0.302213479113252
time_since_restore: 1047.6230056285858
time_this_iter_s: 10.17636513710022
time_total_s: 1047.6230056285858
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.052
timestamp: 1691995226
timesteps_total: 1160850
training_iteration: 103
trial_id: default
train step: 104
agent_timesteps_total: 1172850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021767854690551758
  StateBufferConnector_ms: 0.0038728713989257812
  ViewRequirementAgentConnector_ms: 0.13059353828430176
counters:
  num_agent_steps_sampled: 1172850
  num_agent_steps_trained: 1156000
  num_env_steps_sampled: 1172850
  num_env_steps_trained: 1156000
  num_samples_added_to_queue: 1172500
  num_training_step_calls_since_last_synch_worker_weights: 168
  num_weight_broadcasts: 23043
custom_metrics: {}
date: 2023-08-14_15-40-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.68
episode_reward_min: 1.0
episodes_this_iter: 94
episodes_total: 9164
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6137174963951111
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -40.58689880371094
        total_loss: -4.827258110046387
        var_gnorm: 64.10379791259766
        vf_explained_var: 0.9221794605255127
        vf_loss: 77.65645599365234
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2312.0
  learner_queue:
    size_count: 2319
    size_mean: 14.92
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8421726303471129
  num_agent_steps_sampled: 1172850
  num_agent_steps_trained: 1156000
  num_env_steps_sampled: 1172850
  num_env_steps_trained: 1156000
  num_samples_added_to_queue: 1172500
  num_training_step_calls_since_last_synch_worker_weights: 168
  num_weight_broadcasts: 23043
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 170.408
    learner_load_time_ms: 2.11
    learner_load_wait_time_ms: 1.608
iterations_since_restore: 104
node_ip: 127.0.0.1
num_agent_steps_sampled: 1172850
num_agent_steps_trained: 1156000
num_env_steps_sampled: 1172850
num_env_steps_sampled_this_iter: 12000
num_env_steps_sampled_throughput_per_sec: 1199.9968814930896
num_env_steps_trained: 1156000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9968814930896
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 66.14
  ram_util_percent: 79.3
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07129407885937111
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027829456917453702
  mean_inference_ms: 1.3339185757268262
  mean_raw_obs_processing_ms: 0.30202529081677265
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021767854690551758
    StateBufferConnector_ms: 0.0038728713989257812
    ViewRequirementAgentConnector_ms: 0.13059353828430176
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.68
  episode_reward_min: 1.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 5.0, 4.0, 9.0, 8.0, 8.0, 7.0, 5.0, 4.0, 5.0, 7.0, 7.0,
      4.0, 10.0, 8.0, 9.0, 3.0, 7.0, 5.0, 10.0, 2.0, 8.0, 4.0, 9.0, 4.0, 10.0, 8.0,
      8.0, 4.0, 5.0, 7.0, 3.0, 4.0, 5.0, 2.0, 5.0, 7.0, 9.0, 2.0, 6.0, 7.0, 6.0, 5.0,
      10.0, 10.0, 7.0, 7.0, 4.0, 7.0, 4.0, 8.0, 4.0, 7.0, 10.0, 12.0, 5.0, 6.0, 6.0,
      3.0, 8.0, 6.0, 6.0, 1.0, 6.0, 8.0, 7.0, 6.0, 6.0, 5.0, 7.0, 4.0, 4.0, 5.0, 6.0,
      11.0, 5.0, 7.0, 7.0, 11.0, 11.0, 12.0, 5.0, 11.0, 8.0, 1.0, 7.0, 9.0, 7.0, 5.0,
      11.0, 10.0, 7.0, 9.0, 3.0, 8.0, 8.0, 8.0, 6.0, 11.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07129407885937111
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027829456917453702
    mean_inference_ms: 1.3339185757268262
    mean_raw_obs_processing_ms: 0.30202529081677265
time_since_restore: 1057.8019876480103
time_this_iter_s: 10.178982019424438
time_total_s: 1057.8019876480103
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995236
timesteps_total: 1172850
training_iteration: 104
trial_id: default
train step: 105
agent_timesteps_total: 1186050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019531623989928002
  StateBufferConnector_ms: 0.003535607281853171
  ViewRequirementAgentConnector_ms: 0.11873595854815315
counters:
  num_agent_steps_sampled: 1186050
  num_agent_steps_trained: 1169500
  num_env_steps_sampled: 1186050
  num_env_steps_trained: 1169500
  num_samples_added_to_queue: 1186000
  num_training_step_calls_since_last_synch_worker_weights: 82
  num_weight_broadcasts: 23303
custom_metrics: {}
date: 2023-08-14_15-40-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 5.931372549019608
episode_reward_min: 1.0
episodes_this_iter: 102
episodes_total: 9266
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6792638301849365
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.652681350708008
        total_loss: -5.1481218338012695
        var_gnorm: 64.11166381835938
        vf_explained_var: 0.9783940315246582
        vf_loss: 25.8017578125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2339.0
  learner_queue:
    size_count: 2345
    size_mean: 14.78
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8361917111238686
  num_agent_steps_sampled: 1186050
  num_agent_steps_trained: 1169500
  num_env_steps_sampled: 1186050
  num_env_steps_trained: 1169500
  num_samples_added_to_queue: 1186000
  num_training_step_calls_since_last_synch_worker_weights: 82
  num_weight_broadcasts: 23303
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 165.226
    learner_load_time_ms: 8.696
    learner_load_wait_time_ms: 1.568
iterations_since_restore: 105
node_ip: 127.0.0.1
num_agent_steps_sampled: 1186050
num_agent_steps_trained: 1169500
num_env_steps_sampled: 1186050
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9956569814524
num_env_steps_trained: 1169500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9955582764853
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 64.22857142857143
  ram_util_percent: 79.9357142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07115393450819937
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02778379833658925
  mean_inference_ms: 1.3317420191556595
  mean_raw_obs_processing_ms: 0.301577456948672
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019531623989928002
    StateBufferConnector_ms: 0.003535607281853171
    ViewRequirementAgentConnector_ms: 0.11873595854815315
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 5.931372549019608
  episode_reward_min: 1.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 11.0, 6.0, 7.0, 6.0, 8.0, 5.0, 7.0, 6.0, 7.0, 5.0, 1.0,
      7.0, 5.0, 5.0, 6.0, 6.0, 11.0, 2.0, 5.0, 9.0, 4.0, 9.0, 8.0, 6.0, 5.0, 6.0,
      7.0, 5.0, 5.0, 6.0, 8.0, 5.0, 4.0, 7.0, 6.0, 7.0, 3.0, 5.0, 8.0, 6.0, 7.0, 1.0,
      4.0, 5.0, 7.0, 5.0, 6.0, 8.0, 5.0, 10.0, 4.0, 7.0, 13.0, 3.0, 6.0, 2.0, 6.0,
      10.0, 4.0, 3.0, 7.0, 9.0, 2.0, 3.0, 4.0, 5.0, 4.0, 3.0, 4.0, 7.0, 6.0, 7.0,
      6.0, 7.0, 6.0, 7.0, 3.0, 7.0, 7.0, 5.0, 6.0, 2.0, 4.0, 4.0, 8.0, 6.0, 4.0, 6.0,
      8.0, 9.0, 9.0, 7.0, 5.0, 1.0, 7.0, 9.0, 5.0, 10.0, 7.0, 4.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07115393450819937
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02778379833658925
    mean_inference_ms: 1.3317420191556595
    mean_raw_obs_processing_ms: 0.301577456948672
time_since_restore: 1067.9728996753693
time_this_iter_s: 10.170912027359009
time_total_s: 1067.9728996753693
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995246
timesteps_total: 1186050
training_iteration: 105
trial_id: default
train step: 106
agent_timesteps_total: 1197550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022548437118530273
  StateBufferConnector_ms: 0.004103899002075195
  ViewRequirementAgentConnector_ms: 0.13380050659179688
counters:
  num_agent_steps_sampled: 1197550
  num_agent_steps_trained: 1181000
  num_env_steps_sampled: 1197550
  num_env_steps_trained: 1181000
  num_samples_added_to_queue: 1197500
  num_training_step_calls_since_last_synch_worker_weights: 1003
  num_weight_broadcasts: 23530
custom_metrics: {}
date: 2023-08-14_15-40-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.01
episode_reward_min: 1.0
episodes_this_iter: 90
episodes_total: 9356
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7682293653488159
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 34.48082733154297
        total_loss: 46.16021728515625
        var_gnorm: 64.12214660644531
        vf_explained_var: 0.962562620639801
        vf_loss: 31.04107666015625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2362.0
  learner_queue:
    size_count: 2367
    size_mean: 14.7
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.9313207915827966
  num_agent_steps_sampled: 1197550
  num_agent_steps_trained: 1181000
  num_env_steps_sampled: 1197550
  num_env_steps_trained: 1181000
  num_samples_added_to_queue: 1197500
  num_training_step_calls_since_last_synch_worker_weights: 1003
  num_weight_broadcasts: 23530
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 246.721
    learner_load_time_ms: 8.134
    learner_load_wait_time_ms: 1.878
iterations_since_restore: 106
node_ip: 127.0.0.1
num_agent_steps_sampled: 1197550
num_agent_steps_trained: 1181000
num_env_steps_sampled: 1197550
num_env_steps_sampled_this_iter: 11500
num_env_steps_sampled_throughput_per_sec: 1149.9884844979408
num_env_steps_trained: 1181000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9884844979408
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 73.78571428571429
  ram_util_percent: 80.72857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07117305298877424
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027784077594881013
  mean_inference_ms: 1.3313526360329015
  mean_raw_obs_processing_ms: 0.30150133547077973
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022548437118530273
    StateBufferConnector_ms: 0.004103899002075195
    ViewRequirementAgentConnector_ms: 0.13380050659179688
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.01
  episode_reward_min: 1.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 5.0, 1.0, 7.0, 9.0, 5.0, 10.0, 7.0, 4.0, 8.0, 7.0, 7.0,
      9.0, 4.0, 5.0, 4.0, 1.0, 5.0, 9.0, 5.0, 6.0, 4.0, 11.0, 5.0, 5.0, 2.0, 8.0,
      7.0, 5.0, 10.0, 10.0, 5.0, 10.0, 6.0, 7.0, 7.0, 4.0, 6.0, 7.0, 6.0, 12.0, 8.0,
      5.0, 5.0, 10.0, 2.0, 9.0, 4.0, 5.0, 9.0, 7.0, 3.0, 5.0, 3.0, 7.0, 4.0, 6.0,
      4.0, 7.0, 5.0, 6.0, 7.0, 6.0, 8.0, 6.0, 4.0, 6.0, 5.0, 6.0, 3.0, 3.0, 8.0, 4.0,
      6.0, 5.0, 5.0, 5.0, 6.0, 3.0, 8.0, 6.0, 7.0, 7.0, 3.0, 7.0, 13.0, 5.0, 7.0,
      9.0, 5.0, 7.0, 6.0, 5.0, 7.0, 6.0, 4.0, 4.0, 7.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07117305298877424
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027784077594881013
    mean_inference_ms: 1.3313526360329015
    mean_raw_obs_processing_ms: 0.30150133547077973
time_since_restore: 1078.1049296855927
time_this_iter_s: 10.132030010223389
time_total_s: 1078.1049296855927
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691995256
timesteps_total: 1197550
training_iteration: 106
trial_id: default
train step: 107
agent_timesteps_total: 1209000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023968219757080078
  StateBufferConnector_ms: 0.004252195358276367
  ViewRequirementAgentConnector_ms: 0.14116382598876953
counters:
  num_agent_steps_sampled: 1209000
  num_agent_steps_trained: 1192500
  num_env_steps_sampled: 1209000
  num_env_steps_trained: 1192500
  num_samples_added_to_queue: 1209000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 23753
custom_metrics: {}
date: 2023-08-14_15-41-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.81
episode_reward_min: 1.0
episodes_this_iter: 90
episodes_total: 9446
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8366472125053406
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -26.069448471069336
        total_loss: -6.034193992614746
        var_gnorm: 64.1305923461914
        vf_explained_var: 0.939992368221283
        vf_loss: 48.436981201171875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2385.0
  learner_queue:
    size_count: 2387
    size_mean: 15.06
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.6051168181786646
  num_agent_steps_sampled: 1209000
  num_agent_steps_trained: 1192500
  num_env_steps_sampled: 1209000
  num_env_steps_trained: 1192500
  num_samples_added_to_queue: 1209000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 23753
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 370.774
    learner_load_time_ms: 8.666
    learner_load_wait_time_ms: 2.146
iterations_since_restore: 107
node_ip: 127.0.0.1
num_agent_steps_sampled: 1209000
num_agent_steps_trained: 1192500
num_env_steps_sampled: 1209000
num_env_steps_sampled_this_iter: 11450
num_env_steps_sampled_throughput_per_sec: 1141.1432751424832
num_env_steps_trained: 1192500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1146.126433549219
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 70.78666666666668
  ram_util_percent: 80.78
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0711709309835473
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027793835607468387
  mean_inference_ms: 1.3311602278568953
  mean_raw_obs_processing_ms: 0.30147126270292224
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023968219757080078
    StateBufferConnector_ms: 0.004252195358276367
    ViewRequirementAgentConnector_ms: 0.14116382598876953
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.81
  episode_reward_min: 1.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 6.0, 5.0, 7.0, 6.0, 4.0, 4.0, 7.0, 4.0, 2.0, 6.0, 4.0, 7.0,
      2.0, 3.0, 2.0, 5.0, 9.0, 2.0, 5.0, 6.0, 5.0, 6.0, 4.0, 6.0, 3.0, 6.0, 7.0, 10.0,
      10.0, 4.0, 9.0, 4.0, 5.0, 10.0, 6.0, 5.0, 7.0, 11.0, 6.0, 8.0, 4.0, 6.0, 11.0,
      8.0, 6.0, 5.0, 3.0, 12.0, 7.0, 1.0, 5.0, 2.0, 5.0, 7.0, 6.0, 7.0, 6.0, 4.0,
      4.0, 3.0, 4.0, 7.0, 8.0, 7.0, 9.0, 6.0, 7.0, 4.0, 6.0, 4.0, 7.0, 3.0, 2.0, 5.0,
      7.0, 6.0, 5.0, 6.0, 6.0, 6.0, 4.0, 12.0, 6.0, 3.0, 8.0, 4.0, 9.0, 9.0, 11.0,
      3.0, 6.0, 4.0, 8.0, 6.0, 5.0, 3.0, 7.0, 7.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0711709309835473
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027793835607468387
    mean_inference_ms: 1.3311602278568953
    mean_raw_obs_processing_ms: 0.30147126270292224
time_since_restore: 1088.235767364502
time_this_iter_s: 10.130837678909302
time_total_s: 1088.235767364502
timers:
  sample_time_ms: 0.037
  synch_weights_time_ms: 0.894
  training_iteration_time_ms: 3.441
timestamp: 1691995267
timesteps_total: 1209000
training_iteration: 107
trial_id: default
train step: 108
agent_timesteps_total: 1222400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01939695615034837
  StateBufferConnector_ms: 0.0034703658177302433
  ViewRequirementAgentConnector_ms: 0.11814465889563927
counters:
  num_agent_steps_sampled: 1222400
  num_agent_steps_trained: 1205500
  num_env_steps_sampled: 1222400
  num_env_steps_trained: 1205500
  num_samples_added_to_queue: 1222000
  num_training_step_calls_since_last_synch_worker_weights: 256
  num_weight_broadcasts: 24019
custom_metrics: {}
date: 2023-08-14_15-41-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.980769230769231
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 9550
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7141667008399963
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.276399612426758
        total_loss: 7.252620697021484
        var_gnorm: 64.14424896240234
        vf_explained_var: 0.9723531007766724
        vf_loss: 44.19970703125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2411.0
  learner_queue:
    size_count: 2417
    size_mean: 15.52
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1178550889985697
  num_agent_steps_sampled: 1222400
  num_agent_steps_trained: 1205500
  num_env_steps_sampled: 1222400
  num_env_steps_trained: 1205500
  num_samples_added_to_queue: 1222000
  num_training_step_calls_since_last_synch_worker_weights: 256
  num_weight_broadcasts: 24019
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 183.534
    learner_load_time_ms: 8.592
    learner_load_wait_time_ms: 1.509
iterations_since_restore: 108
node_ip: 127.0.0.1
num_agent_steps_sampled: 1222400
num_agent_steps_trained: 1205500
num_env_steps_sampled: 1222400
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9949202730102
num_env_steps_trained: 1205500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9950719066517
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.20714285714287
  ram_util_percent: 79.8142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07100951674197781
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02774623042495476
  mean_inference_ms: 1.3288686885166503
  mean_raw_obs_processing_ms: 0.30098698145717306
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01939695615034837
    StateBufferConnector_ms: 0.0034703658177302433
    ViewRequirementAgentConnector_ms: 0.11814465889563927
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.980769230769231
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 8.0, 9.0, 3.0, 5.0, 10.0, 6.0, 7.0, 3.0, 3.0, 7.0, 7.0,
      2.0, 9.0, 5.0, 7.0, 9.0, 8.0, 8.0, 8.0, 3.0, 11.0, 9.0, 6.0, 8.0, 6.0, 9.0,
      6.0, 5.0, 11.0, 6.0, 11.0, 2.0, 4.0, 5.0, 6.0, 13.0, 4.0, 11.0, 6.0, 6.0, 7.0,
      3.0, 8.0, 8.0, 9.0, 8.0, 7.0, 11.0, 8.0, 9.0, 12.0, 5.0, 4.0, 4.0, 2.0, 4.0,
      2.0, 5.0, 4.0, 6.0, 9.0, 8.0, 3.0, 8.0, 8.0, 11.0, 8.0, 5.0, 3.0, 7.0, 8.0,
      11.0, 7.0, 6.0, 9.0, 8.0, 8.0, 8.0, 7.0, 6.0, 9.0, 6.0, 9.0, 5.0, 8.0, 9.0,
      11.0, 9.0, 6.0, 4.0, 8.0, 10.0, 8.0, 8.0, 6.0, 6.0, 12.0, 7.0, 8.0, 7.0, 7.0,
      7.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07100951674197781
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02774623042495476
    mean_inference_ms: 1.3288686885166503
    mean_raw_obs_processing_ms: 0.30098698145717306
time_since_restore: 1098.3778111934662
time_this_iter_s: 10.142043828964233
time_total_s: 1098.3778111934662
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691995277
timesteps_total: 1222400
training_iteration: 108
trial_id: default
train step: 109
agent_timesteps_total: 1235200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021385669708251953
  StateBufferConnector_ms: 0.0036766529083251953
  ViewRequirementAgentConnector_ms: 0.12578678131103516
counters:
  num_agent_steps_sampled: 1235200
  num_agent_steps_trained: 1218500
  num_env_steps_sampled: 1235200
  num_env_steps_trained: 1218500
  num_samples_added_to_queue: 1235000
  num_training_step_calls_since_last_synch_worker_weights: 297
  num_weight_broadcasts: 24272
custom_metrics: {}
date: 2023-08-14_15-41-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.58
episode_reward_min: 2.0
episodes_this_iter: 100
episodes_total: 9650
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7784842848777771
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -30.5349178314209
        total_loss: 16.59157371520996
        var_gnorm: 64.1545181274414
        vf_explained_var: 0.8960548043251038
        vf_loss: 102.03782653808594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2437.0
  learner_queue:
    size_count: 2443
    size_mean: 15.2
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5231546211727816
  num_agent_steps_sampled: 1235200
  num_agent_steps_trained: 1218500
  num_env_steps_sampled: 1235200
  num_env_steps_trained: 1218500
  num_samples_added_to_queue: 1235000
  num_training_step_calls_since_last_synch_worker_weights: 297
  num_weight_broadcasts: 24272
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 238.679
    learner_load_time_ms: 8.576
    learner_load_wait_time_ms: 2.21
iterations_since_restore: 109
node_ip: 127.0.0.1
num_agent_steps_sampled: 1235200
num_agent_steps_trained: 1218500
num_env_steps_sampled: 1235200
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9965515229626
num_env_steps_trained: 1218500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9964976405088
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.65714285714285
  ram_util_percent: 78.16428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0709269851135618
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02771588631929725
  mean_inference_ms: 1.3272823435148444
  mean_raw_obs_processing_ms: 0.30068676507530684
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021385669708251953
    StateBufferConnector_ms: 0.0036766529083251953
    ViewRequirementAgentConnector_ms: 0.12578678131103516
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.58
  episode_reward_min: 2.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 9.0, 6.0, 9.0, 8.0, 13.0, 11.0, 10.0, 7.0, 9.0, 7.0, 5.0,
      5.0, 7.0, 7.0, 5.0, 12.0, 7.0, 10.0, 9.0, 11.0, 11.0, 11.0, 5.0, 5.0, 6.0, 10.0,
      12.0, 7.0, 10.0, 8.0, 8.0, 6.0, 10.0, 11.0, 8.0, 9.0, 2.0, 6.0, 8.0, 8.0, 8.0,
      14.0, 6.0, 6.0, 10.0, 9.0, 7.0, 6.0, 9.0, 9.0, 6.0, 4.0, 12.0, 5.0, 3.0, 6.0,
      5.0, 3.0, 6.0, 6.0, 11.0, 4.0, 2.0, 5.0, 6.0, 4.0, 6.0, 7.0, 9.0, 5.0, 8.0,
      13.0, 6.0, 8.0, 10.0, 4.0, 3.0, 5.0, 9.0, 9.0, 8.0, 6.0, 7.0, 6.0, 10.0, 6.0,
      12.0, 15.0, 5.0, 9.0, 8.0, 9.0, 8.0, 7.0, 7.0, 8.0, 4.0, 4.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0709269851135618
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02771588631929725
    mean_inference_ms: 1.3272823435148444
    mean_raw_obs_processing_ms: 0.30068676507530684
time_since_restore: 1108.5869941711426
time_this_iter_s: 10.209182977676392
time_total_s: 1108.5869941711426
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995287
timesteps_total: 1235200
training_iteration: 109
trial_id: default
train step: 110
agent_timesteps_total: 1247000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02374744415283203
  StateBufferConnector_ms: 0.00420379638671875
  ViewRequirementAgentConnector_ms: 0.13660621643066406
counters:
  num_agent_steps_sampled: 1247000
  num_agent_steps_trained: 1230500
  num_env_steps_sampled: 1247000
  num_env_steps_trained: 1230500
  num_samples_added_to_queue: 1247000
  num_training_step_calls_since_last_synch_worker_weights: 735
  num_weight_broadcasts: 24503
custom_metrics: {}
date: 2023-08-14_15-41-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 7.3
episode_reward_min: 1.0
episodes_this_iter: 93
episodes_total: 9743
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8695309162139893
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.042123794555664
        total_loss: -1.4035515785217285
        var_gnorm: 64.16226959228516
        vf_explained_var: 0.9543722867965698
        vf_loss: 37.97245407104492
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2461.0
  learner_queue:
    size_count: 2466
    size_mean: 15.0
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6492422502470643
  num_agent_steps_sampled: 1247000
  num_agent_steps_trained: 1230500
  num_env_steps_sampled: 1247000
  num_env_steps_trained: 1230500
  num_samples_added_to_queue: 1247000
  num_training_step_calls_since_last_synch_worker_weights: 735
  num_weight_broadcasts: 24503
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 212.296
    learner_load_time_ms: 8.561
    learner_load_wait_time_ms: 1.698
iterations_since_restore: 110
node_ip: 127.0.0.1
num_agent_steps_sampled: 1247000
num_agent_steps_trained: 1230500
num_env_steps_sampled: 1247000
num_env_steps_sampled_this_iter: 11800
num_env_steps_sampled_throughput_per_sec: 1179.9967084022787
num_env_steps_trained: 1230500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.996652612487
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 62.84666666666667
  ram_util_percent: 82.36
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07093524008515327
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027715052758669475
  mean_inference_ms: 1.3266445710582797
  mean_raw_obs_processing_ms: 0.30056337197790745
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02374744415283203
    StateBufferConnector_ms: 0.00420379638671875
    ViewRequirementAgentConnector_ms: 0.13660621643066406
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 7.3
  episode_reward_min: 1.0
  episodes_this_iter: 93
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 7.0, 8.0, 4.0, 4.0, 10.0, 8.0, 4.0, 8.0, 6.0, 13.0,
      7.0, 8.0, 8.0, 12.0, 10.0, 7.0, 5.0, 7.0, 9.0, 5.0, 10.0, 7.0, 13.0, 8.0, 7.0,
      5.0, 6.0, 12.0, 4.0, 4.0, 9.0, 7.0, 4.0, 6.0, 6.0, 3.0, 1.0, 5.0, 7.0, 9.0,
      9.0, 10.0, 3.0, 8.0, 5.0, 18.0, 4.0, 9.0, 5.0, 11.0, 5.0, 12.0, 9.0, 8.0, 10.0,
      9.0, 9.0, 8.0, 8.0, 11.0, 8.0, 8.0, 9.0, 3.0, 4.0, 9.0, 7.0, 2.0, 6.0, 5.0,
      9.0, 10.0, 5.0, 6.0, 4.0, 3.0, 7.0, 12.0, 4.0, 1.0, 7.0, 9.0, 7.0, 5.0, 9.0,
      8.0, 6.0, 4.0, 7.0, 10.0, 10.0, 8.0, 9.0, 14.0, 8.0, 6.0, 4.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07093524008515327
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027715052758669475
    mean_inference_ms: 1.3266445710582797
    mean_raw_obs_processing_ms: 0.30056337197790745
time_since_restore: 1118.7134110927582
time_this_iter_s: 10.1264169216156
time_total_s: 1118.7134110927582
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691995297
timesteps_total: 1247000
training_iteration: 110
trial_id: default
train step: 111
agent_timesteps_total: 1258300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023200511932373047
  StateBufferConnector_ms: 0.004118204116821289
  ViewRequirementAgentConnector_ms: 0.13429760932922363
counters:
  num_agent_steps_sampled: 1258300
  num_agent_steps_trained: 1241500
  num_env_steps_sampled: 1258300
  num_env_steps_trained: 1241500
  num_samples_added_to_queue: 1258000
  num_training_step_calls_since_last_synch_worker_weights: 906
  num_weight_broadcasts: 24726
custom_metrics: {}
date: 2023-08-14_15-41-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.01
episode_reward_min: 3.0
episodes_this_iter: 88
episodes_total: 9831
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7463729381561279
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -31.589885711669922
        total_loss: -7.290162563323975
        var_gnorm: 64.17266845703125
        vf_explained_var: 0.9342584013938904
        vf_loss: 56.063175201416016
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2483.0
  learner_queue:
    size_count: 2487
    size_mean: 15.1
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4594519519326425
  num_agent_steps_sampled: 1258300
  num_agent_steps_trained: 1241500
  num_env_steps_sampled: 1258300
  num_env_steps_trained: 1241500
  num_samples_added_to_queue: 1258000
  num_training_step_calls_since_last_synch_worker_weights: 906
  num_weight_broadcasts: 24726
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 276.66
    learner_load_time_ms: 1.998
    learner_load_wait_time_ms: 1.794
iterations_since_restore: 111
node_ip: 127.0.0.1
num_agent_steps_sampled: 1258300
num_agent_steps_trained: 1241500
num_env_steps_sampled: 1258300
num_env_steps_sampled_this_iter: 11300
num_env_steps_sampled_throughput_per_sec: 1129.998087170978
num_env_steps_trained: 1241500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9981379540493
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 58.58571428571429
  ram_util_percent: 80.65714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07095211388807784
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027722662319372645
  mean_inference_ms: 1.3264883648023942
  mean_raw_obs_processing_ms: 0.30055326296921836
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023200511932373047
    StateBufferConnector_ms: 0.004118204116821289
    ViewRequirementAgentConnector_ms: 0.13429760932922363
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.01
  episode_reward_min: 3.0
  episodes_this_iter: 88
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 4.0, 7.0, 10.0, 10.0, 8.0, 9.0, 14.0, 8.0, 6.0, 4.0, 8.0,
      6.0, 10.0, 8.0, 9.0, 8.0, 8.0, 10.0, 6.0, 10.0, 5.0, 4.0, 12.0, 9.0, 9.0, 13.0,
      8.0, 12.0, 10.0, 10.0, 5.0, 3.0, 7.0, 7.0, 6.0, 9.0, 10.0, 13.0, 10.0, 9.0,
      7.0, 9.0, 9.0, 10.0, 5.0, 10.0, 14.0, 7.0, 7.0, 7.0, 7.0, 7.0, 12.0, 6.0, 7.0,
      16.0, 8.0, 11.0, 3.0, 8.0, 5.0, 6.0, 11.0, 7.0, 7.0, 4.0, 3.0, 9.0, 7.0, 10.0,
      8.0, 5.0, 15.0, 7.0, 7.0, 6.0, 8.0, 6.0, 11.0, 7.0, 6.0, 13.0, 3.0, 3.0, 7.0,
      5.0, 9.0, 4.0, 6.0, 6.0, 12.0, 15.0, 8.0, 3.0, 9.0, 10.0, 8.0, 8.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07095211388807784
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027722662319372645
    mean_inference_ms: 1.3264883648023942
    mean_raw_obs_processing_ms: 0.30055326296921836
time_since_restore: 1128.829990386963
time_this_iter_s: 10.116579294204712
time_total_s: 1128.829990386963
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691995307
timesteps_total: 1258300
training_iteration: 111
trial_id: default
train step: 112
agent_timesteps_total: 1270700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02065134048461914
  StateBufferConnector_ms: 0.0036857128143310547
  ViewRequirementAgentConnector_ms: 0.12543439865112305
counters:
  num_agent_steps_sampled: 1270700
  num_agent_steps_trained: 1254000
  num_env_steps_sampled: 1270700
  num_env_steps_trained: 1254000
  num_samples_added_to_queue: 1270500
  num_training_step_calls_since_last_synch_worker_weights: 653
  num_weight_broadcasts: 24971
custom_metrics: {}
date: 2023-08-14_15-41-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.95
episode_reward_min: 2.0
episodes_this_iter: 97
episodes_total: 9928
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8179608583450317
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 49.908287048339844
        total_loss: 87.23462677001953
        var_gnorm: 64.18067169189453
        vf_explained_var: 0.8964062929153442
        vf_loss: 82.83228302001953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2508.0
  learner_queue:
    size_count: 2513
    size_mean: 15.3
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2041594578792294
  num_agent_steps_sampled: 1270700
  num_agent_steps_trained: 1254000
  num_env_steps_sampled: 1270700
  num_env_steps_trained: 1254000
  num_samples_added_to_queue: 1270500
  num_training_step_calls_since_last_synch_worker_weights: 653
  num_weight_broadcasts: 24971
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 221.999
    learner_load_time_ms: 1.93
    learner_load_wait_time_ms: 1.649
iterations_since_restore: 112
node_ip: 127.0.0.1
num_agent_steps_sampled: 1270700
num_agent_steps_trained: 1254000
num_env_steps_sampled: 1270700
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.9949150293974
num_env_steps_trained: 1254000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.99487402157
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 56.92142857142857
  ram_util_percent: 80.14285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07086749230710628
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027712022007902782
  mean_inference_ms: 1.325456855132941
  mean_raw_obs_processing_ms: 0.30034419721965167
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02065134048461914
    StateBufferConnector_ms: 0.0036857128143310547
    ViewRequirementAgentConnector_ms: 0.12543439865112305
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.95
  episode_reward_min: 2.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 7.0, 9.0, 5.0, 7.0, 2.0, 9.0, 10.0, 5.0, 8.0, 4.0,
      12.0, 12.0, 5.0, 5.0, 11.0, 6.0, 8.0, 11.0, 10.0, 7.0, 7.0, 6.0, 10.0, 7.0,
      8.0, 8.0, 9.0, 11.0, 11.0, 8.0, 9.0, 4.0, 8.0, 13.0, 5.0, 7.0, 5.0, 10.0, 7.0,
      5.0, 9.0, 4.0, 4.0, 8.0, 9.0, 13.0, 11.0, 8.0, 7.0, 6.0, 8.0, 12.0, 9.0, 4.0,
      5.0, 8.0, 9.0, 9.0, 9.0, 4.0, 7.0, 7.0, 10.0, 7.0, 10.0, 9.0, 10.0, 7.0, 10.0,
      8.0, 10.0, 12.0, 5.0, 10.0, 6.0, 13.0, 7.0, 6.0, 10.0, 8.0, 6.0, 11.0, 7.0,
      12.0, 5.0, 7.0, 7.0, 6.0, 8.0, 8.0, 7.0, 8.0, 11.0, 10.0, 8.0, 8.0, 4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07086749230710628
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027712022007902782
    mean_inference_ms: 1.325456855132941
    mean_raw_obs_processing_ms: 0.30034419721965167
time_since_restore: 1138.9623403549194
time_this_iter_s: 10.132349967956543
time_total_s: 1138.9623403549194
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995317
timesteps_total: 1270700
training_iteration: 112
trial_id: default
train step: 113
agent_timesteps_total: 1282700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021517038345336914
  StateBufferConnector_ms: 0.003809213638305664
  ViewRequirementAgentConnector_ms: 0.13000822067260742
counters:
  num_agent_steps_sampled: 1282700
  num_agent_steps_trained: 1266000
  num_env_steps_sampled: 1282700
  num_env_steps_trained: 1266000
  num_samples_added_to_queue: 1282500
  num_training_step_calls_since_last_synch_worker_weights: 975
  num_weight_broadcasts: 25204
custom_metrics: {}
date: 2023-08-14_15-42-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.16
episode_reward_min: 0.0
episodes_this_iter: 94
episodes_total: 10022
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4062040150165558
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -15.94188404083252
        total_loss: 44.4653205871582
        var_gnorm: 64.19195556640625
        vf_explained_var: 0.8618730902671814
        vf_loss: 124.87644958496094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2532.0
  learner_queue:
    size_count: 2537
    size_mean: 15.28
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3120975573485378
  num_agent_steps_sampled: 1282700
  num_agent_steps_trained: 1266000
  num_env_steps_sampled: 1282700
  num_env_steps_trained: 1266000
  num_samples_added_to_queue: 1282500
  num_training_step_calls_since_last_synch_worker_weights: 975
  num_weight_broadcasts: 25204
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 239.443
    learner_load_time_ms: 1.458
    learner_load_wait_time_ms: 1.544
iterations_since_restore: 113
node_ip: 127.0.0.1
num_agent_steps_sampled: 1282700
num_agent_steps_trained: 1266000
num_env_steps_sampled: 1282700
num_env_steps_sampled_this_iter: 12000
num_env_steps_sampled_throughput_per_sec: 1199.994478251116
num_env_steps_trained: 1266000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.994478251116
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.279999999999994
  ram_util_percent: 79.63333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07084480034585722
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02770250515413514
  mean_inference_ms: 1.3246677807661218
  mean_raw_obs_processing_ms: 0.3001631024059909
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021517038345336914
    StateBufferConnector_ms: 0.003809213638305664
    ViewRequirementAgentConnector_ms: 0.13000822067260742
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.16
  episode_reward_min: 0.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 10.0, 8.0, 8.0, 4.0, 7.0, 10.0, 11.0, 7.0, 7.0, 9.0, 8.0,
      4.0, 8.0, 6.0, 7.0, 8.0, 6.0, 6.0, 4.0, 12.0, 6.0, 8.0, 9.0, 9.0, 5.0, 10.0,
      6.0, 7.0, 3.0, 6.0, 8.0, 6.0, 6.0, 6.0, 3.0, 5.0, 6.0, 8.0, 5.0, 3.0, 5.0, 5.0,
      2.0, 3.0, 4.0, 0.0, 4.0, 6.0, 9.0, 4.0, 7.0, 5.0, 5.0, 4.0, 9.0, 6.0, 12.0,
      9.0, 9.0, 3.0, 6.0, 9.0, 4.0, 5.0, 9.0, 8.0, 9.0, 5.0, 6.0, 7.0, 6.0, 4.0, 7.0,
      10.0, 4.0, 6.0, 7.0, 7.0, 6.0, 5.0, 6.0, 6.0, 4.0, 4.0, 3.0, 8.0, 4.0, 4.0,
      3.0, 5.0, 5.0, 3.0, 2.0, 11.0, 3.0, 7.0, 3.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07084480034585722
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02770250515413514
    mean_inference_ms: 1.3246677807661218
    mean_raw_obs_processing_ms: 0.3001631024059909
time_since_restore: 1149.0729303359985
time_this_iter_s: 10.110589981079102
time_total_s: 1149.0729303359985
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1691995327
timesteps_total: 1282700
training_iteration: 113
trial_id: default
train step: 114
agent_timesteps_total: 1295750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019602492304131535
  StateBufferConnector_ms: 0.0034778425008943764
  ViewRequirementAgentConnector_ms: 0.12033741072853013
counters:
  num_agent_steps_sampled: 1295750
  num_agent_steps_trained: 1279000
  num_env_steps_sampled: 1295750
  num_env_steps_trained: 1279000
  num_samples_added_to_queue: 1295500
  num_training_step_calls_since_last_synch_worker_weights: 276
  num_weight_broadcasts: 25462
custom_metrics: {}
date: 2023-08-14_15-42-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 0.8316831683168316
episode_reward_min: 0.0
episodes_this_iter: 101
episodes_total: 10123
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.11396100372076035
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.5303516387939453
        total_loss: 10.366704940795898
        var_gnorm: 64.2046890258789
        vf_explained_var: 0.9054765701293945
        vf_loss: 18.81231689453125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2558.0
  learner_queue:
    size_count: 2565
    size_mean: 15.28
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4427751037497147
  num_agent_steps_sampled: 1295750
  num_agent_steps_trained: 1279000
  num_env_steps_sampled: 1295750
  num_env_steps_trained: 1279000
  num_samples_added_to_queue: 1295500
  num_training_step_calls_since_last_synch_worker_weights: 276
  num_weight_broadcasts: 25462
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 151.723
    learner_load_time_ms: 1.413
    learner_load_wait_time_ms: 1.509
iterations_since_restore: 114
node_ip: 127.0.0.1
num_agent_steps_sampled: 1295750
num_agent_steps_trained: 1279000
num_env_steps_sampled: 1295750
num_env_steps_sampled_this_iter: 13050
num_env_steps_sampled_throughput_per_sec: 1304.997137552818
num_env_steps_trained: 1279000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9971485200485
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.449999999999996
  ram_util_percent: 80.0
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07072945369983999
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02765787294024177
  mean_inference_ms: 1.3228981660728751
  mean_raw_obs_processing_ms: 0.29979075344965256
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019602492304131535
    StateBufferConnector_ms: 0.0034778425008943764
    ViewRequirementAgentConnector_ms: 0.12033741072853013
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 0.8316831683168316
  episode_reward_min: 0.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 0.0, 3.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 0.0, 0.0,
      1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0,
      0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0,
      0.0, 1.0, 1.0, 1.0, 0.0, 2.0, 4.0, 4.0, 5.0, 2.0, 4.0, 2.0, 3.0, 3.0, 1.0, 0.0,
      2.0, 2.0, 2.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,
      0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07072945369983999
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02765787294024177
    mean_inference_ms: 1.3228981660728751
    mean_raw_obs_processing_ms: 0.29979075344965256
time_since_restore: 1159.243197441101
time_this_iter_s: 10.170267105102539
time_total_s: 1159.243197441101
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995338
timesteps_total: 1295750
training_iteration: 114
trial_id: default
train step: 115
agent_timesteps_total: 1308950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020134219756493203
  StateBufferConnector_ms: 0.003544183877798227
  ViewRequirementAgentConnector_ms: 0.12015562791090745
counters:
  num_agent_steps_sampled: 1308950
  num_agent_steps_trained: 1292000
  num_env_steps_sampled: 1308950
  num_env_steps_trained: 1292000
  num_samples_added_to_queue: 1308500
  num_training_step_calls_since_last_synch_worker_weights: 307
  num_weight_broadcasts: 25720
custom_metrics: {}
date: 2023-08-14_15-42-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.5576923076923075
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 10227
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1956052780151367
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 5.4835286140441895
        total_loss: 0.21021127700805664
        var_gnorm: 64.21746063232422
        vf_explained_var: 0.9656953811645508
        vf_loss: 1.4094175100326538
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2584.0
  learner_queue:
    size_count: 2590
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.632666530556684
  num_agent_steps_sampled: 1308950
  num_agent_steps_trained: 1292000
  num_env_steps_sampled: 1308950
  num_env_steps_trained: 1292000
  num_samples_added_to_queue: 1308500
  num_training_step_calls_since_last_synch_worker_weights: 307
  num_weight_broadcasts: 25720
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 195.038
    learner_load_time_ms: 1.405
    learner_load_wait_time_ms: 1.54
iterations_since_restore: 115
node_ip: 127.0.0.1
num_agent_steps_sampled: 1308950
num_agent_steps_trained: 1292000
num_env_steps_sampled: 1308950
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9984579104319
num_env_steps_trained: 1292000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9984812754253
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.128571428571426
  ram_util_percent: 78.95714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07062371859633054
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0276115048553236
  mean_inference_ms: 1.3209979247218233
  mean_raw_obs_processing_ms: 0.29940121236494144
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020134219756493203
    StateBufferConnector_ms: 0.003544183877798227
    ViewRequirementAgentConnector_ms: 0.12015562791090745
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.5576923076923075
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 2.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0, 1.0, 1.0, 1.0, 1.0,
      0.0, 3.0, 5.0, 6.0, 0.0, 2.0, 6.0, 7.0, 2.0, 4.0, 5.0, 3.0, 1.0, 2.0, 8.0, 4.0,
      4.0, 2.0, 5.0, 2.0, 3.0, 4.0, 6.0, 4.0, 7.0, 6.0, 6.0, 5.0, 3.0, 4.0, 3.0, 4.0,
      5.0, 4.0, 5.0, 8.0, 6.0, 3.0, 3.0, 0.0, 4.0, 1.0, 0.0, 6.0, 1.0, 2.0, 4.0, 0.0,
      2.0, 1.0, 2.0, 3.0, 4.0, 2.0, 5.0, 4.0, 0.0, 4.0, 5.0, 4.0, 1.0, 2.0, 4.0, 5.0,
      3.0, 2.0, 3.0, 9.0, 4.0, 5.0, 4.0, 4.0, 6.0, 4.0, 8.0, 3.0, 5.0, 5.0, 4.0, 6.0,
      3.0, 10.0, 4.0, 4.0, 3.0, 4.0, 6.0, 6.0, 4.0, 4.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07062371859633054
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0276115048553236
    mean_inference_ms: 1.3209979247218233
    mean_raw_obs_processing_ms: 0.29940121236494144
time_since_restore: 1169.3812673091888
time_this_iter_s: 10.138069868087769
time_total_s: 1169.3812673091888
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691995348
timesteps_total: 1308950
training_iteration: 115
trial_id: default
train step: 116
agent_timesteps_total: 1321550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019723176956176758
  StateBufferConnector_ms: 0.0036025047302246094
  ViewRequirementAgentConnector_ms: 0.12187433242797852
counters:
  num_agent_steps_sampled: 1321550
  num_agent_steps_trained: 1305000
  num_env_steps_sampled: 1321550
  num_env_steps_trained: 1305000
  num_samples_added_to_queue: 1321500
  num_training_step_calls_since_last_synch_worker_weights: 4
  num_weight_broadcasts: 25969
custom_metrics: {}
date: 2023-08-14_15-42-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.46
episode_reward_min: 0.0
episodes_this_iter: 98
episodes_total: 10325
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5092030167579651
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -13.108524322509766
        total_loss: 0.24983572959899902
        var_gnorm: 64.22013092041016
        vf_explained_var: 0.7835984826087952
        vf_loss: 31.80875015258789
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2610.0
  learner_queue:
    size_count: 2616
    size_mean: 15.12
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4918444959177213
  num_agent_steps_sampled: 1321550
  num_agent_steps_trained: 1305000
  num_env_steps_sampled: 1321550
  num_env_steps_trained: 1305000
  num_samples_added_to_queue: 1321500
  num_training_step_calls_since_last_synch_worker_weights: 4
  num_weight_broadcasts: 25969
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 225.313
    learner_load_time_ms: 1.786
    learner_load_wait_time_ms: 1.787
iterations_since_restore: 116
node_ip: 127.0.0.1
num_agent_steps_sampled: 1321550
num_agent_steps_trained: 1305000
num_env_steps_sampled: 1321550
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9949531757322
num_env_steps_trained: 1305000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.994792959089
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 56.83333333333333
  ram_util_percent: 78.37333333333335
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07055411761131314
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027576354689197946
  mean_inference_ms: 1.3198284618197462
  mean_raw_obs_processing_ms: 0.29910539670356046
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019723176956176758
    StateBufferConnector_ms: 0.0036025047302246094
    ViewRequirementAgentConnector_ms: 0.12187433242797852
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.46
  episode_reward_min: 0.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 8.0, 2.0, 4.0, 6.0, 8.0, 3.0, 1.0, 1.0, 4.0, 3.0, 5.0, 6.0,
      2.0, 4.0, 4.0, 2.0, 4.0, 5.0, 6.0, 2.0, 3.0, 2.0, 2.0, 4.0, 1.0, 3.0, 4.0, 2.0,
      0.0, 3.0, 4.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 0.0,
      2.0, 0.0, 3.0, 3.0, 1.0, 1.0, 2.0, 5.0, 3.0, 5.0, 3.0, 1.0, 4.0, 4.0, 4.0, 3.0,
      3.0, 4.0, 0.0, 3.0, 1.0, 1.0, 6.0, 3.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 1.0, 1.0,
      1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 3.0, 4.0, 4.0, 1.0, 1.0, 2.0,
      1.0, 7.0, 2.0, 2.0, 1.0, 0.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07055411761131314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027576354689197946
    mean_inference_ms: 1.3198284618197462
    mean_raw_obs_processing_ms: 0.29910539670356046
time_since_restore: 1179.5441663265228
time_this_iter_s: 10.162899017333984
time_total_s: 1179.5441663265228
timers:
  sample_time_ms: 0.103
  synch_weights_time_ms: 0.738
  training_iteration_time_ms: 2.865
timestamp: 1691995358
timesteps_total: 1321550
training_iteration: 116
trial_id: default
train step: 117
agent_timesteps_total: 1331750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02491021156311035
  StateBufferConnector_ms: 0.004574298858642578
  ViewRequirementAgentConnector_ms: 0.1455368995666504
counters:
  num_agent_steps_sampled: 1331750
  num_agent_steps_trained: 1315000
  num_env_steps_sampled: 1331750
  num_env_steps_trained: 1315000
  num_samples_added_to_queue: 1331500
  num_training_step_calls_since_last_synch_worker_weights: 72
  num_weight_broadcasts: 26168
custom_metrics: {}
date: 2023-08-14_15-42-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.13
episode_reward_min: 0.0
episodes_this_iter: 80
episodes_total: 10405
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0862057209014893
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.9278196096420288
        total_loss: 5.057223320007324
        var_gnorm: 64.22569274902344
        vf_explained_var: 0.841895341873169
        vf_loss: 24.832141876220703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2630.0
  learner_queue:
    size_count: 2638
    size_mean: 14.6
    size_quantiles: [9.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.969771560359221
  num_agent_steps_sampled: 1331750
  num_agent_steps_trained: 1315000
  num_env_steps_sampled: 1331750
  num_env_steps_trained: 1315000
  num_samples_added_to_queue: 1331500
  num_training_step_calls_since_last_synch_worker_weights: 72
  num_weight_broadcasts: 26168
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 240.543
    learner_load_time_ms: 1.812
    learner_load_wait_time_ms: 2.473
iterations_since_restore: 117
node_ip: 127.0.0.1
num_agent_steps_sampled: 1331750
num_agent_steps_trained: 1315000
num_env_steps_sampled: 1331750
num_env_steps_sampled_this_iter: 10200
num_env_steps_sampled_throughput_per_sec: 1019.9975438177127
num_env_steps_trained: 1315000
num_env_steps_trained_this_iter: 10000
num_env_steps_trained_throughput_per_sec: 999.9975919781497
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10000
perf:
  cpu_util_percent: 67.37857142857143
  ram_util_percent: 81.20714285714284
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07068072107917868
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027607125094494873
  mean_inference_ms: 1.320656467414116
  mean_raw_obs_processing_ms: 0.29926668930203626
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02491021156311035
    StateBufferConnector_ms: 0.004574298858642578
    ViewRequirementAgentConnector_ms: 0.1455368995666504
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.13
  episode_reward_min: 0.0
  episodes_this_iter: 80
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 1.0, 2.0, 3.0, 1.0, 0.0, 0.0, 3.0, 4.0, 4.0, 1.0, 1.0, 2.0,
      1.0, 7.0, 2.0, 2.0, 1.0, 0.0, 2.0, 2.0, 2.0, 4.0, 0.0, 1.0, 1.0, 2.0, 2.0, 2.0,
      5.0, 2.0, 2.0, 4.0, 0.0, 0.0, 0.0, 2.0, 6.0, 0.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0,
      4.0, 2.0, 0.0, 1.0, 1.0, 4.0, 0.0, 4.0, 4.0, 2.0, 6.0, 1.0, 5.0, 6.0, 3.0, 1.0,
      0.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0,
      4.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 3.0, 5.0, 4.0, 1.0, 4.0, 4.0, 3.0, 0.0, 3.0,
      0.0, 4.0, 3.0, 5.0, 4.0, 6.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07068072107917868
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027607125094494873
    mean_inference_ms: 1.320656467414116
    mean_raw_obs_processing_ms: 0.29926668930203626
time_since_restore: 1189.8452982902527
time_this_iter_s: 10.301131963729858
time_total_s: 1189.8452982902527
timers:
  sample_time_ms: 0.013
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1691995368
timesteps_total: 1331750
training_iteration: 117
trial_id: default
train step: 118
agent_timesteps_total: 1341350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0261838436126709
  StateBufferConnector_ms: 0.00473785400390625
  ViewRequirementAgentConnector_ms: 0.15482807159423828
counters:
  num_agent_steps_sampled: 1341350
  num_agent_steps_trained: 1324500
  num_env_steps_sampled: 1341350
  num_env_steps_trained: 1324500
  num_samples_added_to_queue: 1341000
  num_training_step_calls_since_last_synch_worker_weights: 1537
  num_weight_broadcasts: 26355
custom_metrics: {}
date: 2023-08-14_15-42-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 3.32
episode_reward_min: 0.0
episodes_this_iter: 75
episodes_total: 10480
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 30.300000000000182
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3316247463226318
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 7.584530353546143
        total_loss: 4.891494274139404
        var_gnorm: 64.228271484375
        vf_explained_var: 0.9714915156364441
        vf_loss: 7.930175304412842
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2649.0
  learner_queue:
    size_count: 2654
    size_mean: 14.56
    size_quantiles: [9.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9303885619221848
  num_agent_steps_sampled: 1341350
  num_agent_steps_trained: 1324500
  num_env_steps_sampled: 1341350
  num_env_steps_trained: 1324500
  num_samples_added_to_queue: 1341000
  num_training_step_calls_since_last_synch_worker_weights: 1537
  num_weight_broadcasts: 26355
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 282.967
    learner_load_time_ms: 2.104
    learner_load_wait_time_ms: 1.834
iterations_since_restore: 118
node_ip: 127.0.0.1
num_agent_steps_sampled: 1341350
num_agent_steps_trained: 1324500
num_env_steps_sampled: 1341350
num_env_steps_sampled_this_iter: 9600
num_env_steps_sampled_throughput_per_sec: 959.9970245453551
num_env_steps_trained: 1324500
num_env_steps_trained_this_iter: 9500
num_env_steps_trained_throughput_per_sec: 949.9970555396743
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 9500
perf:
  cpu_util_percent: 69.32857142857144
  ram_util_percent: 80.87857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07077736745917111
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027663760303795967
  mean_inference_ms: 1.3221614398637564
  mean_raw_obs_processing_ms: 0.2995467522225896
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0261838436126709
    StateBufferConnector_ms: 0.00473785400390625
    ViewRequirementAgentConnector_ms: 0.15482807159423828
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 3.32
  episode_reward_min: 0.0
  episodes_this_iter: 75
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 4.0, 1.0, 3.0, 1.0, 0.0, 2.0, 0.0, 3.0, 5.0, 4.0, 1.0,
      4.0, 4.0, 3.0, 0.0, 3.0, 0.0, 4.0, 3.0, 5.0, 4.0, 6.0, 3.0, 7.0, 5.0, 3.0, 7.0,
      2.0, 2.0, 7.0, 5.0, 2.0, 4.0, 2.0, 5.0, 1.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 4.0,
      5.0, 1.0, 4.0, 3.0, 2.0, 7.0, 0.0, 2.0, 0.0, 5.0, 2.0, 3.0, 4.0, 2.0, 2.0, 6.0,
      5.0, 2.0, 4.0, 1.0, 2.0, 4.0, 3.0, 6.0, 2.0, 0.0, 6.0, 3.0, 3.0, 3.0, 3.0, 6.0,
      3.0, 6.0, 3.0, 4.0, 6.0, 4.0, 6.0, 4.0, 4.0, 6.0, 6.0, 3.0, 6.0, 7.0, 1.0, 5.0,
      2.0, 2.0, 2.0, 4.0, 0.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07077736745917111
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027663760303795967
    mean_inference_ms: 1.3221614398637564
    mean_raw_obs_processing_ms: 0.2995467522225896
time_since_restore: 1200.0239663124084
time_this_iter_s: 10.178668022155762
time_total_s: 1200.0239663124084
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995378
timesteps_total: 1341350
training_iteration: 118
trial_id: default
train step: 119
agent_timesteps_total: 1352750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023643970489501953
  StateBufferConnector_ms: 0.004218578338623047
  ViewRequirementAgentConnector_ms: 0.1411581039428711
counters:
  num_agent_steps_sampled: 1352750
  num_agent_steps_trained: 1336000
  num_env_steps_sampled: 1352750
  num_env_steps_trained: 1336000
  num_samples_added_to_queue: 1352500
  num_training_step_calls_since_last_synch_worker_weights: 399
  num_weight_broadcasts: 26578
custom_metrics: {}
date: 2023-08-14_15-43-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.93
episode_reward_min: 0.0
episodes_this_iter: 89
episodes_total: 10569
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 30.90000000000009
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.2934283018112183
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.135627746582031
        total_loss: -10.108497619628906
        var_gnorm: 64.23509216308594
        vf_explained_var: 0.9715225100517273
        vf_loss: 10.988544464111328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2672.0
  learner_queue:
    size_count: 2678
    size_mean: 14.56
    size_quantiles: [9.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9303885619221846
  num_agent_steps_sampled: 1352750
  num_agent_steps_trained: 1336000
  num_env_steps_sampled: 1352750
  num_env_steps_trained: 1336000
  num_samples_added_to_queue: 1352500
  num_training_step_calls_since_last_synch_worker_weights: 399
  num_weight_broadcasts: 26578
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 251.305
    learner_load_time_ms: 2.229
    learner_load_wait_time_ms: 1.634
iterations_since_restore: 119
node_ip: 127.0.0.1
num_agent_steps_sampled: 1352750
num_agent_steps_trained: 1336000
num_env_steps_sampled: 1352750
num_env_steps_sampled_this_iter: 11400
num_env_steps_sampled_throughput_per_sec: 1139.9948630564422
num_env_steps_trained: 1336000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9948179955338
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 61.49333333333334
  ram_util_percent: 79.88000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07075487734077235
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027692397764805615
  mean_inference_ms: 1.3226844569996012
  mean_raw_obs_processing_ms: 0.29965575432708397
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023643970489501953
    StateBufferConnector_ms: 0.004218578338623047
    ViewRequirementAgentConnector_ms: 0.1411581039428711
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.93
  episode_reward_min: 0.0
  episodes_this_iter: 89
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 7.0, 1.0, 5.0, 2.0, 2.0, 2.0, 4.0, 0.0, 4.0, 3.0, 1.0, 3.0,
      3.0, 1.0, 1.0, 5.0, 4.0, 5.0, 5.0, 5.0, 6.0, 2.0, 4.0, 4.0, 7.0, 5.0, 6.0, 5.0,
      3.0, 1.0, 0.0, 4.0, 5.0, 2.0, 2.0, 3.0, 4.0, 6.0, 4.0, 1.0, 6.0, 2.0, 3.0, 3.0,
      4.0, 6.0, 8.0, 5.0, 10.0, 6.0, 4.0, 7.0, 7.0, 2.0, 6.0, 2.0, 2.0, 7.0, 3.0,
      3.0, 1.0, 3.0, 2.0, 6.0, 6.0, 2.0, 6.0, 4.0, 5.0, 5.0, 5.0, 1.0, 2.0, 5.0, 3.0,
      3.0, 1.0, 1.0, 3.0, 4.0, 4.0, 1.0, 8.0, 2.0, 3.0, 4.0, 5.0, 7.0, 4.0, 6.0, 4.0,
      4.0, 6.0, 3.0, 8.0, 3.0, 1.0, 5.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07075487734077235
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027692397764805615
    mean_inference_ms: 1.3226844569996012
    mean_raw_obs_processing_ms: 0.29965575432708397
time_since_restore: 1210.1796543598175
time_this_iter_s: 10.155688047409058
time_total_s: 1210.1796543598175
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995389
timesteps_total: 1352750
training_iteration: 119
trial_id: default
train step: 120
agent_timesteps_total: 1364250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02364802360534668
  StateBufferConnector_ms: 0.004366159439086914
  ViewRequirementAgentConnector_ms: 0.14342927932739258
counters:
  num_agent_steps_sampled: 1364250
  num_agent_steps_trained: 1347500
  num_env_steps_sampled: 1364250
  num_env_steps_trained: 1347500
  num_samples_added_to_queue: 1364000
  num_training_step_calls_since_last_synch_worker_weights: 558
  num_weight_broadcasts: 26805
custom_metrics: {}
date: 2023-08-14_15-43-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 6.89
episode_reward_min: 1.0
episodes_this_iter: 90
episodes_total: 10659
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0705287456512451
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -37.82417678833008
        total_loss: -31.904767990112305
        var_gnorm: 64.24592590332031
        vf_explained_var: 0.9513970613479614
        vf_loss: 22.544103622436523
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2695.0
  learner_queue:
    size_count: 2700
    size_mean: 14.94
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.567290655877205
  num_agent_steps_sampled: 1364250
  num_agent_steps_trained: 1347500
  num_env_steps_sampled: 1364250
  num_env_steps_trained: 1347500
  num_samples_added_to_queue: 1364000
  num_training_step_calls_since_last_synch_worker_weights: 558
  num_weight_broadcasts: 26805
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 264.261
    learner_load_time_ms: 2.247
    learner_load_wait_time_ms: 2.005
iterations_since_restore: 120
node_ip: 127.0.0.1
num_agent_steps_sampled: 1364250
num_agent_steps_trained: 1347500
num_env_steps_sampled: 1364250
num_env_steps_sampled_this_iter: 11500
num_env_steps_sampled_throughput_per_sec: 1149.9965727431395
num_env_steps_trained: 1347500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9965727431395
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 58.16428571428572
  ram_util_percent: 81.29285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07074030151300491
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027696885569898425
  mean_inference_ms: 1.3225544914720784
  mean_raw_obs_processing_ms: 0.2996572268376682
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02364802360534668
    StateBufferConnector_ms: 0.004366159439086914
    ViewRequirementAgentConnector_ms: 0.14342927932739258
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 6.89
  episode_reward_min: 1.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 4.0, 4.0, 6.0, 3.0, 8.0, 3.0, 1.0, 5.0, 8.0, 3.0, 13.0,
      11.0, 5.0, 6.0, 5.0, 6.0, 7.0, 4.0, 5.0, 6.0, 11.0, 6.0, 8.0, 7.0, 7.0, 9.0,
      5.0, 5.0, 7.0, 7.0, 3.0, 7.0, 7.0, 12.0, 4.0, 3.0, 4.0, 11.0, 10.0, 5.0, 5.0,
      7.0, 5.0, 5.0, 7.0, 5.0, 15.0, 10.0, 8.0, 10.0, 6.0, 8.0, 11.0, 4.0, 5.0, 5.0,
      5.0, 6.0, 5.0, 6.0, 8.0, 12.0, 10.0, 9.0, 10.0, 11.0, 4.0, 6.0, 4.0, 9.0, 6.0,
      8.0, 9.0, 1.0, 3.0, 5.0, 9.0, 8.0, 3.0, 8.0, 6.0, 9.0, 7.0, 8.0, 10.0, 9.0,
      5.0, 7.0, 12.0, 5.0, 8.0, 12.0, 10.0, 7.0, 4.0, 9.0, 9.0, 4.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07074030151300491
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027696885569898425
    mean_inference_ms: 1.3225544914720784
    mean_raw_obs_processing_ms: 0.2996572268376682
time_since_restore: 1220.334995508194
time_this_iter_s: 10.155341148376465
time_total_s: 1220.334995508194
timers:
  sample_time_ms: 0.019
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.052
timestamp: 1691995399
timesteps_total: 1364250
training_iteration: 120
trial_id: default
train step: 121
agent_timesteps_total: 1374200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024007558822631836
  StateBufferConnector_ms: 0.004614591598510742
  ViewRequirementAgentConnector_ms: 0.1542680263519287
counters:
  num_agent_steps_sampled: 1374200
  num_agent_steps_trained: 1357500
  num_env_steps_sampled: 1374200
  num_env_steps_trained: 1357500
  num_samples_added_to_queue: 1374000
  num_training_step_calls_since_last_synch_worker_weights: 292
  num_weight_broadcasts: 27001
custom_metrics: {}
date: 2023-08-14_15-43-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.71
episode_reward_min: 2.0
episodes_this_iter: 77
episodes_total: 10736
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.59999999999991
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9542183876037598
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -17.487552642822266
        total_loss: 6.5973944664001465
        var_gnorm: 64.25625610351562
        vf_explained_var: 0.9132437705993652
        vf_loss: 57.71207809448242
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2715.0
  learner_queue:
    size_count: 2722
    size_mean: 14.76
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7385051049680587
  num_agent_steps_sampled: 1374200
  num_agent_steps_trained: 1357500
  num_env_steps_sampled: 1374200
  num_env_steps_trained: 1357500
  num_samples_added_to_queue: 1374000
  num_training_step_calls_since_last_synch_worker_weights: 292
  num_weight_broadcasts: 27001
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 153.938
    learner_load_time_ms: 4.238
    learner_load_wait_time_ms: 1.551
iterations_since_restore: 121
node_ip: 127.0.0.1
num_agent_steps_sampled: 1374200
num_agent_steps_trained: 1357500
num_env_steps_sampled: 1374200
num_env_steps_sampled_this_iter: 9950
num_env_steps_sampled_throughput_per_sec: 994.996607672813
num_env_steps_trained: 1357500
num_env_steps_trained_this_iter: 10000
num_env_steps_trained_throughput_per_sec: 999.9965906259428
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10000
perf:
  cpu_util_percent: 59.957142857142856
  ram_util_percent: 82.80714285714285
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07083744039424218
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02773767144798443
  mean_inference_ms: 1.3234155154672802
  mean_raw_obs_processing_ms: 0.2998012330630919
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024007558822631836
    StateBufferConnector_ms: 0.004614591598510742
    ViewRequirementAgentConnector_ms: 0.1542680263519287
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.71
  episode_reward_min: 2.0
  episodes_this_iter: 77
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 8.0, 3.0, 8.0, 6.0, 9.0, 7.0, 8.0, 10.0, 9.0, 5.0, 7.0,
      12.0, 5.0, 8.0, 12.0, 10.0, 7.0, 4.0, 9.0, 9.0, 4.0, 10.0, 10.0, 10.0, 5.0,
      7.0, 2.0, 4.0, 11.0, 5.0, 7.0, 14.0, 11.0, 7.0, 7.0, 10.0, 6.0, 6.0, 7.0, 7.0,
      7.0, 7.0, 6.0, 6.0, 8.0, 6.0, 4.0, 6.0, 10.0, 5.0, 5.0, 5.0, 9.0, 7.0, 9.0,
      8.0, 10.0, 7.0, 7.0, 11.0, 6.0, 10.0, 12.0, 3.0, 6.0, 9.0, 11.0, 9.0, 10.0,
      7.0, 8.0, 6.0, 5.0, 11.0, 11.0, 7.0, 7.0, 9.0, 5.0, 6.0, 5.0, 7.0, 8.0, 6.0,
      6.0, 9.0, 9.0, 5.0, 9.0, 13.0, 6.0, 9.0, 11.0, 10.0, 11.0, 9.0, 5.0, 13.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07083744039424218
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02773767144798443
    mean_inference_ms: 1.3234155154672802
    mean_raw_obs_processing_ms: 0.2998012330630919
time_since_restore: 1230.4959785938263
time_this_iter_s: 10.160983085632324
time_total_s: 1230.4959785938263
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691995409
timesteps_total: 1374200
training_iteration: 121
trial_id: default
train step: 122
agent_timesteps_total: 1387600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019749005635579426
  StateBufferConnector_ms: 0.0034438996087937128
  ViewRequirementAgentConnector_ms: 0.11729308537074498
counters:
  num_agent_steps_sampled: 1387600
  num_agent_steps_trained: 1371000
  num_env_steps_sampled: 1387600
  num_env_steps_trained: 1371000
  num_samples_added_to_queue: 1387500
  num_training_step_calls_since_last_synch_worker_weights: 2768
  num_weight_broadcasts: 27266
custom_metrics: {}
date: 2023-08-14_15-43-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 7.123809523809523
episode_reward_min: 1.0
episodes_this_iter: 105
episodes_total: 10841
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9412084221839905
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -31.093507766723633
        total_loss: -5.776171684265137
        var_gnorm: 64.26664733886719
        vf_explained_var: 0.9225236177444458
        vf_loss: 60.046756744384766
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2742.0
  learner_queue:
    size_count: 2747
    size_mean: 14.92
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6228370220080635
  num_agent_steps_sampled: 1387600
  num_agent_steps_trained: 1371000
  num_env_steps_sampled: 1387600
  num_env_steps_trained: 1371000
  num_samples_added_to_queue: 1387500
  num_training_step_calls_since_last_synch_worker_weights: 2768
  num_weight_broadcasts: 27266
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 235.641
    learner_load_time_ms: 4.269
    learner_load_wait_time_ms: 2.065
iterations_since_restore: 122
node_ip: 127.0.0.1
num_agent_steps_sampled: 1387600
num_agent_steps_trained: 1371000
num_env_steps_sampled: 1387600
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9981470133655
num_env_steps_trained: 1371000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.998133185107
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.96666666666667
  ram_util_percent: 82.27333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07066650644481391
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027715472859057268
  mean_inference_ms: 1.322090018864608
  mean_raw_obs_processing_ms: 0.29954922217419844
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019749005635579426
    StateBufferConnector_ms: 0.0034438996087937128
    ViewRequirementAgentConnector_ms: 0.11729308537074498
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 7.123809523809523
  episode_reward_min: 1.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 7.0, 10.0, 4.0, 10.0, 9.0, 2.0, 4.0, 6.0, 7.0, 8.0, 9.0,
      7.0, 10.0, 7.0, 7.0, 7.0, 11.0, 4.0, 5.0, 10.0, 7.0, 6.0, 8.0, 7.0, 6.0, 9.0,
      9.0, 7.0, 7.0, 5.0, 10.0, 6.0, 10.0, 8.0, 1.0, 12.0, 6.0, 9.0, 10.0, 8.0, 6.0,
      5.0, 10.0, 8.0, 8.0, 9.0, 11.0, 7.0, 12.0, 7.0, 8.0, 5.0, 6.0, 7.0, 6.0, 7.0,
      6.0, 8.0, 11.0, 11.0, 9.0, 5.0, 6.0, 8.0, 7.0, 10.0, 7.0, 5.0, 7.0, 6.0, 4.0,
      3.0, 5.0, 6.0, 4.0, 6.0, 10.0, 4.0, 11.0, 11.0, 7.0, 7.0, 9.0, 3.0, 4.0, 8.0,
      5.0, 10.0, 8.0, 11.0, 11.0, 6.0, 11.0, 3.0, 5.0, 6.0, 6.0, 5.0, 4.0, 5.0, 4.0,
      1.0, 9.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07066650644481391
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027715472859057268
    mean_inference_ms: 1.322090018864608
    mean_raw_obs_processing_ms: 0.29954922217419844
time_since_restore: 1240.741542339325
time_this_iter_s: 10.245563745498657
time_total_s: 1240.741542339325
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995419
timesteps_total: 1387600
training_iteration: 122
trial_id: default
train step: 123
agent_timesteps_total: 1401000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020220166160946802
  StateBufferConnector_ms: 0.0036030723935081845
  ViewRequirementAgentConnector_ms: 0.12051900227864583
counters:
  num_agent_steps_sampled: 1401000
  num_agent_steps_trained: 1384500
  num_env_steps_sampled: 1401000
  num_env_steps_trained: 1384500
  num_samples_added_to_queue: 1401000
  num_training_step_calls_since_last_synch_worker_weights: 702
  num_weight_broadcasts: 27529
custom_metrics: {}
date: 2023-08-14_15-43-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.980952380952381
episode_reward_min: 2.0
episodes_this_iter: 105
episodes_total: 10946
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8527368307113647
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 44.008148193359375
        total_loss: 98.05123138427734
        var_gnorm: 64.27961730957031
        vf_explained_var: 0.8529832363128662
        vf_loss: 116.61354064941406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2769.0
  learner_queue:
    size_count: 2775
    size_mean: 15.44
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2191800523302536
  num_agent_steps_sampled: 1401000
  num_agent_steps_trained: 1384500
  num_env_steps_sampled: 1401000
  num_env_steps_trained: 1384500
  num_samples_added_to_queue: 1401000
  num_training_step_calls_since_last_synch_worker_weights: 702
  num_weight_broadcasts: 27529
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 174.78
    learner_load_time_ms: 3.888
    learner_load_wait_time_ms: 1.718
iterations_since_restore: 123
node_ip: 127.0.0.1
num_agent_steps_sampled: 1401000
num_agent_steps_trained: 1384500
num_env_steps_sampled: 1401000
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9937382036999
num_env_steps_trained: 1384500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9936914738767
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.68571428571429
  ram_util_percent: 82.39999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07055633066120556
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027672518563680856
  mean_inference_ms: 1.3201626694316093
  mean_raw_obs_processing_ms: 0.29914498015511115
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020220166160946802
    StateBufferConnector_ms: 0.0036030723935081845
    ViewRequirementAgentConnector_ms: 0.12051900227864583
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.980952380952381
  episode_reward_min: 2.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 5.0, 9.0, 8.0, 6.0, 4.0, 6.0, 8.0, 10.0, 8.0, 8.0, 9.0,
      8.0, 12.0, 8.0, 11.0, 6.0, 11.0, 6.0, 7.0, 9.0, 10.0, 9.0, 9.0, 7.0, 13.0, 11.0,
      11.0, 4.0, 9.0, 9.0, 7.0, 9.0, 6.0, 12.0, 9.0, 4.0, 6.0, 9.0, 8.0, 7.0, 12.0,
      11.0, 10.0, 7.0, 7.0, 10.0, 8.0, 9.0, 8.0, 11.0, 8.0, 15.0, 8.0, 5.0, 10.0,
      9.0, 4.0, 5.0, 8.0, 5.0, 7.0, 7.0, 8.0, 8.0, 6.0, 4.0, 6.0, 9.0, 3.0, 7.0, 9.0,
      5.0, 13.0, 7.0, 10.0, 3.0, 9.0, 7.0, 8.0, 7.0, 7.0, 8.0, 9.0, 8.0, 7.0, 3.0,
      12.0, 7.0, 2.0, 6.0, 10.0, 10.0, 11.0, 6.0, 4.0, 6.0, 14.0, 8.0, 6.0, 11.0,
      9.0, 13.0, 4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07055633066120556
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027672518563680856
    mean_inference_ms: 1.3201626694316093
    mean_raw_obs_processing_ms: 0.29914498015511115
time_since_restore: 1250.8983552455902
time_this_iter_s: 10.156812906265259
time_total_s: 1250.8983552455902
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691995429
timesteps_total: 1401000
training_iteration: 123
trial_id: default
train step: 124
agent_timesteps_total: 1414400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01904597649207482
  StateBufferConnector_ms: 0.0033887533041147087
  ViewRequirementAgentConnector_ms: 0.11758896020742562
counters:
  num_agent_steps_sampled: 1414400
  num_agent_steps_trained: 1397500
  num_env_steps_sampled: 1414400
  num_env_steps_trained: 1397500
  num_samples_added_to_queue: 1414000
  num_training_step_calls_since_last_synch_worker_weights: 1396
  num_weight_broadcasts: 27794
custom_metrics: {}
date: 2023-08-14_15-44-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 8.211538461538462
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 11050
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7763452529907227
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.456920623779297
        total_loss: -0.1390542984008789
        var_gnorm: 64.29521942138672
        vf_explained_var: 0.9588637948036194
        vf_loss: 36.39918518066406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2795.0
  learner_queue:
    size_count: 2799
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3654303350958628
  num_agent_steps_sampled: 1414400
  num_agent_steps_trained: 1397500
  num_env_steps_sampled: 1414400
  num_env_steps_trained: 1397500
  num_samples_added_to_queue: 1414000
  num_training_step_calls_since_last_synch_worker_weights: 1396
  num_weight_broadcasts: 27794
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 275.996
    learner_load_time_ms: 3.866
    learner_load_wait_time_ms: 1.779
iterations_since_restore: 124
node_ip: 127.0.0.1
num_agent_steps_sampled: 1414400
num_agent_steps_trained: 1397500
num_env_steps_sampled: 1414400
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9984025974243
num_env_steps_trained: 1397500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9984502810833
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.80714285714286
  ram_util_percent: 82.32142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07045678289534907
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02762716277572748
  mean_inference_ms: 1.3181960952727736
  mean_raw_obs_processing_ms: 0.2987317648615059
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01904597649207482
    StateBufferConnector_ms: 0.0033887533041147087
    ViewRequirementAgentConnector_ms: 0.11758896020742562
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 8.211538461538462
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 8.0, 13.0, 9.0, 9.0, 10.0, 7.0, 7.0, 9.0, 8.0, 9.0, 12.0,
      8.0, 12.0, 7.0, 8.0, 8.0, 6.0, 9.0, 12.0, 10.0, 8.0, 5.0, 11.0, 10.0, 11.0,
      9.0, 11.0, 7.0, 10.0, 6.0, 9.0, 13.0, 10.0, 9.0, 7.0, 7.0, 10.0, 5.0, 6.0, 6.0,
      10.0, 4.0, 4.0, 7.0, 6.0, 8.0, 3.0, 7.0, 6.0, 7.0, 7.0, 5.0, 7.0, 11.0, 9.0,
      13.0, 11.0, 10.0, 9.0, 13.0, 7.0, 11.0, 10.0, 7.0, 8.0, 6.0, 10.0, 6.0, 7.0,
      5.0, 11.0, 2.0, 11.0, 9.0, 8.0, 3.0, 7.0, 10.0, 10.0, 6.0, 7.0, 8.0, 11.0, 5.0,
      6.0, 13.0, 11.0, 7.0, 8.0, 6.0, 4.0, 10.0, 7.0, 7.0, 8.0, 9.0, 10.0, 6.0, 7.0,
      4.0, 6.0, 7.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07045678289534907
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02762716277572748
    mean_inference_ms: 1.3181960952727736
    mean_raw_obs_processing_ms: 0.2987317648615059
time_since_restore: 1261.0086345672607
time_this_iter_s: 10.110279321670532
time_total_s: 1261.0086345672607
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.044
timestamp: 1691995440
timesteps_total: 1414400
training_iteration: 124
trial_id: default
train step: 125
agent_timesteps_total: 1427600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020243342106158916
  StateBufferConnector_ms: 0.0034909981947678784
  ViewRequirementAgentConnector_ms: 0.1191405149606558
counters:
  num_agent_steps_sampled: 1427600
  num_agent_steps_trained: 1411000
  num_env_steps_sampled: 1427600
  num_env_steps_trained: 1411000
  num_samples_added_to_queue: 1427500
  num_training_step_calls_since_last_synch_worker_weights: 1074
  num_weight_broadcasts: 28053
custom_metrics: {}
date: 2023-08-14_15-44-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.990384615384615
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 11154
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4818553328514099
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.53212833404541
        total_loss: 14.849702835083008
        var_gnorm: 64.31007385253906
        vf_explained_var: 0.8656712770462036
        vf_loss: 57.58221435546875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2822.0
  learner_queue:
    size_count: 2828
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1697863052711808
  num_agent_steps_sampled: 1427600
  num_agent_steps_trained: 1411000
  num_env_steps_sampled: 1427600
  num_env_steps_trained: 1411000
  num_samples_added_to_queue: 1427500
  num_training_step_calls_since_last_synch_worker_weights: 1074
  num_weight_broadcasts: 28053
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 168.351
    learner_load_time_ms: 3.814
    learner_load_wait_time_ms: 1.573
iterations_since_restore: 125
node_ip: 127.0.0.1
num_agent_steps_sampled: 1427600
num_agent_steps_trained: 1411000
num_env_steps_sampled: 1427600
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9970102377897
num_env_steps_trained: 1411000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9969422886486
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.77333333333333
  ram_util_percent: 81.74
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0703683377783241
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027587170859759598
  mean_inference_ms: 1.3165202726804823
  mean_raw_obs_processing_ms: 0.2983694058742668
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020243342106158916
    StateBufferConnector_ms: 0.0034909981947678784
    ViewRequirementAgentConnector_ms: 0.1191405149606558
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.990384615384615
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 2.0, 8.0, 3.0, 5.0, 3.0, 4.0, 8.0, 6.0, 6.0, 2.0, 3.0, 11.0,
      9.0, 4.0, 2.0, 9.0, 7.0, 4.0, 8.0, 9.0, 5.0, 5.0, 6.0, 4.0, 8.0, 8.0, 5.0, 3.0,
      4.0, 7.0, 7.0, 2.0, 3.0, 5.0, 4.0, 4.0, 5.0, 1.0, 1.0, 1.0, 3.0, 2.0, 6.0, 3.0,
      7.0, 3.0, 2.0, 2.0, 9.0, 2.0, 0.0, 7.0, 5.0, 5.0, 5.0, 4.0, 4.0, 6.0, 6.0, 3.0,
      7.0, 3.0, 3.0, 4.0, 8.0, 7.0, 7.0, 2.0, 7.0, 4.0, 7.0, 6.0, 2.0, 7.0, 5.0, 9.0,
      3.0, 5.0, 8.0, 9.0, 9.0, 7.0, 4.0, 6.0, 3.0, 5.0, 6.0, 7.0, 4.0, 6.0, 0.0, 6.0,
      6.0, 5.0, 1.0, 3.0, 7.0, 4.0, 9.0, 5.0, 4.0, 5.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0703683377783241
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027587170859759598
    mean_inference_ms: 1.3165202726804823
    mean_raw_obs_processing_ms: 0.2983694058742668
time_since_restore: 1271.1651995182037
time_this_iter_s: 10.156564950942993
time_total_s: 1271.1651995182037
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691995450
timesteps_total: 1427600
training_iteration: 125
trial_id: default
train step: 126
agent_timesteps_total: 1441200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018779736644816847
  StateBufferConnector_ms: 0.00333313672047741
  ViewRequirementAgentConnector_ms: 0.11451311831204396
counters:
  num_agent_steps_sampled: 1441200
  num_agent_steps_trained: 1424500
  num_env_steps_sampled: 1441200
  num_env_steps_trained: 1424500
  num_samples_added_to_queue: 1441000
  num_training_step_calls_since_last_synch_worker_weights: 1192
  num_weight_broadcasts: 28317
custom_metrics: {}
date: 2023-08-14_15-44-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 5.30188679245283
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 11260
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8674657344818115
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.74102783203125
        total_loss: 8.839226722717285
        var_gnorm: 64.31395721435547
        vf_explained_var: 0.9074136018753052
        vf_loss: 45.835166931152344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2849.0
  learner_queue:
    size_count: 2854
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 1441200
  num_agent_steps_trained: 1424500
  num_env_steps_sampled: 1441200
  num_env_steps_trained: 1424500
  num_samples_added_to_queue: 1441000
  num_training_step_calls_since_last_synch_worker_weights: 1192
  num_weight_broadcasts: 28317
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 206.785
    learner_load_time_ms: 10.287
    learner_load_wait_time_ms: 1.527
iterations_since_restore: 126
node_ip: 127.0.0.1
num_agent_steps_sampled: 1441200
num_agent_steps_trained: 1424500
num_env_steps_sampled: 1441200
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9932880732863
num_env_steps_trained: 1424500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9933374256887
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.66428571428571
  ram_util_percent: 81.75
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07025897333618336
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027537233281063517
  mean_inference_ms: 1.3144560702428831
  mean_raw_obs_processing_ms: 0.29793486109569906
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018779736644816847
    StateBufferConnector_ms: 0.00333313672047741
    ViewRequirementAgentConnector_ms: 0.11451311831204396
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 5.30188679245283
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 1.0, 3.0, 6.0, 4.0, 5.0, 8.0, 7.0, 6.0, 3.0, 0.0, 4.0, 4.0,
      10.0, 2.0, 8.0, 7.0, 4.0, 4.0, 8.0, 4.0, 7.0, 4.0, 6.0, 7.0, 8.0, 1.0, 5.0,
      3.0, 5.0, 5.0, 7.0, 4.0, 6.0, 5.0, 7.0, 3.0, 4.0, 3.0, 4.0, 7.0, 4.0, 6.0, 3.0,
      7.0, 5.0, 9.0, 6.0, 3.0, 5.0, 3.0, 5.0, 5.0, 4.0, 5.0, 4.0, 1.0, 1.0, 5.0, 8.0,
      6.0, 6.0, 6.0, 1.0, 6.0, 9.0, 10.0, 5.0, 8.0, 9.0, 4.0, 6.0, 8.0, 3.0, 7.0,
      7.0, 6.0, 6.0, 5.0, 6.0, 9.0, 10.0, 5.0, 4.0, 3.0, 5.0, 5.0, 7.0, 6.0, 6.0,
      6.0, 5.0, 9.0, 6.0, 1.0, 5.0, 7.0, 3.0, 8.0, 3.0, 6.0, 2.0, 3.0, 6.0, 8.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07025897333618336
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027537233281063517
    mean_inference_ms: 1.3144560702428831
    mean_raw_obs_processing_ms: 0.29793486109569906
time_since_restore: 1281.286565542221
time_this_iter_s: 10.121366024017334
time_total_s: 1281.286565542221
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995460
timesteps_total: 1441200
training_iteration: 126
trial_id: default
train step: 127
agent_timesteps_total: 1453800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020740032196044922
  StateBufferConnector_ms: 0.0035936832427978516
  ViewRequirementAgentConnector_ms: 0.12266778945922852
counters:
  num_agent_steps_sampled: 1453800
  num_agent_steps_trained: 1437000
  num_env_steps_sampled: 1453800
  num_env_steps_trained: 1437000
  num_samples_added_to_queue: 1453500
  num_training_step_calls_since_last_synch_worker_weights: 15
  num_weight_broadcasts: 28563
custom_metrics: {}
date: 2023-08-14_15-44-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.33
episode_reward_min: 2.0
episodes_this_iter: 98
episodes_total: 11358
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7920920252799988
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.270662307739258
        total_loss: 25.757884979248047
        var_gnorm: 64.32000732421875
        vf_explained_var: 0.877753734588623
        vf_loss: 63.9780158996582
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2874.0
  learner_queue:
    size_count: 2882
    size_mean: 15.12
    size_quantiles: [9.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.7045820602130013
  num_agent_steps_sampled: 1453800
  num_agent_steps_trained: 1437000
  num_env_steps_sampled: 1453800
  num_env_steps_trained: 1437000
  num_samples_added_to_queue: 1453500
  num_training_step_calls_since_last_synch_worker_weights: 15
  num_weight_broadcasts: 28563
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 122.047
    learner_load_time_ms: 8.373
    learner_load_wait_time_ms: 1.785
iterations_since_restore: 127
node_ip: 127.0.0.1
num_agent_steps_sampled: 1453800
num_agent_steps_trained: 1437000
num_env_steps_sampled: 1453800
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9955840265548
num_env_steps_trained: 1437000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.995619073963
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 55.40000000000001
  ram_util_percent: 82.82142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07021424276353631
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027519057476823972
  mean_inference_ms: 1.3134492326355272
  mean_raw_obs_processing_ms: 0.29772283282526657
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020740032196044922
    StateBufferConnector_ms: 0.0035936832427978516
    ViewRequirementAgentConnector_ms: 0.12266778945922852
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.33
  episode_reward_min: 2.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 5.0, 8.0, 4.0, 7.0, 7.0, 3.0, 7.0, 5.0, 13.0, 5.0,
      5.0, 5.0, 6.0, 4.0, 8.0, 6.0, 9.0, 2.0, 8.0, 4.0, 5.0, 8.0, 10.0, 6.0, 11.0,
      9.0, 7.0, 9.0, 7.0, 8.0, 9.0, 10.0, 10.0, 6.0, 6.0, 12.0, 14.0, 11.0, 10.0,
      5.0, 11.0, 6.0, 7.0, 8.0, 12.0, 6.0, 5.0, 10.0, 7.0, 2.0, 7.0, 7.0, 6.0, 6.0,
      2.0, 7.0, 7.0, 6.0, 4.0, 8.0, 5.0, 8.0, 5.0, 8.0, 6.0, 11.0, 5.0, 8.0, 9.0,
      4.0, 7.0, 9.0, 5.0, 3.0, 7.0, 7.0, 7.0, 8.0, 7.0, 11.0, 7.0, 12.0, 8.0, 8.0,
      9.0, 7.0, 10.0, 6.0, 7.0, 12.0, 7.0, 8.0, 8.0, 10.0, 9.0, 9.0, 5.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07021424276353631
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027519057476823972
    mean_inference_ms: 1.3134492326355272
    mean_raw_obs_processing_ms: 0.29772283282526657
time_since_restore: 1291.5051865577698
time_this_iter_s: 10.218621015548706
time_total_s: 1291.5051865577698
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691995470
timesteps_total: 1453800
training_iteration: 127
trial_id: default
train step: 128
agent_timesteps_total: 1465100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022896289825439453
  StateBufferConnector_ms: 0.004070758819580078
  ViewRequirementAgentConnector_ms: 0.13637185096740723
counters:
  num_agent_steps_sampled: 1465100
  num_agent_steps_trained: 1448500
  num_env_steps_sampled: 1465100
  num_env_steps_trained: 1448500
  num_samples_added_to_queue: 1465000
  num_training_step_calls_since_last_synch_worker_weights: 723
  num_weight_broadcasts: 28786
custom_metrics: {}
date: 2023-08-14_15-44-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.81
episode_reward_min: 2.0
episodes_this_iter: 88
episodes_total: 11446
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7158181667327881
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -23.279895782470703
        total_loss: 23.22649383544922
        var_gnorm: 64.3224105834961
        vf_explained_var: 0.8779441714286804
        vf_loss: 100.17095947265625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2897.0
  learner_queue:
    size_count: 2902
    size_mean: 14.64
    size_quantiles: [9.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9875613198087752
  num_agent_steps_sampled: 1465100
  num_agent_steps_trained: 1448500
  num_env_steps_sampled: 1465100
  num_env_steps_trained: 1448500
  num_samples_added_to_queue: 1465000
  num_training_step_calls_since_last_synch_worker_weights: 723
  num_weight_broadcasts: 28786
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 242.401
    learner_load_time_ms: 8.354
    learner_load_wait_time_ms: 1.638
iterations_since_restore: 128
node_ip: 127.0.0.1
num_agent_steps_sampled: 1465100
num_agent_steps_trained: 1448500
num_env_steps_sampled: 1465100
num_env_steps_sampled_this_iter: 11300
num_env_steps_sampled_throughput_per_sec: 1129.995824114019
num_env_steps_trained: 1448500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9957502045327
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 63.480000000000004
  ram_util_percent: 82.96000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07025303021247443
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02752224455436028
  mean_inference_ms: 1.3133690808420264
  mean_raw_obs_processing_ms: 0.2977088824590776
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022896289825439453
    StateBufferConnector_ms: 0.004070758819580078
    ViewRequirementAgentConnector_ms: 0.13637185096740723
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.81
  episode_reward_min: 2.0
  episodes_this_iter: 88
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 6.0, 7.0, 12.0, 7.0, 8.0, 8.0, 10.0, 9.0, 9.0, 5.0, 8.0,
      10.0, 4.0, 8.0, 8.0, 16.0, 5.0, 7.0, 10.0, 7.0, 6.0, 12.0, 5.0, 12.0, 7.0, 6.0,
      6.0, 9.0, 7.0, 8.0, 11.0, 8.0, 5.0, 9.0, 9.0, 7.0, 8.0, 9.0, 5.0, 7.0, 14.0,
      12.0, 6.0, 6.0, 11.0, 12.0, 7.0, 7.0, 6.0, 7.0, 10.0, 4.0, 6.0, 5.0, 6.0, 11.0,
      7.0, 9.0, 5.0, 6.0, 10.0, 6.0, 5.0, 10.0, 8.0, 5.0, 8.0, 9.0, 8.0, 5.0, 6.0,
      10.0, 8.0, 4.0, 10.0, 5.0, 8.0, 6.0, 2.0, 8.0, 11.0, 9.0, 11.0, 12.0, 6.0, 6.0,
      11.0, 7.0, 2.0, 10.0, 9.0, 8.0, 10.0, 6.0, 6.0, 9.0, 7.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07025303021247443
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02752224455436028
    mean_inference_ms: 1.3133690808420264
    mean_raw_obs_processing_ms: 0.2977088824590776
time_since_restore: 1301.6410744190216
time_this_iter_s: 10.135887861251831
time_total_s: 1301.6410744190216
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995480
timesteps_total: 1465100
training_iteration: 128
trial_id: default
train step: 129
agent_timesteps_total: 1476900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0260007381439209
  StateBufferConnector_ms: 0.0038695335388183594
  ViewRequirementAgentConnector_ms: 0.13266372680664062
counters:
  num_agent_steps_sampled: 1476900
  num_agent_steps_trained: 1460000
  num_env_steps_sampled: 1476900
  num_env_steps_trained: 1460000
  num_samples_added_to_queue: 1476500
  num_training_step_calls_since_last_synch_worker_weights: 457
  num_weight_broadcasts: 29017
custom_metrics: {}
date: 2023-08-14_15-44-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.01
episode_reward_min: 2.0
episodes_this_iter: 93
episodes_total: 11539
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.90000000000009
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5539643168449402
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.2335362434387207
        total_loss: 14.209388732910156
        var_gnorm: 64.33001708984375
        vf_explained_var: 0.9355836510658264
        vf_loss: 34.42549133300781
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2920.0
  learner_queue:
    size_count: 2926
    size_mean: 14.38
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.0965686251587377
  num_agent_steps_sampled: 1476900
  num_agent_steps_trained: 1460000
  num_env_steps_sampled: 1476900
  num_env_steps_trained: 1460000
  num_samples_added_to_queue: 1476500
  num_training_step_calls_since_last_synch_worker_weights: 457
  num_weight_broadcasts: 29017
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 203.078
    learner_load_time_ms: 8.355
    learner_load_wait_time_ms: 1.632
iterations_since_restore: 129
node_ip: 127.0.0.1
num_agent_steps_sampled: 1476900
num_agent_steps_trained: 1460000
num_env_steps_sampled: 1476900
num_env_steps_sampled_this_iter: 11800
num_env_steps_sampled_throughput_per_sec: 1179.9966802690442
num_env_steps_trained: 1460000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9967646689836
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 59.01428571428571
  ram_util_percent: 81.96428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07022035486952449
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02752296734406447
  mean_inference_ms: 1.3130856080117725
  mean_raw_obs_processing_ms: 0.29766833656089664
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0260007381439209
    StateBufferConnector_ms: 0.0038695335388183594
    ViewRequirementAgentConnector_ms: 0.13266372680664062
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.01
  episode_reward_min: 2.0
  episodes_this_iter: 93
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 6.0, 6.0, 9.0, 7.0, 7.0, 6.0, 8.0, 7.0, 6.0, 14.0, 5.0,
      5.0, 8.0, 12.0, 7.0, 8.0, 7.0, 8.0, 5.0, 11.0, 6.0, 8.0, 2.0, 8.0, 7.0, 3.0,
      7.0, 7.0, 8.0, 7.0, 12.0, 6.0, 8.0, 9.0, 8.0, 6.0, 8.0, 4.0, 10.0, 8.0, 3.0,
      4.0, 8.0, 9.0, 8.0, 6.0, 6.0, 8.0, 6.0, 8.0, 9.0, 6.0, 3.0, 10.0, 7.0, 5.0,
      15.0, 3.0, 5.0, 10.0, 8.0, 9.0, 3.0, 9.0, 8.0, 7.0, 4.0, 9.0, 10.0, 4.0, 5.0,
      8.0, 8.0, 5.0, 6.0, 4.0, 10.0, 8.0, 8.0, 3.0, 10.0, 8.0, 3.0, 5.0, 8.0, 4.0,
      6.0, 3.0, 7.0, 13.0, 3.0, 5.0, 5.0, 11.0, 6.0, 6.0, 4.0, 5.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07022035486952449
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02752296734406447
    mean_inference_ms: 1.3130856080117725
    mean_raw_obs_processing_ms: 0.29766833656089664
time_since_restore: 1311.7789175510406
time_this_iter_s: 10.137843132019043
time_total_s: 1311.7789175510406
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995490
timesteps_total: 1476900
training_iteration: 129
trial_id: default
train step: 130
agent_timesteps_total: 1489900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019705413591743697
  StateBufferConnector_ms: 0.0035158478387511604
  ViewRequirementAgentConnector_ms: 0.12000834587777015
counters:
  num_agent_steps_sampled: 1489900
  num_agent_steps_trained: 1473000
  num_env_steps_sampled: 1489900
  num_env_steps_trained: 1473000
  num_samples_added_to_queue: 1489500
  num_training_step_calls_since_last_synch_worker_weights: 1212
  num_weight_broadcasts: 29273
custom_metrics: {}
date: 2023-08-14_15-45-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.029702970297029
episode_reward_min: 2.0
episodes_this_iter: 101
episodes_total: 11640
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.721926212310791
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.909560203552246
        total_loss: 9.696109771728516
        var_gnorm: 64.33434295654297
        vf_explained_var: 0.9282747507095337
        vf_loss: 46.43060302734375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2946.0
  learner_queue:
    size_count: 2950
    size_mean: 15.06
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5285287043428395
  num_agent_steps_sampled: 1489900
  num_agent_steps_trained: 1473000
  num_env_steps_sampled: 1489900
  num_env_steps_trained: 1473000
  num_samples_added_to_queue: 1489500
  num_training_step_calls_since_last_synch_worker_weights: 1212
  num_weight_broadcasts: 29273
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 285.31
    learner_load_time_ms: 15.106
    learner_load_wait_time_ms: 1.561
iterations_since_restore: 130
node_ip: 127.0.0.1
num_agent_steps_sampled: 1489900
num_agent_steps_trained: 1473000
num_env_steps_sampled: 1489900
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9972724971776
num_env_steps_trained: 1473000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9972724971776
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.949999999999996
  ram_util_percent: 81.60000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.07010759322752172
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02749360475990613
  mean_inference_ms: 1.3117078860305302
  mean_raw_obs_processing_ms: 0.29738294493508194
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019705413591743697
    StateBufferConnector_ms: 0.0035158478387511604
    ViewRequirementAgentConnector_ms: 0.12000834587777015
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.029702970297029
  episode_reward_min: 2.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 5.0, 6.0, 8.0, 7.0, 7.0, 6.0, 5.0, 10.0, 7.0, 10.0, 5.0,
      6.0, 8.0, 11.0, 7.0, 8.0, 8.0, 12.0, 7.0, 10.0, 6.0, 8.0, 9.0, 12.0, 9.0, 6.0,
      6.0, 8.0, 12.0, 7.0, 8.0, 11.0, 3.0, 9.0, 4.0, 7.0, 9.0, 7.0, 6.0, 5.0, 10.0,
      11.0, 7.0, 11.0, 10.0, 6.0, 4.0, 8.0, 7.0, 7.0, 8.0, 9.0, 7.0, 6.0, 10.0, 6.0,
      4.0, 9.0, 14.0, 10.0, 12.0, 7.0, 8.0, 6.0, 11.0, 8.0, 7.0, 12.0, 7.0, 8.0, 9.0,
      7.0, 11.0, 4.0, 9.0, 13.0, 8.0, 9.0, 9.0, 4.0, 8.0, 14.0, 7.0, 10.0, 12.0, 7.0,
      11.0, 8.0, 6.0, 11.0, 9.0, 7.0, 5.0, 5.0, 12.0, 6.0, 9.0, 2.0, 8.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.07010759322752172
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02749360475990613
    mean_inference_ms: 1.3117078860305302
    mean_raw_obs_processing_ms: 0.29738294493508194
time_since_restore: 1321.868956565857
time_this_iter_s: 10.090039014816284
time_total_s: 1321.868956565857
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995500
timesteps_total: 1489900
training_iteration: 130
trial_id: default
train step: 131
agent_timesteps_total: 1503700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019389832461321796
  StateBufferConnector_ms: 0.003341833750406901
  ViewRequirementAgentConnector_ms: 0.11589063538445367
counters:
  num_agent_steps_sampled: 1503700
  num_agent_steps_trained: 1487000
  num_env_steps_sampled: 1503700
  num_env_steps_trained: 1487000
  num_samples_added_to_queue: 1503500
  num_training_step_calls_since_last_synch_worker_weights: 561
  num_weight_broadcasts: 29542
custom_metrics: {}
date: 2023-08-14_15-45-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.953703703703703
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 11748
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5681125521659851
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -4.41973876953125
        total_loss: 16.41290855407715
        var_gnorm: 64.34407806396484
        vf_explained_var: 0.9524009823799133
        vf_loss: 47.34642028808594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2974.0
  learner_queue:
    size_count: 2979
    size_mean: 15.66
    size_quantiles: [12.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.8856635930193811
  num_agent_steps_sampled: 1503700
  num_agent_steps_trained: 1487000
  num_env_steps_sampled: 1503700
  num_env_steps_trained: 1487000
  num_samples_added_to_queue: 1503500
  num_training_step_calls_since_last_synch_worker_weights: 561
  num_weight_broadcasts: 29542
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 205.637
    learner_load_time_ms: 14.73
    learner_load_wait_time_ms: 1.537
iterations_since_restore: 131
node_ip: 127.0.0.1
num_agent_steps_sampled: 1503700
num_agent_steps_trained: 1487000
num_env_steps_sampled: 1503700
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9939461019974
num_env_steps_trained: 1487000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.993858364345
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.83571428571429
  ram_util_percent: 81.28571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06999874684891239
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027442881946270044
  mean_inference_ms: 1.3096000128855916
  mean_raw_obs_processing_ms: 0.29693371536945856
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019389832461321796
    StateBufferConnector_ms: 0.003341833750406901
    ViewRequirementAgentConnector_ms: 0.11589063538445367
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.953703703703703
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 7.0, 9.0, 7.0, 5.0, 10.0, 6.0, 3.0, 10.0, 11.0, 8.0, 9.0,
      7.0, 5.0, 9.0, 8.0, 9.0, 3.0, 7.0, 9.0, 7.0, 6.0, 10.0, 9.0, 4.0, 6.0, 4.0,
      11.0, 8.0, 3.0, 6.0, 9.0, 13.0, 9.0, 8.0, 5.0, 11.0, 10.0, 7.0, 6.0, 4.0, 4.0,
      10.0, 9.0, 7.0, 12.0, 7.0, 8.0, 7.0, 4.0, 5.0, 1.0, 8.0, 6.0, 11.0, 8.0, 6.0,
      2.0, 4.0, 8.0, 8.0, 3.0, 10.0, 6.0, 7.0, 6.0, 5.0, 6.0, 7.0, 4.0, 5.0, 4.0,
      8.0, 8.0, 7.0, 11.0, 8.0, 5.0, 7.0, 4.0, 3.0, 7.0, 9.0, 12.0, 8.0, 6.0, 10.0,
      6.0, 3.0, 13.0, 4.0, 2.0, 5.0, 10.0, 10.0, 8.0, 4.0, 9.0, 8.0, 3.0, 8.0, 6.0,
      5.0, 7.0, 6.0, 6.0, 8.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06999874684891239
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027442881946270044
    mean_inference_ms: 1.3096000128855916
    mean_raw_obs_processing_ms: 0.29693371536945856
time_since_restore: 1331.9942996501923
time_this_iter_s: 10.125343084335327
time_total_s: 1331.9942996501923
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995511
timesteps_total: 1503700
training_iteration: 131
trial_id: default
train step: 132
agent_timesteps_total: 1516600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01973303237763962
  StateBufferConnector_ms: 0.0034374765830464883
  ViewRequirementAgentConnector_ms: 0.12015021673523553
counters:
  num_agent_steps_sampled: 1516600
  num_agent_steps_trained: 1500000
  num_env_steps_sampled: 1516600
  num_env_steps_trained: 1500000
  num_samples_added_to_queue: 1516500
  num_training_step_calls_since_last_synch_worker_weights: 254
  num_weight_broadcasts: 29796
custom_metrics: {}
date: 2023-08-14_15-45-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.9504950495049505
episode_reward_min: 1.0
episodes_this_iter: 101
episodes_total: 11849
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5292001366615295
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -17.751455307006836
        total_loss: 11.652039527893066
        var_gnorm: 64.3482437133789
        vf_explained_var: 0.9212360382080078
        vf_loss: 64.09899139404297
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3000.0
  learner_queue:
    size_count: 3006
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3078226179417451
  num_agent_steps_sampled: 1516600
  num_agent_steps_trained: 1500000
  num_env_steps_sampled: 1516600
  num_env_steps_trained: 1500000
  num_samples_added_to_queue: 1516500
  num_training_step_calls_since_last_synch_worker_weights: 254
  num_weight_broadcasts: 29796
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 190.602
    learner_load_time_ms: 8.192
    learner_load_wait_time_ms: 2.13
iterations_since_restore: 132
node_ip: 127.0.0.1
num_agent_steps_sampled: 1516600
num_agent_steps_trained: 1500000
num_env_steps_sampled: 1516600
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9966783609088
num_env_steps_trained: 1500000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9966526117687
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.17333333333334
  ram_util_percent: 80.79333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06993609276154829
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027411739256312507
  mean_inference_ms: 1.3084399641532576
  mean_raw_obs_processing_ms: 0.2966727559441607
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01973303237763962
    StateBufferConnector_ms: 0.0034374765830464883
    ViewRequirementAgentConnector_ms: 0.12015021673523553
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.9504950495049505
  episode_reward_min: 1.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 3.0, 5.0, 3.0, 6.0, 7.0, 10.0, 2.0, 6.0, 5.0, 1.0, 7.0,
      4.0, 2.0, 6.0, 9.0, 5.0, 5.0, 8.0, 5.0, 8.0, 3.0, 2.0, 7.0, 1.0, 3.0, 4.0, 6.0,
      3.0, 7.0, 6.0, 6.0, 5.0, 2.0, 6.0, 6.0, 6.0, 3.0, 4.0, 10.0, 5.0, 4.0, 6.0,
      6.0, 7.0, 3.0, 7.0, 5.0, 7.0, 11.0, 6.0, 6.0, 4.0, 9.0, 6.0, 4.0, 5.0, 7.0,
      2.0, 7.0, 7.0, 6.0, 3.0, 7.0, 2.0, 5.0, 9.0, 4.0, 2.0, 4.0, 5.0, 4.0, 6.0, 6.0,
      4.0, 10.0, 6.0, 3.0, 5.0, 5.0, 1.0, 7.0, 7.0, 1.0, 2.0, 1.0, 4.0, 3.0, 4.0,
      5.0, 4.0, 3.0, 6.0, 1.0, 5.0, 6.0, 5.0, 4.0, 3.0, 4.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06993609276154829
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027411739256312507
    mean_inference_ms: 1.3084399641532576
    mean_raw_obs_processing_ms: 0.2966727559441607
time_since_restore: 1342.249656677246
time_this_iter_s: 10.255357027053833
time_total_s: 1342.249656677246
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691995521
timesteps_total: 1516600
training_iteration: 132
trial_id: default
train step: 133
agent_timesteps_total: 1528100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02261972427368164
  StateBufferConnector_ms: 0.0043599605560302734
  ViewRequirementAgentConnector_ms: 0.13576102256774902
counters:
  num_agent_steps_sampled: 1528100
  num_agent_steps_trained: 1511500
  num_env_steps_sampled: 1528100
  num_env_steps_trained: 1511500
  num_samples_added_to_queue: 1528000
  num_training_step_calls_since_last_synch_worker_weights: 177
  num_weight_broadcasts: 30022
custom_metrics: {}
date: 2023-08-14_15-45-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.55
episode_reward_min: 1.0
episodes_this_iter: 90
episodes_total: 11939
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8119521737098694
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.893368721008301
        total_loss: 24.350566864013672
        var_gnorm: 64.35016632080078
        vf_explained_var: 0.9172232747077942
        vf_loss: 49.03392028808594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3023.0
  learner_queue:
    size_count: 3029
    size_mean: 15.02
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.606113321033108
  num_agent_steps_sampled: 1528100
  num_agent_steps_trained: 1511500
  num_env_steps_sampled: 1528100
  num_env_steps_trained: 1511500
  num_samples_added_to_queue: 1528000
  num_training_step_calls_since_last_synch_worker_weights: 177
  num_weight_broadcasts: 30022
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 183.491
    learner_load_time_ms: 8.224
    learner_load_wait_time_ms: 1.633
iterations_since_restore: 133
node_ip: 127.0.0.1
num_agent_steps_sampled: 1528100
num_agent_steps_trained: 1511500
num_env_steps_sampled: 1528100
num_env_steps_sampled_this_iter: 11500
num_env_steps_sampled_throughput_per_sec: 1149.993227760142
num_env_steps_trained: 1511500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.993227760142
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 61.135714285714286
  ram_util_percent: 82.71428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06996654217043333
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027411194825935743
  mean_inference_ms: 1.3082944989038583
  mean_raw_obs_processing_ms: 0.2966541850869851
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02261972427368164
    StateBufferConnector_ms: 0.0043599605560302734
    ViewRequirementAgentConnector_ms: 0.13576102256774902
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.55
  episode_reward_min: 1.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 6.0, 1.0, 5.0, 6.0, 5.0, 4.0, 3.0, 4.0, 1.0, 7.0, 8.0, 7.0,
      5.0, 5.0, 5.0, 2.0, 6.0, 5.0, 11.0, 4.0, 6.0, 4.0, 5.0, 4.0, 3.0, 6.0, 9.0,
      4.0, 8.0, 8.0, 9.0, 13.0, 8.0, 11.0, 5.0, 5.0, 2.0, 9.0, 5.0, 9.0, 6.0, 9.0,
      6.0, 5.0, 4.0, 10.0, 10.0, 10.0, 6.0, 9.0, 6.0, 9.0, 3.0, 5.0, 5.0, 5.0, 8.0,
      5.0, 4.0, 8.0, 4.0, 7.0, 5.0, 4.0, 1.0, 4.0, 11.0, 4.0, 6.0, 8.0, 9.0, 10.0,
      5.0, 5.0, 9.0, 6.0, 3.0, 7.0, 10.0, 6.0, 11.0, 10.0, 10.0, 12.0, 6.0, 5.0, 7.0,
      6.0, 7.0, 8.0, 10.0, 5.0, 8.0, 11.0, 12.0, 8.0, 8.0, 10.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06996654217043333
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027411194825935743
    mean_inference_ms: 1.3082944989038583
    mean_raw_obs_processing_ms: 0.2966541850869851
time_since_restore: 1352.4106895923615
time_this_iter_s: 10.161032915115356
time_total_s: 1352.4106895923615
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995531
timesteps_total: 1528100
training_iteration: 133
trial_id: default
train step: 134
agent_timesteps_total: 1541400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019622536805959847
  StateBufferConnector_ms: 0.0034334567876962516
  ViewRequirementAgentConnector_ms: 0.12053709763746995
counters:
  num_agent_steps_sampled: 1541400
  num_agent_steps_trained: 1524500
  num_env_steps_sampled: 1541400
  num_env_steps_trained: 1524500
  num_samples_added_to_queue: 1541000
  num_training_step_calls_since_last_synch_worker_weights: 824
  num_weight_broadcasts: 30284
custom_metrics: {}
date: 2023-08-14_15-45-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.75
episode_reward_min: 3.0
episodes_this_iter: 104
episodes_total: 12043
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7381705045700073
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.06669044494629
        total_loss: 23.25379753112793
        var_gnorm: 64.35102081298828
        vf_explained_var: 0.9717164635658264
        vf_loss: 17.75592041015625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3049.0
  learner_queue:
    size_count: 3054
    size_mean: 14.78
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.8032193432857804
  num_agent_steps_sampled: 1541400
  num_agent_steps_trained: 1524500
  num_env_steps_sampled: 1541400
  num_env_steps_trained: 1524500
  num_samples_added_to_queue: 1541000
  num_training_step_calls_since_last_synch_worker_weights: 824
  num_weight_broadcasts: 30284
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 241.262
    learner_load_time_ms: 8.198
    learner_load_wait_time_ms: 1.644
iterations_since_restore: 134
node_ip: 127.0.0.1
num_agent_steps_sampled: 1541400
num_agent_steps_trained: 1524500
num_env_steps_sampled: 1541400
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9939117710337
num_env_steps_trained: 1524500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9940490995066
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.19333333333335
  ram_util_percent: 82.32666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06984642792877493
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02737950859684723
  mean_inference_ms: 1.3068507350528127
  mean_raw_obs_processing_ms: 0.29633756127014466
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019622536805959847
    StateBufferConnector_ms: 0.0034334567876962516
    ViewRequirementAgentConnector_ms: 0.12053709763746995
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.75
  episode_reward_min: 3.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 6.0, 7.0, 7.0, 7.0, 8.0, 8.0, 8.0, 10.0, 6.0, 5.0, 12.0,
      12.0, 8.0, 4.0, 8.0, 9.0, 6.0, 6.0, 9.0, 8.0, 7.0, 6.0, 12.0, 7.0, 5.0, 6.0,
      7.0, 11.0, 7.0, 7.0, 7.0, 8.0, 4.0, 5.0, 11.0, 7.0, 10.0, 8.0, 8.0, 6.0, 6.0,
      9.0, 5.0, 11.0, 12.0, 4.0, 8.0, 9.0, 8.0, 9.0, 12.0, 9.0, 3.0, 8.0, 5.0, 8.0,
      10.0, 10.0, 8.0, 5.0, 7.0, 5.0, 5.0, 9.0, 8.0, 11.0, 9.0, 9.0, 10.0, 5.0, 11.0,
      10.0, 3.0, 8.0, 4.0, 6.0, 8.0, 10.0, 9.0, 13.0, 5.0, 9.0, 4.0, 5.0, 9.0, 12.0,
      4.0, 7.0, 8.0, 10.0, 8.0, 8.0, 9.0, 4.0, 3.0, 11.0, 9.0, 7.0, 10.0, 7.0, 10.0,
      5.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06984642792877493
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02737950859684723
    mean_inference_ms: 1.3068507350528127
    mean_raw_obs_processing_ms: 0.29633756127014466
time_since_restore: 1362.5491123199463
time_this_iter_s: 10.138422727584839
time_total_s: 1362.5491123199463
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995541
timesteps_total: 1541400
training_iteration: 134
trial_id: default
train step: 135
agent_timesteps_total: 1554300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021108778396455367
  StateBufferConnector_ms: 0.0036978485560653232
  ViewRequirementAgentConnector_ms: 0.1273589559120707
counters:
  num_agent_steps_sampled: 1554300
  num_agent_steps_trained: 1537500
  num_env_steps_sampled: 1554300
  num_env_steps_trained: 1537500
  num_samples_added_to_queue: 1554000
  num_training_step_calls_since_last_synch_worker_weights: 1143
  num_weight_broadcasts: 30537
custom_metrics: {}
date: 2023-08-14_15-45-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.405940594059405
episode_reward_min: 3.0
episodes_this_iter: 101
episodes_total: 12144
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5462688207626343
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 11.107321739196777
        total_loss: 34.2066764831543
        var_gnorm: 64.35647583007812
        vf_explained_var: 0.8968284726142883
        vf_loss: 51.66139602661133
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3075.0
  learner_queue:
    size_count: 3079
    size_mean: 15.24
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4221111067704943
  num_agent_steps_sampled: 1554300
  num_agent_steps_trained: 1537500
  num_env_steps_sampled: 1554300
  num_env_steps_trained: 1537500
  num_samples_added_to_queue: 1554000
  num_training_step_calls_since_last_synch_worker_weights: 1143
  num_weight_broadcasts: 30537
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 288.308
    learner_load_time_ms: 8.4
    learner_load_wait_time_ms: 1.754
iterations_since_restore: 135
node_ip: 127.0.0.1
num_agent_steps_sampled: 1554300
num_agent_steps_trained: 1537500
num_env_steps_sampled: 1554300
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9964938259054
num_env_steps_trained: 1537500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9964666462613
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 55.08571428571429
  ram_util_percent: 82.85714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06977819333536843
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027358040987401504
  mean_inference_ms: 1.3056015139787231
  mean_raw_obs_processing_ms: 0.29607587640317334
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021108778396455367
    StateBufferConnector_ms: 0.0036978485560653232
    ViewRequirementAgentConnector_ms: 0.1273589559120707
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.405940594059405
  episode_reward_min: 3.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 10.0, 6.0, 8.0, 5.0, 5.0, 9.0, 9.0, 12.0, 7.0, 12.0, 4.0,
      7.0, 9.0, 11.0, 11.0, 13.0, 9.0, 6.0, 10.0, 3.0, 12.0, 7.0, 8.0, 9.0, 11.0,
      5.0, 5.0, 11.0, 6.0, 9.0, 7.0, 8.0, 8.0, 8.0, 12.0, 8.0, 8.0, 8.0, 6.0, 7.0,
      7.0, 13.0, 6.0, 8.0, 6.0, 10.0, 11.0, 10.0, 10.0, 10.0, 6.0, 6.0, 8.0, 11.0,
      7.0, 7.0, 8.0, 7.0, 9.0, 9.0, 12.0, 8.0, 14.0, 11.0, 8.0, 10.0, 6.0, 9.0, 7.0,
      9.0, 6.0, 9.0, 12.0, 8.0, 7.0, 10.0, 10.0, 15.0, 9.0, 8.0, 8.0, 4.0, 14.0, 8.0,
      11.0, 6.0, 8.0, 9.0, 8.0, 10.0, 6.0, 5.0, 8.0, 8.0, 6.0, 7.0, 11.0, 5.0, 5.0,
      10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06977819333536843
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027358040987401504
    mean_inference_ms: 1.3056015139787231
    mean_raw_obs_processing_ms: 0.29607587640317334
time_since_restore: 1372.6456532478333
time_this_iter_s: 10.096540927886963
time_total_s: 1372.6456532478333
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995551
timesteps_total: 1554300
training_iteration: 135
trial_id: default
train step: 136
agent_timesteps_total: 1566650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021104812622070312
  StateBufferConnector_ms: 0.0036988258361816406
  ViewRequirementAgentConnector_ms: 0.12626361846923828
counters:
  num_agent_steps_sampled: 1566650
  num_agent_steps_trained: 1550000
  num_env_steps_sampled: 1566650
  num_env_steps_trained: 1550000
  num_samples_added_to_queue: 1566500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 30779
custom_metrics: {}
date: 2023-08-14_15-46-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.34
episode_reward_min: 3.0
episodes_this_iter: 96
episodes_total: 12240
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7315078377723694
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.877591133117676
        total_loss: 12.285175323486328
        var_gnorm: 64.36246490478516
        vf_explained_var: 0.9340924024581909
        vf_loss: 61.64060974121094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3100.0
  learner_queue:
    size_count: 3104
    size_mean: 15.48
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.0438390680559912
  num_agent_steps_sampled: 1566650
  num_agent_steps_trained: 1550000
  num_env_steps_sampled: 1566650
  num_env_steps_trained: 1550000
  num_samples_added_to_queue: 1566500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 30779
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 270.791
    learner_load_time_ms: 1.66
    learner_load_wait_time_ms: 1.582
iterations_since_restore: 136
node_ip: 127.0.0.1
num_agent_steps_sampled: 1566650
num_agent_steps_trained: 1550000
num_env_steps_sampled: 1566650
num_env_steps_sampled_this_iter: 12350
num_env_steps_sampled_throughput_per_sec: 1234.6703368877695
num_env_steps_trained: 1550000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.666332882358
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 57.05714285714286
  ram_util_percent: 82.80714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06976288120316318
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02734687492974268
  mean_inference_ms: 1.304834330451726
  mean_raw_obs_processing_ms: 0.2959159705165423
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021104812622070312
    StateBufferConnector_ms: 0.0036988258361816406
    ViewRequirementAgentConnector_ms: 0.12626361846923828
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.34
  episode_reward_min: 3.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 5.0, 5.0, 10.0, 7.0, 10.0, 7.0, 11.0, 7.0, 11.0, 8.0, 3.0,
      9.0, 4.0, 6.0, 10.0, 5.0, 8.0, 12.0, 7.0, 10.0, 8.0, 7.0, 11.0, 6.0, 11.0, 6.0,
      7.0, 9.0, 7.0, 12.0, 7.0, 12.0, 10.0, 13.0, 11.0, 14.0, 12.0, 6.0, 11.0, 9.0,
      10.0, 6.0, 4.0, 7.0, 11.0, 8.0, 7.0, 12.0, 7.0, 6.0, 10.0, 8.0, 9.0, 15.0, 9.0,
      10.0, 7.0, 5.0, 7.0, 3.0, 11.0, 9.0, 12.0, 8.0, 11.0, 8.0, 5.0, 13.0, 4.0, 9.0,
      4.0, 4.0, 8.0, 13.0, 13.0, 7.0, 5.0, 9.0, 11.0, 6.0, 6.0, 9.0, 10.0, 10.0, 9.0,
      11.0, 3.0, 8.0, 8.0, 5.0, 12.0, 6.0, 8.0, 6.0, 7.0, 11.0, 6.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06976288120316318
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02734687492974268
    mean_inference_ms: 1.304834330451726
    mean_raw_obs_processing_ms: 0.2959159705165423
time_since_restore: 1382.748262166977
time_this_iter_s: 10.102608919143677
time_total_s: 1382.748262166977
timers:
  sample_time_ms: 0.04
  synch_weights_time_ms: 0.261
  training_iteration_time_ms: 0.367
timestamp: 1691995561
timesteps_total: 1566650
training_iteration: 136
trial_id: default
train step: 137
agent_timesteps_total: 1579900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019281873336205117
  StateBufferConnector_ms: 0.003422223604642428
  ViewRequirementAgentConnector_ms: 0.11748098410092868
counters:
  num_agent_steps_sampled: 1579900
  num_agent_steps_trained: 1563000
  num_env_steps_sampled: 1579900
  num_env_steps_trained: 1563000
  num_samples_added_to_queue: 1579500
  num_training_step_calls_since_last_synch_worker_weights: 1153
  num_weight_broadcasts: 31040
custom_metrics: {}
date: 2023-08-14_15-46-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 5.836538461538462
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 12344
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4501945972442627
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -4.809582710266113
        total_loss: 19.813404083251953
        var_gnorm: 64.3718032836914
        vf_explained_var: 0.9541412591934204
        vf_loss: 53.747920989990234
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3126.0
  learner_queue:
    size_count: 3130
    size_mean: 15.62
    size_quantiles: [13.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.845931439302264
  num_agent_steps_sampled: 1579900
  num_agent_steps_trained: 1563000
  num_env_steps_sampled: 1579900
  num_env_steps_trained: 1563000
  num_samples_added_to_queue: 1579500
  num_training_step_calls_since_last_synch_worker_weights: 1153
  num_weight_broadcasts: 31040
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 266.481
    learner_load_time_ms: 1.663
    learner_load_wait_time_ms: 1.649
iterations_since_restore: 137
node_ip: 127.0.0.1
num_agent_steps_sampled: 1579900
num_agent_steps_trained: 1563000
num_env_steps_sampled: 1579900
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.9943137412913
num_env_steps_trained: 1563000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9944210291915
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.214285714285715
  ram_util_percent: 81.75714285714285
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06966648778411398
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027311877790178136
  mean_inference_ms: 1.3033250663819111
  mean_raw_obs_processing_ms: 0.2955888767635355
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019281873336205117
    StateBufferConnector_ms: 0.003422223604642428
    ViewRequirementAgentConnector_ms: 0.11748098410092868
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 5.836538461538462
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 3.0, 7.0, 2.0, 7.0, 12.0, 7.0, 8.0, 4.0, 5.0, 5.0, 6.0,
      6.0, 5.0, 4.0, 8.0, 6.0, 6.0, 10.0, 7.0, 3.0, 5.0, 6.0, 7.0, 9.0, 7.0, 12.0,
      4.0, 5.0, 4.0, 4.0, 3.0, 4.0, 3.0, 3.0, 5.0, 11.0, 5.0, 6.0, 5.0, 5.0, 3.0,
      7.0, 5.0, 4.0, 7.0, 2.0, 5.0, 8.0, 3.0, 6.0, 0.0, 13.0, 10.0, 9.0, 2.0, 7.0,
      6.0, 11.0, 14.0, 11.0, 8.0, 5.0, 9.0, 5.0, 7.0, 6.0, 7.0, 8.0, 10.0, 7.0, 1.0,
      5.0, 6.0, 6.0, 7.0, 4.0, 7.0, 5.0, 4.0, 5.0, 6.0, 2.0, 5.0, 3.0, 5.0, 2.0, 1.0,
      5.0, 7.0, 8.0, 8.0, 9.0, 2.0, 5.0, 2.0, 5.0, 5.0, 1.0, 7.0, 3.0, 6.0, 5.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06966648778411398
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027311877790178136
    mean_inference_ms: 1.3033250663819111
    mean_raw_obs_processing_ms: 0.2955888767635355
time_since_restore: 1392.8524742126465
time_this_iter_s: 10.104212045669556
time_total_s: 1392.8524742126465
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691995572
timesteps_total: 1579900
training_iteration: 137
trial_id: default
train step: 138
agent_timesteps_total: 1593200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019647754155672513
  StateBufferConnector_ms: 0.003430935052724985
  ViewRequirementAgentConnector_ms: 0.11858940124511719
counters:
  num_agent_steps_sampled: 1593200
  num_agent_steps_trained: 1576500
  num_env_steps_sampled: 1593200
  num_env_steps_trained: 1576500
  num_samples_added_to_queue: 1593000
  num_training_step_calls_since_last_synch_worker_weights: 861
  num_weight_broadcasts: 31303
custom_metrics: {}
date: 2023-08-14_15-46-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 5.211538461538462
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 12448
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5643757581710815
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 47.080841064453125
        total_loss: 120.57713317871094
        var_gnorm: 64.36946868896484
        vf_explained_var: 0.8254905343055725
        vf_loss: 152.63633728027344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3153.0
  learner_queue:
    size_count: 3158
    size_mean: 15.62
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9141115905621151
  num_agent_steps_sampled: 1593200
  num_agent_steps_trained: 1576500
  num_env_steps_sampled: 1593200
  num_env_steps_trained: 1576500
  num_samples_added_to_queue: 1593000
  num_training_step_calls_since_last_synch_worker_weights: 861
  num_weight_broadcasts: 31303
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 215.026
    learner_load_time_ms: 1.669
    learner_load_wait_time_ms: 1.692
iterations_since_restore: 138
node_ip: 127.0.0.1
num_agent_steps_sampled: 1593200
num_agent_steps_trained: 1576500
num_env_steps_sampled: 1593200
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9969558785494
num_env_steps_trained: 1576500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.996910102287
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.47333333333333
  ram_util_percent: 81.37333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06958589444479545
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027275696067984155
  mean_inference_ms: 1.3018122159635046
  mean_raw_obs_processing_ms: 0.29527124675217087
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019647754155672513
    StateBufferConnector_ms: 0.003430935052724985
    ViewRequirementAgentConnector_ms: 0.11858940124511719
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 5.211538461538462
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 9.0, 3.0, 8.0, 6.0, 1.0, 5.0, 7.0, 4.0, 2.0, 7.0, 5.0, 10.0,
      3.0, 5.0, 3.0, 4.0, 9.0, 5.0, 8.0, 6.0, 5.0, 3.0, 7.0, 2.0, 4.0, 4.0, 4.0, 8.0,
      3.0, 9.0, 6.0, 7.0, 3.0, 4.0, 9.0, 2.0, 6.0, 9.0, 8.0, 5.0, 3.0, 10.0, 3.0,
      4.0, 6.0, 7.0, 4.0, 3.0, 7.0, 6.0, 6.0, 4.0, 4.0, 7.0, 2.0, 5.0, 4.0, 9.0, 2.0,
      6.0, 6.0, 4.0, 7.0, 5.0, 3.0, 8.0, 2.0, 5.0, 7.0, 4.0, 6.0, 2.0, 3.0, 3.0, 3.0,
      10.0, 0.0, 5.0, 5.0, 8.0, 7.0, 2.0, 2.0, 5.0, 3.0, 3.0, 3.0, 8.0, 5.0, 6.0,
      8.0, 4.0, 5.0, 4.0, 7.0, 10.0, 6.0, 8.0, 4.0, 4.0, 6.0, 10.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06958589444479545
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027275696067984155
    mean_inference_ms: 1.3018122159635046
    mean_raw_obs_processing_ms: 0.29527124675217087
time_since_restore: 1402.9628691673279
time_this_iter_s: 10.110394954681396
time_total_s: 1402.9628691673279
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995582
timesteps_total: 1593200
training_iteration: 138
trial_id: default
train step: 139
agent_timesteps_total: 1606800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019397600641790427
  StateBufferConnector_ms: 0.0035589596010603994
  ViewRequirementAgentConnector_ms: 0.11923650525650888
counters:
  num_agent_steps_sampled: 1606800
  num_agent_steps_trained: 1590000
  num_env_steps_sampled: 1606800
  num_env_steps_trained: 1590000
  num_samples_added_to_queue: 1606500
  num_training_step_calls_since_last_synch_worker_weights: 836
  num_weight_broadcasts: 31568
custom_metrics: {}
date: 2023-08-14_15-46-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 5.216981132075472
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 12554
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.639883816242218
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 63.86515808105469
        total_loss: 165.67642211914062
        var_gnorm: 64.37014770507812
        vf_explained_var: 0.7858695387840271
        vf_loss: 210.0213623046875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3180.0
  learner_queue:
    size_count: 3185
    size_mean: 15.52
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.0814804667676619
  num_agent_steps_sampled: 1606800
  num_agent_steps_trained: 1590000
  num_env_steps_sampled: 1606800
  num_env_steps_trained: 1590000
  num_samples_added_to_queue: 1606500
  num_training_step_calls_since_last_synch_worker_weights: 836
  num_weight_broadcasts: 31568
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 218.412
    learner_load_time_ms: 1.59
    learner_load_wait_time_ms: 1.691
iterations_since_restore: 139
node_ip: 127.0.0.1
num_agent_steps_sampled: 1606800
num_agent_steps_trained: 1590000
num_env_steps_sampled: 1606800
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9942932368372
num_env_steps_trained: 1590000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.994335198331
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.42142857142857
  ram_util_percent: 80.76428571428572
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06949282728749828
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02723149253596925
  mean_inference_ms: 1.3001002379130178
  mean_raw_obs_processing_ms: 0.294894924713705
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019397600641790427
    StateBufferConnector_ms: 0.0035589596010603994
    ViewRequirementAgentConnector_ms: 0.11923650525650888
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 5.216981132075472
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 6.0, 8.0, 4.0, 9.0, 8.0, 4.0, 4.0, 5.0, 4.0, 4.0, 3.0, 3.0,
      7.0, 5.0, 4.0, 1.0, 3.0, 5.0, 9.0, 5.0, 3.0, 8.0, 3.0, 6.0, 4.0, 5.0, 9.0, 4.0,
      8.0, 0.0, 6.0, 6.0, 4.0, 4.0, 6.0, 4.0, 3.0, 7.0, 5.0, 7.0, 3.0, 10.0, 1.0,
      8.0, 5.0, 3.0, 6.0, 5.0, 5.0, 4.0, 5.0, 5.0, 7.0, 6.0, 6.0, 2.0, 5.0, 7.0, 5.0,
      6.0, 2.0, 5.0, 5.0, 4.0, 2.0, 3.0, 9.0, 3.0, 9.0, 5.0, 4.0, 8.0, 2.0, 6.0, 4.0,
      5.0, 4.0, 5.0, 4.0, 5.0, 6.0, 8.0, 8.0, 6.0, 5.0, 7.0, 4.0, 5.0, 9.0, 5.0, 7.0,
      6.0, 5.0, 4.0, 8.0, 4.0, 6.0, 6.0, 6.0, 8.0, 4.0, 5.0, 4.0, 4.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06949282728749828
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02723149253596925
    mean_inference_ms: 1.3001002379130178
    mean_raw_obs_processing_ms: 0.294894924713705
time_since_restore: 1413.0744032859802
time_this_iter_s: 10.111534118652344
time_total_s: 1413.0744032859802
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995592
timesteps_total: 1606800
training_iteration: 139
trial_id: default
train step: 140
agent_timesteps_total: 1619950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019865128600481643
  StateBufferConnector_ms: 0.003605907403149651
  ViewRequirementAgentConnector_ms: 0.11881346841460293
counters:
  num_agent_steps_sampled: 1619950
  num_agent_steps_trained: 1603000
  num_env_steps_sampled: 1619950
  num_env_steps_trained: 1603000
  num_samples_added_to_queue: 1619500
  num_training_step_calls_since_last_synch_worker_weights: 406
  num_weight_broadcasts: 31828
custom_metrics: {}
date: 2023-08-14_15-46-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 5.961165048543689
episode_reward_min: 1.0
episodes_this_iter: 103
episodes_total: 12657
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7392644286155701
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -28.133682250976562
        total_loss: 12.17866325378418
        var_gnorm: 64.37715911865234
        vf_explained_var: 0.8972487449645996
        vf_loss: 88.017333984375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3206.0
  learner_queue:
    size_count: 3212
    size_mean: 15.42
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.250439922587247
  num_agent_steps_sampled: 1619950
  num_agent_steps_trained: 1603000
  num_env_steps_sampled: 1619950
  num_env_steps_trained: 1603000
  num_samples_added_to_queue: 1619500
  num_training_step_calls_since_last_synch_worker_weights: 406
  num_weight_broadcasts: 31828
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 195.89
    learner_load_time_ms: 1.595
    learner_load_wait_time_ms: 1.588
iterations_since_restore: 140
node_ip: 127.0.0.1
num_agent_steps_sampled: 1619950
num_agent_steps_trained: 1603000
num_env_steps_sampled: 1619950
num_env_steps_sampled_this_iter: 13150
num_env_steps_sampled_throughput_per_sec: 1314.9923814976523
num_env_steps_trained: 1603000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.992468400721
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.15714285714285
  ram_util_percent: 80.92142857142856
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06942579417652062
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02720035768839736
  mean_inference_ms: 1.2987560476040112
  mean_raw_obs_processing_ms: 0.29461083133419863
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019865128600481643
    StateBufferConnector_ms: 0.003605907403149651
    ViewRequirementAgentConnector_ms: 0.11881346841460293
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 5.961165048543689
  episode_reward_min: 1.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 5.0, 9.0, 6.0, 6.0, 4.0, 6.0, 11.0, 8.0, 4.0, 5.0, 6.0,
      6.0, 9.0, 6.0, 6.0, 8.0, 8.0, 10.0, 7.0, 5.0, 5.0, 5.0, 3.0, 4.0, 7.0, 3.0,
      8.0, 3.0, 5.0, 7.0, 4.0, 5.0, 7.0, 9.0, 8.0, 5.0, 7.0, 3.0, 5.0, 2.0, 7.0, 6.0,
      6.0, 5.0, 5.0, 7.0, 7.0, 2.0, 7.0, 3.0, 6.0, 7.0, 6.0, 4.0, 6.0, 2.0, 6.0, 7.0,
      2.0, 7.0, 5.0, 6.0, 10.0, 8.0, 7.0, 8.0, 5.0, 3.0, 3.0, 8.0, 6.0, 5.0, 7.0,
      5.0, 6.0, 8.0, 4.0, 9.0, 2.0, 6.0, 7.0, 6.0, 8.0, 5.0, 8.0, 9.0, 4.0, 1.0, 8.0,
      6.0, 8.0, 6.0, 5.0, 8.0, 2.0, 8.0, 7.0, 5.0, 4.0, 8.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06942579417652062
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02720035768839736
    mean_inference_ms: 1.2987560476040112
    mean_raw_obs_processing_ms: 0.29461083133419863
time_since_restore: 1423.2071752548218
time_this_iter_s: 10.132771968841553
time_total_s: 1423.2071752548218
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995602
timesteps_total: 1619950
training_iteration: 140
trial_id: default
train step: 141
agent_timesteps_total: 1633550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019244427950877063
  StateBufferConnector_ms: 0.0034096106043401755
  ViewRequirementAgentConnector_ms: 0.11648839374758163
counters:
  num_agent_steps_sampled: 1633550
  num_agent_steps_trained: 1617000
  num_env_steps_sampled: 1633550
  num_env_steps_trained: 1617000
  num_samples_added_to_queue: 1633500
  num_training_step_calls_since_last_synch_worker_weights: 269
  num_weight_broadcasts: 32097
custom_metrics: {}
date: 2023-08-14_15-46-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.886792452830188
episode_reward_min: 1.0
episodes_this_iter: 106
episodes_total: 12763
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.834139347076416
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.061934471130371
        total_loss: 38.93915939331055
        var_gnorm: 64.38267517089844
        vf_explained_var: 0.8693039417266846
        vf_loss: 70.09584045410156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3234.0
  learner_queue:
    size_count: 3240
    size_mean: 15.28
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4427751037497147
  num_agent_steps_sampled: 1633550
  num_agent_steps_trained: 1617000
  num_env_steps_sampled: 1633550
  num_env_steps_trained: 1617000
  num_samples_added_to_queue: 1633500
  num_training_step_calls_since_last_synch_worker_weights: 269
  num_weight_broadcasts: 32097
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 171.944
    learner_load_time_ms: 1.46
    learner_load_wait_time_ms: 1.579
iterations_since_restore: 141
node_ip: 127.0.0.1
num_agent_steps_sampled: 1633550
num_agent_steps_trained: 1617000
num_env_steps_sampled: 1633550
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9982166313669
num_env_steps_trained: 1617000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9981641793481
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.48571428571429
  ram_util_percent: 80.22857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06933326867794157
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02715988049749038
  mean_inference_ms: 1.2971151223946735
  mean_raw_obs_processing_ms: 0.29426693926419045
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019244427950877063
    StateBufferConnector_ms: 0.0034096106043401755
    ViewRequirementAgentConnector_ms: 0.11648839374758163
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.886792452830188
  episode_reward_min: 1.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 8.0, 6.0, 7.0, 8.0, 5.0, 9.0, 6.0, 7.0, 8.0, 3.0, 2.0, 1.0,
      8.0, 5.0, 7.0, 6.0, 10.0, 10.0, 1.0, 2.0, 7.0, 9.0, 6.0, 10.0, 6.0, 9.0, 9.0,
      9.0, 7.0, 9.0, 5.0, 6.0, 7.0, 11.0, 4.0, 5.0, 7.0, 10.0, 3.0, 7.0, 9.0, 5.0,
      8.0, 7.0, 7.0, 8.0, 5.0, 5.0, 10.0, 9.0, 3.0, 6.0, 3.0, 4.0, 8.0, 7.0, 7.0,
      5.0, 9.0, 4.0, 8.0, 6.0, 5.0, 8.0, 9.0, 6.0, 5.0, 7.0, 6.0, 5.0, 7.0, 7.0, 6.0,
      8.0, 5.0, 9.0, 8.0, 5.0, 4.0, 10.0, 3.0, 4.0, 8.0, 10.0, 8.0, 9.0, 9.0, 9.0,
      11.0, 6.0, 5.0, 10.0, 6.0, 11.0, 8.0, 9.0, 4.0, 13.0, 10.0, 7.0, 7.0, 6.0, 7.0,
      9.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06933326867794157
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02715988049749038
    mean_inference_ms: 1.2971151223946735
    mean_raw_obs_processing_ms: 0.29426693926419045
time_since_restore: 1433.341715335846
time_this_iter_s: 10.13454008102417
time_total_s: 1433.341715335846
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995612
timesteps_total: 1633550
training_iteration: 141
trial_id: default
train step: 142
agent_timesteps_total: 1646100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021358489990234375
  StateBufferConnector_ms: 0.003796815872192383
  ViewRequirementAgentConnector_ms: 0.12554025650024414
counters:
  num_agent_steps_sampled: 1646100
  num_agent_steps_trained: 1629500
  num_env_steps_sampled: 1646100
  num_env_steps_trained: 1629500
  num_samples_added_to_queue: 1646000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 32342
custom_metrics: {}
date: 2023-08-14_15-47-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.58
episode_reward_min: 2.0
episodes_this_iter: 97
episodes_total: 12860
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7630489468574524
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.0050127506256104
        total_loss: 14.677978515625
        var_gnorm: 64.39248657226562
        vf_explained_var: 0.8870447278022766
        vf_loss: 40.9964714050293
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3259.0
  learner_queue:
    size_count: 3262
    size_mean: 15.38
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2789057822998533
  num_agent_steps_sampled: 1646100
  num_agent_steps_trained: 1629500
  num_env_steps_sampled: 1646100
  num_env_steps_trained: 1629500
  num_samples_added_to_queue: 1646000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 32342
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 284.158
    learner_load_time_ms: 1.459
    learner_load_wait_time_ms: 1.595
iterations_since_restore: 142
node_ip: 127.0.0.1
num_agent_steps_sampled: 1646100
num_agent_steps_trained: 1629500
num_env_steps_sampled: 1646100
num_env_steps_sampled_this_iter: 12550
num_env_steps_sampled_throughput_per_sec: 1254.9802820204293
num_env_steps_trained: 1629500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.980360578117
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.66000000000001
  ram_util_percent: 80.62666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06930086637900504
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02714572675806953
  mean_inference_ms: 1.2963073916998824
  mean_raw_obs_processing_ms: 0.2940987151928303
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021358489990234375
    StateBufferConnector_ms: 0.003796815872192383
    ViewRequirementAgentConnector_ms: 0.12554025650024414
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.58
  episode_reward_min: 2.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 9.0, 8.0, 8.0, 5.0, 9.0, 8.0, 10.0, 7.0, 6.0, 8.0, 10.0,
      9.0, 8.0, 8.0, 8.0, 5.0, 7.0, 8.0, 4.0, 9.0, 7.0, 9.0, 4.0, 8.0, 6.0, 3.0, 8.0,
      5.0, 10.0, 5.0, 9.0, 8.0, 6.0, 6.0, 14.0, 10.0, 10.0, 9.0, 9.0, 5.0, 6.0, 9.0,
      7.0, 8.0, 11.0, 3.0, 2.0, 6.0, 7.0, 11.0, 7.0, 7.0, 13.0, 7.0, 7.0, 9.0, 9.0,
      9.0, 5.0, 4.0, 7.0, 6.0, 3.0, 12.0, 3.0, 7.0, 3.0, 6.0, 7.0, 13.0, 5.0, 9.0,
      6.0, 4.0, 5.0, 10.0, 7.0, 12.0, 9.0, 6.0, 6.0, 9.0, 9.0, 6.0, 11.0, 8.0, 11.0,
      7.0, 8.0, 10.0, 11.0, 9.0, 11.0, 10.0, 7.0, 4.0, 6.0, 11.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06930086637900504
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02714572675806953
    mean_inference_ms: 1.2963073916998824
    mean_raw_obs_processing_ms: 0.2940987151928303
time_since_restore: 1443.4234495162964
time_this_iter_s: 10.08173418045044
time_total_s: 1443.4234495162964
timers:
  sample_time_ms: 0.038
  synch_weights_time_ms: 0.271
  training_iteration_time_ms: 0.384
timestamp: 1691995622
timesteps_total: 1646100
training_iteration: 142
trial_id: default
train step: 143
agent_timesteps_total: 1659250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019572545023797787
  StateBufferConnector_ms: 0.00346956901179934
  ViewRequirementAgentConnector_ms: 0.11896392674122042
counters:
  num_agent_steps_sampled: 1659250
  num_agent_steps_trained: 1642500
  num_env_steps_sampled: 1659250
  num_env_steps_trained: 1642500
  num_samples_added_to_queue: 1659000
  num_training_step_calls_since_last_synch_worker_weights: 1311
  num_weight_broadcasts: 32601
custom_metrics: {}
date: 2023-08-14_15-47-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.048543689320388
episode_reward_min: 4.0
episodes_this_iter: 103
episodes_total: 12963
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.520891547203064
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.409682273864746
        total_loss: 24.85543441772461
        var_gnorm: 64.40520477294922
        vf_explained_var: 0.8596838712692261
        vf_loss: 52.10041809082031
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3285.0
  learner_queue:
    size_count: 3289
    size_mean: 15.5
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.118033988749895
  num_agent_steps_sampled: 1659250
  num_agent_steps_trained: 1642500
  num_env_steps_sampled: 1659250
  num_env_steps_trained: 1642500
  num_samples_added_to_queue: 1659000
  num_training_step_calls_since_last_synch_worker_weights: 1311
  num_weight_broadcasts: 32601
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 251.872
    learner_load_time_ms: 6.422
    learner_load_wait_time_ms: 1.57
iterations_since_restore: 143
node_ip: 127.0.0.1
num_agent_steps_sampled: 1659250
num_agent_steps_trained: 1642500
num_env_steps_sampled: 1659250
num_env_steps_sampled_this_iter: 13150
num_env_steps_sampled_throughput_per_sec: 1314.9946074706916
num_env_steps_trained: 1642500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9946689824328
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.21428571428572
  ram_util_percent: 80.45
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.069224532472866
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02711788066596702
  mean_inference_ms: 1.294963208890106
  mean_raw_obs_processing_ms: 0.2938069885336198
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019572545023797787
    StateBufferConnector_ms: 0.00346956901179934
    ViewRequirementAgentConnector_ms: 0.11896392674122042
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.048543689320388
  episode_reward_min: 4.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 7.0, 8.0, 6.0, 6.0, 10.0, 7.0, 12.0, 9.0, 11.0, 7.0, 7.0,
      8.0, 9.0, 7.0, 8.0, 11.0, 9.0, 12.0, 7.0, 9.0, 13.0, 6.0, 9.0, 7.0, 9.0, 10.0,
      7.0, 8.0, 11.0, 15.0, 11.0, 7.0, 12.0, 12.0, 13.0, 9.0, 7.0, 7.0, 7.0, 12.0,
      5.0, 5.0, 11.0, 8.0, 9.0, 9.0, 16.0, 5.0, 10.0, 8.0, 7.0, 6.0, 5.0, 7.0, 7.0,
      9.0, 12.0, 9.0, 7.0, 9.0, 9.0, 7.0, 8.0, 11.0, 7.0, 7.0, 4.0, 8.0, 11.0, 6.0,
      8.0, 11.0, 12.0, 10.0, 10.0, 8.0, 7.0, 11.0, 13.0, 10.0, 8.0, 10.0, 11.0, 5.0,
      13.0, 10.0, 9.0, 15.0, 10.0, 8.0, 12.0, 7.0, 10.0, 14.0, 8.0, 8.0, 11.0, 9.0,
      10.0, 12.0, 13.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.069224532472866
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02711788066596702
    mean_inference_ms: 1.294963208890106
    mean_raw_obs_processing_ms: 0.2938069885336198
time_since_restore: 1453.5072705745697
time_this_iter_s: 10.083821058273315
time_total_s: 1453.5072705745697
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995632
timesteps_total: 1659250
training_iteration: 143
trial_id: default
train step: 144
agent_timesteps_total: 1671850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021342039108276367
  StateBufferConnector_ms: 0.003978729248046875
  ViewRequirementAgentConnector_ms: 0.12956976890563965
counters:
  num_agent_steps_sampled: 1671850
  num_agent_steps_trained: 1655000
  num_env_steps_sampled: 1671850
  num_env_steps_trained: 1655000
  num_samples_added_to_queue: 1671500
  num_training_step_calls_since_last_synch_worker_weights: 710
  num_weight_broadcasts: 32849
custom_metrics: {}
date: 2023-08-14_15-47-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.24
episode_reward_min: 2.0
episodes_this_iter: 99
episodes_total: 13062
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.660598635673523
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 6.817276954650879
        total_loss: 71.64462280273438
        var_gnorm: 64.42242431640625
        vf_explained_var: 0.708808183670044
        vf_loss: 136.26068115234375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3310.0
  learner_queue:
    size_count: 3315
    size_mean: 15.64
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9112628599915613
  num_agent_steps_sampled: 1671850
  num_agent_steps_trained: 1655000
  num_env_steps_sampled: 1671850
  num_env_steps_trained: 1655000
  num_samples_added_to_queue: 1671500
  num_training_step_calls_since_last_synch_worker_weights: 710
  num_weight_broadcasts: 32849
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 227.735
    learner_load_time_ms: 6.436
    learner_load_wait_time_ms: 1.778
iterations_since_restore: 144
node_ip: 127.0.0.1
num_agent_steps_sampled: 1671850
num_agent_steps_trained: 1655000
num_env_steps_sampled: 1671850
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.995073337745
num_env_steps_trained: 1655000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9951124382392
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.82142857142856
  ram_util_percent: 80.89999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06918271720182693
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02710473478757314
  mean_inference_ms: 1.2941523679506433
  mean_raw_obs_processing_ms: 0.29363646653288095
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021342039108276367
    StateBufferConnector_ms: 0.003978729248046875
    ViewRequirementAgentConnector_ms: 0.12956976890563965
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.24
  episode_reward_min: 2.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 9.0, 7.0, 10.0, 4.0, 8.0, 12.0, 8.0, 8.0, 11.0, 13.0,
      12.0, 9.0, 9.0, 13.0, 11.0, 11.0, 6.0, 9.0, 12.0, 5.0, 11.0, 12.0, 7.0, 12.0,
      7.0, 10.0, 9.0, 7.0, 11.0, 2.0, 15.0, 9.0, 10.0, 4.0, 9.0, 14.0, 7.0, 9.0, 4.0,
      12.0, 14.0, 3.0, 6.0, 7.0, 10.0, 9.0, 9.0, 8.0, 11.0, 11.0, 10.0, 7.0, 6.0,
      9.0, 14.0, 10.0, 9.0, 6.0, 17.0, 10.0, 11.0, 9.0, 11.0, 14.0, 8.0, 10.0, 5.0,
      12.0, 8.0, 10.0, 7.0, 9.0, 6.0, 10.0, 7.0, 7.0, 6.0, 8.0, 7.0, 8.0, 10.0, 13.0,
      10.0, 7.0, 11.0, 10.0, 9.0, 15.0, 8.0, 8.0, 11.0, 9.0, 12.0, 15.0, 10.0, 9.0,
      6.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06918271720182693
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02710473478757314
    mean_inference_ms: 1.2941523679506433
    mean_raw_obs_processing_ms: 0.29363646653288095
time_since_restore: 1463.6302354335785
time_this_iter_s: 10.122964859008789
time_total_s: 1463.6302354335785
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691995642
timesteps_total: 1671850
training_iteration: 144
trial_id: default
train step: 145
agent_timesteps_total: 1685250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019581204368954615
  StateBufferConnector_ms: 0.0035092944190615698
  ViewRequirementAgentConnector_ms: 0.11770589011056083
counters:
  num_agent_steps_sampled: 1685250
  num_agent_steps_trained: 1668500
  num_env_steps_sampled: 1685250
  num_env_steps_trained: 1668500
  num_samples_added_to_queue: 1685000
  num_training_step_calls_since_last_synch_worker_weights: 334
  num_weight_broadcasts: 33112
custom_metrics: {}
date: 2023-08-14_15-47-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.514285714285714
episode_reward_min: 3.0
episodes_this_iter: 105
episodes_total: 13167
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5796191692352295
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.4967269897460938
        total_loss: 25.864988327026367
        var_gnorm: 64.43397521972656
        vf_explained_var: 0.8818997144699097
        vf_loss: 50.53271484375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3337.0
  learner_queue:
    size_count: 3343
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3078226179417451
  num_agent_steps_sampled: 1685250
  num_agent_steps_trained: 1668500
  num_env_steps_sampled: 1685250
  num_env_steps_trained: 1668500
  num_samples_added_to_queue: 1685000
  num_training_step_calls_since_last_synch_worker_weights: 334
  num_weight_broadcasts: 33112
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 178.53
    learner_load_time_ms: 6.437
    learner_load_wait_time_ms: 1.535
iterations_since_restore: 145
node_ip: 127.0.0.1
num_agent_steps_sampled: 1685250
num_agent_steps_trained: 1668500
num_env_steps_sampled: 1685250
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9971885740138
num_env_steps_trained: 1668500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.997167593223
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.221428571428575
  ram_util_percent: 80.74285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06911000200191186
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0270735351190483
  mean_inference_ms: 1.29272761627544
  mean_raw_obs_processing_ms: 0.29332650469108573
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019581204368954615
    StateBufferConnector_ms: 0.0035092944190615698
    ViewRequirementAgentConnector_ms: 0.11770589011056083
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.514285714285714
  episode_reward_min: 3.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 9.0, 5.0, 7.0, 15.0, 12.0, 5.0, 11.0, 7.0, 15.0, 10.0, 4.0,
      10.0, 13.0, 12.0, 5.0, 8.0, 7.0, 8.0, 13.0, 10.0, 8.0, 11.0, 4.0, 10.0, 7.0,
      8.0, 12.0, 13.0, 14.0, 11.0, 8.0, 7.0, 10.0, 9.0, 16.0, 16.0, 11.0, 12.0, 10.0,
      5.0, 15.0, 13.0, 9.0, 8.0, 6.0, 10.0, 6.0, 5.0, 7.0, 12.0, 7.0, 13.0, 13.0,
      12.0, 10.0, 8.0, 7.0, 11.0, 13.0, 11.0, 10.0, 5.0, 11.0, 6.0, 10.0, 11.0, 8.0,
      14.0, 10.0, 9.0, 10.0, 7.0, 8.0, 14.0, 14.0, 10.0, 6.0, 11.0, 12.0, 9.0, 13.0,
      11.0, 7.0, 9.0, 7.0, 10.0, 9.0, 9.0, 13.0, 11.0, 9.0, 9.0, 11.0, 7.0, 7.0, 8.0,
      8.0, 6.0, 5.0, 8.0, 13.0, 12.0, 8.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06911000200191186
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0270735351190483
    mean_inference_ms: 1.29272761627544
    mean_raw_obs_processing_ms: 0.29332650469108573
time_since_restore: 1473.7654705047607
time_this_iter_s: 10.135235071182251
time_total_s: 1473.7654705047607
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995652
timesteps_total: 1685250
training_iteration: 145
trial_id: default
train step: 146
agent_timesteps_total: 1697550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02098369598388672
  StateBufferConnector_ms: 0.0036160945892333984
  ViewRequirementAgentConnector_ms: 0.1277484893798828
counters:
  num_agent_steps_sampled: 1697550
  num_agent_steps_trained: 1681000
  num_env_steps_sampled: 1697550
  num_env_steps_trained: 1681000
  num_samples_added_to_queue: 1697500
  num_training_step_calls_since_last_synch_worker_weights: 658
  num_weight_broadcasts: 33354
custom_metrics: {}
date: 2023-08-14_15-47-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.32
episode_reward_min: 1.0
episodes_this_iter: 96
episodes_total: 13263
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6005786657333374
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 5.3191118240356445
        total_loss: 51.84666442871094
        var_gnorm: 64.4443359375
        vf_explained_var: 0.811738908290863
        vf_loss: 99.0608901977539
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3362.0
  learner_queue:
    size_count: 3366
    size_mean: 15.38
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2310970717209915
  num_agent_steps_sampled: 1697550
  num_agent_steps_trained: 1681000
  num_env_steps_sampled: 1697550
  num_env_steps_trained: 1681000
  num_samples_added_to_queue: 1697500
  num_training_step_calls_since_last_synch_worker_weights: 658
  num_weight_broadcasts: 33354
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 297.016
    learner_load_time_ms: 6.487
    learner_load_wait_time_ms: 1.601
iterations_since_restore: 146
node_ip: 127.0.0.1
num_agent_steps_sampled: 1697550
num_agent_steps_trained: 1681000
num_env_steps_sampled: 1697550
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.9982991242086
num_env_steps_trained: 1681000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9982714676917
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.32666666666666
  ram_util_percent: 80.83999999999997
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06908962113793679
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027059753339802536
  mean_inference_ms: 1.2921694068253864
  mean_raw_obs_processing_ms: 0.29317962538777964
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02098369598388672
    StateBufferConnector_ms: 0.0036160945892333984
    ViewRequirementAgentConnector_ms: 0.1277484893798828
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.32
  episode_reward_min: 1.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 12.0, 8.0, 3.0, 8.0, 8.0, 11.0, 7.0, 8.0, 9.0, 8.0, 11.0,
      7.0, 7.0, 1.0, 5.0, 6.0, 9.0, 6.0, 10.0, 8.0, 7.0, 7.0, 11.0, 9.0, 6.0, 11.0,
      4.0, 9.0, 8.0, 12.0, 8.0, 6.0, 8.0, 5.0, 7.0, 11.0, 13.0, 7.0, 8.0, 6.0, 8.0,
      9.0, 4.0, 7.0, 8.0, 10.0, 9.0, 8.0, 13.0, 10.0, 8.0, 9.0, 6.0, 15.0, 9.0, 5.0,
      9.0, 10.0, 6.0, 6.0, 8.0, 8.0, 10.0, 9.0, 8.0, 10.0, 11.0, 4.0, 6.0, 10.0, 7.0,
      5.0, 2.0, 12.0, 8.0, 8.0, 11.0, 5.0, 4.0, 8.0, 7.0, 12.0, 12.0, 13.0, 9.0, 9.0,
      10.0, 11.0, 8.0, 8.0, 10.0, 12.0, 14.0, 3.0, 12.0, 10.0, 7.0, 8.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06908962113793679
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027059753339802536
    mean_inference_ms: 1.2921694068253864
    mean_raw_obs_processing_ms: 0.29317962538777964
time_since_restore: 1483.8757677078247
time_this_iter_s: 10.110297203063965
time_total_s: 1483.8757677078247
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691995663
timesteps_total: 1697550
training_iteration: 146
trial_id: default
train step: 147
agent_timesteps_total: 1710250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020990610122680664
  StateBufferConnector_ms: 0.0037751197814941406
  ViewRequirementAgentConnector_ms: 0.12505292892456055
counters:
  num_agent_steps_sampled: 1710250
  num_agent_steps_trained: 1693500
  num_env_steps_sampled: 1710250
  num_env_steps_trained: 1693500
  num_samples_added_to_queue: 1710000
  num_training_step_calls_since_last_synch_worker_weights: 538
  num_weight_broadcasts: 33605
custom_metrics: {}
date: 2023-08-14_15-47-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.35
episode_reward_min: 2.0
episodes_this_iter: 99
episodes_total: 13362
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6881952881813049
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -22.98055076599121
        total_loss: 11.485684394836426
        var_gnorm: 64.46258544921875
        vf_explained_var: 0.8559165000915527
        vf_loss: 75.81442260742188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3387.0
  learner_queue:
    size_count: 3392
    size_mean: 15.26
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3536617007214173
  num_agent_steps_sampled: 1710250
  num_agent_steps_trained: 1693500
  num_env_steps_sampled: 1710250
  num_env_steps_trained: 1693500
  num_samples_added_to_queue: 1710000
  num_training_step_calls_since_last_synch_worker_weights: 538
  num_weight_broadcasts: 33605
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 220.102
    learner_load_time_ms: 6.47
    learner_load_wait_time_ms: 1.72
iterations_since_restore: 147
node_ip: 127.0.0.1
num_agent_steps_sampled: 1710250
num_agent_steps_trained: 1693500
num_env_steps_sampled: 1710250
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.9966995801865
num_env_steps_trained: 1693500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9967515553017
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.67857142857142
  ram_util_percent: 81.42857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06903166752397785
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027048471860684195
  mean_inference_ms: 1.2913881508764138
  mean_raw_obs_processing_ms: 0.29300462546214723
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020990610122680664
    StateBufferConnector_ms: 0.0037751197814941406
    ViewRequirementAgentConnector_ms: 0.12505292892456055
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.35
  episode_reward_min: 2.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 8.0, 15.0, 10.0, 11.0, 10.0, 11.0, 13.0, 7.0, 11.0, 11.0,
      8.0, 11.0, 10.0, 6.0, 4.0, 7.0, 8.0, 12.0, 9.0, 9.0, 8.0, 6.0, 11.0, 14.0, 10.0,
      9.0, 11.0, 11.0, 11.0, 11.0, 10.0, 11.0, 11.0, 11.0, 12.0, 8.0, 8.0, 8.0, 12.0,
      4.0, 10.0, 10.0, 2.0, 4.0, 8.0, 11.0, 6.0, 14.0, 14.0, 9.0, 12.0, 8.0, 13.0,
      12.0, 6.0, 8.0, 9.0, 11.0, 8.0, 6.0, 9.0, 8.0, 12.0, 11.0, 8.0, 9.0, 9.0, 10.0,
      10.0, 9.0, 6.0, 5.0, 8.0, 4.0, 11.0, 15.0, 6.0, 9.0, 8.0, 5.0, 8.0, 8.0, 9.0,
      11.0, 8.0, 12.0, 9.0, 12.0, 16.0, 8.0, 8.0, 12.0, 6.0, 14.0, 9.0, 7.0, 13.0,
      8.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06903166752397785
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027048471860684195
    mean_inference_ms: 1.2913881508764138
    mean_raw_obs_processing_ms: 0.29300462546214723
time_since_restore: 1494.0434050559998
time_this_iter_s: 10.167637348175049
time_total_s: 1494.0434050559998
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995673
timesteps_total: 1710250
training_iteration: 147
trial_id: default
train step: 148
agent_timesteps_total: 1723000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020193099975585938
  StateBufferConnector_ms: 0.0036859512329101562
  ViewRequirementAgentConnector_ms: 0.12247371673583984
counters:
  num_agent_steps_sampled: 1723000
  num_agent_steps_trained: 1706500
  num_env_steps_sampled: 1723000
  num_env_steps_trained: 1706500
  num_samples_added_to_queue: 1723000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 33857
custom_metrics: {}
date: 2023-08-14_15-48-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.86
episode_reward_min: 4.0
episodes_this_iter: 99
episodes_total: 13461
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6148471236228943
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.6125309467315674
        total_loss: 37.809574127197266
        var_gnorm: 64.48406982421875
        vf_explained_var: 0.896970272064209
        vf_loss: 84.99267578125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3413.0
  learner_queue:
    size_count: 3415
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3453624047073711
  num_agent_steps_sampled: 1723000
  num_agent_steps_trained: 1706500
  num_env_steps_sampled: 1723000
  num_env_steps_trained: 1706500
  num_samples_added_to_queue: 1723000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 33857
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 322.988
    learner_load_time_ms: 6.472
    learner_load_wait_time_ms: 1.859
iterations_since_restore: 148
node_ip: 127.0.0.1
num_agent_steps_sampled: 1723000
num_agent_steps_trained: 1706500
num_env_steps_sampled: 1723000
num_env_steps_sampled_this_iter: 12750
num_env_steps_sampled_throughput_per_sec: 1274.3396032901499
num_env_steps_trained: 1706500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.3266543350546
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.199999999999996
  ram_util_percent: 81.25714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06899412696604652
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027032738491700615
  mean_inference_ms: 1.290470666061909
  mean_raw_obs_processing_ms: 0.2928264759882252
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020193099975585938
    StateBufferConnector_ms: 0.0036859512329101562
    ViewRequirementAgentConnector_ms: 0.12247371673583984
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.86
  episode_reward_min: 4.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 8.0, 8.0, 7.0, 8.0, 7.0, 8.0, 6.0, 9.0, 6.0, 14.0, 7.0,
      8.0, 9.0, 10.0, 9.0, 10.0, 4.0, 8.0, 8.0, 6.0, 12.0, 15.0, 11.0, 8.0, 4.0, 4.0,
      12.0, 16.0, 4.0, 10.0, 11.0, 9.0, 7.0, 4.0, 15.0, 7.0, 7.0, 9.0, 13.0, 11.0,
      9.0, 4.0, 7.0, 6.0, 5.0, 11.0, 16.0, 15.0, 11.0, 6.0, 8.0, 9.0, 8.0, 12.0, 15.0,
      5.0, 10.0, 11.0, 9.0, 10.0, 5.0, 5.0, 13.0, 7.0, 7.0, 7.0, 10.0, 9.0, 9.0, 11.0,
      10.0, 9.0, 7.0, 10.0, 9.0, 6.0, 13.0, 11.0, 9.0, 8.0, 11.0, 8.0, 7.0, 12.0,
      6.0, 10.0, 9.0, 9.0, 8.0, 6.0, 12.0, 12.0, 7.0, 10.0, 8.0, 11.0, 6.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06899412696604652
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027032738491700615
    mean_inference_ms: 1.290470666061909
    mean_raw_obs_processing_ms: 0.2928264759882252
time_since_restore: 1504.1161878108978
time_this_iter_s: 10.072782754898071
time_total_s: 1504.1161878108978
timers:
  sample_time_ms: 0.076
  synch_weights_time_ms: 0.555
  training_iteration_time_ms: 2.184
timestamp: 1691995683
timesteps_total: 1723000
training_iteration: 148
trial_id: default
train step: 149
agent_timesteps_total: 1735450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021112680435180664
  StateBufferConnector_ms: 0.003640890121459961
  ViewRequirementAgentConnector_ms: 0.1275935173034668
counters:
  num_agent_steps_sampled: 1735450
  num_agent_steps_trained: 1718500
  num_env_steps_sampled: 1735450
  num_env_steps_trained: 1718500
  num_samples_added_to_queue: 1735000
  num_training_step_calls_since_last_synch_worker_weights: 1208
  num_weight_broadcasts: 34101
custom_metrics: {}
date: 2023-08-14_15-48-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.23
episode_reward_min: 3.0
episodes_this_iter: 98
episodes_total: 13559
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6513389348983765
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.482099771499634
        total_loss: 42.8300666809082
        var_gnorm: 64.50019073486328
        vf_explained_var: 0.873173713684082
        vf_loss: 85.20932006835938
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3437.0
  learner_queue:
    size_count: 3442
    size_mean: 15.48
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1702991070662234
  num_agent_steps_sampled: 1735450
  num_agent_steps_trained: 1718500
  num_env_steps_sampled: 1735450
  num_env_steps_trained: 1718500
  num_samples_added_to_queue: 1735000
  num_training_step_calls_since_last_synch_worker_weights: 1208
  num_weight_broadcasts: 34101
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 255.922
    learner_load_time_ms: 1.508
    learner_load_wait_time_ms: 1.539
iterations_since_restore: 149
node_ip: 127.0.0.1
num_agent_steps_sampled: 1735450
num_agent_steps_trained: 1718500
num_env_steps_sampled: 1735450
num_env_steps_sampled_this_iter: 12450
num_env_steps_sampled_throughput_per_sec: 1244.9986048952478
num_env_steps_trained: 1718500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9986553207207
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 53.74666666666667
  ram_util_percent: 80.68
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06896063926569357
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.027022305031979794
  mean_inference_ms: 1.289788912566125
  mean_raw_obs_processing_ms: 0.29269477048737735
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021112680435180664
    StateBufferConnector_ms: 0.003640890121459961
    ViewRequirementAgentConnector_ms: 0.1275935173034668
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.23
  episode_reward_min: 3.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 6.0, 9.0, 7.0, 11.0, 10.0, 15.0, 6.0, 8.0, 7.0, 8.0, 6.0,
      6.0, 11.0, 7.0, 8.0, 11.0, 12.0, 9.0, 13.0, 10.0, 5.0, 9.0, 8.0, 8.0, 4.0, 8.0,
      6.0, 9.0, 6.0, 10.0, 6.0, 10.0, 8.0, 6.0, 8.0, 5.0, 10.0, 10.0, 5.0, 6.0, 5.0,
      9.0, 11.0, 9.0, 4.0, 11.0, 4.0, 5.0, 9.0, 8.0, 12.0, 9.0, 8.0, 14.0, 6.0, 8.0,
      10.0, 7.0, 6.0, 10.0, 7.0, 5.0, 4.0, 12.0, 6.0, 10.0, 11.0, 12.0, 9.0, 5.0,
      7.0, 7.0, 10.0, 10.0, 9.0, 10.0, 8.0, 3.0, 8.0, 11.0, 9.0, 8.0, 5.0, 10.0, 11.0,
      7.0, 6.0, 5.0, 12.0, 6.0, 8.0, 11.0, 10.0, 5.0, 10.0, 9.0, 10.0, 6.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06896063926569357
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.027022305031979794
    mean_inference_ms: 1.289788912566125
    mean_raw_obs_processing_ms: 0.29269477048737735
time_since_restore: 1514.2417497634888
time_this_iter_s: 10.125561952590942
time_total_s: 1514.2417497634888
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995693
timesteps_total: 1735450
training_iteration: 149
trial_id: default
train step: 150
agent_timesteps_total: 1748500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020775464501711402
  StateBufferConnector_ms: 0.0037958126256961633
  ViewRequirementAgentConnector_ms: 0.12461147686042408
counters:
  num_agent_steps_sampled: 1748500
  num_agent_steps_trained: 1732000
  num_env_steps_sampled: 1748500
  num_env_steps_trained: 1732000
  num_samples_added_to_queue: 1748500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 34358
custom_metrics: {}
date: 2023-08-14_15-48-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.712871287128713
episode_reward_min: 0.0
episodes_this_iter: 101
episodes_total: 13660
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6751837730407715
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.1479597091674805
        total_loss: 20.497425079345703
        var_gnorm: 64.51939392089844
        vf_explained_var: 0.902292788028717
        vf_loss: 58.04261016845703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3464.0
  learner_queue:
    size_count: 3467
    size_mean: 15.62
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9775479527879949
  num_agent_steps_sampled: 1748500
  num_agent_steps_trained: 1732000
  num_env_steps_sampled: 1748500
  num_env_steps_trained: 1732000
  num_samples_added_to_queue: 1748500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 34358
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 281.113
    learner_load_time_ms: 1.486
    learner_load_wait_time_ms: 1.656
iterations_since_restore: 150
node_ip: 127.0.0.1
num_agent_steps_sampled: 1748500
num_agent_steps_trained: 1732000
num_env_steps_sampled: 1748500
num_env_steps_sampled_this_iter: 13050
num_env_steps_sampled_throughput_per_sec: 1304.3373986017225
num_env_steps_trained: 1732000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.314550277644
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.892857142857146
  ram_util_percent: 80.58571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06889356756803547
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02700087334606965
  mean_inference_ms: 1.2887538074057283
  mean_raw_obs_processing_ms: 0.29246357602875994
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020775464501711402
    StateBufferConnector_ms: 0.0037958126256961633
    ViewRequirementAgentConnector_ms: 0.12461147686042408
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.712871287128713
  episode_reward_min: 0.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 2.0, 6.0, 7.0, 7.0, 6.0, 5.0, 6.0, 9.0, 3.0, 11.0, 10.0,
      8.0, 13.0, 6.0, 6.0, 6.0, 3.0, 4.0, 7.0, 6.0, 7.0, 9.0, 4.0, 10.0, 5.0, 9.0,
      5.0, 7.0, 5.0, 6.0, 9.0, 5.0, 5.0, 8.0, 9.0, 6.0, 8.0, 8.0, 7.0, 8.0, 7.0, 6.0,
      9.0, 8.0, 7.0, 6.0, 5.0, 10.0, 10.0, 6.0, 2.0, 11.0, 7.0, 10.0, 6.0, 4.0, 9.0,
      7.0, 6.0, 6.0, 7.0, 6.0, 9.0, 2.0, 2.0, 2.0, 5.0, 6.0, 10.0, 8.0, 4.0, 7.0,
      4.0, 7.0, 4.0, 7.0, 7.0, 8.0, 3.0, 7.0, 8.0, 4.0, 11.0, 5.0, 11.0, 11.0, 7.0,
      9.0, 4.0, 6.0, 9.0, 11.0, 0.0, 10.0, 6.0, 6.0, 7.0, 6.0, 8.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06889356756803547
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02700087334606965
    mean_inference_ms: 1.2887538074057283
    mean_raw_obs_processing_ms: 0.29246357602875994
time_since_restore: 1524.3315057754517
time_this_iter_s: 10.08975601196289
time_total_s: 1524.3315057754517
timers:
  sample_time_ms: 0.038
  synch_weights_time_ms: 0.284
  training_iteration_time_ms: 2.058
timestamp: 1691995703
timesteps_total: 1748500
training_iteration: 150
trial_id: default
train step: 151
agent_timesteps_total: 1761850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019657153349656325
  StateBufferConnector_ms: 0.003644365530747634
  ViewRequirementAgentConnector_ms: 0.11929709177750808
counters:
  num_agent_steps_sampled: 1761850
  num_agent_steps_trained: 1745000
  num_env_steps_sampled: 1761850
  num_env_steps_trained: 1745000
  num_samples_added_to_queue: 1761500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 34622
custom_metrics: {}
date: 2023-08-14_15-48-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 7.9423076923076925
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 13764
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6841375231742859
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 13.321141242980957
        total_loss: 37.72380065917969
        var_gnorm: 64.541015625
        vf_explained_var: 0.9577286243438721
        vf_loss: 55.64669418334961
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3490.0
  learner_queue:
    size_count: 3498
    size_mean: 15.34
    size_quantiles: [9.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.595117550527233
  num_agent_steps_sampled: 1761850
  num_agent_steps_trained: 1745000
  num_env_steps_sampled: 1761850
  num_env_steps_trained: 1745000
  num_samples_added_to_queue: 1761500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 34622
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 114.215
    learner_load_time_ms: 1.497
    learner_load_wait_time_ms: 1.55
iterations_since_restore: 151
node_ip: 127.0.0.1
num_agent_steps_sampled: 1761850
num_agent_steps_trained: 1745000
num_env_steps_sampled: 1761850
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.5898835895161
num_env_steps_trained: 1745000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.6006357051467
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.97142857142857
  ram_util_percent: 80.33571428571427
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06883069541578177
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026972460501399488
  mean_inference_ms: 1.287472051322739
  mean_raw_obs_processing_ms: 0.29219295131946355
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019657153349656325
    StateBufferConnector_ms: 0.003644365530747634
    ViewRequirementAgentConnector_ms: 0.11929709177750808
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 7.9423076923076925
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 11.0, 6.0, 3.0, 7.0, 4.0, 6.0, 10.0, 8.0, 13.0, 9.0, 10.0,
      7.0, 9.0, 6.0, 9.0, 7.0, 9.0, 8.0, 7.0, 11.0, 8.0, 8.0, 12.0, 12.0, 8.0, 7.0,
      7.0, 9.0, 10.0, 7.0, 9.0, 4.0, 11.0, 2.0, 7.0, 10.0, 10.0, 11.0, 10.0, 5.0,
      6.0, 7.0, 6.0, 8.0, 12.0, 7.0, 7.0, 5.0, 8.0, 7.0, 6.0, 13.0, 9.0, 8.0, 9.0,
      8.0, 7.0, 10.0, 10.0, 9.0, 8.0, 5.0, 7.0, 6.0, 8.0, 7.0, 7.0, 11.0, 7.0, 9.0,
      4.0, 9.0, 9.0, 10.0, 5.0, 7.0, 5.0, 12.0, 9.0, 9.0, 17.0, 7.0, 4.0, 7.0, 4.0,
      5.0, 7.0, 9.0, 6.0, 8.0, 7.0, 6.0, 8.0, 12.0, 7.0, 10.0, 9.0, 6.0, 12.0, 8.0,
      10.0, 3.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06883069541578177
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026972460501399488
    mean_inference_ms: 1.287472051322739
    mean_raw_obs_processing_ms: 0.29219295131946355
time_since_restore: 1534.5144429206848
time_this_iter_s: 10.182937145233154
time_total_s: 1534.5144429206848
timers:
  sample_time_ms: 0.079
  synch_weights_time_ms: 0.532
  training_iteration_time_ms: 0.713
timestamp: 1691995713
timesteps_total: 1761850
training_iteration: 151
trial_id: default
train step: 152
agent_timesteps_total: 1774450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02103447914123535
  StateBufferConnector_ms: 0.003778219223022461
  ViewRequirementAgentConnector_ms: 0.12899184226989746
counters:
  num_agent_steps_sampled: 1774450
  num_agent_steps_trained: 1757500
  num_env_steps_sampled: 1774450
  num_env_steps_trained: 1757500
  num_samples_added_to_queue: 1774000
  num_training_step_calls_since_last_synch_worker_weights: 642
  num_weight_broadcasts: 34872
custom_metrics: {}
date: 2023-08-14_15-48-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.43
episode_reward_min: 4.0
episodes_this_iter: 100
episodes_total: 13864
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6291483044624329
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.324451446533203
        total_loss: 19.868148803710938
        var_gnorm: 64.55198669433594
        vf_explained_var: 0.9450585842132568
        vf_loss: 64.67668151855469
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3515.0
  learner_queue:
    size_count: 3521
    size_mean: 14.88
    size_quantiles: [9.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9456618411224493
  num_agent_steps_sampled: 1774450
  num_agent_steps_trained: 1757500
  num_env_steps_sampled: 1774450
  num_env_steps_trained: 1757500
  num_samples_added_to_queue: 1774000
  num_training_step_calls_since_last_synch_worker_weights: 642
  num_weight_broadcasts: 34872
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 209.548
    learner_load_time_ms: 1.543
    learner_load_wait_time_ms: 1.51
iterations_since_restore: 152
node_ip: 127.0.0.1
num_agent_steps_sampled: 1774450
num_agent_steps_trained: 1757500
num_env_steps_sampled: 1774450
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9982576394334
num_env_steps_trained: 1757500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9982714676917
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.260000000000005
  ram_util_percent: 80.66666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06879287732254846
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026960482547615093
  mean_inference_ms: 1.286732198758414
  mean_raw_obs_processing_ms: 0.2920324256704181
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02103447914123535
    StateBufferConnector_ms: 0.003778219223022461
    ViewRequirementAgentConnector_ms: 0.12899184226989746
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.43
  episode_reward_min: 4.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 10.0, 10.0, 6.0, 6.0, 12.0, 10.0, 11.0, 8.0, 12.0,
      9.0, 8.0, 8.0, 10.0, 9.0, 10.0, 11.0, 11.0, 5.0, 11.0, 10.0, 10.0, 10.0, 14.0,
      10.0, 4.0, 4.0, 8.0, 9.0, 6.0, 12.0, 18.0, 7.0, 9.0, 12.0, 10.0, 12.0, 10.0,
      10.0, 15.0, 6.0, 9.0, 8.0, 11.0, 14.0, 8.0, 8.0, 12.0, 8.0, 8.0, 6.0, 10.0,
      5.0, 8.0, 9.0, 6.0, 6.0, 8.0, 11.0, 10.0, 13.0, 11.0, 9.0, 8.0, 7.0, 9.0, 9.0,
      9.0, 18.0, 14.0, 10.0, 12.0, 7.0, 11.0, 7.0, 6.0, 9.0, 10.0, 10.0, 14.0, 7.0,
      8.0, 14.0, 13.0, 11.0, 7.0, 8.0, 5.0, 9.0, 10.0, 6.0, 13.0, 6.0, 12.0, 9.0,
      13.0, 9.0, 6.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06879287732254846
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026960482547615093
    mean_inference_ms: 1.286732198758414
    mean_raw_obs_processing_ms: 0.2920324256704181
time_since_restore: 1544.6583387851715
time_this_iter_s: 10.143895864486694
time_total_s: 1544.6583387851715
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995723
timesteps_total: 1774450
training_iteration: 152
trial_id: default
train step: 153
agent_timesteps_total: 1787550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020305549397188073
  StateBufferConnector_ms: 0.0036506091847139247
  ViewRequirementAgentConnector_ms: 0.1221009329253552
counters:
  num_agent_steps_sampled: 1787550
  num_agent_steps_trained: 1771000
  num_env_steps_sampled: 1787550
  num_env_steps_trained: 1771000
  num_samples_added_to_queue: 1787500
  num_training_step_calls_since_last_synch_worker_weights: 1041
  num_weight_broadcasts: 35131
custom_metrics: {}
date: 2023-08-14_15-48-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.303921568627452
episode_reward_min: 3.0
episodes_this_iter: 102
episodes_total: 13966
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5855083465576172
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.539444923400879
        total_loss: 23.777624130249023
        var_gnorm: 64.5523452758789
        vf_explained_var: 0.9290639758110046
        vf_loss: 64.48921966552734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3542.0
  learner_queue:
    size_count: 3547
    size_mean: 14.96
    size_quantiles: [9.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.777188791321845
  num_agent_steps_sampled: 1787550
  num_agent_steps_trained: 1771000
  num_env_steps_sampled: 1787550
  num_env_steps_trained: 1771000
  num_samples_added_to_queue: 1787500
  num_training_step_calls_since_last_synch_worker_weights: 1041
  num_weight_broadcasts: 35131
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 211.624
    learner_load_time_ms: 1.554
    learner_load_wait_time_ms: 1.731
iterations_since_restore: 153
node_ip: 127.0.0.1
num_agent_steps_sampled: 1787550
num_agent_steps_trained: 1771000
num_env_steps_sampled: 1787550
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9914734918532
num_env_steps_trained: 1771000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9912131404594
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.04285714285714
  ram_util_percent: 80.47142857142856
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06873648874708226
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026937858376571915
  mean_inference_ms: 1.285665988299209
  mean_raw_obs_processing_ms: 0.2917998223144883
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020305549397188073
    StateBufferConnector_ms: 0.0036506091847139247
    ViewRequirementAgentConnector_ms: 0.1221009329253552
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.303921568627452
  episode_reward_min: 3.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 11.0, 10.0, 9.0, 9.0, 11.0, 9.0, 12.0, 8.0, 9.0, 11.0, 11.0,
      6.0, 9.0, 13.0, 10.0, 8.0, 8.0, 8.0, 11.0, 12.0, 16.0, 7.0, 12.0, 6.0, 6.0,
      8.0, 10.0, 6.0, 9.0, 9.0, 10.0, 10.0, 8.0, 8.0, 14.0, 7.0, 12.0, 9.0, 7.0, 9.0,
      3.0, 13.0, 7.0, 5.0, 13.0, 10.0, 8.0, 12.0, 12.0, 12.0, 10.0, 11.0, 10.0, 7.0,
      11.0, 4.0, 9.0, 10.0, 11.0, 14.0, 9.0, 11.0, 9.0, 7.0, 7.0, 11.0, 11.0, 9.0,
      9.0, 8.0, 11.0, 10.0, 10.0, 12.0, 7.0, 10.0, 9.0, 9.0, 8.0, 7.0, 8.0, 4.0, 14.0,
      5.0, 11.0, 7.0, 15.0, 7.0, 11.0, 6.0, 12.0, 12.0, 5.0, 7.0, 6.0, 12.0, 10.0,
      8.0, 10.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06873648874708226
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026937858376571915
    mean_inference_ms: 1.285665988299209
    mean_raw_obs_processing_ms: 0.2917998223144883
time_since_restore: 1554.7799067497253
time_this_iter_s: 10.121567964553833
time_total_s: 1554.7799067497253
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.047
timestamp: 1691995734
timesteps_total: 1787550
training_iteration: 153
trial_id: default
train step: 154
agent_timesteps_total: 1800750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01936931054568985
  StateBufferConnector_ms: 0.0034123948476846937
  ViewRequirementAgentConnector_ms: 0.1191296623748483
counters:
  num_agent_steps_sampled: 1800750
  num_agent_steps_trained: 1784000
  num_env_steps_sampled: 1800750
  num_env_steps_trained: 1784000
  num_samples_added_to_queue: 1800500
  num_training_step_calls_since_last_synch_worker_weights: 794
  num_weight_broadcasts: 35391
custom_metrics: {}
date: 2023-08-14_15-49-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.20388349514563
episode_reward_min: 2.0
episodes_this_iter: 103
episodes_total: 14069
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6026074290275574
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 66.34135437011719
        total_loss: 138.50732421875
        var_gnorm: 64.54644012451172
        vf_explained_var: 0.7921231985092163
        vf_loss: 150.3579864501953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3568.0
  learner_queue:
    size_count: 3573
    size_mean: 15.5
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.0816653826391966
  num_agent_steps_sampled: 1800750
  num_agent_steps_trained: 1784000
  num_env_steps_sampled: 1800750
  num_env_steps_trained: 1784000
  num_samples_added_to_queue: 1800500
  num_training_step_calls_since_last_synch_worker_weights: 794
  num_weight_broadcasts: 35391
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 216.256
    learner_load_time_ms: 1.49
    learner_load_wait_time_ms: 1.461
iterations_since_restore: 154
node_ip: 127.0.0.1
num_agent_steps_sampled: 1800750
num_agent_steps_trained: 1784000
num_env_steps_sampled: 1800750
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9952793290163
num_env_steps_trained: 1784000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9953508543342
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.72857142857142
  ram_util_percent: 80.85714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06867208489957777
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026915040426651823
  mean_inference_ms: 1.2845494691395904
  mean_raw_obs_processing_ms: 0.2915706496963963
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01936931054568985
    StateBufferConnector_ms: 0.0034123948476846937
    ViewRequirementAgentConnector_ms: 0.1191296623748483
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.20388349514563
  episode_reward_min: 2.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 7.0, 7.0, 7.0, 9.0, 9.0, 11.0, 11.0, 7.0, 11.0, 6.0, 13.0,
      9.0, 10.0, 15.0, 11.0, 11.0, 11.0, 10.0, 11.0, 9.0, 8.0, 10.0, 11.0, 14.0, 8.0,
      13.0, 10.0, 9.0, 8.0, 11.0, 13.0, 4.0, 9.0, 10.0, 8.0, 9.0, 10.0, 10.0, 11.0,
      9.0, 9.0, 12.0, 5.0, 9.0, 5.0, 10.0, 13.0, 8.0, 7.0, 7.0, 12.0, 8.0, 18.0, 11.0,
      12.0, 8.0, 8.0, 11.0, 12.0, 10.0, 16.0, 9.0, 9.0, 9.0, 10.0, 10.0, 10.0, 8.0,
      14.0, 7.0, 12.0, 8.0, 9.0, 8.0, 7.0, 9.0, 6.0, 12.0, 7.0, 6.0, 8.0, 6.0, 8.0,
      8.0, 7.0, 5.0, 10.0, 7.0, 8.0, 7.0, 8.0, 11.0, 4.0, 5.0, 10.0, 9.0, 9.0, 6.0,
      12.0, 7.0, 13.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06867208489957777
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026915040426651823
    mean_inference_ms: 1.2845494691395904
    mean_raw_obs_processing_ms: 0.2915706496963963
time_since_restore: 1564.9037086963654
time_this_iter_s: 10.123801946640015
time_total_s: 1564.9037086963654
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691995744
timesteps_total: 1800750
training_iteration: 154
trial_id: default
train step: 155
agent_timesteps_total: 1813950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019534120281923164
  StateBufferConnector_ms: 0.0036024352879200166
  ViewRequirementAgentConnector_ms: 0.1198821854822844
counters:
  num_agent_steps_sampled: 1813950
  num_agent_steps_trained: 1797000
  num_env_steps_sampled: 1813950
  num_env_steps_trained: 1797000
  num_samples_added_to_queue: 1813500
  num_training_step_calls_since_last_synch_worker_weights: 62
  num_weight_broadcasts: 35652
custom_metrics: {}
date: 2023-08-14_15-49-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.077669902912621
episode_reward_min: 2.0
episodes_this_iter: 103
episodes_total: 14172
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6104592084884644
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 16.05023193359375
        total_loss: 62.4747428894043
        var_gnorm: 64.54872131347656
        vf_explained_var: 0.8681501746177673
        vf_loss: 98.95360565185547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3594.0
  learner_queue:
    size_count: 3601
    size_mean: 15.24
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5041276541570532
  num_agent_steps_sampled: 1813950
  num_agent_steps_trained: 1797000
  num_env_steps_sampled: 1813950
  num_env_steps_trained: 1797000
  num_samples_added_to_queue: 1813500
  num_training_step_calls_since_last_synch_worker_weights: 62
  num_weight_broadcasts: 35652
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 163.227
    learner_load_time_ms: 1.486
    learner_load_wait_time_ms: 1.585
iterations_since_restore: 155
node_ip: 127.0.0.1
num_agent_steps_sampled: 1813950
num_agent_steps_trained: 1797000
num_env_steps_sampled: 1813950
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9927301807243
num_env_steps_trained: 1797000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9928403295012
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.84
  ram_util_percent: 81.16
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06862254221229246
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026891808629320935
  mean_inference_ms: 1.2834679312242168
  mean_raw_obs_processing_ms: 0.2913277809565313
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019534120281923164
    StateBufferConnector_ms: 0.0036024352879200166
    ViewRequirementAgentConnector_ms: 0.1198821854822844
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.077669902912621
  episode_reward_min: 2.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 14.0, 7.0, 8.0, 10.0, 12.0, 15.0, 6.0, 6.0, 9.0, 9.0,
      10.0, 11.0, 5.0, 5.0, 8.0, 10.0, 8.0, 6.0, 8.0, 16.0, 8.0, 8.0, 5.0, 7.0, 11.0,
      9.0, 12.0, 9.0, 6.0, 7.0, 9.0, 6.0, 9.0, 6.0, 10.0, 13.0, 9.0, 8.0, 3.0, 7.0,
      10.0, 6.0, 8.0, 11.0, 13.0, 6.0, 12.0, 4.0, 5.0, 14.0, 9.0, 9.0, 6.0, 5.0, 10.0,
      8.0, 9.0, 8.0, 7.0, 5.0, 2.0, 6.0, 5.0, 6.0, 6.0, 12.0, 8.0, 7.0, 12.0, 12.0,
      8.0, 6.0, 12.0, 13.0, 9.0, 5.0, 11.0, 4.0, 9.0, 8.0, 2.0, 6.0, 4.0, 6.0, 10.0,
      4.0, 8.0, 11.0, 5.0, 8.0, 10.0, 4.0, 12.0, 7.0, 9.0, 6.0, 9.0, 4.0, 8.0, 5.0,
      8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06862254221229246
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026891808629320935
    mean_inference_ms: 1.2834679312242168
    mean_raw_obs_processing_ms: 0.2913277809565313
time_since_restore: 1575.076813697815
time_this_iter_s: 10.173105001449585
time_total_s: 1575.076813697815
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.047
timestamp: 1691995754
timesteps_total: 1813950
training_iteration: 155
trial_id: default
train step: 156
agent_timesteps_total: 1826550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020758867263793945
  StateBufferConnector_ms: 0.0036513805389404297
  ViewRequirementAgentConnector_ms: 0.12353777885437012
counters:
  num_agent_steps_sampled: 1826550
  num_agent_steps_trained: 1810000
  num_env_steps_sampled: 1826550
  num_env_steps_trained: 1810000
  num_samples_added_to_queue: 1826500
  num_training_step_calls_since_last_synch_worker_weights: 723
  num_weight_broadcasts: 35900
custom_metrics: {}
date: 2023-08-14_15-49-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.5
episode_reward_min: 2.0
episodes_this_iter: 98
episodes_total: 14270
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6412482857704163
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.615394592285156
        total_loss: 8.091527938842773
        var_gnorm: 64.54171752929688
        vf_explained_var: 0.8505209684371948
        vf_loss: 55.82632827758789
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3620.0
  learner_queue:
    size_count: 3624
    size_mean: 15.2
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.5231546211727816
  num_agent_steps_sampled: 1826550
  num_agent_steps_trained: 1810000
  num_env_steps_sampled: 1826550
  num_env_steps_trained: 1810000
  num_samples_added_to_queue: 1826500
  num_training_step_calls_since_last_synch_worker_weights: 723
  num_weight_broadcasts: 35900
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 236.277
    learner_load_time_ms: 1.489
    learner_load_wait_time_ms: 1.681
iterations_since_restore: 156
node_ip: 127.0.0.1
num_agent_steps_sampled: 1826550
num_agent_steps_trained: 1810000
num_env_steps_sampled: 1826550
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9933309908038
num_env_steps_trained: 1810000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.993119276226
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 56.028571428571425
  ram_util_percent: 81.7357142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06859500642644885
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026879882879342832
  mean_inference_ms: 1.282798874840574
  mean_raw_obs_processing_ms: 0.29118040085673746
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020758867263793945
    StateBufferConnector_ms: 0.0036513805389404297
    ViewRequirementAgentConnector_ms: 0.12353777885437012
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.5
  episode_reward_min: 2.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 8.0, 7.0, 6.0, 15.0, 12.0, 5.0, 9.0, 8.0, 5.0, 8.0, 4.0,
      5.0, 10.0, 5.0, 11.0, 7.0, 9.0, 8.0, 6.0, 2.0, 5.0, 8.0, 7.0, 5.0, 3.0, 8.0,
      3.0, 7.0, 5.0, 8.0, 12.0, 13.0, 5.0, 5.0, 7.0, 8.0, 3.0, 5.0, 9.0, 6.0, 12.0,
      2.0, 12.0, 7.0, 6.0, 8.0, 7.0, 7.0, 11.0, 11.0, 9.0, 7.0, 9.0, 5.0, 7.0, 9.0,
      5.0, 8.0, 7.0, 5.0, 6.0, 4.0, 6.0, 9.0, 8.0, 10.0, 8.0, 10.0, 9.0, 11.0, 5.0,
      7.0, 11.0, 9.0, 9.0, 5.0, 7.0, 12.0, 7.0, 7.0, 8.0, 9.0, 7.0, 12.0, 5.0, 9.0,
      10.0, 8.0, 10.0, 4.0, 9.0, 6.0, 6.0, 5.0, 8.0, 7.0, 7.0, 10.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06859500642644885
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026879882879342832
    mean_inference_ms: 1.282798874840574
    mean_raw_obs_processing_ms: 0.29118040085673746
time_since_restore: 1585.194415807724
time_this_iter_s: 10.117602109909058
time_total_s: 1585.194415807724
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691995764
timesteps_total: 1826550
training_iteration: 156
trial_id: default
train step: 157
agent_timesteps_total: 1840250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018862220976087783
  StateBufferConnector_ms: 0.0033400676868580005
  ViewRequirementAgentConnector_ms: 0.11420514848497179
counters:
  num_agent_steps_sampled: 1840250
  num_agent_steps_trained: 1823500
  num_env_steps_sampled: 1840250
  num_env_steps_trained: 1823500
  num_samples_added_to_queue: 1840000
  num_training_step_calls_since_last_synch_worker_weights: 1014
  num_weight_broadcasts: 36169
custom_metrics: {}
date: 2023-08-14_15-49-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.12037037037037
episode_reward_min: 4.0
episodes_this_iter: 108
episodes_total: 14378
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5636023283004761
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.06313776969909668
        total_loss: 13.776123046875
        var_gnorm: 64.54341888427734
        vf_explained_var: 0.9272650480270386
        vf_loss: 33.314544677734375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3647.0
  learner_queue:
    size_count: 3651
    size_mean: 15.44
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.134195750300626
  num_agent_steps_sampled: 1840250
  num_agent_steps_trained: 1823500
  num_env_steps_sampled: 1840250
  num_env_steps_trained: 1823500
  num_samples_added_to_queue: 1840000
  num_training_step_calls_since_last_synch_worker_weights: 1014
  num_weight_broadcasts: 36169
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 244.182
    learner_load_time_ms: 1.475
    learner_load_wait_time_ms: 1.502
iterations_since_restore: 157
node_ip: 127.0.0.1
num_agent_steps_sampled: 1840250
num_agent_steps_trained: 1823500
num_env_steps_sampled: 1840250
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9972562844866
num_env_steps_trained: 1823500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9972963387277
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.84285714285715
  ram_util_percent: 80.64999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06850946960620358
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026846675359971324
  mean_inference_ms: 1.2813700586737686
  mean_raw_obs_processing_ms: 0.2908681411066678
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018862220976087783
    StateBufferConnector_ms: 0.0033400676868580005
    ViewRequirementAgentConnector_ms: 0.11420514848497179
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.12037037037037
  episode_reward_min: 4.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 10.0, 9.0, 9.0, 14.0, 8.0, 7.0, 10.0, 9.0, 14.0, 4.0, 6.0,
      9.0, 6.0, 12.0, 8.0, 6.0, 11.0, 12.0, 10.0, 7.0, 8.0, 9.0, 8.0, 4.0, 8.0, 11.0,
      11.0, 10.0, 6.0, 9.0, 11.0, 14.0, 10.0, 5.0, 11.0, 11.0, 8.0, 5.0, 11.0, 9.0,
      5.0, 11.0, 10.0, 10.0, 9.0, 11.0, 15.0, 10.0, 5.0, 9.0, 10.0, 8.0, 4.0, 9.0,
      7.0, 14.0, 10.0, 9.0, 12.0, 12.0, 7.0, 6.0, 8.0, 5.0, 8.0, 14.0, 9.0, 7.0, 6.0,
      9.0, 13.0, 8.0, 12.0, 14.0, 7.0, 4.0, 13.0, 6.0, 8.0, 6.0, 7.0, 10.0, 12.0,
      11.0, 8.0, 10.0, 7.0, 9.0, 7.0, 7.0, 8.0, 9.0, 14.0, 6.0, 9.0, 11.0, 15.0, 7.0,
      12.0, 9.0, 11.0, 9.0, 8.0, 8.0, 7.0, 15.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06850946960620358
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026846675359971324
    mean_inference_ms: 1.2813700586737686
    mean_raw_obs_processing_ms: 0.2908681411066678
time_since_restore: 1595.293122768402
time_this_iter_s: 10.0987069606781
time_total_s: 1595.293122768402
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995774
timesteps_total: 1840250
training_iteration: 157
trial_id: default
train step: 158
agent_timesteps_total: 1854100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018867519166734483
  StateBufferConnector_ms: 0.003371415314850984
  ViewRequirementAgentConnector_ms: 0.11302276893898293
counters:
  num_agent_steps_sampled: 1854100
  num_agent_steps_trained: 1837500
  num_env_steps_sampled: 1854100
  num_env_steps_trained: 1837500
  num_samples_added_to_queue: 1854000
  num_training_step_calls_since_last_synch_worker_weights: 186
  num_weight_broadcasts: 36441
custom_metrics: {}
date: 2023-08-14_15-49-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.537037037037036
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 14486
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.615851640701294
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.798437118530273
        total_loss: 28.362985610961914
        var_gnorm: 64.54725646972656
        vf_explained_var: 0.8759413957595825
        vf_loss: 82.48136138916016
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3675.0
  learner_queue:
    size_count: 3681
    size_mean: 15.52
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1178550889985697
  num_agent_steps_sampled: 1854100
  num_agent_steps_trained: 1837500
  num_env_steps_sampled: 1854100
  num_env_steps_trained: 1837500
  num_samples_added_to_queue: 1854000
  num_training_step_calls_since_last_synch_worker_weights: 186
  num_weight_broadcasts: 36441
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 160.045
    learner_load_time_ms: 1.373
    learner_load_wait_time_ms: 1.474
iterations_since_restore: 158
node_ip: 127.0.0.1
num_agent_steps_sampled: 1854100
num_agent_steps_trained: 1837500
num_env_steps_sampled: 1854100
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.9946176022847
num_env_steps_trained: 1837500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9945593091686
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.75000000000001
  ram_util_percent: 80.48571428571428
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06842644259915555
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02680985590772809
  mean_inference_ms: 1.2798569546182623
  mean_raw_obs_processing_ms: 0.2905450511036747
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018867519166734483
    StateBufferConnector_ms: 0.003371415314850984
    ViewRequirementAgentConnector_ms: 0.11302276893898293
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.537037037037036
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 8.0, 11.0, 8.0, 8.0, 6.0, 10.0, 10.0, 10.0, 15.0, 8.0, 8.0,
      11.0, 7.0, 8.0, 8.0, 8.0, 13.0, 7.0, 9.0, 3.0, 10.0, 10.0, 5.0, 10.0, 7.0, 14.0,
      5.0, 7.0, 12.0, 7.0, 8.0, 9.0, 13.0, 12.0, 4.0, 4.0, 5.0, 10.0, 4.0, 9.0, 9.0,
      7.0, 8.0, 14.0, 11.0, 8.0, 10.0, 12.0, 9.0, 8.0, 7.0, 12.0, 11.0, 11.0, 6.0,
      12.0, 2.0, 13.0, 5.0, 7.0, 8.0, 9.0, 8.0, 7.0, 12.0, 8.0, 8.0, 6.0, 6.0, 9.0,
      7.0, 7.0, 5.0, 7.0, 10.0, 2.0, 10.0, 9.0, 7.0, 11.0, 10.0, 13.0, 10.0, 11.0,
      12.0, 9.0, 5.0, 9.0, 11.0, 9.0, 5.0, 15.0, 11.0, 8.0, 7.0, 5.0, 11.0, 4.0, 11.0,
      12.0, 8.0, 6.0, 10.0, 5.0, 7.0, 6.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06842644259915555
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02680985590772809
    mean_inference_ms: 1.2798569546182623
    mean_raw_obs_processing_ms: 0.2905450511036747
time_since_restore: 1605.4317078590393
time_this_iter_s: 10.138585090637207
time_total_s: 1605.4317078590393
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995784
timesteps_total: 1854100
training_iteration: 158
trial_id: default
train step: 159
agent_timesteps_total: 1867850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018716749743880514
  StateBufferConnector_ms: 0.0033249364835079586
  ViewRequirementAgentConnector_ms: 0.11376064514445368
counters:
  num_agent_steps_sampled: 1867850
  num_agent_steps_trained: 1851000
  num_env_steps_sampled: 1867850
  num_env_steps_trained: 1851000
  num_samples_added_to_queue: 1867500
  num_training_step_calls_since_last_synch_worker_weights: 980
  num_weight_broadcasts: 36712
custom_metrics: {}
date: 2023-08-14_15-49-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.88785046728972
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 14593
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6325515508651733
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -3.8345351219177246
        total_loss: 43.368202209472656
        var_gnorm: 64.54597473144531
        vf_explained_var: 0.8634262084960938
        vf_loss: 100.73098754882812
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3702.0
  learner_queue:
    size_count: 3707
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 1867850
  num_agent_steps_trained: 1851000
  num_env_steps_sampled: 1867850
  num_env_steps_trained: 1851000
  num_samples_added_to_queue: 1867500
  num_training_step_calls_since_last_synch_worker_weights: 980
  num_weight_broadcasts: 36712
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 229.983
    learner_load_time_ms: 1.368
    learner_load_wait_time_ms: 1.476
iterations_since_restore: 159
node_ip: 127.0.0.1
num_agent_steps_sampled: 1867850
num_agent_steps_trained: 1851000
num_env_steps_sampled: 1867850
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9992787841766
num_env_steps_trained: 1851000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9992918971914
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.88666666666667
  ram_util_percent: 80.14
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06834344234995118
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026775011067301308
  mean_inference_ms: 1.2784458071541884
  mean_raw_obs_processing_ms: 0.29022789069686106
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018716749743880514
    StateBufferConnector_ms: 0.0033249364835079586
    ViewRequirementAgentConnector_ms: 0.11376064514445368
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.88785046728972
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 8.0, 13.0, 11.0, 13.0, 12.0, 10.0, 4.0, 9.0, 10.0, 5.0,
      8.0, 7.0, 11.0, 11.0, 6.0, 10.0, 5.0, 10.0, 9.0, 10.0, 5.0, 5.0, 7.0, 5.0, 9.0,
      6.0, 9.0, 9.0, 9.0, 12.0, 9.0, 11.0, 10.0, 9.0, 10.0, 13.0, 8.0, 4.0, 6.0, 8.0,
      11.0, 7.0, 8.0, 8.0, 7.0, 11.0, 5.0, 8.0, 10.0, 10.0, 13.0, 6.0, 8.0, 9.0, 10.0,
      10.0, 11.0, 10.0, 8.0, 9.0, 5.0, 10.0, 8.0, 3.0, 10.0, 9.0, 8.0, 11.0, 11.0,
      10.0, 9.0, 7.0, 7.0, 13.0, 13.0, 13.0, 4.0, 12.0, 5.0, 5.0, 7.0, 10.0, 8.0,
      10.0, 5.0, 8.0, 7.0, 14.0, 7.0, 12.0, 15.0, 10.0, 9.0, 11.0, 6.0, 14.0, 6.0,
      5.0, 12.0, 10.0, 10.0, 12.0, 11.0, 7.0, 10.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06834344234995118
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026775011067301308
    mean_inference_ms: 1.2784458071541884
    mean_raw_obs_processing_ms: 0.29022789069686106
time_since_restore: 1615.538225889206
time_this_iter_s: 10.106518030166626
time_total_s: 1615.538225889206
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995794
timesteps_total: 1867850
training_iteration: 159
trial_id: default
train step: 160
agent_timesteps_total: 1881550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018965314935754846
  StateBufferConnector_ms: 0.0033500017943205655
  ViewRequirementAgentConnector_ms: 0.11578908673039189
counters:
  num_agent_steps_sampled: 1881550
  num_agent_steps_trained: 1865000
  num_env_steps_sampled: 1881550
  num_env_steps_trained: 1865000
  num_samples_added_to_queue: 1881500
  num_training_step_calls_since_last_synch_worker_weights: 1004
  num_weight_broadcasts: 36981
custom_metrics: {}
date: 2023-08-14_15-50-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.351851851851851
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 14701
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7076913714408875
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 16.172927856445312
        total_loss: 32.74709701538086
        var_gnorm: 64.53681945800781
        vf_explained_var: 0.9089143872261047
        vf_loss: 40.225250244140625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3730.0
  learner_queue:
    size_count: 3734
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.916515138991168
  num_agent_steps_sampled: 1881550
  num_agent_steps_trained: 1865000
  num_env_steps_sampled: 1881550
  num_env_steps_trained: 1865000
  num_samples_added_to_queue: 1881500
  num_training_step_calls_since_last_synch_worker_weights: 1004
  num_weight_broadcasts: 36981
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 228.822
    learner_load_time_ms: 1.374
    learner_load_wait_time_ms: 1.643
iterations_since_restore: 160
node_ip: 127.0.0.1
num_agent_steps_sampled: 1881550
num_agent_steps_trained: 1865000
num_env_steps_sampled: 1881550
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9940226338829
num_env_steps_trained: 1865000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9938917426541
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.15714285714285
  ram_util_percent: 79.13571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06826680827544385
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026740129729966953
  mean_inference_ms: 1.2770430851848042
  mean_raw_obs_processing_ms: 0.28991092931910595
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018965314935754846
    StateBufferConnector_ms: 0.0033500017943205655
    ViewRequirementAgentConnector_ms: 0.11578908673039189
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.351851851851851
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 14.0, 12.0, 7.0, 9.0, 14.0, 5.0, 9.0, 13.0, 9.0, 9.0, 11.0,
      11.0, 10.0, 10.0, 9.0, 9.0, 10.0, 12.0, 9.0, 7.0, 14.0, 5.0, 10.0, 7.0, 11.0,
      9.0, 9.0, 8.0, 12.0, 9.0, 10.0, 11.0, 13.0, 9.0, 10.0, 11.0, 13.0, 7.0, 11.0,
      7.0, 11.0, 12.0, 5.0, 10.0, 4.0, 13.0, 10.0, 8.0, 7.0, 6.0, 7.0, 10.0, 9.0,
      10.0, 11.0, 10.0, 9.0, 9.0, 13.0, 6.0, 11.0, 6.0, 11.0, 10.0, 9.0, 9.0, 12.0,
      15.0, 9.0, 10.0, 10.0, 5.0, 9.0, 8.0, 9.0, 9.0, 9.0, 9.0, 13.0, 10.0, 10.0,
      16.0, 10.0, 10.0, 11.0, 15.0, 6.0, 6.0, 7.0, 15.0, 12.0, 7.0, 5.0, 3.0, 9.0,
      9.0, 6.0, 6.0, 10.0, 7.0, 6.0, 12.0, 8.0, 9.0, 5.0, 6.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06826680827544385
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026740129729966953
    mean_inference_ms: 1.2770430851848042
    mean_raw_obs_processing_ms: 0.28991092931910595
time_since_restore: 1625.6285319328308
time_this_iter_s: 10.090306043624878
time_total_s: 1625.6285319328308
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691995805
timesteps_total: 1881550
training_iteration: 160
trial_id: default
train step: 161
agent_timesteps_total: 1895350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018547851348591743
  StateBufferConnector_ms: 0.003278144052095502
  ViewRequirementAgentConnector_ms: 0.1128858494981427
counters:
  num_agent_steps_sampled: 1895350
  num_agent_steps_trained: 1878500
  num_env_steps_sampled: 1895350
  num_env_steps_trained: 1878500
  num_samples_added_to_queue: 1895000
  num_training_step_calls_since_last_synch_worker_weights: 1312
  num_weight_broadcasts: 37253
custom_metrics: {}
date: 2023-08-14_15-50-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.841121495327103
episode_reward_min: 2.0
episodes_this_iter: 107
episodes_total: 14808
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6502333879470825
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -30.618072509765625
        total_loss: 26.525371551513672
        var_gnorm: 64.54879760742188
        vf_explained_var: 0.8680073022842407
        vf_loss: 120.78922271728516
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3757.0
  learner_queue:
    size_count: 3761
    size_mean: 15.72
    size_quantiles: [13.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.7493997598078078
  num_agent_steps_sampled: 1895350
  num_agent_steps_trained: 1878500
  num_env_steps_sampled: 1895350
  num_env_steps_trained: 1878500
  num_samples_added_to_queue: 1895000
  num_training_step_calls_since_last_synch_worker_weights: 1312
  num_weight_broadcasts: 37253
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 257.257
    learner_load_time_ms: 1.385
    learner_load_wait_time_ms: 1.704
iterations_since_restore: 161
node_ip: 127.0.0.1
num_agent_steps_sampled: 1895350
num_agent_steps_trained: 1878500
num_env_steps_sampled: 1895350
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9946370333234
num_env_steps_trained: 1878500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9947536195555
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.47857142857142
  ram_util_percent: 78.8142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06819305190755079
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026705600909004125
  mean_inference_ms: 1.275605410577057
  mean_raw_obs_processing_ms: 0.2895902417974305
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018547851348591743
    StateBufferConnector_ms: 0.003278144052095502
    ViewRequirementAgentConnector_ms: 0.1128858494981427
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.841121495327103
  episode_reward_min: 2.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 8.0, 10.0, 6.0, 8.0, 11.0, 6.0, 9.0, 5.0, 12.0, 8.0, 7.0,
      10.0, 8.0, 8.0, 8.0, 9.0, 7.0, 10.0, 11.0, 6.0, 6.0, 9.0, 11.0, 4.0, 10.0, 7.0,
      8.0, 5.0, 15.0, 9.0, 4.0, 2.0, 7.0, 14.0, 6.0, 10.0, 7.0, 7.0, 5.0, 6.0, 5.0,
      6.0, 9.0, 10.0, 9.0, 7.0, 6.0, 9.0, 11.0, 9.0, 8.0, 6.0, 2.0, 8.0, 8.0, 14.0,
      8.0, 10.0, 9.0, 10.0, 4.0, 9.0, 9.0, 8.0, 11.0, 9.0, 9.0, 11.0, 6.0, 5.0, 3.0,
      6.0, 10.0, 8.0, 7.0, 6.0, 5.0, 5.0, 8.0, 8.0, 6.0, 11.0, 5.0, 5.0, 12.0, 6.0,
      4.0, 11.0, 11.0, 7.0, 10.0, 14.0, 11.0, 8.0, 3.0, 7.0, 10.0, 8.0, 7.0, 7.0,
      5.0, 7.0, 6.0, 5.0, 11.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06819305190755079
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026705600909004125
    mean_inference_ms: 1.275605410577057
    mean_raw_obs_processing_ms: 0.2895902417974305
time_since_restore: 1635.713241815567
time_this_iter_s: 10.084709882736206
time_total_s: 1635.713241815567
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995815
timesteps_total: 1895350
training_iteration: 161
trial_id: default
train step: 162
agent_timesteps_total: 1909250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01860430481237009
  StateBufferConnector_ms: 0.0033137995168703413
  ViewRequirementAgentConnector_ms: 0.11195327163836279
counters:
  num_agent_steps_sampled: 1909250
  num_agent_steps_trained: 1892500
  num_env_steps_sampled: 1909250
  num_env_steps_trained: 1892500
  num_samples_added_to_queue: 1909000
  num_training_step_calls_since_last_synch_worker_weights: 415
  num_weight_broadcasts: 37526
custom_metrics: {}
date: 2023-08-14_15-50-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 6.605504587155964
episode_reward_min: 0.0
episodes_this_iter: 109
episodes_total: 14917
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6209547519683838
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -25.62750244140625
        total_loss: 13.523606300354004
        var_gnorm: 64.5577163696289
        vf_explained_var: 0.9036325216293335
        vf_loss: 84.51176452636719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3785.0
  learner_queue:
    size_count: 3791
    size_mean: 15.56
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0983624174196784
  num_agent_steps_sampled: 1909250
  num_agent_steps_trained: 1892500
  num_env_steps_sampled: 1909250
  num_env_steps_trained: 1892500
  num_samples_added_to_queue: 1909000
  num_training_step_calls_since_last_synch_worker_weights: 415
  num_weight_broadcasts: 37526
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 169.025
    learner_load_time_ms: 1.378
    learner_load_wait_time_ms: 1.483
iterations_since_restore: 162
node_ip: 127.0.0.1
num_agent_steps_sampled: 1909250
num_agent_steps_trained: 1892500
num_env_steps_sampled: 1909250
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9959900494862
num_env_steps_trained: 1892500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9959612009213
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.957142857142856
  ram_util_percent: 78.85
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0681078663873424
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026669871936162198
  mean_inference_ms: 1.2741825640926565
  mean_raw_obs_processing_ms: 0.28927579134105247
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01860430481237009
    StateBufferConnector_ms: 0.0033137995168703413
    ViewRequirementAgentConnector_ms: 0.11195327163836279
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 6.605504587155964
  episode_reward_min: 0.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [1.0, 6.0, 7.0, 5.0, 3.0, 9.0, 8.0, 6.0, 9.0, 5.0, 11.0, 7.0,
      7.0, 3.0, 9.0, 1.0, 5.0, 11.0, 6.0, 3.0, 5.0, 7.0, 5.0, 6.0, 2.0, 5.0, 10.0,
      6.0, 2.0, 3.0, 7.0, 2.0, 6.0, 9.0, 8.0, 8.0, 8.0, 6.0, 7.0, 7.0, 9.0, 8.0, 6.0,
      4.0, 6.0, 6.0, 5.0, 9.0, 16.0, 12.0, 12.0, 8.0, 11.0, 10.0, 7.0, 5.0, 7.0, 6.0,
      8.0, 0.0, 6.0, 6.0, 7.0, 10.0, 9.0, 4.0, 8.0, 6.0, 5.0, 6.0, 9.0, 5.0, 8.0,
      3.0, 8.0, 1.0, 3.0, 7.0, 4.0, 3.0, 1.0, 8.0, 14.0, 8.0, 5.0, 5.0, 8.0, 4.0,
      8.0, 9.0, 3.0, 6.0, 11.0, 7.0, 6.0, 7.0, 6.0, 9.0, 7.0, 7.0, 7.0, 7.0, 7.0,
      8.0, 6.0, 9.0, 11.0, 5.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0681078663873424
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026669871936162198
    mean_inference_ms: 1.2741825640926565
    mean_raw_obs_processing_ms: 0.28927579134105247
time_since_restore: 1645.8434917926788
time_this_iter_s: 10.130249977111816
time_total_s: 1645.8434917926788
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995825
timesteps_total: 1909250
training_iteration: 162
trial_id: default
train step: 163
agent_timesteps_total: 1923150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018531746334499784
  StateBufferConnector_ms: 0.0033146805233425563
  ViewRequirementAgentConnector_ms: 0.11241171095106336
counters:
  num_agent_steps_sampled: 1923150
  num_agent_steps_trained: 1906500
  num_env_steps_sampled: 1923150
  num_env_steps_trained: 1906500
  num_samples_added_to_queue: 1923000
  num_training_step_calls_since_last_synch_worker_weights: 1283
  num_weight_broadcasts: 37797
custom_metrics: {}
date: 2023-08-14_15-50-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.537037037037037
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 15025
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6804921627044678
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 4.413439750671387
        total_loss: 21.651411056518555
        var_gnorm: 64.55186462402344
        vf_explained_var: 0.9017626047134399
        vf_loss: 41.280860900878906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3813.0
  learner_queue:
    size_count: 3817
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2649110640673518
  num_agent_steps_sampled: 1923150
  num_agent_steps_trained: 1906500
  num_env_steps_sampled: 1923150
  num_env_steps_trained: 1906500
  num_samples_added_to_queue: 1923000
  num_training_step_calls_since_last_synch_worker_weights: 1283
  num_weight_broadcasts: 37797
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 238.314
    learner_load_time_ms: 1.525
    learner_load_wait_time_ms: 1.6
iterations_since_restore: 163
node_ip: 127.0.0.1
num_agent_steps_sampled: 1923150
num_agent_steps_trained: 1906500
num_env_steps_sampled: 1923150
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9987738143293
num_env_steps_trained: 1906500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9987649928496
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.846666666666664
  ram_util_percent: 78.98
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06803181619429792
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02663217339132939
  mean_inference_ms: 1.272719201374406
  mean_raw_obs_processing_ms: 0.28895231118575526
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018531746334499784
    StateBufferConnector_ms: 0.0033146805233425563
    ViewRequirementAgentConnector_ms: 0.11241171095106336
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.537037037037037
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 4.0, 6.0, 8.0, 8.0, 9.0, 5.0, 7.0, 9.0, 4.0, 8.0, 6.0,
      1.0, 4.0, 6.0, 5.0, 2.0, 2.0, 4.0, 7.0, 4.0, 8.0, 10.0, 6.0, 6.0, 6.0, 8.0,
      7.0, 9.0, 7.0, 4.0, 5.0, 9.0, 8.0, 5.0, 9.0, 7.0, 8.0, 9.0, 4.0, 10.0, 8.0,
      8.0, 12.0, 8.0, 8.0, 12.0, 7.0, 5.0, 6.0, 7.0, 8.0, 7.0, 6.0, 5.0, 3.0, 7.0,
      9.0, 3.0, 9.0, 3.0, 6.0, 7.0, 5.0, 3.0, 2.0, 4.0, 7.0, 4.0, 9.0, 3.0, 6.0, 8.0,
      8.0, 5.0, 2.0, 9.0, 3.0, 12.0, 6.0, 11.0, 7.0, 5.0, 6.0, 6.0, 4.0, 8.0, 3.0,
      7.0, 5.0, 8.0, 5.0, 5.0, 12.0, 10.0, 5.0, 8.0, 4.0, 5.0, 8.0, 5.0, 7.0, 11.0,
      5.0, 8.0, 10.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06803181619429792
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02663217339132939
    mean_inference_ms: 1.272719201374406
    mean_raw_obs_processing_ms: 0.28895231118575526
time_since_restore: 1655.9290618896484
time_this_iter_s: 10.085570096969604
time_total_s: 1655.9290618896484
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691995835
timesteps_total: 1923150
training_iteration: 163
trial_id: default
train step: 164
agent_timesteps_total: 1936950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018706365867897316
  StateBufferConnector_ms: 0.003316888102778682
  ViewRequirementAgentConnector_ms: 0.11343779387297453
counters:
  num_agent_steps_sampled: 1936950
  num_agent_steps_trained: 1920000
  num_env_steps_sampled: 1936950
  num_env_steps_trained: 1920000
  num_samples_added_to_queue: 1936500
  num_training_step_calls_since_last_synch_worker_weights: 298
  num_weight_broadcasts: 38069
custom_metrics: {}
date: 2023-08-14_15-50-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.203703703703704
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 15133
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7281453013420105
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 22.696535110473633
        total_loss: 51.01626968383789
        var_gnorm: 64.55193328857422
        vf_explained_var: 0.8709045052528381
        vf_loss: 63.92092514038086
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3840.0
  learner_queue:
    size_count: 3846
    size_mean: 15.52
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1178550889985697
  num_agent_steps_sampled: 1936950
  num_agent_steps_trained: 1920000
  num_env_steps_sampled: 1936950
  num_env_steps_trained: 1920000
  num_samples_added_to_queue: 1936500
  num_training_step_calls_since_last_synch_worker_weights: 298
  num_weight_broadcasts: 38069
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 203.819
    learner_load_time_ms: 1.52
    learner_load_wait_time_ms: 1.485
iterations_since_restore: 164
node_ip: 127.0.0.1
num_agent_steps_sampled: 1936950
num_agent_steps_trained: 1920000
num_env_steps_sampled: 1936950
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9976639787162
num_env_steps_trained: 1920000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9977147617876
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.714285714285715
  ram_util_percent: 79.00714285714285
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06795869993264055
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02659972014799354
  mean_inference_ms: 1.2713926351370601
  mean_raw_obs_processing_ms: 0.2886565089508036
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018706365867897316
    StateBufferConnector_ms: 0.003316888102778682
    ViewRequirementAgentConnector_ms: 0.11343779387297453
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.203703703703704
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 7.0, 6.0, 6.0, 10.0, 5.0, 11.0, 9.0, 9.0, 7.0, 4.0, 8.0,
      6.0, 13.0, 6.0, 8.0, 5.0, 6.0, 10.0, 9.0, 5.0, 6.0, 7.0, 9.0, 8.0, 10.0, 9.0,
      6.0, 11.0, 12.0, 11.0, 5.0, 13.0, 8.0, 4.0, 8.0, 10.0, 9.0, 6.0, 7.0, 10.0,
      10.0, 4.0, 7.0, 12.0, 10.0, 11.0, 8.0, 13.0, 10.0, 12.0, 9.0, 12.0, 7.0, 5.0,
      11.0, 6.0, 10.0, 6.0, 5.0, 8.0, 5.0, 10.0, 10.0, 10.0, 5.0, 10.0, 8.0, 11.0,
      4.0, 7.0, 11.0, 7.0, 5.0, 8.0, 7.0, 6.0, 6.0, 6.0, 9.0, 9.0, 5.0, 10.0, 9.0,
      9.0, 10.0, 3.0, 9.0, 8.0, 11.0, 7.0, 9.0, 15.0, 6.0, 7.0, 6.0, 5.0, 9.0, 6.0,
      10.0, 14.0, 8.0, 7.0, 10.0, 9.0, 9.0, 9.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06795869993264055
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02659972014799354
    mean_inference_ms: 1.2713926351370601
    mean_raw_obs_processing_ms: 0.2886565089508036
time_since_restore: 1666.0668828487396
time_this_iter_s: 10.137820959091187
time_total_s: 1666.0668828487396
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995845
timesteps_total: 1936950
training_iteration: 164
trial_id: default
train step: 165
agent_timesteps_total: 1950850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01857545640733507
  StateBufferConnector_ms: 0.003334769496211299
  ViewRequirementAgentConnector_ms: 0.11276028774402759
counters:
  num_agent_steps_sampled: 1950850
  num_agent_steps_trained: 1934000
  num_env_steps_sampled: 1950850
  num_env_steps_trained: 1934000
  num_samples_added_to_queue: 1950500
  num_training_step_calls_since_last_synch_worker_weights: 589
  num_weight_broadcasts: 38343
custom_metrics: {}
date: 2023-08-14_15-50-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.101851851851851
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 15241
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6449164748191833
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -23.38562774658203
        total_loss: 7.3072967529296875
        var_gnorm: 64.55281829833984
        vf_explained_var: 0.8921284675598145
        vf_loss: 67.83501434326172
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3868.0
  learner_queue:
    size_count: 3873
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 1950850
  num_agent_steps_trained: 1934000
  num_env_steps_sampled: 1950850
  num_env_steps_trained: 1934000
  num_samples_added_to_queue: 1950500
  num_training_step_calls_since_last_synch_worker_weights: 589
  num_weight_broadcasts: 38343
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 214.36
    learner_load_time_ms: 1.498
    learner_load_wait_time_ms: 1.481
iterations_since_restore: 165
node_ip: 127.0.0.1
num_agent_steps_sampled: 1950850
num_agent_steps_trained: 1934000
num_env_steps_sampled: 1950850
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9975144907573
num_env_steps_trained: 1934000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9974966093957
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.885714285714286
  ram_util_percent: 78.79999999999998
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06788292092473702
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026565610326229464
  mean_inference_ms: 1.2700064567538216
  mean_raw_obs_processing_ms: 0.28835594608843096
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01857545640733507
    StateBufferConnector_ms: 0.003334769496211299
    ViewRequirementAgentConnector_ms: 0.11276028774402759
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.101851851851851
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 11.0, 11.0, 8.0, 13.0, 2.0, 6.0, 10.0, 11.0, 5.0, 10.0,
      6.0, 8.0, 7.0, 11.0, 11.0, 12.0, 6.0, 4.0, 7.0, 11.0, 10.0, 7.0, 5.0, 4.0, 7.0,
      10.0, 9.0, 14.0, 11.0, 9.0, 5.0, 12.0, 5.0, 6.0, 10.0, 12.0, 9.0, 11.0, 10.0,
      7.0, 9.0, 10.0, 11.0, 10.0, 14.0, 10.0, 9.0, 13.0, 8.0, 11.0, 8.0, 4.0, 6.0,
      9.0, 11.0, 6.0, 8.0, 10.0, 9.0, 6.0, 11.0, 8.0, 8.0, 8.0, 11.0, 11.0, 10.0,
      6.0, 7.0, 18.0, 8.0, 8.0, 10.0, 12.0, 8.0, 13.0, 10.0, 11.0, 12.0, 10.0, 7.0,
      11.0, 13.0, 9.0, 6.0, 8.0, 9.0, 4.0, 9.0, 9.0, 11.0, 12.0, 12.0, 6.0, 10.0,
      11.0, 11.0, 11.0, 12.0, 7.0, 7.0, 12.0, 5.0, 14.0, 5.0, 7.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06788292092473702
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026565610326229464
    mean_inference_ms: 1.2700064567538216
    mean_raw_obs_processing_ms: 0.28835594608843096
time_since_restore: 1676.1907277107239
time_this_iter_s: 10.123844861984253
time_total_s: 1676.1907277107239
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691995855
timesteps_total: 1950850
training_iteration: 165
trial_id: default
train step: 166
agent_timesteps_total: 1964950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018210627815940163
  StateBufferConnector_ms: 0.0032804229042746806
  ViewRequirementAgentConnector_ms: 0.11055729605934837
counters:
  num_agent_steps_sampled: 1964950
  num_agent_steps_trained: 1948000
  num_env_steps_sampled: 1964950
  num_env_steps_trained: 1948000
  num_samples_added_to_queue: 1964500
  num_training_step_calls_since_last_synch_worker_weights: 170
  num_weight_broadcasts: 38617
custom_metrics: {}
date: 2023-08-14_15-51-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.090909090909092
episode_reward_min: 3.0
episodes_this_iter: 110
episodes_total: 15351
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5912280678749084
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 13.846631050109863
        total_loss: 43.748291015625
        var_gnorm: 64.55744934082031
        vf_explained_var: 0.9084410071372986
        vf_loss: 65.7155990600586
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3896.0
  learner_queue:
    size_count: 3902
    size_mean: 15.28
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4005713120009278
  num_agent_steps_sampled: 1964950
  num_agent_steps_trained: 1948000
  num_env_steps_sampled: 1964950
  num_env_steps_trained: 1948000
  num_samples_added_to_queue: 1964500
  num_training_step_calls_since_last_synch_worker_weights: 170
  num_weight_broadcasts: 38617
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 184.673
    learner_load_time_ms: 1.496
    learner_load_wait_time_ms: 1.439
iterations_since_restore: 166
node_ip: 127.0.0.1
num_agent_steps_sampled: 1964950
num_agent_steps_trained: 1948000
num_env_steps_sampled: 1964950
num_env_steps_sampled_this_iter: 14100
num_env_steps_sampled_throughput_per_sec: 1409.995461716954
num_env_steps_trained: 1948000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9954939033585
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.15333333333332
  ram_util_percent: 78.99999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06780275040833336
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02652986046624774
  mean_inference_ms: 1.2685171722796786
  mean_raw_obs_processing_ms: 0.28803457278777633
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018210627815940163
    StateBufferConnector_ms: 0.0032804229042746806
    ViewRequirementAgentConnector_ms: 0.11055729605934837
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.090909090909092
  episode_reward_min: 3.0
  episodes_this_iter: 110
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128]
    episode_reward: [13.0, 7.0, 9.0, 15.0, 11.0, 11.0, 7.0, 11.0, 11.0, 4.0, 9.0,
      9.0, 11.0, 12.0, 10.0, 12.0, 10.0, 9.0, 9.0, 8.0, 7.0, 9.0, 9.0, 10.0, 13.0,
      7.0, 12.0, 11.0, 9.0, 8.0, 11.0, 10.0, 10.0, 8.0, 9.0, 4.0, 7.0, 7.0, 4.0, 8.0,
      9.0, 11.0, 10.0, 11.0, 8.0, 10.0, 5.0, 10.0, 9.0, 10.0, 9.0, 9.0, 8.0, 5.0,
      9.0, 12.0, 11.0, 10.0, 7.0, 6.0, 12.0, 11.0, 10.0, 9.0, 9.0, 9.0, 7.0, 4.0,
      13.0, 10.0, 10.0, 11.0, 4.0, 6.0, 11.0, 12.0, 10.0, 10.0, 8.0, 6.0, 11.0, 9.0,
      9.0, 3.0, 8.0, 10.0, 3.0, 10.0, 7.0, 14.0, 9.0, 12.0, 9.0, 4.0, 9.0, 11.0, 11.0,
      10.0, 7.0, 6.0, 7.0, 6.0, 7.0, 9.0, 9.0, 11.0, 14.0, 10.0, 9.0, 14.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06780275040833336
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02652986046624774
    mean_inference_ms: 1.2685171722796786
    mean_raw_obs_processing_ms: 0.28803457278777633
time_since_restore: 1686.3324856758118
time_this_iter_s: 10.14175796508789
time_total_s: 1686.3324856758118
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691995865
timesteps_total: 1964950
training_iteration: 166
trial_id: default
train step: 167
agent_timesteps_total: 1978750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01872910393608941
  StateBufferConnector_ms: 0.003292383971037688
  ViewRequirementAgentConnector_ms: 0.11412964926825629
counters:
  num_agent_steps_sampled: 1978750
  num_agent_steps_trained: 1962000
  num_env_steps_sampled: 1978750
  num_env_steps_trained: 1962000
  num_samples_added_to_queue: 1978500
  num_training_step_calls_since_last_synch_worker_weights: 571
  num_weight_broadcasts: 38887
custom_metrics: {}
date: 2023-08-14_15-51-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.416666666666666
episode_reward_min: 4.0
episodes_this_iter: 108
episodes_total: 15459
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6508437395095825
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 17.181406021118164
        total_loss: 54.73486328125
        var_gnorm: 64.55722045898438
        vf_explained_var: 0.8871886134147644
        vf_loss: 81.61534881591797
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3924.0
  learner_queue:
    size_count: 3929
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597237
  num_agent_steps_sampled: 1978750
  num_agent_steps_trained: 1962000
  num_env_steps_sampled: 1978750
  num_env_steps_trained: 1962000
  num_samples_added_to_queue: 1978500
  num_training_step_calls_since_last_synch_worker_weights: 571
  num_weight_broadcasts: 38887
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 210.562
    learner_load_time_ms: 1.782
    learner_load_wait_time_ms: 1.598
iterations_since_restore: 167
node_ip: 127.0.0.1
num_agent_steps_sampled: 1978750
num_agent_steps_trained: 1962000
num_env_steps_sampled: 1978750
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.995295063801
num_env_steps_trained: 1962000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9952268763197
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.021428571428565
  ram_util_percent: 79.08571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06773186895258236
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026498115389356272
  mean_inference_ms: 1.2672301776496937
  mean_raw_obs_processing_ms: 0.287757388418435
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01872910393608941
    StateBufferConnector_ms: 0.003292383971037688
    ViewRequirementAgentConnector_ms: 0.11412964926825629
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.416666666666666
  episode_reward_min: 4.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 9.0, 10.0, 13.0, 10.0, 11.0, 9.0, 11.0, 14.0, 8.0, 9.0,
      10.0, 15.0, 10.0, 11.0, 12.0, 10.0, 15.0, 12.0, 8.0, 8.0, 11.0, 7.0, 7.0, 13.0,
      10.0, 11.0, 8.0, 8.0, 15.0, 8.0, 12.0, 11.0, 11.0, 9.0, 4.0, 10.0, 6.0, 5.0,
      9.0, 9.0, 12.0, 7.0, 10.0, 5.0, 11.0, 9.0, 10.0, 9.0, 10.0, 11.0, 11.0, 14.0,
      14.0, 8.0, 11.0, 10.0, 8.0, 15.0, 8.0, 13.0, 8.0, 7.0, 6.0, 6.0, 5.0, 11.0,
      15.0, 7.0, 13.0, 9.0, 7.0, 6.0, 7.0, 9.0, 13.0, 9.0, 8.0, 5.0, 6.0, 8.0, 9.0,
      10.0, 11.0, 4.0, 6.0, 9.0, 8.0, 10.0, 14.0, 7.0, 9.0, 7.0, 7.0, 12.0, 8.0, 9.0,
      13.0, 11.0, 12.0, 7.0, 7.0, 5.0, 8.0, 10.0, 9.0, 7.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06773186895258236
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026498115389356272
    mean_inference_ms: 1.2672301776496937
    mean_raw_obs_processing_ms: 0.287757388418435
time_since_restore: 1696.45645070076
time_this_iter_s: 10.12396502494812
time_total_s: 1696.45645070076
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995875
timesteps_total: 1978750
training_iteration: 167
trial_id: default
train step: 168
agent_timesteps_total: 1992750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01817486502907493
  StateBufferConnector_ms: 0.0032138824462890625
  ViewRequirementAgentConnector_ms: 0.1107833602211692
counters:
  num_agent_steps_sampled: 1992750
  num_agent_steps_trained: 1976000
  num_env_steps_sampled: 1992750
  num_env_steps_trained: 1976000
  num_samples_added_to_queue: 1992500
  num_training_step_calls_since_last_synch_worker_weights: 231
  num_weight_broadcasts: 39162
custom_metrics: {}
date: 2023-08-14_15-51-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.972727272727273
episode_reward_min: 3.0
episodes_this_iter: 110
episodes_total: 15569
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6593832969665527
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.988458633422852
        total_loss: 23.813371658325195
        var_gnorm: 64.55367279052734
        vf_explained_var: 0.8955736756324768
        vf_loss: 66.19749450683594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3952.0
  learner_queue:
    size_count: 3958
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 1992750
  num_agent_steps_trained: 1976000
  num_env_steps_sampled: 1992750
  num_env_steps_trained: 1976000
  num_samples_added_to_queue: 1992500
  num_training_step_calls_since_last_synch_worker_weights: 231
  num_weight_broadcasts: 39162
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 172.601
    learner_load_time_ms: 1.644
    learner_load_wait_time_ms: 1.501
iterations_since_restore: 168
node_ip: 127.0.0.1
num_agent_steps_sampled: 1992750
num_agent_steps_trained: 1976000
num_env_steps_sampled: 1992750
num_env_steps_sampled_this_iter: 14000
num_env_steps_sampled_throughput_per_sec: 1399.9945593091686
num_env_steps_trained: 1976000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9945593091686
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.78571428571429
  ram_util_percent: 79.10714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.067657571180044
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026463856418097387
  mean_inference_ms: 1.2658512887591364
  mean_raw_obs_processing_ms: 0.2874531409652879
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01817486502907493
    StateBufferConnector_ms: 0.0032138824462890625
    ViewRequirementAgentConnector_ms: 0.1107833602211692
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.972727272727273
  episode_reward_min: 3.0
  episodes_this_iter: 110
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128]
    episode_reward: [6.0, 9.0, 15.0, 13.0, 10.0, 9.0, 7.0, 9.0, 5.0, 5.0, 8.0, 7.0,
      10.0, 10.0, 8.0, 9.0, 10.0, 12.0, 13.0, 7.0, 7.0, 9.0, 8.0, 6.0, 8.0, 11.0,
      14.0, 4.0, 10.0, 12.0, 6.0, 8.0, 13.0, 9.0, 7.0, 14.0, 7.0, 3.0, 10.0, 11.0,
      9.0, 6.0, 9.0, 9.0, 12.0, 9.0, 10.0, 9.0, 5.0, 7.0, 7.0, 6.0, 5.0, 5.0, 8.0,
      13.0, 8.0, 14.0, 9.0, 9.0, 11.0, 10.0, 8.0, 8.0, 10.0, 5.0, 9.0, 11.0, 11.0,
      9.0, 8.0, 8.0, 5.0, 8.0, 12.0, 6.0, 7.0, 7.0, 9.0, 9.0, 9.0, 12.0, 14.0, 11.0,
      9.0, 12.0, 7.0, 10.0, 14.0, 7.0, 10.0, 9.0, 9.0, 9.0, 14.0, 8.0, 6.0, 11.0,
      9.0, 9.0, 11.0, 10.0, 11.0, 5.0, 7.0, 12.0, 9.0, 10.0, 6.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.067657571180044
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026463856418097387
    mean_inference_ms: 1.2658512887591364
    mean_raw_obs_processing_ms: 0.2874531409652879
time_since_restore: 1706.5958154201508
time_this_iter_s: 10.13936471939087
time_total_s: 1706.5958154201508
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691995886
timesteps_total: 1992750
training_iteration: 168
trial_id: default
train step: 169
agent_timesteps_total: 2006700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018461253664909152
  StateBufferConnector_ms: 0.00322893125201584
  ViewRequirementAgentConnector_ms: 0.1124740740574828
counters:
  num_agent_steps_sampled: 2006700
  num_agent_steps_trained: 1990000
  num_env_steps_sampled: 2006700
  num_env_steps_trained: 1990000
  num_samples_added_to_queue: 2006500
  num_training_step_calls_since_last_synch_worker_weights: 752
  num_weight_broadcasts: 39438
custom_metrics: {}
date: 2023-08-14_15-51-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 6.798165137614679
episode_reward_min: 2.0
episodes_this_iter: 109
episodes_total: 15678
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6551804542541504
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.869719982147217
        total_loss: 14.512813568115234
        var_gnorm: 64.56200408935547
        vf_explained_var: 0.9331619143486023
        vf_loss: 51.316871643066406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3980.0
  learner_queue:
    size_count: 3985
    size_mean: 15.24
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4636939570825593
  num_agent_steps_sampled: 2006700
  num_agent_steps_trained: 1990000
  num_env_steps_sampled: 2006700
  num_env_steps_trained: 1990000
  num_samples_added_to_queue: 2006500
  num_training_step_calls_since_last_synch_worker_weights: 752
  num_weight_broadcasts: 39438
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 210.753
    learner_load_time_ms: 1.635
    learner_load_wait_time_ms: 1.457
iterations_since_restore: 169
node_ip: 127.0.0.1
num_agent_steps_sampled: 2006700
num_agent_steps_trained: 1990000
num_env_steps_sampled: 2006700
num_env_steps_sampled_this_iter: 13950
num_env_steps_sampled_throughput_per_sec: 1394.9997339249164
num_env_steps_trained: 1990000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9997329712423
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.01333333333333
  ram_util_percent: 79.14666666666669
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06758146141281501
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02642989439537952
  mean_inference_ms: 1.2644988206050638
  mean_raw_obs_processing_ms: 0.2871630845521073
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018461253664909152
    StateBufferConnector_ms: 0.00322893125201584
    ViewRequirementAgentConnector_ms: 0.1124740740574828
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 6.798165137614679
  episode_reward_min: 2.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [8.0, 7.0, 6.0, 5.0, 5.0, 9.0, 3.0, 8.0, 9.0, 6.0, 6.0, 4.0, 11.0,
      9.0, 11.0, 2.0, 8.0, 6.0, 7.0, 7.0, 5.0, 7.0, 7.0, 12.0, 2.0, 8.0, 7.0, 7.0,
      9.0, 8.0, 9.0, 8.0, 5.0, 7.0, 4.0, 5.0, 4.0, 10.0, 7.0, 4.0, 4.0, 9.0, 9.0,
      6.0, 3.0, 6.0, 8.0, 8.0, 7.0, 7.0, 10.0, 9.0, 10.0, 5.0, 8.0, 7.0, 6.0, 5.0,
      7.0, 5.0, 4.0, 6.0, 13.0, 9.0, 6.0, 16.0, 6.0, 6.0, 7.0, 2.0, 4.0, 8.0, 7.0,
      5.0, 4.0, 2.0, 9.0, 9.0, 11.0, 5.0, 4.0, 4.0, 4.0, 6.0, 9.0, 6.0, 7.0, 6.0,
      6.0, 4.0, 7.0, 8.0, 7.0, 2.0, 8.0, 9.0, 5.0, 10.0, 3.0, 5.0, 11.0, 9.0, 9.0,
      3.0, 9.0, 8.0, 6.0, 9.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06758146141281501
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02642989439537952
    mean_inference_ms: 1.2644988206050638
    mean_raw_obs_processing_ms: 0.2871630845521073
time_since_restore: 1716.707796573639
time_this_iter_s: 10.11198115348816
time_total_s: 1716.707796573639
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995896
timesteps_total: 2006700
training_iteration: 169
trial_id: default
train step: 170
agent_timesteps_total: 2020650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01868829814665908
  StateBufferConnector_ms: 0.003311393457815188
  ViewRequirementAgentConnector_ms: 0.11401285818957407
counters:
  num_agent_steps_sampled: 2020650
  num_agent_steps_trained: 2004000
  num_env_steps_sampled: 2020650
  num_env_steps_trained: 2004000
  num_samples_added_to_queue: 2020500
  num_training_step_calls_since_last_synch_worker_weights: 208
  num_weight_broadcasts: 39714
custom_metrics: {}
date: 2023-08-14_15-51-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.256880733944954
episode_reward_min: 2.0
episodes_this_iter: 109
episodes_total: 15787
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.610049307346344
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 4.965935707092285
        total_loss: 13.57713794708252
        var_gnorm: 64.57295227050781
        vf_explained_var: 0.9704758524894714
        vf_loss: 23.32289695739746
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4008.0
  learner_queue:
    size_count: 4014
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3078226179417451
  num_agent_steps_sampled: 2020650
  num_agent_steps_trained: 2004000
  num_env_steps_sampled: 2020650
  num_env_steps_trained: 2004000
  num_samples_added_to_queue: 2020500
  num_training_step_calls_since_last_synch_worker_weights: 208
  num_weight_broadcasts: 39714
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 167.113
    learner_load_time_ms: 1.636
    learner_load_wait_time_ms: 1.4
iterations_since_restore: 170
node_ip: 127.0.0.1
num_agent_steps_sampled: 2020650
num_agent_steps_trained: 2004000
num_env_steps_sampled: 2020650
num_env_steps_sampled_this_iter: 13950
num_env_steps_sampled_throughput_per_sec: 1394.9945454810747
num_env_steps_trained: 2004000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9945259308279
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.442857142857136
  ram_util_percent: 79.27142857142859
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06751739857104644
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026397200987738505
  mean_inference_ms: 1.2631678760420653
  mean_raw_obs_processing_ms: 0.28688120476776297
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01868829814665908
    StateBufferConnector_ms: 0.003311393457815188
    ViewRequirementAgentConnector_ms: 0.11401285818957407
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.256880733944954
  episode_reward_min: 2.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [7.0, 7.0, 7.0, 7.0, 10.0, 7.0, 9.0, 9.0, 9.0, 5.0, 5.0, 8.0,
      6.0, 8.0, 9.0, 6.0, 8.0, 9.0, 10.0, 4.0, 8.0, 8.0, 6.0, 8.0, 7.0, 10.0, 2.0,
      8.0, 4.0, 5.0, 12.0, 9.0, 9.0, 2.0, 9.0, 6.0, 3.0, 10.0, 7.0, 8.0, 9.0, 5.0,
      9.0, 7.0, 7.0, 6.0, 10.0, 7.0, 10.0, 3.0, 11.0, 7.0, 5.0, 6.0, 11.0, 6.0, 7.0,
      5.0, 5.0, 9.0, 5.0, 5.0, 6.0, 10.0, 5.0, 13.0, 9.0, 10.0, 4.0, 7.0, 5.0, 3.0,
      10.0, 9.0, 5.0, 9.0, 9.0, 7.0, 4.0, 8.0, 5.0, 8.0, 12.0, 8.0, 6.0, 6.0, 8.0,
      8.0, 8.0, 5.0, 4.0, 11.0, 6.0, 8.0, 11.0, 6.0, 8.0, 7.0, 7.0, 7.0, 9.0, 6.0,
      12.0, 9.0, 5.0, 6.0, 3.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06751739857104644
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026397200987738505
    mean_inference_ms: 1.2631678760420653
    mean_raw_obs_processing_ms: 0.28688120476776297
time_since_restore: 1726.853230714798
time_this_iter_s: 10.145434141159058
time_total_s: 1726.853230714798
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995906
timesteps_total: 2020650
training_iteration: 170
trial_id: default
train step: 171
agent_timesteps_total: 2034450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018408342644020362
  StateBufferConnector_ms: 0.0032747233355486832
  ViewRequirementAgentConnector_ms: 0.11301106876797146
counters:
  num_agent_steps_sampled: 2034450
  num_agent_steps_trained: 2017500
  num_env_steps_sampled: 2034450
  num_env_steps_trained: 2017500
  num_samples_added_to_queue: 2034000
  num_training_step_calls_since_last_synch_worker_weights: 1106
  num_weight_broadcasts: 39985
custom_metrics: {}
date: 2023-08-14_15-51-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.685185185185185
episode_reward_min: 4.0
episodes_this_iter: 108
episodes_total: 15895
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6530917286872864
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.419942855834961
        total_loss: 0.640225887298584
        var_gnorm: 64.57279968261719
        vf_explained_var: 0.9616233706474304
        vf_loss: 22.651254653930664
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4035.0
  learner_queue:
    size_count: 4039
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3249905660041508
  num_agent_steps_sampled: 2034450
  num_agent_steps_trained: 2017500
  num_env_steps_sampled: 2034450
  num_env_steps_trained: 2017500
  num_samples_added_to_queue: 2034000
  num_training_step_calls_since_last_synch_worker_weights: 1106
  num_weight_broadcasts: 39985
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 255.234
    learner_load_time_ms: 1.795
    learner_load_wait_time_ms: 1.674
iterations_since_restore: 171
node_ip: 127.0.0.1
num_agent_steps_sampled: 2034450
num_agent_steps_trained: 2017500
num_env_steps_sampled: 2034450
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9995722772017
num_env_steps_trained: 2017500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9995815755233
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.48571428571429
  ram_util_percent: 79.14285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06744655171331472
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02636648793225944
  mean_inference_ms: 1.2619422360780879
  mean_raw_obs_processing_ms: 0.2866136125655871
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018408342644020362
    StateBufferConnector_ms: 0.0032747233355486832
    ViewRequirementAgentConnector_ms: 0.11301106876797146
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.685185185185185
  episode_reward_min: 4.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 5.0, 6.0, 11.0, 13.0, 5.0, 10.0, 7.0, 8.0, 10.0, 10.0,
      6.0, 9.0, 9.0, 11.0, 4.0, 8.0, 6.0, 6.0, 9.0, 9.0, 8.0, 8.0, 7.0, 4.0, 6.0,
      13.0, 11.0, 4.0, 12.0, 10.0, 9.0, 11.0, 8.0, 9.0, 7.0, 11.0, 10.0, 9.0, 6.0,
      7.0, 10.0, 7.0, 7.0, 6.0, 10.0, 14.0, 12.0, 10.0, 11.0, 10.0, 7.0, 7.0, 6.0,
      9.0, 4.0, 6.0, 10.0, 8.0, 8.0, 9.0, 6.0, 4.0, 16.0, 7.0, 8.0, 10.0, 8.0, 9.0,
      14.0, 6.0, 4.0, 13.0, 10.0, 11.0, 6.0, 9.0, 11.0, 7.0, 4.0, 9.0, 13.0, 7.0,
      8.0, 4.0, 6.0, 8.0, 6.0, 11.0, 13.0, 9.0, 7.0, 12.0, 11.0, 13.0, 7.0, 9.0, 13.0,
      10.0, 9.0, 7.0, 12.0, 11.0, 12.0, 9.0, 7.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06744655171331472
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02636648793225944
    mean_inference_ms: 1.2619422360780879
    mean_raw_obs_processing_ms: 0.2866136125655871
time_since_restore: 1736.9464917182922
time_this_iter_s: 10.093261003494263
time_total_s: 1736.9464917182922
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691995916
timesteps_total: 2034450
training_iteration: 171
trial_id: default
train step: 172
agent_timesteps_total: 2048050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018756569556470187
  StateBufferConnector_ms: 0.003348656420437795
  ViewRequirementAgentConnector_ms: 0.11423893694607716
counters:
  num_agent_steps_sampled: 2048050
  num_agent_steps_trained: 2031500
  num_env_steps_sampled: 2048050
  num_env_steps_trained: 2031500
  num_samples_added_to_queue: 2048000
  num_training_step_calls_since_last_synch_worker_weights: 442
  num_weight_broadcasts: 40253
custom_metrics: {}
date: 2023-08-14_15-52-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.028301886792454
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 16001
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.558533787727356
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 14.356315612792969
        total_loss: 47.71952438354492
        var_gnorm: 64.57528686523438
        vf_explained_var: 0.8852664828300476
        vf_loss: 72.31175231933594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4063.0
  learner_queue:
    size_count: 4068
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9591663046625439
  num_agent_steps_sampled: 2048050
  num_agent_steps_trained: 2031500
  num_env_steps_sampled: 2048050
  num_env_steps_trained: 2031500
  num_samples_added_to_queue: 2048000
  num_training_step_calls_since_last_synch_worker_weights: 442
  num_weight_broadcasts: 40253
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 205.741
    learner_load_time_ms: 1.509
    learner_load_wait_time_ms: 1.536
iterations_since_restore: 172
node_ip: 127.0.0.1
num_agent_steps_sampled: 2048050
num_agent_steps_trained: 2031500
num_env_steps_sampled: 2048050
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9963684179004
num_env_steps_trained: 2031500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9962616066623
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.028571428571425
  ram_util_percent: 79.1
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06738520880873167
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026339323063005973
  mean_inference_ms: 1.260880474629528
  mean_raw_obs_processing_ms: 0.28636852268758384
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018756569556470187
    StateBufferConnector_ms: 0.003348656420437795
    ViewRequirementAgentConnector_ms: 0.11423893694607716
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.028301886792454
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 9.0, 8.0, 9.0, 15.0, 9.0, 10.0, 9.0, 11.0, 9.0, 13.0, 9.0,
      8.0, 7.0, 6.0, 9.0, 5.0, 8.0, 8.0, 10.0, 5.0, 7.0, 5.0, 3.0, 6.0, 16.0, 7.0,
      12.0, 9.0, 7.0, 5.0, 10.0, 13.0, 9.0, 12.0, 10.0, 9.0, 10.0, 8.0, 10.0, 10.0,
      11.0, 9.0, 11.0, 11.0, 13.0, 9.0, 7.0, 10.0, 12.0, 8.0, 10.0, 7.0, 3.0, 9.0,
      10.0, 8.0, 6.0, 8.0, 7.0, 13.0, 11.0, 6.0, 9.0, 9.0, 10.0, 10.0, 9.0, 11.0,
      12.0, 9.0, 6.0, 4.0, 9.0, 9.0, 11.0, 8.0, 12.0, 10.0, 8.0, 7.0, 11.0, 9.0, 6.0,
      9.0, 9.0, 12.0, 8.0, 9.0, 9.0, 10.0, 12.0, 7.0, 6.0, 10.0, 11.0, 7.0, 11.0,
      11.0, 6.0, 9.0, 11.0, 9.0, 7.0, 8.0, 14.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06738520880873167
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026339323063005973
    mean_inference_ms: 1.260880474629528
    mean_raw_obs_processing_ms: 0.28636852268758384
time_since_restore: 1747.0620849132538
time_this_iter_s: 10.115593194961548
time_total_s: 1747.0620849132538
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995926
timesteps_total: 2048050
training_iteration: 172
trial_id: default
train step: 173
agent_timesteps_total: 2061900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018705359292686533
  StateBufferConnector_ms: 0.003385106357959432
  ViewRequirementAgentConnector_ms: 0.11388183733738891
counters:
  num_agent_steps_sampled: 2061900
  num_agent_steps_trained: 2045000
  num_env_steps_sampled: 2061900
  num_env_steps_trained: 2045000
  num_samples_added_to_queue: 2061500
  num_training_step_calls_since_last_synch_worker_weights: 643
  num_weight_broadcasts: 40527
custom_metrics: {}
date: 2023-08-14_15-52-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.990825688073395
episode_reward_min: 4.0
episodes_this_iter: 109
episodes_total: 16110
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6554902791976929
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -17.024616241455078
        total_loss: -3.9701642990112305
        var_gnorm: 64.57410430908203
        vf_explained_var: 0.9424030184745789
        vf_loss: 32.6638069152832
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4090.0
  learner_queue:
    size_count: 4096
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.40356688476182
  num_agent_steps_sampled: 2061900
  num_agent_steps_trained: 2045000
  num_env_steps_sampled: 2061900
  num_env_steps_trained: 2045000
  num_samples_added_to_queue: 2061500
  num_training_step_calls_since_last_synch_worker_weights: 643
  num_weight_broadcasts: 40527
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 191.057
    learner_load_time_ms: 1.523
    learner_load_wait_time_ms: 1.51
iterations_since_restore: 173
node_ip: 127.0.0.1
num_agent_steps_sampled: 2061900
num_agent_steps_trained: 2045000
num_env_steps_sampled: 2061900
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.9962356192862
num_env_steps_trained: 2045000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9963307480405
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 46.91333333333333
  ram_util_percent: 78.63333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06731683704063796
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026311112314024342
  mean_inference_ms: 1.259667991181694
  mean_raw_obs_processing_ms: 0.2861006200143971
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018705359292686533
    StateBufferConnector_ms: 0.003385106357959432
    ViewRequirementAgentConnector_ms: 0.11388183733738891
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.990825688073395
  episode_reward_min: 4.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [9.0, 11.0, 9.0, 10.0, 5.0, 6.0, 13.0, 7.0, 11.0, 10.0, 12.0,
      10.0, 9.0, 11.0, 9.0, 13.0, 11.0, 10.0, 8.0, 8.0, 4.0, 6.0, 8.0, 11.0, 11.0,
      7.0, 7.0, 9.0, 9.0, 11.0, 14.0, 6.0, 16.0, 11.0, 9.0, 8.0, 11.0, 10.0, 10.0,
      11.0, 11.0, 9.0, 8.0, 9.0, 14.0, 9.0, 9.0, 9.0, 6.0, 6.0, 8.0, 10.0, 8.0, 5.0,
      9.0, 8.0, 11.0, 12.0, 9.0, 9.0, 11.0, 11.0, 8.0, 9.0, 9.0, 6.0, 8.0, 12.0, 9.0,
      9.0, 7.0, 6.0, 9.0, 6.0, 9.0, 8.0, 8.0, 7.0, 10.0, 11.0, 7.0, 9.0, 5.0, 11.0,
      6.0, 8.0, 10.0, 8.0, 12.0, 12.0, 6.0, 13.0, 7.0, 8.0, 9.0, 5.0, 7.0, 7.0, 6.0,
      10.0, 9.0, 8.0, 7.0, 4.0, 12.0, 11.0, 7.0, 12.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06731683704063796
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026311112314024342
    mean_inference_ms: 1.259667991181694
    mean_raw_obs_processing_ms: 0.2861006200143971
time_since_restore: 1757.186594247818
time_this_iter_s: 10.124509334564209
time_total_s: 1757.186594247818
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691995936
timesteps_total: 2061900
training_iteration: 173
trial_id: default
train step: 174
agent_timesteps_total: 2075800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01874279092859339
  StateBufferConnector_ms: 0.003368324703640408
  ViewRequirementAgentConnector_ms: 0.11341395201506438
counters:
  num_agent_steps_sampled: 2075800
  num_agent_steps_trained: 2059000
  num_env_steps_sampled: 2075800
  num_env_steps_trained: 2059000
  num_samples_added_to_queue: 2075500
  num_training_step_calls_since_last_synch_worker_weights: 22
  num_weight_broadcasts: 40802
custom_metrics: {}
date: 2023-08-14_15-52-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.064814814814815
episode_reward_min: 4.0
episodes_this_iter: 108
episodes_total: 16218
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6517094969749451
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -25.307859420776367
        total_loss: 6.594100475311279
        var_gnorm: 64.57543182373047
        vf_explained_var: 0.8838381767272949
        vf_loss: 70.32101440429688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4118.0
  learner_queue:
    size_count: 4125
    size_mean: 15.16
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5793669617919708
  num_agent_steps_sampled: 2075800
  num_agent_steps_trained: 2059000
  num_env_steps_sampled: 2075800
  num_env_steps_trained: 2059000
  num_samples_added_to_queue: 2075500
  num_training_step_calls_since_last_synch_worker_weights: 22
  num_weight_broadcasts: 40802
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 142.453
    learner_load_time_ms: 1.523
    learner_load_wait_time_ms: 1.446
iterations_since_restore: 174
node_ip: 127.0.0.1
num_agent_steps_sampled: 2075800
num_agent_steps_trained: 2059000
num_env_steps_sampled: 2075800
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.994465611559
num_env_steps_trained: 2059000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9944257958148
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.82142857142857
  ram_util_percent: 78.71428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0672537173225925
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026281600235306776
  mean_inference_ms: 1.2584524079520223
  mean_raw_obs_processing_ms: 0.28583151138186286
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01874279092859339
    StateBufferConnector_ms: 0.003368324703640408
    ViewRequirementAgentConnector_ms: 0.11341395201506438
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.064814814814815
  episode_reward_min: 4.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [17.0, 11.0, 11.0, 7.0, 11.0, 10.0, 6.0, 7.0, 9.0, 12.0, 9.0,
      9.0, 8.0, 10.0, 8.0, 15.0, 8.0, 10.0, 13.0, 8.0, 8.0, 13.0, 11.0, 7.0, 6.0,
      12.0, 9.0, 13.0, 10.0, 11.0, 10.0, 5.0, 8.0, 13.0, 10.0, 8.0, 7.0, 9.0, 13.0,
      9.0, 7.0, 7.0, 5.0, 9.0, 9.0, 7.0, 12.0, 8.0, 6.0, 9.0, 5.0, 9.0, 9.0, 12.0,
      7.0, 9.0, 10.0, 9.0, 11.0, 5.0, 8.0, 9.0, 6.0, 7.0, 10.0, 7.0, 11.0, 7.0, 8.0,
      12.0, 8.0, 10.0, 7.0, 6.0, 6.0, 10.0, 9.0, 12.0, 9.0, 12.0, 10.0, 10.0, 10.0,
      12.0, 12.0, 9.0, 8.0, 8.0, 8.0, 8.0, 9.0, 8.0, 5.0, 4.0, 7.0, 11.0, 8.0, 7.0,
      12.0, 9.0, 9.0, 10.0, 8.0, 4.0, 10.0, 14.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0672537173225925
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026281600235306776
    mean_inference_ms: 1.2584524079520223
    mean_raw_obs_processing_ms: 0.28583151138186286
time_since_restore: 1767.3393533229828
time_this_iter_s: 10.152759075164795
time_total_s: 1767.3393533229828
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691995946
timesteps_total: 2075800
training_iteration: 174
trial_id: default
train step: 175
agent_timesteps_total: 2089600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018510332813969365
  StateBufferConnector_ms: 0.0032277018935592088
  ViewRequirementAgentConnector_ms: 0.11379652553134495
counters:
  num_agent_steps_sampled: 2089600
  num_agent_steps_trained: 2073000
  num_env_steps_sampled: 2089600
  num_env_steps_trained: 2073000
  num_samples_added_to_queue: 2089500
  num_training_step_calls_since_last_synch_worker_weights: 428
  num_weight_broadcasts: 41075
custom_metrics: {}
date: 2023-08-14_15-52-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 9.37962962962963
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 16326
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6277022361755371
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -86.4418716430664
        total_loss: -30.962265014648438
        var_gnorm: 64.57475280761719
        vf_explained_var: 0.8311983942985535
        vf_loss: 117.23623657226562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4146.0
  learner_queue:
    size_count: 4152
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6833300330000651
  num_agent_steps_sampled: 2089600
  num_agent_steps_trained: 2073000
  num_env_steps_sampled: 2089600
  num_env_steps_trained: 2073000
  num_samples_added_to_queue: 2089500
  num_training_step_calls_since_last_synch_worker_weights: 428
  num_weight_broadcasts: 41075
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 170.554
    learner_load_time_ms: 1.744
    learner_load_wait_time_ms: 1.49
iterations_since_restore: 175
node_ip: 127.0.0.1
num_agent_steps_sampled: 2089600
num_agent_steps_trained: 2073000
num_env_steps_sampled: 2089600
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9958543902003
num_env_steps_trained: 2073000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.995794308899
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.85
  ram_util_percent: 78.78571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06718901306356272
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026253763794374392
  mean_inference_ms: 1.257302322231413
  mean_raw_obs_processing_ms: 0.2855851427436194
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018510332813969365
    StateBufferConnector_ms: 0.0032277018935592088
    ViewRequirementAgentConnector_ms: 0.11379652553134495
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 9.37962962962963
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 10.0, 10.0, 12.0, 7.0, 7.0, 9.0, 11.0, 6.0, 10.0, 3.0,
      13.0, 11.0, 7.0, 13.0, 8.0, 7.0, 12.0, 12.0, 10.0, 11.0, 6.0, 9.0, 14.0, 7.0,
      7.0, 6.0, 6.0, 5.0, 11.0, 9.0, 5.0, 9.0, 8.0, 6.0, 11.0, 9.0, 5.0, 7.0, 7.0,
      8.0, 10.0, 13.0, 9.0, 5.0, 10.0, 11.0, 12.0, 11.0, 19.0, 11.0, 11.0, 11.0, 9.0,
      9.0, 6.0, 3.0, 14.0, 6.0, 12.0, 9.0, 13.0, 8.0, 12.0, 11.0, 9.0, 10.0, 7.0,
      6.0, 8.0, 9.0, 8.0, 10.0, 11.0, 9.0, 3.0, 8.0, 10.0, 11.0, 10.0, 13.0, 6.0,
      6.0, 6.0, 11.0, 8.0, 13.0, 13.0, 6.0, 5.0, 13.0, 12.0, 8.0, 7.0, 7.0, 7.0, 11.0,
      13.0, 10.0, 14.0, 11.0, 12.0, 11.0, 12.0, 14.0, 13.0, 11.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06718901306356272
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026253763794374392
    mean_inference_ms: 1.257302322231413
    mean_raw_obs_processing_ms: 0.2855851427436194
time_since_restore: 1777.4728362560272
time_this_iter_s: 10.133482933044434
time_total_s: 1777.4728362560272
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691995956
timesteps_total: 2089600
training_iteration: 175
trial_id: default
train step: 176
agent_timesteps_total: 2103500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018367723182395653
  StateBufferConnector_ms: 0.003272957271999783
  ViewRequirementAgentConnector_ms: 0.1124616022463198
counters:
  num_agent_steps_sampled: 2103500
  num_agent_steps_trained: 2087000
  num_env_steps_sampled: 2103500
  num_env_steps_trained: 2087000
  num_samples_added_to_queue: 2103500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 41345
custom_metrics: {}
date: 2023-08-14_15-52-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.527777777777779
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 16434
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6130906939506531
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 164.53826904296875
        total_loss: 318.1766662597656
        var_gnorm: 64.57132720947266
        vf_explained_var: 0.6250243186950684
        vf_loss: 313.4077453613281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4174.0
  learner_queue:
    size_count: 4180
    size_mean: 15.24
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4636939570825591
  num_agent_steps_sampled: 2103500
  num_agent_steps_trained: 2087000
  num_env_steps_sampled: 2103500
  num_env_steps_trained: 2087000
  num_samples_added_to_queue: 2103500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 41345
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 159.876
    learner_load_time_ms: 1.62
    learner_load_wait_time_ms: 1.418
iterations_since_restore: 176
node_ip: 127.0.0.1
num_agent_steps_sampled: 2103500
num_agent_steps_trained: 2087000
num_env_steps_sampled: 2103500
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1388.285191554926
num_env_steps_trained: 2087000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1398.2728548035225
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.61999999999999
  ram_util_percent: 78.83333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0671255238888585
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02622578699573268
  mean_inference_ms: 1.2561326486932818
  mean_raw_obs_processing_ms: 0.2853209119450458
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018367723182395653
    StateBufferConnector_ms: 0.003272957271999783
    ViewRequirementAgentConnector_ms: 0.1124616022463198
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.527777777777779
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 13.0, 10.0, 9.0, 8.0, 13.0, 10.0, 11.0, 12.0, 14.0, 8.0,
      8.0, 5.0, 13.0, 9.0, 8.0, 8.0, 11.0, 14.0, 3.0, 11.0, 11.0, 14.0, 16.0, 9.0,
      10.0, 12.0, 9.0, 11.0, 12.0, 11.0, 10.0, 11.0, 8.0, 7.0, 14.0, 10.0, 11.0, 7.0,
      11.0, 10.0, 8.0, 9.0, 6.0, 12.0, 12.0, 12.0, 8.0, 10.0, 9.0, 7.0, 10.0, 6.0,
      11.0, 6.0, 7.0, 15.0, 8.0, 10.0, 13.0, 8.0, 8.0, 6.0, 10.0, 11.0, 11.0, 6.0,
      10.0, 9.0, 15.0, 7.0, 10.0, 7.0, 5.0, 8.0, 12.0, 11.0, 8.0, 7.0, 6.0, 7.0, 12.0,
      9.0, 9.0, 11.0, 6.0, 8.0, 8.0, 15.0, 8.0, 8.0, 6.0, 13.0, 8.0, 6.0, 9.0, 6.0,
      10.0, 12.0, 11.0, 12.0, 12.0, 8.0, 7.0, 9.0, 5.0, 9.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0671255238888585
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02622578699573268
    mean_inference_ms: 1.2561326486932818
    mean_raw_obs_processing_ms: 0.2853209119450458
time_since_restore: 1787.614230632782
time_this_iter_s: 10.14139437675476
time_total_s: 1787.614230632782
timers:
  sample_time_ms: 0.08
  synch_weights_time_ms: 0.863
  training_iteration_time_ms: 2.336
timestamp: 1691995967
timesteps_total: 2103500
training_iteration: 176
trial_id: default
train step: 177
agent_timesteps_total: 2117150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018515096646603023
  StateBufferConnector_ms: 0.0033427621716650845
  ViewRequirementAgentConnector_ms: 0.1128927569523036
counters:
  num_agent_steps_sampled: 2117150
  num_agent_steps_trained: 2100500
  num_env_steps_sampled: 2117150
  num_env_steps_trained: 2100500
  num_samples_added_to_queue: 2117000
  num_training_step_calls_since_last_synch_worker_weights: 286
  num_weight_broadcasts: 41616
custom_metrics: {}
date: 2023-08-14_15-52-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.485981308411215
episode_reward_min: 4.0
episodes_this_iter: 107
episodes_total: 16541
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.592509388923645
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -52.59450149536133
        total_loss: 2.641045093536377
        var_gnorm: 64.57693481445312
        vf_explained_var: 0.8354494571685791
        vf_loss: 116.39618682861328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4201.0
  learner_queue:
    size_count: 4207
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 2117150
  num_agent_steps_trained: 2100500
  num_env_steps_sampled: 2117150
  num_env_steps_trained: 2100500
  num_samples_added_to_queue: 2117000
  num_training_step_calls_since_last_synch_worker_weights: 286
  num_weight_broadcasts: 41616
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 167.112
    learner_load_time_ms: 1.587
    learner_load_wait_time_ms: 1.517
iterations_since_restore: 177
node_ip: 127.0.0.1
num_agent_steps_sampled: 2117150
num_agent_steps_trained: 2100500
num_env_steps_sampled: 2117150
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.992612521099
num_env_steps_trained: 2100500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9926937021858
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.2
  ram_util_percent: 78.37142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06706853689821417
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026199156434828667
  mean_inference_ms: 1.2550953072166458
  mean_raw_obs_processing_ms: 0.2850796129269863
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018515096646603023
    StateBufferConnector_ms: 0.0033427621716650845
    ViewRequirementAgentConnector_ms: 0.1128927569523036
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.485981308411215
  episode_reward_min: 4.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 4.0, 9.0, 6.0, 14.0, 8.0, 8.0, 8.0, 8.0, 8.0, 7.0, 10.0,
      11.0, 7.0, 11.0, 16.0, 10.0, 11.0, 10.0, 15.0, 8.0, 6.0, 11.0, 11.0, 8.0, 8.0,
      14.0, 7.0, 5.0, 13.0, 11.0, 5.0, 15.0, 9.0, 10.0, 9.0, 8.0, 10.0, 4.0, 8.0,
      8.0, 8.0, 8.0, 10.0, 12.0, 7.0, 11.0, 11.0, 10.0, 6.0, 6.0, 15.0, 11.0, 17.0,
      9.0, 13.0, 9.0, 11.0, 9.0, 11.0, 11.0, 7.0, 6.0, 10.0, 9.0, 9.0, 5.0, 4.0, 11.0,
      6.0, 10.0, 10.0, 11.0, 17.0, 8.0, 14.0, 11.0, 7.0, 11.0, 8.0, 13.0, 10.0, 11.0,
      6.0, 8.0, 13.0, 11.0, 12.0, 13.0, 5.0, 9.0, 8.0, 13.0, 9.0, 11.0, 9.0, 14.0,
      8.0, 5.0, 8.0, 8.0, 5.0, 8.0, 5.0, 13.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06706853689821417
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026199156434828667
    mean_inference_ms: 1.2550953072166458
    mean_raw_obs_processing_ms: 0.2850796129269863
time_since_restore: 1797.7510342597961
time_this_iter_s: 10.13680362701416
time_total_s: 1797.7510342597961
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995977
timesteps_total: 2117150
training_iteration: 177
trial_id: default
train step: 178
agent_timesteps_total: 2130850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018867599629910192
  StateBufferConnector_ms: 0.0034082715756425233
  ViewRequirementAgentConnector_ms: 0.1137635418187792
counters:
  num_agent_steps_sampled: 2130850
  num_agent_steps_trained: 2114000
  num_env_steps_sampled: 2130850
  num_env_steps_trained: 2114000
  num_samples_added_to_queue: 2130500
  num_training_step_calls_since_last_synch_worker_weights: 772
  num_weight_broadcasts: 41886
custom_metrics: {}
date: 2023-08-14_15-53-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.542056074766355
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 16648
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.611944317817688
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -103.0224838256836
        total_loss: 19.941232681274414
        var_gnorm: 64.57411193847656
        vf_explained_var: 0.6626268625259399
        vf_loss: 252.046875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4228.0
  learner_queue:
    size_count: 4233
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.40356688476182
  num_agent_steps_sampled: 2130850
  num_agent_steps_trained: 2114000
  num_env_steps_sampled: 2130850
  num_env_steps_trained: 2114000
  num_samples_added_to_queue: 2130500
  num_training_step_calls_since_last_synch_worker_weights: 772
  num_weight_broadcasts: 41886
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 219.67
    learner_load_time_ms: 1.748
    learner_load_wait_time_ms: 1.472
iterations_since_restore: 178
node_ip: 127.0.0.1
num_agent_steps_sampled: 2130850
num_agent_steps_trained: 2114000
num_env_steps_sampled: 2130850
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.993402036018
num_env_steps_trained: 2114000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9934983566602
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.9
  ram_util_percent: 78.39285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06700540918958024
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026173934333917778
  mean_inference_ms: 1.2540443823729484
  mean_raw_obs_processing_ms: 0.284853603057182
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018867599629910192
    StateBufferConnector_ms: 0.0034082715756425233
    ViewRequirementAgentConnector_ms: 0.1137635418187792
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.542056074766355
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [14.0, 6.0, 11.0, 12.0, 14.0, 9.0, 9.0, 6.0, 13.0, 8.0, 9.0, 3.0,
      11.0, 10.0, 6.0, 9.0, 8.0, 13.0, 16.0, 12.0, 12.0, 7.0, 12.0, 13.0, 10.0, 6.0,
      12.0, 10.0, 8.0, 8.0, 7.0, 5.0, 9.0, 9.0, 6.0, 6.0, 8.0, 7.0, 7.0, 10.0, 3.0,
      9.0, 6.0, 13.0, 9.0, 7.0, 10.0, 6.0, 16.0, 8.0, 7.0, 8.0, 7.0, 9.0, 6.0, 7.0,
      5.0, 9.0, 9.0, 15.0, 7.0, 11.0, 9.0, 14.0, 11.0, 12.0, 10.0, 10.0, 17.0, 12.0,
      6.0, 13.0, 11.0, 9.0, 8.0, 12.0, 12.0, 10.0, 12.0, 8.0, 10.0, 9.0, 13.0, 13.0,
      12.0, 11.0, 10.0, 11.0, 13.0, 11.0, 11.0, 16.0, 14.0, 9.0, 5.0, 7.0, 9.0, 6.0,
      7.0, 10.0, 8.0, 7.0, 5.0, 9.0, 11.0, 8.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06700540918958024
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026173934333917778
    mean_inference_ms: 1.2540443823729484
    mean_raw_obs_processing_ms: 0.284853603057182
time_since_restore: 1807.8630714416504
time_this_iter_s: 10.112037181854248
time_total_s: 1807.8630714416504
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691995987
timesteps_total: 2130850
training_iteration: 178
trial_id: default
train step: 179
agent_timesteps_total: 2144800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018441786459826547
  StateBufferConnector_ms: 0.0033781069134353496
  ViewRequirementAgentConnector_ms: 0.11294872388927214
counters:
  num_agent_steps_sampled: 2144800
  num_agent_steps_trained: 2128000
  num_env_steps_sampled: 2144800
  num_env_steps_trained: 2128000
  num_samples_added_to_queue: 2144500
  num_training_step_calls_since_last_synch_worker_weights: 14
  num_weight_broadcasts: 42162
custom_metrics: {}
date: 2023-08-14_15-53-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.119266055045872
episode_reward_min: 3.0
episodes_this_iter: 109
episodes_total: 16757
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6356868743896484
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -44.63087463378906
        total_loss: 32.08674621582031
        var_gnorm: 64.5795669555664
        vf_explained_var: 0.7719045877456665
        vf_loss: 159.7921142578125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4256.0
  learner_queue:
    size_count: 4263
    size_mean: 15.3
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4594519519326423
  num_agent_steps_sampled: 2144800
  num_agent_steps_trained: 2128000
  num_env_steps_sampled: 2144800
  num_env_steps_trained: 2128000
  num_samples_added_to_queue: 2144500
  num_training_step_calls_since_last_synch_worker_weights: 14
  num_weight_broadcasts: 42162
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 145.206
    learner_load_time_ms: 1.719
    learner_load_wait_time_ms: 1.432
iterations_since_restore: 179
node_ip: 127.0.0.1
num_agent_steps_sampled: 2144800
num_agent_steps_trained: 2128000
num_env_steps_sampled: 2144800
num_env_steps_sampled_this_iter: 13950
num_env_steps_sampled_throughput_per_sec: 1394.9956762924692
num_env_steps_trained: 2128000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9956607953095
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.88666666666667
  ram_util_percent: 78.68666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06694729312244345
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026145839054855277
  mean_inference_ms: 1.2528533924389844
  mean_raw_obs_processing_ms: 0.28459373560343176
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018441786459826547
    StateBufferConnector_ms: 0.0033781069134353496
    ViewRequirementAgentConnector_ms: 0.11294872388927214
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.119266055045872
  episode_reward_min: 3.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [11.0, 9.0, 8.0, 12.0, 8.0, 7.0, 10.0, 14.0, 10.0, 7.0, 7.0, 9.0,
      15.0, 8.0, 7.0, 8.0, 11.0, 8.0, 7.0, 10.0, 8.0, 8.0, 17.0, 9.0, 6.0, 13.0, 5.0,
      8.0, 13.0, 11.0, 10.0, 7.0, 9.0, 10.0, 9.0, 6.0, 8.0, 8.0, 8.0, 4.0, 11.0, 9.0,
      6.0, 9.0, 11.0, 8.0, 8.0, 5.0, 14.0, 9.0, 5.0, 11.0, 5.0, 13.0, 6.0, 8.0, 6.0,
      13.0, 9.0, 15.0, 9.0, 5.0, 10.0, 11.0, 10.0, 12.0, 12.0, 9.0, 8.0, 3.0, 6.0,
      5.0, 9.0, 10.0, 7.0, 9.0, 5.0, 5.0, 13.0, 8.0, 15.0, 7.0, 7.0, 7.0, 11.0, 8.0,
      11.0, 6.0, 13.0, 9.0, 10.0, 11.0, 9.0, 12.0, 5.0, 14.0, 12.0, 11.0, 7.0, 7.0,
      10.0, 10.0, 13.0, 11.0, 14.0, 9.0, 9.0, 7.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06694729312244345
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026145839054855277
    mean_inference_ms: 1.2528533924389844
    mean_raw_obs_processing_ms: 0.28459373560343176
time_since_restore: 1818.015263557434
time_this_iter_s: 10.152192115783691
time_total_s: 1818.015263557434
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691995997
timesteps_total: 2144800
training_iteration: 179
trial_id: default
train step: 180
agent_timesteps_total: 2158500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01856812806887047
  StateBufferConnector_ms: 0.003327164694527599
  ViewRequirementAgentConnector_ms: 0.11363631096955772
counters:
  num_agent_steps_sampled: 2158500
  num_agent_steps_trained: 2142000
  num_env_steps_sampled: 2158500
  num_env_steps_trained: 2142000
  num_samples_added_to_queue: 2158500
  num_training_step_calls_since_last_synch_worker_weights: 141
  num_weight_broadcasts: 42433
custom_metrics: {}
date: 2023-08-14_15-53-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.345794392523365
episode_reward_min: 4.0
episodes_this_iter: 107
episodes_total: 16864
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6243067979812622
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 10.526680946350098
        total_loss: 30.0825252532959
        var_gnorm: 64.5764389038086
        vf_explained_var: 0.9311360120773315
        vf_loss: 45.354759216308594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4284.0
  learner_queue:
    size_count: 4290
    size_mean: 15.1
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6763054614240211
  num_agent_steps_sampled: 2158500
  num_agent_steps_trained: 2142000
  num_env_steps_sampled: 2158500
  num_env_steps_trained: 2142000
  num_samples_added_to_queue: 2158500
  num_training_step_calls_since_last_synch_worker_weights: 141
  num_weight_broadcasts: 42433
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 167.072
    learner_load_time_ms: 1.497
    learner_load_wait_time_ms: 1.55
iterations_since_restore: 180
node_ip: 127.0.0.1
num_agent_steps_sampled: 2158500
num_agent_steps_trained: 2142000
num_env_steps_sampled: 2158500
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.999738693287
num_env_steps_trained: 2142000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9997329712423
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.92857142857142
  ram_util_percent: 78.62857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0668867700886878
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02612242890837207
  mean_inference_ms: 1.2518513035434482
  mean_raw_obs_processing_ms: 0.2843732405331278
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01856812806887047
    StateBufferConnector_ms: 0.003327164694527599
    ViewRequirementAgentConnector_ms: 0.11363631096955772
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.345794392523365
  episode_reward_min: 4.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 6.0, 10.0, 12.0, 7.0, 13.0, 13.0, 9.0, 8.0, 8.0, 9.0, 5.0,
      8.0, 13.0, 17.0, 7.0, 13.0, 8.0, 13.0, 8.0, 6.0, 7.0, 10.0, 11.0, 11.0, 11.0,
      6.0, 6.0, 8.0, 9.0, 16.0, 9.0, 8.0, 12.0, 4.0, 15.0, 16.0, 9.0, 15.0, 6.0, 9.0,
      9.0, 9.0, 10.0, 8.0, 9.0, 13.0, 9.0, 9.0, 7.0, 9.0, 4.0, 8.0, 13.0, 6.0, 6.0,
      4.0, 11.0, 12.0, 12.0, 10.0, 5.0, 11.0, 9.0, 11.0, 9.0, 12.0, 9.0, 6.0, 9.0,
      6.0, 9.0, 10.0, 12.0, 10.0, 9.0, 8.0, 13.0, 9.0, 9.0, 10.0, 9.0, 7.0, 11.0,
      11.0, 11.0, 6.0, 17.0, 8.0, 8.0, 10.0, 4.0, 9.0, 10.0, 6.0, 7.0, 7.0, 11.0,
      12.0, 4.0, 7.0, 13.0, 11.0, 10.0, 9.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0668867700886878
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02612242890837207
    mean_inference_ms: 1.2518513035434482
    mean_raw_obs_processing_ms: 0.2843732405331278
time_since_restore: 1828.1475851535797
time_this_iter_s: 10.13232159614563
time_total_s: 1828.1475851535797
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996007
timesteps_total: 2158500
training_iteration: 180
trial_id: default
train step: 181
agent_timesteps_total: 2172450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01849143876941926
  StateBufferConnector_ms: 0.0033700138057043793
  ViewRequirementAgentConnector_ms: 0.1122183755997124
counters:
  num_agent_steps_sampled: 2172450
  num_agent_steps_trained: 2155500
  num_env_steps_sampled: 2172450
  num_env_steps_trained: 2155500
  num_samples_added_to_queue: 2172000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 42708
custom_metrics: {}
date: 2023-08-14_15-53-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 8.862385321100918
episode_reward_min: 3.0
episodes_this_iter: 109
episodes_total: 16973
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6406450867652893
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -60.882347106933594
        total_loss: 3.7826602458953857
        var_gnorm: 64.57892608642578
        vf_explained_var: 0.7827060222625732
        vf_loss: 135.73646545410156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4311.0
  learner_queue:
    size_count: 4315
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2631706139710503
  num_agent_steps_sampled: 2172450
  num_agent_steps_trained: 2155500
  num_env_steps_sampled: 2172450
  num_env_steps_trained: 2155500
  num_samples_added_to_queue: 2172000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 42708
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 257.8
    learner_load_time_ms: 1.498
    learner_load_wait_time_ms: 1.722
iterations_since_restore: 181
node_ip: 127.0.0.1
num_agent_steps_sampled: 2172450
num_agent_steps_trained: 2155500
num_env_steps_sampled: 2172450
num_env_steps_sampled_this_iter: 13950
num_env_steps_sampled_throughput_per_sec: 1394.6918865437337
num_env_steps_trained: 2155500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.7018256874842
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 46.642857142857146
  ram_util_percent: 78.64285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06683104613363407
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026093959064594933
  mean_inference_ms: 1.2506834986618363
  mean_raw_obs_processing_ms: 0.28412196715632015
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01849143876941926
    StateBufferConnector_ms: 0.0033700138057043793
    ViewRequirementAgentConnector_ms: 0.1122183755997124
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 8.862385321100918
  episode_reward_min: 3.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [7.0, 6.0, 6.0, 12.0, 6.0, 7.0, 11.0, 11.0, 8.0, 7.0, 9.0, 7.0,
      11.0, 6.0, 9.0, 11.0, 11.0, 6.0, 11.0, 10.0, 4.0, 8.0, 9.0, 8.0, 10.0, 8.0,
      9.0, 10.0, 18.0, 8.0, 10.0, 6.0, 11.0, 7.0, 10.0, 11.0, 8.0, 10.0, 10.0, 7.0,
      10.0, 8.0, 6.0, 11.0, 9.0, 11.0, 5.0, 10.0, 7.0, 6.0, 3.0, 14.0, 9.0, 11.0,
      12.0, 7.0, 6.0, 7.0, 6.0, 10.0, 12.0, 10.0, 12.0, 13.0, 8.0, 9.0, 8.0, 6.0,
      8.0, 5.0, 12.0, 11.0, 7.0, 4.0, 6.0, 11.0, 11.0, 8.0, 10.0, 9.0, 11.0, 7.0,
      9.0, 10.0, 9.0, 8.0, 9.0, 14.0, 10.0, 10.0, 7.0, 10.0, 10.0, 11.0, 8.0, 9.0,
      9.0, 7.0, 8.0, 10.0, 8.0, 8.0, 11.0, 9.0, 9.0, 9.0, 6.0, 10.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06683104613363407
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026093959064594933
    mean_inference_ms: 1.2506834986618363
    mean_raw_obs_processing_ms: 0.28412196715632015
time_since_restore: 1838.2323122024536
time_this_iter_s: 10.084727048873901
time_total_s: 1838.2323122024536
timers:
  sample_time_ms: 0.039
  synch_weights_time_ms: 0.277
  training_iteration_time_ms: 0.378
timestamp: 1691996017
timesteps_total: 2172450
training_iteration: 181
trial_id: default
train step: 182
agent_timesteps_total: 2186200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018581274513886355
  StateBufferConnector_ms: 0.00335724554329275
  ViewRequirementAgentConnector_ms: 0.1145302692306376
counters:
  num_agent_steps_sampled: 2186200
  num_agent_steps_trained: 2169500
  num_env_steps_sampled: 2186200
  num_env_steps_trained: 2169500
  num_samples_added_to_queue: 2186000
  num_training_step_calls_since_last_synch_worker_weights: 780
  num_weight_broadcasts: 42980
custom_metrics: {}
date: 2023-08-14_15-53-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.448598130841122
episode_reward_min: 4.0
episodes_this_iter: 107
episodes_total: 17080
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6642827391624451
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.345081329345703
        total_loss: 46.52455139160156
        var_gnorm: 64.57911682128906
        vf_explained_var: 0.8117151260375977
        vf_loss: 120.38209533691406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4339.0
  learner_queue:
    size_count: 4344
    size_mean: 15.64
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9112628599915613
  num_agent_steps_sampled: 2186200
  num_agent_steps_trained: 2169500
  num_env_steps_sampled: 2186200
  num_env_steps_trained: 2169500
  num_samples_added_to_queue: 2186000
  num_training_step_calls_since_last_synch_worker_weights: 780
  num_weight_broadcasts: 42980
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 209.329
    learner_load_time_ms: 1.515
    learner_load_wait_time_ms: 1.506
iterations_since_restore: 182
node_ip: 127.0.0.1
num_agent_steps_sampled: 2186200
num_agent_steps_trained: 2169500
num_env_steps_sampled: 2186200
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9965906227726
num_env_steps_trained: 2169500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9965286340957
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 43.457142857142856
  ram_util_percent: 78.80714285714285
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06676701370798521
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.026069465127339875
  mean_inference_ms: 1.2496445338955995
  mean_raw_obs_processing_ms: 0.28388804590334604
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018581274513886355
    StateBufferConnector_ms: 0.00335724554329275
    ViewRequirementAgentConnector_ms: 0.1145302692306376
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.448598130841122
  episode_reward_min: 4.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 6.0, 7.0, 14.0, 8.0, 13.0, 9.0, 10.0, 15.0, 9.0, 14.0,
      10.0, 9.0, 7.0, 12.0, 8.0, 6.0, 8.0, 11.0, 9.0, 9.0, 11.0, 10.0, 5.0, 6.0, 9.0,
      11.0, 5.0, 6.0, 13.0, 9.0, 8.0, 9.0, 8.0, 11.0, 8.0, 6.0, 10.0, 13.0, 10.0,
      12.0, 11.0, 6.0, 10.0, 8.0, 6.0, 6.0, 13.0, 9.0, 6.0, 9.0, 9.0, 9.0, 13.0, 10.0,
      12.0, 13.0, 12.0, 7.0, 11.0, 16.0, 10.0, 7.0, 7.0, 11.0, 4.0, 11.0, 10.0, 10.0,
      12.0, 7.0, 12.0, 14.0, 12.0, 9.0, 9.0, 8.0, 9.0, 10.0, 6.0, 6.0, 10.0, 6.0,
      11.0, 11.0, 10.0, 10.0, 14.0, 10.0, 5.0, 10.0, 11.0, 8.0, 7.0, 9.0, 8.0, 11.0,
      13.0, 7.0, 18.0, 10.0, 9.0, 8.0, 5.0, 6.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06676701370798521
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.026069465127339875
    mean_inference_ms: 1.2496445338955995
    mean_raw_obs_processing_ms: 0.28388804590334604
time_since_restore: 1848.344650030136
time_this_iter_s: 10.112337827682495
time_total_s: 1848.344650030136
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996027
timesteps_total: 2186200
training_iteration: 182
trial_id: default
train step: 183
agent_timesteps_total: 2200000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01885935112282082
  StateBufferConnector_ms: 0.003329250547620985
  ViewRequirementAgentConnector_ms: 0.1127569763748734
counters:
  num_agent_steps_sampled: 2200000
  num_agent_steps_trained: 2183500
  num_env_steps_sampled: 2200000
  num_env_steps_trained: 2183500
  num_samples_added_to_queue: 2200000
  num_training_step_calls_since_last_synch_worker_weights: 868
  num_weight_broadcasts: 43253
custom_metrics: {}
date: 2023-08-14_15-53-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.351851851851851
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 17188
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.695396900177002
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 65.38414001464844
        total_loss: 132.11956787109375
        var_gnorm: 64.58018493652344
        vf_explained_var: 0.8065134286880493
        vf_loss: 140.42481994628906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4367.0
  learner_queue:
    size_count: 4371
    size_mean: 15.58
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9816312953446422
  num_agent_steps_sampled: 2200000
  num_agent_steps_trained: 2183500
  num_env_steps_sampled: 2200000
  num_env_steps_trained: 2183500
  num_samples_added_to_queue: 2200000
  num_training_step_calls_since_last_synch_worker_weights: 868
  num_weight_broadcasts: 43253
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 232.217
    learner_load_time_ms: 1.34
    learner_load_wait_time_ms: 1.6
iterations_since_restore: 183
node_ip: 127.0.0.1
num_agent_steps_sampled: 2200000
num_agent_steps_trained: 2183500
num_env_steps_sampled: 2200000
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9981904053575
num_env_steps_trained: 2183500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9981641793481
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.42
  ram_util_percent: 78.88000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06671077345175314
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02604321506901622
  mean_inference_ms: 1.2485765793747892
  mean_raw_obs_processing_ms: 0.28366505041601553
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01885935112282082
    StateBufferConnector_ms: 0.003329250547620985
    ViewRequirementAgentConnector_ms: 0.1127569763748734
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.351851851851851
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [14.0, 16.0, 6.0, 3.0, 3.0, 14.0, 9.0, 10.0, 10.0, 9.0, 14.0,
      8.0, 14.0, 5.0, 11.0, 13.0, 7.0, 9.0, 13.0, 9.0, 7.0, 8.0, 13.0, 8.0, 7.0, 8.0,
      12.0, 6.0, 11.0, 8.0, 16.0, 9.0, 4.0, 11.0, 8.0, 10.0, 11.0, 10.0, 7.0, 8.0,
      7.0, 12.0, 14.0, 7.0, 6.0, 12.0, 13.0, 8.0, 10.0, 14.0, 10.0, 5.0, 16.0, 14.0,
      9.0, 8.0, 9.0, 11.0, 12.0, 8.0, 8.0, 11.0, 6.0, 7.0, 4.0, 10.0, 12.0, 10.0,
      6.0, 8.0, 11.0, 14.0, 8.0, 5.0, 12.0, 7.0, 10.0, 9.0, 7.0, 10.0, 9.0, 10.0,
      8.0, 10.0, 12.0, 8.0, 6.0, 12.0, 13.0, 8.0, 8.0, 9.0, 7.0, 11.0, 9.0, 11.0,
      13.0, 7.0, 8.0, 8.0, 8.0, 10.0, 7.0, 7.0, 10.0, 7.0, 6.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06671077345175314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02604321506901622
    mean_inference_ms: 1.2485765793747892
    mean_raw_obs_processing_ms: 0.28366505041601553
time_since_restore: 1858.4404559135437
time_this_iter_s: 10.095805883407593
time_total_s: 1858.4404559135437
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996038
timesteps_total: 2200000
training_iteration: 183
trial_id: default
train step: 184
agent_timesteps_total: 2213900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018794383477727206
  StateBufferConnector_ms: 0.003314455714794474
  ViewRequirementAgentConnector_ms: 0.11245788784202086
counters:
  num_agent_steps_sampled: 2213900
  num_agent_steps_trained: 2197000
  num_env_steps_sampled: 2213900
  num_env_steps_trained: 2197000
  num_samples_added_to_queue: 2213500
  num_training_step_calls_since_last_synch_worker_weights: 349
  num_weight_broadcasts: 43527
custom_metrics: {}
date: 2023-08-14_15-54-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.146788990825687
episode_reward_min: 3.0
episodes_this_iter: 109
episodes_total: 17297
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5983126163482666
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.45383071899414
        total_loss: 19.99342155456543
        var_gnorm: 64.58402252197266
        vf_explained_var: 0.9201328158378601
        vf_loss: 64.87763214111328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4394.0
  learner_queue:
    size_count: 4400
    size_mean: 15.52
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1178550889985697
  num_agent_steps_sampled: 2213900
  num_agent_steps_trained: 2197000
  num_env_steps_sampled: 2213900
  num_env_steps_trained: 2197000
  num_samples_added_to_queue: 2213500
  num_training_step_calls_since_last_synch_worker_weights: 349
  num_weight_broadcasts: 43527
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 189.68
    learner_load_time_ms: 1.336
    learner_load_wait_time_ms: 1.448
iterations_since_restore: 184
node_ip: 127.0.0.1
num_agent_steps_sampled: 2213900
num_agent_steps_trained: 2197000
num_env_steps_sampled: 2213900
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9940347927509
num_env_steps_trained: 2197000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9942064533911
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 46.63571428571429
  ram_util_percent: 79.16428571428573
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06665578524281932
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02601674258485242
  mean_inference_ms: 1.2475004706522195
  mean_raw_obs_processing_ms: 0.2834213204083912
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018794383477727206
    StateBufferConnector_ms: 0.003314455714794474
    ViewRequirementAgentConnector_ms: 0.11245788784202086
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.146788990825687
  episode_reward_min: 3.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [12.0, 11.0, 6.0, 8.0, 7.0, 10.0, 11.0, 6.0, 12.0, 9.0, 10.0,
      11.0, 8.0, 12.0, 7.0, 8.0, 7.0, 11.0, 12.0, 10.0, 11.0, 14.0, 9.0, 9.0, 11.0,
      18.0, 8.0, 12.0, 10.0, 7.0, 5.0, 7.0, 7.0, 7.0, 11.0, 10.0, 11.0, 6.0, 11.0,
      9.0, 7.0, 9.0, 7.0, 9.0, 9.0, 5.0, 9.0, 10.0, 3.0, 13.0, 7.0, 12.0, 9.0, 3.0,
      14.0, 10.0, 7.0, 10.0, 11.0, 4.0, 5.0, 8.0, 8.0, 10.0, 8.0, 6.0, 4.0, 14.0,
      9.0, 10.0, 8.0, 8.0, 10.0, 9.0, 12.0, 13.0, 12.0, 8.0, 10.0, 6.0, 7.0, 10.0,
      8.0, 7.0, 7.0, 9.0, 10.0, 11.0, 16.0, 9.0, 10.0, 12.0, 7.0, 9.0, 6.0, 8.0, 10.0,
      11.0, 12.0, 10.0, 11.0, 12.0, 12.0, 9.0, 5.0, 9.0, 7.0, 10.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06665578524281932
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02601674258485242
    mean_inference_ms: 1.2475004706522195
    mean_raw_obs_processing_ms: 0.2834213204083912
time_since_restore: 1868.5752918720245
time_this_iter_s: 10.134835958480835
time_total_s: 1868.5752918720245
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996048
timesteps_total: 2213900
training_iteration: 184
trial_id: default
train step: 185
agent_timesteps_total: 2227900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018592055784452947
  StateBufferConnector_ms: 0.0033575460451458574
  ViewRequirementAgentConnector_ms: 0.11250119690501362
counters:
  num_agent_steps_sampled: 2227900
  num_agent_steps_trained: 2211000
  num_env_steps_sampled: 2227900
  num_env_steps_trained: 2211000
  num_samples_added_to_queue: 2227500
  num_training_step_calls_since_last_synch_worker_weights: 378
  num_weight_broadcasts: 43802
custom_metrics: {}
date: 2023-08-14_15-54-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.100917431192661
episode_reward_min: 4.0
episodes_this_iter: 109
episodes_total: 17406
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6118094325065613
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 29.232341766357422
        total_loss: 85.53467559814453
        var_gnorm: 64.59029388427734
        vf_explained_var: 0.8072799444198608
        vf_loss: 118.72274780273438
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4422.0
  learner_queue:
    size_count: 4428
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 2227900
  num_agent_steps_trained: 2211000
  num_env_steps_sampled: 2227900
  num_env_steps_trained: 2211000
  num_samples_added_to_queue: 2227500
  num_training_step_calls_since_last_synch_worker_weights: 378
  num_weight_broadcasts: 43802
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 188.648
    learner_load_time_ms: 1.338
    learner_load_wait_time_ms: 1.533
iterations_since_restore: 185
node_ip: 127.0.0.1
num_agent_steps_sampled: 2227900
num_agent_steps_trained: 2211000
num_env_steps_sampled: 2227900
num_env_steps_sampled_this_iter: 14000
num_env_steps_sampled_throughput_per_sec: 1399.9964952556609
num_env_steps_trained: 2211000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9964952556609
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.75714285714286
  ram_util_percent: 79.17142857142859
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06658995187999499
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025990367077135822
  mean_inference_ms: 1.2464021843119164
  mean_raw_obs_processing_ms: 0.28317727247928776
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018592055784452947
    StateBufferConnector_ms: 0.0033575460451458574
    ViewRequirementAgentConnector_ms: 0.11250119690501362
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.100917431192661
  episode_reward_min: 4.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [10.0, 10.0, 7.0, 9.0, 10.0, 7.0, 10.0, 5.0, 5.0, 12.0, 6.0, 9.0,
      7.0, 9.0, 7.0, 9.0, 13.0, 6.0, 11.0, 6.0, 11.0, 7.0, 10.0, 10.0, 8.0, 12.0,
      10.0, 12.0, 7.0, 10.0, 5.0, 6.0, 10.0, 12.0, 7.0, 10.0, 14.0, 7.0, 6.0, 11.0,
      10.0, 9.0, 12.0, 6.0, 12.0, 12.0, 12.0, 10.0, 5.0, 7.0, 9.0, 6.0, 10.0, 7.0,
      13.0, 12.0, 14.0, 9.0, 9.0, 5.0, 15.0, 10.0, 7.0, 14.0, 9.0, 9.0, 12.0, 5.0,
      7.0, 8.0, 11.0, 7.0, 7.0, 12.0, 8.0, 8.0, 11.0, 12.0, 10.0, 12.0, 10.0, 6.0,
      7.0, 5.0, 7.0, 9.0, 8.0, 7.0, 9.0, 10.0, 10.0, 6.0, 8.0, 11.0, 15.0, 9.0, 8.0,
      11.0, 9.0, 12.0, 7.0, 7.0, 10.0, 10.0, 4.0, 13.0, 11.0, 9.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06658995187999499
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025990367077135822
    mean_inference_ms: 1.2464021843119164
    mean_raw_obs_processing_ms: 0.28317727247928776
time_since_restore: 1878.7074706554413
time_this_iter_s: 10.132178783416748
time_total_s: 1878.7074706554413
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996058
timesteps_total: 2227900
training_iteration: 185
trial_id: default
train step: 186
agent_timesteps_total: 2241800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01855552743334289
  StateBufferConnector_ms: 0.003310737259891055
  ViewRequirementAgentConnector_ms: 0.11137494253456046
counters:
  num_agent_steps_sampled: 2241800
  num_agent_steps_trained: 2225000
  num_env_steps_sampled: 2241800
  num_env_steps_trained: 2225000
  num_samples_added_to_queue: 2241500
  num_training_step_calls_since_last_synch_worker_weights: 858
  num_weight_broadcasts: 44075
custom_metrics: {}
date: 2023-08-14_15-54-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.770642201834862
episode_reward_min: 2.0
episodes_this_iter: 109
episodes_total: 17515
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6033181548118591
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.022774696350098
        total_loss: 8.963367462158203
        var_gnorm: 64.58992004394531
        vf_explained_var: 0.935615062713623
        vf_loss: 42.00546646118164
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4450.0
  learner_queue:
    size_count: 4455
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3078226179417451
  num_agent_steps_sampled: 2241800
  num_agent_steps_trained: 2225000
  num_env_steps_sampled: 2241800
  num_env_steps_trained: 2225000
  num_samples_added_to_queue: 2241500
  num_training_step_calls_since_last_synch_worker_weights: 858
  num_weight_broadcasts: 44075
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 213.947
    learner_load_time_ms: 1.349
    learner_load_wait_time_ms: 1.578
iterations_since_restore: 186
node_ip: 127.0.0.1
num_agent_steps_sampled: 2241800
num_agent_steps_trained: 2225000
num_env_steps_sampled: 2241800
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9958243495496
num_env_steps_trained: 2225000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.995794308899
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.149999999999984
  ram_util_percent: 79.24285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06653677857799695
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025963762348527163
  mean_inference_ms: 1.245319043872156
  mean_raw_obs_processing_ms: 0.28293989392648755
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01855552743334289
    StateBufferConnector_ms: 0.003310737259891055
    ViewRequirementAgentConnector_ms: 0.11137494253456046
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.770642201834862
  episode_reward_min: 2.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [8.0, 14.0, 6.0, 8.0, 9.0, 6.0, 10.0, 11.0, 11.0, 7.0, 9.0, 13.0,
      7.0, 17.0, 14.0, 6.0, 12.0, 8.0, 4.0, 8.0, 11.0, 9.0, 9.0, 9.0, 9.0, 12.0, 10.0,
      7.0, 3.0, 13.0, 11.0, 8.0, 10.0, 6.0, 8.0, 9.0, 7.0, 14.0, 6.0, 4.0, 6.0, 7.0,
      11.0, 10.0, 8.0, 7.0, 9.0, 9.0, 11.0, 10.0, 8.0, 7.0, 8.0, 2.0, 12.0, 9.0, 10.0,
      3.0, 6.0, 9.0, 5.0, 10.0, 15.0, 3.0, 7.0, 9.0, 9.0, 6.0, 9.0, 8.0, 7.0, 9.0,
      8.0, 12.0, 9.0, 7.0, 7.0, 8.0, 7.0, 10.0, 16.0, 5.0, 13.0, 6.0, 10.0, 6.0, 7.0,
      9.0, 9.0, 7.0, 11.0, 5.0, 11.0, 16.0, 9.0, 9.0, 11.0, 10.0, 6.0, 9.0, 14.0,
      5.0, 12.0, 10.0, 9.0, 7.0, 8.0, 8.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06653677857799695
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025963762348527163
    mean_inference_ms: 1.245319043872156
    mean_raw_obs_processing_ms: 0.28293989392648755
time_since_restore: 1888.815182685852
time_this_iter_s: 10.107712030410767
time_total_s: 1888.815182685852
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996068
timesteps_total: 2241800
training_iteration: 186
trial_id: default
train step: 187
agent_timesteps_total: 2255600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018585390514797635
  StateBufferConnector_ms: 0.003364130302711769
  ViewRequirementAgentConnector_ms: 0.11333845279834888
counters:
  num_agent_steps_sampled: 2255600
  num_agent_steps_trained: 2239000
  num_env_steps_sampled: 2255600
  num_env_steps_trained: 2239000
  num_samples_added_to_queue: 2255500
  num_training_step_calls_since_last_synch_worker_weights: 1145
  num_weight_broadcasts: 44346
custom_metrics: {}
date: 2023-08-14_15-54-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.185185185185185
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 17623
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5398925542831421
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.3713376522064209
        total_loss: 31.032806396484375
        var_gnorm: 64.60015869140625
        vf_explained_var: 0.9286801218986511
        vf_loss: 68.20721435546875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4478.0
  learner_queue:
    size_count: 4482
    size_mean: 15.58
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9816312953446422
  num_agent_steps_sampled: 2255600
  num_agent_steps_trained: 2239000
  num_env_steps_sampled: 2255600
  num_env_steps_trained: 2239000
  num_samples_added_to_queue: 2255500
  num_training_step_calls_since_last_synch_worker_weights: 1145
  num_weight_broadcasts: 44346
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 243.752
    learner_load_time_ms: 1.349
    learner_load_wait_time_ms: 1.565
iterations_since_restore: 187
node_ip: 127.0.0.1
num_agent_steps_sampled: 2255600
num_agent_steps_trained: 2239000
num_env_steps_sampled: 2255600
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9986181272993
num_env_steps_trained: 2239000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9985981001587
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.64666666666666
  ram_util_percent: 79.41333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06647818922497233
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02593822427761605
  mean_inference_ms: 1.2443249061566444
  mean_raw_obs_processing_ms: 0.2827211006442618
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018585390514797635
    StateBufferConnector_ms: 0.003364130302711769
    ViewRequirementAgentConnector_ms: 0.11333845279834888
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.185185185185185
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 12.0, 8.0, 9.0, 12.0, 8.0, 7.0, 7.0, 12.0, 12.0, 10.0, 9.0,
      7.0, 6.0, 11.0, 13.0, 8.0, 7.0, 14.0, 11.0, 7.0, 12.0, 9.0, 14.0, 7.0, 6.0,
      6.0, 11.0, 4.0, 6.0, 5.0, 9.0, 8.0, 10.0, 8.0, 7.0, 6.0, 8.0, 8.0, 4.0, 3.0,
      12.0, 8.0, 6.0, 7.0, 10.0, 6.0, 7.0, 9.0, 10.0, 7.0, 6.0, 8.0, 6.0, 10.0, 12.0,
      11.0, 8.0, 8.0, 9.0, 7.0, 13.0, 17.0, 7.0, 10.0, 11.0, 10.0, 9.0, 7.0, 5.0,
      7.0, 4.0, 6.0, 8.0, 12.0, 7.0, 8.0, 6.0, 8.0, 7.0, 10.0, 14.0, 8.0, 7.0, 9.0,
      3.0, 8.0, 3.0, 8.0, 7.0, 14.0, 8.0, 10.0, 5.0, 11.0, 11.0, 5.0, 12.0, 6.0, 9.0,
      3.0, 3.0, 8.0, 7.0, 5.0, 7.0, 3.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06647818922497233
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02593822427761605
    mean_inference_ms: 1.2443249061566444
    mean_raw_obs_processing_ms: 0.2827211006442618
time_since_restore: 1898.907164812088
time_this_iter_s: 10.091982126235962
time_total_s: 1898.907164812088
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996078
timesteps_total: 2255600
training_iteration: 187
trial_id: default
train step: 188
agent_timesteps_total: 2269300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018856210528679612
  StateBufferConnector_ms: 0.00334528257262032
  ViewRequirementAgentConnector_ms: 0.11334599189038547
counters:
  num_agent_steps_sampled: 2269300
  num_agent_steps_trained: 2252500
  num_env_steps_sampled: 2269300
  num_env_steps_trained: 2252500
  num_samples_added_to_queue: 2269000
  num_training_step_calls_since_last_synch_worker_weights: 1156
  num_weight_broadcasts: 44612
custom_metrics: {}
date: 2023-08-14_15-54-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.160377358490566
episode_reward_min: 2.0
episodes_this_iter: 106
episodes_total: 17729
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4347359836101532
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -15.137763023376465
        total_loss: 14.286273956298828
        var_gnorm: 64.61695861816406
        vf_explained_var: 0.9353673458099365
        vf_loss: 63.1954345703125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4505.0
  learner_queue:
    size_count: 4509
    size_mean: 15.72
    size_quantiles: [13.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.7493997598078078
  num_agent_steps_sampled: 2269300
  num_agent_steps_trained: 2252500
  num_env_steps_sampled: 2269300
  num_env_steps_trained: 2252500
  num_samples_added_to_queue: 2269000
  num_training_step_calls_since_last_synch_worker_weights: 1156
  num_weight_broadcasts: 44612
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 249.362
    learner_load_time_ms: 1.353
    learner_load_wait_time_ms: 1.533
iterations_since_restore: 188
node_ip: 127.0.0.1
num_agent_steps_sampled: 2269300
num_agent_steps_trained: 2252500
num_env_steps_sampled: 2269300
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.995753778267
num_env_steps_trained: 2252500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9958157669055
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.13571428571429
  ram_util_percent: 79.43571428571428
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06642676096246329
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025913742716640067
  mean_inference_ms: 1.2433917041709295
  mean_raw_obs_processing_ms: 0.2825127733739623
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018856210528679612
    StateBufferConnector_ms: 0.00334528257262032
    ViewRequirementAgentConnector_ms: 0.11334599189038547
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.160377358490566
  episode_reward_min: 2.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 7.0, 14.0, 6.0, 5.0, 8.0, 9.0, 5.0, 9.0, 6.0, 8.0, 4.0,
      6.0, 5.0, 8.0, 5.0, 8.0, 7.0, 9.0, 5.0, 7.0, 4.0, 5.0, 6.0, 4.0, 5.0, 5.0, 8.0,
      6.0, 7.0, 9.0, 3.0, 8.0, 3.0, 7.0, 3.0, 6.0, 4.0, 8.0, 6.0, 6.0, 6.0, 4.0, 5.0,
      7.0, 5.0, 3.0, 3.0, 9.0, 6.0, 5.0, 4.0, 5.0, 8.0, 10.0, 8.0, 8.0, 3.0, 7.0,
      5.0, 7.0, 3.0, 9.0, 6.0, 5.0, 4.0, 8.0, 5.0, 12.0, 7.0, 5.0, 7.0, 5.0, 6.0,
      4.0, 6.0, 6.0, 6.0, 6.0, 9.0, 8.0, 13.0, 5.0, 2.0, 4.0, 7.0, 7.0, 4.0, 10.0,
      8.0, 5.0, 3.0, 4.0, 3.0, 6.0, 3.0, 5.0, 5.0, 11.0, 8.0, 4.0, 7.0, 8.0, 9.0,
      3.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06642676096246329
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025913742716640067
    mean_inference_ms: 1.2433917041709295
    mean_raw_obs_processing_ms: 0.2825127733739623
time_since_restore: 1908.998272895813
time_this_iter_s: 10.091108083724976
time_total_s: 1908.998272895813
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691996088
timesteps_total: 2269300
training_iteration: 188
trial_id: default
train step: 189
agent_timesteps_total: 2283200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01867386179232816
  StateBufferConnector_ms: 0.0033466094130769784
  ViewRequirementAgentConnector_ms: 0.11303971666808522
counters:
  num_agent_steps_sampled: 2283200
  num_agent_steps_trained: 2266500
  num_env_steps_sampled: 2283200
  num_env_steps_trained: 2266500
  num_samples_added_to_queue: 2283000
  num_training_step_calls_since_last_synch_worker_weights: 35
  num_weight_broadcasts: 44882
custom_metrics: {}
date: 2023-08-14_15-54-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.0091743119266057
episode_reward_min: 0.0
episodes_this_iter: 109
episodes_total: 17838
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.19999999999982
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.3690488338470459
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -28.701496124267578
        total_loss: 23.865976333618164
        var_gnorm: 64.62061309814453
        vf_explained_var: 0.7655882835388184
        vf_loss: 108.82543182373047
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4533.0
  learner_queue:
    size_count: 4540
    size_mean: 15.4
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3564659966250536
  num_agent_steps_sampled: 2283200
  num_agent_steps_trained: 2266500
  num_env_steps_sampled: 2283200
  num_env_steps_trained: 2266500
  num_samples_added_to_queue: 2283000
  num_training_step_calls_since_last_synch_worker_weights: 35
  num_weight_broadcasts: 44882
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 139.862
    learner_load_time_ms: 1.504
    learner_load_wait_time_ms: 1.487
iterations_since_restore: 189
node_ip: 127.0.0.1
num_agent_steps_sampled: 2283200
num_agent_steps_trained: 2266500
num_env_steps_sampled: 2283200
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.999304056516
num_env_steps_trained: 2266500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9992990497283
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 51.042857142857144
  ram_util_percent: 79.73571428571428
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06636976257209073
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02588602464689136
  mean_inference_ms: 1.2424075308195053
  mean_raw_obs_processing_ms: 0.2822954154722217
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01867386179232816
    StateBufferConnector_ms: 0.0033466094130769784
    ViewRequirementAgentConnector_ms: 0.11303971666808522
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.0091743119266057
  episode_reward_min: 0.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [5.0, 4.0, 9.0, 2.0, 3.0, 6.0, 4.0, 2.0, 3.0, 7.0, 5.0, 5.0, 2.0,
      3.0, 1.0, 5.0, 3.0, 5.0, 1.0, 0.0, 6.0, 3.0, 5.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0,
      3.0, 8.0, 6.0, 2.0, 0.0, 2.0, 1.0, 0.0, 0.0, 4.0, 2.0, 5.0, 2.0, 4.0, 5.0, 0.0,
      1.0, 1.0, 2.0, 0.0, 7.0, 3.0, 4.0, 3.0, 6.0, 4.0, 7.0, 5.0, 5.0, 4.0, 2.0, 3.0,
      10.0, 5.0, 5.0, 4.0, 4.0, 3.0, 1.0, 2.0, 2.0, 1.0, 5.0, 3.0, 2.0, 4.0, 0.0,
      4.0, 1.0, 2.0, 2.0, 3.0, 7.0, 3.0, 2.0, 0.0, 3.0, 5.0, 0.0, 0.0, 2.0, 1.0, 1.0,
      2.0, 0.0, 6.0, 1.0, 0.0, 5.0, 0.0, 3.0, 1.0, 6.0, 3.0, 1.0, 2.0, 4.0, 0.0, 4.0,
      4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06636976257209073
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02588602464689136
    mean_inference_ms: 1.2424075308195053
    mean_raw_obs_processing_ms: 0.2822954154722217
time_since_restore: 1919.1514358520508
time_this_iter_s: 10.153162956237793
time_total_s: 1919.1514358520508
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996098
timesteps_total: 2283200
training_iteration: 189
trial_id: default
train step: 190
agent_timesteps_total: 2296800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01873613517975139
  StateBufferConnector_ms: 0.0032988664145781614
  ViewRequirementAgentConnector_ms: 0.11409688218731746
counters:
  num_agent_steps_sampled: 2296800
  num_agent_steps_trained: 2280000
  num_env_steps_sampled: 2296800
  num_env_steps_trained: 2280000
  num_samples_added_to_queue: 2296500
  num_training_step_calls_since_last_synch_worker_weights: 952
  num_weight_broadcasts: 45147
custom_metrics: {}
date: 2023-08-14_15-55-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.0373831775700935
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 17945
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6201121211051941
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.846898078918457
        total_loss: 3.3274953365325928
        var_gnorm: 64.6156005859375
        vf_explained_var: 0.9356164336204529
        vf_loss: 30.549907684326172
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4560.0
  learner_queue:
    size_count: 4564
    size_mean: 15.28
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4702380759591285
  num_agent_steps_sampled: 2296800
  num_agent_steps_trained: 2280000
  num_env_steps_sampled: 2296800
  num_env_steps_trained: 2280000
  num_samples_added_to_queue: 2296500
  num_training_step_calls_since_last_synch_worker_weights: 952
  num_weight_broadcasts: 45147
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 255.008
    learner_load_time_ms: 1.978
    learner_load_wait_time_ms: 1.672
iterations_since_restore: 190
node_ip: 127.0.0.1
num_agent_steps_sampled: 2296800
num_agent_steps_trained: 2280000
num_env_steps_sampled: 2296800
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.997146612432
num_env_steps_trained: 2280000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.997167593223
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.192857142857136
  ram_util_percent: 79.75
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06632398307636053
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025858880617358616
  mean_inference_ms: 1.241565067119978
  mean_raw_obs_processing_ms: 0.28209173582741615
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01873613517975139
    StateBufferConnector_ms: 0.0032988664145781614
    ViewRequirementAgentConnector_ms: 0.11409688218731746
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.0373831775700935
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 6.0, 4.0, 2.0, 4.0, 9.0, 1.0, 2.0, 3.0, 1.0, 6.0, 2.0, 3.0,
      3.0, 3.0, 2.0, 2.0, 2.0, 5.0, 1.0, 4.0, 2.0, 1.0, 1.0, 7.0, 3.0, 2.0, 0.0, 2.0,
      4.0, 6.0, 2.0, 2.0, 3.0, 5.0, 6.0, 4.0, 5.0, 4.0, 1.0, 3.0, 3.0, 4.0, 3.0, 4.0,
      1.0, 2.0, 3.0, 2.0, 4.0, 2.0, 2.0, 3.0, 0.0, 0.0, 3.0, 1.0, 3.0, 2.0, 3.0, 3.0,
      3.0, 8.0, 4.0, 6.0, 3.0, 5.0, 0.0, 3.0, 5.0, 3.0, 2.0, 3.0, 2.0, 7.0, 3.0, 1.0,
      3.0, 7.0, 1.0, 4.0, 1.0, 5.0, 0.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 8.0, 0.0,
      2.0, 2.0, 3.0, 2.0, 5.0, 0.0, 3.0, 3.0, 1.0, 2.0, 6.0, 4.0, 1.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06632398307636053
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025858880617358616
    mean_inference_ms: 1.241565067119978
    mean_raw_obs_processing_ms: 0.28209173582741615
time_since_restore: 1929.2566509246826
time_this_iter_s: 10.105215072631836
time_total_s: 1929.2566509246826
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996108
timesteps_total: 2296800
training_iteration: 190
trial_id: default
train step: 191
agent_timesteps_total: 2310500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01895855057914302
  StateBufferConnector_ms: 0.0034480724694593897
  ViewRequirementAgentConnector_ms: 0.1159114657707934
counters:
  num_agent_steps_sampled: 2310500
  num_agent_steps_trained: 2294000
  num_env_steps_sampled: 2310500
  num_env_steps_trained: 2294000
  num_samples_added_to_queue: 2310500
  num_training_step_calls_since_last_synch_worker_weights: 23
  num_weight_broadcasts: 45417
custom_metrics: {}
date: 2023-08-14_15-55-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.773584905660377
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 18051
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5962576866149902
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.1216349601745605
        total_loss: -3.5723471641540527
        var_gnorm: 64.60954284667969
        vf_explained_var: 0.9715396165847778
        vf_loss: 9.061152458190918
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4588.0
  learner_queue:
    size_count: 4594
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1697863052711808
  num_agent_steps_sampled: 2310500
  num_agent_steps_trained: 2294000
  num_env_steps_sampled: 2310500
  num_env_steps_trained: 2294000
  num_samples_added_to_queue: 2310500
  num_training_step_calls_since_last_synch_worker_weights: 23
  num_weight_broadcasts: 45417
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 161.295
    learner_load_time_ms: 1.974
    learner_load_wait_time_ms: 1.577
iterations_since_restore: 191
node_ip: 127.0.0.1
num_agent_steps_sampled: 2310500
num_agent_steps_trained: 2294000
num_env_steps_sampled: 2310500
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9954598100444
num_env_steps_trained: 2294000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9953603898264
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 58.88571428571429
  ram_util_percent: 80.67142857142856
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06627410965082245
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025835489973349623
  mean_inference_ms: 1.2406935373912458
  mean_raw_obs_processing_ms: 0.2819029441688744
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01895855057914302
    StateBufferConnector_ms: 0.0034480724694593897
    ViewRequirementAgentConnector_ms: 0.1159114657707934
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.773584905660377
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 4.0, 7.0, 1.0, 5.0, 6.0, 3.0, 6.0, 3.0, 6.0, 3.0, 5.0,
      4.0, 6.0, 4.0, 3.0, 5.0, 9.0, 4.0, 4.0, 2.0, 3.0, 1.0, 3.0, 8.0, 5.0, 3.0, 4.0,
      4.0, 4.0, 4.0, 5.0, 6.0, 6.0, 7.0, 6.0, 9.0, 4.0, 4.0, 4.0, 5.0, 7.0, 4.0, 3.0,
      7.0, 4.0, 4.0, 6.0, 6.0, 6.0, 2.0, 7.0, 5.0, 6.0, 4.0, 6.0, 8.0, 2.0, 3.0, 6.0,
      4.0, 2.0, 2.0, 2.0, 6.0, 6.0, 3.0, 3.0, 0.0, 4.0, 1.0, 4.0, 4.0, 5.0, 6.0, 4.0,
      4.0, 7.0, 9.0, 4.0, 5.0, 4.0, 7.0, 4.0, 5.0, 0.0, 12.0, 6.0, 7.0, 3.0, 6.0,
      8.0, 6.0, 5.0, 7.0, 6.0, 8.0, 8.0, 8.0, 3.0, 4.0, 3.0, 4.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06627410965082245
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025835489973349623
    mean_inference_ms: 1.2406935373912458
    mean_raw_obs_processing_ms: 0.2819029441688744
time_since_restore: 1939.3965697288513
time_this_iter_s: 10.139918804168701
time_total_s: 1939.3965697288513
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996119
timesteps_total: 2310500
training_iteration: 191
trial_id: default
train step: 192
agent_timesteps_total: 2324200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018959795987164532
  StateBufferConnector_ms: 0.0033694284933584707
  ViewRequirementAgentConnector_ms: 0.11526279979281956
counters:
  num_agent_steps_sampled: 2324200
  num_agent_steps_trained: 2307500
  num_env_steps_sampled: 2324200
  num_env_steps_trained: 2307500
  num_samples_added_to_queue: 2324000
  num_training_step_calls_since_last_synch_worker_weights: 213
  num_weight_broadcasts: 45688
custom_metrics: {}
date: 2023-08-14_15-55-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.175925925925926
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 18159
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0034127235412598
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.949734687805176
        total_loss: -1.6067023277282715
        var_gnorm: 64.6156234741211
        vf_explained_var: 0.9387562274932861
        vf_loss: 26.720191955566406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4615.0
  learner_queue:
    size_count: 4621
    size_mean: 15.24
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4636939570825591
  num_agent_steps_sampled: 2324200
  num_agent_steps_trained: 2307500
  num_env_steps_sampled: 2324200
  num_env_steps_trained: 2307500
  num_samples_added_to_queue: 2324000
  num_training_step_calls_since_last_synch_worker_weights: 213
  num_weight_broadcasts: 45688
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 175.543
    learner_load_time_ms: 1.981
    learner_load_wait_time_ms: 1.531
iterations_since_restore: 192
node_ip: 127.0.0.1
num_agent_steps_sampled: 2324200
num_agent_steps_trained: 2307500
num_env_steps_sampled: 2324200
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.996341715091
num_env_steps_trained: 2307500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.99639512071
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 62.919999999999995
  ram_util_percent: 81.05999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06622730959118733
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02581329625139411
  mean_inference_ms: 1.2398337315977257
  mean_raw_obs_processing_ms: 0.2817102416157829
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018959795987164532
    StateBufferConnector_ms: 0.0033694284933584707
    ViewRequirementAgentConnector_ms: 0.11526279979281956
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.175925925925926
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 7.0, 4.0, 4.0, 6.0, 5.0, 4.0, 8.0, 7.0, 8.0, 0.0, 5.0,
      5.0, 7.0, 5.0, 8.0, 1.0, 10.0, 5.0, 10.0, 5.0, 7.0, 4.0, 5.0, 6.0, 8.0, 10.0,
      10.0, 4.0, 7.0, 5.0, 6.0, 4.0, 3.0, 6.0, 6.0, 8.0, 6.0, 5.0, 7.0, 8.0, 6.0,
      6.0, 7.0, 7.0, 9.0, 2.0, 4.0, 12.0, 11.0, 7.0, 5.0, 10.0, 8.0, 4.0, 5.0, 8.0,
      4.0, 3.0, 5.0, 5.0, 7.0, 2.0, 8.0, 12.0, 5.0, 2.0, 4.0, 6.0, 4.0, 6.0, 9.0,
      7.0, 12.0, 5.0, 6.0, 7.0, 11.0, 2.0, 4.0, 5.0, 6.0, 5.0, 7.0, 7.0, 6.0, 6.0,
      4.0, 10.0, 7.0, 6.0, 4.0, 7.0, 3.0, 6.0, 6.0, 4.0, 9.0, 9.0, 4.0, 6.0, 9.0,
      8.0, 5.0, 6.0, 11.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06622730959118733
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02581329625139411
    mean_inference_ms: 1.2398337315977257
    mean_raw_obs_processing_ms: 0.2817102416157829
time_since_restore: 1949.5404126644135
time_this_iter_s: 10.143842935562134
time_total_s: 1949.5404126644135
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996129
timesteps_total: 2324200
training_iteration: 192
trial_id: default
train step: 193
agent_timesteps_total: 2338100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018602830392343027
  StateBufferConnector_ms: 0.0032477908664279515
  ViewRequirementAgentConnector_ms: 0.11326714798256203
counters:
  num_agent_steps_sampled: 2338100
  num_agent_steps_trained: 2321500
  num_env_steps_sampled: 2338100
  num_env_steps_trained: 2321500
  num_samples_added_to_queue: 2338000
  num_training_step_calls_since_last_synch_worker_weights: 309
  num_weight_broadcasts: 45960
custom_metrics: {}
date: 2023-08-14_15-55-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.083333333333333
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 18267
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8555783629417419
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.704715728759766
        total_loss: -4.483876705169678
        var_gnorm: 64.61699676513672
        vf_explained_var: 0.9407185316085815
        vf_loss: 16.997461318969727
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4643.0
  learner_queue:
    size_count: 4649
    size_mean: 15.14
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5749285698088027
  num_agent_steps_sampled: 2338100
  num_agent_steps_trained: 2321500
  num_env_steps_sampled: 2338100
  num_env_steps_trained: 2321500
  num_samples_added_to_queue: 2338000
  num_training_step_calls_since_last_synch_worker_weights: 309
  num_weight_broadcasts: 45960
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 168.836
    learner_load_time_ms: 2.034
    learner_load_wait_time_ms: 1.482
iterations_since_restore: 193
node_ip: 127.0.0.1
num_agent_steps_sampled: 2338100
num_agent_steps_trained: 2321500
num_env_steps_sampled: 2338100
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9936039742097
num_env_steps_trained: 2321500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9935579596356
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 56.02142857142858
  ram_util_percent: 81.4
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06617338228788329
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025789063942327058
  mean_inference_ms: 1.2388724462287672
  mean_raw_obs_processing_ms: 0.28150064906418715
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018602830392343027
    StateBufferConnector_ms: 0.0032477908664279515
    ViewRequirementAgentConnector_ms: 0.11326714798256203
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.083333333333333
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 11.0, 3.0, 11.0, 4.0, 11.0, 11.0, 9.0, 11.0, 7.0, 7.0, 10.0,
      12.0, 7.0, 10.0, 6.0, 8.0, 9.0, 13.0, 6.0, 2.0, 6.0, 8.0, 7.0, 4.0, 3.0, 8.0,
      6.0, 8.0, 4.0, 9.0, 9.0, 4.0, 1.0, 5.0, 4.0, 6.0, 5.0, 5.0, 7.0, 9.0, 6.0, 7.0,
      7.0, 5.0, 7.0, 9.0, 8.0, 7.0, 7.0, 7.0, 6.0, 7.0, 5.0, 5.0, 11.0, 7.0, 3.0,
      9.0, 7.0, 3.0, 8.0, 9.0, 4.0, 7.0, 7.0, 7.0, 8.0, 11.0, 7.0, 9.0, 11.0, 9.0,
      4.0, 6.0, 7.0, 5.0, 10.0, 12.0, 6.0, 6.0, 6.0, 8.0, 6.0, 9.0, 14.0, 10.0, 5.0,
      9.0, 7.0, 9.0, 6.0, 11.0, 2.0, 6.0, 5.0, 10.0, 6.0, 8.0, 9.0, 1.0, 4.0, 5.0,
      8.0, 3.0, 7.0, 5.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06617338228788329
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025789063942327058
    mean_inference_ms: 1.2388724462287672
    mean_raw_obs_processing_ms: 0.28150064906418715
time_since_restore: 1959.6775307655334
time_this_iter_s: 10.137118101119995
time_total_s: 1959.6775307655334
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691996139
timesteps_total: 2338100
training_iteration: 193
trial_id: default
train step: 194
agent_timesteps_total: 2351400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01967801497532771
  StateBufferConnector_ms: 0.0035001681401179386
  ViewRequirementAgentConnector_ms: 0.11682877173790565
counters:
  num_agent_steps_sampled: 2351400
  num_agent_steps_trained: 2334500
  num_env_steps_sampled: 2351400
  num_env_steps_trained: 2334500
  num_samples_added_to_queue: 2351000
  num_training_step_calls_since_last_synch_worker_weights: 700
  num_weight_broadcasts: 46222
custom_metrics: {}
date: 2023-08-14_15-55-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.5673076923076925
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 18371
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8021699786186218
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 9.995849609375
        total_loss: 42.36860656738281
        var_gnorm: 64.62257385253906
        vf_explained_var: 0.8239995241165161
        vf_loss: 72.7672119140625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4669.0
  learner_queue:
    size_count: 4674
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3332666649999165
  num_agent_steps_sampled: 2351400
  num_agent_steps_trained: 2334500
  num_env_steps_sampled: 2351400
  num_env_steps_trained: 2334500
  num_samples_added_to_queue: 2351000
  num_training_step_calls_since_last_synch_worker_weights: 700
  num_weight_broadcasts: 46222
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 226.661
    learner_load_time_ms: 1.891
    learner_load_wait_time_ms: 1.642
iterations_since_restore: 194
node_ip: 127.0.0.1
num_agent_steps_sampled: 2351400
num_agent_steps_trained: 2334500
num_env_steps_sampled: 2351400
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9964168168283
num_env_steps_trained: 2334500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9964976405088
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.128571428571426
  ram_util_percent: 81.20714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06613821317207272
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02577254028220717
  mean_inference_ms: 1.238229558628338
  mean_raw_obs_processing_ms: 0.2813594498853742
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01967801497532771
    StateBufferConnector_ms: 0.0035001681401179386
    ViewRequirementAgentConnector_ms: 0.11682877173790565
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.5673076923076925
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 6.0, 9.0, 10.0, 11.0, 6.0, 8.0, 5.0, 15.0, 6.0, 5.0, 14.0,
      4.0, 12.0, 4.0, 8.0, 12.0, 6.0, 11.0, 7.0, 7.0, 11.0, 6.0, 6.0, 5.0, 7.0, 10.0,
      4.0, 10.0, 4.0, 9.0, 12.0, 11.0, 9.0, 7.0, 7.0, 11.0, 5.0, 10.0, 1.0, 10.0,
      11.0, 6.0, 7.0, 7.0, 6.0, 4.0, 13.0, 5.0, 11.0, 9.0, 1.0, 9.0, 9.0, 6.0, 9.0,
      11.0, 5.0, 2.0, 13.0, 6.0, 4.0, 8.0, 9.0, 4.0, 3.0, 4.0, 4.0, 3.0, 9.0, 9.0,
      6.0, 7.0, 6.0, 7.0, 11.0, 6.0, 8.0, 4.0, 13.0, 8.0, 9.0, 7.0, 9.0, 11.0, 7.0,
      12.0, 7.0, 5.0, 8.0, 9.0, 8.0, 3.0, 11.0, 6.0, 5.0, 6.0, 8.0, 4.0, 6.0, 10.0,
      10.0, 2.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06613821317207272
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02577254028220717
    mean_inference_ms: 1.238229558628338
    mean_raw_obs_processing_ms: 0.2813594498853742
time_since_restore: 1969.796478509903
time_this_iter_s: 10.118947744369507
time_total_s: 1969.796478509903
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1691996149
timesteps_total: 2351400
training_iteration: 194
trial_id: default
train step: 195
agent_timesteps_total: 2365200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018609453130651404
  StateBufferConnector_ms: 0.003244479497273763
  ViewRequirementAgentConnector_ms: 0.11350357974017108
counters:
  num_agent_steps_sampled: 2365200
  num_agent_steps_trained: 2348500
  num_env_steps_sampled: 2365200
  num_env_steps_trained: 2348500
  num_samples_added_to_queue: 2365000
  num_training_step_calls_since_last_synch_worker_weights: 631
  num_weight_broadcasts: 46495
custom_metrics: {}
date: 2023-08-14_15-55-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.805555555555555
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 18479
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7395406365394592
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -31.988956451416016
        total_loss: 17.68635368347168
        var_gnorm: 64.6231918334961
        vf_explained_var: 0.7553734183311462
        vf_loss: 106.74602508544922
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4697.0
  learner_queue:
    size_count: 4703
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3098091464026353
  num_agent_steps_sampled: 2365200
  num_agent_steps_trained: 2348500
  num_env_steps_sampled: 2365200
  num_env_steps_trained: 2348500
  num_samples_added_to_queue: 2365000
  num_training_step_calls_since_last_synch_worker_weights: 631
  num_weight_broadcasts: 46495
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 178.646
    learner_load_time_ms: 1.888
    learner_load_wait_time_ms: 1.689
iterations_since_restore: 195
node_ip: 127.0.0.1
num_agent_steps_sampled: 2365200
num_agent_steps_trained: 2348500
num_env_steps_sampled: 2365200
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.994900245439
num_env_steps_trained: 2348500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9948263359527
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.14285714285713
  ram_util_percent: 81.23571428571428
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06608803183670407
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025750228204578236
  mean_inference_ms: 1.2373293498425586
  mean_raw_obs_processing_ms: 0.28116373457493843
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018609453130651404
    StateBufferConnector_ms: 0.003244479497273763
    ViewRequirementAgentConnector_ms: 0.11350357974017108
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.805555555555555
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 11.0, 5.0, 11.0, 9.0, 5.0, 7.0, 5.0, 8.0, 4.0, 4.0, 7.0,
      5.0, 7.0, 9.0, 9.0, 7.0, 12.0, 11.0, 7.0, 12.0, 8.0, 12.0, 10.0, 9.0, 10.0,
      12.0, 9.0, 13.0, 12.0, 9.0, 7.0, 11.0, 9.0, 10.0, 14.0, 2.0, 11.0, 5.0, 11.0,
      10.0, 7.0, 10.0, 4.0, 5.0, 12.0, 11.0, 8.0, 6.0, 9.0, 9.0, 7.0, 8.0, 6.0, 14.0,
      11.0, 6.0, 11.0, 11.0, 9.0, 11.0, 9.0, 14.0, 9.0, 9.0, 6.0, 11.0, 11.0, 6.0,
      7.0, 7.0, 11.0, 8.0, 13.0, 10.0, 2.0, 8.0, 9.0, 8.0, 12.0, 16.0, 7.0, 7.0, 8.0,
      12.0, 12.0, 5.0, 8.0, 8.0, 7.0, 10.0, 11.0, 10.0, 10.0, 8.0, 10.0, 11.0, 7.0,
      8.0, 7.0, 6.0, 7.0, 8.0, 8.0, 9.0, 8.0, 13.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06608803183670407
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025750228204578236
    mean_inference_ms: 1.2373293498425586
    mean_raw_obs_processing_ms: 0.28116373457493843
time_since_restore: 1979.9217846393585
time_this_iter_s: 10.125306129455566
time_total_s: 1979.9217846393585
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996159
timesteps_total: 2365200
training_iteration: 195
trial_id: default
train step: 196
agent_timesteps_total: 2378900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018967646304692064
  StateBufferConnector_ms: 0.003383538433324511
  ViewRequirementAgentConnector_ms: 0.11342708195481345
counters:
  num_agent_steps_sampled: 2378900
  num_agent_steps_trained: 2362000
  num_env_steps_sampled: 2378900
  num_env_steps_trained: 2362000
  num_samples_added_to_queue: 2378500
  num_training_step_calls_since_last_synch_worker_weights: 1211
  num_weight_broadcasts: 46763
custom_metrics: {}
date: 2023-08-14_15-56-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.11214953271028
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 18586
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7198073267936707
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -13.861699104309082
        total_loss: 34.27825164794922
        var_gnorm: 64.62653350830078
        vf_explained_var: 0.8326386213302612
        vf_loss: 103.47797393798828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4724.0
  learner_queue:
    size_count: 4728
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.22
  num_agent_steps_sampled: 2378900
  num_agent_steps_trained: 2362000
  num_env_steps_sampled: 2378900
  num_env_steps_trained: 2362000
  num_samples_added_to_queue: 2378500
  num_training_step_calls_since_last_synch_worker_weights: 1211
  num_weight_broadcasts: 46763
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 260.712
    learner_load_time_ms: 1.63
    learner_load_wait_time_ms: 1.422
iterations_since_restore: 196
node_ip: 127.0.0.1
num_agent_steps_sampled: 2378900
num_agent_steps_trained: 2362000
num_env_steps_sampled: 2378900
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.995721115125
num_env_steps_trained: 2362000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9957835805976
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.78666666666667
  ram_util_percent: 81.59333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06603856960670877
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025729475342111233
  mean_inference_ms: 1.2364835827919054
  mean_raw_obs_processing_ms: 0.28097554820518533
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018967646304692064
    StateBufferConnector_ms: 0.003383538433324511
    ViewRequirementAgentConnector_ms: 0.11342708195481345
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.11214953271028
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 6.0, 4.0, 3.0, 9.0, 10.0, 9.0, 7.0, 7.0, 12.0, 11.0, 9.0,
      7.0, 7.0, 8.0, 10.0, 9.0, 7.0, 6.0, 7.0, 7.0, 3.0, 10.0, 8.0, 6.0, 9.0, 8.0,
      10.0, 10.0, 9.0, 11.0, 16.0, 8.0, 16.0, 8.0, 8.0, 13.0, 11.0, 7.0, 6.0, 12.0,
      8.0, 6.0, 8.0, 7.0, 7.0, 6.0, 9.0, 10.0, 11.0, 5.0, 5.0, 6.0, 9.0, 13.0, 13.0,
      12.0, 9.0, 9.0, 8.0, 6.0, 8.0, 8.0, 12.0, 6.0, 5.0, 11.0, 9.0, 4.0, 9.0, 8.0,
      6.0, 6.0, 8.0, 4.0, 9.0, 7.0, 3.0, 9.0, 6.0, 6.0, 6.0, 11.0, 7.0, 10.0, 9.0,
      8.0, 5.0, 8.0, 5.0, 10.0, 8.0, 3.0, 9.0, 8.0, 11.0, 12.0, 7.0, 6.0, 9.0, 6.0,
      9.0, 6.0, 6.0, 5.0, 9.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06603856960670877
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025729475342111233
    mean_inference_ms: 1.2364835827919054
    mean_raw_obs_processing_ms: 0.28097554820518533
time_since_restore: 1990.0089547634125
time_this_iter_s: 10.087170124053955
time_total_s: 1990.0089547634125
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996169
timesteps_total: 2378900
training_iteration: 196
trial_id: default
train step: 197
agent_timesteps_total: 2392600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0190933174061998
  StateBufferConnector_ms: 0.0034430316675489194
  ViewRequirementAgentConnector_ms: 0.1156107287540614
counters:
  num_agent_steps_sampled: 2392600
  num_agent_steps_trained: 2376000
  num_env_steps_sampled: 2392600
  num_env_steps_trained: 2376000
  num_samples_added_to_queue: 2392500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 47033
custom_metrics: {}
date: 2023-08-14_15-56-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.990654205607477
episode_reward_min: 2.0
episodes_this_iter: 107
episodes_total: 18693
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7365114092826843
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.7991821765899658
        total_loss: 31.721515655517578
        var_gnorm: 64.62947845458984
        vf_explained_var: 0.8867576122283936
        vf_loss: 67.20977783203125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4752.0
  learner_queue:
    size_count: 4759
    size_mean: 15.4
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3564659966250536
  num_agent_steps_sampled: 2392600
  num_agent_steps_trained: 2376000
  num_env_steps_sampled: 2392600
  num_env_steps_trained: 2376000
  num_samples_added_to_queue: 2392500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 47033
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 135.902
    learner_load_time_ms: 1.626
    learner_load_wait_time_ms: 1.432
iterations_since_restore: 197
node_ip: 127.0.0.1
num_agent_steps_sampled: 2392600
num_agent_steps_trained: 2376000
num_env_steps_sampled: 2392600
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.5709054167728
num_env_steps_trained: 2376000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.5615091850234
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.19285714285714
  ram_util_percent: 81.55714285714284
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06599991423716633
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02570812084144423
  mean_inference_ms: 1.235663307499137
  mean_raw_obs_processing_ms: 0.2808013408949881
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0190933174061998
    StateBufferConnector_ms: 0.0034430316675489194
    ViewRequirementAgentConnector_ms: 0.1156107287540614
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.990654205607477
  episode_reward_min: 2.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 3.0, 8.0, 13.0, 7.0, 8.0, 3.0, 9.0, 6.0, 7.0, 8.0, 11.0,
      6.0, 13.0, 7.0, 7.0, 8.0, 12.0, 9.0, 7.0, 6.0, 8.0, 7.0, 11.0, 6.0, 5.0, 11.0,
      7.0, 10.0, 5.0, 6.0, 8.0, 4.0, 14.0, 5.0, 7.0, 4.0, 4.0, 7.0, 4.0, 11.0, 6.0,
      6.0, 2.0, 4.0, 7.0, 5.0, 7.0, 9.0, 6.0, 6.0, 7.0, 6.0, 10.0, 7.0, 6.0, 10.0,
      7.0, 2.0, 7.0, 8.0, 8.0, 9.0, 6.0, 2.0, 8.0, 8.0, 4.0, 3.0, 9.0, 9.0, 8.0, 7.0,
      7.0, 4.0, 5.0, 7.0, 8.0, 7.0, 6.0, 8.0, 8.0, 8.0, 6.0, 9.0, 7.0, 5.0, 6.0, 6.0,
      9.0, 12.0, 5.0, 6.0, 5.0, 2.0, 8.0, 7.0, 6.0, 10.0, 5.0, 5.0, 6.0, 8.0, 7.0,
      7.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06599991423716633
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02570812084144423
    mean_inference_ms: 1.235663307499137
    mean_raw_obs_processing_ms: 0.2808013408949881
time_since_restore: 2000.163253545761
time_this_iter_s: 10.154298782348633
time_total_s: 2000.163253545761
timers:
  sample_time_ms: 0.069
  synch_weights_time_ms: 0.691
  training_iteration_time_ms: 0.862
timestamp: 1691996179
timesteps_total: 2392600
training_iteration: 197
trial_id: default
train step: 198
agent_timesteps_total: 2406450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01865316320348669
  StateBufferConnector_ms: 0.0032552966365107785
  ViewRequirementAgentConnector_ms: 0.11312166849772136
counters:
  num_agent_steps_sampled: 2406450
  num_agent_steps_trained: 2389500
  num_env_steps_sampled: 2406450
  num_env_steps_trained: 2389500
  num_samples_added_to_queue: 2406000
  num_training_step_calls_since_last_synch_worker_weights: 322
  num_weight_broadcasts: 47305
custom_metrics: {}
date: 2023-08-14_15-56-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.7407407407407405
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 18801
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7395176291465759
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.5822906494140625
        total_loss: 18.25398063659668
        var_gnorm: 64.62667846679688
        vf_explained_var: 0.9178938865661621
        vf_loss: 42.738555908203125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4779.0
  learner_queue:
    size_count: 4785
    size_mean: 15.04
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.70833252032501
  num_agent_steps_sampled: 2406450
  num_agent_steps_trained: 2389500
  num_env_steps_sampled: 2406450
  num_env_steps_trained: 2389500
  num_samples_added_to_queue: 2406000
  num_training_step_calls_since_last_synch_worker_weights: 322
  num_weight_broadcasts: 47305
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 189.464
    learner_load_time_ms: 1.553
    learner_load_wait_time_ms: 1.565
iterations_since_restore: 198
node_ip: 127.0.0.1
num_agent_steps_sampled: 2406450
num_agent_steps_trained: 2389500
num_env_steps_sampled: 2406450
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.9964007232743
num_env_steps_trained: 2389500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9964916797258
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.471428571428575
  ram_util_percent: 81.56428571428572
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06594666247783175
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025685307155060018
  mean_inference_ms: 1.2347665801749064
  mean_raw_obs_processing_ms: 0.28059761779012016
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01865316320348669
    StateBufferConnector_ms: 0.0032552966365107785
    ViewRequirementAgentConnector_ms: 0.11312166849772136
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.7407407407407405
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [14.0, 5.0, 4.0, 7.0, 10.0, 11.0, 6.0, 9.0, 8.0, 8.0, 6.0, 7.0,
      10.0, 8.0, 5.0, 6.0, 6.0, 6.0, 0.0, 7.0, 4.0, 6.0, 3.0, 7.0, 2.0, 10.0, 3.0,
      4.0, 10.0, 10.0, 7.0, 5.0, 9.0, 9.0, 4.0, 10.0, 7.0, 9.0, 6.0, 4.0, 6.0, 8.0,
      4.0, 5.0, 5.0, 9.0, 6.0, 8.0, 4.0, 9.0, 7.0, 8.0, 5.0, 8.0, 5.0, 7.0, 8.0, 7.0,
      9.0, 2.0, 7.0, 4.0, 9.0, 1.0, 3.0, 12.0, 3.0, 3.0, 3.0, 10.0, 9.0, 8.0, 6.0,
      5.0, 5.0, 5.0, 6.0, 5.0, 5.0, 3.0, 8.0, 4.0, 9.0, 8.0, 10.0, 8.0, 6.0, 8.0,
      4.0, 4.0, 8.0, 10.0, 10.0, 3.0, 9.0, 3.0, 5.0, 9.0, 13.0, 9.0, 12.0, 5.0, 5.0,
      5.0, 10.0, 9.0, 11.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06594666247783175
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025685307155060018
    mean_inference_ms: 1.2347665801749064
    mean_raw_obs_processing_ms: 0.28059761779012016
time_since_restore: 2010.2990317344666
time_this_iter_s: 10.135778188705444
time_total_s: 2010.2990317344666
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996190
timesteps_total: 2406450
training_iteration: 198
trial_id: default
train step: 199
agent_timesteps_total: 2418750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020664453506469727
  StateBufferConnector_ms: 0.0036554336547851562
  ViewRequirementAgentConnector_ms: 0.12417268753051758
counters:
  num_agent_steps_sampled: 2418750
  num_agent_steps_trained: 2402000
  num_env_steps_sampled: 2418750
  num_env_steps_trained: 2402000
  num_samples_added_to_queue: 2418500
  num_training_step_calls_since_last_synch_worker_weights: 1224
  num_weight_broadcasts: 47547
custom_metrics: {}
date: 2023-08-14_15-56-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.84
episode_reward_min: 4.0
episodes_this_iter: 96
episodes_total: 18897
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7131348252296448
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.804986953735352
        total_loss: -2.8318235874176025
        var_gnorm: 64.62890625
        vf_explained_var: 0.9533986449241638
        vf_loss: 25.077674865722656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4804.0
  learner_queue:
    size_count: 4808
    size_mean: 15.0
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6613247725836149
  num_agent_steps_sampled: 2418750
  num_agent_steps_trained: 2402000
  num_env_steps_sampled: 2418750
  num_env_steps_trained: 2402000
  num_samples_added_to_queue: 2418500
  num_training_step_calls_since_last_synch_worker_weights: 1224
  num_weight_broadcasts: 47547
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 265.412
    learner_load_time_ms: 1.561
    learner_load_wait_time_ms: 1.611
iterations_since_restore: 199
node_ip: 127.0.0.1
num_agent_steps_sampled: 2418750
num_agent_steps_trained: 2402000
num_env_steps_sampled: 2418750
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.993372476049
num_env_steps_trained: 2402000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.993264711432
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.67142857142857
  ram_util_percent: 83.14285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06595521581085316
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025685599672530136
  mean_inference_ms: 1.234625870419206
  mean_raw_obs_processing_ms: 0.28055976251129994
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020664453506469727
    StateBufferConnector_ms: 0.0036554336547851562
    ViewRequirementAgentConnector_ms: 0.12417268753051758
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.84
  episode_reward_min: 4.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 9.0, 11.0, 9.0, 9.0, 4.0, 8.0, 6.0, 5.0, 10.0, 6.0, 11.0,
      8.0, 16.0, 12.0, 9.0, 9.0, 9.0, 11.0, 11.0, 7.0, 8.0, 12.0, 10.0, 10.0, 11.0,
      4.0, 6.0, 14.0, 14.0, 9.0, 5.0, 11.0, 10.0, 11.0, 9.0, 13.0, 14.0, 14.0, 8.0,
      7.0, 7.0, 6.0, 9.0, 8.0, 10.0, 8.0, 9.0, 9.0, 12.0, 6.0, 9.0, 7.0, 7.0, 14.0,
      9.0, 8.0, 8.0, 6.0, 8.0, 7.0, 5.0, 9.0, 10.0, 7.0, 8.0, 10.0, 6.0, 7.0, 8.0,
      11.0, 8.0, 10.0, 11.0, 8.0, 7.0, 6.0, 7.0, 6.0, 8.0, 5.0, 10.0, 11.0, 5.0, 10.0,
      13.0, 5.0, 10.0, 12.0, 10.0, 10.0, 7.0, 11.0, 8.0, 7.0, 11.0, 10.0, 9.0, 5.0,
      6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06595521581085316
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025685599672530136
    mean_inference_ms: 1.234625870419206
    mean_raw_obs_processing_ms: 0.28055976251129994
time_since_restore: 2020.391182899475
time_this_iter_s: 10.092151165008545
time_total_s: 2020.391182899475
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996200
timesteps_total: 2418750
training_iteration: 199
trial_id: default
train step: 200
agent_timesteps_total: 2431250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021490097045898438
  StateBufferConnector_ms: 0.0037801265716552734
  ViewRequirementAgentConnector_ms: 0.1299738883972168
counters:
  num_agent_steps_sampled: 2431250
  num_agent_steps_trained: 2414500
  num_env_steps_sampled: 2431250
  num_env_steps_trained: 2414500
  num_samples_added_to_queue: 2431000
  num_training_step_calls_since_last_synch_worker_weights: 1283
  num_weight_broadcasts: 47793
custom_metrics: {}
date: 2023-08-14_15-56-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.5
episode_reward_min: 3.0
episodes_this_iter: 98
episodes_total: 18995
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6758447289466858
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -27.149011611938477
        total_loss: 9.840069770812988
        var_gnorm: 64.63491821289062
        vf_explained_var: 0.8877012729644775
        vf_loss: 80.73661041259766
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4829.0
  learner_queue:
    size_count: 4833
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3181805642627265
  num_agent_steps_sampled: 2431250
  num_agent_steps_trained: 2414500
  num_env_steps_sampled: 2431250
  num_env_steps_trained: 2414500
  num_samples_added_to_queue: 2431000
  num_training_step_calls_since_last_synch_worker_weights: 1283
  num_weight_broadcasts: 47793
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 281.047
    learner_load_time_ms: 1.556
    learner_load_wait_time_ms: 1.813
iterations_since_restore: 200
node_ip: 127.0.0.1
num_agent_steps_sampled: 2431250
num_agent_steps_trained: 2414500
num_env_steps_sampled: 2431250
num_env_steps_sampled_this_iter: 12500
num_env_steps_sampled_throughput_per_sec: 1249.996602544482
num_env_steps_trained: 2414500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.996602544482
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.89333333333333
  ram_util_percent: 82.70666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06593929559553169
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025686573590862308
  mean_inference_ms: 1.234434431996246
  mean_raw_obs_processing_ms: 0.2805102319774391
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021490097045898438
    StateBufferConnector_ms: 0.0037801265716552734
    ViewRequirementAgentConnector_ms: 0.1299738883972168
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.5
  episode_reward_min: 3.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 6.0, 11.0, 11.0, 7.0, 9.0, 6.0, 10.0, 9.0, 9.0, 12.0, 11.0,
      4.0, 13.0, 13.0, 8.0, 9.0, 11.0, 10.0, 12.0, 7.0, 3.0, 14.0, 11.0, 12.0, 8.0,
      7.0, 8.0, 9.0, 6.0, 12.0, 12.0, 8.0, 10.0, 8.0, 4.0, 11.0, 11.0, 8.0, 7.0, 16.0,
      15.0, 8.0, 12.0, 9.0, 9.0, 10.0, 4.0, 8.0, 13.0, 5.0, 6.0, 9.0, 11.0, 12.0,
      12.0, 14.0, 12.0, 13.0, 12.0, 6.0, 6.0, 12.0, 11.0, 13.0, 8.0, 10.0, 15.0, 6.0,
      11.0, 7.0, 8.0, 14.0, 9.0, 9.0, 6.0, 7.0, 6.0, 9.0, 11.0, 6.0, 9.0, 9.0, 12.0,
      7.0, 10.0, 9.0, 14.0, 8.0, 6.0, 18.0, 10.0, 13.0, 7.0, 12.0, 7.0, 6.0, 10.0,
      13.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06593929559553169
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025686573590862308
    mean_inference_ms: 1.234434431996246
    mean_raw_obs_processing_ms: 0.2805102319774391
time_since_restore: 2030.479082107544
time_this_iter_s: 10.087899208068848
time_total_s: 2030.479082107544
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691996210
timesteps_total: 2431250
training_iteration: 200
trial_id: default
train step: 201
agent_timesteps_total: 2444350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01958164514279833
  StateBufferConnector_ms: 0.003444680980607575
  ViewRequirementAgentConnector_ms: 0.1185917386821672
counters:
  num_agent_steps_sampled: 2444350
  num_agent_steps_trained: 2427500
  num_env_steps_sampled: 2444350
  num_env_steps_trained: 2427500
  num_samples_added_to_queue: 2444000
  num_training_step_calls_since_last_synch_worker_weights: 1118
  num_weight_broadcasts: 48051
custom_metrics: {}
date: 2023-08-14_15-57-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.284313725490197
episode_reward_min: 5.0
episodes_this_iter: 102
episodes_total: 19097
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6967871189117432
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.032713890075684
        total_loss: 22.806015014648438
        var_gnorm: 64.64430236816406
        vf_explained_var: 0.9084270596504211
        vf_loss: 62.645328521728516
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4855.0
  learner_queue:
    size_count: 4859
    size_mean: 15.74
    size_quantiles: [13.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.7158212067269312
  num_agent_steps_sampled: 2444350
  num_agent_steps_trained: 2427500
  num_env_steps_sampled: 2444350
  num_env_steps_trained: 2427500
  num_samples_added_to_queue: 2444000
  num_training_step_calls_since_last_synch_worker_weights: 1118
  num_weight_broadcasts: 48051
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 258.957
    learner_load_time_ms: 1.557
    learner_load_wait_time_ms: 1.56
iterations_since_restore: 201
node_ip: 127.0.0.1
num_agent_steps_sampled: 2444350
num_agent_steps_trained: 2427500
num_env_steps_sampled: 2444350
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9950339982413
num_env_steps_trained: 2427500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9950719066517
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.99999999999999
  ram_util_percent: 82.35714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0659063750068382
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02567819688827495
  mean_inference_ms: 1.2339378935497332
  mean_raw_obs_processing_ms: 0.28040180258037584
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01958164514279833
    StateBufferConnector_ms: 0.003444680980607575
    ViewRequirementAgentConnector_ms: 0.1185917386821672
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.284313725490197
  episode_reward_min: 5.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 7.0, 10.0, 6.0, 10.0, 10.0, 8.0, 11.0, 7.0, 8.0, 13.0, 7.0,
      7.0, 9.0, 8.0, 7.0, 6.0, 11.0, 6.0, 10.0, 11.0, 5.0, 8.0, 9.0, 11.0, 11.0, 10.0,
      8.0, 5.0, 9.0, 9.0, 10.0, 6.0, 7.0, 7.0, 10.0, 9.0, 8.0, 12.0, 9.0, 9.0, 12.0,
      14.0, 9.0, 10.0, 10.0, 10.0, 9.0, 11.0, 12.0, 9.0, 16.0, 10.0, 9.0, 12.0, 8.0,
      6.0, 8.0, 5.0, 10.0, 11.0, 11.0, 9.0, 8.0, 9.0, 9.0, 11.0, 10.0, 9.0, 10.0,
      13.0, 8.0, 12.0, 12.0, 5.0, 11.0, 6.0, 7.0, 10.0, 13.0, 11.0, 11.0, 10.0, 7.0,
      7.0, 15.0, 10.0, 9.0, 12.0, 8.0, 10.0, 9.0, 13.0, 9.0, 6.0, 9.0, 9.0, 9.0, 12.0,
      7.0, 11.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0659063750068382
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02567819688827495
    mean_inference_ms: 1.2339378935497332
    mean_raw_obs_processing_ms: 0.28040180258037584
time_since_restore: 2040.5812108516693
time_this_iter_s: 10.102128744125366
time_total_s: 2040.5812108516693
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996220
timesteps_total: 2444350
training_iteration: 201
trial_id: default
train step: 202
agent_timesteps_total: 2457250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020259380340576172
  StateBufferConnector_ms: 0.0035326480865478516
  ViewRequirementAgentConnector_ms: 0.1221308708190918
counters:
  num_agent_steps_sampled: 2457250
  num_agent_steps_trained: 2440500
  num_env_steps_sampled: 2457250
  num_env_steps_trained: 2440500
  num_samples_added_to_queue: 2457000
  num_training_step_calls_since_last_synch_worker_weights: 2965
  num_weight_broadcasts: 48305
custom_metrics: {}
date: 2023-08-14_15-57-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.13
episode_reward_min: 3.0
episodes_this_iter: 100
episodes_total: 19197
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.645548403263092
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.490753173828125
        total_loss: 31.740707397460938
        var_gnorm: 64.64559936523438
        vf_explained_var: 0.9023510813713074
        vf_loss: 74.91840362548828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4881.0
  learner_queue:
    size_count: 4885
    size_mean: 15.68
    size_quantiles: [13.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.8109253973085317
  num_agent_steps_sampled: 2457250
  num_agent_steps_trained: 2440500
  num_env_steps_sampled: 2457250
  num_env_steps_trained: 2440500
  num_samples_added_to_queue: 2457000
  num_training_step_calls_since_last_synch_worker_weights: 2965
  num_weight_broadcasts: 48305
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 282.142
    learner_load_time_ms: 1.389
    learner_load_wait_time_ms: 2.06
iterations_since_restore: 202
node_ip: 127.0.0.1
num_agent_steps_sampled: 2457250
num_agent_steps_trained: 2440500
num_env_steps_sampled: 2457250
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9984314460753
num_env_steps_trained: 2440500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9984192867425
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.99285714285714
  ram_util_percent: 82.41428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06588490323878074
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025671735385343286
  mean_inference_ms: 1.233577866533335
  mean_raw_obs_processing_ms: 0.2803137484939354
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020259380340576172
    StateBufferConnector_ms: 0.0035326480865478516
    ViewRequirementAgentConnector_ms: 0.1221308708190918
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.13
  episode_reward_min: 3.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 7.0, 11.0, 14.0, 9.0, 6.0, 5.0, 5.0, 10.0, 8.0, 10.0, 7.0,
      10.0, 8.0, 9.0, 11.0, 10.0, 9.0, 8.0, 7.0, 11.0, 9.0, 10.0, 7.0, 11.0, 8.0,
      10.0, 5.0, 9.0, 10.0, 11.0, 9.0, 10.0, 5.0, 14.0, 10.0, 12.0, 13.0, 9.0, 15.0,
      11.0, 10.0, 8.0, 10.0, 8.0, 8.0, 8.0, 11.0, 10.0, 9.0, 9.0, 6.0, 9.0, 13.0,
      14.0, 7.0, 8.0, 8.0, 7.0, 5.0, 8.0, 5.0, 12.0, 8.0, 11.0, 12.0, 8.0, 11.0, 10.0,
      10.0, 10.0, 5.0, 13.0, 7.0, 3.0, 15.0, 9.0, 6.0, 8.0, 9.0, 6.0, 12.0, 11.0,
      6.0, 11.0, 7.0, 11.0, 8.0, 7.0, 15.0, 11.0, 8.0, 9.0, 13.0, 5.0, 5.0, 11.0,
      5.0, 10.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06588490323878074
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025671735385343286
    mean_inference_ms: 1.233577866533335
    mean_raw_obs_processing_ms: 0.2803137484939354
time_since_restore: 2050.7296969890594
time_this_iter_s: 10.148486137390137
time_total_s: 2050.7296969890594
timers:
  sample_time_ms: 0.019
  synch_weights_time_ms: 0.006
  training_iteration_time_ms: 0.052
timestamp: 1691996230
timesteps_total: 2457250
training_iteration: 202
trial_id: default
train step: 203
agent_timesteps_total: 2469600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021388769149780273
  StateBufferConnector_ms: 0.003935337066650391
  ViewRequirementAgentConnector_ms: 0.12583279609680176
counters:
  num_agent_steps_sampled: 2469600
  num_agent_steps_trained: 2453000
  num_env_steps_sampled: 2469600
  num_env_steps_trained: 2453000
  num_samples_added_to_queue: 2469500
  num_training_step_calls_since_last_synch_worker_weights: 858
  num_weight_broadcasts: 48549
custom_metrics: {}
date: 2023-08-14_15-57-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.93
episode_reward_min: 3.0
episodes_this_iter: 97
episodes_total: 19294
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6450945138931274
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 7.833249092102051
        total_loss: 56.31272506713867
        var_gnorm: 64.6455307006836
        vf_explained_var: 0.8746457099914551
        vf_loss: 103.40989685058594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4906.0
  learner_queue:
    size_count: 4912
    size_mean: 15.56
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0983624174196784
  num_agent_steps_sampled: 2469600
  num_agent_steps_trained: 2453000
  num_env_steps_sampled: 2469600
  num_env_steps_trained: 2453000
  num_samples_added_to_queue: 2469500
  num_training_step_calls_since_last_synch_worker_weights: 858
  num_weight_broadcasts: 48549
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 178.884
    learner_load_time_ms: 1.402
    learner_load_wait_time_ms: 1.728
iterations_since_restore: 203
node_ip: 127.0.0.1
num_agent_steps_sampled: 2469600
num_agent_steps_trained: 2453000
num_env_steps_sampled: 2469600
num_env_steps_sampled_this_iter: 12350
num_env_steps_sampled_throughput_per_sec: 1234.9980272086186
num_env_steps_trained: 2453000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9980032475896
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.17333333333334
  ram_util_percent: 81.41333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06588594081797047
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02567213732652178
  mean_inference_ms: 1.2334218564283561
  mean_raw_obs_processing_ms: 0.2803141872186072
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021388769149780273
    StateBufferConnector_ms: 0.003935337066650391
    ViewRequirementAgentConnector_ms: 0.12583279609680176
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.93
  episode_reward_min: 3.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 10.0, 11.0, 11.0, 10.0, 10.0, 10.0, 10.0, 4.0, 10.0, 7.0,
      15.0, 10.0, 8.0, 8.0, 8.0, 6.0, 6.0, 15.0, 13.0, 13.0, 7.0, 10.0, 11.0, 11.0,
      5.0, 11.0, 10.0, 6.0, 6.0, 6.0, 9.0, 12.0, 9.0, 7.0, 13.0, 6.0, 8.0, 11.0, 6.0,
      10.0, 10.0, 11.0, 11.0, 12.0, 6.0, 6.0, 10.0, 8.0, 9.0, 7.0, 12.0, 10.0, 8.0,
      11.0, 12.0, 4.0, 13.0, 11.0, 14.0, 9.0, 8.0, 10.0, 5.0, 11.0, 7.0, 9.0, 7.0,
      9.0, 7.0, 5.0, 3.0, 5.0, 9.0, 11.0, 9.0, 6.0, 15.0, 11.0, 6.0, 10.0, 9.0, 13.0,
      7.0, 8.0, 7.0, 7.0, 6.0, 13.0, 8.0, 8.0, 10.0, 10.0, 13.0, 10.0, 3.0, 7.0, 8.0,
      8.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06588594081797047
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02567213732652178
    mean_inference_ms: 1.2334218564283561
    mean_raw_obs_processing_ms: 0.2803141872186072
time_since_restore: 2060.882187128067
time_this_iter_s: 10.152490139007568
time_total_s: 2060.882187128067
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996240
timesteps_total: 2469600
training_iteration: 203
trial_id: default
train step: 204
agent_timesteps_total: 2482150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020786285400390625
  StateBufferConnector_ms: 0.0037186145782470703
  ViewRequirementAgentConnector_ms: 0.12590837478637695
counters:
  num_agent_steps_sampled: 2482150
  num_agent_steps_trained: 2465500
  num_env_steps_sampled: 2482150
  num_env_steps_trained: 2465500
  num_samples_added_to_queue: 2482000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 48796
custom_metrics: {}
date: 2023-08-14_15-57-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.9
episode_reward_min: 5.0
episodes_this_iter: 98
episodes_total: 19392
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6246588230133057
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 32.11533737182617
        total_loss: 84.30934143066406
        var_gnorm: 64.64958953857422
        vf_explained_var: 0.8570539355278015
        vf_loss: 110.63458251953125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4931.0
  learner_queue:
    size_count: 4935
    size_mean: 15.42
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.218031198286809
  num_agent_steps_sampled: 2482150
  num_agent_steps_trained: 2465500
  num_env_steps_sampled: 2482150
  num_env_steps_trained: 2465500
  num_samples_added_to_queue: 2482000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 48796
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 273.486
    learner_load_time_ms: 1.404
    learner_load_wait_time_ms: 1.772
iterations_since_restore: 204
node_ip: 127.0.0.1
num_agent_steps_sampled: 2482150
num_agent_steps_trained: 2465500
num_env_steps_sampled: 2482150
num_env_steps_sampled_this_iter: 12550
num_env_steps_sampled_throughput_per_sec: 1254.9849197292438
num_env_steps_trained: 2465500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9849798100036
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.00714285714287
  ram_util_percent: 81.72857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06587057272665563
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025671478213745748
  mean_inference_ms: 1.233252655726769
  mean_raw_obs_processing_ms: 0.28027075389347744
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020786285400390625
    StateBufferConnector_ms: 0.0037186145782470703
    ViewRequirementAgentConnector_ms: 0.12590837478637695
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.9
  episode_reward_min: 5.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 9.0, 13.0, 11.0, 12.0, 8.0, 9.0, 11.0, 11.0, 9.0, 9.0,
      9.0, 6.0, 13.0, 7.0, 9.0, 8.0, 8.0, 10.0, 6.0, 9.0, 8.0, 11.0, 6.0, 13.0, 10.0,
      8.0, 7.0, 13.0, 8.0, 9.0, 6.0, 11.0, 6.0, 7.0, 5.0, 8.0, 8.0, 7.0, 7.0, 13.0,
      13.0, 13.0, 11.0, 10.0, 9.0, 12.0, 10.0, 7.0, 9.0, 10.0, 6.0, 11.0, 10.0, 12.0,
      9.0, 7.0, 10.0, 7.0, 8.0, 10.0, 7.0, 8.0, 15.0, 8.0, 8.0, 7.0, 6.0, 11.0, 6.0,
      8.0, 12.0, 12.0, 7.0, 5.0, 9.0, 5.0, 9.0, 9.0, 6.0, 11.0, 7.0, 14.0, 13.0, 8.0,
      5.0, 10.0, 5.0, 7.0, 9.0, 11.0, 5.0, 8.0, 8.0, 11.0, 5.0, 12.0, 6.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06587057272665563
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025671478213745748
    mean_inference_ms: 1.233252655726769
    mean_raw_obs_processing_ms: 0.28027075389347744
time_since_restore: 2070.9863250255585
time_this_iter_s: 10.104137897491455
time_total_s: 2070.9863250255585
timers:
  sample_time_ms: 0.039
  synch_weights_time_ms: 0.25
  training_iteration_time_ms: 0.352
timestamp: 1691996250
timesteps_total: 2482150
training_iteration: 204
trial_id: default
train step: 205
agent_timesteps_total: 2495300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019790362385870182
  StateBufferConnector_ms: 0.0034353108082002806
  ViewRequirementAgentConnector_ms: 0.11884703219515606
counters:
  num_agent_steps_sampled: 2495300
  num_agent_steps_trained: 2478500
  num_env_steps_sampled: 2495300
  num_env_steps_trained: 2478500
  num_samples_added_to_queue: 2495000
  num_training_step_calls_since_last_synch_worker_weights: 1828
  num_weight_broadcasts: 49056
custom_metrics: {}
date: 2023-08-14_15-57-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.37864077669903
episode_reward_min: 3.0
episodes_this_iter: 103
episodes_total: 19495
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6068088412284851
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -4.688264846801758
        total_loss: 59.515045166015625
        var_gnorm: 64.64794921875
        vf_explained_var: 0.8379515409469604
        vf_loss: 134.47470092773438
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4957.0
  learner_queue:
    size_count: 4961
    size_mean: 15.46
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.135077089893017
  num_agent_steps_sampled: 2495300
  num_agent_steps_trained: 2478500
  num_env_steps_sampled: 2495300
  num_env_steps_trained: 2478500
  num_samples_added_to_queue: 2495000
  num_training_step_calls_since_last_synch_worker_weights: 1828
  num_weight_broadcasts: 49056
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 259.575
    learner_load_time_ms: 1.406
    learner_load_wait_time_ms: 1.47
iterations_since_restore: 205
node_ip: 127.0.0.1
num_agent_steps_sampled: 2495300
num_agent_steps_trained: 2478500
num_env_steps_sampled: 2495300
num_env_steps_sampled_this_iter: 13150
num_env_steps_sampled_throughput_per_sec: 1314.9939804352703
num_env_steps_trained: 2478500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9940490995066
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.114285714285714
  ram_util_percent: 81.82857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06583233248075351
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02566234000864703
  mean_inference_ms: 1.2327436323290542
  mean_raw_obs_processing_ms: 0.2801556751173462
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019790362385870182
    StateBufferConnector_ms: 0.0034353108082002806
    ViewRequirementAgentConnector_ms: 0.11884703219515606
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.37864077669903
  episode_reward_min: 3.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 7.0, 16.0, 9.0, 5.0, 12.0, 8.0, 16.0, 12.0, 11.0, 13.0,
      12.0, 11.0, 9.0, 7.0, 9.0, 14.0, 11.0, 10.0, 6.0, 9.0, 12.0, 12.0, 10.0, 11.0,
      11.0, 7.0, 5.0, 11.0, 9.0, 7.0, 11.0, 6.0, 7.0, 7.0, 12.0, 8.0, 6.0, 8.0, 8.0,
      6.0, 8.0, 12.0, 7.0, 13.0, 12.0, 13.0, 13.0, 5.0, 9.0, 16.0, 16.0, 10.0, 11.0,
      7.0, 8.0, 9.0, 8.0, 12.0, 6.0, 9.0, 5.0, 7.0, 10.0, 7.0, 13.0, 8.0, 8.0, 12.0,
      11.0, 4.0, 7.0, 9.0, 10.0, 7.0, 10.0, 6.0, 9.0, 13.0, 6.0, 10.0, 8.0, 12.0,
      14.0, 7.0, 5.0, 12.0, 7.0, 9.0, 8.0, 16.0, 6.0, 11.0, 9.0, 8.0, 9.0, 13.0, 8.0,
      13.0, 9.0, 3.0, 8.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06583233248075351
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02566234000864703
    mean_inference_ms: 1.2327436323290542
    mean_raw_obs_processing_ms: 0.2801556751173462
time_since_restore: 2081.1021859645844
time_this_iter_s: 10.115860939025879
time_total_s: 2081.1021859645844
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.006
  training_iteration_time_ms: 0.044
timestamp: 1691996260
timesteps_total: 2495300
training_iteration: 205
trial_id: default
train step: 206
agent_timesteps_total: 2508100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02028512954711914
  StateBufferConnector_ms: 0.0034995079040527344
  ViewRequirementAgentConnector_ms: 0.12031817436218262
counters:
  num_agent_steps_sampled: 2508100
  num_agent_steps_trained: 2491500
  num_env_steps_sampled: 2508100
  num_env_steps_trained: 2491500
  num_samples_added_to_queue: 2508000
  num_training_step_calls_since_last_synch_worker_weights: 1281
  num_weight_broadcasts: 49307
custom_metrics: {}
date: 2023-08-14_15-57-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.64
episode_reward_min: 4.0
episodes_this_iter: 100
episodes_total: 19595
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.624249279499054
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -13.137749671936035
        total_loss: 42.738807678222656
        var_gnorm: 64.64800262451172
        vf_explained_var: 0.8506911993026733
        vf_loss: 117.99560546875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4983.0
  learner_queue:
    size_count: 4987
    size_mean: 15.66
    size_quantiles: [13.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.8392854103342915
  num_agent_steps_sampled: 2508100
  num_agent_steps_trained: 2491500
  num_env_steps_sampled: 2508100
  num_env_steps_trained: 2491500
  num_samples_added_to_queue: 2508000
  num_training_step_calls_since_last_synch_worker_weights: 1281
  num_weight_broadcasts: 49307
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 236.952
    learner_load_time_ms: 1.399
    learner_load_wait_time_ms: 1.629
iterations_since_restore: 206
node_ip: 127.0.0.1
num_agent_steps_sampled: 2508100
num_agent_steps_trained: 2491500
num_env_steps_sampled: 2508100
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9996032716074
num_env_steps_trained: 2491500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9995970727261
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.57142857142857
  ram_util_percent: 82.42142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06581568532690349
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025656645781906056
  mean_inference_ms: 1.2324017561624572
  mean_raw_obs_processing_ms: 0.280070636992406
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02028512954711914
    StateBufferConnector_ms: 0.0034995079040527344
    ViewRequirementAgentConnector_ms: 0.12031817436218262
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.64
  episode_reward_min: 4.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 13.0, 7.0, 16.0, 12.0, 10.0, 10.0, 13.0, 11.0, 9.0, 11.0,
      9.0, 10.0, 10.0, 9.0, 10.0, 12.0, 9.0, 9.0, 8.0, 8.0, 12.0, 12.0, 8.0, 8.0,
      11.0, 10.0, 12.0, 7.0, 11.0, 10.0, 10.0, 9.0, 11.0, 11.0, 12.0, 11.0, 10.0,
      7.0, 13.0, 10.0, 11.0, 14.0, 8.0, 5.0, 13.0, 10.0, 12.0, 12.0, 12.0, 11.0, 9.0,
      7.0, 9.0, 12.0, 5.0, 6.0, 10.0, 11.0, 9.0, 10.0, 8.0, 8.0, 15.0, 9.0, 4.0, 10.0,
      9.0, 8.0, 9.0, 11.0, 12.0, 4.0, 8.0, 9.0, 4.0, 9.0, 13.0, 10.0, 6.0, 8.0, 9.0,
      9.0, 6.0, 8.0, 11.0, 9.0, 8.0, 11.0, 11.0, 11.0, 11.0, 9.0, 5.0, 11.0, 5.0,
      4.0, 11.0, 11.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06581568532690349
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025656645781906056
    mean_inference_ms: 1.2324017561624572
    mean_raw_obs_processing_ms: 0.280070636992406
time_since_restore: 2091.1965177059174
time_this_iter_s: 10.094331741333008
time_total_s: 2091.1965177059174
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691996270
timesteps_total: 2508100
training_iteration: 206
trial_id: default
train step: 207
agent_timesteps_total: 2521650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018825396051946677
  StateBufferConnector_ms: 0.0033796958203585643
  ViewRequirementAgentConnector_ms: 0.11431968437050874
counters:
  num_agent_steps_sampled: 2521650
  num_agent_steps_trained: 2505000
  num_env_steps_sampled: 2521650
  num_env_steps_trained: 2505000
  num_samples_added_to_queue: 2521500
  num_training_step_calls_since_last_synch_worker_weights: 233
  num_weight_broadcasts: 49575
custom_metrics: {}
date: 2023-08-14_15-58-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 8.952830188679245
episode_reward_min: 2.0
episodes_this_iter: 106
episodes_total: 19701
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6510375142097473
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.02881145477295
        total_loss: 10.857593536376953
        var_gnorm: 64.64929962158203
        vf_explained_var: 0.931663453578949
        vf_loss: 50.28318405151367
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5010.0
  learner_queue:
    size_count: 5016
    size_mean: 15.54
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1173182178770737
  num_agent_steps_sampled: 2521650
  num_agent_steps_trained: 2505000
  num_env_steps_sampled: 2521650
  num_env_steps_trained: 2505000
  num_samples_added_to_queue: 2521500
  num_training_step_calls_since_last_synch_worker_weights: 233
  num_weight_broadcasts: 49575
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 167.883
    learner_load_time_ms: 1.393
    learner_load_wait_time_ms: 1.6
iterations_since_restore: 207
node_ip: 127.0.0.1
num_agent_steps_sampled: 2521650
num_agent_steps_trained: 2505000
num_env_steps_sampled: 2521650
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.994831104923
num_env_steps_trained: 2505000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9948501783365
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.693333333333335
  ram_util_percent: 82.35999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06577573731689607
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025640562624508638
  mean_inference_ms: 1.2317202998816417
  mean_raw_obs_processing_ms: 0.27992196358773325
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018825396051946677
    StateBufferConnector_ms: 0.0033796958203585643
    ViewRequirementAgentConnector_ms: 0.11431968437050874
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 8.952830188679245
  episode_reward_min: 2.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 12.0, 8.0, 11.0, 4.0, 18.0, 10.0, 7.0, 13.0, 9.0, 8.0, 8.0,
      9.0, 9.0, 14.0, 11.0, 8.0, 10.0, 7.0, 9.0, 12.0, 6.0, 11.0, 9.0, 7.0, 16.0,
      10.0, 14.0, 10.0, 9.0, 8.0, 10.0, 13.0, 10.0, 6.0, 11.0, 5.0, 7.0, 7.0, 6.0,
      9.0, 9.0, 10.0, 10.0, 11.0, 3.0, 9.0, 11.0, 6.0, 8.0, 6.0, 5.0, 8.0, 11.0, 8.0,
      10.0, 8.0, 13.0, 8.0, 12.0, 6.0, 9.0, 7.0, 7.0, 5.0, 6.0, 11.0, 10.0, 6.0, 7.0,
      8.0, 9.0, 8.0, 7.0, 12.0, 10.0, 7.0, 5.0, 9.0, 12.0, 5.0, 11.0, 9.0, 9.0, 11.0,
      10.0, 9.0, 7.0, 5.0, 12.0, 8.0, 10.0, 8.0, 5.0, 7.0, 9.0, 10.0, 10.0, 11.0,
      2.0, 11.0, 11.0, 11.0, 7.0, 12.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06577573731689607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025640562624508638
    mean_inference_ms: 1.2317202998816417
    mean_raw_obs_processing_ms: 0.27992196358773325
time_since_restore: 2101.350148677826
time_this_iter_s: 10.15363097190857
time_total_s: 2101.350148677826
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691996281
timesteps_total: 2521650
training_iteration: 207
trial_id: default
train step: 208
agent_timesteps_total: 2534450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020543336868286133
  StateBufferConnector_ms: 0.0037975311279296875
  ViewRequirementAgentConnector_ms: 0.12547874450683594
counters:
  num_agent_steps_sampled: 2534450
  num_agent_steps_trained: 2517500
  num_env_steps_sampled: 2534450
  num_env_steps_trained: 2517500
  num_samples_added_to_queue: 2534000
  num_training_step_calls_since_last_synch_worker_weights: 288
  num_weight_broadcasts: 49828
custom_metrics: {}
date: 2023-08-14_15-58-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.49
episode_reward_min: 2.0
episodes_this_iter: 100
episodes_total: 19801
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5672421455383301
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -21.956037521362305
        total_loss: -1.7014505863189697
        var_gnorm: 64.65459442138672
        vf_explained_var: 0.9383121728897095
        vf_loss: 46.18159484863281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5035.0
  learner_queue:
    size_count: 5042
    size_mean: 14.98
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8164801127455263
  num_agent_steps_sampled: 2534450
  num_agent_steps_trained: 2517500
  num_env_steps_sampled: 2534450
  num_env_steps_trained: 2517500
  num_samples_added_to_queue: 2534000
  num_training_step_calls_since_last_synch_worker_weights: 288
  num_weight_broadcasts: 49828
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 194.848
    learner_load_time_ms: 1.351
    learner_load_wait_time_ms: 1.589
iterations_since_restore: 208
node_ip: 127.0.0.1
num_agent_steps_sampled: 2534450
num_agent_steps_trained: 2517500
num_env_steps_sampled: 2534450
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9963989359123
num_env_steps_trained: 2517500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9964833358517
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 51.65000000000001
  ram_util_percent: 82.49285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06576077251052312
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025636201996331785
  mean_inference_ms: 1.2314300556258646
  mean_raw_obs_processing_ms: 0.2798543441589112
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020543336868286133
    StateBufferConnector_ms: 0.0037975311279296875
    ViewRequirementAgentConnector_ms: 0.12547874450683594
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.49
  episode_reward_min: 2.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 13.0, 10.0, 10.0, 7.0, 9.0, 4.0, 7.0, 9.0, 5.0, 9.0, 11.0,
      11.0, 10.0, 6.0, 6.0, 9.0, 8.0, 5.0, 9.0, 10.0, 7.0, 11.0, 2.0, 7.0, 7.0, 6.0,
      4.0, 13.0, 8.0, 9.0, 8.0, 9.0, 8.0, 12.0, 4.0, 5.0, 5.0, 4.0, 8.0, 4.0, 4.0,
      7.0, 5.0, 5.0, 9.0, 4.0, 7.0, 5.0, 8.0, 3.0, 6.0, 5.0, 7.0, 5.0, 10.0, 10.0,
      10.0, 13.0, 11.0, 7.0, 11.0, 10.0, 5.0, 6.0, 11.0, 9.0, 9.0, 8.0, 8.0, 4.0,
      11.0, 6.0, 7.0, 6.0, 10.0, 7.0, 12.0, 9.0, 7.0, 4.0, 7.0, 4.0, 7.0, 6.0, 7.0,
      8.0, 14.0, 7.0, 8.0, 3.0, 6.0, 2.0, 5.0, 6.0, 5.0, 7.0, 9.0, 10.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06576077251052312
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025636201996331785
    mean_inference_ms: 1.2314300556258646
    mean_raw_obs_processing_ms: 0.2798543441589112
time_since_restore: 2111.5269587039948
time_this_iter_s: 10.176810026168823
time_total_s: 2111.5269587039948
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996291
timesteps_total: 2534450
training_iteration: 208
trial_id: default
train step: 209
agent_timesteps_total: 2546850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02127861976623535
  StateBufferConnector_ms: 0.0037238597869873047
  ViewRequirementAgentConnector_ms: 0.12749004364013672
counters:
  num_agent_steps_sampled: 2546850
  num_agent_steps_trained: 2530000
  num_env_steps_sampled: 2546850
  num_env_steps_trained: 2530000
  num_samples_added_to_queue: 2546500
  num_training_step_calls_since_last_synch_worker_weights: 198
  num_weight_broadcasts: 50073
custom_metrics: {}
date: 2023-08-14_15-58-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 6.73
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 19897
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5675036907196045
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.9746783375740051
        total_loss: 12.027029037475586
        var_gnorm: 64.65721130371094
        vf_explained_var: 0.9516241550445557
        vf_loss: 31.678451538085938
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5060.0
  learner_queue:
    size_count: 5067
    size_mean: 14.7
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.9723082923316018
  num_agent_steps_sampled: 2546850
  num_agent_steps_trained: 2530000
  num_env_steps_sampled: 2546850
  num_env_steps_trained: 2530000
  num_samples_added_to_queue: 2546500
  num_training_step_calls_since_last_synch_worker_weights: 198
  num_weight_broadcasts: 50073
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 150.066
    learner_load_time_ms: 1.346
    learner_load_wait_time_ms: 1.509
iterations_since_restore: 209
node_ip: 127.0.0.1
num_agent_steps_sampled: 2546850
num_agent_steps_trained: 2530000
num_env_steps_sampled: 2546850
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.9996156693696
num_env_steps_trained: 2530000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.999612569929
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.792857142857144
  ram_util_percent: 82.63571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06576688516176339
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02563577821237354
  mean_inference_ms: 1.2312841809688801
  mean_raw_obs_processing_ms: 0.27982584274522415
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02127861976623535
    StateBufferConnector_ms: 0.0037238597869873047
    ViewRequirementAgentConnector_ms: 0.12749004364013672
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 6.73
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 9.0, 10.0, 10.0, 8.0, 4.0, 9.0, 8.0, 6.0, 6.0, 8.0, 10.0,
      5.0, 4.0, 8.0, 8.0, 8.0, 7.0, 9.0, 7.0, 9.0, 6.0, 0.0, 6.0, 3.0, 7.0, 9.0, 7.0,
      7.0, 6.0, 1.0, 10.0, 7.0, 10.0, 9.0, 8.0, 9.0, 6.0, 6.0, 10.0, 9.0, 7.0, 3.0,
      4.0, 8.0, 5.0, 3.0, 6.0, 2.0, 4.0, 10.0, 6.0, 5.0, 5.0, 6.0, 4.0, 6.0, 8.0,
      9.0, 15.0, 6.0, 5.0, 1.0, 5.0, 5.0, 8.0, 7.0, 6.0, 8.0, 5.0, 7.0, 5.0, 10.0,
      5.0, 5.0, 7.0, 9.0, 7.0, 6.0, 8.0, 5.0, 7.0, 6.0, 4.0, 11.0, 8.0, 4.0, 7.0,
      9.0, 7.0, 8.0, 7.0, 8.0, 5.0, 7.0, 10.0, 7.0, 3.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06576688516176339
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02563577821237354
    mean_inference_ms: 1.2312841809688801
    mean_raw_obs_processing_ms: 0.27982584274522415
time_since_restore: 2121.6747527122498
time_this_iter_s: 10.147794008255005
time_total_s: 2121.6747527122498
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691996301
timesteps_total: 2546850
training_iteration: 209
trial_id: default
train step: 210
agent_timesteps_total: 2559500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020524024963378906
  StateBufferConnector_ms: 0.003703594207763672
  ViewRequirementAgentConnector_ms: 0.12429428100585938
counters:
  num_agent_steps_sampled: 2559500
  num_agent_steps_trained: 2543000
  num_env_steps_sampled: 2559500
  num_env_steps_trained: 2543000
  num_samples_added_to_queue: 2559500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 50321
custom_metrics: {}
date: 2023-08-14_15-58-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.81
episode_reward_min: 3.0
episodes_this_iter: 100
episodes_total: 19997
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6663392782211304
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.38780975341796875
        total_loss: 17.661746978759766
        var_gnorm: 64.65790557861328
        vf_explained_var: 0.9358949065208435
        vf_loss: 42.76250457763672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5086.0
  learner_queue:
    size_count: 5088
    size_mean: 14.76
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9448393249829148
  num_agent_steps_sampled: 2559500
  num_agent_steps_trained: 2543000
  num_env_steps_sampled: 2559500
  num_env_steps_trained: 2543000
  num_samples_added_to_queue: 2559500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 50321
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 312.894
    learner_load_time_ms: 1.346
    learner_load_wait_time_ms: 1.774
iterations_since_restore: 210
node_ip: 127.0.0.1
num_agent_steps_sampled: 2559500
num_agent_steps_trained: 2543000
num_env_steps_sampled: 2559500
num_env_steps_sampled_this_iter: 12650
num_env_steps_sampled_throughput_per_sec: 1262.4131736130869
num_env_steps_trained: 2543000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1297.3416013415122
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.466666666666676
  ram_util_percent: 82.98
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06574410448518718
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02563347118823916
  mean_inference_ms: 1.231070923325182
  mean_raw_obs_processing_ms: 0.2797807124155739
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020524024963378906
    StateBufferConnector_ms: 0.003703594207763672
    ViewRequirementAgentConnector_ms: 0.12429428100585938
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.81
  episode_reward_min: 3.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 6.0, 4.0, 9.0, 7.0, 7.0, 5.0, 6.0, 6.0, 8.0, 6.0, 4.0, 10.0,
      8.0, 8.0, 12.0, 10.0, 6.0, 8.0, 6.0, 8.0, 10.0, 8.0, 4.0, 10.0, 8.0, 6.0, 9.0,
      9.0, 10.0, 10.0, 13.0, 6.0, 8.0, 4.0, 7.0, 9.0, 10.0, 7.0, 7.0, 12.0, 7.0, 4.0,
      7.0, 6.0, 7.0, 12.0, 4.0, 10.0, 5.0, 6.0, 8.0, 9.0, 8.0, 6.0, 5.0, 8.0, 4.0,
      4.0, 3.0, 5.0, 6.0, 7.0, 9.0, 11.0, 9.0, 6.0, 6.0, 13.0, 10.0, 8.0, 10.0, 9.0,
      9.0, 7.0, 6.0, 9.0, 16.0, 10.0, 9.0, 10.0, 4.0, 9.0, 10.0, 10.0, 10.0, 7.0,
      8.0, 6.0, 7.0, 7.0, 8.0, 9.0, 11.0, 5.0, 7.0, 11.0, 9.0, 7.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06574410448518718
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02563347118823916
    mean_inference_ms: 1.231070923325182
    mean_raw_obs_processing_ms: 0.2797807124155739
time_since_restore: 2131.7619087696075
time_this_iter_s: 10.087156057357788
time_total_s: 2131.7619087696075
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.603
  training_iteration_time_ms: 2.21
timestamp: 1691996311
timesteps_total: 2559500
training_iteration: 210
trial_id: default
train step: 211
agent_timesteps_total: 2572500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019980192184448242
  StateBufferConnector_ms: 0.0035140514373779297
  ViewRequirementAgentConnector_ms: 0.12253522872924805
counters:
  num_agent_steps_sampled: 2572500
  num_agent_steps_trained: 2556000
  num_env_steps_sampled: 2572500
  num_env_steps_trained: 2556000
  num_samples_added_to_queue: 2572500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 50579
custom_metrics: {}
date: 2023-08-14_15-58-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.59
episode_reward_min: 2.0
episodes_this_iter: 100
episodes_total: 20097
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.635310173034668
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.991662979125977
        total_loss: 44.810447692871094
        var_gnorm: 64.65727233886719
        vf_explained_var: 0.8949487805366516
        vf_loss: 77.99067687988281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5112.0
  learner_queue:
    size_count: 5117
    size_mean: 15.56
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.022936948203554
  num_agent_steps_sampled: 2572500
  num_agent_steps_trained: 2556000
  num_env_steps_sampled: 2572500
  num_env_steps_trained: 2556000
  num_samples_added_to_queue: 2572500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 50579
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 189.808
    learner_load_time_ms: 1.358
    learner_load_wait_time_ms: 1.636
iterations_since_restore: 211
node_ip: 127.0.0.1
num_agent_steps_sampled: 2572500
num_agent_steps_trained: 2556000
num_env_steps_sampled: 2572500
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.703544049122
num_env_steps_trained: 2556000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.703544049122
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.86428571428572
  ram_util_percent: 82.24285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06572032459503942
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02562455249925685
  mean_inference_ms: 1.2306601039213643
  mean_raw_obs_processing_ms: 0.27968609196600663
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019980192184448242
    StateBufferConnector_ms: 0.0035140514373779297
    ViewRequirementAgentConnector_ms: 0.12253522872924805
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.59
  episode_reward_min: 2.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 7.0, 7.0, 5.0, 9.0, 8.0, 9.0, 8.0, 6.0, 10.0, 10.0,
      3.0, 9.0, 6.0, 6.0, 5.0, 3.0, 9.0, 12.0, 8.0, 7.0, 2.0, 9.0, 9.0, 9.0, 13.0,
      14.0, 12.0, 4.0, 12.0, 8.0, 11.0, 10.0, 7.0, 8.0, 12.0, 7.0, 12.0, 11.0, 9.0,
      6.0, 3.0, 2.0, 11.0, 14.0, 13.0, 9.0, 10.0, 7.0, 7.0, 8.0, 8.0, 10.0, 5.0, 11.0,
      5.0, 9.0, 9.0, 8.0, 9.0, 6.0, 9.0, 12.0, 11.0, 8.0, 9.0, 8.0, 8.0, 12.0, 5.0,
      8.0, 12.0, 10.0, 10.0, 9.0, 8.0, 13.0, 7.0, 11.0, 5.0, 11.0, 14.0, 10.0, 8.0,
      6.0, 5.0, 7.0, 14.0, 8.0, 7.0, 9.0, 10.0, 10.0, 11.0, 12.0, 13.0, 8.0, 6.0,
      11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06572032459503942
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02562455249925685
    mean_inference_ms: 1.2306601039213643
    mean_raw_obs_processing_ms: 0.27968609196600663
time_since_restore: 2141.8867247104645
time_this_iter_s: 10.124815940856934
time_total_s: 2141.8867247104645
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.428
  training_iteration_time_ms: 1.863
timestamp: 1691996321
timesteps_total: 2572500
training_iteration: 211
trial_id: default
train step: 212
agent_timesteps_total: 2584950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020545482635498047
  StateBufferConnector_ms: 0.003606557846069336
  ViewRequirementAgentConnector_ms: 0.12409734725952148
counters:
  num_agent_steps_sampled: 2584950
  num_agent_steps_trained: 2568000
  num_env_steps_sampled: 2584950
  num_env_steps_trained: 2568000
  num_samples_added_to_queue: 2584500
  num_training_step_calls_since_last_synch_worker_weights: 289
  num_weight_broadcasts: 50825
custom_metrics: {}
date: 2023-08-14_15-58-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.85
episode_reward_min: 2.0
episodes_this_iter: 98
episodes_total: 20195
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6443712711334229
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.768874168395996
        total_loss: 39.547264099121094
        var_gnorm: 64.65508270263672
        vf_explained_var: 0.8905357718467712
        vf_loss: 78.00048828125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5136.0
  learner_queue:
    size_count: 5142
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 2584950
  num_agent_steps_trained: 2568000
  num_env_steps_sampled: 2584950
  num_env_steps_trained: 2568000
  num_samples_added_to_queue: 2584500
  num_training_step_calls_since_last_synch_worker_weights: 289
  num_weight_broadcasts: 50825
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 206.247
    learner_load_time_ms: 1.542
    learner_load_wait_time_ms: 1.543
iterations_since_restore: 212
node_ip: 127.0.0.1
num_agent_steps_sampled: 2584950
num_agent_steps_trained: 2568000
num_env_steps_sampled: 2584950
num_env_steps_sampled_this_iter: 12450
num_env_steps_sampled_throughput_per_sec: 1244.9980112345993
num_env_steps_trained: 2568000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.998083117686
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 52.09285714285714
  ram_util_percent: 82.06428571428572
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06571881762326576
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025624238183415658
  mean_inference_ms: 1.2305027536682187
  mean_raw_obs_processing_ms: 0.2796501867051009
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020545482635498047
    StateBufferConnector_ms: 0.003606557846069336
    ViewRequirementAgentConnector_ms: 0.12409734725952148
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.85
  episode_reward_min: 2.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 11.0, 7.0, 5.0, 7.0, 12.0, 10.0, 8.0, 8.0, 7.0, 9.0, 14.0,
      7.0, 4.0, 13.0, 7.0, 8.0, 8.0, 6.0, 9.0, 10.0, 4.0, 7.0, 6.0, 6.0, 7.0, 8.0,
      8.0, 13.0, 14.0, 11.0, 13.0, 5.0, 7.0, 13.0, 9.0, 7.0, 10.0, 10.0, 9.0, 5.0,
      12.0, 6.0, 6.0, 8.0, 9.0, 5.0, 11.0, 8.0, 10.0, 5.0, 8.0, 7.0, 7.0, 11.0, 13.0,
      11.0, 9.0, 10.0, 6.0, 14.0, 11.0, 11.0, 10.0, 7.0, 2.0, 13.0, 11.0, 14.0, 8.0,
      14.0, 11.0, 13.0, 8.0, 10.0, 15.0, 10.0, 8.0, 7.0, 6.0, 11.0, 10.0, 7.0, 11.0,
      3.0, 11.0, 10.0, 6.0, 10.0, 8.0, 6.0, 11.0, 8.0, 10.0, 8.0, 12.0, 5.0, 10.0,
      9.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06571881762326576
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025624238183415658
    mean_inference_ms: 1.2305027536682187
    mean_raw_obs_processing_ms: 0.2796501867051009
time_since_restore: 2152.0340185165405
time_this_iter_s: 10.14729380607605
time_total_s: 2152.0340185165405
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1691996331
timesteps_total: 2584950
training_iteration: 212
trial_id: default
train step: 213
agent_timesteps_total: 2596000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02542901039123535
  StateBufferConnector_ms: 0.004551887512207031
  ViewRequirementAgentConnector_ms: 0.1470794677734375
counters:
  num_agent_steps_sampled: 2596000
  num_agent_steps_trained: 2579500
  num_env_steps_sampled: 2596000
  num_env_steps_trained: 2579500
  num_samples_added_to_queue: 2596000
  num_training_step_calls_since_last_synch_worker_weights: 216
  num_weight_broadcasts: 51043
custom_metrics: {}
date: 2023-08-14_15-59-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.48
episode_reward_min: 5.0
episodes_this_iter: 87
episodes_total: 20282
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6401657462120056
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 22.457748413085938
        total_loss: 87.34846496582031
        var_gnorm: 64.6564712524414
        vf_explained_var: 0.8284373879432678
        vf_loss: 136.18309020996094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5159.0
  learner_queue:
    size_count: 5165
    size_mean: 14.94
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6175289796476602
  num_agent_steps_sampled: 2596000
  num_agent_steps_trained: 2579500
  num_env_steps_sampled: 2596000
  num_env_steps_trained: 2579500
  num_samples_added_to_queue: 2596000
  num_training_step_calls_since_last_synch_worker_weights: 216
  num_weight_broadcasts: 51043
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 192.959
    learner_load_time_ms: 1.545
    learner_load_wait_time_ms: 1.616
iterations_since_restore: 213
node_ip: 127.0.0.1
num_agent_steps_sampled: 2596000
num_agent_steps_trained: 2579500
num_env_steps_sampled: 2596000
num_env_steps_sampled_this_iter: 11050
num_env_steps_sampled_throughput_per_sec: 1104.996996649322
num_env_steps_trained: 2579500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9968743409233
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 57.586666666666666
  ram_util_percent: 82.64666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06576978511158309
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025638765346658453
  mean_inference_ms: 1.2308869838942171
  mean_raw_obs_processing_ms: 0.2797289622849656
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02542901039123535
    StateBufferConnector_ms: 0.004551887512207031
    ViewRequirementAgentConnector_ms: 0.1470794677734375
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.48
  episode_reward_min: 5.0
  episodes_this_iter: 87
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 10.0, 8.0, 6.0, 11.0, 8.0, 10.0, 8.0, 12.0, 5.0, 10.0, 9.0,
      6.0, 10.0, 6.0, 14.0, 11.0, 10.0, 9.0, 16.0, 8.0, 8.0, 12.0, 12.0, 7.0, 7.0,
      8.0, 5.0, 10.0, 9.0, 10.0, 14.0, 7.0, 7.0, 12.0, 8.0, 11.0, 14.0, 6.0, 12.0,
      10.0, 10.0, 10.0, 11.0, 5.0, 11.0, 11.0, 9.0, 8.0, 10.0, 10.0, 6.0, 8.0, 8.0,
      10.0, 10.0, 6.0, 9.0, 11.0, 8.0, 7.0, 11.0, 12.0, 11.0, 12.0, 8.0, 10.0, 14.0,
      12.0, 10.0, 9.0, 7.0, 12.0, 10.0, 9.0, 8.0, 7.0, 6.0, 9.0, 9.0, 9.0, 14.0, 13.0,
      14.0, 7.0, 11.0, 9.0, 8.0, 8.0, 6.0, 13.0, 13.0, 12.0, 12.0, 11.0, 8.0, 9.0,
      5.0, 11.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06576978511158309
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025638765346658453
    mean_inference_ms: 1.2308869838942171
    mean_raw_obs_processing_ms: 0.2797289622849656
time_since_restore: 2162.17472243309
time_this_iter_s: 10.140703916549683
time_total_s: 2162.17472243309
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691996342
timesteps_total: 2596000
training_iteration: 213
trial_id: default
train step: 214
agent_timesteps_total: 2607650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02342987060546875
  StateBufferConnector_ms: 0.004052877426147461
  ViewRequirementAgentConnector_ms: 0.1437537670135498
counters:
  num_agent_steps_sampled: 2607650
  num_agent_steps_trained: 2591000
  num_env_steps_sampled: 2607650
  num_env_steps_trained: 2591000
  num_samples_added_to_queue: 2607500
  num_training_step_calls_since_last_synch_worker_weights: 1060
  num_weight_broadcasts: 51273
custom_metrics: {}
date: 2023-08-14_15-59-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.13
episode_reward_min: 3.0
episodes_this_iter: 91
episodes_total: 20373
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.652272641658783
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 12.618696212768555
        total_loss: 64.30078887939453
        var_gnorm: 64.65908813476562
        vf_explained_var: 0.8615905046463013
        vf_loss: 109.88690948486328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5182.0
  learner_queue:
    size_count: 5187
    size_mean: 14.88
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6079800993793425
  num_agent_steps_sampled: 2607650
  num_agent_steps_trained: 2591000
  num_env_steps_sampled: 2607650
  num_env_steps_trained: 2591000
  num_samples_added_to_queue: 2607500
  num_training_step_calls_since_last_synch_worker_weights: 1060
  num_weight_broadcasts: 51273
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 235.399
    learner_load_time_ms: 1.764
    learner_load_wait_time_ms: 1.627
iterations_since_restore: 214
node_ip: 127.0.0.1
num_agent_steps_sampled: 2607650
num_agent_steps_trained: 2591000
num_env_steps_sampled: 2607650
num_env_steps_sampled_this_iter: 11650
num_env_steps_sampled_throughput_per_sec: 1164.9982223537868
num_env_steps_trained: 2591000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9982452419354
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 57.49285714285714
  ram_util_percent: 83.44285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06578035775769803
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025652145695125302
  mean_inference_ms: 1.2311803920724855
  mean_raw_obs_processing_ms: 0.27979653133102894
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02342987060546875
    StateBufferConnector_ms: 0.004052877426147461
    ViewRequirementAgentConnector_ms: 0.1437537670135498
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.13
  episode_reward_min: 3.0
  episodes_this_iter: 91
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 12.0, 12.0, 11.0, 8.0, 9.0, 5.0, 11.0, 9.0, 11.0, 11.0,
      9.0, 11.0, 9.0, 11.0, 12.0, 8.0, 7.0, 12.0, 10.0, 8.0, 13.0, 7.0, 8.0, 10.0,
      10.0, 15.0, 11.0, 8.0, 7.0, 11.0, 9.0, 9.0, 9.0, 8.0, 7.0, 8.0, 7.0, 7.0, 12.0,
      10.0, 11.0, 6.0, 11.0, 6.0, 10.0, 9.0, 13.0, 8.0, 8.0, 4.0, 6.0, 7.0, 11.0,
      9.0, 4.0, 11.0, 10.0, 10.0, 5.0, 12.0, 9.0, 8.0, 12.0, 11.0, 14.0, 9.0, 5.0,
      5.0, 9.0, 6.0, 11.0, 3.0, 14.0, 12.0, 7.0, 11.0, 10.0, 8.0, 14.0, 9.0, 9.0,
      9.0, 7.0, 9.0, 6.0, 10.0, 7.0, 7.0, 12.0, 9.0, 12.0, 11.0, 6.0, 7.0, 9.0, 12.0,
      4.0, 8.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06578035775769803
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025652145695125302
    mean_inference_ms: 1.2311803920724855
    mean_raw_obs_processing_ms: 0.27979653133102894
time_since_restore: 2172.286288499832
time_this_iter_s: 10.111566066741943
time_total_s: 2172.286288499832
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996352
timesteps_total: 2607650
training_iteration: 214
trial_id: default
train step: 215
agent_timesteps_total: 2619700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022179603576660156
  StateBufferConnector_ms: 0.004171848297119141
  ViewRequirementAgentConnector_ms: 0.13296890258789062
counters:
  num_agent_steps_sampled: 2619700
  num_agent_steps_trained: 2603000
  num_env_steps_sampled: 2619700
  num_env_steps_trained: 2603000
  num_samples_added_to_queue: 2619500
  num_training_step_calls_since_last_synch_worker_weights: 792
  num_weight_broadcasts: 51511
custom_metrics: {}
date: 2023-08-14_15-59-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.23
episode_reward_min: 4.0
episodes_this_iter: 94
episodes_total: 20467
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6297115087509155
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -34.45148849487305
        total_loss: 40.481475830078125
        var_gnorm: 64.65973663330078
        vf_explained_var: 0.8243332505226135
        vf_loss: 156.1630401611328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5206.0
  learner_queue:
    size_count: 5211
    size_mean: 15.08
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4675149062275312
  num_agent_steps_sampled: 2619700
  num_agent_steps_trained: 2603000
  num_env_steps_sampled: 2619700
  num_env_steps_trained: 2603000
  num_samples_added_to_queue: 2619500
  num_training_step_calls_since_last_synch_worker_weights: 792
  num_weight_broadcasts: 51511
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 238.111
    learner_load_time_ms: 1.77
    learner_load_wait_time_ms: 1.703
iterations_since_restore: 215
node_ip: 127.0.0.1
num_agent_steps_sampled: 2619700
num_agent_steps_trained: 2603000
num_env_steps_sampled: 2619700
num_env_steps_sampled_this_iter: 12050
num_env_steps_sampled_throughput_per_sec: 1204.994685077268
num_env_steps_trained: 2603000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9947071308895
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 51.40714285714286
  ram_util_percent: 82.19285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06576919451403102
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02566137763860648
  mean_inference_ms: 1.2313009564951485
  mean_raw_obs_processing_ms: 0.27981176337022634
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022179603576660156
    StateBufferConnector_ms: 0.004171848297119141
    ViewRequirementAgentConnector_ms: 0.13296890258789062
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.23
  episode_reward_min: 4.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 9.0, 12.0, 4.0, 8.0, 6.0, 9.0, 13.0, 8.0, 7.0, 7.0, 11.0,
      7.0, 11.0, 12.0, 9.0, 13.0, 9.0, 7.0, 10.0, 11.0, 9.0, 14.0, 6.0, 13.0, 9.0,
      9.0, 9.0, 6.0, 13.0, 5.0, 5.0, 12.0, 9.0, 6.0, 14.0, 8.0, 11.0, 9.0, 5.0, 12.0,
      12.0, 9.0, 7.0, 13.0, 9.0, 11.0, 7.0, 11.0, 9.0, 15.0, 16.0, 5.0, 12.0, 15.0,
      10.0, 7.0, 13.0, 8.0, 12.0, 7.0, 10.0, 11.0, 7.0, 5.0, 10.0, 7.0, 10.0, 6.0,
      12.0, 7.0, 8.0, 11.0, 15.0, 5.0, 12.0, 11.0, 6.0, 11.0, 12.0, 8.0, 7.0, 7.0,
      7.0, 9.0, 6.0, 6.0, 7.0, 9.0, 5.0, 10.0, 13.0, 6.0, 9.0, 14.0, 8.0, 8.0, 10.0,
      7.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06576919451403102
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02566137763860648
    mean_inference_ms: 1.2313009564951485
    mean_raw_obs_processing_ms: 0.27981176337022634
time_since_restore: 2182.4110102653503
time_this_iter_s: 10.124721765518188
time_total_s: 2182.4110102653503
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996362
timesteps_total: 2619700
training_iteration: 215
trial_id: default
train step: 216
agent_timesteps_total: 2632600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02009963045025816
  StateBufferConnector_ms: 0.0036282114463277383
  ViewRequirementAgentConnector_ms: 0.12228418104719407
counters:
  num_agent_steps_sampled: 2632600
  num_agent_steps_trained: 2616000
  num_env_steps_sampled: 2632600
  num_env_steps_trained: 2616000
  num_samples_added_to_queue: 2632500
  num_training_step_calls_since_last_synch_worker_weights: 828
  num_weight_broadcasts: 51766
custom_metrics: {}
date: 2023-08-14_15-59-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.702970297029703
episode_reward_min: 2.0
episodes_this_iter: 101
episodes_total: 20568
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6143067479133606
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 24.484432220458984
        total_loss: 109.64106750488281
        var_gnorm: 64.65813446044922
        vf_explained_var: 0.7995104789733887
        vf_loss: 176.45632934570312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5232.0
  learner_queue:
    size_count: 5237
    size_mean: 15.4
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.1489125293076057
  num_agent_steps_sampled: 2632600
  num_agent_steps_trained: 2616000
  num_env_steps_sampled: 2632600
  num_env_steps_trained: 2616000
  num_samples_added_to_queue: 2632500
  num_training_step_calls_since_last_synch_worker_weights: 828
  num_weight_broadcasts: 51766
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 207.056
    learner_load_time_ms: 1.775
    learner_load_wait_time_ms: 1.473
iterations_since_restore: 216
node_ip: 127.0.0.1
num_agent_steps_sampled: 2632600
num_agent_steps_trained: 2616000
num_env_steps_sampled: 2632600
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9995079042405
num_env_steps_trained: 2616000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9995040895446
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.95333333333334
  ram_util_percent: 81.23333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06573974842751824
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02565620757608178
  mean_inference_ms: 1.2309648980796384
  mean_raw_obs_processing_ms: 0.27974556281415586
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02009963045025816
    StateBufferConnector_ms: 0.0036282114463277383
    ViewRequirementAgentConnector_ms: 0.12228418104719407
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.702970297029703
  episode_reward_min: 2.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 2.0, 15.0, 12.0, 8.0, 15.0, 9.0, 10.0, 12.0, 9.0, 12.0,
      13.0, 7.0, 16.0, 7.0, 7.0, 13.0, 10.0, 7.0, 5.0, 6.0, 14.0, 7.0, 10.0, 7.0,
      12.0, 9.0, 8.0, 8.0, 8.0, 8.0, 9.0, 11.0, 8.0, 13.0, 7.0, 6.0, 8.0, 11.0, 11.0,
      9.0, 15.0, 6.0, 9.0, 14.0, 10.0, 11.0, 11.0, 9.0, 9.0, 11.0, 11.0, 10.0, 12.0,
      13.0, 15.0, 11.0, 10.0, 10.0, 13.0, 7.0, 11.0, 13.0, 7.0, 11.0, 7.0, 13.0, 7.0,
      12.0, 7.0, 7.0, 7.0, 6.0, 9.0, 15.0, 7.0, 11.0, 11.0, 10.0, 11.0, 12.0, 8.0,
      9.0, 11.0, 7.0, 7.0, 10.0, 12.0, 7.0, 11.0, 10.0, 9.0, 6.0, 12.0, 10.0, 11.0,
      14.0, 7.0, 7.0, 5.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06573974842751824
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02565620757608178
    mean_inference_ms: 1.2309648980796384
    mean_raw_obs_processing_ms: 0.27974556281415586
time_since_restore: 2192.5220251083374
time_this_iter_s: 10.11101484298706
time_total_s: 2192.5220251083374
timers:
  sample_time_ms: 0.018
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.051
timestamp: 1691996372
timesteps_total: 2632600
training_iteration: 216
trial_id: default
train step: 217
agent_timesteps_total: 2643700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023009777069091797
  StateBufferConnector_ms: 0.004163265228271484
  ViewRequirementAgentConnector_ms: 0.13744330406188965
counters:
  num_agent_steps_sampled: 2643700
  num_agent_steps_trained: 2627000
  num_env_steps_sampled: 2643700
  num_env_steps_trained: 2627000
  num_samples_added_to_queue: 2643500
  num_training_step_calls_since_last_synch_worker_weights: 1687
  num_weight_broadcasts: 51984
custom_metrics: {}
date: 2023-08-14_15-59-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.62
episode_reward_min: 2.0
episodes_this_iter: 86
episodes_total: 20654
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.614084780216217
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -21.27347183227539
        total_loss: 68.44371795654297
        var_gnorm: 64.6616439819336
        vf_explained_var: 0.8251988887786865
        vf_loss: 185.57522583007812
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5254.0
  learner_queue:
    size_count: 5258
    size_mean: 15.28
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.217209924376235
  num_agent_steps_sampled: 2643700
  num_agent_steps_trained: 2627000
  num_env_steps_sampled: 2643700
  num_env_steps_trained: 2627000
  num_samples_added_to_queue: 2643500
  num_training_step_calls_since_last_synch_worker_weights: 1687
  num_weight_broadcasts: 51984
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 305.658
    learner_load_time_ms: 1.777
    learner_load_wait_time_ms: 1.737
iterations_since_restore: 217
node_ip: 127.0.0.1
num_agent_steps_sampled: 2643700
num_agent_steps_trained: 2627000
num_env_steps_sampled: 2643700
num_env_steps_sampled_this_iter: 11100
num_env_steps_sampled_throughput_per_sec: 1109.998438598922
num_env_steps_trained: 2627000
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9984526655983
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 56.72142857142857
  ram_util_percent: 81.78571428571426
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06579348223841103
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025668123748739856
  mean_inference_ms: 1.231304668267992
  mean_raw_obs_processing_ms: 0.2797988987726155
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023009777069091797
    StateBufferConnector_ms: 0.004163265228271484
    ViewRequirementAgentConnector_ms: 0.13744330406188965
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.62
  episode_reward_min: 2.0
  episodes_this_iter: 86
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 7.0, 11.0, 10.0, 9.0, 6.0, 12.0, 10.0, 11.0, 14.0, 7.0,
      7.0, 5.0, 11.0, 9.0, 12.0, 9.0, 9.0, 7.0, 8.0, 10.0, 11.0, 12.0, 8.0, 9.0, 15.0,
      10.0, 10.0, 13.0, 7.0, 7.0, 11.0, 9.0, 12.0, 13.0, 9.0, 11.0, 12.0, 11.0, 9.0,
      7.0, 13.0, 8.0, 10.0, 10.0, 10.0, 13.0, 8.0, 11.0, 8.0, 7.0, 10.0, 12.0, 9.0,
      12.0, 15.0, 9.0, 5.0, 10.0, 8.0, 11.0, 6.0, 13.0, 9.0, 10.0, 13.0, 15.0, 10.0,
      9.0, 9.0, 9.0, 7.0, 9.0, 15.0, 5.0, 15.0, 6.0, 5.0, 10.0, 14.0, 7.0, 2.0, 10.0,
      11.0, 4.0, 12.0, 12.0, 7.0, 4.0, 8.0, 7.0, 10.0, 8.0, 8.0, 9.0, 13.0, 8.0, 13.0,
      6.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06579348223841103
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025668123748739856
    mean_inference_ms: 1.231304668267992
    mean_raw_obs_processing_ms: 0.2797988987726155
time_since_restore: 2202.6218481063843
time_this_iter_s: 10.099822998046875
time_total_s: 2202.6218481063843
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.047
timestamp: 1691996382
timesteps_total: 2643700
training_iteration: 217
trial_id: default
train step: 218
agent_timesteps_total: 2656000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021910667419433594
  StateBufferConnector_ms: 0.004109859466552734
  ViewRequirementAgentConnector_ms: 0.13155293464660645
counters:
  num_agent_steps_sampled: 2656000
  num_agent_steps_trained: 2639500
  num_env_steps_sampled: 2656000
  num_env_steps_trained: 2639500
  num_samples_added_to_queue: 2656000
  num_training_step_calls_since_last_synch_worker_weights: 1677
  num_weight_broadcasts: 52225
custom_metrics: {}
date: 2023-08-14_15-59-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.35
episode_reward_min: 4.0
episodes_this_iter: 96
episodes_total: 20750
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6164957880973816
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -70.5130615234375
        total_loss: 3.59924578666687
        var_gnorm: 64.6610336303711
        vf_explained_var: 0.8072662353515625
        vf_loss: 154.3895721435547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5279.0
  learner_queue:
    size_count: 5283
    size_mean: 15.42
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.0787029248129438
  num_agent_steps_sampled: 2656000
  num_agent_steps_trained: 2639500
  num_env_steps_sampled: 2656000
  num_env_steps_trained: 2639500
  num_samples_added_to_queue: 2656000
  num_training_step_calls_since_last_synch_worker_weights: 1677
  num_weight_broadcasts: 52225
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 269.281
    learner_load_time_ms: 1.601
    learner_load_wait_time_ms: 2.237
iterations_since_restore: 218
node_ip: 127.0.0.1
num_agent_steps_sampled: 2656000
num_agent_steps_trained: 2639500
num_env_steps_sampled: 2656000
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.9985337274863
num_env_steps_trained: 2639500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9985098856569
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.385714285714286
  ram_util_percent: 80.13571428571427
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06576829685076849
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025676638575031014
  mean_inference_ms: 1.2313783836284131
  mean_raw_obs_processing_ms: 0.27981669047680613
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021910667419433594
    StateBufferConnector_ms: 0.004109859466552734
    ViewRequirementAgentConnector_ms: 0.13155293464660645
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.35
  episode_reward_min: 4.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 13.0, 6.0, 13.0, 10.0, 10.0, 15.0, 4.0, 12.0, 8.0, 10.0,
      9.0, 10.0, 10.0, 11.0, 8.0, 7.0, 11.0, 8.0, 8.0, 7.0, 7.0, 7.0, 9.0, 6.0, 11.0,
      4.0, 13.0, 10.0, 8.0, 8.0, 8.0, 6.0, 7.0, 6.0, 11.0, 15.0, 11.0, 8.0, 10.0,
      10.0, 13.0, 5.0, 7.0, 6.0, 5.0, 8.0, 11.0, 14.0, 8.0, 11.0, 10.0, 11.0, 6.0,
      9.0, 13.0, 5.0, 16.0, 7.0, 8.0, 11.0, 14.0, 9.0, 15.0, 10.0, 8.0, 9.0, 11.0,
      6.0, 7.0, 6.0, 13.0, 10.0, 9.0, 8.0, 13.0, 9.0, 11.0, 12.0, 11.0, 6.0, 10.0,
      11.0, 8.0, 14.0, 17.0, 4.0, 7.0, 13.0, 4.0, 13.0, 10.0, 11.0, 9.0, 5.0, 7.0,
      10.0, 9.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06576829685076849
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025676638575031014
    mean_inference_ms: 1.2313783836284131
    mean_raw_obs_processing_ms: 0.27981669047680613
time_since_restore: 2212.758762359619
time_this_iter_s: 10.136914253234863
time_total_s: 2212.758762359619
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.061
timestamp: 1691996392
timesteps_total: 2656000
training_iteration: 218
trial_id: default
train step: 219
agent_timesteps_total: 2668100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021672725677490234
  StateBufferConnector_ms: 0.0042781829833984375
  ViewRequirementAgentConnector_ms: 0.13582921028137207
counters:
  num_agent_steps_sampled: 2668100
  num_agent_steps_trained: 2651500
  num_env_steps_sampled: 2668100
  num_env_steps_trained: 2651500
  num_samples_added_to_queue: 2668000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 52464
custom_metrics: {}
date: 2023-08-14_16-00-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.71
episode_reward_min: 4.0
episodes_this_iter: 95
episodes_total: 20845
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6167464256286621
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -64.60700225830078
        total_loss: 19.678131103515625
        var_gnorm: 64.66084289550781
        vf_explained_var: 0.8078591227531433
        vf_loss: 174.73773193359375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5303.0
  learner_queue:
    size_count: 5310
    size_mean: 15.42
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3577923257994944
  num_agent_steps_sampled: 2668100
  num_agent_steps_trained: 2651500
  num_env_steps_sampled: 2668100
  num_env_steps_trained: 2651500
  num_samples_added_to_queue: 2668000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 52464
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 152.439
    learner_load_time_ms: 1.624
    learner_load_wait_time_ms: 1.596
iterations_since_restore: 219
node_ip: 127.0.0.1
num_agent_steps_sampled: 2668100
num_agent_steps_trained: 2651500
num_env_steps_sampled: 2668100
num_env_steps_sampled_this_iter: 12100
num_env_steps_sampled_throughput_per_sec: 1209.7792038963837
num_env_steps_trained: 2651500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.7810286575705
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 57.74
  ram_util_percent: 80.87333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0657718016157697
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02568092955179127
  mean_inference_ms: 1.2314306270932454
  mean_raw_obs_processing_ms: 0.2798204457690569
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021672725677490234
    StateBufferConnector_ms: 0.0042781829833984375
    ViewRequirementAgentConnector_ms: 0.13582921028137207
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.71
  episode_reward_min: 4.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 10.0, 9.0, 9.0, 10.0, 6.0, 7.0, 6.0, 9.0, 15.0, 14.0, 13.0,
      12.0, 10.0, 7.0, 9.0, 11.0, 6.0, 9.0, 11.0, 14.0, 13.0, 7.0, 8.0, 10.0, 9.0,
      6.0, 10.0, 8.0, 8.0, 11.0, 15.0, 9.0, 11.0, 9.0, 9.0, 8.0, 13.0, 5.0, 8.0, 10.0,
      6.0, 7.0, 11.0, 11.0, 10.0, 10.0, 8.0, 8.0, 7.0, 9.0, 10.0, 10.0, 8.0, 4.0,
      8.0, 8.0, 12.0, 10.0, 9.0, 8.0, 9.0, 14.0, 13.0, 12.0, 13.0, 16.0, 10.0, 13.0,
      13.0, 4.0, 8.0, 12.0, 11.0, 9.0, 12.0, 9.0, 10.0, 12.0, 9.0, 7.0, 10.0, 13.0,
      10.0, 10.0, 9.0, 12.0, 6.0, 13.0, 16.0, 7.0, 8.0, 9.0, 8.0, 11.0, 13.0, 9.0,
      9.0, 5.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0657718016157697
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02568092955179127
    mean_inference_ms: 1.2314306270932454
    mean_raw_obs_processing_ms: 0.2798204457690569
time_since_restore: 2222.921203136444
time_this_iter_s: 10.162440776824951
time_total_s: 2222.921203136444
timers:
  sample_time_ms: 0.274
  synch_weights_time_ms: 0.463
  training_iteration_time_ms: 0.845
timestamp: 1691996402
timesteps_total: 2668100
training_iteration: 219
trial_id: default
train step: 220
agent_timesteps_total: 2679650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023016929626464844
  StateBufferConnector_ms: 0.004547834396362305
  ViewRequirementAgentConnector_ms: 0.13952350616455078
counters:
  num_agent_steps_sampled: 2679650
  num_agent_steps_trained: 2663000
  num_env_steps_sampled: 2679650
  num_env_steps_trained: 2663000
  num_samples_added_to_queue: 2679500
  num_training_step_calls_since_last_synch_worker_weights: 1020
  num_weight_broadcasts: 52693
custom_metrics: {}
date: 2023-08-14_16-00-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 20.0
episode_reward_mean: 9.98
episode_reward_min: 5.0
episodes_this_iter: 90
episodes_total: 20935
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6003589034080505
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -18.237640380859375
        total_loss: 122.58509063720703
        var_gnorm: 64.6575927734375
        vf_explained_var: 0.666677713394165
        vf_loss: 287.6490478515625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5326.0
  learner_queue:
    size_count: 5330
    size_mean: 15.02
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.6551737068960464
  num_agent_steps_sampled: 2679650
  num_agent_steps_trained: 2663000
  num_env_steps_sampled: 2679650
  num_env_steps_trained: 2663000
  num_samples_added_to_queue: 2679500
  num_training_step_calls_since_last_synch_worker_weights: 1020
  num_weight_broadcasts: 52693
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 271.093
    learner_load_time_ms: 9.93
    learner_load_wait_time_ms: 1.706
iterations_since_restore: 220
node_ip: 127.0.0.1
num_agent_steps_sampled: 2679650
num_agent_steps_trained: 2663000
num_env_steps_sampled: 2679650
num_env_steps_sampled_this_iter: 11550
num_env_steps_sampled_throughput_per_sec: 1154.995952024342
num_env_steps_trained: 2663000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.995969548046
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 57.08571428571428
  ram_util_percent: 82.30714285714285
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06580447991476537
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025689235217588216
  mean_inference_ms: 1.2316200779860313
  mean_raw_obs_processing_ms: 0.2798642897429217
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023016929626464844
    StateBufferConnector_ms: 0.004547834396362305
    ViewRequirementAgentConnector_ms: 0.13952350616455078
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 20.0
  episode_reward_mean: 9.98
  episode_reward_min: 5.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 8.0, 9.0, 8.0, 11.0, 13.0, 9.0, 9.0, 5.0, 12.0, 10.0, 6.0,
      11.0, 7.0, 14.0, 7.0, 11.0, 10.0, 13.0, 12.0, 12.0, 11.0, 11.0, 13.0, 8.0, 14.0,
      10.0, 15.0, 6.0, 5.0, 5.0, 8.0, 9.0, 10.0, 12.0, 9.0, 11.0, 8.0, 9.0, 10.0,
      9.0, 8.0, 8.0, 14.0, 6.0, 14.0, 11.0, 12.0, 11.0, 10.0, 11.0, 12.0, 16.0, 5.0,
      12.0, 13.0, 20.0, 12.0, 13.0, 9.0, 11.0, 12.0, 8.0, 13.0, 8.0, 8.0, 12.0, 7.0,
      11.0, 10.0, 8.0, 11.0, 8.0, 7.0, 7.0, 14.0, 7.0, 7.0, 7.0, 9.0, 8.0, 12.0, 6.0,
      14.0, 7.0, 9.0, 8.0, 12.0, 9.0, 10.0, 9.0, 13.0, 10.0, 9.0, 12.0, 10.0, 10.0,
      14.0, 8.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06580447991476537
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025689235217588216
    mean_inference_ms: 1.2316200779860313
    mean_raw_obs_processing_ms: 0.2798642897429217
time_since_restore: 2233.0434861183167
time_this_iter_s: 10.122282981872559
time_total_s: 2233.0434861183167
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691996413
timesteps_total: 2679650
training_iteration: 220
trial_id: default
train step: 221
agent_timesteps_total: 2691350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022352218627929688
  StateBufferConnector_ms: 0.00405573844909668
  ViewRequirementAgentConnector_ms: 0.13435578346252441
counters:
  num_agent_steps_sampled: 2691350
  num_agent_steps_trained: 2674500
  num_env_steps_sampled: 2691350
  num_env_steps_trained: 2674500
  num_samples_added_to_queue: 2691000
  num_training_step_calls_since_last_synch_worker_weights: 1455
  num_weight_broadcasts: 52923
custom_metrics: {}
date: 2023-08-14_16-00-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.59
episode_reward_min: 3.0
episodes_this_iter: 92
episodes_total: 21027
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6058933734893799
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -45.53561019897461
        total_loss: 23.334474563598633
        var_gnorm: 64.66319274902344
        vf_explained_var: 0.8256770372390747
        vf_loss: 143.79910278320312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5349.0
  learner_queue:
    size_count: 5353
    size_mean: 14.9
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.711724276862369
  num_agent_steps_sampled: 2691350
  num_agent_steps_trained: 2674500
  num_env_steps_sampled: 2691350
  num_env_steps_trained: 2674500
  num_samples_added_to_queue: 2691000
  num_training_step_calls_since_last_synch_worker_weights: 1455
  num_weight_broadcasts: 52923
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 321.727
    learner_load_time_ms: 9.94
    learner_load_wait_time_ms: 1.578
iterations_since_restore: 221
node_ip: 127.0.0.1
num_agent_steps_sampled: 2691350
num_agent_steps_trained: 2674500
num_env_steps_sampled: 2691350
num_env_steps_sampled_this_iter: 11700
num_env_steps_sampled_throughput_per_sec: 1169.9929984034873
num_env_steps_trained: 2674500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9931180888977
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 56.33571428571428
  ram_util_percent: 82.8
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06581826389447945
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025701714599951825
  mean_inference_ms: 1.2318147768132142
  mean_raw_obs_processing_ms: 0.27991866544095567
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022352218627929688
    StateBufferConnector_ms: 0.00405573844909668
    ViewRequirementAgentConnector_ms: 0.13435578346252441
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.59
  episode_reward_min: 3.0
  episodes_this_iter: 92
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 9.0, 12.0, 10.0, 10.0, 14.0, 8.0, 9.0, 10.0, 12.0, 10.0,
      9.0, 9.0, 6.0, 13.0, 6.0, 14.0, 10.0, 10.0, 13.0, 13.0, 6.0, 5.0, 10.0, 10.0,
      14.0, 13.0, 8.0, 11.0, 7.0, 8.0, 5.0, 8.0, 6.0, 10.0, 10.0, 6.0, 8.0, 12.0,
      9.0, 7.0, 9.0, 8.0, 13.0, 7.0, 9.0, 3.0, 9.0, 7.0, 11.0, 9.0, 10.0, 8.0, 7.0,
      12.0, 11.0, 10.0, 10.0, 9.0, 12.0, 11.0, 11.0, 12.0, 9.0, 12.0, 8.0, 13.0, 12.0,
      8.0, 9.0, 12.0, 13.0, 11.0, 7.0, 11.0, 10.0, 9.0, 8.0, 9.0, 9.0, 11.0, 8.0,
      10.0, 11.0, 10.0, 10.0, 6.0, 8.0, 10.0, 8.0, 7.0, 8.0, 6.0, 9.0, 14.0, 10.0,
      12.0, 12.0, 15.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06581826389447945
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025701714599951825
    mean_inference_ms: 1.2318147768132142
    mean_raw_obs_processing_ms: 0.27991866544095567
time_since_restore: 2243.141534090042
time_this_iter_s: 10.098047971725464
time_total_s: 2243.141534090042
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691996423
timesteps_total: 2691350
training_iteration: 221
trial_id: default
train step: 222
agent_timesteps_total: 2702150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02466440200805664
  StateBufferConnector_ms: 0.004497051239013672
  ViewRequirementAgentConnector_ms: 0.14397215843200684
counters:
  num_agent_steps_sampled: 2702150
  num_agent_steps_trained: 2685500
  num_env_steps_sampled: 2702150
  num_env_steps_trained: 2685500
  num_samples_added_to_queue: 2702000
  num_training_step_calls_since_last_synch_worker_weights: 88
  num_weight_broadcasts: 53136
custom_metrics: {}
date: 2023-08-14_16-00-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.7
episode_reward_min: 5.0
episodes_this_iter: 84
episodes_total: 21111
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.607637345790863
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -66.69395446777344
        total_loss: -1.430650234222412
        var_gnorm: 64.66606903076172
        vf_explained_var: 0.859618604183197
        vf_loss: 136.6029815673828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5371.0
  learner_queue:
    size_count: 5378
    size_mean: 15.18
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4925146565444507
  num_agent_steps_sampled: 2702150
  num_agent_steps_trained: 2685500
  num_env_steps_sampled: 2702150
  num_env_steps_trained: 2685500
  num_samples_added_to_queue: 2702000
  num_training_step_calls_since_last_synch_worker_weights: 88
  num_weight_broadcasts: 53136
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 150.419
    learner_load_time_ms: 9.97
    learner_load_wait_time_ms: 1.617
iterations_since_restore: 222
node_ip: 127.0.0.1
num_agent_steps_sampled: 2702150
num_agent_steps_trained: 2685500
num_env_steps_sampled: 2702150
num_env_steps_sampled_this_iter: 10800
num_env_steps_sampled_throughput_per_sec: 1079.9950046770357
num_env_steps_trained: 2685500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.994912171055
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 61.1
  ram_util_percent: 83.35333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06586994707275733
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025719106432167006
  mean_inference_ms: 1.2323102350463666
  mean_raw_obs_processing_ms: 0.28002201073130123
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02466440200805664
    StateBufferConnector_ms: 0.004497051239013672
    ViewRequirementAgentConnector_ms: 0.14397215843200684
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.7
  episode_reward_min: 5.0
  episodes_this_iter: 84
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 10.0, 6.0, 8.0, 10.0, 8.0, 7.0, 8.0, 6.0, 9.0, 14.0, 10.0,
      12.0, 12.0, 15.0, 6.0, 11.0, 5.0, 10.0, 11.0, 11.0, 9.0, 12.0, 10.0, 7.0, 7.0,
      11.0, 11.0, 9.0, 9.0, 8.0, 13.0, 10.0, 10.0, 5.0, 11.0, 9.0, 13.0, 13.0, 18.0,
      10.0, 7.0, 10.0, 12.0, 6.0, 10.0, 5.0, 11.0, 8.0, 13.0, 6.0, 8.0, 10.0, 10.0,
      9.0, 8.0, 8.0, 5.0, 9.0, 12.0, 10.0, 5.0, 6.0, 10.0, 9.0, 9.0, 7.0, 6.0, 13.0,
      8.0, 6.0, 14.0, 11.0, 12.0, 14.0, 10.0, 7.0, 16.0, 12.0, 9.0, 8.0, 12.0, 10.0,
      11.0, 14.0, 9.0, 10.0, 9.0, 5.0, 11.0, 13.0, 8.0, 13.0, 11.0, 10.0, 9.0, 10.0,
      10.0, 13.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06586994707275733
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025719106432167006
    mean_inference_ms: 1.2323102350463666
    mean_raw_obs_processing_ms: 0.28002201073130123
time_since_restore: 2253.309370279312
time_this_iter_s: 10.16783618927002
time_total_s: 2253.309370279312
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996433
timesteps_total: 2702150
training_iteration: 222
trial_id: default
train step: 223
agent_timesteps_total: 2715850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018881860180435892
  StateBufferConnector_ms: 0.0033710604516145226
  ViewRequirementAgentConnector_ms: 0.11492443976001204
counters:
  num_agent_steps_sampled: 2715850
  num_agent_steps_trained: 2699000
  num_env_steps_sampled: 2715850
  num_env_steps_trained: 2699000
  num_samples_added_to_queue: 2715500
  num_training_step_calls_since_last_synch_worker_weights: 1531
  num_weight_broadcasts: 53405
custom_metrics: {}
date: 2023-08-14_16-00-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.728971962616823
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 21218
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6032828092575073
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -12.123184204101562
        total_loss: 28.264972686767578
        var_gnorm: 64.66392517089844
        vf_explained_var: 0.8902095556259155
        vf_loss: 86.80914306640625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5398.0
  learner_queue:
    size_count: 5403
    size_mean: 15.16
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5793669617919708
  num_agent_steps_sampled: 2715850
  num_agent_steps_trained: 2699000
  num_env_steps_sampled: 2715850
  num_env_steps_trained: 2699000
  num_samples_added_to_queue: 2715500
  num_training_step_calls_since_last_synch_worker_weights: 1531
  num_weight_broadcasts: 53405
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 223.634
    learner_load_time_ms: 9.977
    learner_load_wait_time_ms: 1.639
iterations_since_restore: 223
node_ip: 127.0.0.1
num_agent_steps_sampled: 2715850
num_agent_steps_trained: 2699000
num_env_steps_sampled: 2715850
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9951005157213
num_env_steps_trained: 2699000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9951720410393
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.957142857142856
  ram_util_percent: 82.24285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06579749679524205
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025710576001165938
  mean_inference_ms: 1.2318200423659442
  mean_raw_obs_processing_ms: 0.2799057598655494
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018881860180435892
    StateBufferConnector_ms: 0.0033710604516145226
    ViewRequirementAgentConnector_ms: 0.11492443976001204
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.728971962616823
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 6.0, 11.0, 12.0, 8.0, 11.0, 7.0, 10.0, 10.0, 10.0, 6.0,
      5.0, 10.0, 8.0, 12.0, 11.0, 10.0, 8.0, 7.0, 9.0, 11.0, 11.0, 8.0, 9.0, 12.0,
      12.0, 10.0, 11.0, 8.0, 8.0, 14.0, 9.0, 10.0, 11.0, 11.0, 5.0, 6.0, 12.0, 14.0,
      14.0, 12.0, 7.0, 12.0, 13.0, 10.0, 15.0, 11.0, 9.0, 10.0, 7.0, 3.0, 7.0, 13.0,
      14.0, 6.0, 14.0, 9.0, 9.0, 11.0, 10.0, 9.0, 13.0, 11.0, 10.0, 8.0, 11.0, 8.0,
      10.0, 8.0, 10.0, 8.0, 9.0, 13.0, 8.0, 9.0, 8.0, 13.0, 9.0, 9.0, 13.0, 8.0, 11.0,
      9.0, 8.0, 11.0, 7.0, 4.0, 11.0, 17.0, 13.0, 9.0, 9.0, 9.0, 8.0, 9.0, 15.0, 8.0,
      13.0, 7.0, 8.0, 12.0, 6.0, 10.0, 10.0, 7.0, 8.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06579749679524205
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025710576001165938
    mean_inference_ms: 1.2318200423659442
    mean_raw_obs_processing_ms: 0.2799057598655494
time_since_restore: 2263.4394612312317
time_this_iter_s: 10.130090951919556
time_total_s: 2263.4394612312317
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996443
timesteps_total: 2715850
training_iteration: 223
trial_id: default
train step: 224
agent_timesteps_total: 2729250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019274212065197173
  StateBufferConnector_ms: 0.0034125645955403647
  ViewRequirementAgentConnector_ms: 0.11696384066627138
counters:
  num_agent_steps_sampled: 2729250
  num_agent_steps_trained: 2712500
  num_env_steps_sampled: 2729250
  num_env_steps_trained: 2712500
  num_samples_added_to_queue: 2729000
  num_training_step_calls_since_last_synch_worker_weights: 304
  num_weight_broadcasts: 53667
custom_metrics: {}
date: 2023-08-14_16-00-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 9.752380952380953
episode_reward_min: 3.0
episodes_this_iter: 105
episodes_total: 21323
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5613811016082764
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 24.484960556030273
        total_loss: 57.1687126159668
        var_gnorm: 64.66780853271484
        vf_explained_var: 0.9238693118095398
        vf_loss: 70.98131561279297
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5425.0
  learner_queue:
    size_count: 5432
    size_mean: 15.24
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5041276541570532
  num_agent_steps_sampled: 2729250
  num_agent_steps_trained: 2712500
  num_env_steps_sampled: 2729250
  num_env_steps_trained: 2712500
  num_samples_added_to_queue: 2729000
  num_training_step_calls_since_last_synch_worker_weights: 304
  num_weight_broadcasts: 53667
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 159.913
    learner_load_time_ms: 9.994
    learner_load_wait_time_ms: 1.66
iterations_since_restore: 224
node_ip: 127.0.0.1
num_agent_steps_sampled: 2729250
num_agent_steps_trained: 2712500
num_env_steps_sampled: 2729250
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9930353526663
num_env_steps_trained: 2712500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9929833776862
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.44285714285714
  ram_util_percent: 81.72142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06576343794118643
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02569895188512962
  mean_inference_ms: 1.231300219884794
  mean_raw_obs_processing_ms: 0.27979322782228055
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019274212065197173
    StateBufferConnector_ms: 0.0034125645955403647
    ViewRequirementAgentConnector_ms: 0.11696384066627138
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 9.752380952380953
  episode_reward_min: 3.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 7.0, 6.0, 10.0, 11.0, 12.0, 7.0, 8.0, 10.0, 10.0, 13.0,
      10.0, 11.0, 7.0, 11.0, 8.0, 12.0, 7.0, 8.0, 9.0, 11.0, 10.0, 10.0, 11.0, 12.0,
      13.0, 7.0, 14.0, 7.0, 12.0, 9.0, 14.0, 13.0, 16.0, 7.0, 9.0, 9.0, 12.0, 12.0,
      10.0, 13.0, 6.0, 6.0, 12.0, 9.0, 6.0, 7.0, 12.0, 19.0, 12.0, 8.0, 8.0, 9.0,
      9.0, 11.0, 6.0, 13.0, 10.0, 10.0, 7.0, 10.0, 12.0, 6.0, 10.0, 3.0, 12.0, 8.0,
      7.0, 11.0, 11.0, 6.0, 12.0, 9.0, 14.0, 6.0, 5.0, 8.0, 10.0, 13.0, 9.0, 13.0,
      7.0, 10.0, 13.0, 6.0, 11.0, 14.0, 4.0, 8.0, 6.0, 12.0, 9.0, 8.0, 9.0, 9.0, 10.0,
      11.0, 9.0, 10.0, 8.0, 6.0, 14.0, 9.0, 12.0, 14.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06576343794118643
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02569895188512962
    mean_inference_ms: 1.231300219884794
    mean_raw_obs_processing_ms: 0.27979322782228055
time_since_restore: 2273.6212520599365
time_this_iter_s: 10.181790828704834
time_total_s: 2273.6212520599365
timers:
  sample_time_ms: 0.018
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.052
timestamp: 1691996453
timesteps_total: 2729250
training_iteration: 224
trial_id: default
train step: 225
agent_timesteps_total: 2742350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01983502331901999
  StateBufferConnector_ms: 0.003555475496778301
  ViewRequirementAgentConnector_ms: 0.11950076795091816
counters:
  num_agent_steps_sampled: 2742350
  num_agent_steps_trained: 2725500
  num_env_steps_sampled: 2742350
  num_env_steps_trained: 2725500
  num_samples_added_to_queue: 2742000
  num_training_step_calls_since_last_synch_worker_weights: 1189
  num_weight_broadcasts: 53926
custom_metrics: {}
date: 2023-08-14_16-01-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 10.22549019607843
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 21425
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5604804158210754
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -84.41329193115234
        total_loss: 3.561924457550049
        var_gnorm: 64.66852569580078
        vf_explained_var: 0.7978495359420776
        vf_loss: 181.55523681640625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5451.0
  learner_queue:
    size_count: 5456
    size_mean: 15.18
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5321879780235843
  num_agent_steps_sampled: 2742350
  num_agent_steps_trained: 2725500
  num_env_steps_sampled: 2742350
  num_env_steps_trained: 2725500
  num_samples_added_to_queue: 2742000
  num_training_step_calls_since_last_synch_worker_weights: 1189
  num_weight_broadcasts: 53926
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 219.397
    learner_load_time_ms: 10.024
    learner_load_wait_time_ms: 1.716
iterations_since_restore: 225
node_ip: 127.0.0.1
num_agent_steps_sampled: 2742350
num_agent_steps_trained: 2725500
num_env_steps_sampled: 2742350
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9965956299561
num_env_steps_trained: 2725500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9966216175137
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.286666666666655
  ram_util_percent: 81.42666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06574292698308057
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025689826416219134
  mean_inference_ms: 1.2308716800262198
  mean_raw_obs_processing_ms: 0.2797010993458521
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01983502331901999
    StateBufferConnector_ms: 0.003555475496778301
    ViewRequirementAgentConnector_ms: 0.11950076795091816
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 10.22549019607843
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 12.0, 8.0, 11.0, 5.0, 7.0, 13.0, 8.0, 12.0, 11.0, 12.0,
      12.0, 6.0, 8.0, 12.0, 9.0, 11.0, 13.0, 11.0, 11.0, 11.0, 14.0, 4.0, 9.0, 5.0,
      5.0, 7.0, 13.0, 14.0, 7.0, 12.0, 13.0, 8.0, 11.0, 14.0, 7.0, 10.0, 7.0, 6.0,
      7.0, 10.0, 16.0, 11.0, 6.0, 8.0, 11.0, 10.0, 8.0, 13.0, 14.0, 11.0, 10.0, 7.0,
      7.0, 11.0, 11.0, 11.0, 12.0, 11.0, 11.0, 11.0, 12.0, 15.0, 12.0, 9.0, 11.0,
      5.0, 12.0, 16.0, 9.0, 5.0, 8.0, 10.0, 9.0, 12.0, 9.0, 10.0, 9.0, 11.0, 12.0,
      11.0, 12.0, 14.0, 15.0, 15.0, 6.0, 8.0, 7.0, 12.0, 11.0, 7.0, 10.0, 14.0, 15.0,
      14.0, 9.0, 4.0, 9.0, 9.0, 16.0, 12.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06574292698308057
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025689826416219134
    mean_inference_ms: 1.2308716800262198
    mean_raw_obs_processing_ms: 0.2797010993458521
time_since_restore: 2283.75420999527
time_this_iter_s: 10.132957935333252
time_total_s: 2283.75420999527
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.006
  training_iteration_time_ms: 0.046
timestamp: 1691996463
timesteps_total: 2742350
training_iteration: 225
trial_id: default
train step: 226
agent_timesteps_total: 2755650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019112687844496507
  StateBufferConnector_ms: 0.0036063102575448844
  ViewRequirementAgentConnector_ms: 0.11750276272113507
counters:
  num_agent_steps_sampled: 2755650
  num_agent_steps_trained: 2739000
  num_env_steps_sampled: 2755650
  num_env_steps_trained: 2739000
  num_samples_added_to_queue: 2755500
  num_training_step_calls_since_last_synch_worker_weights: 1041
  num_weight_broadcasts: 54188
custom_metrics: {}
date: 2023-08-14_16-01-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.298076923076923
episode_reward_min: 3.0
episodes_this_iter: 104
episodes_total: 21529
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5911722779273987
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.3846778869628906
        total_loss: 14.405800819396973
        var_gnorm: 64.66798400878906
        vf_explained_var: 0.9312062859535217
        vf_loss: 39.492679595947266
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5478.0
  learner_queue:
    size_count: 5483
    size_mean: 15.38
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.1643023662262308
  num_agent_steps_sampled: 2755650
  num_agent_steps_trained: 2739000
  num_env_steps_sampled: 2755650
  num_env_steps_trained: 2739000
  num_samples_added_to_queue: 2755500
  num_training_step_calls_since_last_synch_worker_weights: 1041
  num_weight_broadcasts: 54188
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 223.205
    learner_load_time_ms: 1.518
    learner_load_wait_time_ms: 1.712
iterations_since_restore: 226
node_ip: 127.0.0.1
num_agent_steps_sampled: 2755650
num_agent_steps_trained: 2739000
num_env_steps_sampled: 2755650
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.998160841624
num_env_steps_trained: 2739000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.998133185107
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.99285714285714
  ram_util_percent: 81.61428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06571406133422168
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025677602849878325
  mean_inference_ms: 1.2303731275776124
  mean_raw_obs_processing_ms: 0.2795961806899465
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019112687844496507
    StateBufferConnector_ms: 0.0036063102575448844
    ViewRequirementAgentConnector_ms: 0.11750276272113507
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.298076923076923
  episode_reward_min: 3.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 8.0, 10.0, 12.0, 9.0, 11.0, 11.0, 7.0, 7.0, 16.0, 12.0,
      4.0, 13.0, 10.0, 15.0, 8.0, 11.0, 9.0, 10.0, 11.0, 12.0, 6.0, 9.0, 14.0, 10.0,
      6.0, 7.0, 8.0, 11.0, 7.0, 7.0, 8.0, 6.0, 9.0, 6.0, 10.0, 7.0, 12.0, 10.0, 5.0,
      5.0, 8.0, 12.0, 13.0, 11.0, 9.0, 12.0, 13.0, 11.0, 8.0, 10.0, 13.0, 15.0, 6.0,
      8.0, 8.0, 9.0, 18.0, 10.0, 9.0, 6.0, 9.0, 11.0, 6.0, 9.0, 11.0, 10.0, 6.0, 3.0,
      7.0, 11.0, 7.0, 9.0, 12.0, 7.0, 8.0, 13.0, 8.0, 9.0, 7.0, 6.0, 11.0, 11.0, 10.0,
      9.0, 11.0, 11.0, 8.0, 7.0, 9.0, 10.0, 6.0, 12.0, 10.0, 10.0, 5.0, 9.0, 11.0,
      8.0, 8.0, 13.0, 10.0, 6.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06571406133422168
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025677602849878325
    mean_inference_ms: 1.2303731275776124
    mean_raw_obs_processing_ms: 0.2795961806899465
time_since_restore: 2293.903531074524
time_this_iter_s: 10.14932107925415
time_total_s: 2293.903531074524
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.049
timestamp: 1691996474
timesteps_total: 2755650
training_iteration: 226
trial_id: default
train step: 227
agent_timesteps_total: 2769050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01944768996465774
  StateBufferConnector_ms: 0.0034684226626441592
  ViewRequirementAgentConnector_ms: 0.12424310048421223
counters:
  num_agent_steps_sampled: 2769050
  num_agent_steps_trained: 2752500
  num_env_steps_sampled: 2769050
  num_env_steps_trained: 2752500
  num_samples_added_to_queue: 2769000
  num_training_step_calls_since_last_synch_worker_weights: 48
  num_weight_broadcasts: 54451
custom_metrics: {}
date: 2023-08-14_16-01-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 8.876190476190477
episode_reward_min: 3.0
episodes_this_iter: 105
episodes_total: 21634
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5618767738342285
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 4.942094802856445
        total_loss: 39.38108444213867
        var_gnorm: 64.67184448242188
        vf_explained_var: 0.9136577844619751
        vf_loss: 74.49674987792969
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5505.0
  learner_queue:
    size_count: 5511
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 2769050
  num_agent_steps_trained: 2752500
  num_env_steps_sampled: 2769050
  num_env_steps_trained: 2752500
  num_samples_added_to_queue: 2769000
  num_training_step_calls_since_last_synch_worker_weights: 48
  num_weight_broadcasts: 54451
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 160.96
    learner_load_time_ms: 1.505
    learner_load_wait_time_ms: 1.611
iterations_since_restore: 227
node_ip: 127.0.0.1
num_agent_steps_sampled: 2769050
num_agent_steps_trained: 2752500
num_env_steps_sampled: 2769050
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.992492241009
num_env_steps_trained: 2752500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9924362129566
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.771428571428565
  ram_util_percent: 81.3714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06568532593767581
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02566448044505059
  mean_inference_ms: 1.2298555049746973
  mean_raw_obs_processing_ms: 0.27946687496692807
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01944768996465774
    StateBufferConnector_ms: 0.0034684226626441592
    ViewRequirementAgentConnector_ms: 0.12424310048421223
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 8.876190476190477
  episode_reward_min: 3.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 12.0, 4.0, 11.0, 8.0, 14.0, 7.0, 6.0, 15.0, 11.0, 9.0,
      5.0, 13.0, 8.0, 7.0, 11.0, 11.0, 10.0, 8.0, 14.0, 8.0, 6.0, 7.0, 8.0, 10.0,
      8.0, 12.0, 12.0, 10.0, 8.0, 7.0, 6.0, 5.0, 8.0, 13.0, 7.0, 12.0, 9.0, 8.0, 10.0,
      10.0, 8.0, 14.0, 7.0, 7.0, 9.0, 4.0, 4.0, 13.0, 8.0, 12.0, 7.0, 8.0, 9.0, 12.0,
      10.0, 13.0, 11.0, 4.0, 8.0, 10.0, 11.0, 12.0, 4.0, 13.0, 5.0, 15.0, 9.0, 12.0,
      15.0, 10.0, 3.0, 8.0, 8.0, 10.0, 5.0, 6.0, 14.0, 11.0, 11.0, 6.0, 6.0, 8.0,
      11.0, 5.0, 11.0, 4.0, 8.0, 7.0, 7.0, 6.0, 3.0, 9.0, 7.0, 9.0, 5.0, 9.0, 7.0,
      10.0, 7.0, 10.0, 5.0, 9.0, 19.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06568532593767581
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02566448044505059
    mean_inference_ms: 1.2298555049746973
    mean_raw_obs_processing_ms: 0.27946687496692807
time_since_restore: 2304.072454929352
time_this_iter_s: 10.16892385482788
time_total_s: 2304.072454929352
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996484
timesteps_total: 2769050
training_iteration: 227
trial_id: default
train step: 228
agent_timesteps_total: 2780750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022458791732788086
  StateBufferConnector_ms: 0.004136800765991211
  ViewRequirementAgentConnector_ms: 0.13506031036376953
counters:
  num_agent_steps_sampled: 2780750
  num_agent_steps_trained: 2764000
  num_env_steps_sampled: 2780750
  num_env_steps_trained: 2764000
  num_samples_added_to_queue: 2780500
  num_training_step_calls_since_last_synch_worker_weights: 1091
  num_weight_broadcasts: 54680
custom_metrics: {}
date: 2023-08-14_16-01-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 9.31
episode_reward_min: 5.0
episodes_this_iter: 91
episodes_total: 21725
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6027040481567383
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -50.234893798828125
        total_loss: -5.308182716369629
        var_gnorm: 64.67066192626953
        vf_explained_var: 0.8860833644866943
        vf_loss: 95.88046264648438
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5528.0
  learner_queue:
    size_count: 5534
    size_mean: 14.94
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7252246230563717
  num_agent_steps_sampled: 2780750
  num_agent_steps_trained: 2764000
  num_env_steps_sampled: 2780750
  num_env_steps_trained: 2764000
  num_samples_added_to_queue: 2780500
  num_training_step_calls_since_last_synch_worker_weights: 1091
  num_weight_broadcasts: 54680
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 193.239
    learner_load_time_ms: 1.487
    learner_load_wait_time_ms: 1.511
iterations_since_restore: 228
node_ip: 127.0.0.1
num_agent_steps_sampled: 2780750
num_agent_steps_trained: 2764000
num_env_steps_sampled: 2780750
num_env_steps_sampled_this_iter: 11700
num_env_steps_sampled_throughput_per_sec: 1169.9963736646514
num_env_steps_trained: 2764000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9964356532898
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 55.56000000000001
  ram_util_percent: 82.84666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0657168530661342
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025673130493288773
  mean_inference_ms: 1.2300203612060445
  mean_raw_obs_processing_ms: 0.2794999516721016
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022458791732788086
    StateBufferConnector_ms: 0.004136800765991211
    ViewRequirementAgentConnector_ms: 0.13506031036376953
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 9.31
  episode_reward_min: 5.0
  episodes_this_iter: 91
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 7.0, 10.0, 7.0, 10.0, 5.0, 9.0, 19.0, 5.0, 6.0, 11.0, 9.0,
      10.0, 11.0, 6.0, 10.0, 5.0, 8.0, 12.0, 6.0, 12.0, 12.0, 11.0, 9.0, 10.0, 12.0,
      9.0, 7.0, 6.0, 10.0, 10.0, 13.0, 8.0, 8.0, 13.0, 9.0, 12.0, 7.0, 10.0, 10.0,
      10.0, 8.0, 14.0, 14.0, 13.0, 13.0, 13.0, 11.0, 9.0, 9.0, 8.0, 10.0, 9.0, 11.0,
      7.0, 12.0, 9.0, 5.0, 9.0, 7.0, 10.0, 6.0, 6.0, 13.0, 7.0, 7.0, 8.0, 6.0, 7.0,
      9.0, 12.0, 10.0, 9.0, 10.0, 12.0, 11.0, 10.0, 9.0, 8.0, 10.0, 9.0, 11.0, 5.0,
      11.0, 10.0, 8.0, 6.0, 11.0, 7.0, 10.0, 6.0, 11.0, 13.0, 5.0, 8.0, 12.0, 10.0,
      11.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0657168530661342
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025673130493288773
    mean_inference_ms: 1.2300203612060445
    mean_raw_obs_processing_ms: 0.2794999516721016
time_since_restore: 2314.243047952652
time_this_iter_s: 10.170593023300171
time_total_s: 2314.243047952652
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996494
timesteps_total: 2780750
training_iteration: 228
trial_id: default
train step: 229
agent_timesteps_total: 2792850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021625995635986328
  StateBufferConnector_ms: 0.003950595855712891
  ViewRequirementAgentConnector_ms: 0.13109660148620605
counters:
  num_agent_steps_sampled: 2792850
  num_agent_steps_trained: 2776000
  num_env_steps_sampled: 2792850
  num_env_steps_trained: 2776000
  num_samples_added_to_queue: 2792500
  num_training_step_calls_since_last_synch_worker_weights: 861
  num_weight_broadcasts: 54916
custom_metrics: {}
date: 2023-08-14_16-01-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.77
episode_reward_min: 5.0
episodes_this_iter: 95
episodes_total: 21820
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6030641198158264
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 44.92399215698242
        total_loss: 99.62484741210938
        var_gnorm: 64.66859436035156
        vf_explained_var: 0.8334125876426697
        vf_loss: 115.43234252929688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5552.0
  learner_queue:
    size_count: 5556
    size_mean: 14.76
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.7839282496782207
  num_agent_steps_sampled: 2792850
  num_agent_steps_trained: 2776000
  num_env_steps_sampled: 2792850
  num_env_steps_trained: 2776000
  num_samples_added_to_queue: 2792500
  num_training_step_calls_since_last_synch_worker_weights: 861
  num_weight_broadcasts: 54916
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 315.755
    learner_load_time_ms: 1.663
    learner_load_wait_time_ms: 2.271
iterations_since_restore: 229
node_ip: 127.0.0.1
num_agent_steps_sampled: 2792850
num_agent_steps_trained: 2776000
num_env_steps_sampled: 2792850
num_env_steps_sampled_this_iter: 12100
num_env_steps_sampled_throughput_per_sec: 1209.9949226592448
num_env_steps_trained: 2776000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9949646207388
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 56.042857142857144
  ram_util_percent: 82.97142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0657149491753371
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02567992522964418
  mean_inference_ms: 1.2301103544138272
  mean_raw_obs_processing_ms: 0.27951871827971125
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021625995635986328
    StateBufferConnector_ms: 0.003950595855712891
    ViewRequirementAgentConnector_ms: 0.13109660148620605
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.77
  episode_reward_min: 5.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 10.0, 11.0, 7.0, 6.0, 9.0, 17.0, 9.0, 13.0, 9.0, 10.0,
      8.0, 9.0, 13.0, 10.0, 10.0, 10.0, 15.0, 9.0, 11.0, 13.0, 10.0, 11.0, 11.0, 5.0,
      6.0, 12.0, 6.0, 6.0, 7.0, 9.0, 8.0, 7.0, 6.0, 7.0, 9.0, 8.0, 16.0, 10.0, 6.0,
      10.0, 13.0, 6.0, 11.0, 6.0, 14.0, 13.0, 8.0, 5.0, 6.0, 9.0, 12.0, 8.0, 9.0,
      9.0, 8.0, 16.0, 8.0, 13.0, 5.0, 11.0, 14.0, 14.0, 7.0, 10.0, 18.0, 13.0, 10.0,
      7.0, 10.0, 12.0, 9.0, 10.0, 9.0, 11.0, 10.0, 10.0, 5.0, 5.0, 12.0, 13.0, 9.0,
      7.0, 10.0, 14.0, 14.0, 9.0, 16.0, 7.0, 9.0, 8.0, 10.0, 6.0, 13.0, 5.0, 10.0,
      10.0, 8.0, 13.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0657149491753371
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02567992522964418
    mean_inference_ms: 1.2301103544138272
    mean_raw_obs_processing_ms: 0.27951871827971125
time_since_restore: 2324.424421787262
time_this_iter_s: 10.181373834609985
time_total_s: 2324.424421787262
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996504
timesteps_total: 2792850
training_iteration: 229
trial_id: default
train step: 230
agent_timesteps_total: 2802850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02622365951538086
  StateBufferConnector_ms: 0.004928112030029297
  ViewRequirementAgentConnector_ms: 0.15691471099853516
counters:
  num_agent_steps_sampled: 2802850
  num_agent_steps_trained: 2786000
  num_env_steps_sampled: 2802850
  num_env_steps_trained: 2786000
  num_samples_added_to_queue: 2802500
  num_training_step_calls_since_last_synch_worker_weights: 397
  num_weight_broadcasts: 55113
custom_metrics: {}
date: 2023-08-14_16-01-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 10.12
episode_reward_min: 4.0
episodes_this_iter: 78
episodes_total: 21898
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6214221119880676
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -39.074554443359375
        total_loss: 23.472707748413086
        var_gnorm: 64.66867065429688
        vf_explained_var: 0.863344132900238
        vf_loss: 131.30874633789062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5572.0
  learner_queue:
    size_count: 5578
    size_mean: 15.02
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5683111936092278
  num_agent_steps_sampled: 2802850
  num_agent_steps_trained: 2786000
  num_env_steps_sampled: 2802850
  num_env_steps_trained: 2786000
  num_samples_added_to_queue: 2802500
  num_training_step_calls_since_last_synch_worker_weights: 397
  num_weight_broadcasts: 55113
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 224.294
    learner_load_time_ms: 1.669
    learner_load_wait_time_ms: 1.685
iterations_since_restore: 230
node_ip: 127.0.0.1
num_agent_steps_sampled: 2802850
num_agent_steps_trained: 2786000
num_env_steps_sampled: 2802850
num_env_steps_sampled_this_iter: 10000
num_env_steps_sampled_throughput_per_sec: 999.9982118638542
num_env_steps_trained: 2786000
num_env_steps_trained_this_iter: 10000
num_env_steps_trained_throughput_per_sec: 999.9982118638542
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10000
perf:
  cpu_util_percent: 62.10000000000001
  ram_util_percent: 83.90714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06579861897223686
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02570071990908356
  mean_inference_ms: 1.2307547858538737
  mean_raw_obs_processing_ms: 0.2796560614937114
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02622365951538086
    StateBufferConnector_ms: 0.004928112030029297
    ViewRequirementAgentConnector_ms: 0.15691471099853516
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 10.12
  episode_reward_min: 4.0
  episodes_this_iter: 78
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 12.0, 13.0, 9.0, 7.0, 10.0, 14.0, 14.0, 9.0, 16.0, 7.0,
      9.0, 8.0, 10.0, 6.0, 13.0, 5.0, 10.0, 10.0, 8.0, 13.0, 9.0, 10.0, 8.0, 9.0,
      7.0, 7.0, 7.0, 11.0, 8.0, 9.0, 6.0, 11.0, 8.0, 8.0, 12.0, 9.0, 6.0, 13.0, 11.0,
      11.0, 4.0, 11.0, 9.0, 11.0, 8.0, 12.0, 8.0, 9.0, 13.0, 8.0, 12.0, 9.0, 9.0,
      13.0, 11.0, 10.0, 10.0, 13.0, 13.0, 8.0, 11.0, 13.0, 14.0, 6.0, 13.0, 11.0,
      13.0, 12.0, 13.0, 7.0, 11.0, 12.0, 8.0, 12.0, 12.0, 16.0, 9.0, 13.0, 10.0, 14.0,
      8.0, 12.0, 5.0, 12.0, 14.0, 10.0, 10.0, 14.0, 12.0, 9.0, 12.0, 9.0, 10.0, 12.0,
      11.0, 6.0, 10.0, 6.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06579861897223686
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02570071990908356
    mean_inference_ms: 1.2307547858538737
    mean_raw_obs_processing_ms: 0.2796560614937114
time_since_restore: 2334.589614868164
time_this_iter_s: 10.1651930809021
time_total_s: 2334.589614868164
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691996514
timesteps_total: 2802850
training_iteration: 230
trial_id: default
train step: 231
agent_timesteps_total: 2814350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023263931274414062
  StateBufferConnector_ms: 0.004255771636962891
  ViewRequirementAgentConnector_ms: 0.14199399948120117
counters:
  num_agent_steps_sampled: 2814350
  num_agent_steps_trained: 2797500
  num_env_steps_sampled: 2814350
  num_env_steps_trained: 2797500
  num_samples_added_to_queue: 2814000
  num_training_step_calls_since_last_synch_worker_weights: 488
  num_weight_broadcasts: 55340
custom_metrics: {}
date: 2023-08-14_16-02-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.54
episode_reward_min: 3.0
episodes_this_iter: 90
episodes_total: 21988
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6368629932403564
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 59.46488952636719
        total_loss: 145.3479766845703
        var_gnorm: 64.66473388671875
        vf_explained_var: 0.804214358329773
        vf_loss: 178.13478088378906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5595.0
  learner_queue:
    size_count: 5601
    size_mean: 15.0
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5620499351813308
  num_agent_steps_sampled: 2814350
  num_agent_steps_trained: 2797500
  num_env_steps_sampled: 2814350
  num_env_steps_trained: 2797500
  num_samples_added_to_queue: 2814000
  num_training_step_calls_since_last_synch_worker_weights: 488
  num_weight_broadcasts: 55340
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 226.805
    learner_load_time_ms: 1.676
    learner_load_wait_time_ms: 1.826
iterations_since_restore: 231
node_ip: 127.0.0.1
num_agent_steps_sampled: 2814350
num_agent_steps_trained: 2797500
num_env_steps_sampled: 2814350
num_env_steps_sampled_this_iter: 11500
num_env_steps_sampled_throughput_per_sec: 1149.9950647565925
num_env_steps_trained: 2797500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9950647565925
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 56.83333333333333
  ram_util_percent: 81.4
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06579494217469276
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025723410969193842
  mean_inference_ms: 1.2313387610461843
  mean_raw_obs_processing_ms: 0.279774851245115
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023263931274414062
    StateBufferConnector_ms: 0.004255771636962891
    ViewRequirementAgentConnector_ms: 0.14199399948120117
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.54
  episode_reward_min: 3.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 12.0, 9.0, 10.0, 12.0, 11.0, 6.0, 10.0, 6.0, 11.0, 14.0,
      11.0, 5.0, 18.0, 11.0, 12.0, 16.0, 6.0, 12.0, 10.0, 6.0, 14.0, 7.0, 7.0, 9.0,
      11.0, 16.0, 8.0, 10.0, 13.0, 6.0, 14.0, 10.0, 13.0, 8.0, 11.0, 9.0, 8.0, 12.0,
      12.0, 10.0, 10.0, 12.0, 11.0, 7.0, 5.0, 8.0, 6.0, 12.0, 4.0, 7.0, 6.0, 6.0,
      9.0, 5.0, 15.0, 13.0, 5.0, 10.0, 12.0, 12.0, 12.0, 8.0, 9.0, 8.0, 9.0, 11.0,
      11.0, 11.0, 9.0, 7.0, 14.0, 7.0, 10.0, 14.0, 7.0, 4.0, 16.0, 9.0, 11.0, 17.0,
      9.0, 7.0, 6.0, 12.0, 8.0, 9.0, 8.0, 9.0, 4.0, 8.0, 11.0, 6.0, 8.0, 9.0, 8.0,
      9.0, 7.0, 9.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06579494217469276
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025723410969193842
    mean_inference_ms: 1.2313387610461843
    mean_raw_obs_processing_ms: 0.279774851245115
time_since_restore: 2344.7580268383026
time_this_iter_s: 10.16841197013855
time_total_s: 2344.7580268383026
timers:
  sample_time_ms: 0.02
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.053
timestamp: 1691996524
timesteps_total: 2814350
training_iteration: 231
trial_id: default
train step: 232
agent_timesteps_total: 2825750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024031639099121094
  StateBufferConnector_ms: 0.004343986511230469
  ViewRequirementAgentConnector_ms: 0.13946080207824707
counters:
  num_agent_steps_sampled: 2825750
  num_agent_steps_trained: 2809000
  num_env_steps_sampled: 2825750
  num_env_steps_trained: 2809000
  num_samples_added_to_queue: 2825500
  num_training_step_calls_since_last_synch_worker_weights: 207
  num_weight_broadcasts: 55565
custom_metrics: {}
date: 2023-08-14_16-02-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.2
episode_reward_min: 3.0
episodes_this_iter: 89
episodes_total: 22077
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.650801956653595
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.74252700805664
        total_loss: 101.62443542480469
        var_gnorm: 64.6672592163086
        vf_explained_var: 0.7776491045951843
        vf_loss: 243.24195861816406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5618.0
  learner_queue:
    size_count: 5624
    size_mean: 14.8
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6970562748477138
  num_agent_steps_sampled: 2825750
  num_agent_steps_trained: 2809000
  num_env_steps_sampled: 2825750
  num_env_steps_trained: 2809000
  num_samples_added_to_queue: 2825500
  num_training_step_calls_since_last_synch_worker_weights: 207
  num_weight_broadcasts: 55565
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 216.046
    learner_load_time_ms: 1.609
    learner_load_wait_time_ms: 1.651
iterations_since_restore: 232
node_ip: 127.0.0.1
num_agent_steps_sampled: 2825750
num_agent_steps_trained: 2809000
num_env_steps_sampled: 2825750
num_env_steps_sampled_this_iter: 11400
num_env_steps_sampled_throughput_per_sec: 1139.9957599797592
num_env_steps_trained: 2809000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9957227865993
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 56.99285714285713
  ram_util_percent: 81.61428571428573
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06581263475967632
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025737325199672575
  mean_inference_ms: 1.231695373025373
  mean_raw_obs_processing_ms: 0.27984545580387055
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024031639099121094
    StateBufferConnector_ms: 0.004343986511230469
    ViewRequirementAgentConnector_ms: 0.13946080207824707
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.2
  episode_reward_min: 3.0
  episodes_this_iter: 89
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 8.0, 11.0, 6.0, 8.0, 9.0, 8.0, 9.0, 7.0, 9.0, 3.0, 10.0,
      9.0, 13.0, 12.0, 10.0, 4.0, 7.0, 12.0, 12.0, 5.0, 8.0, 10.0, 16.0, 9.0, 10.0,
      9.0, 8.0, 8.0, 8.0, 12.0, 11.0, 14.0, 11.0, 5.0, 8.0, 9.0, 8.0, 6.0, 7.0, 11.0,
      8.0, 6.0, 5.0, 6.0, 9.0, 12.0, 11.0, 18.0, 9.0, 16.0, 12.0, 14.0, 5.0, 9.0,
      13.0, 7.0, 11.0, 9.0, 6.0, 7.0, 11.0, 8.0, 6.0, 6.0, 5.0, 8.0, 13.0, 13.0, 10.0,
      7.0, 14.0, 7.0, 7.0, 13.0, 11.0, 13.0, 13.0, 11.0, 10.0, 7.0, 10.0, 8.0, 6.0,
      5.0, 8.0, 10.0, 12.0, 7.0, 10.0, 7.0, 9.0, 11.0, 12.0, 7.0, 10.0, 6.0, 11.0,
      9.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06581263475967632
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025737325199672575
    mean_inference_ms: 1.231695373025373
    mean_raw_obs_processing_ms: 0.27984545580387055
time_since_restore: 2354.942102909088
time_this_iter_s: 10.184076070785522
time_total_s: 2354.942102909088
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691996535
timesteps_total: 2825750
training_iteration: 232
trial_id: default
train step: 233
agent_timesteps_total: 2837550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022681474685668945
  StateBufferConnector_ms: 0.004222393035888672
  ViewRequirementAgentConnector_ms: 0.1361691951751709
counters:
  num_agent_steps_sampled: 2837550
  num_agent_steps_trained: 2821000
  num_env_steps_sampled: 2837550
  num_env_steps_trained: 2821000
  num_samples_added_to_queue: 2837500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 55797
custom_metrics: {}
date: 2023-08-14_16-02-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 9.22
episode_reward_min: 4.0
episodes_this_iter: 91
episodes_total: 22168
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.659284770488739
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 20.102182388305664
        total_loss: 95.82101440429688
        var_gnorm: 64.66365051269531
        vf_explained_var: 0.7541388869285583
        vf_loss: 158.030517578125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5642.0
  learner_queue:
    size_count: 5648
    size_mean: 14.88
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.704582060213001
  num_agent_steps_sampled: 2837550
  num_agent_steps_trained: 2821000
  num_env_steps_sampled: 2837550
  num_env_steps_trained: 2821000
  num_samples_added_to_queue: 2837500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 55797
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 164.225
    learner_load_time_ms: 1.637
    learner_load_wait_time_ms: 1.449
iterations_since_restore: 233
node_ip: 127.0.0.1
num_agent_steps_sampled: 2837550
num_agent_steps_trained: 2821000
num_env_steps_sampled: 2837550
num_env_steps_sampled_this_iter: 11800
num_env_steps_sampled_throughput_per_sec: 1179.809483298531
num_env_steps_trained: 2821000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.8062542018959
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 56.300000000000004
  ram_util_percent: 81.45
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06582450448403161
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025746629936980403
  mean_inference_ms: 1.2318756777075621
  mean_raw_obs_processing_ms: 0.27988781500026544
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022681474685668945
    StateBufferConnector_ms: 0.004222393035888672
    ViewRequirementAgentConnector_ms: 0.1361691951751709
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 9.22
  episode_reward_min: 4.0
  episodes_this_iter: 91
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 11.0, 12.0, 7.0, 10.0, 6.0, 11.0, 9.0, 12.0, 12.0, 9.0,
      10.0, 10.0, 5.0, 4.0, 12.0, 8.0, 5.0, 4.0, 10.0, 8.0, 6.0, 14.0, 9.0, 13.0,
      11.0, 9.0, 11.0, 8.0, 7.0, 9.0, 13.0, 8.0, 6.0, 10.0, 4.0, 11.0, 9.0, 10.0,
      8.0, 12.0, 8.0, 7.0, 7.0, 12.0, 12.0, 13.0, 8.0, 6.0, 9.0, 10.0, 10.0, 7.0,
      10.0, 5.0, 11.0, 8.0, 10.0, 12.0, 6.0, 11.0, 13.0, 7.0, 11.0, 9.0, 14.0, 11.0,
      9.0, 8.0, 9.0, 6.0, 11.0, 6.0, 5.0, 9.0, 9.0, 7.0, 6.0, 10.0, 5.0, 7.0, 9.0,
      9.0, 12.0, 12.0, 12.0, 11.0, 7.0, 11.0, 10.0, 12.0, 14.0, 11.0, 11.0, 8.0, 11.0,
      9.0, 10.0, 11.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06582450448403161
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025746629936980403
    mean_inference_ms: 1.2318756777075621
    mean_raw_obs_processing_ms: 0.27988781500026544
time_since_restore: 2365.082312822342
time_this_iter_s: 10.140209913253784
time_total_s: 2365.082312822342
timers:
  sample_time_ms: 0.073
  synch_weights_time_ms: 0.637
  training_iteration_time_ms: 2.24
timestamp: 1691996545
timesteps_total: 2837550
training_iteration: 233
trial_id: default
train step: 234
agent_timesteps_total: 2850350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01959399421616356
  StateBufferConnector_ms: 0.0035061694607876315
  ViewRequirementAgentConnector_ms: 0.12049486141393681
counters:
  num_agent_steps_sampled: 2850350
  num_agent_steps_trained: 2833500
  num_env_steps_sampled: 2850350
  num_env_steps_trained: 2833500
  num_samples_added_to_queue: 2850000
  num_training_step_calls_since_last_synch_worker_weights: 560
  num_weight_broadcasts: 56049
custom_metrics: {}
date: 2023-08-14_16-02-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.178217821782178
episode_reward_min: 3.0
episodes_this_iter: 101
episodes_total: 22269
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6764090657234192
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 38.162559509277344
        total_loss: 119.21003723144531
        var_gnorm: 64.66460418701172
        vf_explained_var: 0.8079690933227539
        vf_loss: 168.85903930664062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5667.0
  learner_queue:
    size_count: 5673
    size_mean: 14.88
    size_quantiles: [11.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.750885490259143
  num_agent_steps_sampled: 2850350
  num_agent_steps_trained: 2833500
  num_env_steps_sampled: 2850350
  num_env_steps_trained: 2833500
  num_samples_added_to_queue: 2850000
  num_training_step_calls_since_last_synch_worker_weights: 560
  num_weight_broadcasts: 56049
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 203.598
    learner_load_time_ms: 1.639
    learner_load_wait_time_ms: 1.547
iterations_since_restore: 234
node_ip: 127.0.0.1
num_agent_steps_sampled: 2850350
num_agent_steps_trained: 2833500
num_env_steps_sampled: 2850350
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.993621857954
num_env_steps_trained: 2833500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.993771345658
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 51.77333333333333
  ram_util_percent: 81.61333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06578096452554887
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025744462154545344
  mean_inference_ms: 1.2316657702490823
  mean_raw_obs_processing_ms: 0.2798215843701917
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01959399421616356
    StateBufferConnector_ms: 0.0035061694607876315
    ViewRequirementAgentConnector_ms: 0.12049486141393681
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.178217821782178
  episode_reward_min: 3.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 10.0, 13.0, 6.0, 9.0, 11.0, 3.0, 11.0, 13.0, 14.0,
      6.0, 9.0, 9.0, 7.0, 12.0, 9.0, 5.0, 13.0, 7.0, 11.0, 6.0, 13.0, 10.0, 9.0, 6.0,
      8.0, 9.0, 9.0, 9.0, 7.0, 12.0, 9.0, 8.0, 9.0, 8.0, 10.0, 15.0, 7.0, 13.0, 10.0,
      13.0, 14.0, 9.0, 6.0, 6.0, 7.0, 10.0, 11.0, 6.0, 8.0, 8.0, 11.0, 5.0, 10.0,
      12.0, 5.0, 9.0, 5.0, 9.0, 11.0, 14.0, 5.0, 9.0, 8.0, 8.0, 10.0, 7.0, 3.0, 8.0,
      11.0, 4.0, 11.0, 9.0, 9.0, 12.0, 7.0, 9.0, 10.0, 8.0, 12.0, 12.0, 8.0, 12.0,
      6.0, 12.0, 5.0, 9.0, 7.0, 10.0, 11.0, 13.0, 11.0, 14.0, 8.0, 11.0, 11.0, 8.0,
      7.0, 11.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06578096452554887
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025744462154545344
    mean_inference_ms: 1.2316657702490823
    mean_raw_obs_processing_ms: 0.2798215843701917
time_since_restore: 2375.2090768814087
time_this_iter_s: 10.126764059066772
time_total_s: 2375.2090768814087
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691996555
timesteps_total: 2850350
training_iteration: 234
trial_id: default
train step: 235
agent_timesteps_total: 2863150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02053380012512207
  StateBufferConnector_ms: 0.0035858154296875
  ViewRequirementAgentConnector_ms: 0.12446188926696777
counters:
  num_agent_steps_sampled: 2863150
  num_agent_steps_trained: 2846500
  num_env_steps_sampled: 2863150
  num_env_steps_trained: 2846500
  num_samples_added_to_queue: 2863000
  num_training_step_calls_since_last_synch_worker_weights: 677
  num_weight_broadcasts: 56301
custom_metrics: {}
date: 2023-08-14_16-02-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.94
episode_reward_min: 4.0
episodes_this_iter: 100
episodes_total: 22369
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6546805500984192
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.005962371826172
        total_loss: 65.95427703857422
        var_gnorm: 64.66539764404297
        vf_explained_var: 0.7872232794761658
        vf_loss: 156.46728515625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5693.0
  learner_queue:
    size_count: 5698
    size_mean: 15.12
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5051910177781425
  num_agent_steps_sampled: 2863150
  num_agent_steps_trained: 2846500
  num_env_steps_sampled: 2863150
  num_env_steps_trained: 2846500
  num_samples_added_to_queue: 2863000
  num_training_step_calls_since_last_synch_worker_weights: 677
  num_weight_broadcasts: 56301
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 215.157
    learner_load_time_ms: 1.448
    learner_load_wait_time_ms: 1.535
iterations_since_restore: 235
node_ip: 127.0.0.1
num_agent_steps_sampled: 2863150
num_agent_steps_trained: 2846500
num_env_steps_sampled: 2863150
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9989929207143
num_env_steps_trained: 2846500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9989771851003
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.63571428571428
  ram_util_percent: 81.54285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06576699504183693
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025738239047952423
  mean_inference_ms: 1.2313794737565003
  mean_raw_obs_processing_ms: 0.27975959297631414
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02053380012512207
    StateBufferConnector_ms: 0.0035858154296875
    ViewRequirementAgentConnector_ms: 0.12446188926696777
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.94
  episode_reward_min: 4.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 9.0, 6.0, 10.0, 13.0, 9.0, 8.0, 12.0, 8.0, 10.0, 14.0, 10.0,
      8.0, 6.0, 11.0, 15.0, 9.0, 7.0, 6.0, 5.0, 7.0, 9.0, 8.0, 12.0, 6.0, 9.0, 9.0,
      12.0, 9.0, 8.0, 8.0, 11.0, 5.0, 9.0, 7.0, 11.0, 7.0, 12.0, 8.0, 9.0, 8.0, 13.0,
      14.0, 12.0, 9.0, 10.0, 5.0, 8.0, 8.0, 7.0, 7.0, 12.0, 11.0, 6.0, 9.0, 9.0, 7.0,
      9.0, 9.0, 11.0, 10.0, 9.0, 10.0, 4.0, 7.0, 5.0, 7.0, 9.0, 12.0, 11.0, 9.0, 15.0,
      10.0, 11.0, 5.0, 9.0, 8.0, 5.0, 11.0, 10.0, 10.0, 8.0, 10.0, 6.0, 7.0, 7.0,
      7.0, 8.0, 5.0, 14.0, 10.0, 9.0, 8.0, 11.0, 6.0, 10.0, 9.0, 8.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06576699504183693
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025738239047952423
    mean_inference_ms: 1.2313794737565003
    mean_raw_obs_processing_ms: 0.27975959297631414
time_since_restore: 2385.330148935318
time_this_iter_s: 10.121072053909302
time_total_s: 2385.330148935318
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996565
timesteps_total: 2863150
training_iteration: 235
trial_id: default
train step: 236
agent_timesteps_total: 2875750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02089667320251465
  StateBufferConnector_ms: 0.0036478042602539062
  ViewRequirementAgentConnector_ms: 0.1233980655670166
counters:
  num_agent_steps_sampled: 2875750
  num_agent_steps_trained: 2859000
  num_env_steps_sampled: 2875750
  num_env_steps_trained: 2859000
  num_samples_added_to_queue: 2875500
  num_training_step_calls_since_last_synch_worker_weights: 77
  num_weight_broadcasts: 56550
custom_metrics: {}
date: 2023-08-14_16-02-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 10.04
episode_reward_min: 4.0
episodes_this_iter: 98
episodes_total: 22467
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6031301021575928
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 13.030641555786133
        total_loss: 40.04008865356445
        var_gnorm: 64.66657257080078
        vf_explained_var: 0.9144418835639954
        vf_loss: 60.050201416015625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5718.0
  learner_queue:
    size_count: 5725
    size_mean: 15.22
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5005332385522157
  num_agent_steps_sampled: 2875750
  num_agent_steps_trained: 2859000
  num_env_steps_sampled: 2875750
  num_env_steps_trained: 2859000
  num_samples_added_to_queue: 2875500
  num_training_step_calls_since_last_synch_worker_weights: 77
  num_weight_broadcasts: 56550
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 162.39
    learner_load_time_ms: 1.445
    learner_load_wait_time_ms: 1.613
iterations_since_restore: 236
node_ip: 127.0.0.1
num_agent_steps_sampled: 2875750
num_agent_steps_trained: 2859000
num_env_steps_sampled: 2875750
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9995193483278
num_env_steps_trained: 2859000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9995231630237
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.892857142857146
  ram_util_percent: 80.59285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06575958976713324
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025737812019626095
  mean_inference_ms: 1.2312271253598095
  mean_raw_obs_processing_ms: 0.2796973678893949
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02089667320251465
    StateBufferConnector_ms: 0.0036478042602539062
    ViewRequirementAgentConnector_ms: 0.1233980655670166
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 10.04
  episode_reward_min: 4.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 10.0, 9.0, 6.0, 11.0, 10.0, 10.0, 17.0, 13.0, 11.0, 9.0,
      10.0, 7.0, 13.0, 8.0, 9.0, 11.0, 12.0, 12.0, 6.0, 4.0, 11.0, 7.0, 13.0, 11.0,
      12.0, 7.0, 10.0, 9.0, 8.0, 9.0, 7.0, 10.0, 10.0, 11.0, 8.0, 10.0, 8.0, 12.0,
      11.0, 10.0, 5.0, 16.0, 12.0, 10.0, 11.0, 7.0, 9.0, 14.0, 11.0, 13.0, 7.0, 8.0,
      14.0, 17.0, 12.0, 4.0, 11.0, 7.0, 9.0, 14.0, 9.0, 11.0, 14.0, 12.0, 14.0, 13.0,
      8.0, 10.0, 17.0, 16.0, 8.0, 7.0, 6.0, 13.0, 6.0, 6.0, 11.0, 7.0, 12.0, 13.0,
      7.0, 10.0, 11.0, 12.0, 8.0, 12.0, 9.0, 6.0, 7.0, 9.0, 9.0, 9.0, 7.0, 10.0, 14.0,
      8.0, 9.0, 13.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06575958976713324
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025737812019626095
    mean_inference_ms: 1.2312271253598095
    mean_raw_obs_processing_ms: 0.2796973678893949
time_since_restore: 2395.4894456863403
time_this_iter_s: 10.159296751022339
time_total_s: 2395.4894456863403
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996575
timesteps_total: 2875750
training_iteration: 236
trial_id: default
train step: 237
agent_timesteps_total: 2888750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019995371500651043
  StateBufferConnector_ms: 0.003529529945523131
  ViewRequirementAgentConnector_ms: 0.12049604864681468
counters:
  num_agent_steps_sampled: 2888750
  num_agent_steps_trained: 2872000
  num_env_steps_sampled: 2888750
  num_env_steps_trained: 2872000
  num_samples_added_to_queue: 2888500
  num_training_step_calls_since_last_synch_worker_weights: 451
  num_weight_broadcasts: 56806
custom_metrics: {}
date: 2023-08-14_16-03-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.519607843137255
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 22569
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5806602239608765
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -50.031883239746094
        total_loss: -2.1040189266204834
        var_gnorm: 64.6721420288086
        vf_explained_var: 0.8759444952011108
        vf_loss: 101.6623306274414
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5744.0
  learner_queue:
    size_count: 5750
    size_mean: 15.02
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.702821188498663
  num_agent_steps_sampled: 2888750
  num_agent_steps_trained: 2872000
  num_env_steps_sampled: 2888750
  num_env_steps_trained: 2872000
  num_samples_added_to_queue: 2888500
  num_training_step_calls_since_last_synch_worker_weights: 451
  num_weight_broadcasts: 56806
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 181.306
    learner_load_time_ms: 1.677
    learner_load_wait_time_ms: 1.624
iterations_since_restore: 237
node_ip: 127.0.0.1
num_agent_steps_sampled: 2888750
num_agent_steps_trained: 2872000
num_env_steps_sampled: 2888750
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9992251400797
num_env_steps_trained: 2872000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9992251400797
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.29333333333334
  ram_util_percent: 80.59333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06573546191362445
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02573234217335279
  mean_inference_ms: 1.230877589787122
  mean_raw_obs_processing_ms: 0.2796193428862973
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019995371500651043
    StateBufferConnector_ms: 0.003529529945523131
    ViewRequirementAgentConnector_ms: 0.12049604864681468
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.519607843137255
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 11.0, 6.0, 8.0, 10.0, 14.0, 7.0, 7.0, 4.0, 13.0, 8.0, 10.0,
      8.0, 9.0, 13.0, 7.0, 7.0, 7.0, 9.0, 7.0, 12.0, 10.0, 12.0, 9.0, 8.0, 8.0, 12.0,
      10.0, 10.0, 13.0, 12.0, 8.0, 10.0, 8.0, 12.0, 10.0, 12.0, 10.0, 8.0, 9.0, 5.0,
      10.0, 9.0, 13.0, 8.0, 9.0, 7.0, 7.0, 10.0, 7.0, 14.0, 7.0, 7.0, 10.0, 13.0,
      7.0, 12.0, 7.0, 5.0, 6.0, 10.0, 7.0, 10.0, 11.0, 6.0, 9.0, 10.0, 11.0, 9.0,
      8.0, 10.0, 9.0, 8.0, 8.0, 7.0, 10.0, 10.0, 12.0, 13.0, 7.0, 13.0, 8.0, 14.0,
      14.0, 9.0, 11.0, 13.0, 16.0, 15.0, 7.0, 8.0, 5.0, 9.0, 8.0, 9.0, 7.0, 15.0,
      8.0, 10.0, 16.0, 7.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06573546191362445
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02573234217335279
    mean_inference_ms: 1.230877589787122
    mean_raw_obs_processing_ms: 0.2796193428862973
time_since_restore: 2405.619648694992
time_this_iter_s: 10.130203008651733
time_total_s: 2405.619648694992
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996585
timesteps_total: 2888750
training_iteration: 237
trial_id: default
train step: 238
agent_timesteps_total: 2901650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01994501246084081
  StateBufferConnector_ms: 0.0035850128324905243
  ViewRequirementAgentConnector_ms: 0.12288258807493908
counters:
  num_agent_steps_sampled: 2901650
  num_agent_steps_trained: 2885000
  num_env_steps_sampled: 2901650
  num_env_steps_trained: 2885000
  num_samples_added_to_queue: 2901500
  num_training_step_calls_since_last_synch_worker_weights: 1068
  num_weight_broadcasts: 57060
custom_metrics: {}
date: 2023-08-14_16-03-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.514851485148515
episode_reward_min: 3.0
episodes_this_iter: 101
episodes_total: 22670
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5981883406639099
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 172.40322875976562
        total_loss: 397.9186706542969
        var_gnorm: 64.67047119140625
        vf_explained_var: 0.7157080173492432
        vf_loss: 457.0127868652344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5770.0
  learner_queue:
    size_count: 5775
    size_mean: 15.12
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5051910177781422
  num_agent_steps_sampled: 2901650
  num_agent_steps_trained: 2885000
  num_env_steps_sampled: 2901650
  num_env_steps_trained: 2885000
  num_samples_added_to_queue: 2901500
  num_training_step_calls_since_last_synch_worker_weights: 1068
  num_weight_broadcasts: 57060
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 252.221
    learner_load_time_ms: 1.657
    learner_load_wait_time_ms: 1.6
iterations_since_restore: 238
node_ip: 127.0.0.1
num_agent_steps_sampled: 2901650
num_agent_steps_trained: 2885000
num_env_steps_sampled: 2901650
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9971704545096
num_env_steps_trained: 2885000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9971485200485
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.10714285714287
  ram_util_percent: 80.98571428571428
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06572107082687825
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02572520508867407
  mean_inference_ms: 1.2305451465832442
  mean_raw_obs_processing_ms: 0.27954812302945287
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01994501246084081
    StateBufferConnector_ms: 0.0035850128324905243
    ViewRequirementAgentConnector_ms: 0.12288258807493908
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.514851485148515
  episode_reward_min: 3.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 12.0, 13.0, 7.0, 8.0, 11.0, 10.0, 11.0, 6.0, 12.0, 13.0,
      11.0, 3.0, 10.0, 10.0, 14.0, 8.0, 9.0, 5.0, 11.0, 11.0, 11.0, 5.0, 11.0, 7.0,
      8.0, 9.0, 13.0, 8.0, 11.0, 13.0, 8.0, 11.0, 11.0, 7.0, 10.0, 12.0, 12.0, 9.0,
      12.0, 7.0, 4.0, 11.0, 13.0, 5.0, 13.0, 9.0, 12.0, 16.0, 10.0, 9.0, 15.0, 6.0,
      7.0, 5.0, 8.0, 9.0, 6.0, 12.0, 12.0, 10.0, 10.0, 8.0, 10.0, 5.0, 10.0, 8.0,
      10.0, 5.0, 9.0, 7.0, 9.0, 11.0, 16.0, 5.0, 11.0, 11.0, 11.0, 12.0, 4.0, 12.0,
      4.0, 8.0, 5.0, 11.0, 11.0, 15.0, 8.0, 9.0, 8.0, 6.0, 10.0, 9.0, 6.0, 12.0, 13.0,
      11.0, 9.0, 11.0, 8.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06572107082687825
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02572520508867407
    mean_inference_ms: 1.2305451465832442
    mean_raw_obs_processing_ms: 0.27954812302945287
time_since_restore: 2415.7305886745453
time_this_iter_s: 10.110939979553223
time_total_s: 2415.7305886745453
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996595
timesteps_total: 2901650
training_iteration: 238
trial_id: default
train step: 239
agent_timesteps_total: 2915000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019313509647662822
  StateBufferConnector_ms: 0.0034417097385113058
  ViewRequirementAgentConnector_ms: 0.11820174180544339
counters:
  num_agent_steps_sampled: 2915000
  num_agent_steps_trained: 2898500
  num_env_steps_sampled: 2915000
  num_env_steps_trained: 2898500
  num_samples_added_to_queue: 2915000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 57323
custom_metrics: {}
date: 2023-08-14_16-03-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.73076923076923
episode_reward_min: 4.0
episodes_this_iter: 104
episodes_total: 22774
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5902882218360901
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.224398136138916
        total_loss: 28.393718719482422
        var_gnorm: 64.67475891113281
        vf_explained_var: 0.9145612120628357
        vf_loss: 67.13911437988281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5797.0
  learner_queue:
    size_count: 5800
    size_mean: 15.52
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0438390680559912
  num_agent_steps_sampled: 2915000
  num_agent_steps_trained: 2898500
  num_env_steps_sampled: 2915000
  num_env_steps_trained: 2898500
  num_samples_added_to_queue: 2915000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 57323
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 264.055
    learner_load_time_ms: 1.704
    learner_load_wait_time_ms: 1.638
iterations_since_restore: 239
node_ip: 127.0.0.1
num_agent_steps_sampled: 2915000
num_agent_steps_trained: 2898500
num_env_steps_sampled: 2915000
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1333.8515524598602
num_env_steps_trained: 2898500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1348.838648554915
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.964285714285715
  ram_util_percent: 82.12142857142855
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06568890086322467
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025714491287259538
  mean_inference_ms: 1.2300453200805197
  mean_raw_obs_processing_ms: 0.27943548042019206
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019313509647662822
    StateBufferConnector_ms: 0.0034417097385113058
    ViewRequirementAgentConnector_ms: 0.11820174180544339
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.73076923076923
  episode_reward_min: 4.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 6.0, 11.0, 8.0, 12.0, 6.0, 7.0, 9.0, 10.0, 12.0, 15.0,
      11.0, 9.0, 9.0, 13.0, 9.0, 7.0, 8.0, 13.0, 6.0, 11.0, 10.0, 5.0, 8.0, 12.0,
      14.0, 12.0, 7.0, 9.0, 12.0, 10.0, 11.0, 12.0, 11.0, 9.0, 6.0, 13.0, 8.0, 8.0,
      12.0, 9.0, 11.0, 11.0, 7.0, 11.0, 9.0, 14.0, 9.0, 9.0, 7.0, 8.0, 8.0, 11.0,
      4.0, 12.0, 7.0, 9.0, 14.0, 13.0, 8.0, 7.0, 10.0, 10.0, 11.0, 12.0, 16.0, 12.0,
      8.0, 9.0, 12.0, 10.0, 10.0, 10.0, 10.0, 10.0, 9.0, 11.0, 11.0, 11.0, 11.0, 13.0,
      12.0, 10.0, 7.0, 6.0, 13.0, 7.0, 7.0, 10.0, 9.0, 9.0, 11.0, 9.0, 5.0, 9.0, 9.0,
      7.0, 13.0, 7.0, 7.0, 8.0, 8.0, 16.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06568890086322467
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025714491287259538
    mean_inference_ms: 1.2300453200805197
    mean_raw_obs_processing_ms: 0.27943548042019206
time_since_restore: 2425.804621696472
time_this_iter_s: 10.07403302192688
time_total_s: 2425.804621696472
timers:
  sample_time_ms: 0.096
  synch_weights_time_ms: 0.581
  training_iteration_time_ms: 2.074
timestamp: 1691996606
timesteps_total: 2915000
training_iteration: 239
trial_id: default
train step: 240
agent_timesteps_total: 2928650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018509748940155887
  StateBufferConnector_ms: 0.003215976964647525
  ViewRequirementAgentConnector_ms: 0.11296517381044192
counters:
  num_agent_steps_sampled: 2928650
  num_agent_steps_trained: 2912000
  num_env_steps_sampled: 2928650
  num_env_steps_trained: 2912000
  num_samples_added_to_queue: 2928500
  num_training_step_calls_since_last_synch_worker_weights: 1050
  num_weight_broadcasts: 57591
custom_metrics: {}
date: 2023-08-14_16-03-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 9.14018691588785
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 22881
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5639873147010803
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -28.113330841064453
        total_loss: 56.35407257080078
        var_gnorm: 64.68165588378906
        vf_explained_var: 0.787897527217865
        vf_loss: 174.57467651367188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5824.0
  learner_queue:
    size_count: 5828
    size_mean: 15.8
    size_quantiles: [13.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.6
  num_agent_steps_sampled: 2928650
  num_agent_steps_trained: 2912000
  num_env_steps_sampled: 2928650
  num_env_steps_trained: 2912000
  num_samples_added_to_queue: 2928500
  num_training_step_calls_since_last_synch_worker_weights: 1050
  num_weight_broadcasts: 57591
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 238.466
    learner_load_time_ms: 1.706
    learner_load_wait_time_ms: 1.592
iterations_since_restore: 240
node_ip: 127.0.0.1
num_agent_steps_sampled: 2928650
num_agent_steps_trained: 2912000
num_env_steps_sampled: 2928650
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.9993165734852
num_env_steps_trained: 2912000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9993240836666
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.6
  ram_util_percent: 81.41428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06565054542395257
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02569755011034229
  mean_inference_ms: 1.2293983234065922
  mean_raw_obs_processing_ms: 0.27929113266785793
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018509748940155887
    StateBufferConnector_ms: 0.003215976964647525
    ViewRequirementAgentConnector_ms: 0.11296517381044192
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 9.14018691588785
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 14.0, 9.0, 9.0, 9.0, 6.0, 12.0, 11.0, 5.0, 10.0, 12.0,
      10.0, 11.0, 6.0, 8.0, 5.0, 5.0, 11.0, 7.0, 15.0, 9.0, 9.0, 12.0, 12.0, 19.0,
      12.0, 11.0, 10.0, 3.0, 6.0, 10.0, 9.0, 9.0, 12.0, 7.0, 9.0, 9.0, 10.0, 7.0,
      9.0, 9.0, 13.0, 8.0, 13.0, 4.0, 10.0, 6.0, 9.0, 13.0, 8.0, 5.0, 5.0, 9.0, 16.0,
      13.0, 10.0, 15.0, 6.0, 7.0, 10.0, 7.0, 11.0, 6.0, 6.0, 13.0, 9.0, 8.0, 14.0,
      9.0, 13.0, 7.0, 4.0, 6.0, 5.0, 7.0, 4.0, 7.0, 13.0, 10.0, 13.0, 8.0, 12.0, 10.0,
      8.0, 9.0, 7.0, 9.0, 10.0, 7.0, 13.0, 11.0, 12.0, 8.0, 7.0, 6.0, 8.0, 9.0, 9.0,
      6.0, 10.0, 9.0, 12.0, 7.0, 8.0, 10.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06565054542395257
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02569755011034229
    mean_inference_ms: 1.2293983234065922
    mean_raw_obs_processing_ms: 0.27929113266785793
time_since_restore: 2435.9016876220703
time_this_iter_s: 10.097065925598145
time_total_s: 2435.9016876220703
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691996616
timesteps_total: 2928650
training_iteration: 240
trial_id: default
train step: 241
agent_timesteps_total: 2942050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019301588718707744
  StateBufferConnector_ms: 0.003355970749488244
  ViewRequirementAgentConnector_ms: 0.11748579832223746
counters:
  num_agent_steps_sampled: 2942050
  num_agent_steps_trained: 2925500
  num_env_steps_sampled: 2942050
  num_env_steps_trained: 2925500
  num_samples_added_to_queue: 2942000
  num_training_step_calls_since_last_synch_worker_weights: 245
  num_weight_broadcasts: 57856
custom_metrics: {}
date: 2023-08-14_16-03-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.528846153846153
episode_reward_min: 3.0
episodes_this_iter: 104
episodes_total: 22985
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5736747980117798
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 9.743522644042969
        total_loss: 44.1259765625
        var_gnorm: 64.68222045898438
        vf_explained_var: 0.9172632694244385
        vf_loss: 74.50165557861328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5851.0
  learner_queue:
    size_count: 5857
    size_mean: 15.48
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1702991070662234
  num_agent_steps_sampled: 2942050
  num_agent_steps_trained: 2925500
  num_env_steps_sampled: 2942050
  num_env_steps_trained: 2925500
  num_samples_added_to_queue: 2942000
  num_training_step_calls_since_last_synch_worker_weights: 245
  num_weight_broadcasts: 57856
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 179.89
    learner_load_time_ms: 1.791
    learner_load_wait_time_ms: 1.772
iterations_since_restore: 241
node_ip: 127.0.0.1
num_agent_steps_sampled: 2942050
num_agent_steps_trained: 2925500
num_env_steps_sampled: 2942050
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9944730032962
num_env_steps_trained: 2925500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.994431757052
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.62666666666667
  ram_util_percent: 80.96666666666665
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06562745131845116
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025686545784287678
  mean_inference_ms: 1.228927538740636
  mean_raw_obs_processing_ms: 0.27918834885311483
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019301588718707744
    StateBufferConnector_ms: 0.003355970749488244
    ViewRequirementAgentConnector_ms: 0.11748579832223746
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.528846153846153
  episode_reward_min: 3.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 7.0, 9.0, 6.0, 4.0, 8.0, 6.0, 11.0, 11.0, 14.0, 10.0, 6.0,
      12.0, 13.0, 3.0, 7.0, 8.0, 10.0, 12.0, 10.0, 13.0, 7.0, 5.0, 10.0, 10.0, 9.0,
      8.0, 7.0, 6.0, 8.0, 13.0, 14.0, 8.0, 7.0, 8.0, 11.0, 9.0, 13.0, 7.0, 8.0, 10.0,
      11.0, 11.0, 15.0, 11.0, 12.0, 9.0, 7.0, 7.0, 10.0, 13.0, 14.0, 10.0, 11.0, 14.0,
      9.0, 9.0, 16.0, 9.0, 8.0, 6.0, 13.0, 11.0, 11.0, 6.0, 9.0, 12.0, 6.0, 13.0,
      6.0, 7.0, 12.0, 11.0, 11.0, 9.0, 10.0, 9.0, 11.0, 8.0, 11.0, 11.0, 11.0, 12.0,
      8.0, 10.0, 14.0, 4.0, 11.0, 10.0, 12.0, 12.0, 10.0, 10.0, 10.0, 11.0, 5.0, 5.0,
      8.0, 9.0, 5.0, 11.0, 9.0, 13.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06562745131845116
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025686545784287678
    mean_inference_ms: 1.228927538740636
    mean_raw_obs_processing_ms: 0.27918834885311483
time_since_restore: 2446.12948179245
time_this_iter_s: 10.227794170379639
time_total_s: 2446.12948179245
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996626
timesteps_total: 2942050
training_iteration: 241
trial_id: default
train step: 242
agent_timesteps_total: 2955350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019529003363389235
  StateBufferConnector_ms: 0.003535013932448167
  ViewRequirementAgentConnector_ms: 0.11930373998788688
counters:
  num_agent_steps_sampled: 2955350
  num_agent_steps_trained: 2938500
  num_env_steps_sampled: 2955350
  num_env_steps_trained: 2938500
  num_samples_added_to_queue: 2955000
  num_training_step_calls_since_last_synch_worker_weights: 1330
  num_weight_broadcasts: 58117
custom_metrics: {}
date: 2023-08-14_16-03-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.576923076923077
episode_reward_min: 3.0
episodes_this_iter: 104
episodes_total: 23089
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5864381790161133
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -4.5618085861206055
        total_loss: 80.75199890136719
        var_gnorm: 64.67842864990234
        vf_explained_var: 0.7975955009460449
        vf_loss: 176.4919891357422
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5877.0
  learner_queue:
    size_count: 5880
    size_mean: 15.44
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.283121194587635
  num_agent_steps_sampled: 2955350
  num_agent_steps_trained: 2938500
  num_env_steps_sampled: 2955350
  num_env_steps_trained: 2938500
  num_samples_added_to_queue: 2955000
  num_training_step_calls_since_last_synch_worker_weights: 1330
  num_weight_broadcasts: 58117
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 299.911
    learner_load_time_ms: 1.782
    learner_load_wait_time_ms: 1.548
iterations_since_restore: 242
node_ip: 127.0.0.1
num_agent_steps_sampled: 2955350
num_agent_steps_trained: 2938500
num_env_steps_sampled: 2955350
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9934995492122
num_env_steps_trained: 2938500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9936461759219
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.114285714285714
  ram_util_percent: 81.85714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06560045942598197
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02567617816596631
  mean_inference_ms: 1.2284375100265723
  mean_raw_obs_processing_ms: 0.27908392702958396
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019529003363389235
    StateBufferConnector_ms: 0.003535013932448167
    ViewRequirementAgentConnector_ms: 0.11930373998788688
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.576923076923077
  episode_reward_min: 3.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 8.0, 9.0, 12.0, 15.0, 12.0, 6.0, 12.0, 4.0, 9.0, 9.0, 10.0,
      12.0, 11.0, 10.0, 10.0, 8.0, 9.0, 7.0, 12.0, 13.0, 13.0, 11.0, 15.0, 7.0, 6.0,
      9.0, 12.0, 10.0, 12.0, 7.0, 11.0, 8.0, 9.0, 10.0, 12.0, 12.0, 10.0, 14.0, 7.0,
      9.0, 11.0, 12.0, 8.0, 9.0, 11.0, 11.0, 8.0, 7.0, 10.0, 4.0, 9.0, 7.0, 8.0, 5.0,
      11.0, 10.0, 11.0, 10.0, 7.0, 10.0, 14.0, 11.0, 13.0, 3.0, 14.0, 6.0, 10.0, 11.0,
      7.0, 9.0, 8.0, 8.0, 9.0, 9.0, 10.0, 9.0, 13.0, 7.0, 10.0, 10.0, 8.0, 8.0, 7.0,
      9.0, 8.0, 10.0, 5.0, 14.0, 10.0, 15.0, 7.0, 10.0, 9.0, 11.0, 8.0, 10.0, 10.0,
      12.0, 6.0, 13.0, 5.0, 11.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06560045942598197
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02567617816596631
    mean_inference_ms: 1.2284375100265723
    mean_raw_obs_processing_ms: 0.27908392702958396
time_since_restore: 2456.211681842804
time_this_iter_s: 10.082200050354004
time_total_s: 2456.211681842804
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691996636
timesteps_total: 2955350
training_iteration: 242
trial_id: default
train step: 243
agent_timesteps_total: 2968650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01926720142364502
  StateBufferConnector_ms: 0.003568713481609638
  ViewRequirementAgentConnector_ms: 0.11710914281698373
counters:
  num_agent_steps_sampled: 2968650
  num_agent_steps_trained: 2952000
  num_env_steps_sampled: 2968650
  num_env_steps_trained: 2952000
  num_samples_added_to_queue: 2968500
  num_training_step_calls_since_last_synch_worker_weights: 1265
  num_weight_broadcasts: 58379
custom_metrics: {}
date: 2023-08-14_16-04-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.403846153846153
episode_reward_min: 4.0
episodes_this_iter: 104
episodes_total: 23193
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5885356664657593
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 78.9946060180664
        total_loss: 158.29653930664062
        var_gnorm: 64.67843627929688
        vf_explained_var: 0.8170095682144165
        vf_loss: 164.4892120361328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5904.0
  learner_queue:
    size_count: 5908
    size_mean: 15.64
    size_quantiles: [13.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.8428523002282191
  num_agent_steps_sampled: 2968650
  num_agent_steps_trained: 2952000
  num_env_steps_sampled: 2968650
  num_env_steps_trained: 2952000
  num_samples_added_to_queue: 2968500
  num_training_step_calls_since_last_synch_worker_weights: 1265
  num_weight_broadcasts: 58379
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 254.371
    learner_load_time_ms: 1.527
    learner_load_wait_time_ms: 1.514
iterations_since_restore: 243
node_ip: 127.0.0.1
num_agent_steps_sampled: 2968650
num_agent_steps_trained: 2952000
num_env_steps_sampled: 2968650
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9978754554354
num_env_steps_trained: 2952000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9978435073967
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.19285714285714
  ram_util_percent: 81.77857142857144
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06557411013029243
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025663926414647615
  mean_inference_ms: 1.2279580296977906
  mean_raw_obs_processing_ms: 0.2789748865991044
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01926720142364502
    StateBufferConnector_ms: 0.003568713481609638
    ViewRequirementAgentConnector_ms: 0.11710914281698373
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.403846153846153
  episode_reward_min: 4.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 13.0, 11.0, 8.0, 8.0, 13.0, 9.0, 4.0, 9.0, 6.0, 15.0, 12.0,
      11.0, 12.0, 9.0, 10.0, 7.0, 12.0, 11.0, 10.0, 15.0, 4.0, 8.0, 7.0, 7.0, 9.0,
      7.0, 15.0, 9.0, 7.0, 10.0, 11.0, 6.0, 12.0, 12.0, 11.0, 8.0, 8.0, 14.0, 14.0,
      12.0, 10.0, 8.0, 6.0, 5.0, 9.0, 9.0, 8.0, 6.0, 6.0, 11.0, 12.0, 10.0, 7.0, 7.0,
      11.0, 7.0, 15.0, 9.0, 7.0, 9.0, 12.0, 9.0, 12.0, 8.0, 7.0, 9.0, 9.0, 11.0, 11.0,
      11.0, 8.0, 8.0, 7.0, 9.0, 6.0, 11.0, 13.0, 6.0, 6.0, 9.0, 10.0, 8.0, 7.0, 8.0,
      7.0, 10.0, 6.0, 15.0, 9.0, 7.0, 7.0, 14.0, 14.0, 8.0, 9.0, 11.0, 11.0, 7.0,
      12.0, 12.0, 7.0, 8.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06557411013029243
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025663926414647615
    mean_inference_ms: 1.2279580296977906
    mean_raw_obs_processing_ms: 0.2789748865991044
time_since_restore: 2466.299931049347
time_this_iter_s: 10.088249206542969
time_total_s: 2466.299931049347
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691996646
timesteps_total: 2968650
training_iteration: 243
trial_id: default
train step: 244
agent_timesteps_total: 2982250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01900038629207971
  StateBufferConnector_ms: 0.0034147838376603038
  ViewRequirementAgentConnector_ms: 0.11589842022589918
counters:
  num_agent_steps_sampled: 2982250
  num_agent_steps_trained: 2965500
  num_env_steps_sampled: 2982250
  num_env_steps_trained: 2965500
  num_samples_added_to_queue: 2982000
  num_training_step_calls_since_last_synch_worker_weights: 162
  num_weight_broadcasts: 58646
custom_metrics: {}
date: 2023-08-14_16-04-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 9.377358490566039
episode_reward_min: 4.0
episodes_this_iter: 106
episodes_total: 23299
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5853784084320068
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 14.524860382080078
        total_loss: 53.86992645263672
        var_gnorm: 64.67842864990234
        vf_explained_var: 0.9084377884864807
        vf_loss: 84.54391479492188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5931.0
  learner_queue:
    size_count: 5938
    size_mean: 15.42
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3577923257994944
  num_agent_steps_sampled: 2982250
  num_agent_steps_trained: 2965500
  num_env_steps_sampled: 2982250
  num_env_steps_trained: 2965500
  num_samples_added_to_queue: 2982000
  num_training_step_calls_since_last_synch_worker_weights: 162
  num_weight_broadcasts: 58646
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 150.742
    learner_load_time_ms: 1.427
    learner_load_wait_time_ms: 1.732
iterations_since_restore: 244
node_ip: 127.0.0.1
num_agent_steps_sampled: 2982250
num_agent_steps_trained: 2965500
num_env_steps_sampled: 2982250
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9997406006355
num_env_steps_trained: 2965500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9997425079837
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.06666666666667
  ram_util_percent: 81.84666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06554366735091319
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025651482214738848
  mean_inference_ms: 1.227406511594282
  mean_raw_obs_processing_ms: 0.27885388956894896
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01900038629207971
    StateBufferConnector_ms: 0.0034147838376603038
    ViewRequirementAgentConnector_ms: 0.11589842022589918
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 9.377358490566039
  episode_reward_min: 4.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 10.0, 10.0, 11.0, 6.0, 8.0, 5.0, 7.0, 13.0, 10.0, 6.0,
      13.0, 7.0, 11.0, 6.0, 8.0, 12.0, 8.0, 7.0, 12.0, 9.0, 9.0, 8.0, 9.0, 11.0, 12.0,
      9.0, 6.0, 8.0, 11.0, 7.0, 10.0, 13.0, 8.0, 9.0, 9.0, 7.0, 12.0, 6.0, 7.0, 10.0,
      12.0, 8.0, 6.0, 13.0, 9.0, 9.0, 6.0, 8.0, 8.0, 8.0, 12.0, 8.0, 9.0, 10.0, 5.0,
      4.0, 10.0, 9.0, 8.0, 12.0, 14.0, 10.0, 10.0, 9.0, 14.0, 9.0, 7.0, 13.0, 6.0,
      11.0, 12.0, 13.0, 12.0, 7.0, 12.0, 10.0, 12.0, 13.0, 8.0, 7.0, 12.0, 7.0, 13.0,
      5.0, 11.0, 13.0, 9.0, 14.0, 7.0, 13.0, 13.0, 6.0, 12.0, 8.0, 11.0, 12.0, 8.0,
      6.0, 12.0, 9.0, 5.0, 8.0, 9.0, 7.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06554366735091319
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025651482214738848
    mean_inference_ms: 1.227406511594282
    mean_raw_obs_processing_ms: 0.27885388956894896
time_since_restore: 2476.484310865402
time_this_iter_s: 10.184379816055298
time_total_s: 2476.484310865402
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691996656
timesteps_total: 2982250
training_iteration: 244
trial_id: default
train step: 245
agent_timesteps_total: 2995250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02063185560937021
  StateBufferConnector_ms: 0.003844616459865196
  ViewRequirementAgentConnector_ms: 0.12467725604188208
counters:
  num_agent_steps_sampled: 2995250
  num_agent_steps_trained: 2978500
  num_env_steps_sampled: 2995250
  num_env_steps_trained: 2978500
  num_samples_added_to_queue: 2995000
  num_training_step_calls_since_last_synch_worker_weights: 131
  num_weight_broadcasts: 58903
custom_metrics: {}
date: 2023-08-14_16-04-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 9.931372549019608
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 23401
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6228387951850891
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.841120719909668
        total_loss: 36.13402557373047
        var_gnorm: 64.67597961425781
        vf_explained_var: 0.878195583820343
        vf_loss: 94.17868041992188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5957.0
  learner_queue:
    size_count: 5964
    size_mean: 14.96
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8216476058777122
  num_agent_steps_sampled: 2995250
  num_agent_steps_trained: 2978500
  num_env_steps_sampled: 2995250
  num_env_steps_trained: 2978500
  num_samples_added_to_queue: 2995000
  num_training_step_calls_since_last_synch_worker_weights: 131
  num_weight_broadcasts: 58903
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 160.438
    learner_load_time_ms: 1.425
    learner_load_wait_time_ms: 1.842
iterations_since_restore: 245
node_ip: 127.0.0.1
num_agent_steps_sampled: 2995250
num_agent_steps_trained: 2978500
num_env_steps_sampled: 2995250
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9980163604487
num_env_steps_trained: 2978500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9980163604487
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.75714285714286
  ram_util_percent: 82.19285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06552814490709191
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02564696004242584
  mean_inference_ms: 1.2271313934139751
  mean_raw_obs_processing_ms: 0.2787878838399628
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02063185560937021
    StateBufferConnector_ms: 0.003844616459865196
    ViewRequirementAgentConnector_ms: 0.12467725604188208
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 9.931372549019608
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 10.0, 11.0, 9.0, 8.0, 12.0, 12.0, 19.0, 9.0, 9.0, 10.0,
      9.0, 9.0, 8.0, 10.0, 11.0, 5.0, 11.0, 5.0, 12.0, 9.0, 6.0, 11.0, 10.0, 7.0,
      9.0, 15.0, 9.0, 10.0, 4.0, 5.0, 15.0, 16.0, 11.0, 9.0, 7.0, 13.0, 7.0, 12.0,
      12.0, 6.0, 11.0, 13.0, 6.0, 9.0, 10.0, 9.0, 8.0, 8.0, 9.0, 10.0, 9.0, 4.0, 5.0,
      11.0, 14.0, 9.0, 7.0, 11.0, 10.0, 13.0, 10.0, 8.0, 6.0, 8.0, 9.0, 13.0, 7.0,
      9.0, 14.0, 14.0, 16.0, 12.0, 8.0, 11.0, 10.0, 9.0, 15.0, 13.0, 11.0, 12.0, 9.0,
      10.0, 10.0, 10.0, 10.0, 17.0, 7.0, 11.0, 9.0, 10.0, 6.0, 13.0, 4.0, 11.0, 10.0,
      10.0, 5.0, 16.0, 13.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06552814490709191
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02564696004242584
    mean_inference_ms: 1.2271313934139751
    mean_raw_obs_processing_ms: 0.2787878838399628
time_since_restore: 2486.710203886032
time_this_iter_s: 10.225893020629883
time_total_s: 2486.710203886032
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996666
timesteps_total: 2995250
training_iteration: 245
trial_id: default
train step: 246
agent_timesteps_total: 3007950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02107405662536621
  StateBufferConnector_ms: 0.003725767135620117
  ViewRequirementAgentConnector_ms: 0.12424683570861816
counters:
  num_agent_steps_sampled: 3007950
  num_agent_steps_trained: 2991000
  num_env_steps_sampled: 3007950
  num_env_steps_trained: 2991000
  num_samples_added_to_queue: 3007500
  num_training_step_calls_since_last_synch_worker_weights: 1286
  num_weight_broadcasts: 59153
custom_metrics: {}
date: 2023-08-14_16-04-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.51
episode_reward_min: 3.0
episodes_this_iter: 99
episodes_total: 23500
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6019241809844971
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 30.723976135253906
        total_loss: 81.4869613647461
        var_gnorm: 64.68470001220703
        vf_explained_var: 0.8818379640579224
        vf_loss: 107.54521942138672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5982.0
  learner_queue:
    size_count: 5986
    size_mean: 14.68
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.9943921379708656
  num_agent_steps_sampled: 3007950
  num_agent_steps_trained: 2991000
  num_env_steps_sampled: 3007950
  num_env_steps_trained: 2991000
  num_samples_added_to_queue: 3007500
  num_training_step_calls_since_last_synch_worker_weights: 1286
  num_weight_broadcasts: 59153
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 274.391
    learner_load_time_ms: 7.409
    learner_load_wait_time_ms: 1.59
iterations_since_restore: 246
node_ip: 127.0.0.1
num_agent_steps_sampled: 3007950
num_agent_steps_trained: 2991000
num_env_steps_sampled: 3007950
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.9954278633688
num_env_steps_trained: 2991000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9954998655205
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.37142857142858
  ram_util_percent: 82.60714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06552139700274695
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02564415473649941
  mean_inference_ms: 1.2268924269860149
  mean_raw_obs_processing_ms: 0.2787390740669384
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02107405662536621
    StateBufferConnector_ms: 0.003725767135620117
    ViewRequirementAgentConnector_ms: 0.12424683570861816
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.51
  episode_reward_min: 3.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 14.0, 13.0, 11.0, 7.0, 5.0, 10.0, 7.0, 8.0, 11.0, 8.0,
      9.0, 9.0, 8.0, 12.0, 12.0, 13.0, 11.0, 7.0, 9.0, 7.0, 15.0, 12.0, 10.0, 12.0,
      11.0, 14.0, 8.0, 12.0, 5.0, 4.0, 8.0, 8.0, 6.0, 14.0, 9.0, 11.0, 3.0, 5.0, 6.0,
      12.0, 11.0, 6.0, 6.0, 14.0, 10.0, 8.0, 11.0, 9.0, 9.0, 12.0, 8.0, 9.0, 10.0,
      10.0, 8.0, 8.0, 5.0, 14.0, 5.0, 9.0, 12.0, 11.0, 9.0, 11.0, 9.0, 8.0, 11.0,
      9.0, 8.0, 10.0, 9.0, 10.0, 13.0, 10.0, 5.0, 6.0, 8.0, 14.0, 7.0, 15.0, 16.0,
      9.0, 11.0, 11.0, 8.0, 10.0, 10.0, 11.0, 11.0, 13.0, 7.0, 12.0, 6.0, 9.0, 10.0,
      10.0, 11.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06552139700274695
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02564415473649941
    mean_inference_ms: 1.2268924269860149
    mean_raw_obs_processing_ms: 0.2787390740669384
time_since_restore: 2496.7950859069824
time_this_iter_s: 10.084882020950317
time_total_s: 2496.7950859069824
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996677
timesteps_total: 3007950
training_iteration: 246
trial_id: default
train step: 247
agent_timesteps_total: 3021650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018774683230391172
  StateBufferConnector_ms: 0.003297752309068341
  ViewRequirementAgentConnector_ms: 0.11344379353746076
counters:
  num_agent_steps_sampled: 3021650
  num_agent_steps_trained: 3005000
  num_env_steps_sampled: 3021650
  num_env_steps_trained: 3005000
  num_samples_added_to_queue: 3021500
  num_training_step_calls_since_last_synch_worker_weights: 1092
  num_weight_broadcasts: 59423
custom_metrics: {}
date: 2023-08-14_16-04-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.383177570093459
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 23607
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5859370827674866
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -51.609012603759766
        total_loss: -28.514408111572266
        var_gnorm: 64.68097686767578
        vf_explained_var: 0.9331556558609009
        vf_loss: 52.048580169677734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6010.0
  learner_queue:
    size_count: 6014
    size_mean: 15.38
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.354843164355196
  num_agent_steps_sampled: 3021650
  num_agent_steps_trained: 3005000
  num_env_steps_sampled: 3021650
  num_env_steps_trained: 3005000
  num_samples_added_to_queue: 3021500
  num_training_step_calls_since_last_synch_worker_weights: 1092
  num_weight_broadcasts: 59423
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 237.399
    learner_load_time_ms: 7.41
    learner_load_wait_time_ms: 1.559
iterations_since_restore: 247
node_ip: 127.0.0.1
num_agent_steps_sampled: 3021650
num_agent_steps_trained: 3005000
num_env_steps_sampled: 3021650
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.996701010065
num_env_steps_trained: 3005000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9966287694094
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.806666666666665
  ram_util_percent: 82.03333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06548004215912853
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025628888213239984
  mean_inference_ms: 1.2262839638579173
  mean_raw_obs_processing_ms: 0.2786095860103801
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018774683230391172
    StateBufferConnector_ms: 0.003297752309068341
    ViewRequirementAgentConnector_ms: 0.11344379353746076
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.383177570093459
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 8.0, 7.0, 9.0, 7.0, 4.0, 10.0, 9.0, 16.0, 5.0, 10.0, 9.0,
      8.0, 11.0, 5.0, 9.0, 11.0, 8.0, 8.0, 7.0, 11.0, 13.0, 11.0, 6.0, 12.0, 11.0,
      3.0, 14.0, 9.0, 13.0, 9.0, 11.0, 12.0, 8.0, 8.0, 7.0, 6.0, 8.0, 8.0, 12.0, 8.0,
      9.0, 12.0, 12.0, 11.0, 13.0, 10.0, 12.0, 11.0, 4.0, 9.0, 10.0, 11.0, 7.0, 12.0,
      7.0, 16.0, 12.0, 8.0, 9.0, 7.0, 11.0, 11.0, 5.0, 8.0, 7.0, 10.0, 5.0, 8.0, 10.0,
      13.0, 6.0, 14.0, 7.0, 7.0, 9.0, 9.0, 11.0, 12.0, 10.0, 8.0, 10.0, 11.0, 7.0,
      10.0, 13.0, 9.0, 8.0, 11.0, 12.0, 11.0, 7.0, 9.0, 5.0, 8.0, 10.0, 12.0, 6.0,
      10.0, 12.0, 7.0, 13.0, 9.0, 10.0, 12.0, 9.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06548004215912853
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025628888213239984
    mean_inference_ms: 1.2262839638579173
    mean_raw_obs_processing_ms: 0.2786095860103801
time_since_restore: 2506.889158964157
time_this_iter_s: 10.094073057174683
time_total_s: 2506.889158964157
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.042
timestamp: 1691996687
timesteps_total: 3021650
training_iteration: 247
trial_id: default
train step: 248
agent_timesteps_total: 3035350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01881011178560346
  StateBufferConnector_ms: 0.003302654373311551
  ViewRequirementAgentConnector_ms: 0.1131278332148757
counters:
  num_agent_steps_sampled: 3035350
  num_agent_steps_trained: 3018500
  num_env_steps_sampled: 3035350
  num_env_steps_trained: 3018500
  num_samples_added_to_queue: 3035000
  num_training_step_calls_since_last_synch_worker_weights: 101
  num_weight_broadcasts: 59691
custom_metrics: {}
date: 2023-08-14_16-04-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.242990654205608
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 23714
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5593648552894592
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.319133758544922
        total_loss: 33.17997360229492
        var_gnorm: 64.68437194824219
        vf_explained_var: 0.9114440679550171
        vf_loss: 67.3153305053711
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6037.0
  learner_queue:
    size_count: 6044
    size_mean: 15.38
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3840520221436765
  num_agent_steps_sampled: 3035350
  num_agent_steps_trained: 3018500
  num_env_steps_sampled: 3035350
  num_env_steps_trained: 3018500
  num_samples_added_to_queue: 3035000
  num_training_step_calls_since_last_synch_worker_weights: 101
  num_weight_broadcasts: 59691
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 153.372
    learner_load_time_ms: 7.405
    learner_load_wait_time_ms: 1.542
iterations_since_restore: 248
node_ip: 127.0.0.1
num_agent_steps_sampled: 3035350
num_agent_steps_trained: 3018500
num_env_steps_sampled: 3035350
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9969623156192
num_env_steps_trained: 3018500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9970066613764
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.82857142857143
  ram_util_percent: 81.95714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06545108597476466
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025613531376256004
  mean_inference_ms: 1.2256821247429066
  mean_raw_obs_processing_ms: 0.2784741114165128
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01881011178560346
    StateBufferConnector_ms: 0.003302654373311551
    ViewRequirementAgentConnector_ms: 0.1131278332148757
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.242990654205608
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 9.0, 10.0, 8.0, 8.0, 10.0, 10.0, 10.0, 9.0, 9.0, 7.0, 8.0,
      8.0, 6.0, 6.0, 18.0, 8.0, 6.0, 8.0, 7.0, 11.0, 10.0, 9.0, 11.0, 7.0, 11.0, 9.0,
      8.0, 9.0, 9.0, 8.0, 9.0, 8.0, 6.0, 10.0, 8.0, 7.0, 10.0, 7.0, 10.0, 14.0, 13.0,
      9.0, 11.0, 15.0, 6.0, 14.0, 14.0, 9.0, 8.0, 10.0, 10.0, 9.0, 10.0, 14.0, 10.0,
      9.0, 8.0, 8.0, 5.0, 11.0, 7.0, 9.0, 11.0, 8.0, 8.0, 7.0, 7.0, 8.0, 6.0, 7.0,
      9.0, 9.0, 10.0, 9.0, 9.0, 14.0, 10.0, 3.0, 12.0, 10.0, 11.0, 5.0, 3.0, 7.0,
      12.0, 9.0, 10.0, 12.0, 11.0, 8.0, 10.0, 11.0, 7.0, 13.0, 6.0, 12.0, 14.0, 12.0,
      10.0, 7.0, 11.0, 7.0, 11.0, 8.0, 10.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06545108597476466
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025613531376256004
    mean_inference_ms: 1.2256821247429066
    mean_raw_obs_processing_ms: 0.2784741114165128
time_since_restore: 2517.0397090911865
time_this_iter_s: 10.150550127029419
time_total_s: 2517.0397090911865
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.041
timestamp: 1691996697
timesteps_total: 3035350
training_iteration: 248
trial_id: default
train step: 249
agent_timesteps_total: 3048750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019018990652901784
  StateBufferConnector_ms: 0.003323327927362351
  ViewRequirementAgentConnector_ms: 0.11671702067057292
counters:
  num_agent_steps_sampled: 3048750
  num_agent_steps_trained: 3032000
  num_env_steps_sampled: 3048750
  num_env_steps_trained: 3032000
  num_samples_added_to_queue: 3048500
  num_training_step_calls_since_last_synch_worker_weights: 408
  num_weight_broadcasts: 59956
custom_metrics: {}
date: 2023-08-14_16-05-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.628571428571428
episode_reward_min: 4.0
episodes_this_iter: 105
episodes_total: 23819
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6321998238563538
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 4.994283676147461
        total_loss: 20.32881736755371
        var_gnorm: 64.68363189697266
        vf_explained_var: 0.9512383937835693
        vf_loss: 36.991065979003906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6064.0
  learner_queue:
    size_count: 6070
    size_mean: 15.1
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.676305461424021
  num_agent_steps_sampled: 3048750
  num_agent_steps_trained: 3032000
  num_env_steps_sampled: 3048750
  num_env_steps_trained: 3032000
  num_samples_added_to_queue: 3048500
  num_training_step_calls_since_last_synch_worker_weights: 408
  num_weight_broadcasts: 59956
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 185.405
    learner_load_time_ms: 7.454
    learner_load_wait_time_ms: 1.486
iterations_since_restore: 249
node_ip: 127.0.0.1
num_agent_steps_sampled: 3048750
num_agent_steps_trained: 3032000
num_env_steps_sampled: 3048750
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.991278228308
num_env_steps_trained: 3032000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9912131404594
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.16428571428571
  ram_util_percent: 81.07142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06541873607177223
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025601651404639426
  mean_inference_ms: 1.2252342937455336
  mean_raw_obs_processing_ms: 0.2783670362626374
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019018990652901784
    StateBufferConnector_ms: 0.003323327927362351
    ViewRequirementAgentConnector_ms: 0.11671702067057292
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.628571428571428
  episode_reward_min: 4.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 8.0, 10.0, 12.0, 11.0, 9.0, 7.0, 11.0, 16.0, 9.0, 10.0,
      10.0, 8.0, 10.0, 11.0, 11.0, 14.0, 8.0, 5.0, 12.0, 9.0, 6.0, 11.0, 7.0, 11.0,
      10.0, 10.0, 13.0, 10.0, 7.0, 14.0, 12.0, 10.0, 9.0, 10.0, 8.0, 7.0, 7.0, 8.0,
      11.0, 11.0, 9.0, 11.0, 6.0, 9.0, 8.0, 8.0, 13.0, 7.0, 12.0, 10.0, 7.0, 5.0,
      13.0, 13.0, 12.0, 8.0, 8.0, 8.0, 9.0, 11.0, 11.0, 7.0, 8.0, 8.0, 7.0, 13.0,
      12.0, 18.0, 10.0, 9.0, 13.0, 13.0, 10.0, 7.0, 6.0, 11.0, 8.0, 9.0, 9.0, 4.0,
      10.0, 16.0, 9.0, 9.0, 7.0, 10.0, 8.0, 14.0, 5.0, 8.0, 9.0, 10.0, 9.0, 5.0, 10.0,
      14.0, 10.0, 7.0, 6.0, 12.0, 15.0, 8.0, 10.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06541873607177223
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025601651404639426
    mean_inference_ms: 1.2252342937455336
    mean_raw_obs_processing_ms: 0.2783670362626374
time_since_restore: 2527.1750481128693
time_this_iter_s: 10.13533902168274
time_total_s: 2527.1750481128693
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.047
timestamp: 1691996707
timesteps_total: 3048750
training_iteration: 249
trial_id: default
train step: 250
agent_timesteps_total: 3062200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019240833464122954
  StateBufferConnector_ms: 0.0033619290306454615
  ViewRequirementAgentConnector_ms: 0.11485167912074498
counters:
  num_agent_steps_sampled: 3062200
  num_agent_steps_trained: 3045500
  num_env_steps_sampled: 3062200
  num_env_steps_trained: 3045500
  num_samples_added_to_queue: 3062000
  num_training_step_calls_since_last_synch_worker_weights: 92
  num_weight_broadcasts: 60220
custom_metrics: {}
date: 2023-08-14_16-05-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 9.123809523809523
episode_reward_min: 3.0
episodes_this_iter: 105
episodes_total: 23924
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5973226428031921
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.727787017822266
        total_loss: 37.33970260620117
        var_gnorm: 64.69025421142578
        vf_explained_var: 0.8855374455451965
        vf_loss: 110.10820770263672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6091.0
  learner_queue:
    size_count: 6098
    size_mean: 15.14
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6125755796240995
  num_agent_steps_sampled: 3062200
  num_agent_steps_trained: 3045500
  num_env_steps_sampled: 3062200
  num_env_steps_trained: 3045500
  num_samples_added_to_queue: 3062000
  num_training_step_calls_since_last_synch_worker_weights: 92
  num_weight_broadcasts: 60220
  timing_breakdown:
    learner_dequeue_time_ms: 0.015
    learner_grad_time_ms: 143.317
    learner_load_time_ms: 7.46
    learner_load_wait_time_ms: 1.536
iterations_since_restore: 250
node_ip: 127.0.0.1
num_agent_steps_sampled: 3062200
num_agent_steps_trained: 3045500
num_env_steps_sampled: 3062200
num_env_steps_sampled_this_iter: 13450
num_env_steps_sampled_throughput_per_sec: 1344.997306352288
num_env_steps_trained: 3045500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9972963387277
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.70666666666667
  ram_util_percent: 80.73333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06539526040684066
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02558888184914024
  mean_inference_ms: 1.2247157064931953
  mean_raw_obs_processing_ms: 0.27825441021689845
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019240833464122954
    StateBufferConnector_ms: 0.0033619290306454615
    ViewRequirementAgentConnector_ms: 0.11485167912074498
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 9.123809523809523
  episode_reward_min: 3.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 7.0, 4.0, 9.0, 11.0, 9.0, 6.0, 10.0, 7.0, 7.0, 10.0, 10.0,
      8.0, 9.0, 10.0, 8.0, 10.0, 8.0, 19.0, 3.0, 7.0, 10.0, 9.0, 9.0, 9.0, 5.0, 10.0,
      12.0, 11.0, 7.0, 8.0, 10.0, 6.0, 7.0, 5.0, 7.0, 9.0, 12.0, 14.0, 10.0, 7.0,
      7.0, 10.0, 12.0, 15.0, 8.0, 10.0, 10.0, 10.0, 9.0, 11.0, 7.0, 10.0, 9.0, 13.0,
      7.0, 9.0, 9.0, 9.0, 12.0, 13.0, 9.0, 13.0, 9.0, 10.0, 6.0, 8.0, 10.0, 12.0,
      8.0, 8.0, 8.0, 5.0, 7.0, 9.0, 8.0, 13.0, 8.0, 9.0, 12.0, 8.0, 9.0, 12.0, 8.0,
      13.0, 12.0, 6.0, 12.0, 9.0, 8.0, 12.0, 7.0, 7.0, 5.0, 12.0, 10.0, 7.0, 14.0,
      9.0, 8.0, 9.0, 5.0, 10.0, 10.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06539526040684066
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02558888184914024
    mean_inference_ms: 1.2247157064931953
    mean_raw_obs_processing_ms: 0.27825441021689845
time_since_restore: 2537.328068971634
time_this_iter_s: 10.153020858764648
time_total_s: 2537.328068971634
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691996717
timesteps_total: 3062200
training_iteration: 250
trial_id: default
train step: 251
agent_timesteps_total: 3075800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01922010261321736
  StateBufferConnector_ms: 0.0033048825843311914
  ViewRequirementAgentConnector_ms: 0.1142882855139046
counters:
  num_agent_steps_sampled: 3075800
  num_agent_steps_trained: 3059000
  num_env_steps_sampled: 3075800
  num_env_steps_trained: 3059000
  num_samples_added_to_queue: 3075500
  num_training_step_calls_since_last_synch_worker_weights: 982
  num_weight_broadcasts: 60487
custom_metrics: {}
date: 2023-08-14_16-05-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.953271028037383
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 24031
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5813767910003662
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 16.98710823059082
        total_loss: 94.00536346435547
        var_gnorm: 64.69063568115234
        vf_explained_var: 0.7917144894599915
        vf_loss: 159.85028076171875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6118.0
  learner_queue:
    size_count: 6122
    size_mean: 15.28
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.45657131648265
  num_agent_steps_sampled: 3075800
  num_agent_steps_trained: 3059000
  num_env_steps_sampled: 3075800
  num_env_steps_trained: 3059000
  num_samples_added_to_queue: 3075500
  num_training_step_calls_since_last_synch_worker_weights: 982
  num_weight_broadcasts: 60487
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 257.776
    learner_load_time_ms: 7.459
    learner_load_wait_time_ms: 1.622
iterations_since_restore: 251
node_ip: 127.0.0.1
num_agent_steps_sampled: 3075800
num_agent_steps_trained: 3059000
num_env_steps_sampled: 3075800
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.994163538231
num_env_steps_trained: 3059000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9942064533911
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.45714285714285
  ram_util_percent: 80.70714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06535851089374001
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0255747736446807
  mean_inference_ms: 1.22417358573985
  mean_raw_obs_processing_ms: 0.278129985014529
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01922010261321736
    StateBufferConnector_ms: 0.0033048825843311914
    ViewRequirementAgentConnector_ms: 0.1142882855139046
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.953271028037383
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 14.0, 7.0, 11.0, 8.0, 11.0, 6.0, 3.0, 9.0, 14.0, 15.0, 6.0,
      6.0, 11.0, 11.0, 9.0, 9.0, 8.0, 8.0, 10.0, 8.0, 10.0, 7.0, 9.0, 13.0, 9.0, 11.0,
      5.0, 13.0, 9.0, 6.0, 7.0, 8.0, 12.0, 6.0, 9.0, 9.0, 9.0, 11.0, 5.0, 7.0, 10.0,
      9.0, 5.0, 7.0, 10.0, 5.0, 9.0, 10.0, 12.0, 6.0, 10.0, 9.0, 10.0, 8.0, 5.0, 12.0,
      4.0, 3.0, 8.0, 13.0, 11.0, 13.0, 8.0, 7.0, 7.0, 9.0, 9.0, 12.0, 11.0, 11.0,
      12.0, 3.0, 10.0, 9.0, 10.0, 11.0, 11.0, 7.0, 14.0, 11.0, 8.0, 5.0, 14.0, 4.0,
      4.0, 6.0, 12.0, 12.0, 7.0, 9.0, 8.0, 6.0, 4.0, 11.0, 9.0, 7.0, 11.0, 14.0, 12.0,
      6.0, 15.0, 10.0, 9.0, 9.0, 10.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06535851089374001
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0255747736446807
    mean_inference_ms: 1.22417358573985
    mean_raw_obs_processing_ms: 0.278129985014529
time_since_restore: 2547.4337940216064
time_this_iter_s: 10.105725049972534
time_total_s: 2547.4337940216064
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691996727
timesteps_total: 3075800
training_iteration: 251
trial_id: default
train step: 252
agent_timesteps_total: 3089500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01880582773460532
  StateBufferConnector_ms: 0.0033423585711785083
  ViewRequirementAgentConnector_ms: 0.1139834242047004
counters:
  num_agent_steps_sampled: 3089500
  num_agent_steps_trained: 3073000
  num_env_steps_sampled: 3089500
  num_env_steps_trained: 3073000
  num_samples_added_to_queue: 3089500
  num_training_step_calls_since_last_synch_worker_weights: 643
  num_weight_broadcasts: 60758
custom_metrics: {}
date: 2023-08-14_16-05-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.433962264150944
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 24137
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6419268846511841
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -27.096454620361328
        total_loss: 38.89816665649414
        var_gnorm: 64.68803405761719
        vf_explained_var: 0.8315907716751099
        vf_loss: 138.40850830078125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6146.0
  learner_queue:
    size_count: 6150
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9165151389911679
  num_agent_steps_sampled: 3089500
  num_agent_steps_trained: 3073000
  num_env_steps_sampled: 3089500
  num_env_steps_trained: 3073000
  num_samples_added_to_queue: 3089500
  num_training_step_calls_since_last_synch_worker_weights: 643
  num_weight_broadcasts: 60758
  timing_breakdown:
    learner_dequeue_time_ms: 0.016
    learner_grad_time_ms: 230.11
    learner_load_time_ms: 1.472
    learner_load_wait_time_ms: 1.559
iterations_since_restore: 252
node_ip: 127.0.0.1
num_agent_steps_sampled: 3089500
num_agent_steps_trained: 3073000
num_env_steps_sampled: 3089500
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9991834168534
num_env_steps_trained: 3073000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9991655354704
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.81428571428571
  ram_util_percent: 81.00714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06532648182913948
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025558949478095717
  mean_inference_ms: 1.2235747955558527
  mean_raw_obs_processing_ms: 0.27799955250166586
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01880582773460532
    StateBufferConnector_ms: 0.0033423585711785083
    ViewRequirementAgentConnector_ms: 0.1139834242047004
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.433962264150944
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 13.0, 12.0, 10.0, 8.0, 6.0, 9.0, 9.0, 7.0, 9.0, 9.0, 8.0,
      10.0, 11.0, 6.0, 7.0, 12.0, 10.0, 5.0, 14.0, 9.0, 7.0, 6.0, 9.0, 8.0, 7.0, 11.0,
      15.0, 8.0, 9.0, 5.0, 9.0, 10.0, 10.0, 8.0, 7.0, 7.0, 9.0, 2.0, 8.0, 8.0, 7.0,
      10.0, 13.0, 5.0, 4.0, 6.0, 8.0, 9.0, 9.0, 2.0, 8.0, 11.0, 4.0, 9.0, 7.0, 7.0,
      7.0, 7.0, 9.0, 5.0, 4.0, 8.0, 7.0, 6.0, 8.0, 7.0, 11.0, 12.0, 11.0, 11.0, 10.0,
      9.0, 10.0, 9.0, 8.0, 8.0, 6.0, 12.0, 9.0, 10.0, 10.0, 4.0, 8.0, 4.0, 9.0, 9.0,
      9.0, 14.0, 2.0, 15.0, 9.0, 8.0, 7.0, 11.0, 7.0, 13.0, 13.0, 9.0, 9.0, 8.0, 14.0,
      7.0, 0.0, 11.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06532648182913948
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025558949478095717
    mean_inference_ms: 1.2235747955558527
    mean_raw_obs_processing_ms: 0.27799955250166586
time_since_restore: 2557.5402171611786
time_this_iter_s: 10.106423139572144
time_total_s: 2557.5402171611786
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996737
timesteps_total: 3089500
training_iteration: 252
trial_id: default
train step: 253
agent_timesteps_total: 3103000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019675155855574698
  StateBufferConnector_ms: 0.0033787961276072376
  ViewRequirementAgentConnector_ms: 0.11967083193221183
counters:
  num_agent_steps_sampled: 3103000
  num_agent_steps_trained: 3086500
  num_env_steps_sampled: 3103000
  num_env_steps_trained: 3086500
  num_samples_added_to_queue: 3103000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 61023
custom_metrics: {}
date: 2023-08-14_16-05-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 8.915094339622641
episode_reward_min: 1.0
episodes_this_iter: 106
episodes_total: 24243
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6021602153778076
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -15.798916816711426
        total_loss: 3.279465913772583
        var_gnorm: 64.68767547607422
        vf_explained_var: 0.9309596419334412
        vf_loss: 44.178367614746094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6173.0
  learner_queue:
    size_count: 6179
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.22
  num_agent_steps_sampled: 3103000
  num_agent_steps_trained: 3086500
  num_env_steps_sampled: 3103000
  num_env_steps_trained: 3086500
  num_samples_added_to_queue: 3103000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 61023
  timing_breakdown:
    learner_dequeue_time_ms: 0.016
    learner_grad_time_ms: 172.847
    learner_load_time_ms: 1.421
    learner_load_wait_time_ms: 1.622
iterations_since_restore: 253
node_ip: 127.0.0.1
num_agent_steps_sampled: 3103000
num_agent_steps_trained: 3086500
num_env_steps_sampled: 3103000
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.658394491293
num_env_steps_trained: 3086500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.658394491293
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.971428571428575
  ram_util_percent: 81.02142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06529742142326656
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025546214255763026
  mean_inference_ms: 1.22308370753526
  mean_raw_obs_processing_ms: 0.27789772963936155
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019675155855574698
    StateBufferConnector_ms: 0.0033787961276072376
    ViewRequirementAgentConnector_ms: 0.11967083193221183
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 8.915094339622641
  episode_reward_min: 1.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 8.0, 11.0, 13.0, 7.0, 11.0, 9.0, 12.0, 11.0, 4.0, 6.0, 10.0,
      8.0, 8.0, 8.0, 8.0, 6.0, 14.0, 14.0, 9.0, 6.0, 15.0, 9.0, 9.0, 10.0, 9.0, 1.0,
      7.0, 11.0, 10.0, 12.0, 9.0, 12.0, 6.0, 4.0, 8.0, 13.0, 4.0, 13.0, 9.0, 8.0,
      9.0, 7.0, 8.0, 7.0, 9.0, 13.0, 7.0, 10.0, 12.0, 8.0, 9.0, 12.0, 6.0, 9.0, 7.0,
      9.0, 10.0, 9.0, 5.0, 4.0, 11.0, 12.0, 10.0, 12.0, 6.0, 6.0, 14.0, 9.0, 7.0,
      7.0, 4.0, 5.0, 10.0, 10.0, 9.0, 9.0, 7.0, 8.0, 11.0, 7.0, 12.0, 8.0, 9.0, 7.0,
      14.0, 9.0, 12.0, 5.0, 12.0, 11.0, 9.0, 18.0, 7.0, 14.0, 6.0, 4.0, 7.0, 6.0,
      9.0, 11.0, 10.0, 7.0, 4.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06529742142326656
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025546214255763026
    mean_inference_ms: 1.22308370753526
    mean_raw_obs_processing_ms: 0.27789772963936155
time_since_restore: 2567.6884491443634
time_this_iter_s: 10.148231983184814
time_total_s: 2567.6884491443634
timers:
  sample_time_ms: 0.04
  synch_weights_time_ms: 0.668
  training_iteration_time_ms: 2.189
timestamp: 1691996748
timesteps_total: 3103000
training_iteration: 253
trial_id: default
train step: 254
agent_timesteps_total: 3115650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02117300033569336
  StateBufferConnector_ms: 0.0037784576416015625
  ViewRequirementAgentConnector_ms: 0.12512540817260742
counters:
  num_agent_steps_sampled: 3115650
  num_agent_steps_trained: 3099000
  num_env_steps_sampled: 3115650
  num_env_steps_trained: 3099000
  num_samples_added_to_queue: 3115500
  num_training_step_calls_since_last_synch_worker_weights: 271
  num_weight_broadcasts: 61272
custom_metrics: {}
date: 2023-08-14_16-05-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.66
episode_reward_min: 3.0
episodes_this_iter: 98
episodes_total: 24341
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5900710225105286
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.4489493370056152
        total_loss: 64.11418914794922
        var_gnorm: 64.68974304199219
        vf_explained_var: 0.8549344539642334
        vf_loss: 127.23119354248047
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6198.0
  learner_queue:
    size_count: 6204
    size_mean: 15.2
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5231546211727816
  num_agent_steps_sampled: 3115650
  num_agent_steps_trained: 3099000
  num_env_steps_sampled: 3115650
  num_env_steps_trained: 3099000
  num_samples_added_to_queue: 3115500
  num_training_step_calls_since_last_synch_worker_weights: 271
  num_weight_broadcasts: 61272
  timing_breakdown:
    learner_dequeue_time_ms: 0.015
    learner_grad_time_ms: 192.563
    learner_load_time_ms: 1.426
    learner_load_wait_time_ms: 1.623
iterations_since_restore: 254
node_ip: 127.0.0.1
num_agent_steps_sampled: 3115650
num_agent_steps_trained: 3099000
num_env_steps_sampled: 3115650
num_env_steps_sampled_this_iter: 12650
num_env_steps_sampled_throughput_per_sec: 1264.9964712956632
num_env_steps_trained: 3099000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9965131380072
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.20000000000001
  ram_util_percent: 82.85333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06529221540856353
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025543278388769144
  mean_inference_ms: 1.2229056977331072
  mean_raw_obs_processing_ms: 0.27786256773799234
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02117300033569336
    StateBufferConnector_ms: 0.0037784576416015625
    ViewRequirementAgentConnector_ms: 0.12512540817260742
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.66
  episode_reward_min: 3.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 10.0, 5.0, 11.0, 9.0, 10.0, 7.0, 8.0, 9.0, 12.0, 12.0, 16.0,
      13.0, 13.0, 12.0, 11.0, 5.0, 12.0, 7.0, 7.0, 12.0, 7.0, 12.0, 9.0, 7.0, 11.0,
      9.0, 6.0, 11.0, 11.0, 12.0, 10.0, 10.0, 13.0, 11.0, 13.0, 10.0, 11.0, 11.0,
      9.0, 6.0, 8.0, 12.0, 9.0, 9.0, 7.0, 10.0, 10.0, 9.0, 9.0, 7.0, 8.0, 13.0, 8.0,
      13.0, 9.0, 10.0, 13.0, 11.0, 9.0, 7.0, 13.0, 10.0, 5.0, 15.0, 12.0, 10.0, 6.0,
      8.0, 6.0, 9.0, 8.0, 9.0, 12.0, 13.0, 14.0, 4.0, 13.0, 11.0, 8.0, 7.0, 10.0,
      8.0, 5.0, 9.0, 4.0, 14.0, 10.0, 12.0, 9.0, 3.0, 8.0, 9.0, 12.0, 9.0, 10.0, 13.0,
      7.0, 11.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06529221540856353
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025543278388769144
    mean_inference_ms: 1.2229056977331072
    mean_raw_obs_processing_ms: 0.27786256773799234
time_since_restore: 2577.8360211849213
time_this_iter_s: 10.147572040557861
time_total_s: 2577.8360211849213
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996758
timesteps_total: 3115650
training_iteration: 254
trial_id: default
train step: 255
agent_timesteps_total: 3129150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019340695075269015
  StateBufferConnector_ms: 0.0033502308827526163
  ViewRequirementAgentConnector_ms: 0.11654237531266122
counters:
  num_agent_steps_sampled: 3129150
  num_agent_steps_trained: 3112500
  num_env_steps_sampled: 3129150
  num_env_steps_trained: 3112500
  num_samples_added_to_queue: 3129000
  num_training_step_calls_since_last_synch_worker_weights: 200
  num_weight_broadcasts: 61538
custom_metrics: {}
date: 2023-08-14_16-06-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.462264150943396
episode_reward_min: 2.0
episodes_this_iter: 106
episodes_total: 24447
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5983485579490662
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 24.804670333862305
        total_loss: 60.0621223449707
        var_gnorm: 64.69280242919922
        vf_explained_var: 0.9228854179382324
        vf_loss: 76.4983901977539
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6225.0
  learner_queue:
    size_count: 6231
    size_mean: 15.12
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5574337867145427
  num_agent_steps_sampled: 3129150
  num_agent_steps_trained: 3112500
  num_env_steps_sampled: 3129150
  num_env_steps_trained: 3112500
  num_samples_added_to_queue: 3129000
  num_training_step_calls_since_last_synch_worker_weights: 200
  num_weight_broadcasts: 61538
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 174.118
    learner_load_time_ms: 1.578
    learner_load_wait_time_ms: 1.542
iterations_since_restore: 255
node_ip: 127.0.0.1
num_agent_steps_sampled: 3129150
num_agent_steps_trained: 3112500
num_env_steps_sampled: 3129150
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.999195337775
num_env_steps_trained: 3112500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.999195337775
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.07857142857143
  ram_util_percent: 82.47142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06525957141251619
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025532740947914488
  mean_inference_ms: 1.222434775642748
  mean_raw_obs_processing_ms: 0.2777518721273302
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019340695075269015
    StateBufferConnector_ms: 0.0033502308827526163
    ViewRequirementAgentConnector_ms: 0.11654237531266122
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.462264150943396
  episode_reward_min: 2.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 8.0, 16.0, 9.0, 13.0, 10.0, 11.0, 10.0, 7.0, 6.0, 7.0,
      12.0, 10.0, 15.0, 6.0, 13.0, 9.0, 8.0, 5.0, 7.0, 8.0, 8.0, 7.0, 7.0, 11.0, 10.0,
      4.0, 6.0, 8.0, 12.0, 8.0, 9.0, 11.0, 12.0, 9.0, 11.0, 9.0, 10.0, 12.0, 11.0,
      11.0, 8.0, 9.0, 13.0, 9.0, 6.0, 8.0, 12.0, 11.0, 8.0, 7.0, 8.0, 13.0, 6.0, 12.0,
      10.0, 9.0, 14.0, 11.0, 9.0, 9.0, 8.0, 10.0, 6.0, 10.0, 7.0, 12.0, 10.0, 9.0,
      10.0, 9.0, 8.0, 7.0, 9.0, 10.0, 14.0, 8.0, 12.0, 2.0, 9.0, 6.0, 8.0, 12.0, 15.0,
      15.0, 7.0, 12.0, 9.0, 11.0, 8.0, 5.0, 10.0, 10.0, 8.0, 7.0, 6.0, 13.0, 9.0,
      8.0, 10.0, 10.0, 9.0, 14.0, 11.0, 10.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06525957141251619
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025532740947914488
    mean_inference_ms: 1.222434775642748
    mean_raw_obs_processing_ms: 0.2777518721273302
time_since_restore: 2587.980362176895
time_this_iter_s: 10.144340991973877
time_total_s: 2587.980362176895
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996768
timesteps_total: 3129150
training_iteration: 255
trial_id: default
train step: 256
agent_timesteps_total: 3141550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021434545516967773
  StateBufferConnector_ms: 0.0039637088775634766
  ViewRequirementAgentConnector_ms: 0.13047027587890625
counters:
  num_agent_steps_sampled: 3141550
  num_agent_steps_trained: 3125000
  num_env_steps_sampled: 3141550
  num_env_steps_trained: 3125000
  num_samples_added_to_queue: 3141500
  num_training_step_calls_since_last_synch_worker_weights: 724
  num_weight_broadcasts: 61783
custom_metrics: {}
date: 2023-08-14_16-06-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.23
episode_reward_min: 3.0
episodes_this_iter: 97
episodes_total: 24544
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5585911870002747
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 16.177181243896484
        total_loss: 49.20969009399414
        var_gnorm: 64.70225524902344
        vf_explained_var: 0.904525876045227
        vf_loss: 71.65093231201172
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6250.0
  learner_queue:
    size_count: 6254
    size_mean: 15.12
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5574337867145427
  num_agent_steps_sampled: 3141550
  num_agent_steps_trained: 3125000
  num_env_steps_sampled: 3141550
  num_env_steps_trained: 3125000
  num_samples_added_to_queue: 3141500
  num_training_step_calls_since_last_synch_worker_weights: 724
  num_weight_broadcasts: 61783
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 238.404
    learner_load_time_ms: 1.589
    learner_load_wait_time_ms: 1.657
iterations_since_restore: 256
node_ip: 127.0.0.1
num_agent_steps_sampled: 3141550
num_agent_steps_trained: 3125000
num_env_steps_sampled: 3141550
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.9960088858318
num_env_steps_trained: 3125000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9959766994273
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.17857142857144
  ram_util_percent: 82.25714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0652590534846902
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025531690718440227
  mean_inference_ms: 1.2223483295670972
  mean_raw_obs_processing_ms: 0.27773925331640276
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021434545516967773
    StateBufferConnector_ms: 0.0039637088775634766
    ViewRequirementAgentConnector_ms: 0.13047027587890625
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.23
  episode_reward_min: 3.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 10.0, 11.0, 10.0, 9.0, 8.0, 7.0, 9.0, 10.0, 13.0, 12.0,
      14.0, 8.0, 8.0, 13.0, 12.0, 11.0, 6.0, 11.0, 12.0, 8.0, 9.0, 9.0, 7.0, 9.0,
      9.0, 11.0, 10.0, 6.0, 9.0, 14.0, 6.0, 11.0, 8.0, 9.0, 3.0, 7.0, 9.0, 9.0, 8.0,
      10.0, 15.0, 7.0, 12.0, 11.0, 7.0, 11.0, 8.0, 8.0, 7.0, 10.0, 9.0, 15.0, 9.0,
      9.0, 9.0, 11.0, 14.0, 9.0, 8.0, 12.0, 9.0, 14.0, 11.0, 11.0, 10.0, 8.0, 5.0,
      7.0, 10.0, 8.0, 10.0, 7.0, 15.0, 4.0, 12.0, 7.0, 12.0, 15.0, 9.0, 9.0, 5.0,
      6.0, 8.0, 8.0, 6.0, 9.0, 4.0, 6.0, 9.0, 10.0, 11.0, 8.0, 13.0, 8.0, 3.0, 8.0,
      8.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0652590534846902
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025531690718440227
    mean_inference_ms: 1.2223483295670972
    mean_raw_obs_processing_ms: 0.27773925331640276
time_since_restore: 2598.083186149597
time_this_iter_s: 10.102823972702026
time_total_s: 2598.083186149597
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996778
timesteps_total: 3141550
training_iteration: 256
trial_id: default
train step: 257
agent_timesteps_total: 3154850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01936050561758188
  StateBufferConnector_ms: 0.003435978522667518
  ViewRequirementAgentConnector_ms: 0.11790005060342643
counters:
  num_agent_steps_sampled: 3154850
  num_agent_steps_trained: 3138000
  num_env_steps_sampled: 3154850
  num_env_steps_trained: 3138000
  num_samples_added_to_queue: 3154500
  num_training_step_calls_since_last_synch_worker_weights: 801
  num_weight_broadcasts: 62044
custom_metrics: {}
date: 2023-08-14_16-06-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 20.0
episode_reward_mean: 9.221153846153847
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 24648
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5826604962348938
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -50.11344528198242
        total_loss: 25.468658447265625
        var_gnorm: 64.69992065429688
        vf_explained_var: 0.8084701895713806
        vf_loss: 156.99081420898438
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6276.0
  learner_queue:
    size_count: 6281
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2631706139710503
  num_agent_steps_sampled: 3154850
  num_agent_steps_trained: 3138000
  num_env_steps_sampled: 3154850
  num_env_steps_trained: 3138000
  num_samples_added_to_queue: 3154500
  num_training_step_calls_since_last_synch_worker_weights: 801
  num_weight_broadcasts: 62044
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 227.192
    learner_load_time_ms: 1.816
    learner_load_wait_time_ms: 1.593
iterations_since_restore: 257
node_ip: 127.0.0.1
num_agent_steps_sampled: 3154850
num_agent_steps_trained: 3138000
num_env_steps_sampled: 3154850
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.994165446128
num_env_steps_trained: 3138000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9942970526063
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.79333333333334
  ram_util_percent: 82.16666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06523113098358947
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0255232985196151
  mean_inference_ms: 1.2219425598087617
  mean_raw_obs_processing_ms: 0.27765138954060375
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01936050561758188
    StateBufferConnector_ms: 0.003435978522667518
    ViewRequirementAgentConnector_ms: 0.11790005060342643
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 20.0
  episode_reward_mean: 9.221153846153847
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 12.0, 10.0, 11.0, 10.0, 8.0, 4.0, 6.0, 9.0, 5.0, 11.0,
      8.0, 10.0, 11.0, 11.0, 6.0, 8.0, 7.0, 8.0, 9.0, 15.0, 11.0, 9.0, 8.0, 7.0, 7.0,
      8.0, 7.0, 11.0, 5.0, 12.0, 5.0, 12.0, 13.0, 12.0, 9.0, 9.0, 15.0, 4.0, 9.0,
      6.0, 10.0, 2.0, 13.0, 12.0, 10.0, 10.0, 5.0, 14.0, 9.0, 10.0, 12.0, 9.0, 20.0,
      6.0, 10.0, 8.0, 11.0, 7.0, 12.0, 11.0, 8.0, 8.0, 12.0, 8.0, 14.0, 8.0, 8.0,
      7.0, 11.0, 8.0, 6.0, 8.0, 12.0, 14.0, 12.0, 11.0, 9.0, 10.0, 12.0, 6.0, 12.0,
      9.0, 8.0, 13.0, 11.0, 7.0, 9.0, 7.0, 5.0, 7.0, 5.0, 5.0, 8.0, 12.0, 6.0, 7.0,
      17.0, 9.0, 9.0, 5.0, 4.0, 9.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06523113098358947
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0255232985196151
    mean_inference_ms: 1.2219425598087617
    mean_raw_obs_processing_ms: 0.27765138954060375
time_since_restore: 2608.1982731819153
time_this_iter_s: 10.115087032318115
time_total_s: 2608.1982731819153
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996788
timesteps_total: 3154850
training_iteration: 257
trial_id: default
train step: 258
agent_timesteps_total: 3168150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019388244702265814
  StateBufferConnector_ms: 0.0034261208314162036
  ViewRequirementAgentConnector_ms: 0.11858481627244216
counters:
  num_agent_steps_sampled: 3168150
  num_agent_steps_trained: 3151500
  num_env_steps_sampled: 3168150
  num_env_steps_trained: 3151500
  num_samples_added_to_queue: 3168000
  num_training_step_calls_since_last_synch_worker_weights: 1299
  num_weight_broadcasts: 62306
custom_metrics: {}
date: 2023-08-14_16-06-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.51923076923077
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 24752
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6077679395675659
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.841447830200195
        total_loss: 32.60106658935547
        var_gnorm: 64.69532012939453
        vf_explained_var: 0.8892388939857483
        vf_loss: 92.96270751953125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6303.0
  learner_queue:
    size_count: 6307
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9591663046625439
  num_agent_steps_sampled: 3168150
  num_agent_steps_trained: 3151500
  num_env_steps_sampled: 3168150
  num_env_steps_trained: 3151500
  num_samples_added_to_queue: 3168000
  num_training_step_calls_since_last_synch_worker_weights: 1299
  num_weight_broadcasts: 62306
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 245.682
    learner_load_time_ms: 1.896
    learner_load_wait_time_ms: 1.578
iterations_since_restore: 258
node_ip: 127.0.0.1
num_agent_steps_sampled: 3168150
num_agent_steps_trained: 3151500
num_env_steps_sampled: 3168150
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9940386085686
num_env_steps_trained: 3151500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9939489635847
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.478571428571435
  ram_util_percent: 82.44285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06520815830776916
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02551428714787635
  mean_inference_ms: 1.2215195765334848
  mean_raw_obs_processing_ms: 0.27756139404891844
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019388244702265814
    StateBufferConnector_ms: 0.0034261208314162036
    ViewRequirementAgentConnector_ms: 0.11858481627244216
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.51923076923077
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 10.0, 9.0, 11.0, 8.0, 4.0, 11.0, 14.0, 6.0, 8.0, 8.0, 10.0,
      6.0, 11.0, 9.0, 14.0, 5.0, 10.0, 7.0, 7.0, 14.0, 15.0, 11.0, 12.0, 10.0, 9.0,
      8.0, 5.0, 10.0, 6.0, 5.0, 15.0, 13.0, 10.0, 6.0, 18.0, 13.0, 14.0, 12.0, 9.0,
      11.0, 12.0, 1.0, 5.0, 5.0, 11.0, 13.0, 10.0, 14.0, 13.0, 11.0, 8.0, 12.0, 9.0,
      10.0, 8.0, 5.0, 8.0, 8.0, 9.0, 5.0, 7.0, 10.0, 11.0, 6.0, 11.0, 9.0, 9.0, 10.0,
      11.0, 8.0, 8.0, 10.0, 4.0, 13.0, 12.0, 8.0, 11.0, 8.0, 12.0, 13.0, 9.0, 5.0,
      9.0, 10.0, 7.0, 11.0, 7.0, 14.0, 10.0, 10.0, 12.0, 5.0, 6.0, 13.0, 6.0, 11.0,
      7.0, 6.0, 12.0, 11.0, 13.0, 10.0, 15.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06520815830776916
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02551428714787635
    mean_inference_ms: 1.2215195765334848
    mean_raw_obs_processing_ms: 0.27756139404891844
time_since_restore: 2618.293795108795
time_this_iter_s: 10.095521926879883
time_total_s: 2618.293795108795
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691996798
timesteps_total: 3168150
training_iteration: 258
trial_id: default
train step: 259
agent_timesteps_total: 3181450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01948018675868951
  StateBufferConnector_ms: 0.0036410915041432796
  ViewRequirementAgentConnector_ms: 0.12018726867379494
counters:
  num_agent_steps_sampled: 3181450
  num_agent_steps_trained: 3164500
  num_env_steps_sampled: 3181450
  num_env_steps_trained: 3164500
  num_samples_added_to_queue: 3181000
  num_training_step_calls_since_last_synch_worker_weights: 850
  num_weight_broadcasts: 62569
custom_metrics: {}
date: 2023-08-14_16-06-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 9.29126213592233
episode_reward_min: 4.0
episodes_this_iter: 103
episodes_total: 24855
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6032260060310364
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 67.63224029541016
        total_loss: 116.70951080322266
        var_gnorm: 64.6891860961914
        vf_explained_var: 0.8916882872581482
        vf_loss: 104.18679809570312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6329.0
  learner_queue:
    size_count: 6335
    size_mean: 15.52
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1178550889985697
  num_agent_steps_sampled: 3181450
  num_agent_steps_trained: 3164500
  num_env_steps_sampled: 3181450
  num_env_steps_trained: 3164500
  num_samples_added_to_queue: 3181000
  num_training_step_calls_since_last_synch_worker_weights: 850
  num_weight_broadcasts: 62569
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 204.693
    learner_load_time_ms: 1.876
    learner_load_wait_time_ms: 1.642
iterations_since_restore: 259
node_ip: 127.0.0.1
num_agent_steps_sampled: 3181450
num_agent_steps_trained: 3164500
num_env_steps_sampled: 3181450
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9988901624404
num_env_steps_trained: 3164500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9989151963703
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.785714285714285
  ram_util_percent: 82.37857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06519058771382534
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025506044328679013
  mean_inference_ms: 1.2211372908103324
  mean_raw_obs_processing_ms: 0.27748317707253584
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01948018675868951
    StateBufferConnector_ms: 0.0036410915041432796
    ViewRequirementAgentConnector_ms: 0.12018726867379494
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 9.29126213592233
  episode_reward_min: 4.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 9.0, 10.0, 8.0, 9.0, 8.0, 5.0, 11.0, 4.0, 13.0, 9.0, 6.0,
      14.0, 7.0, 9.0, 7.0, 5.0, 10.0, 11.0, 10.0, 8.0, 9.0, 10.0, 11.0, 8.0, 4.0,
      9.0, 9.0, 12.0, 10.0, 9.0, 13.0, 5.0, 9.0, 6.0, 5.0, 10.0, 12.0, 11.0, 13.0,
      7.0, 12.0, 10.0, 10.0, 11.0, 8.0, 12.0, 12.0, 8.0, 5.0, 7.0, 9.0, 7.0, 4.0,
      8.0, 8.0, 11.0, 10.0, 5.0, 10.0, 12.0, 14.0, 6.0, 11.0, 10.0, 11.0, 11.0, 13.0,
      9.0, 19.0, 12.0, 7.0, 8.0, 9.0, 12.0, 11.0, 6.0, 11.0, 9.0, 8.0, 10.0, 7.0,
      9.0, 11.0, 7.0, 7.0, 9.0, 13.0, 11.0, 10.0, 9.0, 13.0, 11.0, 10.0, 12.0, 8.0,
      8.0, 6.0, 11.0, 10.0, 10.0, 6.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06519058771382534
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025506044328679013
    mean_inference_ms: 1.2211372908103324
    mean_raw_obs_processing_ms: 0.27748317707253584
time_since_restore: 2628.5063621997833
time_this_iter_s: 10.21256709098816
time_total_s: 2628.5063621997833
timers:
  sample_time_ms: 0.02
  synch_weights_time_ms: 0.006
  training_iteration_time_ms: 0.057
timestamp: 1691996808
timesteps_total: 3181450
training_iteration: 259
trial_id: default
train step: 260
agent_timesteps_total: 3194050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02149367332458496
  StateBufferConnector_ms: 0.004016876220703125
  ViewRequirementAgentConnector_ms: 0.12672877311706543
counters:
  num_agent_steps_sampled: 3194050
  num_agent_steps_trained: 3177500
  num_env_steps_sampled: 3194050
  num_env_steps_trained: 3177500
  num_samples_added_to_queue: 3194000
  num_training_step_calls_since_last_synch_worker_weights: 124
  num_weight_broadcasts: 62816
custom_metrics: {}
date: 2023-08-14_16-06-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 9.39
episode_reward_min: 2.0
episodes_this_iter: 99
episodes_total: 24954
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6408588886260986
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -80.850341796875
        total_loss: -34.83333969116211
        var_gnorm: 64.69110107421875
        vf_explained_var: 0.8878567218780518
        vf_loss: 98.44259643554688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6355.0
  learner_queue:
    size_count: 6362
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6326665305566843
  num_agent_steps_sampled: 3194050
  num_agent_steps_trained: 3177500
  num_env_steps_sampled: 3194050
  num_env_steps_trained: 3177500
  num_samples_added_to_queue: 3194000
  num_training_step_calls_since_last_synch_worker_weights: 124
  num_weight_broadcasts: 62816
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 135.35
    learner_load_time_ms: 2.277
    learner_load_wait_time_ms: 1.591
iterations_since_restore: 260
node_ip: 127.0.0.1
num_agent_steps_sampled: 3194050
num_agent_steps_trained: 3177500
num_env_steps_sampled: 3194050
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.989936432154
num_env_steps_trained: 3177500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9896169538097
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.10666666666666
  ram_util_percent: 82.86666666666665
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06518344808318025
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025507372258629958
  mean_inference_ms: 1.2210271032214772
  mean_raw_obs_processing_ms: 0.2774612798287903
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02149367332458496
    StateBufferConnector_ms: 0.004016876220703125
    ViewRequirementAgentConnector_ms: 0.12672877311706543
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 9.39
  episode_reward_min: 2.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 8.0, 10.0, 10.0, 8.0, 13.0, 11.0, 8.0, 7.0, 11.0, 8.0, 14.0,
      8.0, 10.0, 10.0, 5.0, 11.0, 13.0, 19.0, 10.0, 7.0, 10.0, 10.0, 13.0, 12.0, 14.0,
      8.0, 13.0, 9.0, 6.0, 7.0, 8.0, 9.0, 7.0, 12.0, 8.0, 4.0, 9.0, 10.0, 10.0, 6.0,
      6.0, 5.0, 6.0, 6.0, 14.0, 7.0, 9.0, 14.0, 5.0, 12.0, 7.0, 9.0, 2.0, 14.0, 8.0,
      11.0, 8.0, 6.0, 11.0, 8.0, 12.0, 8.0, 12.0, 14.0, 7.0, 8.0, 14.0, 9.0, 7.0,
      13.0, 9.0, 13.0, 8.0, 11.0, 11.0, 7.0, 8.0, 8.0, 10.0, 16.0, 11.0, 11.0, 7.0,
      7.0, 15.0, 7.0, 4.0, 14.0, 9.0, 8.0, 8.0, 7.0, 3.0, 10.0, 8.0, 7.0, 15.0, 10.0,
      10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06518344808318025
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025507372258629958
    mean_inference_ms: 1.2210271032214772
    mean_raw_obs_processing_ms: 0.2774612798287903
time_since_restore: 2638.691414117813
time_this_iter_s: 10.185051918029785
time_total_s: 2638.691414117813
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.052
timestamp: 1691996819
timesteps_total: 3194050
training_iteration: 260
trial_id: default
train step: 261
agent_timesteps_total: 3206700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021154165267944336
  StateBufferConnector_ms: 0.0038459300994873047
  ViewRequirementAgentConnector_ms: 0.12714934349060059
counters:
  num_agent_steps_sampled: 3206700
  num_agent_steps_trained: 3190000
  num_env_steps_sampled: 3206700
  num_env_steps_trained: 3190000
  num_samples_added_to_queue: 3206500
  num_training_step_calls_since_last_synch_worker_weights: 1122
  num_weight_broadcasts: 63066
custom_metrics: {}
date: 2023-08-14_16-07-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.43
episode_reward_min: 3.0
episodes_this_iter: 99
episodes_total: 25053
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6621266603469849
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -38.49454116821289
        total_loss: 51.68633270263672
        var_gnorm: 64.68913269042969
        vf_explained_var: 0.7785038948059082
        vf_loss: 186.98301696777344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6380.0
  learner_queue:
    size_count: 6386
    size_mean: 14.92
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.787064632295094
  num_agent_steps_sampled: 3206700
  num_agent_steps_trained: 3190000
  num_env_steps_sampled: 3206700
  num_env_steps_trained: 3190000
  num_samples_added_to_queue: 3206500
  num_training_step_calls_since_last_synch_worker_weights: 1122
  num_weight_broadcasts: 63066
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 190.236
    learner_load_time_ms: 2.098
    learner_load_wait_time_ms: 1.656
iterations_since_restore: 261
node_ip: 127.0.0.1
num_agent_steps_sampled: 3206700
num_agent_steps_trained: 3190000
num_env_steps_sampled: 3206700
num_env_steps_sampled_this_iter: 12650
num_env_steps_sampled_throughput_per_sec: 1264.999607920768
num_env_steps_trained: 3190000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.999612569929
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.05
  ram_util_percent: 82.93571428571428
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0651821854822888
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025506992398425403
  mean_inference_ms: 1.220861772791559
  mean_raw_obs_processing_ms: 0.2774307032388172
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021154165267944336
    StateBufferConnector_ms: 0.0038459300994873047
    ViewRequirementAgentConnector_ms: 0.12714934349060059
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.43
  episode_reward_min: 3.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 12.0, 8.0, 9.0, 10.0, 6.0, 10.0, 10.0, 10.0, 10.0, 9.0,
      17.0, 13.0, 9.0, 11.0, 5.0, 3.0, 11.0, 10.0, 8.0, 9.0, 9.0, 8.0, 9.0, 11.0,
      8.0, 4.0, 13.0, 11.0, 9.0, 12.0, 4.0, 5.0, 10.0, 11.0, 10.0, 8.0, 7.0, 7.0,
      10.0, 5.0, 7.0, 8.0, 6.0, 17.0, 17.0, 9.0, 5.0, 12.0, 11.0, 9.0, 11.0, 11.0,
      13.0, 9.0, 13.0, 10.0, 12.0, 9.0, 11.0, 8.0, 10.0, 9.0, 8.0, 7.0, 10.0, 10.0,
      6.0, 8.0, 9.0, 10.0, 10.0, 10.0, 9.0, 6.0, 12.0, 8.0, 9.0, 8.0, 7.0, 10.0, 7.0,
      11.0, 12.0, 16.0, 10.0, 12.0, 6.0, 8.0, 7.0, 6.0, 8.0, 9.0, 11.0, 8.0, 15.0,
      11.0, 12.0, 8.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0651821854822888
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025506992398425403
    mean_inference_ms: 1.220861772791559
    mean_raw_obs_processing_ms: 0.2774307032388172
time_since_restore: 2648.834856033325
time_this_iter_s: 10.143441915512085
time_total_s: 2648.834856033325
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691996829
timesteps_total: 3206700
training_iteration: 261
trial_id: default
train step: 262
agent_timesteps_total: 3220050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01964569091796875
  StateBufferConnector_ms: 0.00350906735374814
  ViewRequirementAgentConnector_ms: 0.1186091559273856
counters:
  num_agent_steps_sampled: 3220050
  num_agent_steps_trained: 3203500
  num_env_steps_sampled: 3220050
  num_env_steps_trained: 3203500
  num_samples_added_to_queue: 3220000
  num_training_step_calls_since_last_synch_worker_weights: 781
  num_weight_broadcasts: 63330
custom_metrics: {}
date: 2023-08-14_16-07-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.514285714285714
episode_reward_min: 3.0
episodes_this_iter: 105
episodes_total: 25158
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6610504984855652
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.19715404510498
        total_loss: 70.66471099853516
        var_gnorm: 64.69140625
        vf_explained_var: 0.811259388923645
        vf_loss: 170.334228515625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6407.0
  learner_queue:
    size_count: 6413
    size_mean: 15.08
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.547126368465097
  num_agent_steps_sampled: 3220050
  num_agent_steps_trained: 3203500
  num_env_steps_sampled: 3220050
  num_env_steps_trained: 3203500
  num_samples_added_to_queue: 3220000
  num_training_step_calls_since_last_synch_worker_weights: 781
  num_weight_broadcasts: 63330
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 169.33
    learner_load_time_ms: 2.085
    learner_load_wait_time_ms: 1.613
iterations_since_restore: 262
node_ip: 127.0.0.1
num_agent_steps_sampled: 3220050
num_agent_steps_trained: 3203500
num_env_steps_sampled: 3220050
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9947482554087
num_env_steps_trained: 3203500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9946892470425
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.78571428571429
  ram_util_percent: 81.96428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06515326145124228
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025498544935018536
  mean_inference_ms: 1.2204617033722702
  mean_raw_obs_processing_ms: 0.27734855891725146
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01964569091796875
    StateBufferConnector_ms: 0.00350906735374814
    ViewRequirementAgentConnector_ms: 0.1186091559273856
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.514285714285714
  episode_reward_min: 3.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 10.0, 6.0, 13.0, 9.0, 10.0, 12.0, 8.0, 11.0, 8.0, 9.0,
      12.0, 9.0, 12.0, 11.0, 6.0, 6.0, 10.0, 10.0, 14.0, 10.0, 9.0, 11.0, 8.0, 7.0,
      12.0, 9.0, 8.0, 9.0, 8.0, 14.0, 12.0, 6.0, 13.0, 8.0, 8.0, 11.0, 10.0, 10.0,
      11.0, 9.0, 9.0, 8.0, 12.0, 7.0, 15.0, 10.0, 7.0, 7.0, 10.0, 9.0, 11.0, 10.0,
      13.0, 14.0, 4.0, 8.0, 5.0, 3.0, 7.0, 15.0, 13.0, 7.0, 10.0, 7.0, 8.0, 11.0,
      10.0, 7.0, 7.0, 13.0, 8.0, 6.0, 10.0, 16.0, 8.0, 5.0, 9.0, 5.0, 9.0, 13.0, 11.0,
      7.0, 12.0, 9.0, 10.0, 12.0, 9.0, 5.0, 18.0, 11.0, 14.0, 8.0, 15.0, 7.0, 6.0,
      10.0, 8.0, 8.0, 11.0, 11.0, 9.0, 5.0, 6.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06515326145124228
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025498544935018536
    mean_inference_ms: 1.2204617033722702
    mean_raw_obs_processing_ms: 0.27734855891725146
time_since_restore: 2658.9775202274323
time_this_iter_s: 10.142664194107056
time_total_s: 2658.9775202274323
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691996839
timesteps_total: 3220050
training_iteration: 262
trial_id: default
train step: 263
agent_timesteps_total: 3233650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01863511103504109
  StateBufferConnector_ms: 0.0033047963988106204
  ViewRequirementAgentConnector_ms: 0.11492090405158277
counters:
  num_agent_steps_sampled: 3233650
  num_agent_steps_trained: 3217000
  num_env_steps_sampled: 3233650
  num_env_steps_trained: 3217000
  num_samples_added_to_queue: 3233500
  num_training_step_calls_since_last_synch_worker_weights: 298
  num_weight_broadcasts: 63599
custom_metrics: {}
date: 2023-08-14_16-07-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.518867924528301
episode_reward_min: 4.0
episodes_this_iter: 106
episodes_total: 25264
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6513220071792603
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 39.79547119140625
        total_loss: 81.75645446777344
        var_gnorm: 64.69095611572266
        vf_explained_var: 0.8757888078689575
        vf_loss: 90.43517303466797
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6434.0
  learner_queue:
    size_count: 6441
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6326665305566843
  num_agent_steps_sampled: 3233650
  num_agent_steps_trained: 3217000
  num_env_steps_sampled: 3233650
  num_env_steps_trained: 3217000
  num_samples_added_to_queue: 3233500
  num_training_step_calls_since_last_synch_worker_weights: 298
  num_weight_broadcasts: 63599
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 134.684
    learner_load_time_ms: 4.524
    learner_load_wait_time_ms: 1.525
iterations_since_restore: 263
node_ip: 127.0.0.1
num_agent_steps_sampled: 3233650
num_agent_steps_trained: 3217000
num_env_steps_sampled: 3233650
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9938717164575
num_env_steps_trained: 3217000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.993916777366
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.16666666666667
  ram_util_percent: 81.17999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06512708644218486
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025486193087010476
  mean_inference_ms: 1.2199723587438196
  mean_raw_obs_processing_ms: 0.2772351014564481
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01863511103504109
    StateBufferConnector_ms: 0.0033047963988106204
    ViewRequirementAgentConnector_ms: 0.11492090405158277
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.518867924528301
  episode_reward_min: 4.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 6.0, 13.0, 12.0, 8.0, 11.0, 13.0, 9.0, 13.0, 12.0, 10.0,
      9.0, 9.0, 16.0, 13.0, 10.0, 13.0, 10.0, 9.0, 5.0, 11.0, 9.0, 12.0, 11.0, 9.0,
      11.0, 12.0, 6.0, 5.0, 10.0, 8.0, 8.0, 7.0, 10.0, 10.0, 9.0, 12.0, 11.0, 5.0,
      11.0, 9.0, 8.0, 11.0, 9.0, 12.0, 9.0, 9.0, 11.0, 12.0, 12.0, 12.0, 8.0, 12.0,
      8.0, 11.0, 5.0, 6.0, 7.0, 9.0, 9.0, 11.0, 13.0, 7.0, 8.0, 7.0, 12.0, 12.0, 12.0,
      12.0, 10.0, 5.0, 11.0, 11.0, 6.0, 7.0, 11.0, 4.0, 6.0, 9.0, 7.0, 10.0, 8.0,
      7.0, 9.0, 13.0, 5.0, 14.0, 9.0, 10.0, 10.0, 7.0, 9.0, 5.0, 12.0, 13.0, 8.0,
      9.0, 12.0, 7.0, 12.0, 8.0, 11.0, 10.0, 9.0, 11.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06512708644218486
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025486193087010476
    mean_inference_ms: 1.2199723587438196
    mean_raw_obs_processing_ms: 0.2772351014564481
time_since_restore: 2669.1496303081512
time_this_iter_s: 10.172110080718994
time_total_s: 2669.1496303081512
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996849
timesteps_total: 3233650
training_iteration: 263
trial_id: default
train step: 264
agent_timesteps_total: 3246650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020389509673165804
  StateBufferConnector_ms: 0.0035191526507387066
  ViewRequirementAgentConnector_ms: 0.12034024342451946
counters:
  num_agent_steps_sampled: 3246650
  num_agent_steps_trained: 3230000
  num_env_steps_sampled: 3246650
  num_env_steps_trained: 3230000
  num_samples_added_to_queue: 3246500
  num_training_step_calls_since_last_synch_worker_weights: 232
  num_weight_broadcasts: 63854
custom_metrics: {}
date: 2023-08-14_16-07-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.366336633663366
episode_reward_min: 3.0
episodes_this_iter: 101
episodes_total: 25365
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6741189956665039
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -4.662487983703613
        total_loss: 49.43570327758789
        var_gnorm: 64.6905288696289
        vf_explained_var: 0.8137260675430298
        vf_loss: 114.93756866455078
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6460.0
  learner_queue:
    size_count: 6468
    size_mean: 14.74
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.0669784711022032
  num_agent_steps_sampled: 3246650
  num_agent_steps_trained: 3230000
  num_env_steps_sampled: 3246650
  num_env_steps_trained: 3230000
  num_samples_added_to_queue: 3246500
  num_training_step_calls_since_last_synch_worker_weights: 232
  num_weight_broadcasts: 63854
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 110.751
    learner_load_time_ms: 4.451
    learner_load_wait_time_ms: 1.564
iterations_since_restore: 264
node_ip: 127.0.0.1
num_agent_steps_sampled: 3246650
num_agent_steps_trained: 3230000
num_env_steps_sampled: 3246650
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9968695715945
num_env_steps_trained: 3230000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9968695715945
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.78571428571429
  ram_util_percent: 82.08571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06511064491665644
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02548139042023871
  mean_inference_ms: 1.2197365543626264
  mean_raw_obs_processing_ms: 0.27718311857473615
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020389509673165804
    StateBufferConnector_ms: 0.0035191526507387066
    ViewRequirementAgentConnector_ms: 0.12034024342451946
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.366336633663366
  episode_reward_min: 3.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 11.0, 10.0, 9.0, 6.0, 8.0, 7.0, 16.0, 10.0, 13.0, 10.0,
      8.0, 8.0, 11.0, 8.0, 11.0, 6.0, 11.0, 8.0, 9.0, 12.0, 11.0, 12.0, 9.0, 3.0,
      10.0, 12.0, 7.0, 8.0, 12.0, 9.0, 11.0, 10.0, 10.0, 7.0, 10.0, 7.0, 9.0, 8.0,
      7.0, 9.0, 9.0, 10.0, 11.0, 5.0, 13.0, 8.0, 5.0, 9.0, 8.0, 4.0, 14.0, 9.0, 5.0,
      9.0, 13.0, 14.0, 9.0, 10.0, 8.0, 7.0, 11.0, 12.0, 10.0, 12.0, 6.0, 9.0, 5.0,
      11.0, 11.0, 3.0, 7.0, 10.0, 12.0, 12.0, 9.0, 8.0, 8.0, 9.0, 16.0, 10.0, 12.0,
      11.0, 8.0, 14.0, 13.0, 10.0, 12.0, 13.0, 8.0, 8.0, 7.0, 10.0, 7.0, 9.0, 5.0,
      12.0, 9.0, 10.0, 7.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06511064491665644
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02548139042023871
    mean_inference_ms: 1.2197365543626264
    mean_raw_obs_processing_ms: 0.27718311857473615
time_since_restore: 2679.349092245102
time_this_iter_s: 10.199461936950684
time_total_s: 2679.349092245102
timers:
  sample_time_ms: 0.019
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.053
timestamp: 1691996859
timesteps_total: 3246650
training_iteration: 264
trial_id: default
train step: 265
agent_timesteps_total: 3258750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02194833755493164
  StateBufferConnector_ms: 0.003786325454711914
  ViewRequirementAgentConnector_ms: 0.1315901279449463
counters:
  num_agent_steps_sampled: 3258750
  num_agent_steps_trained: 3242000
  num_env_steps_sampled: 3258750
  num_env_steps_trained: 3242000
  num_samples_added_to_queue: 3258500
  num_training_step_calls_since_last_synch_worker_weights: 691
  num_weight_broadcasts: 64092
custom_metrics: {}
date: 2023-08-14_16-07-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.15
episode_reward_min: 3.0
episodes_this_iter: 95
episodes_total: 25460
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6699203848838806
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 16.670989990234375
        total_loss: 65.19684600830078
        var_gnorm: 64.68687438964844
        vf_explained_var: 0.8636225461959839
        vf_loss: 103.75090789794922
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6484.0
  learner_queue:
    size_count: 6491
    size_mean: 14.44
    size_quantiles: [9.0, 10.9, 16.0, 16.0, 16.0]
    size_std: 2.201454064930722
  num_agent_steps_sampled: 3258750
  num_agent_steps_trained: 3242000
  num_env_steps_sampled: 3258750
  num_env_steps_trained: 3242000
  num_samples_added_to_queue: 3258500
  num_training_step_calls_since_last_synch_worker_weights: 691
  num_weight_broadcasts: 64092
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 172.952
    learner_load_time_ms: 4.459
    learner_load_wait_time_ms: 1.919
iterations_since_restore: 265
node_ip: 127.0.0.1
num_agent_steps_sampled: 3258750
num_agent_steps_trained: 3242000
num_env_steps_sampled: 3258750
num_env_steps_sampled_this_iter: 12100
num_env_steps_sampled_throughput_per_sec: 1209.997086293561
num_env_steps_trained: 3242000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9971103737796
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.97857142857142
  ram_util_percent: 82.78571428571426
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06513218163560369
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025485166931122922
  mean_inference_ms: 1.219785167314764
  mean_raw_obs_processing_ms: 0.277208094530865
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02194833755493164
    StateBufferConnector_ms: 0.003786325454711914
    ViewRequirementAgentConnector_ms: 0.1315901279449463
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.15
  episode_reward_min: 3.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 9.0, 10.0, 7.0, 8.0, 6.0, 11.0, 4.0, 12.0, 11.0, 9.0, 10.0,
      9.0, 8.0, 12.0, 5.0, 7.0, 11.0, 7.0, 14.0, 7.0, 8.0, 13.0, 9.0, 10.0, 11.0,
      12.0, 12.0, 10.0, 5.0, 7.0, 15.0, 10.0, 6.0, 8.0, 7.0, 7.0, 10.0, 8.0, 10.0,
      16.0, 14.0, 5.0, 5.0, 11.0, 11.0, 10.0, 7.0, 11.0, 13.0, 7.0, 10.0, 9.0, 9.0,
      6.0, 11.0, 6.0, 10.0, 11.0, 7.0, 9.0, 6.0, 9.0, 8.0, 10.0, 8.0, 12.0, 3.0, 9.0,
      11.0, 14.0, 7.0, 5.0, 10.0, 8.0, 9.0, 6.0, 7.0, 8.0, 9.0, 8.0, 13.0, 13.0, 10.0,
      7.0, 10.0, 11.0, 9.0, 5.0, 8.0, 10.0, 11.0, 7.0, 12.0, 8.0, 10.0, 13.0, 8.0,
      9.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06513218163560369
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025485166931122922
    mean_inference_ms: 1.219785167314764
    mean_raw_obs_processing_ms: 0.277208094530865
time_since_restore: 2689.5805990695953
time_this_iter_s: 10.231506824493408
time_total_s: 2689.5805990695953
timers:
  sample_time_ms: 0.022
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.06
timestamp: 1691996870
timesteps_total: 3258750
training_iteration: 265
trial_id: default
train step: 266
agent_timesteps_total: 3271300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021115541458129883
  StateBufferConnector_ms: 0.0037186145782470703
  ViewRequirementAgentConnector_ms: 0.12810420989990234
counters:
  num_agent_steps_sampled: 3271300
  num_agent_steps_trained: 3254500
  num_env_steps_sampled: 3271300
  num_env_steps_trained: 3254500
  num_samples_added_to_queue: 3271000
  num_training_step_calls_since_last_synch_worker_weights: 1424
  num_weight_broadcasts: 64340
custom_metrics: {}
date: 2023-08-14_16-08-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.92
episode_reward_min: 3.0
episodes_this_iter: 98
episodes_total: 25558
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.656453013420105
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 51.00080871582031
        total_loss: 130.89808654785156
        var_gnorm: 64.68975830078125
        vf_explained_var: 0.8053300976753235
        vf_loss: 166.35910034179688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6509.0
  learner_queue:
    size_count: 6514
    size_mean: 14.44
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.1648094604375694
  num_agent_steps_sampled: 3271300
  num_agent_steps_trained: 3254500
  num_env_steps_sampled: 3271300
  num_env_steps_trained: 3254500
  num_samples_added_to_queue: 3271000
  num_training_step_calls_since_last_synch_worker_weights: 1424
  num_weight_broadcasts: 64340
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 231.488
    learner_load_time_ms: 4.048
    learner_load_wait_time_ms: 1.495
iterations_since_restore: 266
node_ip: 127.0.0.1
num_agent_steps_sampled: 3271300
num_agent_steps_trained: 3254500
num_env_steps_sampled: 3271300
num_env_steps_sampled_this_iter: 12550
num_env_steps_sampled_throughput_per_sec: 1254.9975763606146
num_env_steps_trained: 3254500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9975860165484
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.82
  ram_util_percent: 83.45333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06511821364295443
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02548599433533158
  mean_inference_ms: 1.21970806867464
  mean_raw_obs_processing_ms: 0.27719170791665626
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021115541458129883
    StateBufferConnector_ms: 0.0037186145782470703
    ViewRequirementAgentConnector_ms: 0.12810420989990234
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.92
  episode_reward_min: 3.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 9.0, 10.0, 6.0, 10.0, 11.0, 13.0, 3.0, 5.0, 5.0, 7.0, 11.0,
      8.0, 6.0, 9.0, 7.0, 6.0, 9.0, 10.0, 13.0, 7.0, 5.0, 11.0, 9.0, 7.0, 8.0, 10.0,
      6.0, 13.0, 13.0, 4.0, 13.0, 9.0, 8.0, 10.0, 10.0, 5.0, 10.0, 10.0, 8.0, 7.0,
      8.0, 8.0, 9.0, 3.0, 13.0, 11.0, 12.0, 7.0, 10.0, 13.0, 11.0, 7.0, 5.0, 12.0,
      10.0, 7.0, 13.0, 13.0, 9.0, 5.0, 6.0, 7.0, 10.0, 5.0, 9.0, 9.0, 10.0, 16.0,
      12.0, 9.0, 16.0, 10.0, 5.0, 13.0, 11.0, 6.0, 10.0, 9.0, 4.0, 8.0, 8.0, 10.0,
      9.0, 9.0, 7.0, 11.0, 6.0, 14.0, 9.0, 10.0, 10.0, 17.0, 5.0, 5.0, 5.0, 14.0,
      6.0, 8.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06511821364295443
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02548599433533158
    mean_inference_ms: 1.21970806867464
    mean_raw_obs_processing_ms: 0.27719170791665626
time_since_restore: 2699.7119171619415
time_this_iter_s: 10.131318092346191
time_total_s: 2699.7119171619415
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691996880
timesteps_total: 3271300
training_iteration: 266
trial_id: default
train step: 267
agent_timesteps_total: 3282600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02255415916442871
  StateBufferConnector_ms: 0.005491495132446289
  ViewRequirementAgentConnector_ms: 0.13750052452087402
counters:
  num_agent_steps_sampled: 3282600
  num_agent_steps_trained: 3266000
  num_env_steps_sampled: 3282600
  num_env_steps_trained: 3266000
  num_samples_added_to_queue: 3282500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 64563
custom_metrics: {}
date: 2023-08-14_16-08-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.44
episode_reward_min: 4.0
episodes_this_iter: 87
episodes_total: 25645
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6462129950523376
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 50.06542205810547
        total_loss: 125.62086486816406
        var_gnorm: 64.6945571899414
        vf_explained_var: 0.8234899044036865
        vf_loss: 157.57301330566406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6532.0
  learner_queue:
    size_count: 6537
    size_mean: 14.96
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6728418933061189
  num_agent_steps_sampled: 3282600
  num_agent_steps_trained: 3266000
  num_env_steps_sampled: 3282600
  num_env_steps_trained: 3266000
  num_samples_added_to_queue: 3282500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 64563
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 283.712
    learner_load_time_ms: 4.053
    learner_load_wait_time_ms: 1.768
iterations_since_restore: 267
node_ip: 127.0.0.1
num_agent_steps_sampled: 3282600
num_agent_steps_trained: 3266000
num_env_steps_sampled: 3282600
num_env_steps_sampled_this_iter: 11300
num_env_steps_sampled_throughput_per_sec: 1129.8548050546826
num_env_steps_trained: 3266000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.8522352326415
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 62.192857142857136
  ram_util_percent: 83.52857142857144
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06516186189829769
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025494657788299912
  mean_inference_ms: 1.2199701733583452
  mean_raw_obs_processing_ms: 0.2772596669276789
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02255415916442871
    StateBufferConnector_ms: 0.005491495132446289
    ViewRequirementAgentConnector_ms: 0.13750052452087402
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.44
  episode_reward_min: 4.0
  episodes_this_iter: 87
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 14.0, 9.0, 10.0, 10.0, 17.0, 5.0, 5.0, 5.0, 14.0, 6.0, 8.0,
      8.0, 12.0, 12.0, 7.0, 10.0, 9.0, 8.0, 10.0, 8.0, 6.0, 9.0, 7.0, 6.0, 14.0, 10.0,
      12.0, 11.0, 12.0, 11.0, 6.0, 8.0, 10.0, 18.0, 10.0, 13.0, 10.0, 9.0, 9.0, 8.0,
      9.0, 10.0, 8.0, 11.0, 8.0, 7.0, 6.0, 7.0, 6.0, 11.0, 13.0, 9.0, 5.0, 13.0, 12.0,
      12.0, 5.0, 10.0, 9.0, 9.0, 11.0, 10.0, 5.0, 14.0, 10.0, 9.0, 9.0, 10.0, 8.0,
      10.0, 10.0, 13.0, 11.0, 10.0, 11.0, 6.0, 4.0, 9.0, 10.0, 6.0, 10.0, 11.0, 10.0,
      14.0, 7.0, 9.0, 12.0, 10.0, 11.0, 7.0, 14.0, 8.0, 7.0, 12.0, 10.0, 9.0, 9.0,
      7.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06516186189829769
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025494657788299912
    mean_inference_ms: 1.2199701733583452
    mean_raw_obs_processing_ms: 0.2772596669276789
time_since_restore: 2709.839353084564
time_this_iter_s: 10.12743592262268
time_total_s: 2709.839353084564
timers:
  sample_time_ms: 0.042
  synch_weights_time_ms: 0.266
  training_iteration_time_ms: 0.383
timestamp: 1691996890
timesteps_total: 3282600
training_iteration: 267
trial_id: default
train step: 268
agent_timesteps_total: 3294800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0217893123626709
  StateBufferConnector_ms: 0.003941535949707031
  ViewRequirementAgentConnector_ms: 0.13379526138305664
counters:
  num_agent_steps_sampled: 3294800
  num_agent_steps_trained: 3278000
  num_env_steps_sampled: 3294800
  num_env_steps_trained: 3278000
  num_samples_added_to_queue: 3294500
  num_training_step_calls_since_last_synch_worker_weights: 817
  num_weight_broadcasts: 64805
custom_metrics: {}
date: 2023-08-14_16-08-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.85
episode_reward_min: 4.0
episodes_this_iter: 96
episodes_total: 25741
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6429265141487122
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.40107154846191406
        total_loss: 75.93991088867188
        var_gnorm: 64.69682312011719
        vf_explained_var: 0.8102865219116211
        vf_loss: 159.11122131347656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6556.0
  learner_queue:
    size_count: 6562
    size_mean: 15.18
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4098226838861685
  num_agent_steps_sampled: 3294800
  num_agent_steps_trained: 3278000
  num_env_steps_sampled: 3294800
  num_env_steps_trained: 3278000
  num_samples_added_to_queue: 3294500
  num_training_step_calls_since_last_synch_worker_weights: 817
  num_weight_broadcasts: 64805
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 217.782
    learner_load_time_ms: 4.082
    learner_load_wait_time_ms: 1.749
iterations_since_restore: 268
node_ip: 127.0.0.1
num_agent_steps_sampled: 3294800
num_agent_steps_trained: 3278000
num_env_steps_sampled: 3294800
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.9943862219682
num_env_steps_trained: 3278000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.994478251116
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.028571428571425
  ram_util_percent: 83.32142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06514729152379349
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02550112927364634
  mean_inference_ms: 1.2200879771131077
  mean_raw_obs_processing_ms: 0.2772802579302895
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0217893123626709
    StateBufferConnector_ms: 0.003941535949707031
    ViewRequirementAgentConnector_ms: 0.13379526138305664
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.85
  episode_reward_min: 4.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 9.0, 7.0, 9.0, 10.0, 9.0, 8.0, 7.0, 9.0, 8.0, 13.0, 6.0,
      9.0, 8.0, 8.0, 10.0, 14.0, 10.0, 14.0, 11.0, 10.0, 9.0, 10.0, 9.0, 8.0, 12.0,
      9.0, 12.0, 11.0, 11.0, 4.0, 5.0, 12.0, 5.0, 4.0, 9.0, 6.0, 10.0, 7.0, 6.0, 5.0,
      5.0, 11.0, 9.0, 8.0, 5.0, 9.0, 11.0, 8.0, 7.0, 11.0, 11.0, 11.0, 10.0, 10.0,
      12.0, 8.0, 8.0, 10.0, 8.0, 14.0, 12.0, 10.0, 5.0, 6.0, 9.0, 14.0, 6.0, 10.0,
      5.0, 8.0, 8.0, 7.0, 7.0, 11.0, 10.0, 10.0, 7.0, 14.0, 11.0, 6.0, 9.0, 4.0, 11.0,
      10.0, 8.0, 12.0, 5.0, 5.0, 10.0, 7.0, 8.0, 13.0, 10.0, 8.0, 7.0, 6.0, 9.0, 9.0,
      10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06514729152379349
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02550112927364634
    mean_inference_ms: 1.2200879771131077
    mean_raw_obs_processing_ms: 0.2772802579302895
time_since_restore: 2720.0245230197906
time_this_iter_s: 10.18516993522644
time_total_s: 2720.0245230197906
timers:
  sample_time_ms: 0.019
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.052
timestamp: 1691996900
timesteps_total: 3294800
training_iteration: 268
trial_id: default
train step: 269
agent_timesteps_total: 3307450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021085500717163086
  StateBufferConnector_ms: 0.0037963390350341797
  ViewRequirementAgentConnector_ms: 0.12557053565979004
counters:
  num_agent_steps_sampled: 3307450
  num_agent_steps_trained: 3290500
  num_env_steps_sampled: 3307450
  num_env_steps_trained: 3290500
  num_samples_added_to_queue: 3307000
  num_training_step_calls_since_last_synch_worker_weights: 136
  num_weight_broadcasts: 65055
custom_metrics: {}
date: 2023-08-14_16-08-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 9.16
episode_reward_min: 4.0
episodes_this_iter: 99
episodes_total: 25840
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6702367067337036
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -27.909198760986328
        total_loss: 2.641061305999756
        var_gnorm: 64.70245361328125
        vf_explained_var: 0.9216755628585815
        vf_loss: 67.80288696289062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6581.0
  learner_queue:
    size_count: 6588
    size_mean: 15.14
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.587576769797291
  num_agent_steps_sampled: 3307450
  num_agent_steps_trained: 3290500
  num_env_steps_sampled: 3307450
  num_env_steps_trained: 3290500
  num_samples_added_to_queue: 3307000
  num_training_step_calls_since_last_synch_worker_weights: 136
  num_weight_broadcasts: 65055
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 151.896
    learner_load_time_ms: 1.421
    learner_load_wait_time_ms: 1.474
iterations_since_restore: 269
node_ip: 127.0.0.1
num_agent_steps_sampled: 3307450
num_agent_steps_trained: 3290500
num_env_steps_sampled: 3307450
num_env_steps_sampled_this_iter: 12650
num_env_steps_sampled_throughput_per_sec: 1264.9945410725609
num_env_steps_trained: 3290500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.994605802926
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 51.760000000000005
  ram_util_percent: 83.98666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06512979738393829
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025499393313316833
  mean_inference_ms: 1.2199722274802711
  mean_raw_obs_processing_ms: 0.27725356683243013
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021085500717163086
    StateBufferConnector_ms: 0.0037963390350341797
    ViewRequirementAgentConnector_ms: 0.12557053565979004
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 9.16
  episode_reward_min: 4.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 9.0, 9.0, 8.0, 5.0, 6.0, 7.0, 9.0, 12.0, 10.0, 6.0, 10.0,
      7.0, 10.0, 11.0, 9.0, 14.0, 4.0, 11.0, 11.0, 10.0, 13.0, 9.0, 9.0, 8.0, 7.0,
      11.0, 5.0, 9.0, 7.0, 9.0, 12.0, 14.0, 9.0, 11.0, 10.0, 7.0, 4.0, 7.0, 9.0, 5.0,
      9.0, 8.0, 9.0, 5.0, 8.0, 11.0, 6.0, 5.0, 10.0, 12.0, 10.0, 4.0, 19.0, 10.0,
      12.0, 9.0, 8.0, 8.0, 12.0, 8.0, 5.0, 16.0, 13.0, 6.0, 9.0, 6.0, 10.0, 10.0,
      10.0, 8.0, 4.0, 10.0, 12.0, 18.0, 13.0, 10.0, 12.0, 13.0, 10.0, 12.0, 10.0,
      13.0, 4.0, 5.0, 9.0, 7.0, 9.0, 14.0, 10.0, 11.0, 10.0, 9.0, 5.0, 9.0, 8.0, 6.0,
      6.0, 6.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06512979738393829
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025499393313316833
    mean_inference_ms: 1.2199722274802711
    mean_raw_obs_processing_ms: 0.27725356683243013
time_since_restore: 2730.1691031455994
time_this_iter_s: 10.144580125808716
time_total_s: 2730.1691031455994
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996910
timesteps_total: 3307450
training_iteration: 269
trial_id: default
train step: 270
agent_timesteps_total: 3320150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020239591598510742
  StateBufferConnector_ms: 0.0036935806274414062
  ViewRequirementAgentConnector_ms: 0.12352204322814941
counters:
  num_agent_steps_sampled: 3320150
  num_agent_steps_trained: 3303500
  num_env_steps_sampled: 3320150
  num_env_steps_trained: 3303500
  num_samples_added_to_queue: 3320000
  num_training_step_calls_since_last_synch_worker_weights: 263
  num_weight_broadcasts: 65306
custom_metrics: {}
date: 2023-08-14_16-08-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.58
episode_reward_min: 3.0
episodes_this_iter: 99
episodes_total: 25939
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6060331463813782
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -54.20358657836914
        total_loss: 12.50700855255127
        var_gnorm: 64.71437072753906
        vf_explained_var: 0.8459509611129761
        vf_loss: 139.4815216064453
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6607.0
  learner_queue:
    size_count: 6614
    size_mean: 14.96
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8216476058777122
  num_agent_steps_sampled: 3320150
  num_agent_steps_trained: 3303500
  num_env_steps_sampled: 3320150
  num_env_steps_trained: 3303500
  num_samples_added_to_queue: 3320000
  num_training_step_calls_since_last_synch_worker_weights: 263
  num_weight_broadcasts: 65306
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 138.618
    learner_load_time_ms: 6.978
    learner_load_wait_time_ms: 1.563
iterations_since_restore: 270
node_ip: 127.0.0.1
num_agent_steps_sampled: 3320150
num_agent_steps_trained: 3303500
num_env_steps_sampled: 3320150
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.996669301185
num_env_steps_trained: 3303500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9965906232603
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.03571428571429
  ram_util_percent: 84.09285714285716
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06512619978917715
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025496683732391744
  mean_inference_ms: 1.2198106121543966
  mean_raw_obs_processing_ms: 0.2772192792707858
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020239591598510742
    StateBufferConnector_ms: 0.0036935806274414062
    ViewRequirementAgentConnector_ms: 0.12352204322814941
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.58
  episode_reward_min: 3.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 6.0, 4.0, 10.0, 17.0, 5.0, 11.0, 7.0, 10.0, 11.0, 10.0,
      4.0, 8.0, 10.0, 9.0, 11.0, 8.0, 12.0, 9.0, 5.0, 7.0, 7.0, 7.0, 5.0, 9.0, 9.0,
      10.0, 11.0, 7.0, 7.0, 8.0, 9.0, 8.0, 11.0, 9.0, 10.0, 8.0, 8.0, 9.0, 6.0, 6.0,
      7.0, 11.0, 11.0, 11.0, 6.0, 5.0, 6.0, 8.0, 8.0, 13.0, 10.0, 9.0, 5.0, 11.0,
      8.0, 12.0, 12.0, 8.0, 5.0, 10.0, 6.0, 9.0, 9.0, 9.0, 6.0, 9.0, 10.0, 8.0, 11.0,
      5.0, 10.0, 8.0, 9.0, 15.0, 10.0, 6.0, 8.0, 13.0, 10.0, 8.0, 6.0, 9.0, 13.0,
      7.0, 5.0, 6.0, 8.0, 8.0, 12.0, 8.0, 9.0, 10.0, 3.0, 9.0, 9.0, 9.0, 4.0, 10.0,
      8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06512619978917715
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025496683732391744
    mean_inference_ms: 1.2198106121543966
    mean_raw_obs_processing_ms: 0.2772192792707858
time_since_restore: 2740.3302643299103
time_this_iter_s: 10.161161184310913
time_total_s: 2740.3302643299103
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691996920
timesteps_total: 3320150
training_iteration: 270
trial_id: default
train step: 271
agent_timesteps_total: 3333250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02016835999720305
  StateBufferConnector_ms: 0.003601046441828163
  ViewRequirementAgentConnector_ms: 0.1192155393581946
counters:
  num_agent_steps_sampled: 3333250
  num_agent_steps_trained: 3316500
  num_env_steps_sampled: 3333250
  num_env_steps_trained: 3316500
  num_samples_added_to_queue: 3333000
  num_training_step_calls_since_last_synch_worker_weights: 304
  num_weight_broadcasts: 65564
custom_metrics: {}
date: 2023-08-14_16-08-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.922330097087379
episode_reward_min: 0.0
episodes_this_iter: 103
episodes_total: 26042
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6186488270759583
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 7.204171180725098
        total_loss: 93.80674743652344
        var_gnorm: 64.7214126586914
        vf_explained_var: 0.8414610028266907
        vf_loss: 179.3916473388672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6633.0
  learner_queue:
    size_count: 6639
    size_mean: 14.98
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7028211884986633
  num_agent_steps_sampled: 3333250
  num_agent_steps_trained: 3316500
  num_env_steps_sampled: 3333250
  num_env_steps_trained: 3316500
  num_samples_added_to_queue: 3333000
  num_training_step_calls_since_last_synch_worker_weights: 304
  num_weight_broadcasts: 65564
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 180.388
    learner_load_time_ms: 6.972
    learner_load_wait_time_ms: 1.633
iterations_since_restore: 271
node_ip: 127.0.0.1
num_agent_steps_sampled: 3333250
num_agent_steps_trained: 3316500
num_env_steps_sampled: 3333250
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9925353952417
num_env_steps_trained: 3316500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9925923769574
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.08571428571428
  ram_util_percent: 81.83571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06510263745247125
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02548932429137227
  mean_inference_ms: 1.2195249924030045
  mean_raw_obs_processing_ms: 0.2771609239580699
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02016835999720305
    StateBufferConnector_ms: 0.003601046441828163
    ViewRequirementAgentConnector_ms: 0.1192155393581946
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.922330097087379
  episode_reward_min: 0.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 11.0, 7.0, 8.0, 11.0, 4.0, 10.0, 9.0, 7.0, 4.0, 3.0, 8.0,
      8.0, 6.0, 6.0, 3.0, 11.0, 7.0, 8.0, 4.0, 7.0, 3.0, 5.0, 4.0, 4.0, 2.0, 1.0,
      7.0, 6.0, 2.0, 5.0, 2.0, 7.0, 1.0, 3.0, 7.0, 0.0, 6.0, 8.0, 1.0, 2.0, 4.0, 2.0,
      5.0, 7.0, 4.0, 1.0, 5.0, 4.0, 3.0, 6.0, 3.0, 9.0, 3.0, 6.0, 7.0, 5.0, 6.0, 3.0,
      4.0, 7.0, 3.0, 3.0, 5.0, 8.0, 7.0, 11.0, 6.0, 2.0, 3.0, 6.0, 4.0, 7.0, 7.0,
      3.0, 0.0, 3.0, 2.0, 5.0, 3.0, 2.0, 7.0, 3.0, 7.0, 1.0, 3.0, 3.0, 4.0, 4.0, 2.0,
      7.0, 4.0, 1.0, 2.0, 6.0, 4.0, 3.0, 9.0, 7.0, 10.0, 4.0, 2.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06510263745247125
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02548932429137227
    mean_inference_ms: 1.2195249924030045
    mean_raw_obs_processing_ms: 0.2771609239580699
time_since_restore: 2750.4768521785736
time_this_iter_s: 10.14658784866333
time_total_s: 2750.4768521785736
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691996931
timesteps_total: 3333250
training_iteration: 271
trial_id: default
train step: 272
agent_timesteps_total: 3346100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0203249454498291
  StateBufferConnector_ms: 0.0036194324493408203
  ViewRequirementAgentConnector_ms: 0.1230008602142334
counters:
  num_agent_steps_sampled: 3346100
  num_agent_steps_trained: 3329500
  num_env_steps_sampled: 3346100
  num_env_steps_trained: 3329500
  num_samples_added_to_queue: 3346000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 65818
custom_metrics: {}
date: 2023-08-14_16-09-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.49
episode_reward_min: 3.0
episodes_this_iter: 100
episodes_total: 26142
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7128198742866516
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -42.170921325683594
        total_loss: -21.119915008544922
        var_gnorm: 64.71971893310547
        vf_explained_var: 0.9318216443061829
        vf_loss: 49.23020935058594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6659.0
  learner_queue:
    size_count: 6663
    size_mean: 15.04
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.648757107641996
  num_agent_steps_sampled: 3346100
  num_agent_steps_trained: 3329500
  num_env_steps_sampled: 3346100
  num_env_steps_trained: 3329500
  num_samples_added_to_queue: 3346000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 65818
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 244.683
    learner_load_time_ms: 7.076
    learner_load_wait_time_ms: 1.766
iterations_since_restore: 272
node_ip: 127.0.0.1
num_agent_steps_sampled: 3346100
num_agent_steps_trained: 3329500
num_env_steps_sampled: 3346100
num_env_steps_sampled_this_iter: 12850
num_env_steps_sampled_throughput_per_sec: 1284.5846994275037
num_env_steps_trained: 3329500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.5798515608985
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.040000000000006
  ram_util_percent: 81.59333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06509296911104104
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02548565311270889
  mean_inference_ms: 1.2193056245591958
  mean_raw_obs_processing_ms: 0.27712095856069646
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0203249454498291
    StateBufferConnector_ms: 0.0036194324493408203
    ViewRequirementAgentConnector_ms: 0.1230008602142334
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.49
  episode_reward_min: 3.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 7.0, 3.0, 6.0, 7.0, 4.0, 8.0, 6.0, 8.0, 9.0, 6.0, 6.0, 5.0,
      10.0, 6.0, 13.0, 10.0, 7.0, 12.0, 9.0, 14.0, 13.0, 10.0, 9.0, 10.0, 6.0, 12.0,
      10.0, 8.0, 8.0, 9.0, 10.0, 9.0, 7.0, 6.0, 11.0, 9.0, 11.0, 8.0, 12.0, 10.0,
      8.0, 7.0, 11.0, 10.0, 7.0, 6.0, 13.0, 10.0, 10.0, 8.0, 5.0, 7.0, 9.0, 7.0, 5.0,
      9.0, 6.0, 8.0, 8.0, 9.0, 5.0, 8.0, 6.0, 10.0, 9.0, 8.0, 7.0, 9.0, 5.0, 9.0,
      12.0, 8.0, 8.0, 7.0, 7.0, 7.0, 11.0, 7.0, 10.0, 6.0, 11.0, 7.0, 7.0, 8.0, 12.0,
      14.0, 9.0, 8.0, 8.0, 11.0, 9.0, 8.0, 7.0, 11.0, 5.0, 12.0, 11.0, 9.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06509296911104104
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02548565311270889
    mean_inference_ms: 1.2193056245591958
    mean_raw_obs_processing_ms: 0.27712095856069646
time_since_restore: 2760.5697412490845
time_this_iter_s: 10.092889070510864
time_total_s: 2760.5697412490845
timers:
  sample_time_ms: 0.041
  synch_weights_time_ms: 0.265
  training_iteration_time_ms: 0.366
timestamp: 1691996941
timesteps_total: 3346100
training_iteration: 272
trial_id: default
train step: 273
agent_timesteps_total: 3359350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019152347858135518
  StateBufferConnector_ms: 0.0034577571428739107
  ViewRequirementAgentConnector_ms: 0.11777602709256686
counters:
  num_agent_steps_sampled: 3359350
  num_agent_steps_trained: 3342500
  num_env_steps_sampled: 3359350
  num_env_steps_trained: 3342500
  num_samples_added_to_queue: 3359000
  num_training_step_calls_since_last_synch_worker_weights: 437
  num_weight_broadcasts: 66081
custom_metrics: {}
date: 2023-08-14_16-09-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.211538461538462
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 26246
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6290908455848694
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 7.895699501037598
        total_loss: 32.448387145996094
        var_gnorm: 64.72259521484375
        vf_explained_var: 0.9331343770027161
        vf_loss: 55.39628219604492
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6685.0
  learner_queue:
    size_count: 6691
    size_mean: 15.48
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.135605565326271
  num_agent_steps_sampled: 3359350
  num_agent_steps_trained: 3342500
  num_env_steps_sampled: 3359350
  num_env_steps_trained: 3342500
  num_samples_added_to_queue: 3359000
  num_training_step_calls_since_last_synch_worker_weights: 437
  num_weight_broadcasts: 66081
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 182.013
    learner_load_time_ms: 7.047
    learner_load_wait_time_ms: 1.548
iterations_since_restore: 273
node_ip: 127.0.0.1
num_agent_steps_sampled: 3359350
num_agent_steps_trained: 3342500
num_env_steps_sampled: 3359350
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.998957515583
num_env_steps_trained: 3342500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9989771851003
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.728571428571435
  ram_util_percent: 81.85000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06507191466300591
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025476414601789676
  mean_inference_ms: 1.2189324158098291
  mean_raw_obs_processing_ms: 0.2770494911296606
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019152347858135518
    StateBufferConnector_ms: 0.0034577571428739107
    ViewRequirementAgentConnector_ms: 0.11777602709256686
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.211538461538462
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 11.0, 6.0, 10.0, 8.0, 9.0, 5.0, 10.0, 13.0, 11.0, 12.0,
      6.0, 3.0, 15.0, 4.0, 12.0, 5.0, 11.0, 5.0, 13.0, 10.0, 15.0, 12.0, 10.0, 6.0,
      7.0, 4.0, 7.0, 9.0, 7.0, 8.0, 5.0, 8.0, 10.0, 12.0, 12.0, 10.0, 9.0, 11.0, 8.0,
      11.0, 6.0, 8.0, 10.0, 3.0, 11.0, 11.0, 13.0, 6.0, 11.0, 4.0, 6.0, 11.0, 8.0,
      7.0, 8.0, 9.0, 6.0, 6.0, 7.0, 9.0, 8.0, 9.0, 8.0, 16.0, 7.0, 7.0, 8.0, 10.0,
      6.0, 3.0, 15.0, 4.0, 11.0, 10.0, 8.0, 8.0, 9.0, 10.0, 8.0, 8.0, 7.0, 8.0, 7.0,
      7.0, 4.0, 10.0, 6.0, 10.0, 6.0, 4.0, 2.0, 7.0, 8.0, 5.0, 6.0, 5.0, 10.0, 6.0,
      4.0, 12.0, 7.0, 7.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06507191466300591
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025476414601789676
    mean_inference_ms: 1.2189324158098291
    mean_raw_obs_processing_ms: 0.2770494911296606
time_since_restore: 2770.7038440704346
time_this_iter_s: 10.134102821350098
time_total_s: 2770.7038440704346
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996951
timesteps_total: 3359350
training_iteration: 273
trial_id: default
train step: 274
agent_timesteps_total: 3373000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01886948099676168
  StateBufferConnector_ms: 0.003421981379670917
  ViewRequirementAgentConnector_ms: 0.11546656770526238
counters:
  num_agent_steps_sampled: 3373000
  num_agent_steps_trained: 3356500
  num_env_steps_sampled: 3373000
  num_env_steps_trained: 3356500
  num_samples_added_to_queue: 3373000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 66350
custom_metrics: {}
date: 2023-08-14_16-09-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.037735849056604
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 26352
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5503280758857727
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.40809160470962524
        total_loss: 13.614727020263672
        var_gnorm: 64.7319564819336
        vf_explained_var: 0.9710487127304077
        vf_loss: 31.916549682617188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6713.0
  learner_queue:
    size_count: 6716
    size_mean: 15.52
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1178550889985697
  num_agent_steps_sampled: 3373000
  num_agent_steps_trained: 3356500
  num_env_steps_sampled: 3373000
  num_env_steps_trained: 3356500
  num_samples_added_to_queue: 3373000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 66350
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 265.123
    learner_load_time_ms: 7.043
    learner_load_wait_time_ms: 1.672
iterations_since_restore: 274
node_ip: 127.0.0.1
num_agent_steps_sampled: 3373000
num_agent_steps_trained: 3356500
num_env_steps_sampled: 3373000
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1362.1740347472778
num_env_steps_trained: 3356500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1397.1015740997723
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.785714285714285
  ram_util_percent: 81.61428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06504501155627702
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02546333735422243
  mean_inference_ms: 1.2184385171218857
  mean_raw_obs_processing_ms: 0.2769401949262178
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01886948099676168
    StateBufferConnector_ms: 0.003421981379670917
    ViewRequirementAgentConnector_ms: 0.11546656770526238
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.037735849056604
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 11.0, 8.0, 4.0, 7.0, 7.0, 6.0, 9.0, 6.0, 7.0, 7.0,
      10.0, 9.0, 4.0, 7.0, 9.0, 6.0, 5.0, 8.0, 7.0, 7.0, 8.0, 4.0, 5.0, 9.0, 8.0,
      6.0, 7.0, 2.0, 3.0, 4.0, 2.0, 10.0, 7.0, 7.0, 5.0, 8.0, 6.0, 2.0, 6.0, 1.0,
      0.0, 5.0, 7.0, 2.0, 11.0, 0.0, 6.0, 2.0, 2.0, 3.0, 4.0, 7.0, 8.0, 11.0, 11.0,
      10.0, 7.0, 10.0, 11.0, 7.0, 5.0, 10.0, 6.0, 8.0, 6.0, 7.0, 8.0, 11.0, 8.0, 6.0,
      12.0, 1.0, 5.0, 10.0, 5.0, 6.0, 4.0, 8.0, 6.0, 8.0, 7.0, 5.0, 5.0, 5.0, 4.0,
      5.0, 8.0, 7.0, 9.0, 8.0, 9.0, 0.0, 1.0, 3.0, 0.0, 3.0, 2.0, 4.0, 5.0, 4.0, 0.0,
      6.0, 0.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06504501155627702
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02546333735422243
    mean_inference_ms: 1.2184385171218857
    mean_raw_obs_processing_ms: 0.2769401949262178
time_since_restore: 2780.7899849414825
time_this_iter_s: 10.086140871047974
time_total_s: 2780.7899849414825
timers:
  sample_time_ms: 0.038
  synch_weights_time_ms: 0.585
  training_iteration_time_ms: 2.192
timestamp: 1691996961
timesteps_total: 3373000
training_iteration: 274
trial_id: default
train step: 275
agent_timesteps_total: 3386550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018797955423031212
  StateBufferConnector_ms: 0.003413209375345482
  ViewRequirementAgentConnector_ms: 0.11523534666817144
counters:
  num_agent_steps_sampled: 3386550
  num_agent_steps_trained: 3370000
  num_env_steps_sampled: 3386550
  num_env_steps_trained: 3370000
  num_samples_added_to_queue: 3386500
  num_training_step_calls_since_last_synch_worker_weights: 1049
  num_weight_broadcasts: 66618
custom_metrics: {}
date: 2023-08-14_16-09-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 5.188679245283019
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 26458
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7422022819519043
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -38.4701042175293
        total_loss: -21.538801193237305
        var_gnorm: 64.73812103271484
        vf_explained_var: 0.9583137035369873
        vf_loss: 41.284629821777344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6740.0
  learner_queue:
    size_count: 6744
    size_mean: 15.8
    size_quantiles: [13.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.6
  num_agent_steps_sampled: 3386550
  num_agent_steps_trained: 3370000
  num_env_steps_sampled: 3386550
  num_env_steps_trained: 3370000
  num_samples_added_to_queue: 3386500
  num_training_step_calls_since_last_synch_worker_weights: 1049
  num_weight_broadcasts: 66618
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 231.936
    learner_load_time_ms: 7.041
    learner_load_wait_time_ms: 1.665
iterations_since_restore: 275
node_ip: 127.0.0.1
num_agent_steps_sampled: 3386550
num_agent_steps_trained: 3370000
num_env_steps_sampled: 3386550
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9982554935027
num_env_steps_trained: 3370000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.998261930796
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.22142857142858
  ram_util_percent: 81.87857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06501748044853956
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0254488954524994
  mean_inference_ms: 1.2179515944014945
  mean_raw_obs_processing_ms: 0.2768338910085272
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018797955423031212
    StateBufferConnector_ms: 0.003413209375345482
    ViewRequirementAgentConnector_ms: 0.11523534666817144
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 5.188679245283019
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 1.0, 0.0, 6.0, 2.0, 5.0, 4.0, 8.0, 0.0, 3.0, 4.0, 2.0,
      9.0, 5.0, 2.0, 5.0, 3.0, 7.0, 3.0, 3.0, 2.0, 0.0, 5.0, 4.0, 7.0, 6.0, 10.0,
      8.0, 4.0, 5.0, 6.0, 7.0, 5.0, 6.0, 5.0, 5.0, 7.0, 9.0, 6.0, 5.0, 11.0, 10.0,
      11.0, 7.0, 5.0, 2.0, 11.0, 8.0, 10.0, 7.0, 7.0, 8.0, 2.0, 5.0, 5.0, 2.0, 0.0,
      2.0, 3.0, 6.0, 5.0, 4.0, 2.0, 0.0, 6.0, 2.0, 1.0, 2.0, 11.0, 0.0, 4.0, 3.0,
      2.0, 6.0, 8.0, 3.0, 2.0, 6.0, 9.0, 2.0, 4.0, 6.0, 6.0, 10.0, 4.0, 5.0, 4.0,
      10.0, 3.0, 2.0, 6.0, 10.0, 9.0, 7.0, 7.0, 4.0, 8.0, 10.0, 10.0, 5.0, 4.0, 4.0,
      7.0, 10.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06501748044853956
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0254488954524994
    mean_inference_ms: 1.2179515944014945
    mean_raw_obs_processing_ms: 0.2768338910085272
time_since_restore: 2790.874543905258
time_this_iter_s: 10.084558963775635
time_total_s: 2790.874543905258
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691996971
timesteps_total: 3386550
training_iteration: 275
trial_id: default
train step: 276
agent_timesteps_total: 3400000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018947919209798176
  StateBufferConnector_ms: 0.0034216472080775668
  ViewRequirementAgentConnector_ms: 0.1168498538789295
counters:
  num_agent_steps_sampled: 3400000
  num_agent_steps_trained: 3383500
  num_env_steps_sampled: 3400000
  num_env_steps_trained: 3383500
  num_samples_added_to_queue: 3400000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 66882
custom_metrics: {}
date: 2023-08-14_16-09-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.066666666666666
episode_reward_min: 1.0
episodes_this_iter: 105
episodes_total: 26563
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7771451473236084
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -21.944103240966797
        total_loss: 18.050783157348633
        var_gnorm: 64.73478698730469
        vf_explained_var: 0.8544678688049316
        vf_loss: 87.76122283935547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6767.0
  learner_queue:
    size_count: 6769
    size_mean: 15.82
    size_quantiles: [13.0, 15.9, 16.0, 16.0, 16.0]
    size_std: 0.589576118919347
  num_agent_steps_sampled: 3400000
  num_agent_steps_trained: 3383500
  num_env_steps_sampled: 3400000
  num_env_steps_trained: 3383500
  num_samples_added_to_queue: 3400000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 66882
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 304.769
    learner_load_time_ms: 1.482
    learner_load_wait_time_ms: 1.577
iterations_since_restore: 276
node_ip: 127.0.0.1
num_agent_steps_sampled: 3400000
num_agent_steps_trained: 3383500
num_env_steps_sampled: 3400000
num_env_steps_sampled_this_iter: 13450
num_env_steps_sampled_throughput_per_sec: 1344.8132018634305
num_env_steps_trained: 3383500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.812507446566
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.60666666666666
  ram_util_percent: 82.07333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0649957764794836
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025438186175841794
  mean_inference_ms: 1.217518419959967
  mean_raw_obs_processing_ms: 0.27674592451899466
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018947919209798176
    StateBufferConnector_ms: 0.0034216472080775668
    ViewRequirementAgentConnector_ms: 0.1168498538789295
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.066666666666666
  episode_reward_min: 1.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 8.0, 4.0, 1.0, 7.0, 8.0, 8.0, 14.0, 6.0, 9.0, 7.0, 4.0,
      7.0, 10.0, 6.0, 6.0, 5.0, 6.0, 8.0, 4.0, 9.0, 6.0, 4.0, 10.0, 8.0, 5.0, 6.0,
      10.0, 10.0, 7.0, 9.0, 7.0, 7.0, 9.0, 10.0, 2.0, 4.0, 8.0, 10.0, 10.0, 5.0, 12.0,
      8.0, 5.0, 9.0, 7.0, 4.0, 8.0, 10.0, 10.0, 6.0, 8.0, 7.0, 7.0, 4.0, 13.0, 7.0,
      3.0, 5.0, 6.0, 9.0, 8.0, 8.0, 4.0, 8.0, 5.0, 2.0, 9.0, 6.0, 4.0, 6.0, 5.0, 7.0,
      12.0, 3.0, 5.0, 5.0, 3.0, 7.0, 7.0, 6.0, 2.0, 5.0, 7.0, 4.0, 5.0, 7.0, 8.0,
      7.0, 8.0, 9.0, 7.0, 10.0, 7.0, 3.0, 7.0, 11.0, 4.0, 8.0, 12.0, 10.0, 12.0, 11.0,
      7.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0649957764794836
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025438186175841794
    mean_inference_ms: 1.217518419959967
    mean_raw_obs_processing_ms: 0.27674592451899466
time_since_restore: 2800.940958738327
time_this_iter_s: 10.066414833068848
time_total_s: 2800.940958738327
timers:
  sample_time_ms: 0.073
  synch_weights_time_ms: 0.421
  training_iteration_time_ms: 2.219
timestamp: 1691996981
timesteps_total: 3400000
training_iteration: 276
trial_id: default
train step: 277
agent_timesteps_total: 3412500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020687341690063477
  StateBufferConnector_ms: 0.0037937164306640625
  ViewRequirementAgentConnector_ms: 0.1277785301208496
counters:
  num_agent_steps_sampled: 3412500
  num_agent_steps_trained: 3396000
  num_env_steps_sampled: 3412500
  num_env_steps_trained: 3396000
  num_samples_added_to_queue: 3412500
  num_training_step_calls_since_last_synch_worker_weights: 662
  num_weight_broadcasts: 67129
custom_metrics: {}
date: 2023-08-14_16-09-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.21
episode_reward_min: 0.0
episodes_this_iter: 97
episodes_total: 26660
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7201793789863586
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.4496480226516724
        total_loss: 25.317907333374023
        var_gnorm: 64.74199676513672
        vf_explained_var: 0.9020236730575562
        vf_loss: 60.73690414428711
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6792.0
  learner_queue:
    size_count: 6796
    size_mean: 15.8
    size_quantiles: [13.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.6
  num_agent_steps_sampled: 3412500
  num_agent_steps_trained: 3396000
  num_env_steps_sampled: 3412500
  num_env_steps_trained: 3396000
  num_samples_added_to_queue: 3412500
  num_training_step_calls_since_last_synch_worker_weights: 662
  num_weight_broadcasts: 67129
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 255.854
    learner_load_time_ms: 1.482
    learner_load_wait_time_ms: 1.664
iterations_since_restore: 277
node_ip: 127.0.0.1
num_agent_steps_sampled: 3412500
num_agent_steps_trained: 3396000
num_env_steps_sampled: 3412500
num_env_steps_sampled_this_iter: 12500
num_env_steps_sampled_throughput_per_sec: 1249.9972283901634
num_env_steps_trained: 3396000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9972283901634
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.92857142857143
  ram_util_percent: 82.38571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06499005327183839
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025434945390027518
  mean_inference_ms: 1.217425602687927
  mean_raw_obs_processing_ms: 0.27671074365978887
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020687341690063477
    StateBufferConnector_ms: 0.0037937164306640625
    ViewRequirementAgentConnector_ms: 0.1277785301208496
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.21
  episode_reward_min: 0.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 7.0, 7.0, 12.0, 8.0, 5.0, 11.0, 5.0, 10.0, 10.0, 0.0, 10.0,
      15.0, 11.0, 10.0, 14.0, 7.0, 11.0, 11.0, 11.0, 12.0, 6.0, 7.0, 10.0, 8.0, 10.0,
      9.0, 8.0, 7.0, 10.0, 7.0, 6.0, 9.0, 6.0, 5.0, 5.0, 11.0, 7.0, 9.0, 6.0, 7.0,
      6.0, 3.0, 12.0, 7.0, 4.0, 9.0, 9.0, 6.0, 9.0, 7.0, 10.0, 8.0, 2.0, 10.0, 4.0,
      12.0, 13.0, 9.0, 10.0, 11.0, 8.0, 8.0, 9.0, 11.0, 10.0, 8.0, 8.0, 10.0, 6.0,
      10.0, 6.0, 5.0, 3.0, 15.0, 4.0, 6.0, 9.0, 11.0, 5.0, 9.0, 11.0, 6.0, 15.0, 9.0,
      4.0, 11.0, 5.0, 10.0, 8.0, 7.0, 6.0, 7.0, 5.0, 5.0, 10.0, 6.0, 11.0, 8.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06499005327183839
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025434945390027518
    mean_inference_ms: 1.217425602687927
    mean_raw_obs_processing_ms: 0.27671074365978887
time_since_restore: 2811.049959897995
time_this_iter_s: 10.109001159667969
time_total_s: 2811.049959897995
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691996991
timesteps_total: 3412500
training_iteration: 277
trial_id: default
train step: 278
agent_timesteps_total: 3425500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020170913023107192
  StateBufferConnector_ms: 0.0035503331352682676
  ViewRequirementAgentConnector_ms: 0.12400360668406767
counters:
  num_agent_steps_sampled: 3425500
  num_agent_steps_trained: 3409000
  num_env_steps_sampled: 3425500
  num_env_steps_trained: 3409000
  num_samples_added_to_queue: 3425500
  num_training_step_calls_since_last_synch_worker_weights: 157
  num_weight_broadcasts: 67385
custom_metrics: {}
date: 2023-08-14_16-10-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.019607843137255
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 26762
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7097198367118835
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.563620567321777
        total_loss: 16.313133239746094
        var_gnorm: 64.74771881103516
        vf_explained_var: 0.8952946662902832
        vf_loss: 68.8507080078125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6818.0
  learner_queue:
    size_count: 6824
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1697863052711808
  num_agent_steps_sampled: 3425500
  num_agent_steps_trained: 3409000
  num_env_steps_sampled: 3425500
  num_env_steps_trained: 3409000
  num_samples_added_to_queue: 3425500
  num_training_step_calls_since_last_synch_worker_weights: 157
  num_weight_broadcasts: 67385
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 171.35
    learner_load_time_ms: 1.384
    learner_load_wait_time_ms: 1.429
iterations_since_restore: 278
node_ip: 127.0.0.1
num_agent_steps_sampled: 3425500
num_agent_steps_trained: 3409000
num_env_steps_sampled: 3425500
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9979543718102
num_env_steps_trained: 3409000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9979543718102
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.24285714285714
  ram_util_percent: 82.29285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06497085903412624
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025430077367935202
  mean_inference_ms: 1.2171776419616769
  mean_raw_obs_processing_ms: 0.2766576013752302
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020170913023107192
    StateBufferConnector_ms: 0.0035503331352682676
    ViewRequirementAgentConnector_ms: 0.12400360668406767
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.019607843137255
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 10.0, 8.0, 6.0, 9.0, 5.0, 13.0, 8.0, 6.0, 10.0, 8.0, 9.0,
      11.0, 7.0, 5.0, 10.0, 7.0, 10.0, 5.0, 10.0, 10.0, 15.0, 7.0, 7.0, 10.0, 5.0,
      5.0, 8.0, 4.0, 9.0, 9.0, 7.0, 7.0, 11.0, 14.0, 10.0, 9.0, 11.0, 4.0, 8.0, 9.0,
      13.0, 7.0, 11.0, 6.0, 10.0, 12.0, 8.0, 6.0, 14.0, 7.0, 13.0, 7.0, 12.0, 12.0,
      16.0, 8.0, 6.0, 10.0, 10.0, 9.0, 11.0, 10.0, 12.0, 11.0, 6.0, 10.0, 11.0, 13.0,
      7.0, 10.0, 8.0, 7.0, 6.0, 7.0, 11.0, 9.0, 9.0, 9.0, 10.0, 11.0, 11.0, 12.0,
      8.0, 7.0, 11.0, 10.0, 8.0, 8.0, 4.0, 8.0, 9.0, 11.0, 12.0, 11.0, 5.0, 7.0, 11.0,
      12.0, 7.0, 12.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06497085903412624
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025430077367935202
    mean_inference_ms: 1.2171776419616769
    mean_raw_obs_processing_ms: 0.2766576013752302
time_since_restore: 2821.1877250671387
time_this_iter_s: 10.137765169143677
time_total_s: 2821.1877250671387
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997001
timesteps_total: 3425500
training_iteration: 278
trial_id: default
train step: 279
agent_timesteps_total: 3438600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019681219961128982
  StateBufferConnector_ms: 0.0035094279868929995
  ViewRequirementAgentConnector_ms: 0.11985348720176547
counters:
  num_agent_steps_sampled: 3438600
  num_agent_steps_trained: 3422000
  num_env_steps_sampled: 3438600
  num_env_steps_trained: 3422000
  num_samples_added_to_queue: 3438500
  num_training_step_calls_since_last_synch_worker_weights: 7
  num_weight_broadcasts: 67640
custom_metrics: {}
date: 2023-08-14_16-10-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.098039215686274
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 26864
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7012210488319397
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -33.03429412841797
        total_loss: 14.538217544555664
        var_gnorm: 64.75236511230469
        vf_explained_var: 0.8588531017303467
        vf_loss: 102.15723419189453
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6844.0
  learner_queue:
    size_count: 6851
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.632666530556684
  num_agent_steps_sampled: 3438600
  num_agent_steps_trained: 3422000
  num_env_steps_sampled: 3438600
  num_env_steps_trained: 3422000
  num_samples_added_to_queue: 3438500
  num_training_step_calls_since_last_synch_worker_weights: 7
  num_weight_broadcasts: 67640
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 129.288
    learner_load_time_ms: 1.411
    learner_load_wait_time_ms: 1.529
iterations_since_restore: 279
node_ip: 127.0.0.1
num_agent_steps_sampled: 3438600
num_agent_steps_trained: 3422000
num_env_steps_sampled: 3438600
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9953150916751
num_env_steps_trained: 3422000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9953508543342
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.693333333333335
  ram_util_percent: 81.97999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06495532739873933
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02542381293343511
  mean_inference_ms: 1.2168966421745355
  mean_raw_obs_processing_ms: 0.27660299360314733
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019681219961128982
    StateBufferConnector_ms: 0.0035094279868929995
    ViewRequirementAgentConnector_ms: 0.11985348720176547
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.098039215686274
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 13.0, 10.0, 9.0, 13.0, 8.0, 6.0, 8.0, 5.0, 10.0, 6.0, 11.0,
      5.0, 9.0, 7.0, 5.0, 12.0, 9.0, 10.0, 12.0, 7.0, 8.0, 10.0, 13.0, 8.0, 10.0,
      10.0, 8.0, 10.0, 11.0, 13.0, 6.0, 12.0, 7.0, 7.0, 6.0, 14.0, 7.0, 9.0, 10.0,
      5.0, 6.0, 8.0, 8.0, 12.0, 7.0, 10.0, 9.0, 5.0, 11.0, 8.0, 7.0, 9.0, 12.0, 12.0,
      9.0, 10.0, 9.0, 8.0, 10.0, 4.0, 7.0, 6.0, 6.0, 9.0, 5.0, 9.0, 11.0, 7.0, 14.0,
      12.0, 9.0, 9.0, 9.0, 14.0, 13.0, 15.0, 8.0, 11.0, 10.0, 12.0, 9.0, 10.0, 6.0,
      7.0, 9.0, 11.0, 10.0, 10.0, 9.0, 10.0, 14.0, 9.0, 11.0, 6.0, 7.0, 7.0, 4.0,
      14.0, 9.0, 9.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06495532739873933
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02542381293343511
    mean_inference_ms: 1.2168966421745355
    mean_raw_obs_processing_ms: 0.27660299360314733
time_since_restore: 2831.3410110473633
time_this_iter_s: 10.15328598022461
time_total_s: 2831.3410110473633
timers:
  sample_time_ms: 0.166
  synch_weights_time_ms: 0.498
  training_iteration_time_ms: 0.796
timestamp: 1691997011
timesteps_total: 3438600
training_iteration: 279
trial_id: default
train step: 280
agent_timesteps_total: 3451800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019766963445223294
  StateBufferConnector_ms: 0.00357513244335468
  ViewRequirementAgentConnector_ms: 0.11869646035707913
counters:
  num_agent_steps_sampled: 3451800
  num_agent_steps_trained: 3435000
  num_env_steps_sampled: 3451800
  num_env_steps_trained: 3435000
  num_samples_added_to_queue: 3451500
  num_training_step_calls_since_last_synch_worker_weights: 1044
  num_weight_broadcasts: 67895
custom_metrics: {}
date: 2023-08-14_16-10-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.846153846153847
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 26968
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6772533059120178
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 83.3775634765625
        total_loss: 143.96844482421875
        var_gnorm: 64.75292205810547
        vf_explained_var: 0.8558346629142761
        vf_loss: 127.95428466796875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6870.0
  learner_queue:
    size_count: 6874
    size_mean: 15.1
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.6031219541881396
  num_agent_steps_sampled: 3451800
  num_agent_steps_trained: 3435000
  num_env_steps_sampled: 3451800
  num_env_steps_trained: 3435000
  num_samples_added_to_queue: 3451500
  num_training_step_calls_since_last_synch_worker_weights: 1044
  num_weight_broadcasts: 67895
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 263.398
    learner_load_time_ms: 1.419
    learner_load_wait_time_ms: 1.597
iterations_since_restore: 280
node_ip: 127.0.0.1
num_agent_steps_sampled: 3451800
num_agent_steps_trained: 3435000
num_env_steps_sampled: 3451800
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9984264392538
num_env_steps_trained: 3435000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9984502810833
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.26428571428572
  ram_util_percent: 82.07857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06493729658685404
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025416281642724334
  mean_inference_ms: 1.2165709766882302
  mean_raw_obs_processing_ms: 0.2765274327792937
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019766963445223294
    StateBufferConnector_ms: 0.00357513244335468
    ViewRequirementAgentConnector_ms: 0.11869646035707913
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.846153846153847
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 6.0, 10.0, 6.0, 9.0, 9.0, 11.0, 9.0, 9.0, 8.0, 13.0, 8.0,
      8.0, 6.0, 6.0, 6.0, 11.0, 8.0, 11.0, 10.0, 9.0, 12.0, 10.0, 11.0, 14.0, 10.0,
      7.0, 13.0, 13.0, 11.0, 4.0, 8.0, 4.0, 2.0, 8.0, 6.0, 10.0, 11.0, 10.0, 8.0,
      4.0, 11.0, 13.0, 9.0, 5.0, 12.0, 11.0, 9.0, 9.0, 11.0, 8.0, 5.0, 11.0, 6.0,
      7.0, 11.0, 7.0, 3.0, 8.0, 8.0, 10.0, 12.0, 9.0, 10.0, 4.0, 9.0, 9.0, 9.0, 10.0,
      10.0, 9.0, 6.0, 7.0, 7.0, 8.0, 9.0, 7.0, 8.0, 10.0, 9.0, 9.0, 8.0, 6.0, 10.0,
      15.0, 8.0, 7.0, 9.0, 14.0, 10.0, 8.0, 7.0, 9.0, 10.0, 7.0, 11.0, 12.0, 10.0,
      12.0, 5.0, 7.0, 12.0, 15.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06493729658685404
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025416281642724334
    mean_inference_ms: 1.2165709766882302
    mean_raw_obs_processing_ms: 0.2765274327792937
time_since_restore: 2841.4445452690125
time_this_iter_s: 10.10353422164917
time_total_s: 2841.4445452690125
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997022
timesteps_total: 3451800
training_iteration: 280
trial_id: default
train step: 281
agent_timesteps_total: 3465700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018541238926075124
  StateBufferConnector_ms: 0.00332880903173376
  ViewRequirementAgentConnector_ms: 0.11218410951119882
counters:
  num_agent_steps_sampled: 3465700
  num_agent_steps_trained: 3449000
  num_env_steps_sampled: 3465700
  num_env_steps_trained: 3449000
  num_samples_added_to_queue: 3465500
  num_training_step_calls_since_last_synch_worker_weights: 455
  num_weight_broadcasts: 68163
custom_metrics: {}
date: 2023-08-14_16-10-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.527777777777779
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 27076
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6621219515800476
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -31.917224884033203
        total_loss: 17.65028953552246
        var_gnorm: 64.7590103149414
        vf_explained_var: 0.8701804876327515
        vf_loss: 105.7562484741211
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6898.0
  learner_queue:
    size_count: 6904
    size_mean: 15.42
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.250439922587247
  num_agent_steps_sampled: 3465700
  num_agent_steps_trained: 3449000
  num_env_steps_sampled: 3465700
  num_env_steps_trained: 3449000
  num_samples_added_to_queue: 3465500
  num_training_step_calls_since_last_synch_worker_weights: 455
  num_weight_broadcasts: 68163
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 174.389
    learner_load_time_ms: 1.396
    learner_load_wait_time_ms: 1.58
iterations_since_restore: 281
node_ip: 127.0.0.1
num_agent_steps_sampled: 3465700
num_agent_steps_trained: 3449000
num_env_steps_sampled: 3465700
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9940016528535
num_env_steps_trained: 3449000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.993958499277
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.67142857142858
  ram_util_percent: 81.95
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06490674553925907
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025402376534712626
  mean_inference_ms: 1.216016237094178
  mean_raw_obs_processing_ms: 0.27640425833550075
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018541238926075124
    StateBufferConnector_ms: 0.00332880903173376
    ViewRequirementAgentConnector_ms: 0.11218410951119882
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.527777777777779
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 5.0, 10.0, 13.0, 10.0, 12.0, 8.0, 7.0, 6.0, 7.0, 8.0, 9.0,
      7.0, 7.0, 11.0, 10.0, 7.0, 8.0, 10.0, 3.0, 9.0, 13.0, 6.0, 14.0, 9.0, 10.0,
      7.0, 12.0, 13.0, 11.0, 9.0, 11.0, 9.0, 5.0, 7.0, 12.0, 11.0, 7.0, 7.0, 5.0,
      10.0, 9.0, 8.0, 11.0, 10.0, 7.0, 10.0, 8.0, 10.0, 5.0, 9.0, 8.0, 16.0, 8.0,
      5.0, 6.0, 9.0, 10.0, 7.0, 13.0, 10.0, 9.0, 11.0, 6.0, 3.0, 7.0, 11.0, 6.0, 8.0,
      8.0, 10.0, 8.0, 12.0, 9.0, 8.0, 12.0, 10.0, 6.0, 7.0, 8.0, 8.0, 6.0, 6.0, 9.0,
      8.0, 6.0, 13.0, 7.0, 8.0, 5.0, 5.0, 8.0, 9.0, 9.0, 12.0, 11.0, 3.0, 11.0, 8.0,
      10.0, 10.0, 8.0, 8.0, 10.0, 4.0, 4.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06490674553925907
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025402376534712626
    mean_inference_ms: 1.216016237094178
    mean_raw_obs_processing_ms: 0.27640425833550075
time_since_restore: 2851.5836572647095
time_this_iter_s: 10.139111995697021
time_total_s: 2851.5836572647095
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997032
timesteps_total: 3465700
training_iteration: 281
trial_id: default
train step: 282
agent_timesteps_total: 3479200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01920709070169701
  StateBufferConnector_ms: 0.0034235558419857385
  ViewRequirementAgentConnector_ms: 0.11638785308262087
counters:
  num_agent_steps_sampled: 3479200
  num_agent_steps_trained: 3462500
  num_env_steps_sampled: 3479200
  num_env_steps_trained: 3462500
  num_samples_added_to_queue: 3479000
  num_training_step_calls_since_last_synch_worker_weights: 1088
  num_weight_broadcasts: 68425
custom_metrics: {}
date: 2023-08-14_16-10-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.79245283018868
episode_reward_min: 2.0
episodes_this_iter: 106
episodes_total: 27182
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6696997880935669
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 12.331720352172852
        total_loss: 64.67391967773438
        var_gnorm: 64.7610092163086
        vf_explained_var: 0.8298665881156921
        vf_loss: 111.38138580322266
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6925.0
  learner_queue:
    size_count: 6929
    size_mean: 15.44
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2191800523302536
  num_agent_steps_sampled: 3479200
  num_agent_steps_trained: 3462500
  num_env_steps_sampled: 3479200
  num_env_steps_trained: 3462500
  num_samples_added_to_queue: 3479000
  num_training_step_calls_since_last_synch_worker_weights: 1088
  num_weight_broadcasts: 68425
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 250.492
    learner_load_time_ms: 1.386
    learner_load_wait_time_ms: 1.628
iterations_since_restore: 282
node_ip: 127.0.0.1
num_agent_steps_sampled: 3479200
num_agent_steps_trained: 3462500
num_env_steps_sampled: 3479200
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.996781356856
num_env_steps_trained: 3462500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.996781356856
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.153333333333336
  ram_util_percent: 81.96666666666665
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0648822823021385
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025391331169743007
  mean_inference_ms: 1.2155828202787133
  mean_raw_obs_processing_ms: 0.2763159868390272
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01920709070169701
    StateBufferConnector_ms: 0.0034235558419857385
    ViewRequirementAgentConnector_ms: 0.11638785308262087
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.79245283018868
  episode_reward_min: 2.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 11.0, 7.0, 10.0, 11.0, 10.0, 7.0, 10.0, 8.0, 9.0, 11.0,
      10.0, 11.0, 7.0, 6.0, 12.0, 7.0, 6.0, 10.0, 9.0, 11.0, 9.0, 8.0, 8.0, 5.0, 7.0,
      6.0, 6.0, 5.0, 11.0, 7.0, 10.0, 8.0, 7.0, 7.0, 6.0, 10.0, 8.0, 7.0, 7.0, 10.0,
      10.0, 14.0, 9.0, 5.0, 6.0, 11.0, 13.0, 11.0, 8.0, 9.0, 9.0, 8.0, 5.0, 12.0,
      5.0, 9.0, 8.0, 11.0, 6.0, 9.0, 11.0, 14.0, 9.0, 9.0, 7.0, 11.0, 10.0, 7.0, 5.0,
      10.0, 10.0, 9.0, 8.0, 11.0, 6.0, 10.0, 12.0, 12.0, 9.0, 2.0, 9.0, 8.0, 8.0,
      10.0, 10.0, 8.0, 11.0, 11.0, 11.0, 7.0, 9.0, 6.0, 7.0, 8.0, 11.0, 8.0, 8.0,
      10.0, 8.0, 10.0, 10.0, 11.0, 13.0, 3.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0648822823021385
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025391331169743007
    mean_inference_ms: 1.2155828202787133
    mean_raw_obs_processing_ms: 0.2763159868390272
time_since_restore: 2861.6802320480347
time_this_iter_s: 10.096574783325195
time_total_s: 2861.6802320480347
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997042
timesteps_total: 3479200
training_iteration: 282
trial_id: default
train step: 283
agent_timesteps_total: 3493000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018368826972113714
  StateBufferConnector_ms: 0.003293487760755751
  ViewRequirementAgentConnector_ms: 0.11226689374005352
counters:
  num_agent_steps_sampled: 3493000
  num_agent_steps_trained: 3476500
  num_env_steps_sampled: 3493000
  num_env_steps_trained: 3476500
  num_samples_added_to_queue: 3493000
  num_training_step_calls_since_last_synch_worker_weights: 539
  num_weight_broadcasts: 68697
custom_metrics: {}
date: 2023-08-14_16-10-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.694444444444445
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 27290
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6911948323249817
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.0619155168533325
        total_loss: 20.048139572143555
        var_gnorm: 64.7635269165039
        vf_explained_var: 0.9352468252182007
        vf_loss: 49.13206100463867
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6953.0
  learner_queue:
    size_count: 6958
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9591663046625439
  num_agent_steps_sampled: 3493000
  num_agent_steps_trained: 3476500
  num_env_steps_sampled: 3493000
  num_env_steps_trained: 3476500
  num_samples_added_to_queue: 3493000
  num_training_step_calls_since_last_synch_worker_weights: 539
  num_weight_broadcasts: 68697
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 197.25
    learner_load_time_ms: 1.38
    learner_load_wait_time_ms: 1.43
iterations_since_restore: 283
node_ip: 127.0.0.1
num_agent_steps_sampled: 3493000
num_agent_steps_trained: 3476500
num_env_steps_sampled: 3493000
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9951634576553
num_env_steps_trained: 3476500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9950933628386
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.00714285714285
  ram_util_percent: 81.74285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06485316661193799
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02537770553567629
  mean_inference_ms: 1.2150560804438018
  mean_raw_obs_processing_ms: 0.2762049816068281
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018368826972113714
    StateBufferConnector_ms: 0.003293487760755751
    ViewRequirementAgentConnector_ms: 0.11226689374005352
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.694444444444445
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 5.0, 7.0, 7.0, 6.0, 7.0, 11.0, 11.0, 8.0, 7.0, 8.0, 11.0,
      6.0, 11.0, 10.0, 7.0, 10.0, 11.0, 10.0, 7.0, 15.0, 8.0, 6.0, 10.0, 9.0, 10.0,
      9.0, 8.0, 14.0, 5.0, 8.0, 8.0, 15.0, 6.0, 9.0, 8.0, 7.0, 6.0, 15.0, 9.0, 10.0,
      10.0, 9.0, 12.0, 9.0, 10.0, 11.0, 8.0, 13.0, 6.0, 6.0, 10.0, 6.0, 12.0, 15.0,
      9.0, 6.0, 7.0, 7.0, 14.0, 9.0, 8.0, 7.0, 12.0, 8.0, 7.0, 7.0, 7.0, 11.0, 11.0,
      5.0, 10.0, 9.0, 4.0, 6.0, 3.0, 6.0, 11.0, 7.0, 4.0, 10.0, 8.0, 10.0, 10.0, 4.0,
      8.0, 10.0, 7.0, 13.0, 11.0, 12.0, 9.0, 5.0, 6.0, 8.0, 8.0, 12.0, 8.0, 8.0, 11.0,
      12.0, 6.0, 10.0, 7.0, 7.0, 11.0, 9.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06485316661193799
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02537770553567629
    mean_inference_ms: 1.2150560804438018
    mean_raw_obs_processing_ms: 0.2762049816068281
time_since_restore: 2871.7908658981323
time_this_iter_s: 10.110633850097656
time_total_s: 2871.7908658981323
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691997052
timesteps_total: 3493000
training_iteration: 283
trial_id: default
train step: 284
agent_timesteps_total: 3506700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018620940874207695
  StateBufferConnector_ms: 0.0033864435159935142
  ViewRequirementAgentConnector_ms: 0.11361949848678876
counters:
  num_agent_steps_sampled: 3506700
  num_agent_steps_trained: 3490000
  num_env_steps_sampled: 3506700
  num_env_steps_trained: 3490000
  num_samples_added_to_queue: 3506500
  num_training_step_calls_since_last_synch_worker_weights: 232
  num_weight_broadcasts: 68964
custom_metrics: {}
date: 2023-08-14_16-11-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.29245283018868
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 27396
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7073743343353271
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -27.208662033081055
        total_loss: 10.769545555114746
        var_gnorm: 64.76535034179688
        vf_explained_var: 0.8822542428970337
        vf_loss: 83.03015899658203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 6980.0
  learner_queue:
    size_count: 6986
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2649110640673518
  num_agent_steps_sampled: 3506700
  num_agent_steps_trained: 3490000
  num_env_steps_sampled: 3506700
  num_env_steps_trained: 3490000
  num_samples_added_to_queue: 3506500
  num_training_step_calls_since_last_synch_worker_weights: 232
  num_weight_broadcasts: 68964
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 175.137
    learner_load_time_ms: 1.583
    learner_load_wait_time_ms: 1.493
iterations_since_restore: 284
node_ip: 127.0.0.1
num_agent_steps_sampled: 3506700
num_agent_steps_trained: 3490000
num_env_steps_sampled: 3506700
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.995492473174
num_env_steps_trained: 3490000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9955582764853
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.67142857142857
  ram_util_percent: 81.72142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06482721630685724
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025365115104142216
  mean_inference_ms: 1.2145836588962955
  mean_raw_obs_processing_ms: 0.2760996079885173
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018620940874207695
    StateBufferConnector_ms: 0.0033864435159935142
    ViewRequirementAgentConnector_ms: 0.11361949848678876
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.29245283018868
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 8.0, 6.0, 6.0, 9.0, 11.0, 6.0, 12.0, 11.0, 8.0, 12.0, 9.0,
      8.0, 12.0, 8.0, 12.0, 8.0, 12.0, 5.0, 4.0, 8.0, 14.0, 12.0, 10.0, 12.0, 6.0,
      9.0, 7.0, 6.0, 3.0, 8.0, 11.0, 9.0, 12.0, 18.0, 5.0, 13.0, 10.0, 9.0, 7.0, 10.0,
      10.0, 13.0, 12.0, 10.0, 6.0, 5.0, 8.0, 14.0, 7.0, 9.0, 10.0, 7.0, 7.0, 4.0,
      8.0, 6.0, 9.0, 5.0, 5.0, 7.0, 5.0, 13.0, 13.0, 11.0, 9.0, 9.0, 11.0, 10.0, 12.0,
      11.0, 13.0, 8.0, 9.0, 9.0, 12.0, 8.0, 10.0, 5.0, 9.0, 15.0, 7.0, 8.0, 10.0,
      6.0, 10.0, 10.0, 6.0, 8.0, 10.0, 13.0, 8.0, 6.0, 7.0, 13.0, 13.0, 8.0, 11.0,
      12.0, 9.0, 9.0, 13.0, 10.0, 12.0, 14.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06482721630685724
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025365115104142216
    mean_inference_ms: 1.2145836588962955
    mean_raw_obs_processing_ms: 0.2760996079885173
time_since_restore: 2881.930308818817
time_this_iter_s: 10.139442920684814
time_total_s: 2881.930308818817
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691997062
timesteps_total: 3506700
training_iteration: 284
trial_id: default
train step: 285
agent_timesteps_total: 3520600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018307945945046165
  StateBufferConnector_ms: 0.0033209540627219462
  ViewRequirementAgentConnector_ms: 0.11117978529496626
counters:
  num_agent_steps_sampled: 3520600
  num_agent_steps_trained: 3504000
  num_env_steps_sampled: 3520600
  num_env_steps_trained: 3504000
  num_samples_added_to_queue: 3520500
  num_training_step_calls_since_last_synch_worker_weights: 940
  num_weight_broadcasts: 69236
custom_metrics: {}
date: 2023-08-14_16-11-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 9.2
episode_reward_min: 4.0
episodes_this_iter: 110
episodes_total: 27506
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7164992690086365
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 54.41737365722656
        total_loss: 112.6509780883789
        var_gnorm: 64.76563262939453
        vf_explained_var: 0.8763465285301208
        vf_loss: 123.63220977783203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7008.0
  learner_queue:
    size_count: 7012
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3230268326832983
  num_agent_steps_sampled: 3520600
  num_agent_steps_trained: 3504000
  num_env_steps_sampled: 3520600
  num_env_steps_trained: 3504000
  num_samples_added_to_queue: 3520500
  num_training_step_calls_since_last_synch_worker_weights: 940
  num_weight_broadcasts: 69236
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 240.271
    learner_load_time_ms: 1.56
    learner_load_wait_time_ms: 1.632
iterations_since_restore: 285
node_ip: 127.0.0.1
num_agent_steps_sampled: 3520600
num_agent_steps_trained: 3504000
num_env_steps_sampled: 3520600
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9977464712438
num_env_steps_trained: 3504000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9977302588068
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.21428571428572
  ram_util_percent: 81.66428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0647964415000946
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02535053789983165
  mean_inference_ms: 1.2140322821785963
  mean_raw_obs_processing_ms: 0.2759776047518876
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018307945945046165
    StateBufferConnector_ms: 0.0033209540627219462
    ViewRequirementAgentConnector_ms: 0.11117978529496626
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 9.2
  episode_reward_min: 4.0
  episodes_this_iter: 110
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128]
    episode_reward: [6.0, 10.0, 11.0, 8.0, 7.0, 8.0, 9.0, 10.0, 10.0, 10.0, 9.0, 10.0,
      10.0, 8.0, 10.0, 9.0, 12.0, 8.0, 10.0, 10.0, 14.0, 5.0, 13.0, 6.0, 10.0, 5.0,
      6.0, 6.0, 8.0, 6.0, 5.0, 7.0, 11.0, 6.0, 10.0, 8.0, 7.0, 4.0, 12.0, 5.0, 11.0,
      10.0, 10.0, 8.0, 12.0, 10.0, 9.0, 5.0, 9.0, 12.0, 6.0, 8.0, 11.0, 6.0, 7.0,
      10.0, 7.0, 10.0, 11.0, 10.0, 7.0, 13.0, 7.0, 6.0, 10.0, 10.0, 13.0, 10.0, 8.0,
      10.0, 11.0, 8.0, 11.0, 11.0, 13.0, 15.0, 10.0, 10.0, 9.0, 9.0, 12.0, 7.0, 8.0,
      9.0, 13.0, 4.0, 7.0, 7.0, 9.0, 5.0, 13.0, 19.0, 4.0, 11.0, 7.0, 10.0, 12.0,
      10.0, 11.0, 14.0, 11.0, 14.0, 9.0, 9.0, 7.0, 8.0, 9.0, 14.0, 10.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0647964415000946
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02535053789983165
    mean_inference_ms: 1.2140322821785963
    mean_raw_obs_processing_ms: 0.2759776047518876
time_since_restore: 2892.0360090732574
time_this_iter_s: 10.105700254440308
time_total_s: 2892.0360090732574
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997072
timesteps_total: 3520600
training_iteration: 285
trial_id: default
train step: 286
agent_timesteps_total: 3534200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019006234294963332
  StateBufferConnector_ms: 0.0034183826086656103
  ViewRequirementAgentConnector_ms: 0.11754013457388249
counters:
  num_agent_steps_sampled: 3534200
  num_agent_steps_trained: 3517500
  num_env_steps_sampled: 3534200
  num_env_steps_trained: 3517500
  num_samples_added_to_queue: 3534000
  num_training_step_calls_since_last_synch_worker_weights: 91
  num_weight_broadcasts: 69505
custom_metrics: {}
date: 2023-08-14_16-11-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.273584905660377
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 27612
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7113949060440063
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 124.76229095458984
        total_loss: 216.0952606201172
        var_gnorm: 64.76896667480469
        vf_explained_var: 0.8132442235946655
        vf_loss: 189.77989196777344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7035.0
  learner_queue:
    size_count: 7042
    size_mean: 15.38
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3840520221436765
  num_agent_steps_sampled: 3534200
  num_agent_steps_trained: 3517500
  num_env_steps_sampled: 3534200
  num_env_steps_trained: 3517500
  num_samples_added_to_queue: 3534000
  num_training_step_calls_since_last_synch_worker_weights: 91
  num_weight_broadcasts: 69505
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 142.391
    learner_load_time_ms: 1.568
    learner_load_wait_time_ms: 1.535
iterations_since_restore: 286
node_ip: 127.0.0.1
num_agent_steps_sampled: 3534200
num_agent_steps_trained: 3517500
num_env_steps_sampled: 3534200
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9930935256739
num_env_steps_trained: 3517500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9931443085734
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.93999999999999
  ram_util_percent: 81.16666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06477228569646383
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025340241538518195
  mean_inference_ms: 1.213606791585344
  mean_raw_obs_processing_ms: 0.2758788414755187
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019006234294963332
    StateBufferConnector_ms: 0.0034183826086656103
    ViewRequirementAgentConnector_ms: 0.11754013457388249
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.273584905660377
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 12.0, 9.0, 9.0, 10.0, 10.0, 4.0, 12.0, 12.0, 12.0, 9.0,
      7.0, 8.0, 9.0, 9.0, 7.0, 9.0, 12.0, 11.0, 15.0, 13.0, 8.0, 7.0, 9.0, 9.0, 6.0,
      7.0, 12.0, 13.0, 9.0, 12.0, 8.0, 6.0, 10.0, 12.0, 4.0, 7.0, 12.0, 7.0, 9.0,
      10.0, 9.0, 10.0, 12.0, 7.0, 10.0, 11.0, 10.0, 7.0, 8.0, 6.0, 9.0, 11.0, 14.0,
      7.0, 13.0, 12.0, 5.0, 6.0, 7.0, 9.0, 11.0, 10.0, 5.0, 13.0, 8.0, 11.0, 12.0,
      13.0, 7.0, 7.0, 3.0, 10.0, 4.0, 12.0, 8.0, 12.0, 7.0, 9.0, 10.0, 11.0, 9.0,
      10.0, 8.0, 10.0, 8.0, 11.0, 6.0, 6.0, 5.0, 15.0, 10.0, 12.0, 8.0, 12.0, 12.0,
      5.0, 8.0, 14.0, 7.0, 9.0, 7.0, 7.0, 11.0, 13.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06477228569646383
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025340241538518195
    mean_inference_ms: 1.213606791585344
    mean_raw_obs_processing_ms: 0.2758788414755187
time_since_restore: 2902.1869502067566
time_this_iter_s: 10.150941133499146
time_total_s: 2902.1869502067566
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997082
timesteps_total: 3534200
training_iteration: 286
trial_id: default
train step: 287
agent_timesteps_total: 3547800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018984641668931494
  StateBufferConnector_ms: 0.0034280543057423718
  ViewRequirementAgentConnector_ms: 0.11457722142057598
counters:
  num_agent_steps_sampled: 3547800
  num_agent_steps_trained: 3531000
  num_env_steps_sampled: 3547800
  num_env_steps_trained: 3531000
  num_samples_added_to_queue: 3547500
  num_training_step_calls_since_last_synch_worker_weights: 531
  num_weight_broadcasts: 69772
custom_metrics: {}
date: 2023-08-14_16-11-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.160377358490566
episode_reward_min: 4.0
episodes_this_iter: 106
episodes_total: 27718
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6976235508918762
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 30.557796478271484
        total_loss: 84.15064239501953
        var_gnorm: 64.768798828125
        vf_explained_var: 0.835547685623169
        vf_loss: 114.16194152832031
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7062.0
  learner_queue:
    size_count: 7067
    size_mean: 15.2
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5748015748023623
  num_agent_steps_sampled: 3547800
  num_agent_steps_trained: 3531000
  num_env_steps_sampled: 3547800
  num_env_steps_trained: 3531000
  num_samples_added_to_queue: 3547500
  num_training_step_calls_since_last_synch_worker_weights: 531
  num_weight_broadcasts: 69772
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 220.821
    learner_load_time_ms: 1.56
    learner_load_wait_time_ms: 1.491
iterations_since_restore: 287
node_ip: 127.0.0.1
num_agent_steps_sampled: 3547800
num_agent_steps_trained: 3531000
num_env_steps_sampled: 3547800
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9964981169271
num_env_steps_trained: 3531000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9965238660675
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.142857142857146
  ram_util_percent: 81.61428571428573
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06474847749567109
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02532936469825095
  mean_inference_ms: 1.2131709515030014
  mean_raw_obs_processing_ms: 0.2757878248777603
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018984641668931494
    StateBufferConnector_ms: 0.0034280543057423718
    ViewRequirementAgentConnector_ms: 0.11457722142057598
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.160377358490566
  episode_reward_min: 4.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 10.0, 8.0, 6.0, 15.0, 10.0, 6.0, 15.0, 12.0, 8.0, 10.0,
      8.0, 8.0, 8.0, 13.0, 10.0, 11.0, 10.0, 9.0, 10.0, 7.0, 7.0, 12.0, 11.0, 10.0,
      8.0, 10.0, 10.0, 8.0, 11.0, 9.0, 17.0, 12.0, 6.0, 8.0, 13.0, 10.0, 9.0, 12.0,
      7.0, 9.0, 8.0, 8.0, 4.0, 12.0, 9.0, 7.0, 7.0, 8.0, 7.0, 13.0, 4.0, 12.0, 8.0,
      9.0, 8.0, 12.0, 5.0, 9.0, 11.0, 8.0, 8.0, 11.0, 8.0, 6.0, 10.0, 10.0, 8.0, 8.0,
      10.0, 8.0, 16.0, 8.0, 8.0, 8.0, 8.0, 13.0, 9.0, 8.0, 6.0, 10.0, 10.0, 6.0, 10.0,
      9.0, 6.0, 7.0, 9.0, 7.0, 7.0, 12.0, 12.0, 12.0, 7.0, 9.0, 7.0, 7.0, 8.0, 4.0,
      15.0, 10.0, 7.0, 11.0, 4.0, 6.0, 16.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06474847749567109
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02532936469825095
    mean_inference_ms: 1.2131709515030014
    mean_raw_obs_processing_ms: 0.2757878248777603
time_since_restore: 2912.3109200000763
time_this_iter_s: 10.123969793319702
time_total_s: 2912.3109200000763
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691997092
timesteps_total: 3547800
training_iteration: 287
trial_id: default
train step: 288
agent_timesteps_total: 3558700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024553537368774414
  StateBufferConnector_ms: 0.004572153091430664
  ViewRequirementAgentConnector_ms: 0.14507699012756348
counters:
  num_agent_steps_sampled: 3558700
  num_agent_steps_trained: 3542000
  num_env_steps_sampled: 3558700
  num_env_steps_trained: 3542000
  num_samples_added_to_queue: 3558500
  num_training_step_calls_since_last_synch_worker_weights: 1669
  num_weight_broadcasts: 69981
custom_metrics: {}
date: 2023-08-14_16-11-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.8
episode_reward_min: 2.0
episodes_this_iter: 84
episodes_total: 27802
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6684951186180115
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.354900360107422
        total_loss: 34.52760314941406
        var_gnorm: 64.7750473022461
        vf_explained_var: 0.8961001634597778
        vf_loss: 94.44995880126953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7084.0
  learner_queue:
    size_count: 7088
    size_mean: 15.0
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6492422502470643
  num_agent_steps_sampled: 3558700
  num_agent_steps_trained: 3542000
  num_env_steps_sampled: 3558700
  num_env_steps_trained: 3542000
  num_samples_added_to_queue: 3558500
  num_training_step_calls_since_last_synch_worker_weights: 1669
  num_weight_broadcasts: 69981
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 281.634
    learner_load_time_ms: 1.655
    learner_load_wait_time_ms: 1.636
iterations_since_restore: 288
node_ip: 127.0.0.1
num_agent_steps_sampled: 3558700
num_agent_steps_trained: 3542000
num_env_steps_sampled: 3558700
num_env_steps_sampled_this_iter: 10900
num_env_steps_sampled_throughput_per_sec: 1089.996075882734
num_env_steps_trained: 3542000
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9960398816581
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 58.99999999999999
  ram_util_percent: 84.64285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06480763000240153
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02533993667457765
  mean_inference_ms: 1.2134698251643115
  mean_raw_obs_processing_ms: 0.27588587824832084
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024553537368774414
    StateBufferConnector_ms: 0.004572153091430664
    ViewRequirementAgentConnector_ms: 0.14507699012756348
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.8
  episode_reward_min: 2.0
  episodes_this_iter: 84
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 12.0, 12.0, 7.0, 9.0, 7.0, 7.0, 8.0, 4.0, 15.0, 10.0, 7.0,
      11.0, 4.0, 6.0, 16.0, 7.0, 6.0, 8.0, 11.0, 12.0, 7.0, 12.0, 13.0, 11.0, 11.0,
      8.0, 11.0, 10.0, 11.0, 10.0, 9.0, 10.0, 7.0, 17.0, 10.0, 5.0, 8.0, 5.0, 2.0,
      10.0, 6.0, 7.0, 10.0, 10.0, 8.0, 6.0, 8.0, 13.0, 9.0, 9.0, 9.0, 8.0, 6.0, 11.0,
      8.0, 10.0, 10.0, 3.0, 11.0, 5.0, 7.0, 9.0, 11.0, 8.0, 11.0, 12.0, 5.0, 8.0,
      9.0, 4.0, 10.0, 7.0, 6.0, 4.0, 7.0, 10.0, 9.0, 6.0, 13.0, 8.0, 6.0, 6.0, 9.0,
      7.0, 12.0, 12.0, 13.0, 12.0, 11.0, 11.0, 8.0, 13.0, 5.0, 8.0, 6.0, 6.0, 6.0,
      12.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06480763000240153
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02533993667457765
    mean_inference_ms: 1.2134698251643115
    mean_raw_obs_processing_ms: 0.27588587824832084
time_since_restore: 2922.4082148075104
time_this_iter_s: 10.097294807434082
time_total_s: 2922.4082148075104
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691997103
timesteps_total: 3558700
training_iteration: 288
trial_id: default
train step: 289
agent_timesteps_total: 3568900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02559971809387207
  StateBufferConnector_ms: 0.004542827606201172
  ViewRequirementAgentConnector_ms: 0.14803647994995117
counters:
  num_agent_steps_sampled: 3568900
  num_agent_steps_trained: 3552000
  num_env_steps_sampled: 3568900
  num_env_steps_trained: 3552000
  num_samples_added_to_queue: 3568500
  num_training_step_calls_since_last_synch_worker_weights: 133
  num_weight_broadcasts: 70182
custom_metrics: {}
date: 2023-08-14_16-11-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.23
episode_reward_min: 3.0
episodes_this_iter: 80
episodes_total: 27882
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6842292547225952
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -32.11399841308594
        total_loss: 35.41830825805664
        var_gnorm: 64.77733612060547
        vf_explained_var: 0.746353030204773
        vf_loss: 141.9069061279297
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7104.0
  learner_queue:
    size_count: 7111
    size_mean: 14.98
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5683111936092278
  num_agent_steps_sampled: 3568900
  num_agent_steps_trained: 3552000
  num_env_steps_sampled: 3568900
  num_env_steps_trained: 3552000
  num_samples_added_to_queue: 3568500
  num_training_step_calls_since_last_synch_worker_weights: 133
  num_weight_broadcasts: 70182
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 189.448
    learner_load_time_ms: 1.68
    learner_load_wait_time_ms: 1.554
iterations_since_restore: 289
node_ip: 127.0.0.1
num_agent_steps_sampled: 3568900
num_agent_steps_trained: 3552000
num_env_steps_sampled: 3568900
num_env_steps_sampled_this_iter: 10200
num_env_steps_sampled_throughput_per_sec: 1019.9956226536732
num_env_steps_trained: 3552000
num_env_steps_trained_this_iter: 10000
num_env_steps_trained_throughput_per_sec: 999.9957084839933
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10000
perf:
  cpu_util_percent: 62.52666666666667
  ram_util_percent: 82.99333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06485625336405805
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025363197543039093
  mean_inference_ms: 1.2141127626946429
  mean_raw_obs_processing_ms: 0.2760260698257627
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02559971809387207
    StateBufferConnector_ms: 0.004542827606201172
    ViewRequirementAgentConnector_ms: 0.14803647994995117
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.23
  episode_reward_min: 3.0
  episodes_this_iter: 80
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 6.0, 6.0, 9.0, 7.0, 12.0, 12.0, 13.0, 12.0, 11.0, 11.0,
      8.0, 13.0, 5.0, 8.0, 6.0, 6.0, 6.0, 12.0, 8.0, 6.0, 12.0, 10.0, 13.0, 7.0, 11.0,
      14.0, 12.0, 12.0, 7.0, 6.0, 8.0, 11.0, 13.0, 9.0, 7.0, 7.0, 6.0, 10.0, 10.0,
      7.0, 11.0, 9.0, 6.0, 3.0, 8.0, 10.0, 7.0, 13.0, 6.0, 10.0, 9.0, 9.0, 6.0, 7.0,
      13.0, 10.0, 11.0, 15.0, 9.0, 12.0, 3.0, 8.0, 9.0, 7.0, 5.0, 7.0, 11.0, 9.0,
      10.0, 13.0, 14.0, 6.0, 7.0, 7.0, 10.0, 14.0, 7.0, 7.0, 9.0, 12.0, 11.0, 8.0,
      10.0, 8.0, 9.0, 9.0, 9.0, 11.0, 9.0, 10.0, 10.0, 13.0, 6.0, 15.0, 11.0, 13.0,
      10.0, 7.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06485625336405805
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025363197543039093
    mean_inference_ms: 1.2141127626946429
    mean_raw_obs_processing_ms: 0.2760260698257627
time_since_restore: 2932.5743589401245
time_this_iter_s: 10.166144132614136
time_total_s: 2932.5743589401245
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997113
timesteps_total: 3568900
training_iteration: 289
trial_id: default
train step: 290
agent_timesteps_total: 3578900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.026198148727416992
  StateBufferConnector_ms: 0.0047376155853271484
  ViewRequirementAgentConnector_ms: 0.15230584144592285
counters:
  num_agent_steps_sampled: 3578900
  num_agent_steps_trained: 3562000
  num_env_steps_sampled: 3578900
  num_env_steps_trained: 3562000
  num_samples_added_to_queue: 3578500
  num_training_step_calls_since_last_synch_worker_weights: 663
  num_weight_broadcasts: 70375
custom_metrics: {}
date: 2023-08-14_16-12-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.32
episode_reward_min: 3.0
episodes_this_iter: 78
episodes_total: 27960
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6743569374084473
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 16.26299285888672
        total_loss: 48.09566879272461
        var_gnorm: 64.77471160888672
        vf_explained_var: 0.8978793025016785
        vf_loss: 70.40892028808594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7124.0
  learner_queue:
    size_count: 7131
    size_mean: 14.58
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8983150423467652
  num_agent_steps_sampled: 3578900
  num_agent_steps_trained: 3562000
  num_env_steps_sampled: 3578900
  num_env_steps_trained: 3562000
  num_samples_added_to_queue: 3578500
  num_training_step_calls_since_last_synch_worker_weights: 663
  num_weight_broadcasts: 70375
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 193.792
    learner_load_time_ms: 1.476
    learner_load_wait_time_ms: 1.725
iterations_since_restore: 290
node_ip: 127.0.0.1
num_agent_steps_sampled: 3578900
num_agent_steps_trained: 3562000
num_env_steps_sampled: 3578900
num_env_steps_sampled_this_iter: 10000
num_env_steps_sampled_throughput_per_sec: 999.9961137922633
num_env_steps_trained: 3562000
num_env_steps_trained_this_iter: 10000
num_env_steps_trained_throughput_per_sec: 999.9961137922633
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10000
perf:
  cpu_util_percent: 63.17857142857143
  ram_util_percent: 83.99285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0649048504964412
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025388657110071478
  mean_inference_ms: 1.2148902389062062
  mean_raw_obs_processing_ms: 0.27618918533175985
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.026198148727416992
    StateBufferConnector_ms: 0.0047376155853271484
    ViewRequirementAgentConnector_ms: 0.15230584144592285
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.32
  episode_reward_min: 3.0
  episodes_this_iter: 78
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 9.0, 12.0, 11.0, 8.0, 10.0, 8.0, 9.0, 9.0, 9.0, 11.0, 9.0,
      10.0, 10.0, 13.0, 6.0, 15.0, 11.0, 13.0, 10.0, 7.0, 8.0, 6.0, 12.0, 13.0, 13.0,
      8.0, 9.0, 10.0, 14.0, 8.0, 8.0, 12.0, 7.0, 8.0, 8.0, 11.0, 5.0, 6.0, 15.0, 10.0,
      10.0, 9.0, 8.0, 10.0, 7.0, 9.0, 10.0, 8.0, 9.0, 5.0, 10.0, 5.0, 9.0, 8.0, 10.0,
      10.0, 13.0, 10.0, 16.0, 10.0, 10.0, 6.0, 8.0, 12.0, 12.0, 6.0, 7.0, 8.0, 9.0,
      12.0, 7.0, 10.0, 7.0, 10.0, 7.0, 9.0, 14.0, 13.0, 12.0, 5.0, 11.0, 13.0, 9.0,
      8.0, 8.0, 3.0, 10.0, 9.0, 4.0, 4.0, 6.0, 9.0, 7.0, 14.0, 8.0, 12.0, 10.0, 8.0,
      11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0649048504964412
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025388657110071478
    mean_inference_ms: 1.2148902389062062
    mean_raw_obs_processing_ms: 0.27618918533175985
time_since_restore: 2942.7702679634094
time_this_iter_s: 10.195909023284912
time_total_s: 2942.7702679634094
timers:
  sample_time_ms: 0.02
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.051
timestamp: 1691997123
timesteps_total: 3578900
training_iteration: 290
trial_id: default
train step: 291
agent_timesteps_total: 3589800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024535655975341797
  StateBufferConnector_ms: 0.004514932632446289
  ViewRequirementAgentConnector_ms: 0.14806914329528809
counters:
  num_agent_steps_sampled: 3589800
  num_agent_steps_trained: 3573000
  num_env_steps_sampled: 3589800
  num_env_steps_trained: 3573000
  num_samples_added_to_queue: 3589500
  num_training_step_calls_since_last_synch_worker_weights: 185
  num_weight_broadcasts: 70587
custom_metrics: {}
date: 2023-08-14_16-12-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.66
episode_reward_min: 2.0
episodes_this_iter: 86
episodes_total: 28046
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.67527174949646
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -42.44953536987305
        total_loss: 36.31708908081055
        var_gnorm: 64.7763442993164
        vf_explained_var: 0.8122326135635376
        vf_loss: 164.2859649658203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7146.0
  learner_queue:
    size_count: 7153
    size_mean: 14.22
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 2.081249624624591
  num_agent_steps_sampled: 3589800
  num_agent_steps_trained: 3573000
  num_env_steps_sampled: 3589800
  num_env_steps_trained: 3573000
  num_samples_added_to_queue: 3589500
  num_training_step_calls_since_last_synch_worker_weights: 185
  num_weight_broadcasts: 70587
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 185.037
    learner_load_time_ms: 2.037
    learner_load_wait_time_ms: 1.777
iterations_since_restore: 291
node_ip: 127.0.0.1
num_agent_steps_sampled: 3589800
num_agent_steps_trained: 3573000
num_env_steps_sampled: 3589800
num_env_steps_sampled_this_iter: 10900
num_env_steps_sampled_throughput_per_sec: 1089.994646575518
num_env_steps_trained: 3573000
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9945974615316
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 60.26
  ram_util_percent: 83.19333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06491787177169792
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025410962295497073
  mean_inference_ms: 1.2155810590473957
  mean_raw_obs_processing_ms: 0.2763077208442355
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024535655975341797
    StateBufferConnector_ms: 0.004514932632446289
    ViewRequirementAgentConnector_ms: 0.14806914329528809
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.66
  episode_reward_min: 2.0
  episodes_this_iter: 86
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 10.0, 9.0, 4.0, 4.0, 6.0, 9.0, 7.0, 14.0, 8.0, 12.0, 10.0,
      8.0, 11.0, 8.0, 8.0, 7.0, 13.0, 8.0, 6.0, 10.0, 9.0, 8.0, 9.0, 7.0, 8.0, 14.0,
      12.0, 12.0, 15.0, 10.0, 14.0, 7.0, 9.0, 5.0, 7.0, 6.0, 5.0, 9.0, 10.0, 6.0,
      4.0, 9.0, 4.0, 10.0, 9.0, 9.0, 8.0, 10.0, 5.0, 9.0, 6.0, 8.0, 7.0, 9.0, 12.0,
      10.0, 6.0, 10.0, 3.0, 7.0, 7.0, 10.0, 5.0, 10.0, 10.0, 2.0, 9.0, 10.0, 12.0,
      8.0, 8.0, 11.0, 9.0, 6.0, 6.0, 11.0, 9.0, 8.0, 7.0, 10.0, 9.0, 6.0, 12.0, 7.0,
      10.0, 7.0, 9.0, 13.0, 8.0, 9.0, 11.0, 14.0, 11.0, 10.0, 11.0, 9.0, 12.0, 13.0,
      5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06491787177169792
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025410962295497073
    mean_inference_ms: 1.2155810590473957
    mean_raw_obs_processing_ms: 0.2763077208442355
time_since_restore: 2952.9804520606995
time_this_iter_s: 10.210184097290039
time_total_s: 2952.9804520606995
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691997133
timesteps_total: 3589800
training_iteration: 291
trial_id: default
train step: 292
agent_timesteps_total: 3602200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02131032943725586
  StateBufferConnector_ms: 0.0038323402404785156
  ViewRequirementAgentConnector_ms: 0.12874531745910645
counters:
  num_agent_steps_sampled: 3602200
  num_agent_steps_trained: 3585500
  num_env_steps_sampled: 3602200
  num_env_steps_trained: 3585500
  num_samples_added_to_queue: 3602000
  num_training_step_calls_since_last_synch_worker_weights: 1681
  num_weight_broadcasts: 70825
custom_metrics: {}
date: 2023-08-14_16-12-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.49
episode_reward_min: 4.0
episodes_this_iter: 96
episodes_total: 28142
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6801531910896301
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 24.410554885864258
        total_loss: 103.94819641113281
        var_gnorm: 64.77747344970703
        vf_explained_var: 0.7960512638092041
        vf_loss: 165.87681579589844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7171.0
  learner_queue:
    size_count: 7176
    size_mean: 14.48
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.0123617964968425
  num_agent_steps_sampled: 3602200
  num_agent_steps_trained: 3585500
  num_env_steps_sampled: 3602200
  num_env_steps_trained: 3585500
  num_samples_added_to_queue: 3602000
  num_training_step_calls_since_last_synch_worker_weights: 1681
  num_weight_broadcasts: 70825
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 220.681
    learner_load_time_ms: 2.043
    learner_load_wait_time_ms: 1.769
iterations_since_restore: 292
node_ip: 127.0.0.1
num_agent_steps_sampled: 3602200
num_agent_steps_trained: 3585500
num_env_steps_sampled: 3602200
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.9944124473584
num_env_steps_trained: 3585500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.99436738645
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.78571428571429
  ram_util_percent: 80.54285714285716
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06489724465868953
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025415831118740594
  mean_inference_ms: 1.2156986591884675
  mean_raw_obs_processing_ms: 0.2763100457090618
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02131032943725586
    StateBufferConnector_ms: 0.0038323402404785156
    ViewRequirementAgentConnector_ms: 0.12874531745910645
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.49
  episode_reward_min: 4.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 12.0, 13.0, 5.0, 9.0, 7.0, 6.0, 9.0, 11.0, 8.0, 9.0, 9.0,
      9.0, 7.0, 7.0, 8.0, 7.0, 10.0, 9.0, 10.0, 14.0, 11.0, 8.0, 10.0, 9.0, 8.0, 11.0,
      7.0, 14.0, 10.0, 13.0, 10.0, 7.0, 15.0, 15.0, 11.0, 11.0, 13.0, 4.0, 8.0, 8.0,
      11.0, 10.0, 9.0, 8.0, 12.0, 6.0, 5.0, 11.0, 9.0, 13.0, 11.0, 12.0, 10.0, 8.0,
      10.0, 9.0, 12.0, 9.0, 13.0, 10.0, 7.0, 8.0, 8.0, 8.0, 7.0, 10.0, 7.0, 10.0,
      9.0, 9.0, 5.0, 13.0, 12.0, 8.0, 14.0, 10.0, 8.0, 11.0, 10.0, 4.0, 9.0, 12.0,
      6.0, 6.0, 8.0, 17.0, 12.0, 5.0, 5.0, 13.0, 10.0, 11.0, 11.0, 8.0, 18.0, 9.0,
      7.0, 7.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06489724465868953
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025415831118740594
    mean_inference_ms: 1.2156986591884675
    mean_raw_obs_processing_ms: 0.2763100457090618
time_since_restore: 2963.1291880607605
time_this_iter_s: 10.148736000061035
time_total_s: 2963.1291880607605
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.047
timestamp: 1691997143
timesteps_total: 3602200
training_iteration: 292
trial_id: default
train step: 293
agent_timesteps_total: 3613800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02276611328125
  StateBufferConnector_ms: 0.004083395004272461
  ViewRequirementAgentConnector_ms: 0.13378238677978516
counters:
  num_agent_steps_sampled: 3613800
  num_agent_steps_trained: 3597000
  num_env_steps_sampled: 3613800
  num_env_steps_trained: 3597000
  num_samples_added_to_queue: 3613500
  num_training_step_calls_since_last_synch_worker_weights: 368
  num_weight_broadcasts: 71054
custom_metrics: {}
date: 2023-08-14_16-12-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.76
episode_reward_min: 4.0
episodes_this_iter: 92
episodes_total: 28234
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6947794556617737
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 52.2238655090332
        total_loss: 82.44072723388672
        var_gnorm: 64.7768325805664
        vf_explained_var: 0.9002774953842163
        vf_loss: 67.38151550292969
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7194.0
  learner_queue:
    size_count: 7201
    size_mean: 14.66
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.965807722031837
  num_agent_steps_sampled: 3613800
  num_agent_steps_trained: 3597000
  num_env_steps_sampled: 3613800
  num_env_steps_trained: 3597000
  num_samples_added_to_queue: 3613500
  num_training_step_calls_since_last_synch_worker_weights: 368
  num_weight_broadcasts: 71054
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 183.386
    learner_load_time_ms: 2.051
    learner_load_wait_time_ms: 1.73
iterations_since_restore: 293
node_ip: 127.0.0.1
num_agent_steps_sampled: 3613800
num_agent_steps_trained: 3597000
num_env_steps_sampled: 3613800
num_env_steps_sampled_this_iter: 11600
num_env_steps_sampled_throughput_per_sec: 1159.993860277248
num_env_steps_trained: 3597000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9939132058923
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 58.528571428571425
  ram_util_percent: 81.60714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06491959134854522
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025424578327350247
  mean_inference_ms: 1.2159414123342835
  mean_raw_obs_processing_ms: 0.2763625455229795
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02276611328125
    StateBufferConnector_ms: 0.004083395004272461
    ViewRequirementAgentConnector_ms: 0.13378238677978516
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.76
  episode_reward_min: 4.0
  episodes_this_iter: 92
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 11.0, 8.0, 18.0, 9.0, 7.0, 7.0, 8.0, 9.0, 10.0, 5.0, 12.0,
      7.0, 9.0, 8.0, 6.0, 10.0, 6.0, 8.0, 8.0, 12.0, 10.0, 13.0, 9.0, 13.0, 15.0,
      8.0, 8.0, 9.0, 9.0, 5.0, 5.0, 11.0, 10.0, 15.0, 9.0, 10.0, 5.0, 8.0, 10.0, 12.0,
      12.0, 9.0, 4.0, 9.0, 10.0, 11.0, 11.0, 7.0, 10.0, 8.0, 16.0, 14.0, 12.0, 9.0,
      10.0, 12.0, 11.0, 8.0, 9.0, 6.0, 9.0, 7.0, 10.0, 11.0, 7.0, 9.0, 8.0, 9.0, 8.0,
      13.0, 9.0, 11.0, 11.0, 9.0, 12.0, 14.0, 13.0, 15.0, 8.0, 9.0, 13.0, 8.0, 9.0,
      10.0, 15.0, 6.0, 11.0, 11.0, 6.0, 9.0, 8.0, 9.0, 13.0, 15.0, 10.0, 11.0, 11.0,
      10.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06491959134854522
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025424578327350247
    mean_inference_ms: 1.2159414123342835
    mean_raw_obs_processing_ms: 0.2763625455229795
time_since_restore: 2973.3622319698334
time_this_iter_s: 10.233043909072876
time_total_s: 2973.3622319698334
timers:
  sample_time_ms: 0.022
  synch_weights_time_ms: 0.006
  training_iteration_time_ms: 0.055
timestamp: 1691997154
timesteps_total: 3613800
training_iteration: 293
trial_id: default
train step: 294
agent_timesteps_total: 3626100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02108025550842285
  StateBufferConnector_ms: 0.003835439682006836
  ViewRequirementAgentConnector_ms: 0.12728238105773926
counters:
  num_agent_steps_sampled: 3626100
  num_agent_steps_trained: 3609500
  num_env_steps_sampled: 3626100
  num_env_steps_trained: 3609500
  num_samples_added_to_queue: 3626000
  num_training_step_calls_since_last_synch_worker_weights: 519
  num_weight_broadcasts: 71293
custom_metrics: {}
date: 2023-08-14_16-12-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.37
episode_reward_min: 4.0
episodes_this_iter: 96
episodes_total: 28330
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6974647045135498
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 54.567222595214844
        total_loss: 110.94169616699219
        var_gnorm: 64.77777099609375
        vf_explained_var: 0.83382248878479
        vf_loss: 119.72357940673828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7219.0
  learner_queue:
    size_count: 7225
    size_mean: 14.76
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.8499729727755485
  num_agent_steps_sampled: 3626100
  num_agent_steps_trained: 3609500
  num_env_steps_sampled: 3626100
  num_env_steps_trained: 3609500
  num_samples_added_to_queue: 3626000
  num_training_step_calls_since_last_synch_worker_weights: 519
  num_weight_broadcasts: 71293
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 191.197
    learner_load_time_ms: 2.062
    learner_load_wait_time_ms: 1.696
iterations_since_restore: 294
node_ip: 127.0.0.1
num_agent_steps_sampled: 3626100
num_agent_steps_trained: 3609500
num_env_steps_sampled: 3626100
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.9968915064217
num_env_steps_trained: 3609500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9968409618104
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 55.88666666666667
  ram_util_percent: 80.53333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06491284924436881
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025430027856483458
  mean_inference_ms: 1.216010973062864
  mean_raw_obs_processing_ms: 0.2763651939379283
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02108025550842285
    StateBufferConnector_ms: 0.003835439682006836
    ViewRequirementAgentConnector_ms: 0.12728238105773926
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.37
  episode_reward_min: 4.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 11.0, 10.0, 8.0, 7.0, 8.0, 11.0, 8.0, 9.0, 9.0, 11.0, 11.0,
      16.0, 10.0, 8.0, 5.0, 8.0, 11.0, 8.0, 7.0, 7.0, 9.0, 12.0, 7.0, 13.0, 12.0,
      10.0, 7.0, 7.0, 10.0, 7.0, 9.0, 11.0, 10.0, 8.0, 8.0, 7.0, 10.0, 8.0, 11.0,
      4.0, 5.0, 9.0, 11.0, 6.0, 15.0, 11.0, 8.0, 10.0, 16.0, 7.0, 4.0, 7.0, 10.0,
      12.0, 8.0, 13.0, 8.0, 11.0, 5.0, 8.0, 13.0, 10.0, 14.0, 10.0, 10.0, 9.0, 6.0,
      13.0, 14.0, 7.0, 8.0, 13.0, 12.0, 8.0, 6.0, 13.0, 9.0, 6.0, 12.0, 13.0, 11.0,
      8.0, 13.0, 5.0, 13.0, 8.0, 12.0, 7.0, 5.0, 8.0, 9.0, 9.0, 10.0, 10.0, 9.0, 10.0,
      7.0, 8.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06491284924436881
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025430027856483458
    mean_inference_ms: 1.216010973062864
    mean_raw_obs_processing_ms: 0.2763651939379283
time_since_restore: 2983.5336921215057
time_this_iter_s: 10.171460151672363
time_total_s: 2983.5336921215057
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691997164
timesteps_total: 3626100
training_iteration: 294
trial_id: default
train step: 295
agent_timesteps_total: 3638300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021016597747802734
  StateBufferConnector_ms: 0.003728151321411133
  ViewRequirementAgentConnector_ms: 0.12601709365844727
counters:
  num_agent_steps_sampled: 3638300
  num_agent_steps_trained: 3621500
  num_env_steps_sampled: 3638300
  num_env_steps_trained: 3621500
  num_samples_added_to_queue: 3638000
  num_training_step_calls_since_last_synch_worker_weights: 834
  num_weight_broadcasts: 71528
custom_metrics: {}
date: 2023-08-14_16-12-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.88
episode_reward_min: 3.0
episodes_this_iter: 94
episodes_total: 28424
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6899809837341309
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 12.893609046936035
        total_loss: 67.60558319091797
        var_gnorm: 64.78005981445312
        vf_explained_var: 0.8774722814559937
        vf_loss: 116.32376098632812
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7243.0
  learner_queue:
    size_count: 7248
    size_mean: 14.72
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.90829767070025
  num_agent_steps_sampled: 3638300
  num_agent_steps_trained: 3621500
  num_env_steps_sampled: 3638300
  num_env_steps_trained: 3621500
  num_samples_added_to_queue: 3638000
  num_training_step_calls_since_last_synch_worker_weights: 834
  num_weight_broadcasts: 71528
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 229.997
    learner_load_time_ms: 1.989
    learner_load_wait_time_ms: 1.611
iterations_since_restore: 295
node_ip: 127.0.0.1
num_agent_steps_sampled: 3638300
num_agent_steps_trained: 3621500
num_env_steps_sampled: 3638300
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.9970913002699
num_env_steps_trained: 3621500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.997138983872
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 54.878571428571426
  ram_util_percent: 79.45
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06491674559177481
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02543099159008456
  mean_inference_ms: 1.2159668967507673
  mean_raw_obs_processing_ms: 0.2763624455289087
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021016597747802734
    StateBufferConnector_ms: 0.003728151321411133
    ViewRequirementAgentConnector_ms: 0.12601709365844727
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.88
  episode_reward_min: 3.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 9.0, 10.0, 7.0, 8.0, 11.0, 7.0, 7.0, 8.0, 5.0, 12.0, 8.0,
      10.0, 7.0, 9.0, 5.0, 10.0, 10.0, 9.0, 15.0, 10.0, 13.0, 7.0, 10.0, 5.0, 15.0,
      10.0, 8.0, 6.0, 6.0, 13.0, 14.0, 3.0, 10.0, 10.0, 11.0, 9.0, 6.0, 6.0, 7.0,
      4.0, 15.0, 10.0, 16.0, 8.0, 14.0, 8.0, 4.0, 9.0, 6.0, 7.0, 7.0, 7.0, 7.0, 8.0,
      11.0, 8.0, 16.0, 10.0, 10.0, 11.0, 14.0, 8.0, 12.0, 10.0, 7.0, 9.0, 6.0, 9.0,
      6.0, 8.0, 10.0, 9.0, 7.0, 8.0, 5.0, 8.0, 11.0, 6.0, 6.0, 7.0, 6.0, 11.0, 7.0,
      11.0, 9.0, 9.0, 7.0, 4.0, 7.0, 11.0, 13.0, 8.0, 8.0, 7.0, 10.0, 13.0, 9.0, 9.0,
      11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06491674559177481
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02543099159008456
    mean_inference_ms: 1.2159668967507673
    mean_raw_obs_processing_ms: 0.2763624455289087
time_since_restore: 2993.6654381752014
time_this_iter_s: 10.131746053695679
time_total_s: 2993.6654381752014
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691997174
timesteps_total: 3638300
training_iteration: 295
trial_id: default
train step: 296
agent_timesteps_total: 3651100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020990848541259766
  StateBufferConnector_ms: 0.0037250518798828125
  ViewRequirementAgentConnector_ms: 0.1260817050933838
counters:
  num_agent_steps_sampled: 3651100
  num_agent_steps_trained: 3634500
  num_env_steps_sampled: 3651100
  num_env_steps_trained: 3634500
  num_samples_added_to_queue: 3651000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 71779
custom_metrics: {}
date: 2023-08-14_16-13-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 20.0
episode_reward_mean: 9.46
episode_reward_min: 4.0
episodes_this_iter: 100
episodes_total: 28524
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7131602764129639
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.613494873046875
        total_loss: 70.16197204589844
        var_gnorm: 64.77931213378906
        vf_explained_var: 0.8059297800064087
        vf_loss: 186.6825408935547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7269.0
  learner_queue:
    size_count: 7276
    size_mean: 15.1
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5652475842498528
  num_agent_steps_sampled: 3651100
  num_agent_steps_trained: 3634500
  num_env_steps_sampled: 3651100
  num_env_steps_trained: 3634500
  num_samples_added_to_queue: 3651000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 71779
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 134.396
    learner_load_time_ms: 1.991
    learner_load_wait_time_ms: 1.529
iterations_since_restore: 296
node_ip: 127.0.0.1
num_agent_steps_sampled: 3651100
num_agent_steps_trained: 3634500
num_env_steps_sampled: 3651100
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.5538359915881
num_env_steps_trained: 3634500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.5468646789568
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.964285714285715
  ram_util_percent: 79.00714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06489641907913749
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02543034925804587
  mean_inference_ms: 1.215853563514903
  mean_raw_obs_processing_ms: 0.27633396367429475
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020990848541259766
    StateBufferConnector_ms: 0.0037250518798828125
    ViewRequirementAgentConnector_ms: 0.1260817050933838
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 20.0
  episode_reward_mean: 9.46
  episode_reward_min: 4.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 7.0, 11.0, 7.0, 10.0, 13.0, 11.0, 8.0, 5.0, 5.0, 8.0, 6.0,
      11.0, 15.0, 14.0, 13.0, 9.0, 13.0, 10.0, 9.0, 5.0, 12.0, 7.0, 10.0, 11.0, 14.0,
      10.0, 11.0, 11.0, 6.0, 10.0, 12.0, 11.0, 7.0, 12.0, 7.0, 4.0, 10.0, 10.0, 9.0,
      8.0, 9.0, 9.0, 8.0, 9.0, 7.0, 12.0, 8.0, 8.0, 8.0, 8.0, 8.0, 12.0, 7.0, 7.0,
      12.0, 14.0, 12.0, 6.0, 9.0, 12.0, 9.0, 11.0, 7.0, 12.0, 9.0, 8.0, 16.0, 11.0,
      6.0, 8.0, 9.0, 13.0, 9.0, 11.0, 12.0, 13.0, 5.0, 7.0, 11.0, 8.0, 7.0, 12.0,
      7.0, 12.0, 7.0, 9.0, 5.0, 8.0, 13.0, 5.0, 7.0, 17.0, 9.0, 8.0, 11.0, 10.0, 20.0,
      4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06489641907913749
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02543034925804587
    mean_inference_ms: 1.215853563514903
    mean_raw_obs_processing_ms: 0.27633396367429475
time_since_restore: 3003.8461589813232
time_this_iter_s: 10.180720806121826
time_total_s: 3003.8461589813232
timers:
  sample_time_ms: 0.145
  synch_weights_time_ms: 0.509
  training_iteration_time_ms: 0.763
timestamp: 1691997184
timesteps_total: 3651100
training_iteration: 296
trial_id: default
train step: 297
agent_timesteps_total: 3663350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02115011215209961
  StateBufferConnector_ms: 0.003827333450317383
  ViewRequirementAgentConnector_ms: 0.13411736488342285
counters:
  num_agent_steps_sampled: 3663350
  num_agent_steps_trained: 3646500
  num_env_steps_sampled: 3663350
  num_env_steps_trained: 3646500
  num_samples_added_to_queue: 3663000
  num_training_step_calls_since_last_synch_worker_weights: 1295
  num_weight_broadcasts: 72022
custom_metrics: {}
date: 2023-08-14_16-13-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 20.0
episode_reward_mean: 9.11
episode_reward_min: 3.0
episodes_this_iter: 96
episodes_total: 28620
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6945685744285583
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -49.84546661376953
        total_loss: -14.74856948852539
        var_gnorm: 64.77941131591797
        vf_explained_var: 0.8982871770858765
        vf_loss: 77.13948059082031
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7293.0
  learner_queue:
    size_count: 7297
    size_mean: 14.9
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7691806012954132
  num_agent_steps_sampled: 3663350
  num_agent_steps_trained: 3646500
  num_env_steps_sampled: 3663350
  num_env_steps_trained: 3646500
  num_samples_added_to_queue: 3663000
  num_training_step_calls_since_last_synch_worker_weights: 1295
  num_weight_broadcasts: 72022
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 293.814
    learner_load_time_ms: 1.777
    learner_load_wait_time_ms: 1.766
iterations_since_restore: 297
node_ip: 127.0.0.1
num_agent_steps_sampled: 3663350
num_agent_steps_trained: 3646500
num_env_steps_sampled: 3663350
num_env_steps_sampled_this_iter: 12250
num_env_steps_sampled_throughput_per_sec: 1224.9998539686378
num_env_steps_trained: 3646500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9998569488696
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 54.919999999999995
  ram_util_percent: 78.07333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0649055346417854
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025430361633922177
  mean_inference_ms: 1.2158280329451416
  mean_raw_obs_processing_ms: 0.27633645014525504
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02115011215209961
    StateBufferConnector_ms: 0.003827333450317383
    ViewRequirementAgentConnector_ms: 0.13411736488342285
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 20.0
  episode_reward_mean: 9.11
  episode_reward_min: 3.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 20.0, 4.0, 7.0, 12.0, 14.0, 9.0, 9.0, 12.0, 14.0, 13.0,
      14.0, 11.0, 10.0, 9.0, 9.0, 7.0, 6.0, 10.0, 7.0, 12.0, 10.0, 10.0, 8.0, 12.0,
      10.0, 8.0, 6.0, 11.0, 3.0, 9.0, 8.0, 6.0, 7.0, 9.0, 7.0, 10.0, 8.0, 7.0, 7.0,
      15.0, 9.0, 12.0, 6.0, 5.0, 5.0, 15.0, 16.0, 10.0, 3.0, 11.0, 10.0, 8.0, 5.0,
      15.0, 7.0, 6.0, 8.0, 8.0, 8.0, 7.0, 9.0, 12.0, 8.0, 7.0, 8.0, 10.0, 7.0, 8.0,
      7.0, 7.0, 7.0, 8.0, 4.0, 9.0, 9.0, 9.0, 10.0, 12.0, 11.0, 8.0, 6.0, 9.0, 10.0,
      11.0, 9.0, 7.0, 11.0, 6.0, 15.0, 12.0, 12.0, 14.0, 8.0, 7.0, 8.0, 5.0, 12.0,
      6.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0649055346417854
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025430361633922177
    mean_inference_ms: 1.2158280329451416
    mean_raw_obs_processing_ms: 0.27633645014525504
time_since_restore: 3013.9520432949066
time_this_iter_s: 10.105884313583374
time_total_s: 3013.9520432949066
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691997194
timesteps_total: 3663350
training_iteration: 297
trial_id: default
train step: 298
agent_timesteps_total: 3676850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019305831981155108
  StateBufferConnector_ms: 0.003470564788242556
  ViewRequirementAgentConnector_ms: 0.11730846369041587
counters:
  num_agent_steps_sampled: 3676850
  num_agent_steps_trained: 3660000
  num_env_steps_sampled: 3676850
  num_env_steps_trained: 3660000
  num_samples_added_to_queue: 3676500
  num_training_step_calls_since_last_synch_worker_weights: 365
  num_weight_broadcasts: 72289
custom_metrics: {}
date: 2023-08-14_16-13-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.90566037735849
episode_reward_min: 5.0
episodes_this_iter: 106
episodes_total: 28726
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.694901168346405
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -12.579490661621094
        total_loss: 36.44020462036133
        var_gnorm: 64.77870178222656
        vf_explained_var: 0.8713461756706238
        vf_loss: 104.9884033203125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7320.0
  learner_queue:
    size_count: 7327
    size_mean: 15.16
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.540908822740658
  num_agent_steps_sampled: 3676850
  num_agent_steps_trained: 3660000
  num_env_steps_sampled: 3676850
  num_env_steps_trained: 3660000
  num_samples_added_to_queue: 3676500
  num_training_step_calls_since_last_synch_worker_weights: 365
  num_weight_broadcasts: 72289
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 147.746
    learner_load_time_ms: 1.759
    learner_load_wait_time_ms: 1.371
iterations_since_restore: 298
node_ip: 127.0.0.1
num_agent_steps_sampled: 3676850
num_agent_steps_trained: 3660000
num_env_steps_sampled: 3676850
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9940455222506
num_env_steps_trained: 3660000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9940455222506
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.77857142857143
  ram_util_percent: 78.49285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0648750958900752
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025421815290292662
  mean_inference_ms: 1.2154627414967738
  mean_raw_obs_processing_ms: 0.27624972617763166
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019305831981155108
    StateBufferConnector_ms: 0.003470564788242556
    ViewRequirementAgentConnector_ms: 0.11730846369041587
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.90566037735849
  episode_reward_min: 5.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 9.0, 8.0, 9.0, 7.0, 13.0, 8.0, 11.0, 8.0, 12.0, 9.0, 13.0,
      11.0, 7.0, 9.0, 12.0, 7.0, 13.0, 9.0, 18.0, 8.0, 9.0, 12.0, 12.0, 10.0, 11.0,
      8.0, 8.0, 9.0, 8.0, 6.0, 5.0, 6.0, 12.0, 10.0, 9.0, 9.0, 10.0, 12.0, 11.0, 15.0,
      10.0, 10.0, 12.0, 11.0, 10.0, 9.0, 10.0, 9.0, 8.0, 15.0, 12.0, 9.0, 7.0, 7.0,
      9.0, 12.0, 9.0, 11.0, 11.0, 12.0, 7.0, 12.0, 12.0, 11.0, 13.0, 6.0, 8.0, 11.0,
      8.0, 13.0, 11.0, 13.0, 10.0, 11.0, 11.0, 8.0, 13.0, 11.0, 13.0, 7.0, 8.0, 6.0,
      8.0, 9.0, 7.0, 8.0, 11.0, 8.0, 9.0, 10.0, 13.0, 8.0, 8.0, 7.0, 18.0, 13.0, 8.0,
      13.0, 6.0, 8.0, 9.0, 9.0, 13.0, 10.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0648750958900752
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025421815290292662
    mean_inference_ms: 1.2154627414967738
    mean_raw_obs_processing_ms: 0.27624972617763166
time_since_restore: 3024.1037831306458
time_this_iter_s: 10.151739835739136
time_total_s: 3024.1037831306458
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691997204
timesteps_total: 3676850
training_iteration: 298
trial_id: default
train step: 299
agent_timesteps_total: 3689850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020432472229003906
  StateBufferConnector_ms: 0.0036281697890337777
  ViewRequirementAgentConnector_ms: 0.12248918121936274
counters:
  num_agent_steps_sampled: 3689850
  num_agent_steps_trained: 3673000
  num_env_steps_sampled: 3689850
  num_env_steps_trained: 3673000
  num_samples_added_to_queue: 3689500
  num_training_step_calls_since_last_synch_worker_weights: 10
  num_weight_broadcasts: 72542
custom_metrics: {}
date: 2023-08-14_16-13-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.049019607843137
episode_reward_min: 2.0
episodes_this_iter: 102
episodes_total: 28828
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6671359539031982
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -3.12361216545105
        total_loss: 104.06979370117188
        var_gnorm: 64.78186798095703
        vf_explained_var: 0.7686352729797363
        vf_loss: 221.05816650390625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7346.0
  learner_queue:
    size_count: 7354
    size_mean: 14.82
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.9968975937688944
  num_agent_steps_sampled: 3689850
  num_agent_steps_trained: 3673000
  num_env_steps_sampled: 3689850
  num_env_steps_trained: 3673000
  num_samples_added_to_queue: 3689500
  num_training_step_calls_since_last_synch_worker_weights: 10
  num_weight_broadcasts: 72542
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 112.602
    learner_load_time_ms: 1.875
    learner_load_wait_time_ms: 1.613
iterations_since_restore: 299
node_ip: 127.0.0.1
num_agent_steps_sampled: 3689850
num_agent_steps_trained: 3673000
num_env_steps_sampled: 3689850
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9946689824328
num_env_steps_trained: 3673000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9946689824328
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.728571428571435
  ram_util_percent: 78.56428571428572
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06486520504286575
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025418919061178536
  mean_inference_ms: 1.2152701854327626
  mean_raw_obs_processing_ms: 0.27620418834438115
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020432472229003906
    StateBufferConnector_ms: 0.0036281697890337777
    ViewRequirementAgentConnector_ms: 0.12248918121936274
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.049019607843137
  episode_reward_min: 2.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 7.0, 11.0, 6.0, 10.0, 9.0, 9.0, 4.0, 13.0, 11.0, 14.0, 7.0,
      10.0, 6.0, 11.0, 5.0, 10.0, 12.0, 12.0, 8.0, 9.0, 2.0, 8.0, 11.0, 8.0, 8.0,
      14.0, 3.0, 9.0, 5.0, 10.0, 11.0, 16.0, 7.0, 9.0, 10.0, 8.0, 5.0, 10.0, 5.0,
      12.0, 13.0, 10.0, 8.0, 12.0, 9.0, 6.0, 12.0, 4.0, 7.0, 13.0, 9.0, 12.0, 6.0,
      10.0, 12.0, 7.0, 11.0, 12.0, 5.0, 6.0, 11.0, 5.0, 10.0, 8.0, 8.0, 8.0, 5.0,
      9.0, 12.0, 14.0, 9.0, 6.0, 8.0, 8.0, 7.0, 12.0, 9.0, 8.0, 6.0, 12.0, 5.0, 11.0,
      7.0, 9.0, 11.0, 11.0, 12.0, 11.0, 11.0, 3.0, 13.0, 10.0, 11.0, 11.0, 10.0, 7.0,
      13.0, 7.0, 6.0, 11.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06486520504286575
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025418919061178536
    mean_inference_ms: 1.2152701854327626
    mean_raw_obs_processing_ms: 0.27620418834438115
time_since_restore: 3034.303722143173
time_this_iter_s: 10.199939012527466
time_total_s: 3034.303722143173
timers:
  sample_time_ms: 0.065
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.105
timestamp: 1691997215
timesteps_total: 3689850
training_iteration: 299
trial_id: default
train step: 300
agent_timesteps_total: 3702200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022429466247558594
  StateBufferConnector_ms: 0.0038118362426757812
  ViewRequirementAgentConnector_ms: 0.12817049026489258
counters:
  num_agent_steps_sampled: 3702200
  num_agent_steps_trained: 3685500
  num_env_steps_sampled: 3702200
  num_env_steps_trained: 3685500
  num_samples_added_to_queue: 3702000
  num_training_step_calls_since_last_synch_worker_weights: 88
  num_weight_broadcasts: 72786
custom_metrics: {}
date: 2023-08-14_16-13-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.22
episode_reward_min: 4.0
episodes_this_iter: 96
episodes_total: 28924
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6711066365242004
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 21.559396743774414
        total_loss: 93.35140228271484
        var_gnorm: 64.78382110595703
        vf_explained_var: 0.826371431350708
        vf_loss: 150.29507446289062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7371.0
  learner_queue:
    size_count: 7378
    size_mean: 14.64
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.0664946164943183
  num_agent_steps_sampled: 3702200
  num_agent_steps_trained: 3685500
  num_env_steps_sampled: 3702200
  num_env_steps_trained: 3685500
  num_samples_added_to_queue: 3702000
  num_training_step_calls_since_last_synch_worker_weights: 88
  num_weight_broadcasts: 72786
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 141.401
    learner_load_time_ms: 1.852
    learner_load_wait_time_ms: 1.617
iterations_since_restore: 300
node_ip: 127.0.0.1
num_agent_steps_sampled: 3702200
num_agent_steps_trained: 3685500
num_env_steps_sampled: 3702200
num_env_steps_sampled_this_iter: 12350
num_env_steps_sampled_throughput_per_sec: 1234.9987633240685
num_env_steps_trained: 3685500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.998748303713
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 54.95333333333333
  ram_util_percent: 78.88666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0648749209225909
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025420106019766145
  mean_inference_ms: 1.2152470720681594
  mean_raw_obs_processing_ms: 0.2762056910616843
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022429466247558594
    StateBufferConnector_ms: 0.0038118362426757812
    ViewRequirementAgentConnector_ms: 0.12817049026489258
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.22
  episode_reward_min: 4.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 6.0, 11.0, 13.0, 11.0, 10.0, 7.0, 8.0, 7.0, 9.0, 10.0, 12.0,
      7.0, 9.0, 10.0, 10.0, 9.0, 12.0, 11.0, 9.0, 9.0, 7.0, 7.0, 10.0, 9.0, 10.0,
      9.0, 8.0, 8.0, 10.0, 12.0, 4.0, 7.0, 12.0, 4.0, 13.0, 4.0, 9.0, 8.0, 8.0, 7.0,
      8.0, 11.0, 11.0, 9.0, 7.0, 9.0, 10.0, 12.0, 11.0, 8.0, 16.0, 9.0, 10.0, 8.0,
      7.0, 8.0, 6.0, 11.0, 8.0, 5.0, 14.0, 9.0, 11.0, 7.0, 10.0, 10.0, 11.0, 13.0,
      8.0, 12.0, 8.0, 14.0, 5.0, 11.0, 14.0, 14.0, 8.0, 7.0, 8.0, 9.0, 10.0, 9.0,
      5.0, 12.0, 9.0, 8.0, 11.0, 9.0, 11.0, 10.0, 5.0, 9.0, 9.0, 7.0, 11.0, 9.0, 11.0,
      9.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0648749209225909
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025420106019766145
    mean_inference_ms: 1.2152470720681594
    mean_raw_obs_processing_ms: 0.2762056910616843
time_since_restore: 3044.485145330429
time_this_iter_s: 10.18142318725586
time_total_s: 3044.485145330429
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.05
timestamp: 1691997225
timesteps_total: 3702200
training_iteration: 300
trial_id: default
train step: 301
agent_timesteps_total: 3715600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019080298287527903
  StateBufferConnector_ms: 0.0034143811180478052
  ViewRequirementAgentConnector_ms: 0.116664795648484
counters:
  num_agent_steps_sampled: 3715600
  num_agent_steps_trained: 3699000
  num_env_steps_sampled: 3715600
  num_env_steps_trained: 3699000
  num_samples_added_to_queue: 3715500
  num_training_step_calls_since_last_synch_worker_weights: 1009
  num_weight_broadcasts: 73048
custom_metrics: {}
date: 2023-08-14_16-13-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.352380952380953
episode_reward_min: 3.0
episodes_this_iter: 105
episodes_total: 29029
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6614304780960083
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.72911262512207
        total_loss: 64.83126068115234
        var_gnorm: 64.78744506835938
        vf_explained_var: 0.7801328897476196
        vf_loss: 157.73504638671875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7398.0
  learner_queue:
    size_count: 7403
    size_mean: 14.58
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.126875642815066
  num_agent_steps_sampled: 3715600
  num_agent_steps_trained: 3699000
  num_env_steps_sampled: 3715600
  num_env_steps_trained: 3699000
  num_samples_added_to_queue: 3715500
  num_training_step_calls_since_last_synch_worker_weights: 1009
  num_weight_broadcasts: 73048
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 205.156
    learner_load_time_ms: 1.872
    learner_load_wait_time_ms: 1.69
iterations_since_restore: 301
node_ip: 127.0.0.1
num_agent_steps_sampled: 3715600
num_agent_steps_trained: 3699000
num_env_steps_sampled: 3715600
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9954314387633
num_env_steps_trained: 3699000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9953973450226
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.42142857142858
  ram_util_percent: 78.59285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06484508722781654
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025413435051418812
  mean_inference_ms: 1.214924039544422
  mean_raw_obs_processing_ms: 0.2761271039826481
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019080298287527903
    StateBufferConnector_ms: 0.0034143811180478052
    ViewRequirementAgentConnector_ms: 0.116664795648484
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.352380952380953
  episode_reward_min: 3.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 10.0, 9.0, 15.0, 6.0, 15.0, 4.0, 7.0, 3.0, 5.0, 11.0, 9.0,
      7.0, 9.0, 8.0, 10.0, 6.0, 9.0, 13.0, 13.0, 7.0, 11.0, 10.0, 9.0, 7.0, 7.0, 6.0,
      14.0, 5.0, 10.0, 6.0, 7.0, 8.0, 8.0, 10.0, 9.0, 9.0, 9.0, 7.0, 5.0, 6.0, 8.0,
      4.0, 14.0, 15.0, 8.0, 10.0, 12.0, 10.0, 12.0, 5.0, 9.0, 10.0, 7.0, 10.0, 13.0,
      8.0, 11.0, 11.0, 13.0, 6.0, 11.0, 11.0, 15.0, 11.0, 9.0, 8.0, 15.0, 9.0, 7.0,
      13.0, 14.0, 12.0, 7.0, 8.0, 8.0, 9.0, 8.0, 12.0, 9.0, 8.0, 7.0, 9.0, 11.0, 10.0,
      12.0, 11.0, 7.0, 11.0, 5.0, 9.0, 10.0, 8.0, 13.0, 12.0, 10.0, 6.0, 12.0, 5.0,
      10.0, 12.0, 13.0, 8.0, 10.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06484508722781654
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025413435051418812
    mean_inference_ms: 1.214924039544422
    mean_raw_obs_processing_ms: 0.2761271039826481
time_since_restore: 3054.6258583068848
time_this_iter_s: 10.140712976455688
time_total_s: 3054.6258583068848
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691997235
timesteps_total: 3715600
training_iteration: 301
trial_id: default
train step: 302
agent_timesteps_total: 3728600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020308588065353093
  StateBufferConnector_ms: 0.003720264808804381
  ViewRequirementAgentConnector_ms: 0.12490281871720857
counters:
  num_agent_steps_sampled: 3728600
  num_agent_steps_trained: 3712000
  num_env_steps_sampled: 3728600
  num_env_steps_trained: 3712000
  num_samples_added_to_queue: 3728500
  num_training_step_calls_since_last_synch_worker_weights: 381
  num_weight_broadcasts: 73302
custom_metrics: {}
date: 2023-08-14_16-14-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.352941176470589
episode_reward_min: 2.0
episodes_this_iter: 102
episodes_total: 29131
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6544290781021118
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -65.98994445800781
        total_loss: 3.491633415222168
        var_gnorm: 64.79259490966797
        vf_explained_var: 0.7601481676101685
        vf_loss: 145.5074462890625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7424.0
  learner_queue:
    size_count: 7431
    size_mean: 15.16
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5278743403827424
  num_agent_steps_sampled: 3728600
  num_agent_steps_trained: 3712000
  num_env_steps_sampled: 3728600
  num_env_steps_trained: 3712000
  num_samples_added_to_queue: 3728500
  num_training_step_calls_since_last_synch_worker_weights: 381
  num_weight_broadcasts: 73302
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 136.333
    learner_load_time_ms: 1.837
    learner_load_wait_time_ms: 1.56
iterations_since_restore: 302
node_ip: 127.0.0.1
num_agent_steps_sampled: 3728600
num_agent_steps_trained: 3712000
num_env_steps_sampled: 3728600
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.994142081908
num_env_steps_trained: 3712000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.994142081908
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.38571428571429
  ram_util_percent: 80.04285714285716
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0648361918648041
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02540919970816112
  mean_inference_ms: 1.2147160454944919
  mean_raw_obs_processing_ms: 0.2760889052832916
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020308588065353093
    StateBufferConnector_ms: 0.003720264808804381
    ViewRequirementAgentConnector_ms: 0.12490281871720857
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.352941176470589
  episode_reward_min: 2.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 16.0, 9.0, 14.0, 11.0, 8.0, 12.0, 7.0, 11.0, 7.0, 6.0,
      11.0, 15.0, 9.0, 7.0, 11.0, 11.0, 12.0, 10.0, 9.0, 11.0, 7.0, 11.0, 8.0, 13.0,
      7.0, 5.0, 10.0, 7.0, 12.0, 11.0, 8.0, 7.0, 8.0, 9.0, 6.0, 12.0, 9.0, 13.0, 8.0,
      10.0, 12.0, 8.0, 10.0, 7.0, 9.0, 7.0, 9.0, 8.0, 13.0, 6.0, 8.0, 9.0, 8.0, 6.0,
      5.0, 9.0, 11.0, 10.0, 8.0, 9.0, 11.0, 12.0, 8.0, 11.0, 13.0, 13.0, 7.0, 9.0,
      8.0, 12.0, 12.0, 4.0, 7.0, 8.0, 4.0, 9.0, 8.0, 11.0, 7.0, 8.0, 9.0, 10.0, 9.0,
      10.0, 7.0, 12.0, 8.0, 7.0, 6.0, 16.0, 5.0, 11.0, 8.0, 9.0, 11.0, 15.0, 13.0,
      11.0, 2.0, 13.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0648361918648041
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02540919970816112
    mean_inference_ms: 1.2147160454944919
    mean_raw_obs_processing_ms: 0.2760889052832916
time_since_restore: 3064.8092093467712
time_this_iter_s: 10.183351039886475
time_total_s: 3064.8092093467712
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691997245
timesteps_total: 3728600
training_iteration: 302
trial_id: default
train step: 303
agent_timesteps_total: 3742100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019262157953702487
  StateBufferConnector_ms: 0.0034242868423461914
  ViewRequirementAgentConnector_ms: 0.11658118321345402
counters:
  num_agent_steps_sampled: 3742100
  num_agent_steps_trained: 3725500
  num_env_steps_sampled: 3742100
  num_env_steps_trained: 3725500
  num_samples_added_to_queue: 3742000
  num_training_step_calls_since_last_synch_worker_weights: 561
  num_weight_broadcasts: 73568
custom_metrics: {}
date: 2023-08-14_16-14-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.115384615384615
episode_reward_min: 4.0
episodes_this_iter: 104
episodes_total: 29235
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6265228390693665
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -31.060779571533203
        total_loss: 18.049755096435547
        var_gnorm: 64.79178619384766
        vf_explained_var: 0.8466742038726807
        vf_loss: 104.48629760742188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7451.0
  learner_queue:
    size_count: 7458
    size_mean: 14.92
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8421726303471129
  num_agent_steps_sampled: 3742100
  num_agent_steps_trained: 3725500
  num_env_steps_sampled: 3742100
  num_env_steps_trained: 3725500
  num_samples_added_to_queue: 3742000
  num_training_step_calls_since_last_synch_worker_weights: 561
  num_weight_broadcasts: 73568
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 134.355
    learner_load_time_ms: 1.486
    learner_load_wait_time_ms: 1.674
iterations_since_restore: 303
node_ip: 127.0.0.1
num_agent_steps_sampled: 3742100
num_agent_steps_trained: 3725500
num_env_steps_sampled: 3742100
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9963629343745
num_env_steps_trained: 3725500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9963629343745
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.97999999999999
  ram_util_percent: 79.91999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06481657580068535
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025400334537785785
  mean_inference_ms: 1.214347632035677
  mean_raw_obs_processing_ms: 0.276014487541423
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019262157953702487
    StateBufferConnector_ms: 0.0034242868423461914
    ViewRequirementAgentConnector_ms: 0.11658118321345402
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.115384615384615
  episode_reward_min: 4.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 5.0, 10.0, 9.0, 9.0, 11.0, 6.0, 7.0, 7.0, 11.0, 9.0, 10.0,
      13.0, 8.0, 11.0, 11.0, 11.0, 13.0, 11.0, 7.0, 15.0, 4.0, 10.0, 11.0, 9.0, 7.0,
      5.0, 12.0, 10.0, 12.0, 8.0, 5.0, 11.0, 6.0, 10.0, 7.0, 8.0, 11.0, 12.0, 8.0,
      9.0, 9.0, 13.0, 5.0, 7.0, 11.0, 11.0, 7.0, 8.0, 12.0, 11.0, 5.0, 15.0, 11.0,
      9.0, 8.0, 8.0, 6.0, 13.0, 10.0, 12.0, 7.0, 8.0, 11.0, 8.0, 12.0, 6.0, 7.0, 6.0,
      9.0, 11.0, 9.0, 13.0, 7.0, 8.0, 8.0, 11.0, 7.0, 10.0, 8.0, 8.0, 10.0, 7.0, 10.0,
      9.0, 7.0, 6.0, 10.0, 7.0, 7.0, 8.0, 5.0, 9.0, 13.0, 10.0, 10.0, 11.0, 11.0,
      8.0, 7.0, 7.0, 8.0, 9.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06481657580068535
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025400334537785785
    mean_inference_ms: 1.214347632035677
    mean_raw_obs_processing_ms: 0.276014487541423
time_since_restore: 3074.983025074005
time_this_iter_s: 10.173815727233887
time_total_s: 3074.983025074005
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691997255
timesteps_total: 3742100
training_iteration: 303
trial_id: default
train step: 304
agent_timesteps_total: 3755600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019070562326683187
  StateBufferConnector_ms: 0.0034228810724222436
  ViewRequirementAgentConnector_ms: 0.11696545582897258
counters:
  num_agent_steps_sampled: 3755600
  num_agent_steps_trained: 3739000
  num_env_steps_sampled: 3755600
  num_env_steps_trained: 3739000
  num_samples_added_to_queue: 3755500
  num_training_step_calls_since_last_synch_worker_weights: 1325
  num_weight_broadcasts: 73833
custom_metrics: {}
date: 2023-08-14_16-14-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.61320754716981
episode_reward_min: 2.0
episodes_this_iter: 106
episodes_total: 29341
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6398018598556519
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -35.77284240722656
        total_loss: 110.44786834716797
        var_gnorm: 64.79227447509766
        vf_explained_var: 0.6510967016220093
        vf_loss: 298.8394470214844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7478.0
  learner_queue:
    size_count: 7482
    size_mean: 15.12
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5829087149927503
  num_agent_steps_sampled: 3755600
  num_agent_steps_trained: 3739000
  num_env_steps_sampled: 3755600
  num_env_steps_trained: 3739000
  num_samples_added_to_queue: 3755500
  num_training_step_calls_since_last_synch_worker_weights: 1325
  num_weight_broadcasts: 73833
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 237.273
    learner_load_time_ms: 1.487
    learner_load_wait_time_ms: 1.545
iterations_since_restore: 304
node_ip: 127.0.0.1
num_agent_steps_sampled: 3755600
num_agent_steps_trained: 3739000
num_env_steps_sampled: 3755600
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9942064533911
num_env_steps_trained: 3739000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9942064533911
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.142857142857146
  ram_util_percent: 79.27142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0647956548689857
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025389994342912375
  mean_inference_ms: 1.213958988683146
  mean_raw_obs_processing_ms: 0.2759296807661187
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019070562326683187
    StateBufferConnector_ms: 0.0034228810724222436
    ViewRequirementAgentConnector_ms: 0.11696545582897258
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.61320754716981
  episode_reward_min: 2.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 10.0, 9.0, 12.0, 10.0, 9.0, 10.0, 15.0, 9.0, 8.0, 8.0,
      14.0, 8.0, 7.0, 10.0, 11.0, 13.0, 7.0, 9.0, 8.0, 10.0, 6.0, 9.0, 11.0, 12.0,
      6.0, 12.0, 6.0, 8.0, 11.0, 10.0, 11.0, 12.0, 5.0, 12.0, 6.0, 8.0, 6.0, 11.0,
      8.0, 11.0, 11.0, 12.0, 14.0, 13.0, 11.0, 8.0, 17.0, 11.0, 8.0, 10.0, 11.0, 5.0,
      11.0, 12.0, 12.0, 12.0, 2.0, 5.0, 11.0, 9.0, 11.0, 11.0, 12.0, 8.0, 5.0, 7.0,
      8.0, 10.0, 8.0, 10.0, 14.0, 14.0, 5.0, 8.0, 9.0, 8.0, 9.0, 12.0, 11.0, 14.0,
      8.0, 9.0, 10.0, 13.0, 12.0, 8.0, 12.0, 8.0, 6.0, 4.0, 9.0, 10.0, 10.0, 6.0,
      13.0, 10.0, 5.0, 14.0, 11.0, 9.0, 6.0, 11.0, 9.0, 8.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0647956548689857
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025389994342912375
    mean_inference_ms: 1.213958988683146
    mean_raw_obs_processing_ms: 0.2759296807661187
time_since_restore: 3085.0865750312805
time_this_iter_s: 10.10354995727539
time_total_s: 3085.0865750312805
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691997265
timesteps_total: 3755600
training_iteration: 304
trial_id: default
train step: 305
agent_timesteps_total: 3769300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019099094249584055
  StateBufferConnector_ms: 0.003358390596177843
  ViewRequirementAgentConnector_ms: 0.1156484639203107
counters:
  num_agent_steps_sampled: 3769300
  num_agent_steps_trained: 3752500
  num_env_steps_sampled: 3769300
  num_env_steps_trained: 3752500
  num_samples_added_to_queue: 3769000
  num_training_step_calls_since_last_synch_worker_weights: 131
  num_weight_broadcasts: 74104
custom_metrics: {}
date: 2023-08-14_16-14-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.425925925925926
episode_reward_min: 4.0
episodes_this_iter: 108
episodes_total: 29449
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5985082983970642
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 29.56601905822754
        total_loss: 85.47142791748047
        var_gnorm: 64.79186248779297
        vf_explained_var: 0.8477544188499451
        vf_loss: 117.7958984375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7505.0
  learner_queue:
    size_count: 7512
    size_mean: 15.34
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3944174410842687
  num_agent_steps_sampled: 3769300
  num_agent_steps_trained: 3752500
  num_env_steps_sampled: 3769300
  num_env_steps_trained: 3752500
  num_samples_added_to_queue: 3769000
  num_training_step_calls_since_last_synch_worker_weights: 131
  num_weight_broadcasts: 74104
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 150.507
    learner_load_time_ms: 1.374
    learner_load_wait_time_ms: 1.566
iterations_since_restore: 305
node_ip: 127.0.0.1
num_agent_steps_sampled: 3769300
num_agent_steps_trained: 3752500
num_env_steps_sampled: 3769300
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9995753766423
num_env_steps_trained: 3752500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9995815755233
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.278571428571425
  ram_util_percent: 78.72142857142856
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0647733852418159
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025379999686191226
  mean_inference_ms: 1.2135380799787256
  mean_raw_obs_processing_ms: 0.27583667247425137
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019099094249584055
    StateBufferConnector_ms: 0.003358390596177843
    ViewRequirementAgentConnector_ms: 0.1156484639203107
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.425925925925926
  episode_reward_min: 4.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [14.0, 6.0, 7.0, 12.0, 8.0, 8.0, 9.0, 15.0, 9.0, 6.0, 12.0, 12.0,
      15.0, 6.0, 9.0, 11.0, 14.0, 6.0, 5.0, 9.0, 7.0, 7.0, 9.0, 7.0, 14.0, 4.0, 8.0,
      12.0, 5.0, 12.0, 10.0, 12.0, 7.0, 8.0, 4.0, 9.0, 11.0, 9.0, 6.0, 7.0, 7.0, 14.0,
      12.0, 11.0, 6.0, 9.0, 9.0, 11.0, 6.0, 14.0, 13.0, 13.0, 13.0, 12.0, 12.0, 7.0,
      11.0, 8.0, 5.0, 8.0, 8.0, 10.0, 7.0, 8.0, 7.0, 7.0, 12.0, 11.0, 10.0, 8.0, 9.0,
      9.0, 10.0, 8.0, 13.0, 9.0, 13.0, 7.0, 11.0, 8.0, 6.0, 15.0, 11.0, 12.0, 8.0,
      8.0, 6.0, 11.0, 6.0, 10.0, 11.0, 11.0, 8.0, 9.0, 7.0, 8.0, 8.0, 6.0, 12.0, 11.0,
      14.0, 8.0, 15.0, 9.0, 10.0, 9.0, 8.0, 14.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0647733852418159
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025379999686191226
    mean_inference_ms: 1.2135380799787256
    mean_raw_obs_processing_ms: 0.27583667247425137
time_since_restore: 3095.2802670001984
time_this_iter_s: 10.193691968917847
time_total_s: 3095.2802670001984
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691997276
timesteps_total: 3769300
training_iteration: 305
trial_id: default
train step: 306
agent_timesteps_total: 3782550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019580710167978323
  StateBufferConnector_ms: 0.0035164402980430456
  ViewRequirementAgentConnector_ms: 0.11850268233056162
counters:
  num_agent_steps_sampled: 3782550
  num_agent_steps_trained: 3766000
  num_env_steps_sampled: 3782550
  num_env_steps_trained: 3766000
  num_samples_added_to_queue: 3782500
  num_training_step_calls_since_last_synch_worker_weights: 502
  num_weight_broadcasts: 74366
custom_metrics: {}
date: 2023-08-14_16-14-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.794117647058824
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 29551
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6584755778312683
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -83.1795654296875
        total_loss: -21.180309295654297
        var_gnorm: 64.79447174072266
        vf_explained_var: 0.8316668272018433
        vf_loss: 130.58326721191406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7532.0
  learner_queue:
    size_count: 7538
    size_mean: 14.96
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8216476058777122
  num_agent_steps_sampled: 3782550
  num_agent_steps_trained: 3766000
  num_env_steps_sampled: 3782550
  num_env_steps_trained: 3766000
  num_samples_added_to_queue: 3782500
  num_training_step_calls_since_last_synch_worker_weights: 502
  num_weight_broadcasts: 74366
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 160.047
    learner_load_time_ms: 1.373
    learner_load_wait_time_ms: 1.601
iterations_since_restore: 306
node_ip: 127.0.0.1
num_agent_steps_sampled: 3782550
num_agent_steps_trained: 3766000
num_env_steps_sampled: 3782550
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.996525058323
num_env_steps_trained: 3766000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9964594933856
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 53.900000000000006
  ram_util_percent: 77.61999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06475733058729953
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025375223244340966
  mean_inference_ms: 1.2132348868017118
  mean_raw_obs_processing_ms: 0.27577843789691203
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019580710167978323
    StateBufferConnector_ms: 0.0035164402980430456
    ViewRequirementAgentConnector_ms: 0.11850268233056162
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.794117647058824
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 11.0, 13.0, 9.0, 9.0, 9.0, 4.0, 8.0, 10.0, 11.0, 11.0, 15.0,
      12.0, 14.0, 14.0, 7.0, 8.0, 13.0, 10.0, 15.0, 11.0, 13.0, 6.0, 9.0, 10.0, 10.0,
      8.0, 10.0, 9.0, 12.0, 12.0, 9.0, 13.0, 7.0, 10.0, 10.0, 8.0, 11.0, 7.0, 15.0,
      7.0, 8.0, 11.0, 7.0, 16.0, 8.0, 13.0, 14.0, 13.0, 10.0, 9.0, 6.0, 10.0, 9.0,
      10.0, 7.0, 9.0, 9.0, 12.0, 9.0, 13.0, 8.0, 9.0, 5.0, 7.0, 11.0, 12.0, 7.0, 9.0,
      11.0, 10.0, 5.0, 11.0, 8.0, 9.0, 10.0, 9.0, 11.0, 5.0, 9.0, 11.0, 13.0, 11.0,
      15.0, 7.0, 10.0, 10.0, 12.0, 6.0, 4.0, 8.0, 12.0, 7.0, 11.0, 9.0, 5.0, 9.0,
      13.0, 8.0, 12.0, 11.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06475733058729953
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025375223244340966
    mean_inference_ms: 1.2132348868017118
    mean_raw_obs_processing_ms: 0.27577843789691203
time_since_restore: 3105.4222593307495
time_this_iter_s: 10.141992330551147
time_total_s: 3105.4222593307495
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691997286
timesteps_total: 3782550
training_iteration: 306
trial_id: default
train step: 307
agent_timesteps_total: 3796150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019405489770051475
  StateBufferConnector_ms: 0.003465313777745327
  ViewRequirementAgentConnector_ms: 0.11625690994975722
counters:
  num_agent_steps_sampled: 3796150
  num_agent_steps_trained: 3779500
  num_env_steps_sampled: 3796150
  num_env_steps_trained: 3779500
  num_samples_added_to_queue: 3796000
  num_training_step_calls_since_last_synch_worker_weights: 755
  num_weight_broadcasts: 74632
custom_metrics: {}
date: 2023-08-14_16-14-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.448598130841122
episode_reward_min: 4.0
episodes_this_iter: 107
episodes_total: 29658
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6614508032798767
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -68.99778747558594
        total_loss: -5.879427909851074
        var_gnorm: 64.79624938964844
        vf_explained_var: 0.8467283248901367
        vf_loss: 132.85122680664062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7559.0
  learner_queue:
    size_count: 7565
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6351146748775756
  num_agent_steps_sampled: 3796150
  num_agent_steps_trained: 3779500
  num_env_steps_sampled: 3796150
  num_env_steps_trained: 3779500
  num_samples_added_to_queue: 3796000
  num_training_step_calls_since_last_synch_worker_weights: 755
  num_weight_broadcasts: 74632
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 171.708
    learner_load_time_ms: 1.348
    learner_load_wait_time_ms: 1.517
iterations_since_restore: 307
node_ip: 127.0.0.1
num_agent_steps_sampled: 3796150
num_agent_steps_trained: 3779500
num_env_steps_sampled: 3796150
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9921207884465
num_env_steps_trained: 3779500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9921787238256
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.314285714285724
  ram_util_percent: 76.44285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06473412505776
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025366197554560443
  mean_inference_ms: 1.2128505209933755
  mean_raw_obs_processing_ms: 0.2756946375826454
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019405489770051475
    StateBufferConnector_ms: 0.003465313777745327
    ViewRequirementAgentConnector_ms: 0.11625690994975722
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.448598130841122
  episode_reward_min: 4.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 15.0, 11.0, 12.0, 14.0, 10.0, 5.0, 4.0, 9.0, 9.0, 11.0,
      7.0, 8.0, 10.0, 10.0, 10.0, 8.0, 12.0, 8.0, 9.0, 9.0, 14.0, 12.0, 7.0, 14.0,
      10.0, 10.0, 5.0, 8.0, 7.0, 13.0, 7.0, 9.0, 10.0, 7.0, 14.0, 6.0, 8.0, 10.0,
      12.0, 8.0, 8.0, 9.0, 11.0, 9.0, 13.0, 11.0, 14.0, 8.0, 11.0, 14.0, 8.0, 9.0,
      7.0, 8.0, 8.0, 10.0, 5.0, 8.0, 9.0, 6.0, 8.0, 11.0, 9.0, 10.0, 6.0, 15.0, 11.0,
      10.0, 5.0, 10.0, 9.0, 7.0, 4.0, 6.0, 10.0, 11.0, 10.0, 8.0, 13.0, 11.0, 12.0,
      11.0, 8.0, 12.0, 8.0, 10.0, 13.0, 12.0, 9.0, 11.0, 13.0, 11.0, 4.0, 12.0, 8.0,
      11.0, 6.0, 10.0, 11.0, 8.0, 10.0, 5.0, 11.0, 6.0, 14.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06473412505776
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025366197554560443
    mean_inference_ms: 1.2128505209933755
    mean_raw_obs_processing_ms: 0.2756946375826454
time_since_restore: 3115.587453365326
time_this_iter_s: 10.165194034576416
time_total_s: 3115.587453365326
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.006
  training_iteration_time_ms: 0.06
timestamp: 1691997296
timesteps_total: 3796150
training_iteration: 307
trial_id: default
train step: 308
agent_timesteps_total: 3809550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019583020891462053
  StateBufferConnector_ms: 0.003449122111002604
  ViewRequirementAgentConnector_ms: 0.11707169669015068
counters:
  num_agent_steps_sampled: 3809550
  num_agent_steps_trained: 3793000
  num_env_steps_sampled: 3809550
  num_env_steps_trained: 3793000
  num_samples_added_to_queue: 3809500
  num_training_step_calls_since_last_synch_worker_weights: 1269
  num_weight_broadcasts: 74894
custom_metrics: {}
date: 2023-08-14_16-15-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.40952380952381
episode_reward_min: 3.0
episodes_this_iter: 105
episodes_total: 29763
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6217727661132812
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 21.31151580810547
        total_loss: 52.761775970458984
        var_gnorm: 64.8009262084961
        vf_explained_var: 0.898109495639801
        vf_loss: 69.11824798583984
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7586.0
  learner_queue:
    size_count: 7590
    size_mean: 15.24
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4221111067704943
  num_agent_steps_sampled: 3809550
  num_agent_steps_trained: 3793000
  num_env_steps_sampled: 3809550
  num_env_steps_trained: 3793000
  num_samples_added_to_queue: 3809500
  num_training_step_calls_since_last_synch_worker_weights: 1269
  num_weight_broadcasts: 74894
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 231.311
    learner_load_time_ms: 1.517
    learner_load_wait_time_ms: 1.568
iterations_since_restore: 308
node_ip: 127.0.0.1
num_agent_steps_sampled: 3809550
num_agent_steps_trained: 3793000
num_env_steps_sampled: 3809550
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9993290904542
num_env_steps_trained: 3793000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9993240836666
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.90714285714286
  ram_util_percent: 76.26428571428572
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06472056434012613
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025357787066453343
  mean_inference_ms: 1.212493786157678
  mean_raw_obs_processing_ms: 0.27561933255997895
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019583020891462053
    StateBufferConnector_ms: 0.003449122111002604
    ViewRequirementAgentConnector_ms: 0.11707169669015068
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.40952380952381
  episode_reward_min: 3.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 13.0, 10.0, 9.0, 10.0, 9.0, 9.0, 12.0, 5.0, 8.0, 13.0,
      10.0, 6.0, 11.0, 7.0, 8.0, 10.0, 12.0, 10.0, 7.0, 8.0, 7.0, 7.0, 9.0, 10.0,
      8.0, 12.0, 15.0, 13.0, 13.0, 10.0, 11.0, 7.0, 9.0, 8.0, 9.0, 15.0, 7.0, 7.0,
      7.0, 9.0, 8.0, 8.0, 11.0, 6.0, 13.0, 9.0, 12.0, 11.0, 7.0, 9.0, 11.0, 9.0, 5.0,
      8.0, 12.0, 12.0, 5.0, 8.0, 9.0, 4.0, 10.0, 4.0, 12.0, 11.0, 6.0, 9.0, 10.0,
      5.0, 7.0, 11.0, 11.0, 11.0, 3.0, 13.0, 8.0, 15.0, 10.0, 12.0, 11.0, 9.0, 6.0,
      10.0, 8.0, 9.0, 9.0, 11.0, 16.0, 11.0, 12.0, 12.0, 5.0, 6.0, 8.0, 8.0, 15.0,
      8.0, 7.0, 10.0, 11.0, 10.0, 11.0, 7.0, 13.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06472056434012613
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025357787066453343
    mean_inference_ms: 1.212493786157678
    mean_raw_obs_processing_ms: 0.27561933255997895
time_since_restore: 3125.6920251846313
time_this_iter_s: 10.10457181930542
time_total_s: 3125.6920251846313
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691997306
timesteps_total: 3809550
training_iteration: 308
trial_id: default
train step: 309
agent_timesteps_total: 3822450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020724058151245117
  StateBufferConnector_ms: 0.0036025047302246094
  ViewRequirementAgentConnector_ms: 0.12404751777648926
counters:
  num_agent_steps_sampled: 3822450
  num_agent_steps_trained: 3805500
  num_env_steps_sampled: 3822450
  num_env_steps_trained: 3805500
  num_samples_added_to_queue: 3822000
  num_training_step_calls_since_last_synch_worker_weights: 398
  num_weight_broadcasts: 75149
custom_metrics: {}
date: 2023-08-14_16-15-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.01
episode_reward_min: 4.0
episodes_this_iter: 100
episodes_total: 29863
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6519355177879333
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 47.00691223144531
        total_loss: 119.3492431640625
        var_gnorm: 64.79784393310547
        vf_explained_var: 0.8326994180679321
        vf_loss: 151.20401000976562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7611.0
  learner_queue:
    size_count: 7617
    size_mean: 15.44
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1689311356961964
  num_agent_steps_sampled: 3822450
  num_agent_steps_trained: 3805500
  num_env_steps_sampled: 3822450
  num_env_steps_trained: 3805500
  num_samples_added_to_queue: 3822000
  num_training_step_calls_since_last_synch_worker_weights: 398
  num_weight_broadcasts: 75149
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 186.763
    learner_load_time_ms: 1.525
    learner_load_wait_time_ms: 1.572
iterations_since_restore: 309
node_ip: 127.0.0.1
num_agent_steps_sampled: 3822450
num_agent_steps_trained: 3805500
num_env_steps_sampled: 3822450
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9962477793163
num_env_steps_trained: 3805500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9963641272443
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.013333333333335
  ram_util_percent: 75.70666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06470701805033761
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02535432371956601
  mean_inference_ms: 1.2123473491254118
  mean_raw_obs_processing_ms: 0.27557370934145714
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020724058151245117
    StateBufferConnector_ms: 0.0036025047302246094
    ViewRequirementAgentConnector_ms: 0.12404751777648926
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.01
  episode_reward_min: 4.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 4.0, 8.0, 9.0, 7.0, 11.0, 8.0, 8.0, 14.0, 10.0, 9.0, 11.0,
      8.0, 8.0, 14.0, 9.0, 9.0, 5.0, 7.0, 6.0, 14.0, 5.0, 9.0, 8.0, 11.0, 10.0, 7.0,
      13.0, 8.0, 9.0, 9.0, 6.0, 12.0, 8.0, 6.0, 5.0, 9.0, 12.0, 9.0, 6.0, 6.0, 9.0,
      10.0, 11.0, 10.0, 10.0, 8.0, 9.0, 9.0, 6.0, 8.0, 10.0, 11.0, 7.0, 11.0, 9.0,
      12.0, 10.0, 11.0, 7.0, 12.0, 11.0, 12.0, 10.0, 10.0, 4.0, 6.0, 11.0, 8.0, 6.0,
      11.0, 7.0, 8.0, 10.0, 7.0, 7.0, 7.0, 9.0, 7.0, 6.0, 7.0, 15.0, 12.0, 11.0, 8.0,
      9.0, 9.0, 9.0, 12.0, 7.0, 12.0, 11.0, 8.0, 9.0, 11.0, 9.0, 9.0, 11.0, 11.0,
      11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06470701805033761
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02535432371956601
    mean_inference_ms: 1.2123473491254118
    mean_raw_obs_processing_ms: 0.27557370934145714
time_since_restore: 3135.842524290085
time_this_iter_s: 10.150499105453491
time_total_s: 3135.842524290085
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997316
timesteps_total: 3822450
training_iteration: 309
trial_id: default
train step: 310
agent_timesteps_total: 3835550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01992945577584061
  StateBufferConnector_ms: 0.0035187777350930605
  ViewRequirementAgentConnector_ms: 0.11926842670814664
counters:
  num_agent_steps_sampled: 3835550
  num_agent_steps_trained: 3819000
  num_env_steps_sampled: 3835550
  num_env_steps_trained: 3819000
  num_samples_added_to_queue: 3835500
  num_training_step_calls_since_last_synch_worker_weights: 750
  num_weight_broadcasts: 75405
custom_metrics: {}
date: 2023-08-14_16-15-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 9.333333333333334
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 29965
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7093400359153748
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -4.4081926345825195
        total_loss: 21.8399658203125
        var_gnorm: 64.79627227783203
        vf_explained_var: 0.9148873090744019
        vf_loss: 59.58971405029297
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7638.0
  learner_queue:
    size_count: 7642
    size_mean: 15.44
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2191800523302536
  num_agent_steps_sampled: 3835550
  num_agent_steps_trained: 3819000
  num_env_steps_sampled: 3835550
  num_env_steps_trained: 3819000
  num_samples_added_to_queue: 3835500
  num_training_step_calls_since_last_synch_worker_weights: 750
  num_weight_broadcasts: 75405
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 241.863
    learner_load_time_ms: 1.538
    learner_load_wait_time_ms: 1.714
iterations_since_restore: 310
node_ip: 127.0.0.1
num_agent_steps_sampled: 3835550
num_agent_steps_trained: 3819000
num_env_steps_sampled: 3835550
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.993972090802
num_env_steps_trained: 3819000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9937880325058
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.55714285714286
  ram_util_percent: 76.23571428571428
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06469384499377857
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025348992282935315
  mean_inference_ms: 1.2121056161310986
  mean_raw_obs_processing_ms: 0.2755188067018946
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01992945577584061
    StateBufferConnector_ms: 0.0035187777350930605
    ViewRequirementAgentConnector_ms: 0.11926842670814664
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 9.333333333333334
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 12.0, 11.0, 12.0, 9.0, 8.0, 8.0, 7.0, 9.0, 10.0, 13.0,
      9.0, 9.0, 9.0, 10.0, 6.0, 10.0, 9.0, 14.0, 9.0, 11.0, 11.0, 12.0, 6.0, 6.0,
      9.0, 6.0, 10.0, 7.0, 9.0, 10.0, 9.0, 13.0, 6.0, 12.0, 12.0, 11.0, 9.0, 5.0,
      10.0, 11.0, 9.0, 13.0, 8.0, 7.0, 8.0, 13.0, 11.0, 5.0, 11.0, 9.0, 7.0, 9.0,
      5.0, 9.0, 10.0, 5.0, 9.0, 12.0, 9.0, 7.0, 10.0, 9.0, 11.0, 9.0, 6.0, 10.0, 8.0,
      10.0, 7.0, 13.0, 8.0, 11.0, 11.0, 10.0, 8.0, 8.0, 4.0, 11.0, 11.0, 7.0, 9.0,
      12.0, 7.0, 10.0, 11.0, 9.0, 11.0, 7.0, 12.0, 11.0, 11.0, 11.0, 9.0, 9.0, 8.0,
      11.0, 11.0, 7.0, 8.0, 11.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06469384499377857
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025348992282935315
    mean_inference_ms: 1.2121056161310986
    mean_raw_obs_processing_ms: 0.2755188067018946
time_since_restore: 3145.955555200577
time_this_iter_s: 10.113030910491943
time_total_s: 3145.955555200577
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997326
timesteps_total: 3835550
training_iteration: 310
trial_id: default
train step: 311
agent_timesteps_total: 3848900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019429524739583332
  StateBufferConnector_ms: 0.0035329092116582962
  ViewRequirementAgentConnector_ms: 0.11810438973563057
counters:
  num_agent_steps_sampled: 3848900
  num_agent_steps_trained: 3832000
  num_env_steps_sampled: 3848900
  num_env_steps_trained: 3832000
  num_samples_added_to_queue: 3848500
  num_training_step_calls_since_last_synch_worker_weights: 1048
  num_weight_broadcasts: 75669
custom_metrics: {}
date: 2023-08-14_16-15-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.219047619047618
episode_reward_min: 1.0
episodes_this_iter: 105
episodes_total: 30070
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6664585471153259
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 22.591197967529297
        total_loss: 77.10338592529297
        var_gnorm: 64.80610656738281
        vf_explained_var: 0.8794459104537964
        vf_loss: 115.68895721435547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7664.0
  learner_queue:
    size_count: 7668
    size_mean: 15.54
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9840731680114035
  num_agent_steps_sampled: 3848900
  num_agent_steps_trained: 3832000
  num_env_steps_sampled: 3848900
  num_env_steps_trained: 3832000
  num_samples_added_to_queue: 3848500
  num_training_step_calls_since_last_synch_worker_weights: 1048
  num_weight_broadcasts: 75669
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 264.479
    learner_load_time_ms: 1.525
    learner_load_wait_time_ms: 1.551
iterations_since_restore: 311
node_ip: 127.0.0.1
num_agent_steps_sampled: 3848900
num_agent_steps_trained: 3832000
num_env_steps_sampled: 3848900
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9966579759339
num_env_steps_trained: 3832000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9967455945423
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 59.00714285714286
  ram_util_percent: 77.12142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06467291421797154
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025340770466259967
  mean_inference_ms: 1.2117892076469163
  mean_raw_obs_processing_ms: 0.2754468073432613
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019429524739583332
    StateBufferConnector_ms: 0.0035329092116582962
    ViewRequirementAgentConnector_ms: 0.11810438973563057
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.219047619047618
  episode_reward_min: 1.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 6.0, 5.0, 6.0, 11.0, 6.0, 9.0, 6.0, 13.0, 8.0, 10.0,
      9.0, 5.0, 10.0, 10.0, 7.0, 7.0, 10.0, 11.0, 10.0, 10.0, 11.0, 5.0, 10.0, 7.0,
      8.0, 14.0, 14.0, 10.0, 11.0, 9.0, 8.0, 4.0, 5.0, 6.0, 8.0, 8.0, 12.0, 5.0, 8.0,
      13.0, 6.0, 7.0, 8.0, 4.0, 7.0, 8.0, 5.0, 5.0, 10.0, 9.0, 1.0, 9.0, 12.0, 10.0,
      7.0, 8.0, 5.0, 12.0, 6.0, 13.0, 4.0, 3.0, 11.0, 7.0, 10.0, 5.0, 8.0, 7.0, 14.0,
      7.0, 5.0, 5.0, 11.0, 10.0, 8.0, 9.0, 4.0, 7.0, 9.0, 8.0, 13.0, 8.0, 9.0, 9.0,
      9.0, 9.0, 9.0, 5.0, 10.0, 9.0, 8.0, 12.0, 4.0, 4.0, 8.0, 14.0, 10.0, 9.0, 8.0,
      9.0, 9.0, 8.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06467291421797154
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025340770466259967
    mean_inference_ms: 1.2117892076469163
    mean_raw_obs_processing_ms: 0.2754468073432613
time_since_restore: 3156.061466217041
time_this_iter_s: 10.105911016464233
time_total_s: 3156.061466217041
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691997336
timesteps_total: 3848900
training_iteration: 311
trial_id: default
train step: 312
agent_timesteps_total: 3862000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019711840386484183
  StateBufferConnector_ms: 0.0041178628510119865
  ViewRequirementAgentConnector_ms: 0.12033546672147863
counters:
  num_agent_steps_sampled: 3862000
  num_agent_steps_trained: 3845500
  num_env_steps_sampled: 3862000
  num_env_steps_trained: 3845500
  num_samples_added_to_queue: 3862000
  num_training_step_calls_since_last_synch_worker_weights: 802
  num_weight_broadcasts: 75927
custom_metrics: {}
date: 2023-08-14_16-15-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 5.7254901960784315
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 30172
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6040507555007935
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -13.909834861755371
        total_loss: 11.752942085266113
        var_gnorm: 64.81145477294922
        vf_explained_var: 0.922135591506958
        vf_loss: 57.36606216430664
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7691.0
  learner_queue:
    size_count: 7695
    size_mean: 15.68
    size_quantiles: [13.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.8109253973085319
  num_agent_steps_sampled: 3862000
  num_agent_steps_trained: 3845500
  num_env_steps_sampled: 3862000
  num_env_steps_trained: 3845500
  num_samples_added_to_queue: 3862000
  num_training_step_calls_since_last_synch_worker_weights: 802
  num_weight_broadcasts: 75927
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 239.877
    learner_load_time_ms: 1.527
    learner_load_wait_time_ms: 1.593
iterations_since_restore: 312
node_ip: 127.0.0.1
num_agent_steps_sampled: 3862000
num_agent_steps_trained: 3845500
num_env_steps_sampled: 3862000
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.998063567163
num_env_steps_trained: 3845500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9980044394426
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.78571428571428
  ram_util_percent: 77.16428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06466175210576654
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025333400035368832
  mean_inference_ms: 1.2115456512616936
  mean_raw_obs_processing_ms: 0.27538996936217686
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019711840386484183
    StateBufferConnector_ms: 0.0041178628510119865
    ViewRequirementAgentConnector_ms: 0.12033546672147863
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 5.7254901960784315
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 11.0, 7.0, 8.0, 13.0, 8.0, 8.0, 10.0, 6.0, 10.0, 3.0, 4.0,
      8.0, 4.0, 4.0, 8.0, 2.0, 2.0, 6.0, 7.0, 9.0, 3.0, 2.0, 7.0, 11.0, 10.0, 5.0,
      5.0, 10.0, 2.0, 8.0, 7.0, 6.0, 8.0, 1.0, 5.0, 0.0, 1.0, 7.0, 2.0, 1.0, 4.0,
      7.0, 4.0, 4.0, 8.0, 5.0, 3.0, 4.0, 2.0, 8.0, 6.0, 8.0, 10.0, 7.0, 10.0, 6.0,
      6.0, 11.0, 10.0, 4.0, 7.0, 10.0, 2.0, 5.0, 3.0, 8.0, 0.0, 6.0, 6.0, 12.0, 11.0,
      7.0, 7.0, 8.0, 5.0, 10.0, 5.0, 3.0, 2.0, 5.0, 5.0, 5.0, 0.0, 2.0, 8.0, 4.0,
      7.0, 1.0, 5.0, 9.0, 4.0, 2.0, 4.0, 7.0, 5.0, 2.0, 8.0, 2.0, 7.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06466175210576654
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025333400035368832
    mean_inference_ms: 1.2115456512616936
    mean_raw_obs_processing_ms: 0.27538996936217686
time_since_restore: 3166.16455745697
time_this_iter_s: 10.1030912399292
time_total_s: 3166.16455745697
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691997347
timesteps_total: 3862000
training_iteration: 312
trial_id: default
train step: 313
agent_timesteps_total: 3875300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019142490166884202
  StateBufferConnector_ms: 0.0035400574023907003
  ViewRequirementAgentConnector_ms: 0.11809514119074895
counters:
  num_agent_steps_sampled: 3875300
  num_agent_steps_trained: 3858500
  num_env_steps_sampled: 3875300
  num_env_steps_trained: 3858500
  num_samples_added_to_queue: 3875000
  num_training_step_calls_since_last_synch_worker_weights: 251
  num_weight_broadcasts: 76189
custom_metrics: {}
date: 2023-08-14_16-15-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.3173076923076925
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 30276
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6763373017311096
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.737083435058594
        total_loss: -1.608473777770996
        var_gnorm: 64.81847381591797
        vf_explained_var: 0.939988911151886
        vf_loss: 43.020591735839844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7717.0
  learner_queue:
    size_count: 7723
    size_mean: 15.5
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1532562594670797
  num_agent_steps_sampled: 3875300
  num_agent_steps_trained: 3858500
  num_env_steps_sampled: 3875300
  num_env_steps_trained: 3858500
  num_samples_added_to_queue: 3875000
  num_training_step_calls_since_last_synch_worker_weights: 251
  num_weight_broadcasts: 76189
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 179.294
    learner_load_time_ms: 1.752
    learner_load_wait_time_ms: 1.571
iterations_since_restore: 313
node_ip: 127.0.0.1
num_agent_steps_sampled: 3875300
num_agent_steps_trained: 3858500
num_env_steps_sampled: 3875300
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9962899788397
num_env_steps_trained: 3858500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9963736635275
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.35333333333334
  ram_util_percent: 78.04
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0646460601607319
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02532565547091317
  mean_inference_ms: 1.2112532775549256
  mean_raw_obs_processing_ms: 0.27533131242824493
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019142490166884202
    StateBufferConnector_ms: 0.0035400574023907003
    ViewRequirementAgentConnector_ms: 0.11809514119074895
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.3173076923076925
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 4.0, 3.0, 2.0, 1.0, 1.0, 4.0, 2.0, 7.0, 6.0, 1.0, 6.0, 6.0,
      6.0, 4.0, 2.0, 6.0, 1.0, 6.0, 3.0, 4.0, 1.0, 0.0, 4.0, 1.0, 5.0, 3.0, 2.0, 6.0,
      3.0, 6.0, 4.0, 5.0, 10.0, 1.0, 7.0, 7.0, 3.0, 4.0, 7.0, 5.0, 7.0, 10.0, 6.0,
      8.0, 5.0, 5.0, 4.0, 4.0, 8.0, 6.0, 8.0, 7.0, 8.0, 4.0, 2.0, 0.0, 5.0, 1.0, 3.0,
      1.0, 4.0, 1.0, 5.0, 6.0, 8.0, 4.0, 8.0, 1.0, 3.0, 4.0, 3.0, 4.0, 4.0, 5.0, 0.0,
      2.0, 3.0, 1.0, 5.0, 0.0, 5.0, 1.0, 6.0, 3.0, 6.0, 4.0, 6.0, 7.0, 7.0, 3.0, 4.0,
      6.0, 1.0, 4.0, 6.0, 6.0, 4.0, 5.0, 3.0, 2.0, 9.0, 9.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0646460601607319
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02532565547091317
    mean_inference_ms: 1.2112532775549256
    mean_raw_obs_processing_ms: 0.27533131242824493
time_since_restore: 3176.3084394931793
time_this_iter_s: 10.143882036209106
time_total_s: 3176.3084394931793
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691997357
timesteps_total: 3875300
training_iteration: 313
trial_id: default
train step: 314
agent_timesteps_total: 3888000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019979000091552734
  StateBufferConnector_ms: 0.0037250518798828125
  ViewRequirementAgentConnector_ms: 0.12313628196716309
counters:
  num_agent_steps_sampled: 3888000
  num_agent_steps_trained: 3871500
  num_env_steps_sampled: 3888000
  num_env_steps_trained: 3871500
  num_samples_added_to_queue: 3888000
  num_training_step_calls_since_last_synch_worker_weights: 621
  num_weight_broadcasts: 76440
custom_metrics: {}
date: 2023-08-14_16-16-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 6.92
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 30376
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.705714225769043
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.273377418518066
        total_loss: 17.00653839111328
        var_gnorm: 64.82244873046875
        vf_explained_var: 0.9282408356666565
        vf_loss: 57.61697769165039
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7743.0
  learner_queue:
    size_count: 7748
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 3888000
  num_agent_steps_trained: 3871500
  num_env_steps_sampled: 3888000
  num_env_steps_trained: 3871500
  num_samples_added_to_queue: 3888000
  num_training_step_calls_since_last_synch_worker_weights: 621
  num_weight_broadcasts: 76440
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 204.065
    learner_load_time_ms: 1.847
    learner_load_wait_time_ms: 1.64
iterations_since_restore: 314
node_ip: 127.0.0.1
num_agent_steps_sampled: 3888000
num_agent_steps_trained: 3871500
num_env_steps_sampled: 3888000
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.9967904171995
num_env_steps_trained: 3871500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.996714600283
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 59.607142857142854
  ram_util_percent: 79.04285714285716
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0646401192471566
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02532288234991924
  mean_inference_ms: 1.211138312804251
  mean_raw_obs_processing_ms: 0.2753079255154491
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019979000091552734
    StateBufferConnector_ms: 0.0037250518798828125
    ViewRequirementAgentConnector_ms: 0.12313628196716309
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 6.92
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 8.0, 7.0, 7.0, 12.0, 12.0, 8.0, 9.0, 8.0, 3.0, 0.0, 9.0,
      12.0, 6.0, 14.0, 8.0, 8.0, 8.0, 6.0, 13.0, 6.0, 11.0, 6.0, 8.0, 9.0, 5.0, 6.0,
      7.0, 13.0, 9.0, 9.0, 9.0, 3.0, 2.0, 4.0, 9.0, 7.0, 5.0, 9.0, 9.0, 8.0, 2.0,
      10.0, 4.0, 3.0, 4.0, 3.0, 2.0, 8.0, 5.0, 6.0, 2.0, 6.0, 2.0, 6.0, 9.0, 6.0,
      7.0, 3.0, 2.0, 10.0, 11.0, 3.0, 5.0, 8.0, 6.0, 8.0, 8.0, 9.0, 7.0, 15.0, 8.0,
      5.0, 10.0, 3.0, 5.0, 7.0, 7.0, 0.0, 8.0, 10.0, 9.0, 9.0, 6.0, 8.0, 4.0, 5.0,
      9.0, 9.0, 8.0, 5.0, 9.0, 8.0, 6.0, 9.0, 2.0, 6.0, 6.0, 9.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0646401192471566
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02532288234991924
    mean_inference_ms: 1.211138312804251
    mean_raw_obs_processing_ms: 0.2753079255154491
time_since_restore: 3186.4176964759827
time_this_iter_s: 10.109256982803345
time_total_s: 3186.4176964759827
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691997367
timesteps_total: 3888000
training_iteration: 314
trial_id: default
train step: 315
agent_timesteps_total: 3901300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01963514548081618
  StateBufferConnector_ms: 0.0035781126755934497
  ViewRequirementAgentConnector_ms: 0.11964898843031663
counters:
  num_agent_steps_sampled: 3901300
  num_agent_steps_trained: 3884500
  num_env_steps_sampled: 3901300
  num_env_steps_trained: 3884500
  num_samples_added_to_queue: 3901000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 76702
custom_metrics: {}
date: 2023-08-14_16-16-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.6923076923076925
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 30480
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6953446269035339
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.6376638412475586
        total_loss: 37.686466217041016
        var_gnorm: 64.81938171386719
        vf_explained_var: 0.8878780603408813
        vf_loss: 79.0510482788086
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7769.0
  learner_queue:
    size_count: 7775
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2611106216347558
  num_agent_steps_sampled: 3901300
  num_agent_steps_trained: 3884500
  num_env_steps_sampled: 3901300
  num_env_steps_trained: 3884500
  num_samples_added_to_queue: 3901000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 76702
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 179.712
    learner_load_time_ms: 1.845
    learner_load_wait_time_ms: 1.479
iterations_since_restore: 315
node_ip: 127.0.0.1
num_agent_steps_sampled: 3901300
num_agent_steps_trained: 3884500
num_env_steps_sampled: 3901300
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9430518693648
num_env_steps_trained: 3884500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9443364136648
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.73571428571429
  ram_util_percent: 78.28571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0646250229976686
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025316523007277006
  mean_inference_ms: 1.2108520730389143
  mean_raw_obs_processing_ms: 0.2752475242645765
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01963514548081618
    StateBufferConnector_ms: 0.0035781126755934497
    ViewRequirementAgentConnector_ms: 0.11964898843031663
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.6923076923076925
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 9.0, 11.0, 5.0, 5.0, 4.0, 12.0, 4.0, 4.0, 4.0, 6.0, 11.0,
      6.0, 7.0, 6.0, 10.0, 9.0, 6.0, 2.0, 12.0, 10.0, 5.0, 8.0, 8.0, 12.0, 6.0, 9.0,
      8.0, 8.0, 12.0, 10.0, 8.0, 8.0, 9.0, 6.0, 5.0, 14.0, 8.0, 11.0, 4.0, 6.0, 8.0,
      4.0, 5.0, 8.0, 7.0, 13.0, 9.0, 13.0, 10.0, 9.0, 6.0, 5.0, 9.0, 8.0, 7.0, 1.0,
      5.0, 5.0, 9.0, 8.0, 0.0, 5.0, 9.0, 2.0, 11.0, 4.0, 2.0, 13.0, 9.0, 9.0, 8.0,
      5.0, 2.0, 10.0, 11.0, 11.0, 8.0, 11.0, 6.0, 7.0, 8.0, 11.0, 10.0, 7.0, 3.0,
      10.0, 8.0, 13.0, 12.0, 10.0, 8.0, 7.0, 4.0, 4.0, 10.0, 9.0, 7.0, 6.0, 10.0,
      9.0, 9.0, 13.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0646250229976686
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025316523007277006
    mean_inference_ms: 1.2108520730389143
    mean_raw_obs_processing_ms: 0.2752475242645765
time_since_restore: 3196.553096294403
time_this_iter_s: 10.13539981842041
time_total_s: 3196.553096294403
timers:
  sample_time_ms: 0.033
  synch_weights_time_ms: 0.241
  training_iteration_time_ms: 0.341
timestamp: 1691997377
timesteps_total: 3901300
training_iteration: 315
trial_id: default
train step: 316
agent_timesteps_total: 3914650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0194852168743427
  StateBufferConnector_ms: 0.0034566108997051534
  ViewRequirementAgentConnector_ms: 0.11745141102717473
counters:
  num_agent_steps_sampled: 3914650
  num_agent_steps_trained: 3898000
  num_env_steps_sampled: 3914650
  num_env_steps_trained: 3898000
  num_samples_added_to_queue: 3914500
  num_training_step_calls_since_last_synch_worker_weights: 319
  num_weight_broadcasts: 76967
custom_metrics: {}
date: 2023-08-14_16-16-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.875
episode_reward_min: 3.0
episodes_this_iter: 104
episodes_total: 30584
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6455990076065063
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 34.71409606933594
        total_loss: 112.88374328613281
        var_gnorm: 64.826171875
        vf_explained_var: 0.7857750654220581
        vf_loss: 162.7952880859375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7796.0
  learner_queue:
    size_count: 7802
    size_mean: 15.22
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5138031576133006
  num_agent_steps_sampled: 3914650
  num_agent_steps_trained: 3898000
  num_env_steps_sampled: 3914650
  num_env_steps_trained: 3898000
  num_samples_added_to_queue: 3914500
  num_training_step_calls_since_last_synch_worker_weights: 319
  num_weight_broadcasts: 76967
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 170.46
    learner_load_time_ms: 2.306
    learner_load_wait_time_ms: 1.487
iterations_since_restore: 316
node_ip: 127.0.0.1
num_agent_steps_sampled: 3914650
num_agent_steps_trained: 3898000
num_env_steps_sampled: 3914650
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9988859901187
num_env_steps_trained: 3898000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9988734731537
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.85999999999999
  ram_util_percent: 77.51333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0646073289208429
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025309327063585445
  mean_inference_ms: 1.210531336703841
  mean_raw_obs_processing_ms: 0.27517826219867375
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0194852168743427
    StateBufferConnector_ms: 0.0034566108997051534
    ViewRequirementAgentConnector_ms: 0.11745141102717473
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.875
  episode_reward_min: 3.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 9.0, 8.0, 10.0, 8.0, 15.0, 6.0, 8.0, 9.0, 7.0, 9.0, 10.0,
      9.0, 6.0, 5.0, 7.0, 8.0, 8.0, 10.0, 7.0, 7.0, 12.0, 7.0, 5.0, 10.0, 12.0, 6.0,
      10.0, 8.0, 11.0, 7.0, 10.0, 9.0, 6.0, 11.0, 7.0, 5.0, 10.0, 7.0, 8.0, 3.0, 10.0,
      7.0, 14.0, 7.0, 8.0, 11.0, 10.0, 6.0, 13.0, 9.0, 12.0, 12.0, 10.0, 8.0, 9.0,
      8.0, 11.0, 9.0, 12.0, 13.0, 10.0, 15.0, 9.0, 13.0, 10.0, 7.0, 4.0, 9.0, 4.0,
      3.0, 12.0, 7.0, 9.0, 10.0, 8.0, 6.0, 15.0, 6.0, 11.0, 8.0, 11.0, 11.0, 9.0,
      4.0, 10.0, 5.0, 7.0, 11.0, 9.0, 8.0, 12.0, 7.0, 10.0, 7.0, 9.0, 10.0, 5.0, 9.0,
      9.0, 6.0, 14.0, 11.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0646073289208429
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025309327063585445
    mean_inference_ms: 1.210531336703841
    mean_raw_obs_processing_ms: 0.27517826219867375
time_since_restore: 3206.696164369583
time_this_iter_s: 10.143068075180054
time_total_s: 3206.696164369583
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997387
timesteps_total: 3914650
training_iteration: 316
trial_id: default
train step: 317
agent_timesteps_total: 3927750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01976793887568455
  StateBufferConnector_ms: 0.0036160151163736978
  ViewRequirementAgentConnector_ms: 0.11858051898432713
counters:
  num_agent_steps_sampled: 3927750
  num_agent_steps_trained: 3911000
  num_env_steps_sampled: 3927750
  num_env_steps_trained: 3911000
  num_samples_added_to_queue: 3927500
  num_training_step_calls_since_last_synch_worker_weights: 146
  num_weight_broadcasts: 77225
custom_metrics: {}
date: 2023-08-14_16-16-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.970588235294118
episode_reward_min: 2.0
episodes_this_iter: 102
episodes_total: 30686
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6885766983032227
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -20.615087509155273
        total_loss: 15.143616676330566
        var_gnorm: 64.82984924316406
        vf_explained_var: 0.8740473389625549
        vf_loss: 78.4031753540039
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7822.0
  learner_queue:
    size_count: 7828
    size_mean: 15.18
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5190786681406594
  num_agent_steps_sampled: 3927750
  num_agent_steps_trained: 3911000
  num_env_steps_sampled: 3927750
  num_env_steps_trained: 3911000
  num_samples_added_to_queue: 3927500
  num_training_step_calls_since_last_synch_worker_weights: 146
  num_weight_broadcasts: 77225
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 167.015
    learner_load_time_ms: 2.323
    learner_load_wait_time_ms: 1.559
iterations_since_restore: 317
node_ip: 127.0.0.1
num_agent_steps_sampled: 3927750
num_agent_steps_trained: 3911000
num_env_steps_sampled: 3927750
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9963457686315
num_env_steps_trained: 3911000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9963736635275
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.52142857142858
  ram_util_percent: 77.28571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06459499265517603
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025303744078859478
  mean_inference_ms: 1.2103128614311416
  mean_raw_obs_processing_ms: 0.27513280868426193
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01976793887568455
    StateBufferConnector_ms: 0.0036160151163736978
    ViewRequirementAgentConnector_ms: 0.11858051898432713
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.970588235294118
  episode_reward_min: 2.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 9.0, 5.0, 7.0, 5.0, 7.0, 7.0, 11.0, 9.0, 9.0, 8.0, 4.0,
      14.0, 8.0, 5.0, 11.0, 11.0, 9.0, 3.0, 10.0, 2.0, 9.0, 9.0, 9.0, 14.0, 4.0, 7.0,
      8.0, 9.0, 9.0, 10.0, 9.0, 14.0, 9.0, 8.0, 4.0, 11.0, 7.0, 7.0, 5.0, 9.0, 7.0,
      12.0, 3.0, 7.0, 11.0, 12.0, 10.0, 14.0, 7.0, 4.0, 5.0, 6.0, 8.0, 9.0, 8.0, 6.0,
      7.0, 9.0, 8.0, 10.0, 5.0, 8.0, 7.0, 8.0, 7.0, 6.0, 7.0, 11.0, 4.0, 6.0, 8.0,
      8.0, 6.0, 6.0, 8.0, 11.0, 7.0, 6.0, 8.0, 5.0, 7.0, 7.0, 11.0, 10.0, 11.0, 9.0,
      9.0, 3.0, 4.0, 11.0, 6.0, 5.0, 9.0, 6.0, 15.0, 9.0, 10.0, 6.0, 10.0, 9.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06459499265517603
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025303744078859478
    mean_inference_ms: 1.2103128614311416
    mean_raw_obs_processing_ms: 0.27513280868426193
time_since_restore: 3216.8434562683105
time_this_iter_s: 10.147291898727417
time_total_s: 3216.8434562683105
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997397
timesteps_total: 3927750
training_iteration: 317
trial_id: default
train step: 318
agent_timesteps_total: 3941150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02446105846991906
  StateBufferConnector_ms: 0.003441938987145057
  ViewRequirementAgentConnector_ms: 0.1232080734693087
counters:
  num_agent_steps_sampled: 3941150
  num_agent_steps_trained: 3924500
  num_env_steps_sampled: 3941150
  num_env_steps_trained: 3924500
  num_samples_added_to_queue: 3941000
  num_training_step_calls_since_last_synch_worker_weights: 816
  num_weight_broadcasts: 77484
custom_metrics: {}
date: 2023-08-14_16-16-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.26923076923077
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 30790
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7008476853370667
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.151114463806152
        total_loss: 32.98700714111328
        var_gnorm: 64.82916259765625
        vf_explained_var: 0.8599593043327332
        vf_loss: 95.28472137451172
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7849.0
  learner_queue:
    size_count: 7853
    size_mean: 15.26
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3683566786477859
  num_agent_steps_sampled: 3941150
  num_agent_steps_trained: 3924500
  num_env_steps_sampled: 3941150
  num_env_steps_trained: 3924500
  num_samples_added_to_queue: 3941000
  num_training_step_calls_since_last_synch_worker_weights: 816
  num_weight_broadcasts: 77484
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 240.809
    learner_load_time_ms: 2.314
    learner_load_wait_time_ms: 1.75
iterations_since_restore: 318
node_ip: 127.0.0.1
num_agent_steps_sampled: 3941150
num_agent_steps_trained: 3924500
num_env_steps_sampled: 3941150
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9989137658342
num_env_steps_trained: 3924500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.998905659609
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.75
  ram_util_percent: 77.8142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06457656046207297
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025295424255573254
  mean_inference_ms: 1.2099907272961563
  mean_raw_obs_processing_ms: 0.2750628573869638
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02446105846991906
    StateBufferConnector_ms: 0.003441938987145057
    ViewRequirementAgentConnector_ms: 0.1232080734693087
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.26923076923077
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 7.0, 7.0, 9.0, 7.0, 10.0, 6.0, 13.0, 9.0, 5.0, 9.0, 10.0,
      8.0, 11.0, 12.0, 10.0, 9.0, 10.0, 5.0, 9.0, 6.0, 10.0, 8.0, 6.0, 7.0, 9.0, 2.0,
      14.0, 11.0, 10.0, 7.0, 11.0, 6.0, 11.0, 10.0, 10.0, 7.0, 12.0, 5.0, 8.0, 11.0,
      9.0, 10.0, 13.0, 11.0, 11.0, 5.0, 6.0, 9.0, 12.0, 6.0, 12.0, 8.0, 9.0, 8.0,
      9.0, 9.0, 12.0, 13.0, 11.0, 10.0, 10.0, 8.0, 10.0, 6.0, 6.0, 13.0, 11.0, 12.0,
      13.0, 4.0, 9.0, 11.0, 11.0, 10.0, 9.0, 7.0, 6.0, 13.0, 9.0, 6.0, 10.0, 9.0,
      6.0, 11.0, 15.0, 12.0, 12.0, 6.0, 9.0, 12.0, 10.0, 11.0, 14.0, 11.0, 8.0, 12.0,
      14.0, 6.0, 10.0, 8.0, 7.0, 13.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06457656046207297
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025295424255573254
    mean_inference_ms: 1.2099907272961563
    mean_raw_obs_processing_ms: 0.2750628573869638
time_since_restore: 3226.9516263008118
time_this_iter_s: 10.10817003250122
time_total_s: 3226.9516263008118
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.042
timestamp: 1691997407
timesteps_total: 3941150
training_iteration: 318
trial_id: default
train step: 319
agent_timesteps_total: 3952050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02297830581665039
  StateBufferConnector_ms: 0.004263162612915039
  ViewRequirementAgentConnector_ms: 0.13816356658935547
counters:
  num_agent_steps_sampled: 3952050
  num_agent_steps_trained: 3935500
  num_env_steps_sampled: 3952050
  num_env_steps_trained: 3935500
  num_samples_added_to_queue: 3952000
  num_training_step_calls_since_last_synch_worker_weights: 733
  num_weight_broadcasts: 77697
custom_metrics: {}
date: 2023-08-14_16-16-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.7
episode_reward_min: 4.0
episodes_this_iter: 86
episodes_total: 30876
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7150686979293823
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 60.424015045166016
        total_loss: 131.41424560546875
        var_gnorm: 64.83289337158203
        vf_explained_var: 0.8171070218086243
        vf_loss: 149.13116455078125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7871.0
  learner_queue:
    size_count: 7876
    size_mean: 15.16
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5014659503298768
  num_agent_steps_sampled: 3952050
  num_agent_steps_trained: 3935500
  num_env_steps_sampled: 3952050
  num_env_steps_trained: 3935500
  num_samples_added_to_queue: 3952000
  num_training_step_calls_since_last_synch_worker_weights: 733
  num_weight_broadcasts: 77697
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 224.222
    learner_load_time_ms: 4.207
    learner_load_wait_time_ms: 1.61
iterations_since_restore: 319
node_ip: 127.0.0.1
num_agent_steps_sampled: 3952050
num_agent_steps_trained: 3935500
num_env_steps_sampled: 3952050
num_env_steps_sampled_this_iter: 10900
num_env_steps_sampled_throughput_per_sec: 1089.995841995842
num_env_steps_trained: 3935500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.995803849015
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 60.48571428571427
  ram_util_percent: 80.46428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06462833704811267
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02530573094502927
  mean_inference_ms: 1.2103004370194044
  mean_raw_obs_processing_ms: 0.2751611032723463
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02297830581665039
    StateBufferConnector_ms: 0.004263162612915039
    ViewRequirementAgentConnector_ms: 0.13816356658935547
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.7
  episode_reward_min: 4.0
  episodes_this_iter: 86
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 10.0, 11.0, 14.0, 11.0, 8.0, 12.0, 14.0, 6.0, 10.0, 8.0,
      7.0, 13.0, 8.0, 10.0, 10.0, 8.0, 11.0, 9.0, 8.0, 13.0, 9.0, 9.0, 9.0, 15.0,
      8.0, 9.0, 12.0, 9.0, 15.0, 11.0, 15.0, 8.0, 11.0, 4.0, 6.0, 13.0, 9.0, 6.0,
      7.0, 11.0, 5.0, 11.0, 11.0, 6.0, 8.0, 8.0, 12.0, 8.0, 12.0, 9.0, 9.0, 14.0,
      5.0, 12.0, 9.0, 8.0, 8.0, 9.0, 8.0, 10.0, 8.0, 11.0, 9.0, 10.0, 8.0, 6.0, 14.0,
      11.0, 5.0, 8.0, 12.0, 11.0, 13.0, 6.0, 11.0, 11.0, 10.0, 11.0, 13.0, 12.0, 9.0,
      11.0, 13.0, 8.0, 12.0, 8.0, 10.0, 10.0, 10.0, 10.0, 5.0, 8.0, 8.0, 4.0, 9.0,
      12.0, 11.0, 11.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06462833704811267
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02530573094502927
    mean_inference_ms: 1.2103004370194044
    mean_raw_obs_processing_ms: 0.2751611032723463
time_since_restore: 3237.0782995224
time_this_iter_s: 10.126673221588135
time_total_s: 3237.0782995224
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691997418
timesteps_total: 3952050
training_iteration: 319
trial_id: default
train step: 320
agent_timesteps_total: 3964450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02200007438659668
  StateBufferConnector_ms: 0.0038967132568359375
  ViewRequirementAgentConnector_ms: 0.12934541702270508
counters:
  num_agent_steps_sampled: 3964450
  num_agent_steps_trained: 3947500
  num_env_steps_sampled: 3964450
  num_env_steps_trained: 3947500
  num_samples_added_to_queue: 3964000
  num_training_step_calls_since_last_synch_worker_weights: 160
  num_weight_broadcasts: 77940
custom_metrics: {}
date: 2023-08-14_16-17-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.09
episode_reward_min: 3.0
episodes_this_iter: 96
episodes_total: 30972
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7285831570625305
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.899577140808105
        total_loss: 42.7465934753418
        var_gnorm: 64.83844757080078
        vf_explained_var: 0.8642771244049072
        vf_loss: 116.57817077636719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7895.0
  learner_queue:
    size_count: 7901
    size_mean: 15.18
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4098226838861685
  num_agent_steps_sampled: 3964450
  num_agent_steps_trained: 3947500
  num_env_steps_sampled: 3964450
  num_env_steps_trained: 3947500
  num_samples_added_to_queue: 3964000
  num_training_step_calls_since_last_synch_worker_weights: 160
  num_weight_broadcasts: 77940
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 193.511
    learner_load_time_ms: 3.955
    learner_load_wait_time_ms: 1.626
iterations_since_restore: 320
node_ip: 127.0.0.1
num_agent_steps_sampled: 3964450
num_agent_steps_trained: 3947500
num_env_steps_sampled: 3964450
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.996422777959
num_env_steps_trained: 3947500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9965381722184
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 51.70666666666667
  ram_util_percent: 80.23333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06460905214870634
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025310501291542362
  mean_inference_ms: 1.210425817689938
  mean_raw_obs_processing_ms: 0.2751617167805948
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02200007438659668
    StateBufferConnector_ms: 0.0038967132568359375
    ViewRequirementAgentConnector_ms: 0.12934541702270508
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.09
  episode_reward_min: 3.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 11.0, 11.0, 10.0, 7.0, 6.0, 7.0, 10.0, 8.0, 9.0, 11.0,
      9.0, 3.0, 10.0, 8.0, 14.0, 9.0, 12.0, 6.0, 5.0, 9.0, 7.0, 3.0, 13.0, 10.0, 8.0,
      10.0, 13.0, 9.0, 13.0, 6.0, 10.0, 9.0, 13.0, 8.0, 13.0, 6.0, 9.0, 6.0, 8.0,
      14.0, 4.0, 4.0, 11.0, 10.0, 7.0, 9.0, 9.0, 13.0, 10.0, 7.0, 10.0, 8.0, 11.0,
      6.0, 12.0, 12.0, 7.0, 6.0, 7.0, 8.0, 9.0, 5.0, 11.0, 11.0, 10.0, 11.0, 10.0,
      9.0, 8.0, 15.0, 11.0, 11.0, 10.0, 9.0, 12.0, 10.0, 6.0, 5.0, 6.0, 6.0, 4.0,
      10.0, 5.0, 10.0, 10.0, 15.0, 12.0, 9.0, 8.0, 5.0, 9.0, 12.0, 10.0, 11.0, 10.0,
      6.0, 13.0, 7.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06460905214870634
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025310501291542362
    mean_inference_ms: 1.210425817689938
    mean_raw_obs_processing_ms: 0.2751617167805948
time_since_restore: 3247.225301504135
time_this_iter_s: 10.14700198173523
time_total_s: 3247.225301504135
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691997428
timesteps_total: 3964450
training_iteration: 320
trial_id: default
train step: 321
agent_timesteps_total: 3977950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019217887014712928
  StateBufferConnector_ms: 0.0035337682040232532
  ViewRequirementAgentConnector_ms: 0.11577741155084574
counters:
  num_agent_steps_sampled: 3977950
  num_agent_steps_trained: 3961000
  num_env_steps_sampled: 3977950
  num_env_steps_trained: 3961000
  num_samples_added_to_queue: 3977500
  num_training_step_calls_since_last_synch_worker_weights: 58
  num_weight_broadcasts: 78205
custom_metrics: {}
date: 2023-08-14_16-17-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.150943396226415
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 31078
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7253233790397644
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.28646469116211
        total_loss: 40.24686050415039
        var_gnorm: 64.84478759765625
        vf_explained_var: 0.8448731899261475
        vf_loss: 126.31988525390625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7922.0
  learner_queue:
    size_count: 7929
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6833300330000651
  num_agent_steps_sampled: 3977950
  num_agent_steps_trained: 3961000
  num_env_steps_sampled: 3977950
  num_env_steps_trained: 3961000
  num_samples_added_to_queue: 3977500
  num_training_step_calls_since_last_synch_worker_weights: 58
  num_weight_broadcasts: 78205
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 149.799
    learner_load_time_ms: 4.151
    learner_load_wait_time_ms: 1.59
iterations_since_restore: 321
node_ip: 127.0.0.1
num_agent_steps_sampled: 3977950
num_agent_steps_trained: 3961000
num_env_steps_sampled: 3977950
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9972963387277
num_env_steps_trained: 3961000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9972963387277
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.792857142857144
  ram_util_percent: 78.76428571428573
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06458074389624961
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025302236993910678
  mean_inference_ms: 1.2101121240662374
  mean_raw_obs_processing_ms: 0.27508544661577267
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019217887014712928
    StateBufferConnector_ms: 0.0035337682040232532
    ViewRequirementAgentConnector_ms: 0.11577741155084574
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.150943396226415
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 17.0, 4.0, 9.0, 3.0, 6.0, 10.0, 12.0, 12.0, 14.0, 8.0, 14.0,
      16.0, 12.0, 8.0, 12.0, 6.0, 11.0, 9.0, 9.0, 5.0, 5.0, 10.0, 12.0, 10.0, 10.0,
      14.0, 11.0, 9.0, 5.0, 12.0, 10.0, 8.0, 6.0, 8.0, 15.0, 7.0, 12.0, 12.0, 8.0,
      16.0, 10.0, 14.0, 9.0, 16.0, 5.0, 6.0, 10.0, 5.0, 10.0, 12.0, 6.0, 4.0, 10.0,
      7.0, 11.0, 14.0, 7.0, 6.0, 11.0, 12.0, 7.0, 9.0, 7.0, 9.0, 7.0, 5.0, 7.0, 6.0,
      7.0, 10.0, 9.0, 7.0, 8.0, 10.0, 8.0, 9.0, 8.0, 10.0, 6.0, 7.0, 7.0, 11.0, 8.0,
      10.0, 6.0, 12.0, 5.0, 8.0, 15.0, 10.0, 10.0, 8.0, 8.0, 10.0, 5.0, 7.0, 11.0,
      8.0, 9.0, 7.0, 10.0, 9.0, 7.0, 12.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06458074389624961
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025302236993910678
    mean_inference_ms: 1.2101121240662374
    mean_raw_obs_processing_ms: 0.27508544661577267
time_since_restore: 3257.379452228546
time_this_iter_s: 10.15415072441101
time_total_s: 3257.379452228546
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691997438
timesteps_total: 3977950
training_iteration: 321
trial_id: default
train step: 322
agent_timesteps_total: 3990050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021707534790039062
  StateBufferConnector_ms: 0.0038728713989257812
  ViewRequirementAgentConnector_ms: 0.12830424308776855
counters:
  num_agent_steps_sampled: 3990050
  num_agent_steps_trained: 3973500
  num_env_steps_sampled: 3990050
  num_env_steps_trained: 3973500
  num_samples_added_to_queue: 3990000
  num_training_step_calls_since_last_synch_worker_weights: 359
  num_weight_broadcasts: 78442
custom_metrics: {}
date: 2023-08-14_16-17-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.91
episode_reward_min: 3.0
episodes_this_iter: 94
episodes_total: 31172
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.726170539855957
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -49.147701263427734
        total_loss: -21.190715789794922
        var_gnorm: 64.85125732421875
        vf_explained_var: 0.9184378385543823
        vf_loss: 63.17567443847656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7947.0
  learner_queue:
    size_count: 7952
    size_mean: 15.06
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5926079241294764
  num_agent_steps_sampled: 3990050
  num_agent_steps_trained: 3973500
  num_env_steps_sampled: 3990050
  num_env_steps_trained: 3973500
  num_samples_added_to_queue: 3990000
  num_training_step_calls_since_last_synch_worker_weights: 359
  num_weight_broadcasts: 78442
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 200.22
    learner_load_time_ms: 3.74
    learner_load_wait_time_ms: 1.533
iterations_since_restore: 322
node_ip: 127.0.0.1
num_agent_steps_sampled: 3990050
num_agent_steps_trained: 3973500
num_env_steps_sampled: 3990050
num_env_steps_sampled_this_iter: 12100
num_env_steps_sampled_throughput_per_sec: 1209.997115142071
num_env_steps_trained: 3973500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9970197748667
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 60.135714285714286
  ram_util_percent: 80.0642857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06459926270006541
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025304965115532468
  mean_inference_ms: 1.2101515615295093
  mean_raw_obs_processing_ms: 0.2751106241333162
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021707534790039062
    StateBufferConnector_ms: 0.0038728713989257812
    ViewRequirementAgentConnector_ms: 0.12830424308776855
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.91
  episode_reward_min: 3.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 10.0, 9.0, 7.0, 12.0, 10.0, 8.0, 10.0, 7.0, 8.0, 12.0, 6.0,
      12.0, 6.0, 10.0, 10.0, 8.0, 11.0, 11.0, 11.0, 7.0, 9.0, 16.0, 3.0, 11.0, 13.0,
      9.0, 8.0, 12.0, 3.0, 12.0, 7.0, 8.0, 9.0, 12.0, 7.0, 10.0, 7.0, 7.0, 6.0, 10.0,
      12.0, 15.0, 9.0, 9.0, 10.0, 8.0, 6.0, 8.0, 6.0, 8.0, 12.0, 4.0, 7.0, 13.0, 11.0,
      14.0, 9.0, 9.0, 13.0, 5.0, 8.0, 11.0, 8.0, 7.0, 10.0, 9.0, 6.0, 8.0, 7.0, 8.0,
      8.0, 9.0, 12.0, 9.0, 11.0, 5.0, 9.0, 8.0, 6.0, 9.0, 11.0, 9.0, 9.0, 8.0, 11.0,
      9.0, 8.0, 6.0, 15.0, 8.0, 9.0, 9.0, 6.0, 5.0, 10.0, 5.0, 9.0, 5.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06459926270006541
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025304965115532468
    mean_inference_ms: 1.2101515615295093
    mean_raw_obs_processing_ms: 0.2751106241333162
time_since_restore: 3267.5021710395813
time_this_iter_s: 10.122718811035156
time_total_s: 3267.5021710395813
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997448
timesteps_total: 3990050
training_iteration: 322
trial_id: default
train step: 323
agent_timesteps_total: 4002550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019954442977905273
  StateBufferConnector_ms: 0.0036132335662841797
  ViewRequirementAgentConnector_ms: 0.12299418449401855
counters:
  num_agent_steps_sampled: 4002550
  num_agent_steps_trained: 3986000
  num_env_steps_sampled: 4002550
  num_env_steps_trained: 3986000
  num_samples_added_to_queue: 4002500
  num_training_step_calls_since_last_synch_worker_weights: 406
  num_weight_broadcasts: 78686
custom_metrics: {}
date: 2023-08-14_16-17-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.63
episode_reward_min: 2.0
episodes_this_iter: 98
episodes_total: 31270
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7029459476470947
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -24.660877227783203
        total_loss: 24.466552734375
        var_gnorm: 64.85669708251953
        vf_explained_var: 0.8677031993865967
        vf_loss: 105.28431701660156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7972.0
  learner_queue:
    size_count: 7977
    size_mean: 14.98
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6430459518832696
  num_agent_steps_sampled: 4002550
  num_agent_steps_trained: 3986000
  num_env_steps_sampled: 4002550
  num_env_steps_trained: 3986000
  num_samples_added_to_queue: 4002500
  num_training_step_calls_since_last_synch_worker_weights: 406
  num_weight_broadcasts: 78686
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 209.05
    learner_load_time_ms: 3.739
    learner_load_wait_time_ms: 1.687
iterations_since_restore: 323
node_ip: 127.0.0.1
num_agent_steps_sampled: 4002550
num_agent_steps_trained: 3986000
num_env_steps_sampled: 4002550
num_env_steps_sampled_this_iter: 12500
num_env_steps_sampled_throughput_per_sec: 1249.997496609933
num_env_steps_trained: 3986000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.997496609933
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 54.74
  ram_util_percent: 77.72
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06458763211963843
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02530485333071824
  mean_inference_ms: 1.2101531926792828
  mean_raw_obs_processing_ms: 0.27509624885444417
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019954442977905273
    StateBufferConnector_ms: 0.0036132335662841797
    ViewRequirementAgentConnector_ms: 0.12299418449401855
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.63
  episode_reward_min: 2.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 12.0, 11.0, 7.0, 9.0, 7.0, 9.0, 9.0, 7.0, 10.0, 11.0, 14.0,
      8.0, 10.0, 7.0, 10.0, 8.0, 9.0, 5.0, 3.0, 7.0, 4.0, 11.0, 12.0, 8.0, 7.0, 8.0,
      12.0, 9.0, 9.0, 12.0, 13.0, 15.0, 4.0, 8.0, 9.0, 7.0, 9.0, 10.0, 10.0, 9.0,
      6.0, 6.0, 4.0, 11.0, 8.0, 7.0, 10.0, 7.0, 11.0, 12.0, 13.0, 9.0, 3.0, 10.0,
      9.0, 6.0, 7.0, 12.0, 9.0, 12.0, 7.0, 2.0, 9.0, 9.0, 11.0, 9.0, 8.0, 10.0, 10.0,
      6.0, 13.0, 6.0, 14.0, 9.0, 9.0, 13.0, 7.0, 7.0, 4.0, 9.0, 11.0, 7.0, 5.0, 8.0,
      6.0, 5.0, 9.0, 6.0, 12.0, 8.0, 7.0, 9.0, 11.0, 9.0, 9.0, 6.0, 7.0, 12.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06458763211963843
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02530485333071824
    mean_inference_ms: 1.2101531926792828
    mean_raw_obs_processing_ms: 0.27509624885444417
time_since_restore: 3277.637050151825
time_this_iter_s: 10.134879112243652
time_total_s: 3277.637050151825
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997458
timesteps_total: 4002550
training_iteration: 323
trial_id: default
train step: 324
agent_timesteps_total: 4014900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02150273323059082
  StateBufferConnector_ms: 0.0038733482360839844
  ViewRequirementAgentConnector_ms: 0.12867093086242676
counters:
  num_agent_steps_sampled: 4014900
  num_agent_steps_trained: 3998000
  num_env_steps_sampled: 4014900
  num_env_steps_trained: 3998000
  num_samples_added_to_queue: 4014500
  num_training_step_calls_since_last_synch_worker_weights: 672
  num_weight_broadcasts: 78928
custom_metrics: {}
date: 2023-08-14_16-17-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.07
episode_reward_min: 3.0
episodes_this_iter: 97
episodes_total: 31367
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6804287433624268
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 33.0692138671875
        total_loss: 85.38178253173828
        var_gnorm: 64.8619613647461
        vf_explained_var: 0.8826779723167419
        vf_loss: 111.42942810058594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 7996.0
  learner_queue:
    size_count: 8002
    size_mean: 15.24
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3792751719653333
  num_agent_steps_sampled: 4014900
  num_agent_steps_trained: 3998000
  num_env_steps_sampled: 4014900
  num_env_steps_trained: 3998000
  num_samples_added_to_queue: 4014500
  num_training_step_calls_since_last_synch_worker_weights: 672
  num_weight_broadcasts: 78928
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 228.742
    learner_load_time_ms: 3.753
    learner_load_wait_time_ms: 1.887
iterations_since_restore: 324
node_ip: 127.0.0.1
num_agent_steps_sampled: 4014900
num_agent_steps_trained: 3998000
num_env_steps_sampled: 4014900
num_env_steps_sampled_this_iter: 12350
num_env_steps_sampled_throughput_per_sec: 1234.992609425903
num_env_steps_trained: 3998000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9928188753715
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 57.74285714285714
  ram_util_percent: 77.10000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06459346341114487
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025306986426438534
  mean_inference_ms: 1.2101428348052494
  mean_raw_obs_processing_ms: 0.27509828896184574
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02150273323059082
    StateBufferConnector_ms: 0.0038733482360839844
    ViewRequirementAgentConnector_ms: 0.12867093086242676
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.07
  episode_reward_min: 3.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 12.0, 8.0, 9.0, 7.0, 10.0, 9.0, 8.0, 9.0, 9.0, 11.0, 6.0,
      11.0, 8.0, 7.0, 11.0, 10.0, 7.0, 6.0, 7.0, 8.0, 11.0, 10.0, 16.0, 7.0, 12.0,
      6.0, 10.0, 5.0, 10.0, 8.0, 11.0, 10.0, 8.0, 11.0, 12.0, 11.0, 7.0, 7.0, 8.0,
      4.0, 8.0, 6.0, 10.0, 14.0, 12.0, 11.0, 11.0, 6.0, 9.0, 10.0, 7.0, 5.0, 11.0,
      5.0, 10.0, 8.0, 7.0, 9.0, 11.0, 7.0, 12.0, 7.0, 7.0, 8.0, 13.0, 13.0, 14.0,
      10.0, 16.0, 6.0, 12.0, 3.0, 12.0, 9.0, 7.0, 10.0, 10.0, 9.0, 7.0, 14.0, 11.0,
      8.0, 3.0, 11.0, 9.0, 8.0, 10.0, 5.0, 7.0, 9.0, 13.0, 12.0, 5.0, 10.0, 8.0, 9.0,
      9.0, 6.0, 14.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06459346341114487
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025306986426438534
    mean_inference_ms: 1.2101428348052494
    mean_raw_obs_processing_ms: 0.27509828896184574
time_since_restore: 3287.7772669792175
time_this_iter_s: 10.140216827392578
time_total_s: 3287.7772669792175
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.051
timestamp: 1691997468
timesteps_total: 4014900
training_iteration: 324
trial_id: default
train step: 325
agent_timesteps_total: 4027700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020280122756958008
  StateBufferConnector_ms: 0.00363922119140625
  ViewRequirementAgentConnector_ms: 0.12221145629882812
counters:
  num_agent_steps_sampled: 4027700
  num_agent_steps_trained: 4011000
  num_env_steps_sampled: 4027700
  num_env_steps_trained: 4011000
  num_samples_added_to_queue: 4027500
  num_training_step_calls_since_last_synch_worker_weights: 1012
  num_weight_broadcasts: 79181
custom_metrics: {}
date: 2023-08-14_16-17-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.75
episode_reward_min: 3.0
episodes_this_iter: 100
episodes_total: 31467
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7015271782875061
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 30.939197540283203
        total_loss: 87.86791229248047
        var_gnorm: 64.86080932617188
        vf_explained_var: 0.8168043494224548
        vf_loss: 120.87271118164062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8022.0
  learner_queue:
    size_count: 8026
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3029197979921863
  num_agent_steps_sampled: 4027700
  num_agent_steps_trained: 4011000
  num_env_steps_sampled: 4027700
  num_env_steps_trained: 4011000
  num_samples_added_to_queue: 4027500
  num_training_step_calls_since_last_synch_worker_weights: 1012
  num_weight_broadcasts: 79181
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 273.298
    learner_load_time_ms: 1.638
    learner_load_wait_time_ms: 1.546
iterations_since_restore: 325
node_ip: 127.0.0.1
num_agent_steps_sampled: 4027700
num_agent_steps_trained: 4011000
num_env_steps_sampled: 4027700
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9967956623186
num_env_steps_trained: 4011000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9967455945423
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.06428571428573
  ram_util_percent: 77.40714285714284
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06457835009792494
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02530515784153204
  mean_inference_ms: 1.210030490087858
  mean_raw_obs_processing_ms: 0.27506239497732254
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020280122756958008
    StateBufferConnector_ms: 0.00363922119140625
    ViewRequirementAgentConnector_ms: 0.12221145629882812
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.75
  episode_reward_min: 3.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 11.0, 11.0, 11.0, 11.0, 12.0, 11.0, 10.0, 14.0, 9.0, 13.0,
      9.0, 13.0, 7.0, 10.0, 12.0, 12.0, 7.0, 9.0, 9.0, 10.0, 8.0, 9.0, 7.0, 13.0,
      7.0, 9.0, 9.0, 10.0, 11.0, 10.0, 6.0, 14.0, 11.0, 12.0, 9.0, 9.0, 10.0, 6.0,
      13.0, 10.0, 11.0, 9.0, 13.0, 8.0, 14.0, 9.0, 9.0, 11.0, 7.0, 11.0, 7.0, 10.0,
      13.0, 9.0, 9.0, 17.0, 10.0, 9.0, 9.0, 3.0, 11.0, 14.0, 9.0, 11.0, 5.0, 8.0,
      8.0, 11.0, 9.0, 11.0, 9.0, 9.0, 12.0, 9.0, 12.0, 6.0, 10.0, 9.0, 9.0, 6.0, 7.0,
      7.0, 9.0, 9.0, 8.0, 10.0, 9.0, 8.0, 7.0, 7.0, 12.0, 11.0, 17.0, 7.0, 9.0, 5.0,
      13.0, 11.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06457835009792494
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02530515784153204
    mean_inference_ms: 1.210030490087858
    mean_raw_obs_processing_ms: 0.27506239497732254
time_since_restore: 3297.8827550411224
time_this_iter_s: 10.105488061904907
time_total_s: 3297.8827550411224
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997478
timesteps_total: 4027700
training_iteration: 325
trial_id: default
train step: 326
agent_timesteps_total: 4039800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02135610580444336
  StateBufferConnector_ms: 0.0038068294525146484
  ViewRequirementAgentConnector_ms: 0.1296977996826172
counters:
  num_agent_steps_sampled: 4039800
  num_agent_steps_trained: 4023000
  num_env_steps_sampled: 4039800
  num_env_steps_trained: 4023000
  num_samples_added_to_queue: 4039500
  num_training_step_calls_since_last_synch_worker_weights: 628
  num_weight_broadcasts: 79419
custom_metrics: {}
date: 2023-08-14_16-18-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.14
episode_reward_min: 4.0
episodes_this_iter: 95
episodes_total: 31562
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6648300886154175
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -43.21805191040039
        total_loss: 15.846778869628906
        var_gnorm: 64.86502075195312
        vf_explained_var: 0.8422664403915405
        vf_loss: 124.77796173095703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8046.0
  learner_queue:
    size_count: 8051
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.216552506059644
  num_agent_steps_sampled: 4039800
  num_agent_steps_trained: 4023000
  num_env_steps_sampled: 4039800
  num_env_steps_trained: 4023000
  num_samples_added_to_queue: 4039500
  num_training_step_calls_since_last_synch_worker_weights: 628
  num_weight_broadcasts: 79419
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 245.191
    learner_load_time_ms: 1.628
    learner_load_wait_time_ms: 1.709
iterations_since_restore: 326
node_ip: 127.0.0.1
num_agent_steps_sampled: 4039800
num_agent_steps_trained: 4023000
num_env_steps_sampled: 4039800
num_env_steps_sampled_this_iter: 12100
num_env_steps_sampled_throughput_per_sec: 1209.9974613242962
num_env_steps_trained: 4023000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.997482305087
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 53.32142857142856
  ram_util_percent: 77.77142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06459253346381441
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025308732081142916
  mean_inference_ms: 1.2100887213634919
  mean_raw_obs_processing_ms: 0.27508068493802296
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02135610580444336
    StateBufferConnector_ms: 0.0038068294525146484
    ViewRequirementAgentConnector_ms: 0.1296977996826172
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.14
  episode_reward_min: 4.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 5.0, 13.0, 11.0, 6.0, 11.0, 15.0, 8.0, 9.0, 14.0, 9.0, 6.0,
      10.0, 8.0, 7.0, 8.0, 11.0, 9.0, 6.0, 9.0, 6.0, 12.0, 12.0, 11.0, 9.0, 9.0, 8.0,
      10.0, 8.0, 9.0, 7.0, 11.0, 8.0, 13.0, 8.0, 8.0, 7.0, 4.0, 12.0, 10.0, 10.0,
      12.0, 7.0, 8.0, 8.0, 8.0, 8.0, 8.0, 12.0, 7.0, 8.0, 6.0, 5.0, 6.0, 5.0, 10.0,
      9.0, 7.0, 7.0, 9.0, 7.0, 6.0, 12.0, 10.0, 5.0, 8.0, 13.0, 8.0, 13.0, 9.0, 7.0,
      10.0, 14.0, 10.0, 9.0, 11.0, 16.0, 9.0, 6.0, 11.0, 7.0, 9.0, 10.0, 11.0, 13.0,
      11.0, 9.0, 10.0, 11.0, 10.0, 9.0, 13.0, 12.0, 6.0, 9.0, 9.0, 11.0, 8.0, 8.0,
      8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06459253346381441
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025308732081142916
    mean_inference_ms: 1.2100887213634919
    mean_raw_obs_processing_ms: 0.27508068493802296
time_since_restore: 3308.00789809227
time_this_iter_s: 10.125143051147461
time_total_s: 3308.00789809227
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997489
timesteps_total: 4039800
training_iteration: 326
trial_id: default
train step: 327
agent_timesteps_total: 4052900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01979949427585976
  StateBufferConnector_ms: 0.003547528210808249
  ViewRequirementAgentConnector_ms: 0.1187287124932981
counters:
  num_agent_steps_sampled: 4052900
  num_agent_steps_trained: 4036000
  num_env_steps_sampled: 4052900
  num_env_steps_trained: 4036000
  num_samples_added_to_queue: 4052500
  num_training_step_calls_since_last_synch_worker_weights: 653
  num_weight_broadcasts: 79676
custom_metrics: {}
date: 2023-08-14_16-18-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.392156862745098
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 31664
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6625750064849854
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -29.403249740600586
        total_loss: 11.689286231994629
        var_gnorm: 64.86419677734375
        vf_explained_var: 0.8789643049240112
        vf_loss: 88.81082153320312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8072.0
  learner_queue:
    size_count: 8077
    size_mean: 15.44
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1516944039110375
  num_agent_steps_sampled: 4052900
  num_agent_steps_trained: 4036000
  num_env_steps_sampled: 4052900
  num_env_steps_trained: 4036000
  num_samples_added_to_queue: 4052500
  num_training_step_calls_since_last_synch_worker_weights: 653
  num_weight_broadcasts: 79676
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 226.445
    learner_load_time_ms: 1.43
    learner_load_wait_time_ms: 1.483
iterations_since_restore: 327
node_ip: 127.0.0.1
num_agent_steps_sampled: 4052900
num_agent_steps_trained: 4036000
num_env_steps_sampled: 4052900
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9980011016828
num_env_steps_trained: 4036000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9980163604487
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.75333333333334
  ram_util_percent: 78.01333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06457243994986016
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02530477916988008
  mean_inference_ms: 1.209896683623034
  mean_raw_obs_processing_ms: 0.2750272934851937
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01979949427585976
    StateBufferConnector_ms: 0.003547528210808249
    ViewRequirementAgentConnector_ms: 0.1187287124932981
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.392156862745098
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 9.0, 8.0, 13.0, 9.0, 14.0, 8.0, 12.0, 8.0, 10.0, 4.0, 9.0,
      7.0, 10.0, 15.0, 16.0, 9.0, 14.0, 8.0, 16.0, 12.0, 9.0, 9.0, 8.0, 6.0, 12.0,
      10.0, 11.0, 10.0, 9.0, 11.0, 11.0, 12.0, 11.0, 7.0, 15.0, 12.0, 9.0, 10.0, 9.0,
      11.0, 11.0, 7.0, 12.0, 11.0, 9.0, 14.0, 4.0, 8.0, 6.0, 5.0, 10.0, 6.0, 9.0,
      9.0, 4.0, 9.0, 10.0, 8.0, 10.0, 12.0, 9.0, 8.0, 12.0, 6.0, 8.0, 12.0, 5.0, 11.0,
      6.0, 8.0, 7.0, 9.0, 9.0, 8.0, 8.0, 11.0, 11.0, 6.0, 7.0, 12.0, 12.0, 13.0, 6.0,
      8.0, 9.0, 6.0, 4.0, 8.0, 12.0, 12.0, 10.0, 10.0, 10.0, 13.0, 10.0, 7.0, 6.0,
      9.0, 10.0, 7.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06457243994986016
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02530477916988008
    mean_inference_ms: 1.209896683623034
    mean_raw_obs_processing_ms: 0.2750272934851937
time_since_restore: 3318.1288430690765
time_this_iter_s: 10.12094497680664
time_total_s: 3318.1288430690765
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997499
timesteps_total: 4052900
training_iteration: 327
trial_id: default
train step: 328
agent_timesteps_total: 4065900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019906535006985807
  StateBufferConnector_ms: 0.003474065572908609
  ViewRequirementAgentConnector_ms: 0.12092897207430094
counters:
  num_agent_steps_sampled: 4065900
  num_agent_steps_trained: 4049000
  num_env_steps_sampled: 4065900
  num_env_steps_trained: 4049000
  num_samples_added_to_queue: 4065500
  num_training_step_calls_since_last_synch_worker_weights: 1208
  num_weight_broadcasts: 79932
custom_metrics: {}
date: 2023-08-14_16-18-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.792079207920793
episode_reward_min: 3.0
episodes_this_iter: 101
episodes_total: 31765
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6772707104682922
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 19.320159912109375
        total_loss: 95.03015899658203
        var_gnorm: 64.86592102050781
        vf_explained_var: 0.7793834209442139
        vf_loss: 158.1927032470703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8098.0
  learner_queue:
    size_count: 8102
    size_mean: 15.5
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0630145812734648
  num_agent_steps_sampled: 4065900
  num_agent_steps_trained: 4049000
  num_env_steps_sampled: 4065900
  num_env_steps_trained: 4049000
  num_samples_added_to_queue: 4065500
  num_training_step_calls_since_last_synch_worker_weights: 1208
  num_weight_broadcasts: 79932
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 287.002
    learner_load_time_ms: 1.774
    learner_load_wait_time_ms: 1.594
iterations_since_restore: 328
node_ip: 127.0.0.1
num_agent_steps_sampled: 4065900
num_agent_steps_trained: 4049000
num_env_steps_sampled: 4065900
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9985742584606
num_env_steps_trained: 4049000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9985742584606
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.39285714285715
  ram_util_percent: 77.28571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0645628797769587
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025298556039463953
  mean_inference_ms: 1.2096932652614643
  mean_raw_obs_processing_ms: 0.27498564016073085
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019906535006985807
    StateBufferConnector_ms: 0.003474065572908609
    ViewRequirementAgentConnector_ms: 0.12092897207430094
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.792079207920793
  episode_reward_min: 3.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 11.0, 6.0, 10.0, 8.0, 8.0, 5.0, 9.0, 8.0, 10.0, 4.0, 6.0,
      11.0, 9.0, 6.0, 8.0, 7.0, 13.0, 13.0, 6.0, 6.0, 8.0, 12.0, 6.0, 10.0, 10.0,
      11.0, 10.0, 5.0, 3.0, 6.0, 7.0, 4.0, 7.0, 7.0, 8.0, 9.0, 11.0, 9.0, 10.0, 13.0,
      10.0, 10.0, 7.0, 6.0, 6.0, 12.0, 11.0, 12.0, 11.0, 10.0, 14.0, 11.0, 12.0, 10.0,
      8.0, 8.0, 12.0, 10.0, 8.0, 8.0, 9.0, 7.0, 10.0, 6.0, 5.0, 5.0, 13.0, 8.0, 5.0,
      8.0, 12.0, 15.0, 12.0, 8.0, 6.0, 10.0, 11.0, 7.0, 12.0, 9.0, 12.0, 16.0, 9.0,
      10.0, 11.0, 7.0, 8.0, 5.0, 7.0, 11.0, 7.0, 9.0, 8.0, 10.0, 9.0, 5.0, 9.0, 11.0,
      6.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0645628797769587
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025298556039463953
    mean_inference_ms: 1.2096932652614643
    mean_raw_obs_processing_ms: 0.27498564016073085
time_since_restore: 3328.21804022789
time_this_iter_s: 10.089197158813477
time_total_s: 3328.21804022789
timers:
  sample_time_ms: 0.032
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.082
timestamp: 1691997509
timesteps_total: 4065900
training_iteration: 328
trial_id: default
train step: 329
agent_timesteps_total: 4078900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019660416771383846
  StateBufferConnector_ms: 0.0035222838906680837
  ViewRequirementAgentConnector_ms: 0.11951829872879327
counters:
  num_agent_steps_sampled: 4078900
  num_agent_steps_trained: 4062000
  num_env_steps_sampled: 4078900
  num_env_steps_trained: 4062000
  num_samples_added_to_queue: 4078500
  num_training_step_calls_since_last_synch_worker_weights: 574
  num_weight_broadcasts: 80189
custom_metrics: {}
date: 2023-08-14_16-18-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.647058823529411
episode_reward_min: 5.0
episodes_this_iter: 102
episodes_total: 31867
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6849077343940735
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.968000411987305
        total_loss: 82.11919403076172
        var_gnorm: 64.87103271484375
        vf_explained_var: 0.8000195622444153
        vf_loss: 133.15145874023438
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8124.0
  learner_queue:
    size_count: 8130
    size_mean: 15.52
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1178550889985697
  num_agent_steps_sampled: 4078900
  num_agent_steps_trained: 4062000
  num_env_steps_sampled: 4078900
  num_env_steps_trained: 4062000
  num_samples_added_to_queue: 4078500
  num_training_step_calls_since_last_synch_worker_weights: 574
  num_weight_broadcasts: 80189
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 204.814
    learner_load_time_ms: 1.745
    learner_load_wait_time_ms: 1.577
iterations_since_restore: 329
node_ip: 127.0.0.1
num_agent_steps_sampled: 4078900
num_agent_steps_trained: 4062000
num_env_steps_sampled: 4078900
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9971795143285
num_env_steps_trained: 4062000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9971795143285
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.93571428571429
  ram_util_percent: 77.72857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06454927625088713
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02529405920696039
  mean_inference_ms: 1.2095203745866745
  mean_raw_obs_processing_ms: 0.2749409083999369
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019660416771383846
    StateBufferConnector_ms: 0.0035222838906680837
    ViewRequirementAgentConnector_ms: 0.11951829872879327
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.647058823529411
  episode_reward_min: 5.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 12.0, 9.0, 6.0, 5.0, 12.0, 9.0, 9.0, 7.0, 10.0, 12.0, 10.0,
      16.0, 9.0, 9.0, 8.0, 15.0, 12.0, 9.0, 12.0, 14.0, 10.0, 9.0, 9.0, 10.0, 10.0,
      8.0, 5.0, 12.0, 8.0, 6.0, 7.0, 11.0, 12.0, 11.0, 14.0, 10.0, 14.0, 11.0, 10.0,
      11.0, 7.0, 6.0, 8.0, 8.0, 14.0, 13.0, 12.0, 9.0, 5.0, 6.0, 13.0, 8.0, 12.0,
      12.0, 10.0, 10.0, 10.0, 10.0, 7.0, 6.0, 8.0, 5.0, 11.0, 6.0, 11.0, 9.0, 12.0,
      9.0, 10.0, 13.0, 10.0, 13.0, 7.0, 9.0, 11.0, 10.0, 10.0, 5.0, 12.0, 9.0, 7.0,
      8.0, 9.0, 8.0, 7.0, 10.0, 8.0, 9.0, 9.0, 8.0, 12.0, 14.0, 13.0, 9.0, 15.0, 11.0,
      9.0, 7.0, 10.0, 7.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06454927625088713
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02529405920696039
    mean_inference_ms: 1.2095203745866745
    mean_raw_obs_processing_ms: 0.2749409083999369
time_since_restore: 3338.3538603782654
time_this_iter_s: 10.135820150375366
time_total_s: 3338.3538603782654
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691997519
timesteps_total: 4078900
training_iteration: 329
trial_id: default
train step: 330
agent_timesteps_total: 4091600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020026206970214844
  StateBufferConnector_ms: 0.0035543441772460938
  ViewRequirementAgentConnector_ms: 0.12043905258178711
counters:
  num_agent_steps_sampled: 4091600
  num_agent_steps_trained: 4075000
  num_env_steps_sampled: 4091600
  num_env_steps_trained: 4075000
  num_samples_added_to_queue: 4091500
  num_training_step_calls_since_last_synch_worker_weights: 831
  num_weight_broadcasts: 80439
custom_metrics: {}
date: 2023-08-14_16-18-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.22
episode_reward_min: 2.0
episodes_this_iter: 99
episodes_total: 31966
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6522502303123474
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.512418746948242
        total_loss: 70.52584075927734
        var_gnorm: 64.87540435791016
        vf_explained_var: 0.865818440914154
        vf_loss: 110.54935455322266
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8150.0
  learner_queue:
    size_count: 8155
    size_mean: 15.42
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.250439922587247
  num_agent_steps_sampled: 4091600
  num_agent_steps_trained: 4075000
  num_env_steps_sampled: 4091600
  num_env_steps_trained: 4075000
  num_samples_added_to_queue: 4091500
  num_training_step_calls_since_last_synch_worker_weights: 831
  num_weight_broadcasts: 80439
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 220.933
    learner_load_time_ms: 1.741
    learner_load_wait_time_ms: 1.609
iterations_since_restore: 330
node_ip: 127.0.0.1
num_agent_steps_sampled: 4091600
num_agent_steps_trained: 4075000
num_env_steps_sampled: 4091600
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.9992430214625
num_env_steps_trained: 4075000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9992251400797
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.413333333333334
  ram_util_percent: 78.14
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06454535888847907
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025292207845237277
  mean_inference_ms: 1.2094242397809614
  mean_raw_obs_processing_ms: 0.274917324324773
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020026206970214844
    StateBufferConnector_ms: 0.0035543441772460938
    ViewRequirementAgentConnector_ms: 0.12043905258178711
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.22
  episode_reward_min: 2.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 8.0, 10.0, 6.0, 9.0, 7.0, 11.0, 11.0, 5.0, 6.0, 8.0, 8.0,
      6.0, 8.0, 13.0, 9.0, 6.0, 11.0, 12.0, 15.0, 8.0, 11.0, 7.0, 11.0, 6.0, 10.0,
      11.0, 12.0, 10.0, 16.0, 4.0, 10.0, 14.0, 12.0, 8.0, 10.0, 10.0, 16.0, 5.0, 8.0,
      10.0, 5.0, 11.0, 7.0, 9.0, 16.0, 10.0, 13.0, 9.0, 15.0, 9.0, 12.0, 3.0, 5.0,
      9.0, 13.0, 8.0, 8.0, 9.0, 8.0, 10.0, 9.0, 14.0, 10.0, 15.0, 8.0, 7.0, 9.0, 7.0,
      7.0, 6.0, 6.0, 7.0, 10.0, 10.0, 15.0, 4.0, 12.0, 11.0, 4.0, 9.0, 9.0, 15.0,
      8.0, 2.0, 8.0, 8.0, 10.0, 11.0, 10.0, 14.0, 7.0, 9.0, 14.0, 6.0, 11.0, 4.0,
      7.0, 5.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06454535888847907
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025292207845237277
    mean_inference_ms: 1.2094242397809614
    mean_raw_obs_processing_ms: 0.274917324324773
time_since_restore: 3348.4716782569885
time_this_iter_s: 10.117817878723145
time_total_s: 3348.4716782569885
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691997529
timesteps_total: 4091600
training_iteration: 330
trial_id: default
train step: 331
agent_timesteps_total: 4103700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022402048110961914
  StateBufferConnector_ms: 0.00393223762512207
  ViewRequirementAgentConnector_ms: 0.13000082969665527
counters:
  num_agent_steps_sampled: 4103700
  num_agent_steps_trained: 4087000
  num_env_steps_sampled: 4103700
  num_env_steps_trained: 4087000
  num_samples_added_to_queue: 4103500
  num_training_step_calls_since_last_synch_worker_weights: 1185
  num_weight_broadcasts: 80678
custom_metrics: {}
date: 2023-08-14_16-18-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.52
episode_reward_min: 3.0
episodes_this_iter: 95
episodes_total: 32061
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.607876181602478
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 29.769023895263672
        total_loss: 90.47661590576172
        var_gnorm: 64.87812805175781
        vf_explained_var: 0.8605753779411316
        vf_loss: 127.49394989013672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8174.0
  learner_queue:
    size_count: 8178
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3029197979921865
  num_agent_steps_sampled: 4103700
  num_agent_steps_trained: 4087000
  num_env_steps_sampled: 4103700
  num_env_steps_trained: 4087000
  num_samples_added_to_queue: 4103500
  num_training_step_calls_since_last_synch_worker_weights: 1185
  num_weight_broadcasts: 80678
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 258.55
    learner_load_time_ms: 1.741
    learner_load_wait_time_ms: 1.602
iterations_since_restore: 331
node_ip: 127.0.0.1
num_agent_steps_sampled: 4103700
num_agent_steps_trained: 4087000
num_env_steps_sampled: 4103700
num_env_steps_sampled_this_iter: 12100
num_env_steps_sampled_throughput_per_sec: 1209.9986729636441
num_env_steps_trained: 4087000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9986839308867
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 54.07857142857142
  ram_util_percent: 78.95
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06456242566210808
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025295066116920117
  mean_inference_ms: 1.2094593004053928
  mean_raw_obs_processing_ms: 0.2749329764624297
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022402048110961914
    StateBufferConnector_ms: 0.00393223762512207
    ViewRequirementAgentConnector_ms: 0.13000082969665527
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.52
  episode_reward_min: 3.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 4.0, 7.0, 5.0, 8.0, 8.0, 8.0, 13.0, 13.0, 14.0, 14.0, 8.0,
      7.0, 8.0, 11.0, 10.0, 6.0, 5.0, 3.0, 10.0, 7.0, 9.0, 11.0, 6.0, 4.0, 8.0, 10.0,
      14.0, 9.0, 6.0, 12.0, 9.0, 13.0, 10.0, 10.0, 11.0, 9.0, 11.0, 9.0, 10.0, 15.0,
      13.0, 8.0, 7.0, 8.0, 10.0, 10.0, 10.0, 8.0, 15.0, 14.0, 10.0, 9.0, 10.0, 11.0,
      9.0, 9.0, 12.0, 7.0, 10.0, 10.0, 6.0, 12.0, 8.0, 8.0, 12.0, 12.0, 8.0, 8.0,
      14.0, 14.0, 10.0, 10.0, 7.0, 9.0, 6.0, 12.0, 11.0, 10.0, 10.0, 9.0, 16.0, 10.0,
      12.0, 12.0, 14.0, 11.0, 5.0, 7.0, 6.0, 4.0, 10.0, 8.0, 14.0, 11.0, 8.0, 10.0,
      7.0, 7.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06456242566210808
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025295066116920117
    mean_inference_ms: 1.2094593004053928
    mean_raw_obs_processing_ms: 0.2749329764624297
time_since_restore: 3358.5656843185425
time_this_iter_s: 10.094006061553955
time_total_s: 3358.5656843185425
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997539
timesteps_total: 4103700
training_iteration: 331
trial_id: default
train step: 332
agent_timesteps_total: 4116100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02116847038269043
  StateBufferConnector_ms: 0.00413203239440918
  ViewRequirementAgentConnector_ms: 0.12967777252197266
counters:
  num_agent_steps_sampled: 4116100
  num_agent_steps_trained: 4099500
  num_env_steps_sampled: 4116100
  num_env_steps_trained: 4099500
  num_samples_added_to_queue: 4116000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 80922
custom_metrics: {}
date: 2023-08-14_16-19-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.09
episode_reward_min: 1.0
episodes_this_iter: 96
episodes_total: 32157
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6121150851249695
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 53.322364807128906
        total_loss: 135.44125366210938
        var_gnorm: 64.87838745117188
        vf_explained_var: 0.8143521547317505
        vf_loss: 170.35894775390625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8199.0
  learner_queue:
    size_count: 8206
    size_mean: 15.34
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3944174410842687
  num_agent_steps_sampled: 4116100
  num_agent_steps_trained: 4099500
  num_env_steps_sampled: 4116100
  num_env_steps_trained: 4099500
  num_samples_added_to_queue: 4116000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 80922
  timing_breakdown:
    learner_dequeue_time_ms: 0.015
    learner_grad_time_ms: 143.113
    learner_load_time_ms: 1.761
    learner_load_wait_time_ms: 1.487
iterations_since_restore: 332
node_ip: 127.0.0.1
num_agent_steps_sampled: 4116100
num_agent_steps_trained: 4099500
num_env_steps_sampled: 4116100
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.718704154314
num_env_steps_trained: 4099500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.7164356394296
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.05
  ram_util_percent: 78.95714285714287
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0645594361783925
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02529749070655634
  mean_inference_ms: 1.2094857467064128
  mean_raw_obs_processing_ms: 0.2749296915236898
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02116847038269043
    StateBufferConnector_ms: 0.00413203239440918
    ViewRequirementAgentConnector_ms: 0.12967777252197266
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.09
  episode_reward_min: 1.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 7.0, 7.0, 8.0, 8.0, 7.0, 14.0, 7.0, 8.0, 9.0, 12.0, 6.0,
      6.0, 12.0, 7.0, 5.0, 6.0, 12.0, 7.0, 8.0, 14.0, 10.0, 8.0, 13.0, 12.0, 7.0,
      10.0, 7.0, 6.0, 12.0, 10.0, 9.0, 5.0, 8.0, 8.0, 11.0, 7.0, 15.0, 7.0, 14.0,
      11.0, 6.0, 4.0, 8.0, 5.0, 8.0, 15.0, 9.0, 6.0, 3.0, 14.0, 7.0, 10.0, 9.0, 9.0,
      9.0, 8.0, 7.0, 5.0, 10.0, 14.0, 10.0, 1.0, 9.0, 7.0, 11.0, 16.0, 14.0, 13.0,
      7.0, 7.0, 14.0, 10.0, 8.0, 15.0, 5.0, 9.0, 8.0, 6.0, 8.0, 9.0, 12.0, 6.0, 10.0,
      8.0, 10.0, 9.0, 6.0, 10.0, 5.0, 14.0, 13.0, 14.0, 7.0, 10.0, 11.0, 9.0, 11.0,
      10.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0645594361783925
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02529749070655634
    mean_inference_ms: 1.2094857467064128
    mean_raw_obs_processing_ms: 0.2749296915236898
time_since_restore: 3368.728132247925
time_this_iter_s: 10.162447929382324
time_total_s: 3368.728132247925
timers:
  sample_time_ms: 0.116
  synch_weights_time_ms: 0.501
  training_iteration_time_ms: 0.723
timestamp: 1691997549
timesteps_total: 4116100
training_iteration: 332
trial_id: default
train step: 333
agent_timesteps_total: 4128350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020936012268066406
  StateBufferConnector_ms: 0.0037801265716552734
  ViewRequirementAgentConnector_ms: 0.1266469955444336
counters:
  num_agent_steps_sampled: 4128350
  num_agent_steps_trained: 4111500
  num_env_steps_sampled: 4128350
  num_env_steps_trained: 4111500
  num_samples_added_to_queue: 4128000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 81165
custom_metrics: {}
date: 2023-08-14_16-19-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.53
episode_reward_min: 3.0
episodes_this_iter: 96
episodes_total: 32253
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6280725002288818
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 12.429986953735352
        total_loss: 65.44734191894531
        var_gnorm: 64.88163757324219
        vf_explained_var: 0.8870975375175476
        vf_loss: 112.31543731689453
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8223.0
  learner_queue:
    size_count: 8230
    size_mean: 14.88
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9041008376659045
  num_agent_steps_sampled: 4128350
  num_agent_steps_trained: 4111500
  num_env_steps_sampled: 4128350
  num_env_steps_trained: 4111500
  num_samples_added_to_queue: 4128000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 81165
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 167.814
    learner_load_time_ms: 4.144
    learner_load_wait_time_ms: 1.608
iterations_since_restore: 333
node_ip: 127.0.0.1
num_agent_steps_sampled: 4128350
num_agent_steps_trained: 4111500
num_env_steps_sampled: 4128350
num_env_steps_sampled_this_iter: 12250
num_env_steps_sampled_throughput_per_sec: 1224.818597480594
num_env_steps_trained: 4111500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.8222995728268
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 53.84666666666666
  ram_util_percent: 78.18666666666665
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06456369170694552
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02529992370026982
  mean_inference_ms: 1.209518562523153
  mean_raw_obs_processing_ms: 0.2749348574336662
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020936012268066406
    StateBufferConnector_ms: 0.0037801265716552734
    ViewRequirementAgentConnector_ms: 0.1266469955444336
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.53
  episode_reward_min: 3.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 11.0, 10.0, 11.0, 10.0, 14.0, 8.0, 6.0, 8.0, 7.0, 5.0, 5.0,
      10.0, 8.0, 11.0, 11.0, 6.0, 9.0, 8.0, 9.0, 7.0, 10.0, 13.0, 8.0, 7.0, 8.0, 9.0,
      9.0, 10.0, 13.0, 12.0, 8.0, 9.0, 11.0, 9.0, 9.0, 5.0, 6.0, 10.0, 8.0, 7.0, 8.0,
      8.0, 12.0, 7.0, 12.0, 14.0, 15.0, 9.0, 8.0, 9.0, 8.0, 4.0, 7.0, 11.0, 10.0,
      10.0, 9.0, 9.0, 7.0, 13.0, 12.0, 7.0, 9.0, 14.0, 11.0, 11.0, 3.0, 9.0, 10.0,
      11.0, 9.0, 7.0, 12.0, 11.0, 10.0, 12.0, 11.0, 8.0, 7.0, 10.0, 9.0, 12.0, 13.0,
      12.0, 12.0, 12.0, 13.0, 7.0, 12.0, 10.0, 10.0, 9.0, 9.0, 8.0, 11.0, 12.0, 11.0,
      12.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06456369170694552
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02529992370026982
    mean_inference_ms: 1.209518562523153
    mean_raw_obs_processing_ms: 0.2749348574336662
time_since_restore: 3378.882520198822
time_this_iter_s: 10.154387950897217
time_total_s: 3378.882520198822
timers:
  sample_time_ms: 0.077
  synch_weights_time_ms: 0.488
  training_iteration_time_ms: 0.673
timestamp: 1691997559
timesteps_total: 4128350
training_iteration: 333
trial_id: default
train step: 334
agent_timesteps_total: 4141700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01900654572706956
  StateBufferConnector_ms: 0.0033901287959172176
  ViewRequirementAgentConnector_ms: 0.11736452579498291
counters:
  num_agent_steps_sampled: 4141700
  num_agent_steps_trained: 4125000
  num_env_steps_sampled: 4141700
  num_env_steps_trained: 4125000
  num_samples_added_to_queue: 4141500
  num_training_step_calls_since_last_synch_worker_weights: 928
  num_weight_broadcasts: 81429
custom_metrics: {}
date: 2023-08-14_16-19-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.51923076923077
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 32357
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6739682555198669
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 21.418453216552734
        total_loss: 72.20777893066406
        var_gnorm: 64.88185119628906
        vf_explained_var: 0.8812788128852844
        vf_loss: 108.31834411621094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8250.0
  learner_queue:
    size_count: 8254
    size_mean: 14.7
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.972308292331602
  num_agent_steps_sampled: 4141700
  num_agent_steps_trained: 4125000
  num_env_steps_sampled: 4141700
  num_env_steps_trained: 4125000
  num_samples_added_to_queue: 4141500
  num_training_step_calls_since_last_synch_worker_weights: 928
  num_weight_broadcasts: 81429
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 249.405
    learner_load_time_ms: 3.755
    learner_load_wait_time_ms: 1.761
iterations_since_restore: 334
node_ip: 127.0.0.1
num_agent_steps_sampled: 4141700
num_agent_steps_trained: 4125000
num_env_steps_sampled: 4141700
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9960214018183
num_env_steps_trained: 4125000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.995976698468
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.43571428571429
  ram_util_percent: 77.97142857142856
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06453806488415048
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02529246077412354
  mean_inference_ms: 1.2092353338203938
  mean_raw_obs_processing_ms: 0.2748703316762928
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01900654572706956
    StateBufferConnector_ms: 0.0033901287959172176
    ViewRequirementAgentConnector_ms: 0.11736452579498291
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.51923076923077
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 5.0, 8.0, 8.0, 8.0, 4.0, 14.0, 10.0, 10.0, 9.0, 10.0, 5.0,
      10.0, 8.0, 11.0, 10.0, 8.0, 11.0, 8.0, 11.0, 10.0, 8.0, 11.0, 7.0, 11.0, 9.0,
      10.0, 6.0, 9.0, 10.0, 11.0, 10.0, 7.0, 10.0, 7.0, 13.0, 8.0, 10.0, 8.0, 14.0,
      9.0, 9.0, 9.0, 10.0, 10.0, 8.0, 7.0, 12.0, 11.0, 10.0, 9.0, 9.0, 11.0, 12.0,
      11.0, 10.0, 11.0, 17.0, 8.0, 12.0, 11.0, 13.0, 9.0, 9.0, 6.0, 7.0, 13.0, 2.0,
      9.0, 6.0, 9.0, 10.0, 11.0, 10.0, 6.0, 11.0, 12.0, 11.0, 11.0, 8.0, 13.0, 11.0,
      8.0, 10.0, 10.0, 11.0, 15.0, 11.0, 9.0, 8.0, 9.0, 7.0, 5.0, 9.0, 16.0, 7.0,
      10.0, 9.0, 8.0, 9.0, 6.0, 14.0, 8.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06453806488415048
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02529246077412354
    mean_inference_ms: 1.2092353338203938
    mean_raw_obs_processing_ms: 0.2748703316762928
time_since_restore: 3388.9891023635864
time_this_iter_s: 10.106582164764404
time_total_s: 3388.9891023635864
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997570
timesteps_total: 4141700
training_iteration: 334
trial_id: default
train step: 335
agent_timesteps_total: 4154400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02246832847595215
  StateBufferConnector_ms: 0.0037441253662109375
  ViewRequirementAgentConnector_ms: 0.1246175765991211
counters:
  num_agent_steps_sampled: 4154400
  num_agent_steps_trained: 4137500
  num_env_steps_sampled: 4154400
  num_env_steps_trained: 4137500
  num_samples_added_to_queue: 4154000
  num_training_step_calls_since_last_synch_worker_weights: 361
  num_weight_broadcasts: 81678
custom_metrics: {}
date: 2023-08-14_16-19-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.79
episode_reward_min: 2.0
episodes_this_iter: 100
episodes_total: 32457
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6551397442817688
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 32.05989074707031
        total_loss: 132.24871826171875
        var_gnorm: 64.88243103027344
        vf_explained_var: 0.8009756803512573
        vf_loss: 206.9290313720703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8275.0
  learner_queue:
    size_count: 8281
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3029197979921865
  num_agent_steps_sampled: 4154400
  num_agent_steps_trained: 4137500
  num_env_steps_sampled: 4154400
  num_env_steps_trained: 4137500
  num_samples_added_to_queue: 4154000
  num_training_step_calls_since_last_synch_worker_weights: 361
  num_weight_broadcasts: 81678
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 210.601
    learner_load_time_ms: 3.87
    learner_load_wait_time_ms: 1.57
iterations_since_restore: 335
node_ip: 127.0.0.1
num_agent_steps_sampled: 4154400
num_agent_steps_trained: 4137500
num_env_steps_sampled: 4154400
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.994943400489
num_env_steps_trained: 4137500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9950230319776
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.12142857142857
  ram_util_percent: 78.55000000000003
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06453232702663204
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025290978876494216
  mean_inference_ms: 1.2091466328455487
  mean_raw_obs_processing_ms: 0.27485505063974763
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02246832847595215
    StateBufferConnector_ms: 0.0037441253662109375
    ViewRequirementAgentConnector_ms: 0.1246175765991211
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.79
  episode_reward_min: 2.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 10.0, 10.0, 12.0, 13.0, 10.0, 7.0, 8.0, 8.0, 11.0, 8.0,
      8.0, 9.0, 8.0, 10.0, 10.0, 8.0, 14.0, 7.0, 10.0, 3.0, 7.0, 10.0, 10.0, 11.0,
      4.0, 8.0, 9.0, 8.0, 8.0, 10.0, 9.0, 9.0, 7.0, 9.0, 14.0, 9.0, 13.0, 5.0, 6.0,
      12.0, 12.0, 11.0, 10.0, 9.0, 8.0, 11.0, 12.0, 9.0, 8.0, 15.0, 13.0, 13.0, 9.0,
      9.0, 6.0, 13.0, 9.0, 8.0, 14.0, 10.0, 9.0, 10.0, 12.0, 11.0, 11.0, 9.0, 10.0,
      6.0, 8.0, 2.0, 16.0, 14.0, 11.0, 10.0, 10.0, 11.0, 13.0, 13.0, 9.0, 17.0, 12.0,
      9.0, 9.0, 15.0, 10.0, 11.0, 9.0, 10.0, 9.0, 15.0, 9.0, 4.0, 11.0, 5.0, 13.0,
      10.0, 3.0, 12.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06453232702663204
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025290978876494216
    mean_inference_ms: 1.2091466328455487
    mean_raw_obs_processing_ms: 0.27485505063974763
time_since_restore: 3399.1330263614655
time_this_iter_s: 10.143923997879028
time_total_s: 3399.1330263614655
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997580
timesteps_total: 4154400
training_iteration: 335
trial_id: default
train step: 336
agent_timesteps_total: 4167400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020310691758698107
  StateBufferConnector_ms: 0.003583524741378485
  ViewRequirementAgentConnector_ms: 0.12176106957828298
counters:
  num_agent_steps_sampled: 4167400
  num_agent_steps_trained: 4150500
  num_env_steps_sampled: 4167400
  num_env_steps_trained: 4150500
  num_samples_added_to_queue: 4167000
  num_training_step_calls_since_last_synch_worker_weights: 6
  num_weight_broadcasts: 81931
custom_metrics: {}
date: 2023-08-14_16-19-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.96078431372549
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 32559
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6769014596939087
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -21.873380661010742
        total_loss: 16.189617156982422
        var_gnorm: 64.88448333740234
        vf_explained_var: 0.9018607139587402
        vf_loss: 82.89501190185547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8301.0
  learner_queue:
    size_count: 8308
    size_mean: 15.06
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.678213335663854
  num_agent_steps_sampled: 4167400
  num_agent_steps_trained: 4150500
  num_env_steps_sampled: 4167400
  num_env_steps_trained: 4150500
  num_samples_added_to_queue: 4167000
  num_training_step_calls_since_last_synch_worker_weights: 6
  num_weight_broadcasts: 81931
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 174.054
    learner_load_time_ms: 3.907
    learner_load_wait_time_ms: 1.742
iterations_since_restore: 336
node_ip: 127.0.0.1
num_agent_steps_sampled: 4167400
num_agent_steps_trained: 4150500
num_env_steps_sampled: 4167400
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9990701682066
num_env_steps_trained: 4150500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9990701682066
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.89999999999999
  ram_util_percent: 78.17142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06452353293073594
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02528747127267629
  mean_inference_ms: 1.2089868913005384
  mean_raw_obs_processing_ms: 0.2748214970453619
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020310691758698107
    StateBufferConnector_ms: 0.003583524741378485
    ViewRequirementAgentConnector_ms: 0.12176106957828298
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.96078431372549
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 9.0, 12.0, 7.0, 5.0, 9.0, 8.0, 10.0, 7.0, 8.0, 10.0,
      8.0, 6.0, 11.0, 7.0, 8.0, 4.0, 10.0, 6.0, 11.0, 10.0, 13.0, 9.0, 9.0, 11.0,
      6.0, 5.0, 4.0, 11.0, 8.0, 9.0, 12.0, 9.0, 13.0, 9.0, 7.0, 9.0, 10.0, 11.0, 14.0,
      11.0, 12.0, 6.0, 6.0, 11.0, 6.0, 8.0, 5.0, 7.0, 14.0, 6.0, 13.0, 6.0, 11.0,
      12.0, 6.0, 10.0, 5.0, 10.0, 8.0, 6.0, 11.0, 12.0, 8.0, 9.0, 8.0, 7.0, 10.0,
      12.0, 9.0, 9.0, 15.0, 6.0, 8.0, 7.0, 11.0, 10.0, 9.0, 9.0, 11.0, 10.0, 10.0,
      9.0, 12.0, 9.0, 10.0, 14.0, 14.0, 7.0, 7.0, 7.0, 5.0, 10.0, 8.0, 6.0, 7.0, 14.0,
      7.0, 9.0, 9.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06452353293073594
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02528747127267629
    mean_inference_ms: 1.2089868913005384
    mean_raw_obs_processing_ms: 0.2748214970453619
time_since_restore: 3409.3240101337433
time_this_iter_s: 10.190983772277832
time_total_s: 3409.3240101337433
timers:
  sample_time_ms: 0.086
  synch_weights_time_ms: 0.284
  training_iteration_time_ms: 0.454
timestamp: 1691997590
timesteps_total: 4167400
training_iteration: 336
trial_id: default
train step: 337
agent_timesteps_total: 4178400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02498912811279297
  StateBufferConnector_ms: 0.004375457763671875
  ViewRequirementAgentConnector_ms: 0.1466081142425537
counters:
  num_agent_steps_sampled: 4178400
  num_agent_steps_trained: 4161500
  num_env_steps_sampled: 4178400
  num_env_steps_trained: 4161500
  num_samples_added_to_queue: 4178000
  num_training_step_calls_since_last_synch_worker_weights: 810
  num_weight_broadcasts: 82147
custom_metrics: {}
date: 2023-08-14_16-20-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.03
episode_reward_min: 3.0
episodes_this_iter: 86
episodes_total: 32645
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6659672260284424
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.838907241821289
        total_loss: 18.59016227722168
        var_gnorm: 64.88633728027344
        vf_explained_var: 0.9202359318733215
        vf_loss: 59.5178108215332
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8323.0
  learner_queue:
    size_count: 8328
    size_mean: 14.6
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.9287301521985911
  num_agent_steps_sampled: 4178400
  num_agent_steps_trained: 4161500
  num_env_steps_sampled: 4178400
  num_env_steps_trained: 4161500
  num_samples_added_to_queue: 4178000
  num_training_step_calls_since_last_synch_worker_weights: 810
  num_weight_broadcasts: 82147
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 251.296
    learner_load_time_ms: 3.91
    learner_load_wait_time_ms: 1.692
iterations_since_restore: 337
node_ip: 127.0.0.1
num_agent_steps_sampled: 4178400
num_agent_steps_trained: 4161500
num_env_steps_sampled: 4178400
num_env_steps_sampled_this_iter: 11000
num_env_steps_sampled_throughput_per_sec: 1099.9984788915688
num_env_steps_trained: 4161500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9984788915688
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 60.04666666666667
  ram_util_percent: 80.35333333333331
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06457286643376231
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025296751768591027
  mean_inference_ms: 1.2092536197696377
  mean_raw_obs_processing_ms: 0.27489262206606296
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02498912811279297
    StateBufferConnector_ms: 0.004375457763671875
    ViewRequirementAgentConnector_ms: 0.1466081142425537
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.03
  episode_reward_min: 3.0
  episodes_this_iter: 86
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [14.0, 7.0, 7.0, 7.0, 5.0, 10.0, 8.0, 6.0, 7.0, 14.0, 7.0, 9.0,
      9.0, 9.0, 6.0, 11.0, 13.0, 8.0, 9.0, 10.0, 5.0, 12.0, 11.0, 10.0, 14.0, 10.0,
      10.0, 6.0, 10.0, 6.0, 11.0, 9.0, 12.0, 9.0, 7.0, 11.0, 5.0, 7.0, 7.0, 9.0, 6.0,
      12.0, 6.0, 13.0, 5.0, 12.0, 7.0, 6.0, 12.0, 9.0, 6.0, 11.0, 4.0, 8.0, 13.0,
      6.0, 7.0, 13.0, 6.0, 11.0, 12.0, 12.0, 8.0, 3.0, 10.0, 10.0, 15.0, 11.0, 15.0,
      10.0, 11.0, 7.0, 5.0, 12.0, 5.0, 8.0, 9.0, 9.0, 5.0, 12.0, 7.0, 10.0, 12.0,
      4.0, 13.0, 7.0, 11.0, 10.0, 14.0, 5.0, 8.0, 6.0, 11.0, 8.0, 13.0, 8.0, 11.0,
      8.0, 7.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06457286643376231
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025296751768591027
    mean_inference_ms: 1.2092536197696377
    mean_raw_obs_processing_ms: 0.27489262206606296
time_since_restore: 3419.435847043991
time_this_iter_s: 10.111836910247803
time_total_s: 3419.435847043991
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997600
timesteps_total: 4178400
training_iteration: 337
trial_id: default
train step: 338
agent_timesteps_total: 4190300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02186417579650879
  StateBufferConnector_ms: 0.003979682922363281
  ViewRequirementAgentConnector_ms: 0.13035178184509277
counters:
  num_agent_steps_sampled: 4190300
  num_agent_steps_trained: 4173500
  num_env_steps_sampled: 4190300
  num_env_steps_trained: 4173500
  num_samples_added_to_queue: 4190000
  num_training_step_calls_since_last_synch_worker_weights: 1458
  num_weight_broadcasts: 82381
custom_metrics: {}
date: 2023-08-14_16-20-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 9.32
episode_reward_min: 3.0
episodes_this_iter: 92
episodes_total: 32737
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6652370691299438
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -45.0229377746582
        total_loss: 56.305328369140625
        var_gnorm: 64.8870849609375
        vf_explained_var: 0.7686007618904114
        vf_loss: 209.30889892578125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8347.0
  learner_queue:
    size_count: 8351
    size_mean: 14.86
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7551068343551055
  num_agent_steps_sampled: 4190300
  num_agent_steps_trained: 4173500
  num_env_steps_sampled: 4190300
  num_env_steps_trained: 4173500
  num_samples_added_to_queue: 4190000
  num_training_step_calls_since_last_synch_worker_weights: 1458
  num_weight_broadcasts: 82381
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 261.463
    learner_load_time_ms: 3.911
    learner_load_wait_time_ms: 1.804
iterations_since_restore: 338
node_ip: 127.0.0.1
num_agent_steps_sampled: 4190300
num_agent_steps_trained: 4173500
num_env_steps_sampled: 4190300
num_env_steps_sampled_this_iter: 11900
num_env_steps_sampled_throughput_per_sec: 1189.9982409503236
num_env_steps_trained: 4173500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9982261683936
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 64.54285714285714
  ram_util_percent: 79.09285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06456815100471358
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02530228001919475
  mean_inference_ms: 1.209464490094011
  mean_raw_obs_processing_ms: 0.27492447660584657
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02186417579650879
    StateBufferConnector_ms: 0.003979682922363281
    ViewRequirementAgentConnector_ms: 0.13035178184509277
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 9.32
  episode_reward_min: 3.0
  episodes_this_iter: 92
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 8.0, 13.0, 8.0, 11.0, 8.0, 7.0, 11.0, 7.0, 9.0, 7.0, 10.0,
      9.0, 7.0, 9.0, 6.0, 11.0, 5.0, 6.0, 9.0, 12.0, 6.0, 10.0, 6.0, 8.0, 10.0, 4.0,
      10.0, 11.0, 11.0, 9.0, 13.0, 9.0, 12.0, 8.0, 9.0, 13.0, 13.0, 8.0, 7.0, 11.0,
      7.0, 10.0, 12.0, 11.0, 8.0, 9.0, 12.0, 9.0, 9.0, 11.0, 11.0, 10.0, 9.0, 11.0,
      8.0, 14.0, 7.0, 8.0, 11.0, 13.0, 8.0, 6.0, 7.0, 8.0, 13.0, 9.0, 14.0, 10.0,
      11.0, 11.0, 13.0, 10.0, 10.0, 4.0, 3.0, 10.0, 12.0, 12.0, 6.0, 5.0, 4.0, 9.0,
      9.0, 14.0, 8.0, 11.0, 13.0, 6.0, 11.0, 7.0, 13.0, 13.0, 11.0, 9.0, 7.0, 9.0,
      10.0, 6.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06456815100471358
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02530228001919475
    mean_inference_ms: 1.209464490094011
    mean_raw_obs_processing_ms: 0.27492447660584657
time_since_restore: 3429.5329003334045
time_this_iter_s: 10.097053289413452
time_total_s: 3429.5329003334045
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691997610
timesteps_total: 4190300
training_iteration: 338
trial_id: default
train step: 339
agent_timesteps_total: 4202700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021438121795654297
  StateBufferConnector_ms: 0.0037615299224853516
  ViewRequirementAgentConnector_ms: 0.1295938491821289
counters:
  num_agent_steps_sampled: 4202700
  num_agent_steps_trained: 4186000
  num_env_steps_sampled: 4202700
  num_env_steps_trained: 4186000
  num_samples_added_to_queue: 4202500
  num_training_step_calls_since_last_synch_worker_weights: 425
  num_weight_broadcasts: 82626
custom_metrics: {}
date: 2023-08-14_16-20-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.22
episode_reward_min: 3.0
episodes_this_iter: 97
episodes_total: 32834
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6561259627342224
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 21.13972282409668
        total_loss: 48.92488479614258
        var_gnorm: 64.88722229003906
        vf_explained_var: 0.9036820530891418
        vf_loss: 62.1315803527832
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8372.0
  learner_queue:
    size_count: 8379
    size_mean: 15.4
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3564659966250536
  num_agent_steps_sampled: 4202700
  num_agent_steps_trained: 4186000
  num_env_steps_sampled: 4202700
  num_env_steps_trained: 4186000
  num_samples_added_to_queue: 4202500
  num_training_step_calls_since_last_synch_worker_weights: 425
  num_weight_broadcasts: 82626
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 174.914
    learner_load_time_ms: 1.737
    learner_load_wait_time_ms: 1.799
iterations_since_restore: 339
node_ip: 127.0.0.1
num_agent_steps_sampled: 4202700
num_agent_steps_trained: 4186000
num_env_steps_sampled: 4202700
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.995269793435
num_env_steps_trained: 4186000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9952316466079
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 68.83571428571429
  ram_util_percent: 78.97857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06456205419439212
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025303466519086378
  mean_inference_ms: 1.2095171647373304
  mean_raw_obs_processing_ms: 0.27493721070300287
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021438121795654297
    StateBufferConnector_ms: 0.0037615299224853516
    ViewRequirementAgentConnector_ms: 0.1295938491821289
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.22
  episode_reward_min: 3.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 6.0, 8.0, 11.0, 9.0, 10.0, 10.0, 6.0, 4.0, 9.0, 7.0, 10.0,
      9.0, 9.0, 8.0, 13.0, 9.0, 13.0, 7.0, 8.0, 5.0, 13.0, 9.0, 10.0, 10.0, 12.0,
      15.0, 4.0, 10.0, 5.0, 10.0, 4.0, 7.0, 11.0, 9.0, 8.0, 5.0, 9.0, 10.0, 8.0, 12.0,
      9.0, 3.0, 12.0, 11.0, 7.0, 9.0, 10.0, 8.0, 9.0, 13.0, 8.0, 11.0, 9.0, 10.0,
      12.0, 6.0, 9.0, 12.0, 8.0, 10.0, 10.0, 5.0, 9.0, 4.0, 10.0, 8.0, 9.0, 4.0, 6.0,
      13.0, 13.0, 8.0, 6.0, 9.0, 11.0, 10.0, 8.0, 15.0, 9.0, 6.0, 12.0, 12.0, 14.0,
      13.0, 8.0, 7.0, 11.0, 14.0, 7.0, 9.0, 9.0, 12.0, 11.0, 8.0, 12.0, 8.0, 14.0,
      10.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06456205419439212
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025303466519086378
    mean_inference_ms: 1.2095171647373304
    mean_raw_obs_processing_ms: 0.27493721070300287
time_since_restore: 3439.7404475212097
time_this_iter_s: 10.207547187805176
time_total_s: 3439.7404475212097
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691997620
timesteps_total: 4202700
training_iteration: 339
trial_id: default
train step: 340
agent_timesteps_total: 4214400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023329496383666992
  StateBufferConnector_ms: 0.0041654109954833984
  ViewRequirementAgentConnector_ms: 0.13559770584106445
counters:
  num_agent_steps_sampled: 4214400
  num_agent_steps_trained: 4197500
  num_env_steps_sampled: 4214400
  num_env_steps_trained: 4197500
  num_samples_added_to_queue: 4214000
  num_training_step_calls_since_last_synch_worker_weights: 900
  num_weight_broadcasts: 82857
custom_metrics: {}
date: 2023-08-14_16-20-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.9
episode_reward_min: 4.0
episodes_this_iter: 91
episodes_total: 32925
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.620161771774292
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.9537057876586914
        total_loss: 51.472835540771484
        var_gnorm: 64.89022827148438
        vf_explained_var: 0.8683527708053589
        vf_loss: 107.23987579345703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8395.0
  learner_queue:
    size_count: 8401
    size_mean: 15.02
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7145261736118234
  num_agent_steps_sampled: 4214400
  num_agent_steps_trained: 4197500
  num_env_steps_sampled: 4214400
  num_env_steps_trained: 4197500
  num_samples_added_to_queue: 4214000
  num_training_step_calls_since_last_synch_worker_weights: 900
  num_weight_broadcasts: 82857
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 239.867
    learner_load_time_ms: 1.781
    learner_load_wait_time_ms: 1.982
iterations_since_restore: 340
node_ip: 127.0.0.1
num_agent_steps_sampled: 4214400
num_agent_steps_trained: 4197500
num_env_steps_sampled: 4214400
num_env_steps_sampled_this_iter: 11700
num_env_steps_sampled_throughput_per_sec: 1169.997768406356
num_env_steps_trained: 4197500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.997806553256
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 61.84
  ram_util_percent: 82.71999999999998
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06458257620483128
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02531159469088965
  mean_inference_ms: 1.2096873336836884
  mean_raw_obs_processing_ms: 0.274979088504479
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023329496383666992
    StateBufferConnector_ms: 0.0041654109954833984
    ViewRequirementAgentConnector_ms: 0.13559770584106445
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.9
  episode_reward_min: 4.0
  episodes_this_iter: 91
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 12.0, 11.0, 8.0, 12.0, 8.0, 14.0, 10.0, 10.0, 10.0, 13.0,
      8.0, 17.0, 8.0, 10.0, 9.0, 6.0, 14.0, 12.0, 7.0, 11.0, 7.0, 12.0, 15.0, 10.0,
      11.0, 9.0, 14.0, 9.0, 10.0, 8.0, 11.0, 14.0, 15.0, 12.0, 8.0, 8.0, 9.0, 9.0,
      12.0, 10.0, 11.0, 5.0, 12.0, 6.0, 13.0, 6.0, 9.0, 7.0, 13.0, 11.0, 7.0, 11.0,
      7.0, 10.0, 8.0, 9.0, 9.0, 7.0, 10.0, 10.0, 13.0, 11.0, 9.0, 8.0, 12.0, 11.0,
      10.0, 9.0, 13.0, 4.0, 12.0, 9.0, 8.0, 11.0, 9.0, 8.0, 7.0, 11.0, 9.0, 10.0,
      8.0, 7.0, 7.0, 6.0, 7.0, 11.0, 7.0, 6.0, 11.0, 11.0, 10.0, 15.0, 15.0, 11.0,
      4.0, 14.0, 13.0, 10.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06458257620483128
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02531159469088965
    mean_inference_ms: 1.2096873336836884
    mean_raw_obs_processing_ms: 0.274979088504479
time_since_restore: 3449.9170665740967
time_this_iter_s: 10.176619052886963
time_total_s: 3449.9170665740967
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.047
timestamp: 1691997631
timesteps_total: 4214400
training_iteration: 340
trial_id: default
train step: 341
agent_timesteps_total: 4226800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02248978614807129
  StateBufferConnector_ms: 0.0038652420043945312
  ViewRequirementAgentConnector_ms: 0.13100981712341309
counters:
  num_agent_steps_sampled: 4226800
  num_agent_steps_trained: 4210000
  num_env_steps_sampled: 4226800
  num_env_steps_trained: 4210000
  num_samples_added_to_queue: 4226500
  num_training_step_calls_since_last_synch_worker_weights: 18
  num_weight_broadcasts: 83101
custom_metrics: {}
date: 2023-08-14_16-20-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 9.24
episode_reward_min: 2.0
episodes_this_iter: 98
episodes_total: 33023
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5925244688987732
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -44.852638244628906
        total_loss: 29.009965896606445
        var_gnorm: 64.89901733398438
        vf_explained_var: 0.8308305740356445
        vf_loss: 153.65045166015625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8420.0
  learner_queue:
    size_count: 8428
    size_mean: 14.64
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.047046653107838
  num_agent_steps_sampled: 4226800
  num_agent_steps_trained: 4210000
  num_env_steps_sampled: 4226800
  num_env_steps_trained: 4210000
  num_samples_added_to_queue: 4226500
  num_training_step_calls_since_last_synch_worker_weights: 18
  num_weight_broadcasts: 83101
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 119.7
    learner_load_time_ms: 1.671
    learner_load_wait_time_ms: 1.613
iterations_since_restore: 341
node_ip: 127.0.0.1
num_agent_steps_sampled: 4226800
num_agent_steps_trained: 4210000
num_env_steps_sampled: 4226800
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.996156704417
num_env_steps_trained: 4210000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9961257100977
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 50.72857142857142
  ram_util_percent: 81.90714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0645718147271802
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025316050068188822
  mean_inference_ms: 1.2097641268541814
  mean_raw_obs_processing_ms: 0.2749813576348786
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02248978614807129
    StateBufferConnector_ms: 0.0038652420043945312
    ViewRequirementAgentConnector_ms: 0.13100981712341309
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 9.24
  episode_reward_min: 2.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 10.0, 12.0, 9.0, 10.0, 10.0, 10.0, 7.0, 13.0, 8.0, 8.0,
      8.0, 11.0, 9.0, 8.0, 10.0, 9.0, 10.0, 5.0, 11.0, 7.0, 8.0, 9.0, 7.0, 8.0, 14.0,
      2.0, 9.0, 10.0, 12.0, 10.0, 8.0, 11.0, 11.0, 8.0, 4.0, 11.0, 11.0, 12.0, 6.0,
      10.0, 9.0, 9.0, 10.0, 9.0, 11.0, 8.0, 12.0, 8.0, 9.0, 6.0, 6.0, 9.0, 5.0, 8.0,
      10.0, 11.0, 10.0, 12.0, 6.0, 4.0, 11.0, 5.0, 10.0, 8.0, 11.0, 12.0, 11.0, 7.0,
      7.0, 12.0, 8.0, 12.0, 14.0, 14.0, 12.0, 8.0, 6.0, 12.0, 9.0, 9.0, 6.0, 10.0,
      11.0, 11.0, 9.0, 6.0, 9.0, 10.0, 11.0, 8.0, 5.0, 10.0, 10.0, 12.0, 9.0, 12.0,
      11.0, 12.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0645718147271802
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025316050068188822
    mean_inference_ms: 1.2097641268541814
    mean_raw_obs_processing_ms: 0.2749813576348786
time_since_restore: 3460.134822368622
time_this_iter_s: 10.217755794525146
time_total_s: 3460.134822368622
timers:
  sample_time_ms: 0.021
  synch_weights_time_ms: 0.01
  training_iteration_time_ms: 0.069
timestamp: 1691997641
timesteps_total: 4226800
training_iteration: 341
trial_id: default
train step: 342
agent_timesteps_total: 4239800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020240321017727995
  StateBufferConnector_ms: 0.00364473550626547
  ViewRequirementAgentConnector_ms: 0.12105951214780902
counters:
  num_agent_steps_sampled: 4239800
  num_agent_steps_trained: 4223000
  num_env_steps_sampled: 4239800
  num_env_steps_trained: 4223000
  num_samples_added_to_queue: 4239500
  num_training_step_calls_since_last_synch_worker_weights: 1411
  num_weight_broadcasts: 83353
custom_metrics: {}
date: 2023-08-14_16-20-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.831683168316832
episode_reward_min: 4.0
episodes_this_iter: 101
episodes_total: 33124
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6022862195968628
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.6346426010131836
        total_loss: 57.48640441894531
        var_gnorm: 64.90094757080078
        vf_explained_var: 0.8312925100326538
        vf_loss: 124.26496124267578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8446.0
  learner_queue:
    size_count: 8451
    size_mean: 14.86
    size_quantiles: [9.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.8762729012593025
  num_agent_steps_sampled: 4239800
  num_agent_steps_trained: 4223000
  num_env_steps_sampled: 4239800
  num_env_steps_trained: 4223000
  num_samples_added_to_queue: 4239500
  num_training_step_calls_since_last_synch_worker_weights: 1411
  num_weight_broadcasts: 83353
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 228.091
    learner_load_time_ms: 1.766
    learner_load_wait_time_ms: 1.632
iterations_since_restore: 342
node_ip: 127.0.0.1
num_agent_steps_sampled: 4239800
num_agent_steps_trained: 4223000
num_env_steps_sampled: 4239800
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9945450058003
num_env_steps_trained: 4223000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9945450058003
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.23333333333333
  ram_util_percent: 80.28666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06455969393848963
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025312160869571738
  mean_inference_ms: 1.2096087485983427
  mean_raw_obs_processing_ms: 0.2749388146533969
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020240321017727995
    StateBufferConnector_ms: 0.00364473550626547
    ViewRequirementAgentConnector_ms: 0.12105951214780902
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.831683168316832
  episode_reward_min: 4.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 6.0, 8.0, 10.0, 7.0, 10.0, 10.0, 7.0, 12.0, 7.0, 9.0, 10.0,
      12.0, 6.0, 6.0, 11.0, 12.0, 9.0, 8.0, 13.0, 10.0, 7.0, 7.0, 10.0, 8.0, 8.0,
      7.0, 5.0, 8.0, 10.0, 11.0, 6.0, 7.0, 9.0, 10.0, 13.0, 13.0, 12.0, 11.0, 11.0,
      6.0, 11.0, 10.0, 10.0, 6.0, 9.0, 12.0, 7.0, 6.0, 9.0, 9.0, 6.0, 7.0, 10.0, 12.0,
      7.0, 10.0, 9.0, 7.0, 6.0, 5.0, 9.0, 4.0, 9.0, 8.0, 11.0, 7.0, 14.0, 12.0, 9.0,
      8.0, 10.0, 8.0, 6.0, 9.0, 10.0, 8.0, 7.0, 5.0, 7.0, 8.0, 8.0, 10.0, 9.0, 8.0,
      6.0, 6.0, 7.0, 14.0, 10.0, 9.0, 10.0, 12.0, 11.0, 5.0, 7.0, 8.0, 11.0, 8.0,
      12.0, 14.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06455969393848963
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025312160869571738
    mean_inference_ms: 1.2096087485983427
    mean_raw_obs_processing_ms: 0.2749388146533969
time_since_restore: 3470.286799430847
time_this_iter_s: 10.151977062225342
time_total_s: 3470.286799430847
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691997651
timesteps_total: 4239800
training_iteration: 342
trial_id: default
train step: 343
agent_timesteps_total: 4251100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023004770278930664
  StateBufferConnector_ms: 0.00402379035949707
  ViewRequirementAgentConnector_ms: 0.13716483116149902
counters:
  num_agent_steps_sampled: 4251100
  num_agent_steps_trained: 4234500
  num_env_steps_sampled: 4251100
  num_env_steps_trained: 4234500
  num_samples_added_to_queue: 4251000
  num_training_step_calls_since_last_synch_worker_weights: 329
  num_weight_broadcasts: 83575
custom_metrics: {}
date: 2023-08-14_16-21-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.13
episode_reward_min: 3.0
episodes_this_iter: 89
episodes_total: 33213
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.20000000000073
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6111925840377808
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -24.740842819213867
        total_loss: 41.90264129638672
        var_gnorm: 64.8988265991211
        vf_explained_var: 0.8050013780593872
        vf_loss: 139.39889526367188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8469.0
  learner_queue:
    size_count: 8476
    size_mean: 14.74
    size_quantiles: [9.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9880643852752857
  num_agent_steps_sampled: 4251100
  num_agent_steps_trained: 4234500
  num_env_steps_sampled: 4251100
  num_env_steps_trained: 4234500
  num_samples_added_to_queue: 4251000
  num_training_step_calls_since_last_synch_worker_weights: 329
  num_weight_broadcasts: 83575
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 161.159
    learner_load_time_ms: 1.754
    learner_load_wait_time_ms: 1.62
iterations_since_restore: 343
node_ip: 127.0.0.1
num_agent_steps_sampled: 4251100
num_agent_steps_trained: 4234500
num_env_steps_sampled: 4251100
num_env_steps_sampled_this_iter: 11300
num_env_steps_sampled_throughput_per_sec: 1129.9971442294768
num_env_steps_trained: 4234500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9970936848656
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 57.89285714285713
  ram_util_percent: 79.74285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06459642828493722
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025321354055692427
  mean_inference_ms: 1.2098596271405762
  mean_raw_obs_processing_ms: 0.2750010494860933
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023004770278930664
    StateBufferConnector_ms: 0.00402379035949707
    ViewRequirementAgentConnector_ms: 0.13716483116149902
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.13
  episode_reward_min: 3.0
  episodes_this_iter: 89
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 10.0, 12.0, 11.0, 5.0, 7.0, 8.0, 11.0, 8.0, 12.0, 14.0,
      7.0, 6.0, 10.0, 8.0, 14.0, 9.0, 9.0, 12.0, 6.0, 9.0, 6.0, 6.0, 8.0, 7.0, 9.0,
      6.0, 9.0, 11.0, 14.0, 6.0, 6.0, 12.0, 9.0, 9.0, 3.0, 12.0, 5.0, 11.0, 10.0,
      9.0, 11.0, 10.0, 10.0, 10.0, 8.0, 11.0, 9.0, 7.0, 7.0, 11.0, 15.0, 10.0, 10.0,
      9.0, 8.0, 9.0, 9.0, 9.0, 11.0, 9.0, 6.0, 9.0, 5.0, 8.0, 11.0, 12.0, 14.0, 7.0,
      7.0, 11.0, 11.0, 7.0, 12.0, 10.0, 11.0, 8.0, 8.0, 8.0, 12.0, 9.0, 7.0, 6.0,
      6.0, 17.0, 9.0, 9.0, 11.0, 6.0, 12.0, 7.0, 8.0, 10.0, 7.0, 6.0, 11.0, 7.0, 7.0,
      13.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06459642828493722
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025321354055692427
    mean_inference_ms: 1.2098596271405762
    mean_raw_obs_processing_ms: 0.2750010494860933
time_since_restore: 3480.485124349594
time_this_iter_s: 10.198324918746948
time_total_s: 3480.485124349594
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997661
timesteps_total: 4251100
training_iteration: 343
trial_id: default
train step: 344
agent_timesteps_total: 4264200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019831283419739967
  StateBufferConnector_ms: 0.003562487807928347
  ViewRequirementAgentConnector_ms: 0.12150161406573128
counters:
  num_agent_steps_sampled: 4264200
  num_agent_steps_trained: 4247500
  num_env_steps_sampled: 4264200
  num_env_steps_trained: 4247500
  num_samples_added_to_queue: 4264000
  num_training_step_calls_since_last_synch_worker_weights: 130
  num_weight_broadcasts: 83832
custom_metrics: {}
date: 2023-08-14_16-21-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.745098039215685
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 33315
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6477878093719482
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 44.64192199707031
        total_loss: 119.19230651855469
        var_gnorm: 64.89773559570312
        vf_explained_var: 0.7853542566299438
        vf_loss: 155.57864379882812
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8495.0
  learner_queue:
    size_count: 8502
    size_mean: 14.76
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.944839324982915
  num_agent_steps_sampled: 4264200
  num_agent_steps_trained: 4247500
  num_env_steps_sampled: 4264200
  num_env_steps_trained: 4247500
  num_samples_added_to_queue: 4264000
  num_training_step_calls_since_last_synch_worker_weights: 130
  num_weight_broadcasts: 83832
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 140.429
    learner_load_time_ms: 1.825
    learner_load_wait_time_ms: 1.539
iterations_since_restore: 344
node_ip: 127.0.0.1
num_agent_steps_sampled: 4264200
num_agent_steps_trained: 4247500
num_env_steps_sampled: 4264200
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.996220838005
num_env_steps_trained: 4247500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9962496865699
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 55.42142857142858
  ram_util_percent: 78.93571428571428
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0645665762287518
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02531915068998281
  mean_inference_ms: 1.2097705041291307
  mean_raw_obs_processing_ms: 0.2749601827711032
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019831283419739967
    StateBufferConnector_ms: 0.003562487807928347
    ViewRequirementAgentConnector_ms: 0.12150161406573128
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.745098039215685
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 7.0, 11.0, 10.0, 9.0, 7.0, 7.0, 7.0, 6.0, 10.0, 6.0, 12.0,
      6.0, 4.0, 11.0, 11.0, 10.0, 6.0, 6.0, 10.0, 14.0, 7.0, 7.0, 8.0, 9.0, 6.0, 8.0,
      5.0, 12.0, 7.0, 7.0, 10.0, 10.0, 9.0, 9.0, 13.0, 7.0, 6.0, 8.0, 10.0, 10.0,
      5.0, 8.0, 5.0, 7.0, 9.0, 10.0, 8.0, 16.0, 6.0, 8.0, 7.0, 4.0, 10.0, 8.0, 8.0,
      11.0, 9.0, 15.0, 9.0, 8.0, 7.0, 10.0, 11.0, 8.0, 7.0, 7.0, 9.0, 9.0, 7.0, 11.0,
      9.0, 8.0, 9.0, 15.0, 9.0, 14.0, 10.0, 12.0, 9.0, 12.0, 8.0, 7.0, 10.0, 7.0,
      10.0, 10.0, 6.0, 12.0, 7.0, 5.0, 8.0, 14.0, 8.0, 13.0, 10.0, 9.0, 8.0, 8.0,
      7.0, 5.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0645665762287518
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02531915068998281
    mean_inference_ms: 1.2097705041291307
    mean_raw_obs_processing_ms: 0.2749601827711032
time_since_restore: 3490.669785261154
time_this_iter_s: 10.184660911560059
time_total_s: 3490.669785261154
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.049
timestamp: 1691997671
timesteps_total: 4264200
training_iteration: 344
trial_id: default
train step: 345
agent_timesteps_total: 4277400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019611096849628522
  StateBufferConnector_ms: 0.003624897377163756
  ViewRequirementAgentConnector_ms: 0.11978336409026501
counters:
  num_agent_steps_sampled: 4277400
  num_agent_steps_trained: 4260500
  num_env_steps_sampled: 4277400
  num_env_steps_trained: 4260500
  num_samples_added_to_queue: 4277000
  num_training_step_calls_since_last_synch_worker_weights: 808
  num_weight_broadcasts: 84090
custom_metrics: {}
date: 2023-08-14_16-21-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.588235294117647
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 33417
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6373588442802429
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 36.538848876953125
        total_loss: 72.90067291259766
        var_gnorm: 64.89786529541016
        vf_explained_var: 0.873318076133728
        vf_loss: 79.09722137451172
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8521.0
  learner_queue:
    size_count: 8526
    size_mean: 14.84
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8586016248782309
  num_agent_steps_sampled: 4277400
  num_agent_steps_trained: 4260500
  num_env_steps_sampled: 4277400
  num_env_steps_trained: 4260500
  num_samples_added_to_queue: 4277000
  num_training_step_calls_since_last_synch_worker_weights: 808
  num_weight_broadcasts: 84090
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 227.764
    learner_load_time_ms: 1.615
    learner_load_wait_time_ms: 1.638
iterations_since_restore: 345
node_ip: 127.0.0.1
num_agent_steps_sampled: 4277400
num_agent_steps_trained: 4260500
num_env_steps_sampled: 4277400
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.999055863102
num_env_steps_trained: 4260500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9990701682066
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.019999999999996
  ram_util_percent: 78.42666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06455294833600117
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0253127647845334
  mean_inference_ms: 1.209535871255662
  mean_raw_obs_processing_ms: 0.2749107248208585
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019611096849628522
    StateBufferConnector_ms: 0.003624897377163756
    ViewRequirementAgentConnector_ms: 0.11978336409026501
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.588235294117647
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 8.0, 10.0, 4.0, 10.0, 11.0, 7.0, 14.0, 16.0, 7.0, 9.0,
      10.0, 11.0, 10.0, 5.0, 14.0, 12.0, 8.0, 9.0, 13.0, 5.0, 7.0, 15.0, 10.0, 9.0,
      13.0, 12.0, 11.0, 11.0, 9.0, 14.0, 7.0, 11.0, 13.0, 6.0, 4.0, 12.0, 13.0, 8.0,
      7.0, 8.0, 8.0, 6.0, 10.0, 12.0, 7.0, 7.0, 12.0, 10.0, 7.0, 7.0, 7.0, 9.0, 10.0,
      13.0, 14.0, 10.0, 8.0, 13.0, 7.0, 7.0, 13.0, 10.0, 9.0, 8.0, 5.0, 6.0, 10.0,
      16.0, 11.0, 7.0, 9.0, 12.0, 12.0, 6.0, 6.0, 18.0, 8.0, 9.0, 7.0, 7.0, 7.0, 10.0,
      9.0, 10.0, 10.0, 12.0, 10.0, 8.0, 10.0, 15.0, 6.0, 5.0, 12.0, 12.0, 10.0, 10.0,
      10.0, 8.0, 6.0, 13.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06455294833600117
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0253127647845334
    mean_inference_ms: 1.209535871255662
    mean_raw_obs_processing_ms: 0.2749107248208585
time_since_restore: 3500.7911233901978
time_this_iter_s: 10.121338129043579
time_total_s: 3500.7911233901978
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997682
timesteps_total: 4277400
training_iteration: 345
trial_id: default
train step: 346
agent_timesteps_total: 4290100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020507097244262695
  StateBufferConnector_ms: 0.0036537647247314453
  ViewRequirementAgentConnector_ms: 0.1256091594696045
counters:
  num_agent_steps_sampled: 4290100
  num_agent_steps_trained: 4273500
  num_env_steps_sampled: 4290100
  num_env_steps_trained: 4273500
  num_samples_added_to_queue: 4290000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 84339
custom_metrics: {}
date: 2023-08-14_16-21-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.38
episode_reward_min: 4.0
episodes_this_iter: 99
episodes_total: 33516
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6171896457672119
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -28.4949951171875
        total_loss: 21.21712875366211
        var_gnorm: 64.89787292480469
        vf_explained_var: 0.8507143259048462
        vf_loss: 105.59614562988281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8547.0
  learner_queue:
    size_count: 8554
    size_mean: 15.24
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.477294825009551
  num_agent_steps_sampled: 4290100
  num_agent_steps_trained: 4273500
  num_env_steps_sampled: 4290100
  num_env_steps_trained: 4273500
  num_samples_added_to_queue: 4290000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 84339
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 134.469
    learner_load_time_ms: 2.101
    learner_load_wait_time_ms: 1.585
iterations_since_restore: 346
node_ip: 127.0.0.1
num_agent_steps_sampled: 4290100
num_agent_steps_trained: 4273500
num_env_steps_sampled: 4290100
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.7323583655284
num_env_steps_trained: 4273500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.7260361221943
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 65.79285714285714
  ram_util_percent: 78.64999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.064552468828521
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025311630028143073
  mean_inference_ms: 1.2094429034332899
  mean_raw_obs_processing_ms: 0.2748948879730397
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020507097244262695
    StateBufferConnector_ms: 0.0036537647247314453
    ViewRequirementAgentConnector_ms: 0.1256091594696045
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.38
  episode_reward_min: 4.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 12.0, 7.0, 13.0, 6.0, 10.0, 7.0, 6.0, 10.0, 10.0, 15.0,
      12.0, 5.0, 12.0, 16.0, 7.0, 5.0, 10.0, 12.0, 10.0, 12.0, 8.0, 6.0, 5.0, 7.0,
      10.0, 8.0, 11.0, 10.0, 13.0, 8.0, 10.0, 15.0, 8.0, 14.0, 7.0, 12.0, 11.0, 10.0,
      10.0, 9.0, 7.0, 5.0, 11.0, 6.0, 7.0, 9.0, 12.0, 14.0, 8.0, 5.0, 8.0, 7.0, 13.0,
      7.0, 9.0, 5.0, 11.0, 7.0, 11.0, 8.0, 8.0, 14.0, 13.0, 10.0, 7.0, 9.0, 6.0, 15.0,
      9.0, 10.0, 17.0, 12.0, 10.0, 11.0, 7.0, 9.0, 6.0, 14.0, 13.0, 5.0, 10.0, 4.0,
      8.0, 11.0, 12.0, 5.0, 11.0, 10.0, 9.0, 8.0, 4.0, 9.0, 11.0, 12.0, 9.0, 10.0,
      11.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.064552468828521
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025311630028143073
    mean_inference_ms: 1.2094429034332899
    mean_raw_obs_processing_ms: 0.2748948879730397
time_since_restore: 3510.951147556305
time_this_iter_s: 10.160024166107178
time_total_s: 3510.951147556305
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.231
  training_iteration_time_ms: 0.332
timestamp: 1691997692
timesteps_total: 4290100
training_iteration: 346
trial_id: default
train step: 347
agent_timesteps_total: 4302350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02048206329345703
  StateBufferConnector_ms: 0.0038025379180908203
  ViewRequirementAgentConnector_ms: 0.14372611045837402
counters:
  num_agent_steps_sampled: 4302350
  num_agent_steps_trained: 4285500
  num_env_steps_sampled: 4302350
  num_env_steps_trained: 4285500
  num_samples_added_to_queue: 4302000
  num_training_step_calls_since_last_synch_worker_weights: 156
  num_weight_broadcasts: 84582
custom_metrics: {}
date: 2023-08-14_16-21-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.61
episode_reward_min: 3.0
episodes_this_iter: 97
episodes_total: 33613
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6048442125320435
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.4944206476211548
        total_loss: 46.58112716674805
        var_gnorm: 64.89842224121094
        vf_explained_var: 0.8811291456222534
        vf_loss: 100.19953155517578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8571.0
  learner_queue:
    size_count: 8578
    size_mean: 14.98
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8164801127455263
  num_agent_steps_sampled: 4302350
  num_agent_steps_trained: 4285500
  num_env_steps_sampled: 4302350
  num_env_steps_trained: 4285500
  num_samples_added_to_queue: 4302000
  num_training_step_calls_since_last_synch_worker_weights: 156
  num_weight_broadcasts: 84582
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 154.319
    learner_load_time_ms: 2.07
    learner_load_wait_time_ms: 1.713
iterations_since_restore: 347
node_ip: 127.0.0.1
num_agent_steps_sampled: 4302350
num_agent_steps_trained: 4285500
num_env_steps_sampled: 4302350
num_env_steps_sampled_this_iter: 12250
num_env_steps_sampled_throughput_per_sec: 1224.995940341098
num_env_steps_trained: 4285500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9960231912798
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 59.87857142857143
  ram_util_percent: 78.20714285714284
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.064554924759362
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02531421042769642
  mean_inference_ms: 1.209473776346483
  mean_raw_obs_processing_ms: 0.2749057977085367
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02048206329345703
    StateBufferConnector_ms: 0.0038025379180908203
    ViewRequirementAgentConnector_ms: 0.14372611045837402
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.61
  episode_reward_min: 3.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 7.0, 6.0, 12.0, 6.0, 9.0, 12.0, 7.0, 11.0, 8.0, 11.0, 10.0,
      6.0, 13.0, 10.0, 14.0, 8.0, 9.0, 9.0, 7.0, 7.0, 7.0, 9.0, 8.0, 10.0, 3.0, 10.0,
      9.0, 7.0, 6.0, 12.0, 12.0, 14.0, 8.0, 13.0, 8.0, 13.0, 14.0, 11.0, 9.0, 11.0,
      10.0, 11.0, 13.0, 9.0, 9.0, 6.0, 6.0, 14.0, 9.0, 10.0, 11.0, 13.0, 3.0, 8.0,
      11.0, 9.0, 9.0, 10.0, 14.0, 8.0, 11.0, 10.0, 13.0, 9.0, 9.0, 13.0, 6.0, 9.0,
      12.0, 9.0, 8.0, 10.0, 11.0, 6.0, 11.0, 15.0, 12.0, 9.0, 9.0, 10.0, 9.0, 8.0,
      6.0, 12.0, 9.0, 12.0, 6.0, 6.0, 11.0, 13.0, 13.0, 8.0, 8.0, 11.0, 8.0, 8.0,
      11.0, 12.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.064554924759362
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02531421042769642
    mean_inference_ms: 1.209473776346483
    mean_raw_obs_processing_ms: 0.2749057977085367
time_since_restore: 3521.1291074752808
time_this_iter_s: 10.17795991897583
time_total_s: 3521.1291074752808
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691997702
timesteps_total: 4302350
training_iteration: 347
trial_id: default
train step: 348
agent_timesteps_total: 4314750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02112436294555664
  StateBufferConnector_ms: 0.0038318634033203125
  ViewRequirementAgentConnector_ms: 0.12849164009094238
counters:
  num_agent_steps_sampled: 4314750
  num_agent_steps_trained: 4298000
  num_env_steps_sampled: 4314750
  num_env_steps_trained: 4298000
  num_samples_added_to_queue: 4314500
  num_training_step_calls_since_last_synch_worker_weights: 709
  num_weight_broadcasts: 84827
custom_metrics: {}
date: 2023-08-14_16-21-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.36
episode_reward_min: 4.0
episodes_this_iter: 97
episodes_total: 33710
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6569364070892334
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.452472686767578
        total_loss: 80.08984375
        var_gnorm: 64.8995132446289
        vf_explained_var: 0.7851596474647522
        vf_loss: 205.65399169921875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8596.0
  learner_queue:
    size_count: 8601
    size_mean: 14.72
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8977881862842332
  num_agent_steps_sampled: 4314750
  num_agent_steps_trained: 4298000
  num_env_steps_sampled: 4314750
  num_env_steps_trained: 4298000
  num_samples_added_to_queue: 4314500
  num_training_step_calls_since_last_synch_worker_weights: 709
  num_weight_broadcasts: 84827
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 219.331
    learner_load_time_ms: 1.968
    learner_load_wait_time_ms: 1.522
iterations_since_restore: 348
node_ip: 127.0.0.1
num_agent_steps_sampled: 4314750
num_agent_steps_trained: 4298000
num_env_steps_sampled: 4314750
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.9935551024673
num_env_steps_trained: 4298000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9935031274872
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 60.27857142857143
  ram_util_percent: 78.78571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06456030972533068
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025316184752575053
  mean_inference_ms: 1.2094483626423553
  mean_raw_obs_processing_ms: 0.2749081295494252
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02112436294555664
    StateBufferConnector_ms: 0.0038318634033203125
    ViewRequirementAgentConnector_ms: 0.12849164009094238
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.36
  episode_reward_min: 4.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 12.0, 8.0, 7.0, 7.0, 5.0, 8.0, 11.0, 11.0, 9.0, 7.0, 4.0,
      14.0, 14.0, 7.0, 9.0, 8.0, 12.0, 10.0, 14.0, 5.0, 11.0, 12.0, 12.0, 7.0, 11.0,
      7.0, 10.0, 13.0, 5.0, 13.0, 12.0, 10.0, 6.0, 8.0, 12.0, 9.0, 11.0, 10.0, 11.0,
      10.0, 8.0, 8.0, 5.0, 10.0, 11.0, 11.0, 10.0, 5.0, 9.0, 8.0, 13.0, 9.0, 4.0,
      10.0, 6.0, 9.0, 12.0, 13.0, 8.0, 5.0, 7.0, 8.0, 10.0, 9.0, 11.0, 10.0, 12.0,
      9.0, 9.0, 9.0, 11.0, 7.0, 7.0, 11.0, 10.0, 12.0, 9.0, 8.0, 10.0, 12.0, 6.0,
      8.0, 10.0, 8.0, 9.0, 11.0, 11.0, 14.0, 9.0, 8.0, 5.0, 4.0, 15.0, 12.0, 6.0,
      9.0, 12.0, 9.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06456030972533068
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025316184752575053
    mean_inference_ms: 1.2094483626423553
    mean_raw_obs_processing_ms: 0.2749081295494252
time_since_restore: 3531.2463104724884
time_this_iter_s: 10.117202997207642
time_total_s: 3531.2463104724884
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997712
timesteps_total: 4314750
training_iteration: 348
trial_id: default
train step: 349
agent_timesteps_total: 4328150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019421485754159782
  StateBufferConnector_ms: 0.0035132353122417745
  ViewRequirementAgentConnector_ms: 0.11656146783095139
counters:
  num_agent_steps_sampled: 4328150
  num_agent_steps_trained: 4311500
  num_env_steps_sampled: 4328150
  num_env_steps_trained: 4311500
  num_samples_added_to_queue: 4328000
  num_training_step_calls_since_last_synch_worker_weights: 489
  num_weight_broadcasts: 85092
custom_metrics: {}
date: 2023-08-14_16-22-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.846153846153847
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 33814
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.724948525428772
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 28.316543579101562
        total_loss: 71.41924285888672
        var_gnorm: 64.89886474609375
        vf_explained_var: 0.8803491592407227
        vf_loss: 93.45487976074219
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8623.0
  learner_queue:
    size_count: 8629
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3152946437965904
  num_agent_steps_sampled: 4328150
  num_agent_steps_trained: 4311500
  num_env_steps_sampled: 4328150
  num_env_steps_trained: 4311500
  num_samples_added_to_queue: 4328000
  num_training_step_calls_since_last_synch_worker_weights: 489
  num_weight_broadcasts: 85092
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 169.614
    learner_load_time_ms: 1.966
    learner_load_wait_time_ms: 1.697
iterations_since_restore: 349
node_ip: 127.0.0.1
num_agent_steps_sampled: 4328150
num_agent_steps_trained: 4311500
num_env_steps_sampled: 4328150
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9973483138106
num_env_steps_trained: 4311500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9973285251076
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.61333333333333
  ram_util_percent: 78.37333333333335
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06453438274286935
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025308457896983716
  mean_inference_ms: 1.2091929503178496
  mean_raw_obs_processing_ms: 0.27484225346615543
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019421485754159782
    StateBufferConnector_ms: 0.0035132353122417745
    ViewRequirementAgentConnector_ms: 0.11656146783095139
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.846153846153847
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 10.0, 6.0, 10.0, 8.0, 10.0, 7.0, 9.0, 4.0, 6.0, 7.0, 10.0,
      7.0, 8.0, 7.0, 12.0, 10.0, 8.0, 7.0, 10.0, 13.0, 5.0, 17.0, 9.0, 6.0, 6.0, 12.0,
      8.0, 9.0, 11.0, 9.0, 11.0, 9.0, 6.0, 8.0, 12.0, 8.0, 9.0, 7.0, 4.0, 15.0, 11.0,
      14.0, 9.0, 10.0, 8.0, 9.0, 3.0, 5.0, 3.0, 8.0, 13.0, 12.0, 8.0, 8.0, 2.0, 7.0,
      12.0, 6.0, 7.0, 9.0, 7.0, 11.0, 6.0, 11.0, 6.0, 13.0, 14.0, 10.0, 5.0, 7.0,
      6.0, 11.0, 10.0, 9.0, 11.0, 8.0, 5.0, 8.0, 9.0, 9.0, 8.0, 11.0, 8.0, 13.0, 7.0,
      13.0, 8.0, 7.0, 9.0, 8.0, 13.0, 11.0, 11.0, 9.0, 9.0, 11.0, 12.0, 6.0, 4.0,
      6.0, 17.0, 9.0, 14.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06453438274286935
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025308457896983716
    mean_inference_ms: 1.2091929503178496
    mean_raw_obs_processing_ms: 0.27484225346615543
time_since_restore: 3541.381932258606
time_this_iter_s: 10.135621786117554
time_total_s: 3541.381932258606
timers:
  sample_time_ms: 0.018
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.051
timestamp: 1691997722
timesteps_total: 4328150
training_iteration: 349
trial_id: default
train step: 350
agent_timesteps_total: 4341450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019821983117323656
  StateBufferConnector_ms: 0.0035267609816331128
  ViewRequirementAgentConnector_ms: 0.11853300608121432
counters:
  num_agent_steps_sampled: 4341450
  num_agent_steps_trained: 4324500
  num_env_steps_sampled: 4341450
  num_env_steps_trained: 4324500
  num_samples_added_to_queue: 4341000
  num_training_step_calls_since_last_synch_worker_weights: 12
  num_weight_broadcasts: 85352
custom_metrics: {}
date: 2023-08-14_16-22-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.25
episode_reward_min: 4.0
episodes_this_iter: 104
episodes_total: 33918
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6830080151557922
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.786397933959961
        total_loss: 22.617855072021484
        var_gnorm: 64.89835357666016
        vf_explained_var: 0.9263883829116821
        vf_loss: 44.49299621582031
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8649.0
  learner_queue:
    size_count: 8656
    size_mean: 15.18
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5835403373454053
  num_agent_steps_sampled: 4341450
  num_agent_steps_trained: 4324500
  num_env_steps_sampled: 4341450
  num_env_steps_trained: 4324500
  num_samples_added_to_queue: 4341000
  num_training_step_calls_since_last_synch_worker_weights: 12
  num_weight_broadcasts: 85352
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 147.931
    learner_load_time_ms: 1.875
    learner_load_wait_time_ms: 1.553
iterations_since_restore: 350
node_ip: 127.0.0.1
num_agent_steps_sampled: 4341450
num_agent_steps_trained: 4324500
num_env_steps_sampled: 4341450
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9944191213187
num_env_steps_trained: 4324500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9945450058003
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 48.79285714285714
  ram_util_percent: 77.31428571428572
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06452042673226024
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025302617209940818
  mean_inference_ms: 1.2089467650681036
  mean_raw_obs_processing_ms: 0.2747865595867763
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019821983117323656
    StateBufferConnector_ms: 0.0035267609816331128
    ViewRequirementAgentConnector_ms: 0.11853300608121432
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.25
  episode_reward_min: 4.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 8.0, 11.0, 13.0, 9.0, 9.0, 9.0, 5.0, 11.0, 5.0, 8.0, 10.0,
      10.0, 7.0, 7.0, 6.0, 9.0, 4.0, 11.0, 10.0, 5.0, 15.0, 12.0, 7.0, 5.0, 8.0, 9.0,
      12.0, 6.0, 14.0, 14.0, 10.0, 8.0, 11.0, 11.0, 9.0, 13.0, 10.0, 8.0, 9.0, 12.0,
      7.0, 8.0, 9.0, 14.0, 13.0, 9.0, 8.0, 4.0, 7.0, 11.0, 11.0, 9.0, 8.0, 12.0, 11.0,
      7.0, 7.0, 6.0, 12.0, 10.0, 8.0, 10.0, 11.0, 12.0, 14.0, 8.0, 10.0, 12.0, 9.0,
      16.0, 8.0, 8.0, 7.0, 12.0, 6.0, 8.0, 14.0, 5.0, 10.0, 8.0, 8.0, 12.0, 8.0, 8.0,
      11.0, 7.0, 10.0, 10.0, 9.0, 9.0, 9.0, 10.0, 12.0, 12.0, 5.0, 7.0, 10.0, 10.0,
      6.0, 11.0, 5.0, 6.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06452042673226024
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025302617209940818
    mean_inference_ms: 1.2089467650681036
    mean_raw_obs_processing_ms: 0.2747865595867763
time_since_restore: 3551.533664226532
time_this_iter_s: 10.151731967926025
time_total_s: 3551.533664226532
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691997732
timesteps_total: 4341450
training_iteration: 350
trial_id: default
train step: 351
agent_timesteps_total: 4354650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019590368548643242
  StateBufferConnector_ms: 0.0036230365049491806
  ViewRequirementAgentConnector_ms: 0.11795192088895631
counters:
  num_agent_steps_sampled: 4354650
  num_agent_steps_trained: 4338000
  num_env_steps_sampled: 4354650
  num_env_steps_trained: 4338000
  num_samples_added_to_queue: 4354500
  num_training_step_calls_since_last_synch_worker_weights: 1344
  num_weight_broadcasts: 85611
custom_metrics: {}
date: 2023-08-14_16-22-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.262135922330097
episode_reward_min: 3.0
episodes_this_iter: 103
episodes_total: 34021
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6793152093887329
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 6.200321197509766
        total_loss: 45.527679443359375
        var_gnorm: 64.90269470214844
        vf_explained_var: 0.8712841272354126
        vf_loss: 85.44786834716797
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8676.0
  learner_queue:
    size_count: 8680
    size_mean: 15.26
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4671059948074647
  num_agent_steps_sampled: 4354650
  num_agent_steps_trained: 4338000
  num_env_steps_sampled: 4354650
  num_env_steps_trained: 4338000
  num_samples_added_to_queue: 4354500
  num_training_step_calls_since_last_synch_worker_weights: 1344
  num_weight_broadcasts: 85611
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 244.265
    learner_load_time_ms: 1.878
    learner_load_wait_time_ms: 1.72
iterations_since_restore: 351
node_ip: 127.0.0.1
num_agent_steps_sampled: 4354650
num_agent_steps_trained: 4338000
num_env_steps_sampled: 4354650
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.994996089831
num_env_steps_trained: 4338000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9948823645998
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.38571428571429
  ram_util_percent: 76.0642857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06450276122379747
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025295290620579898
  mean_inference_ms: 1.2087254745111913
  mean_raw_obs_processing_ms: 0.2747250732125506
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019590368548643242
    StateBufferConnector_ms: 0.0036230365049491806
    ViewRequirementAgentConnector_ms: 0.11795192088895631
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.262135922330097
  episode_reward_min: 3.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 9.0, 7.0, 10.0, 14.0, 10.0, 11.0, 11.0, 10.0, 8.0,
      11.0, 8.0, 8.0, 15.0, 9.0, 8.0, 16.0, 8.0, 14.0, 9.0, 3.0, 8.0, 5.0, 7.0, 9.0,
      9.0, 8.0, 14.0, 10.0, 10.0, 11.0, 7.0, 8.0, 11.0, 8.0, 12.0, 10.0, 7.0, 9.0,
      10.0, 9.0, 14.0, 5.0, 9.0, 7.0, 11.0, 8.0, 10.0, 10.0, 8.0, 10.0, 7.0, 7.0,
      8.0, 8.0, 11.0, 10.0, 8.0, 11.0, 8.0, 9.0, 6.0, 7.0, 10.0, 11.0, 11.0, 9.0,
      10.0, 6.0, 10.0, 14.0, 9.0, 6.0, 11.0, 11.0, 8.0, 5.0, 11.0, 9.0, 9.0, 15.0,
      9.0, 9.0, 9.0, 7.0, 9.0, 6.0, 11.0, 10.0, 7.0, 10.0, 6.0, 10.0, 8.0, 9.0, 11.0,
      11.0, 11.0, 8.0, 10.0, 8.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06450276122379747
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025295290620579898
    mean_inference_ms: 1.2087254745111913
    mean_raw_obs_processing_ms: 0.2747250732125506
time_since_restore: 3561.620714187622
time_this_iter_s: 10.087049961090088
time_total_s: 3561.620714187622
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997742
timesteps_total: 4354650
training_iteration: 351
trial_id: default
train step: 352
agent_timesteps_total: 4364850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024710416793823242
  StateBufferConnector_ms: 0.004474639892578125
  ViewRequirementAgentConnector_ms: 0.1600806713104248
counters:
  num_agent_steps_sampled: 4364850
  num_agent_steps_trained: 4348000
  num_env_steps_sampled: 4364850
  num_env_steps_trained: 4348000
  num_samples_added_to_queue: 4364500
  num_training_step_calls_since_last_synch_worker_weights: 1240
  num_weight_broadcasts: 85809
custom_metrics: {}
date: 2023-08-14_16-22-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.41
episode_reward_min: 4.0
episodes_this_iter: 80
episodes_total: 34101
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6450024247169495
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -26.601787567138672
        total_loss: 2.1484506130218506
        var_gnorm: 64.90597534179688
        vf_explained_var: 0.9065991640090942
        vf_loss: 63.95050048828125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8696.0
  learner_queue:
    size_count: 8700
    size_mean: 15.12
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4918444959177213
  num_agent_steps_sampled: 4364850
  num_agent_steps_trained: 4348000
  num_env_steps_sampled: 4364850
  num_env_steps_trained: 4348000
  num_samples_added_to_queue: 4364500
  num_training_step_calls_since_last_synch_worker_weights: 1240
  num_weight_broadcasts: 85809
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 325.446
    learner_load_time_ms: 1.5
    learner_load_wait_time_ms: 1.915
iterations_since_restore: 352
node_ip: 127.0.0.1
num_agent_steps_sampled: 4364850
num_agent_steps_trained: 4348000
num_env_steps_sampled: 4364850
num_env_steps_sampled_this_iter: 10200
num_env_steps_sampled_throughput_per_sec: 1019.9985651990092
num_env_steps_trained: 4348000
num_env_steps_trained_this_iter: 10000
num_env_steps_trained_throughput_per_sec: 999.998593332362
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10000
perf:
  cpu_util_percent: 65.28666666666666
  ram_util_percent: 77.84666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06457652134931834
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02530712845077819
  mean_inference_ms: 1.2090884648735547
  mean_raw_obs_processing_ms: 0.2748414889550191
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024710416793823242
    StateBufferConnector_ms: 0.004474639892578125
    ViewRequirementAgentConnector_ms: 0.1600806713104248
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.41
  episode_reward_min: 4.0
  episodes_this_iter: 80
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 9.0, 7.0, 9.0, 6.0, 11.0, 10.0, 7.0, 10.0, 6.0, 10.0, 8.0,
      9.0, 11.0, 11.0, 11.0, 8.0, 10.0, 8.0, 10.0, 9.0, 9.0, 10.0, 9.0, 8.0, 12.0,
      9.0, 5.0, 14.0, 8.0, 11.0, 15.0, 7.0, 9.0, 13.0, 6.0, 11.0, 11.0, 8.0, 12.0,
      10.0, 10.0, 13.0, 9.0, 10.0, 8.0, 9.0, 11.0, 11.0, 7.0, 7.0, 7.0, 5.0, 7.0,
      13.0, 12.0, 8.0, 7.0, 9.0, 10.0, 12.0, 6.0, 10.0, 13.0, 8.0, 12.0, 14.0, 9.0,
      13.0, 4.0, 13.0, 8.0, 12.0, 6.0, 13.0, 11.0, 11.0, 10.0, 12.0, 9.0, 14.0, 6.0,
      10.0, 7.0, 5.0, 7.0, 5.0, 6.0, 10.0, 8.0, 10.0, 7.0, 8.0, 7.0, 9.0, 11.0, 12.0,
      15.0, 12.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06457652134931834
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02530712845077819
    mean_inference_ms: 1.2090884648735547
    mean_raw_obs_processing_ms: 0.2748414889550191
time_since_restore: 3571.742664337158
time_this_iter_s: 10.121950149536133
time_total_s: 3571.742664337158
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997753
timesteps_total: 4364850
training_iteration: 352
trial_id: default
train step: 353
agent_timesteps_total: 4375650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.026057958602905273
  StateBufferConnector_ms: 0.004823446273803711
  ViewRequirementAgentConnector_ms: 0.14783811569213867
counters:
  num_agent_steps_sampled: 4375650
  num_agent_steps_trained: 4359000
  num_env_steps_sampled: 4375650
  num_env_steps_trained: 4359000
  num_samples_added_to_queue: 4375500
  num_training_step_calls_since_last_synch_worker_weights: 318
  num_weight_broadcasts: 86022
custom_metrics: {}
date: 2023-08-14_16-22-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.99
episode_reward_min: 2.0
episodes_this_iter: 84
episodes_total: 34185
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5880850553512573
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 6.917385101318359
        total_loss: 42.98766326904297
        var_gnorm: 64.90618133544922
        vf_explained_var: 0.9155914187431335
        vf_loss: 78.02140808105469
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8718.0
  learner_queue:
    size_count: 8724
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2237646832622684
  num_agent_steps_sampled: 4375650
  num_agent_steps_trained: 4359000
  num_env_steps_sampled: 4375650
  num_env_steps_trained: 4359000
  num_samples_added_to_queue: 4375500
  num_training_step_calls_since_last_synch_worker_weights: 318
  num_weight_broadcasts: 86022
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 219.98
    learner_load_time_ms: 1.543
    learner_load_wait_time_ms: 1.572
iterations_since_restore: 353
node_ip: 127.0.0.1
num_agent_steps_sampled: 4375650
num_agent_steps_trained: 4359000
num_env_steps_sampled: 4375650
num_env_steps_sampled_this_iter: 10800
num_env_steps_sampled_throughput_per_sec: 1079.9955711546363
num_env_steps_trained: 4359000
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9954891389816
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 63.78571428571428
  ram_util_percent: 78.32142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06459419806406305
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02532049589851618
  mean_inference_ms: 1.209615033526091
  mean_raw_obs_processing_ms: 0.27494320256630916
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.026057958602905273
    StateBufferConnector_ms: 0.004823446273803711
    ViewRequirementAgentConnector_ms: 0.14783811569213867
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.99
  episode_reward_min: 2.0
  episodes_this_iter: 84
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 7.0, 5.0, 6.0, 10.0, 8.0, 10.0, 7.0, 8.0, 7.0, 9.0, 11.0,
      12.0, 15.0, 12.0, 7.0, 6.0, 6.0, 11.0, 7.0, 12.0, 8.0, 14.0, 8.0, 8.0, 8.0,
      11.0, 8.0, 10.0, 8.0, 11.0, 8.0, 12.0, 13.0, 9.0, 11.0, 10.0, 5.0, 9.0, 10.0,
      8.0, 10.0, 2.0, 6.0, 11.0, 6.0, 6.0, 8.0, 11.0, 3.0, 9.0, 8.0, 9.0, 10.0, 6.0,
      7.0, 13.0, 5.0, 9.0, 8.0, 14.0, 13.0, 12.0, 9.0, 9.0, 9.0, 7.0, 7.0, 6.0, 12.0,
      11.0, 9.0, 13.0, 9.0, 7.0, 8.0, 13.0, 16.0, 6.0, 14.0, 7.0, 13.0, 8.0, 9.0,
      8.0, 6.0, 9.0, 13.0, 9.0, 12.0, 7.0, 8.0, 9.0, 8.0, 6.0, 9.0, 10.0, 11.0, 5.0,
      11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06459419806406305
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02532049589851618
    mean_inference_ms: 1.209615033526091
    mean_raw_obs_processing_ms: 0.27494320256630916
time_since_restore: 3581.903795480728
time_this_iter_s: 10.161131143569946
time_total_s: 3581.903795480728
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997763
timesteps_total: 4375650
training_iteration: 353
trial_id: default
train step: 354
agent_timesteps_total: 4388200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020535945892333984
  StateBufferConnector_ms: 0.003947257995605469
  ViewRequirementAgentConnector_ms: 0.12461304664611816
counters:
  num_agent_steps_sampled: 4388200
  num_agent_steps_trained: 4371500
  num_env_steps_sampled: 4388200
  num_env_steps_trained: 4371500
  num_samples_added_to_queue: 4388000
  num_training_step_calls_since_last_synch_worker_weights: 573
  num_weight_broadcasts: 86270
custom_metrics: {}
date: 2023-08-14_16-22-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 20.0
episode_reward_mean: 9.07
episode_reward_min: 3.0
episodes_this_iter: 98
episodes_total: 34283
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6964231729507446
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 17.583885192871094
        total_loss: 57.14775848388672
        var_gnorm: 64.9061050415039
        vf_explained_var: 0.8541331887245178
        vf_loss: 86.09197998046875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8743.0
  learner_queue:
    size_count: 8749
    size_mean: 15.02
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.593612248948909
  num_agent_steps_sampled: 4388200
  num_agent_steps_trained: 4371500
  num_env_steps_sampled: 4388200
  num_env_steps_trained: 4371500
  num_samples_added_to_queue: 4388000
  num_training_step_calls_since_last_synch_worker_weights: 573
  num_weight_broadcasts: 86270
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 204.392
    learner_load_time_ms: 1.525
    learner_load_wait_time_ms: 1.576
iterations_since_restore: 354
node_ip: 127.0.0.1
num_agent_steps_sampled: 4388200
num_agent_steps_trained: 4371500
num_env_steps_sampled: 4388200
num_env_steps_sampled_this_iter: 12550
num_env_steps_sampled_throughput_per_sec: 1254.99395587971
num_env_steps_trained: 4371500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9939799598706
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.48571428571429
  ram_util_percent: 77.69285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06456048710818964
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025321195597231956
  mean_inference_ms: 1.2097404380303758
  mean_raw_obs_processing_ms: 0.27492694533077533
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020535945892333984
    StateBufferConnector_ms: 0.003947257995605469
    ViewRequirementAgentConnector_ms: 0.12461304664611816
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 20.0
  episode_reward_mean: 9.07
  episode_reward_min: 3.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 11.0, 5.0, 7.0, 8.0, 6.0, 10.0, 8.0, 8.0, 9.0, 10.0, 13.0,
      5.0, 5.0, 5.0, 8.0, 6.0, 11.0, 8.0, 5.0, 9.0, 3.0, 12.0, 8.0, 9.0, 11.0, 10.0,
      10.0, 9.0, 8.0, 10.0, 13.0, 9.0, 9.0, 9.0, 11.0, 7.0, 8.0, 7.0, 6.0, 9.0, 10.0,
      5.0, 10.0, 8.0, 11.0, 11.0, 20.0, 11.0, 8.0, 13.0, 10.0, 10.0, 5.0, 9.0, 6.0,
      11.0, 7.0, 10.0, 9.0, 14.0, 5.0, 9.0, 6.0, 9.0, 6.0, 5.0, 13.0, 11.0, 8.0, 8.0,
      8.0, 11.0, 10.0, 14.0, 9.0, 9.0, 13.0, 13.0, 9.0, 16.0, 7.0, 7.0, 11.0, 11.0,
      9.0, 11.0, 9.0, 17.0, 11.0, 8.0, 5.0, 12.0, 11.0, 8.0, 7.0, 9.0, 10.0, 6.0,
      8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06456048710818964
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025321195597231956
    mean_inference_ms: 1.2097404380303758
    mean_raw_obs_processing_ms: 0.27492694533077533
time_since_restore: 3592.0354464054108
time_this_iter_s: 10.131650924682617
time_total_s: 3592.0354464054108
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997773
timesteps_total: 4388200
training_iteration: 354
trial_id: default
train step: 355
agent_timesteps_total: 4401800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018761517866602483
  StateBufferConnector_ms: 0.0033736228942871094
  ViewRequirementAgentConnector_ms: 0.11509904321634544
counters:
  num_agent_steps_sampled: 4401800
  num_agent_steps_trained: 4385000
  num_env_steps_sampled: 4401800
  num_env_steps_trained: 4385000
  num_samples_added_to_queue: 4401500
  num_training_step_calls_since_last_synch_worker_weights: 626
  num_weight_broadcasts: 86539
custom_metrics: {}
date: 2023-08-14_16-23-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.858490566037736
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 34389
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7408499717712402
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -4.744498252868652
        total_loss: 30.513866424560547
        var_gnorm: 64.90208435058594
        vf_explained_var: 0.8881796002388
        vf_loss: 77.92523193359375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8770.0
  learner_queue:
    size_count: 8776
    size_mean: 15.2
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4422205101855956
  num_agent_steps_sampled: 4401800
  num_agent_steps_trained: 4385000
  num_env_steps_sampled: 4401800
  num_env_steps_trained: 4385000
  num_samples_added_to_queue: 4401500
  num_training_step_calls_since_last_synch_worker_weights: 626
  num_weight_broadcasts: 86539
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 186.323
    learner_load_time_ms: 1.802
    learner_load_wait_time_ms: 1.565
iterations_since_restore: 355
node_ip: 127.0.0.1
num_agent_steps_sampled: 4401800
num_agent_steps_trained: 4385000
num_env_steps_sampled: 4401800
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9934826209544
num_env_steps_trained: 4385000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9935305428592
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.56428571428571
  ram_util_percent: 76.16428571428573
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0645371100810638
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025312476400202375
  mean_inference_ms: 1.209417540111453
  mean_raw_obs_processing_ms: 0.2748490042524764
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018761517866602483
    StateBufferConnector_ms: 0.0033736228942871094
    ViewRequirementAgentConnector_ms: 0.11509904321634544
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.858490566037736
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 14.0, 7.0, 11.0, 15.0, 10.0, 10.0, 15.0, 9.0, 11.0, 10.0,
      11.0, 13.0, 12.0, 15.0, 10.0, 13.0, 7.0, 6.0, 14.0, 9.0, 14.0, 11.0, 14.0, 13.0,
      7.0, 12.0, 10.0, 7.0, 12.0, 6.0, 7.0, 12.0, 15.0, 15.0, 7.0, 9.0, 11.0, 9.0,
      11.0, 11.0, 15.0, 7.0, 7.0, 8.0, 8.0, 8.0, 5.0, 11.0, 7.0, 5.0, 8.0, 15.0, 9.0,
      8.0, 13.0, 11.0, 7.0, 12.0, 3.0, 15.0, 8.0, 11.0, 9.0, 11.0, 8.0, 14.0, 9.0,
      8.0, 5.0, 6.0, 9.0, 14.0, 7.0, 8.0, 6.0, 12.0, 10.0, 10.0, 6.0, 10.0, 11.0,
      7.0, 10.0, 10.0, 7.0, 8.0, 12.0, 11.0, 9.0, 9.0, 9.0, 6.0, 12.0, 11.0, 7.0,
      6.0, 12.0, 9.0, 12.0, 12.0, 10.0, 7.0, 8.0, 13.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0645371100810638
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025312476400202375
    mean_inference_ms: 1.209417540111453
    mean_raw_obs_processing_ms: 0.2748490042524764
time_since_restore: 3602.167920589447
time_this_iter_s: 10.132474184036255
time_total_s: 3602.167920589447
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.057
timestamp: 1691997783
timesteps_total: 4401800
training_iteration: 355
trial_id: default
train step: 356
agent_timesteps_total: 4414700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020291309545535853
  StateBufferConnector_ms: 0.0036407225202805924
  ViewRequirementAgentConnector_ms: 0.12081259548073948
counters:
  num_agent_steps_sampled: 4414700
  num_agent_steps_trained: 4398000
  num_env_steps_sampled: 4414700
  num_env_steps_trained: 4398000
  num_samples_added_to_queue: 4414500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 86793
custom_metrics: {}
date: 2023-08-14_16-23-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.603960396039604
episode_reward_min: 4.0
episodes_this_iter: 101
episodes_total: 34490
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7720186710357666
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.888492584228516
        total_loss: 54.89560317993164
        var_gnorm: 64.9053726196289
        vf_explained_var: 0.8520686030387878
        vf_loss: 139.2883758544922
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8796.0
  learner_queue:
    size_count: 8803
    size_mean: 15.16
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.616910634512619
  num_agent_steps_sampled: 4414700
  num_agent_steps_trained: 4398000
  num_env_steps_sampled: 4414700
  num_env_steps_trained: 4398000
  num_samples_added_to_queue: 4414500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 86793
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 147.643
    learner_load_time_ms: 1.798
    learner_load_wait_time_ms: 1.576
iterations_since_restore: 356
node_ip: 127.0.0.1
num_agent_steps_sampled: 4414700
num_agent_steps_trained: 4398000
num_env_steps_sampled: 4414700
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.8900874335172
num_env_steps_trained: 4398000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.8892353981182
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.99333333333334
  ram_util_percent: 76.6
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0645268108775219
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02530986475902142
  mean_inference_ms: 1.2092889178923523
  mean_raw_obs_processing_ms: 0.27482136549208214
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020291309545535853
    StateBufferConnector_ms: 0.0036407225202805924
    ViewRequirementAgentConnector_ms: 0.12081259548073948
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.603960396039604
  episode_reward_min: 4.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 13.0, 11.0, 6.0, 13.0, 7.0, 6.0, 12.0, 13.0, 14.0, 8.0,
      9.0, 9.0, 7.0, 10.0, 11.0, 8.0, 6.0, 7.0, 7.0, 11.0, 12.0, 7.0, 5.0, 14.0, 10.0,
      7.0, 9.0, 13.0, 12.0, 7.0, 9.0, 9.0, 8.0, 10.0, 8.0, 13.0, 9.0, 6.0, 14.0, 5.0,
      9.0, 10.0, 11.0, 12.0, 10.0, 16.0, 4.0, 6.0, 11.0, 9.0, 12.0, 9.0, 13.0, 10.0,
      14.0, 9.0, 10.0, 7.0, 7.0, 10.0, 7.0, 9.0, 12.0, 10.0, 13.0, 10.0, 8.0, 5.0,
      6.0, 10.0, 9.0, 11.0, 4.0, 11.0, 15.0, 8.0, 10.0, 15.0, 10.0, 8.0, 13.0, 8.0,
      8.0, 10.0, 9.0, 11.0, 9.0, 10.0, 15.0, 10.0, 10.0, 8.0, 10.0, 9.0, 8.0, 11.0,
      11.0, 10.0, 11.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0645268108775219
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02530986475902142
    mean_inference_ms: 1.2092889178923523
    mean_raw_obs_processing_ms: 0.27482136549208214
time_since_restore: 3612.3193795681
time_this_iter_s: 10.151458978652954
time_total_s: 3612.3193795681
timers:
  sample_time_ms: 0.104
  synch_weights_time_ms: 0.527
  training_iteration_time_ms: 0.758
timestamp: 1691997793
timesteps_total: 4414700
training_iteration: 356
trial_id: default
train step: 357
agent_timesteps_total: 4427850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02020169230340754
  StateBufferConnector_ms: 0.00360475003140644
  ViewRequirementAgentConnector_ms: 0.12134695516049283
counters:
  num_agent_steps_sampled: 4427850
  num_agent_steps_trained: 4411000
  num_env_steps_sampled: 4427850
  num_env_steps_trained: 4411000
  num_samples_added_to_queue: 4427500
  num_training_step_calls_since_last_synch_worker_weights: 1894
  num_weight_broadcasts: 87053
custom_metrics: {}
date: 2023-08-14_16-23-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.54368932038835
episode_reward_min: 3.0
episodes_this_iter: 103
episodes_total: 34593
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8179393410682678
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 7.323448181152344
        total_loss: 44.213356018066406
        var_gnorm: 64.9065170288086
        vf_explained_var: 0.8948030471801758
        vf_loss: 81.9592056274414
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8822.0
  learner_queue:
    size_count: 8827
    size_mean: 15.16
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5793669617919708
  num_agent_steps_sampled: 4427850
  num_agent_steps_trained: 4411000
  num_env_steps_sampled: 4427850
  num_env_steps_trained: 4411000
  num_samples_added_to_queue: 4427500
  num_training_step_calls_since_last_synch_worker_weights: 1894
  num_weight_broadcasts: 87053
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 237.765
    learner_load_time_ms: 1.798
    learner_load_wait_time_ms: 1.681
iterations_since_restore: 357
node_ip: 127.0.0.1
num_agent_steps_sampled: 4427850
num_agent_steps_trained: 4411000
num_env_steps_sampled: 4427850
num_env_steps_sampled_this_iter: 13150
num_env_steps_sampled_throughput_per_sec: 1314.9919739259403
num_env_steps_trained: 4411000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.992065478116
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.83571428571428
  ram_util_percent: 77.2
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06451884335655779
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025304032963348645
  mean_inference_ms: 1.2090510208225773
  mean_raw_obs_processing_ms: 0.27477287945649315
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02020169230340754
    StateBufferConnector_ms: 0.00360475003140644
    ViewRequirementAgentConnector_ms: 0.12134695516049283
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.54368932038835
  episode_reward_min: 3.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 9.0, 8.0, 14.0, 9.0, 8.0, 7.0, 12.0, 8.0, 10.0, 15.0, 14.0,
      13.0, 7.0, 10.0, 3.0, 11.0, 8.0, 11.0, 10.0, 13.0, 10.0, 9.0, 10.0, 13.0, 11.0,
      14.0, 12.0, 6.0, 10.0, 5.0, 12.0, 8.0, 13.0, 10.0, 10.0, 3.0, 8.0, 6.0, 15.0,
      9.0, 4.0, 9.0, 11.0, 10.0, 10.0, 6.0, 15.0, 9.0, 11.0, 7.0, 14.0, 3.0, 11.0,
      5.0, 9.0, 12.0, 13.0, 8.0, 8.0, 8.0, 11.0, 11.0, 7.0, 4.0, 17.0, 18.0, 8.0,
      12.0, 12.0, 5.0, 11.0, 6.0, 9.0, 7.0, 7.0, 7.0, 8.0, 11.0, 12.0, 6.0, 12.0,
      9.0, 11.0, 9.0, 9.0, 13.0, 11.0, 8.0, 8.0, 6.0, 9.0, 14.0, 5.0, 7.0, 15.0, 9.0,
      13.0, 10.0, 10.0, 8.0, 6.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06451884335655779
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025304032963348645
    mean_inference_ms: 1.2090510208225773
    mean_raw_obs_processing_ms: 0.27477287945649315
time_since_restore: 3622.43146443367
time_this_iter_s: 10.112084865570068
time_total_s: 3622.43146443367
timers:
  sample_time_ms: 0.022
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.055
timestamp: 1691997803
timesteps_total: 4427850
training_iteration: 357
trial_id: default
train step: 358
agent_timesteps_total: 4441150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019248403035677396
  StateBufferConnector_ms: 0.003418555626502404
  ViewRequirementAgentConnector_ms: 0.11685582307668832
counters:
  num_agent_steps_sampled: 4441150
  num_agent_steps_trained: 4424500
  num_env_steps_sampled: 4441150
  num_env_steps_trained: 4424500
  num_samples_added_to_queue: 4441000
  num_training_step_calls_since_last_synch_worker_weights: 159
  num_weight_broadcasts: 87312
custom_metrics: {}
date: 2023-08-14_16-23-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.836538461538462
episode_reward_min: 4.0
episodes_this_iter: 104
episodes_total: 34697
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7979277968406677
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -72.17056274414062
        total_loss: -29.378570556640625
        var_gnorm: 64.90951538085938
        vf_explained_var: 0.8671661019325256
        vf_loss: 93.56326293945312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8849.0
  learner_queue:
    size_count: 8855
    size_mean: 15.42
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.218031198286809
  num_agent_steps_sampled: 4441150
  num_agent_steps_trained: 4424500
  num_env_steps_sampled: 4441150
  num_env_steps_trained: 4424500
  num_samples_added_to_queue: 4441000
  num_training_step_calls_since_last_synch_worker_weights: 159
  num_weight_broadcasts: 87312
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 173.593
    learner_load_time_ms: 1.677
    learner_load_wait_time_ms: 1.451
iterations_since_restore: 358
node_ip: 127.0.0.1
num_agent_steps_sampled: 4441150
num_agent_steps_trained: 4424500
num_env_steps_sampled: 4441150
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9947045060242
num_env_steps_trained: 4424500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9946248745357
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.99285714285714
  ram_util_percent: 77.7357142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06450231669702824
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02529908417105276
  mean_inference_ms: 1.2088169450227677
  mean_raw_obs_processing_ms: 0.2747149495238842
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019248403035677396
    StateBufferConnector_ms: 0.003418555626502404
    ViewRequirementAgentConnector_ms: 0.11685582307668832
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.836538461538462
  episode_reward_min: 4.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 5.0, 8.0, 14.0, 6.0, 7.0, 7.0, 15.0, 9.0, 9.0, 5.0, 8.0,
      5.0, 12.0, 9.0, 11.0, 5.0, 5.0, 7.0, 14.0, 10.0, 11.0, 10.0, 4.0, 7.0, 9.0,
      10.0, 11.0, 7.0, 11.0, 10.0, 6.0, 14.0, 10.0, 10.0, 10.0, 8.0, 13.0, 8.0, 7.0,
      9.0, 17.0, 8.0, 7.0, 6.0, 13.0, 10.0, 7.0, 5.0, 7.0, 9.0, 11.0, 8.0, 7.0, 11.0,
      7.0, 4.0, 8.0, 6.0, 10.0, 9.0, 8.0, 7.0, 17.0, 7.0, 5.0, 9.0, 8.0, 7.0, 8.0,
      7.0, 6.0, 10.0, 6.0, 8.0, 9.0, 8.0, 10.0, 10.0, 12.0, 4.0, 12.0, 9.0, 13.0,
      5.0, 11.0, 10.0, 14.0, 5.0, 8.0, 10.0, 8.0, 9.0, 12.0, 11.0, 8.0, 7.0, 9.0,
      12.0, 10.0, 7.0, 9.0, 7.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06450231669702824
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02529908417105276
    mean_inference_ms: 1.2088169450227677
    mean_raw_obs_processing_ms: 0.2747149495238842
time_since_restore: 3632.5814714431763
time_this_iter_s: 10.150007009506226
time_total_s: 3632.5814714431763
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997813
timesteps_total: 4441150
training_iteration: 358
trial_id: default
train step: 359
agent_timesteps_total: 4454450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01923212638268104
  StateBufferConnector_ms: 0.003426350080049955
  ViewRequirementAgentConnector_ms: 0.1171343601666964
counters:
  num_agent_steps_sampled: 4454450
  num_agent_steps_trained: 4437500
  num_env_steps_sampled: 4454450
  num_env_steps_trained: 4437500
  num_samples_added_to_queue: 4454000
  num_training_step_calls_since_last_synch_worker_weights: 537
  num_weight_broadcasts: 87575
custom_metrics: {}
date: 2023-08-14_16-23-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 9.26923076923077
episode_reward_min: 5.0
episodes_this_iter: 104
episodes_total: 34801
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7566308975219727
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -38.02937316894531
        total_loss: 11.606074333190918
        var_gnorm: 64.90796661376953
        vf_explained_var: 0.8401004672050476
        vf_loss: 106.83720397949219
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8875.0
  learner_queue:
    size_count: 8881
    size_mean: 15.16
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5538339679644027
  num_agent_steps_sampled: 4454450
  num_agent_steps_trained: 4437500
  num_env_steps_sampled: 4454450
  num_env_steps_trained: 4437500
  num_samples_added_to_queue: 4454000
  num_training_step_calls_since_last_synch_worker_weights: 537
  num_weight_broadcasts: 87575
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 197.883
    learner_load_time_ms: 1.638
    learner_load_wait_time_ms: 1.533
iterations_since_restore: 359
node_ip: 127.0.0.1
num_agent_steps_sampled: 4454450
num_agent_steps_trained: 4437500
num_env_steps_sampled: 4454450
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9937215147768
num_env_steps_trained: 4437500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.993863134744
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.27333333333333
  ram_util_percent: 77.20666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06448881948618618
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025292744412109318
  mean_inference_ms: 1.2085676592002956
  mean_raw_obs_processing_ms: 0.2746613745911508
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01923212638268104
    StateBufferConnector_ms: 0.003426350080049955
    ViewRequirementAgentConnector_ms: 0.1171343601666964
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 9.26923076923077
  episode_reward_min: 5.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 5.0, 13.0, 10.0, 10.0, 9.0, 12.0, 6.0, 7.0, 11.0, 10.0,
      11.0, 11.0, 9.0, 11.0, 12.0, 10.0, 5.0, 12.0, 6.0, 6.0, 12.0, 8.0, 5.0, 6.0,
      9.0, 8.0, 7.0, 8.0, 6.0, 9.0, 8.0, 7.0, 7.0, 8.0, 13.0, 12.0, 8.0, 8.0, 6.0,
      13.0, 9.0, 10.0, 11.0, 11.0, 9.0, 9.0, 7.0, 11.0, 9.0, 6.0, 8.0, 12.0, 13.0,
      6.0, 13.0, 7.0, 12.0, 9.0, 9.0, 11.0, 8.0, 7.0, 13.0, 12.0, 9.0, 7.0, 8.0, 8.0,
      8.0, 9.0, 9.0, 10.0, 13.0, 12.0, 13.0, 10.0, 10.0, 10.0, 5.0, 10.0, 5.0, 9.0,
      7.0, 13.0, 7.0, 12.0, 9.0, 7.0, 12.0, 9.0, 7.0, 9.0, 12.0, 7.0, 9.0, 14.0, 14.0,
      11.0, 12.0, 8.0, 7.0, 10.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06448881948618618
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025292744412109318
    mean_inference_ms: 1.2085676592002956
    mean_raw_obs_processing_ms: 0.2746613745911508
time_since_restore: 3642.712307691574
time_this_iter_s: 10.130836248397827
time_total_s: 3642.712307691574
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997824
timesteps_total: 4454450
training_iteration: 359
trial_id: default
train step: 360
agent_timesteps_total: 4467950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019391977562094636
  StateBufferConnector_ms: 0.0034930571070257224
  ViewRequirementAgentConnector_ms: 0.11579877925368975
counters:
  num_agent_steps_sampled: 4467950
  num_agent_steps_trained: 4451000
  num_env_steps_sampled: 4467950
  num_env_steps_trained: 4451000
  num_samples_added_to_queue: 4467500
  num_training_step_calls_since_last_synch_worker_weights: 749
  num_weight_broadcasts: 87841
custom_metrics: {}
date: 2023-08-14_16-23-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.330188679245284
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 34907
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6291846632957458
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.8190228939056396
        total_loss: 19.70048713684082
        var_gnorm: 64.90975189208984
        vf_explained_var: 0.9365404844284058
        vf_loss: 47.330867767333984
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8902.0
  learner_queue:
    size_count: 8907
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2745195173083854
  num_agent_steps_sampled: 4467950
  num_agent_steps_trained: 4451000
  num_env_steps_sampled: 4467950
  num_env_steps_trained: 4451000
  num_samples_added_to_queue: 4467500
  num_training_step_calls_since_last_synch_worker_weights: 749
  num_weight_broadcasts: 87841
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 230.644
    learner_load_time_ms: 1.647
    learner_load_wait_time_ms: 1.487
iterations_since_restore: 360
node_ip: 127.0.0.1
num_agent_steps_sampled: 4467950
num_agent_steps_trained: 4451000
num_env_steps_sampled: 4467950
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9938202187184
num_env_steps_trained: 4451000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9938202187184
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.535714285714285
  ram_util_percent: 77.02142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06447249143744013
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02528476286424838
  mean_inference_ms: 1.2082651703140987
  mean_raw_obs_processing_ms: 0.2745913962567712
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019391977562094636
    StateBufferConnector_ms: 0.0034930571070257224
    ViewRequirementAgentConnector_ms: 0.11579877925368975
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.330188679245284
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 14.0, 7.0, 11.0, 12.0, 10.0, 6.0, 11.0, 8.0, 10.0,
      12.0, 5.0, 9.0, 11.0, 7.0, 8.0, 3.0, 7.0, 9.0, 14.0, 13.0, 9.0, 9.0, 7.0, 8.0,
      7.0, 5.0, 14.0, 9.0, 11.0, 13.0, 6.0, 15.0, 18.0, 14.0, 9.0, 12.0, 7.0, 10.0,
      12.0, 8.0, 12.0, 10.0, 7.0, 10.0, 8.0, 8.0, 13.0, 12.0, 9.0, 4.0, 6.0, 8.0,
      14.0, 8.0, 8.0, 10.0, 9.0, 8.0, 5.0, 8.0, 13.0, 9.0, 9.0, 8.0, 8.0, 11.0, 5.0,
      13.0, 4.0, 14.0, 9.0, 9.0, 12.0, 13.0, 7.0, 12.0, 10.0, 11.0, 7.0, 8.0, 11.0,
      11.0, 11.0, 10.0, 12.0, 5.0, 8.0, 10.0, 7.0, 10.0, 7.0, 11.0, 9.0, 7.0, 10.0,
      10.0, 4.0, 8.0, 10.0, 8.0, 6.0, 10.0, 7.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06447249143744013
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02528476286424838
    mean_inference_ms: 1.2082651703140987
    mean_raw_obs_processing_ms: 0.2745913962567712
time_since_restore: 3652.827791929245
time_this_iter_s: 10.115484237670898
time_total_s: 3652.827791929245
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691997834
timesteps_total: 4467950
training_iteration: 360
trial_id: default
train step: 361
agent_timesteps_total: 4481650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0185705580801334
  StateBufferConnector_ms: 0.0032755563843925046
  ViewRequirementAgentConnector_ms: 0.1133682592859808
counters:
  num_agent_steps_sampled: 4481650
  num_agent_steps_trained: 4465000
  num_env_steps_sampled: 4481650
  num_env_steps_trained: 4465000
  num_samples_added_to_queue: 4481500
  num_training_step_calls_since_last_synch_worker_weights: 1188
  num_weight_broadcasts: 88107
custom_metrics: {}
date: 2023-08-14_16-24-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.70754716981132
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 35013
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.648306667804718
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -61.237674713134766
        total_loss: 13.290643692016602
        var_gnorm: 64.9189453125
        vf_explained_var: 0.7755691409111023
        vf_loss: 155.53970336914062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8930.0
  learner_queue:
    size_count: 8934
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9591663046625439
  num_agent_steps_sampled: 4481650
  num_agent_steps_trained: 4465000
  num_env_steps_sampled: 4481650
  num_env_steps_trained: 4465000
  num_samples_added_to_queue: 4481500
  num_training_step_calls_since_last_synch_worker_weights: 1188
  num_weight_broadcasts: 88107
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 241.063
    learner_load_time_ms: 1.363
    learner_load_wait_time_ms: 1.568
iterations_since_restore: 361
node_ip: 127.0.0.1
num_agent_steps_sampled: 4481650
num_agent_steps_trained: 4465000
num_env_steps_sampled: 4481650
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.996178399256
num_env_steps_trained: 4465000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.996094714568
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.51428571428571
  ram_util_percent: 76.72142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06445236257019189
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025274976698322783
  mean_inference_ms: 1.2079027587673856
  mean_raw_obs_processing_ms: 0.2745088124431434
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0185705580801334
    StateBufferConnector_ms: 0.0032755563843925046
    ViewRequirementAgentConnector_ms: 0.1133682592859808
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.70754716981132
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 10.0, 13.0, 7.0, 5.0, 9.0, 7.0, 7.0, 9.0, 11.0, 7.0, 11.0,
      12.0, 11.0, 7.0, 10.0, 5.0, 13.0, 10.0, 10.0, 11.0, 6.0, 11.0, 13.0, 8.0, 8.0,
      11.0, 9.0, 9.0, 11.0, 13.0, 12.0, 9.0, 10.0, 8.0, 10.0, 11.0, 8.0, 10.0, 5.0,
      12.0, 7.0, 10.0, 8.0, 7.0, 10.0, 9.0, 8.0, 13.0, 11.0, 11.0, 9.0, 13.0, 11.0,
      10.0, 15.0, 7.0, 11.0, 10.0, 12.0, 9.0, 11.0, 6.0, 10.0, 9.0, 11.0, 9.0, 16.0,
      12.0, 7.0, 10.0, 3.0, 10.0, 6.0, 11.0, 15.0, 11.0, 9.0, 11.0, 9.0, 9.0, 12.0,
      10.0, 6.0, 7.0, 8.0, 10.0, 8.0, 11.0, 13.0, 11.0, 7.0, 11.0, 14.0, 13.0, 12.0,
      9.0, 6.0, 11.0, 6.0, 8.0, 12.0, 10.0, 10.0, 9.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06445236257019189
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025274976698322783
    mean_inference_ms: 1.2079027587673856
    mean_raw_obs_processing_ms: 0.2745088124431434
time_since_restore: 3662.9186160564423
time_this_iter_s: 10.090824127197266
time_total_s: 3662.9186160564423
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997844
timesteps_total: 4481650
training_iteration: 361
trial_id: default
train step: 362
agent_timesteps_total: 4494950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019557659442608174
  StateBufferConnector_ms: 0.0034334567876962516
  ViewRequirementAgentConnector_ms: 0.11814695138197678
counters:
  num_agent_steps_sampled: 4494950
  num_agent_steps_trained: 4478000
  num_env_steps_sampled: 4494950
  num_env_steps_trained: 4478000
  num_samples_added_to_queue: 4494500
  num_training_step_calls_since_last_synch_worker_weights: 1075
  num_weight_broadcasts: 88368
custom_metrics: {}
date: 2023-08-14_16-24-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.817307692307692
episode_reward_min: 4.0
episodes_this_iter: 104
episodes_total: 35117
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.709108829498291
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.273412704467773
        total_loss: 43.37971878051758
        var_gnorm: 64.91802978515625
        vf_explained_var: 0.8515787124633789
        vf_loss: 110.39734649658203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8956.0
  learner_queue:
    size_count: 8960
    size_mean: 15.72
    size_quantiles: [13.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.7493997598078078
  num_agent_steps_sampled: 4494950
  num_agent_steps_trained: 4478000
  num_env_steps_sampled: 4494950
  num_env_steps_trained: 4478000
  num_samples_added_to_queue: 4494500
  num_training_step_calls_since_last_synch_worker_weights: 1075
  num_weight_broadcasts: 88368
  timing_breakdown:
    learner_dequeue_time_ms: 0.017
    learner_grad_time_ms: 265.666
    learner_load_time_ms: 1.386
    learner_load_wait_time_ms: 1.679
iterations_since_restore: 362
node_ip: 127.0.0.1
num_agent_steps_sampled: 4494950
num_agent_steps_trained: 4478000
num_env_steps_sampled: 4494950
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9938800616537
num_env_steps_trained: 4478000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.994018105376
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.99285714285713
  ram_util_percent: 76.57857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06443851889522972
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025268070636980947
  mean_inference_ms: 1.207653816439115
  mean_raw_obs_processing_ms: 0.2744515806009967
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019557659442608174
    StateBufferConnector_ms: 0.0034334567876962516
    ViewRequirementAgentConnector_ms: 0.11814695138197678
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.817307692307692
  episode_reward_min: 4.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 10.0, 9.0, 11.0, 6.0, 14.0, 10.0, 9.0, 10.0, 6.0, 7.0, 10.0,
      11.0, 6.0, 15.0, 12.0, 10.0, 11.0, 10.0, 7.0, 12.0, 9.0, 13.0, 12.0, 4.0, 8.0,
      7.0, 9.0, 9.0, 7.0, 8.0, 9.0, 14.0, 7.0, 12.0, 8.0, 11.0, 8.0, 9.0, 10.0, 6.0,
      11.0, 11.0, 12.0, 11.0, 9.0, 11.0, 9.0, 11.0, 10.0, 12.0, 9.0, 12.0, 13.0, 10.0,
      12.0, 13.0, 17.0, 9.0, 10.0, 8.0, 12.0, 9.0, 10.0, 9.0, 10.0, 9.0, 5.0, 5.0,
      11.0, 8.0, 9.0, 13.0, 9.0, 8.0, 8.0, 8.0, 12.0, 13.0, 9.0, 13.0, 8.0, 8.0, 8.0,
      11.0, 11.0, 11.0, 11.0, 10.0, 14.0, 11.0, 12.0, 7.0, 8.0, 7.0, 10.0, 7.0, 9.0,
      10.0, 13.0, 11.0, 10.0, 8.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06443851889522972
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025268070636980947
    mean_inference_ms: 1.207653816439115
    mean_raw_obs_processing_ms: 0.2744515806009967
time_since_restore: 3673.016448020935
time_this_iter_s: 10.097831964492798
time_total_s: 3673.016448020935
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691997854
timesteps_total: 4494950
training_iteration: 362
trial_id: default
train step: 363
agent_timesteps_total: 4508450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01942099265332492
  StateBufferConnector_ms: 0.003440425081073113
  ViewRequirementAgentConnector_ms: 0.11599153842566148
counters:
  num_agent_steps_sampled: 4508450
  num_agent_steps_trained: 4491500
  num_env_steps_sampled: 4508450
  num_env_steps_trained: 4491500
  num_samples_added_to_queue: 4508000
  num_training_step_calls_since_last_synch_worker_weights: 1056
  num_weight_broadcasts: 88634
custom_metrics: {}
date: 2023-08-14_16-24-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.50943396226415
episode_reward_min: 5.0
episodes_this_iter: 106
episodes_total: 35223
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6842859983444214
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -35.42042541503906
        total_loss: 36.53334426879883
        var_gnorm: 64.91503143310547
        vf_explained_var: 0.8185008764266968
        vf_loss: 150.75039672851562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 8983.0
  learner_queue:
    size_count: 8987
    size_mean: 15.66
    size_quantiles: [13.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.8392854103342915
  num_agent_steps_sampled: 4508450
  num_agent_steps_trained: 4491500
  num_env_steps_sampled: 4508450
  num_env_steps_trained: 4491500
  num_samples_added_to_queue: 4508000
  num_training_step_calls_since_last_synch_worker_weights: 1056
  num_weight_broadcasts: 88634
  timing_breakdown:
    learner_dequeue_time_ms: 0.019
    learner_grad_time_ms: 261.843
    learner_load_time_ms: 1.391
    learner_load_wait_time_ms: 1.762
iterations_since_restore: 363
node_ip: 127.0.0.1
num_agent_steps_sampled: 4508450
num_agent_steps_trained: 4491500
num_env_steps_sampled: 4508450
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9949789233992
num_env_steps_trained: 4491500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9949789233992
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.046666666666674
  ram_util_percent: 75.37333333333332
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06442149790540003
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025259839578207443
  mean_inference_ms: 1.2073492824227037
  mean_raw_obs_processing_ms: 0.27438767075507003
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01942099265332492
    StateBufferConnector_ms: 0.003440425081073113
    ViewRequirementAgentConnector_ms: 0.11599153842566148
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.50943396226415
  episode_reward_min: 5.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 7.0, 7.0, 8.0, 9.0, 10.0, 11.0, 6.0, 9.0, 9.0, 13.0, 11.0,
      10.0, 7.0, 8.0, 11.0, 9.0, 9.0, 8.0, 9.0, 15.0, 9.0, 13.0, 8.0, 5.0, 7.0, 13.0,
      7.0, 9.0, 11.0, 9.0, 12.0, 13.0, 9.0, 12.0, 5.0, 7.0, 11.0, 9.0, 9.0, 11.0,
      10.0, 14.0, 16.0, 8.0, 6.0, 10.0, 10.0, 11.0, 9.0, 11.0, 11.0, 8.0, 7.0, 10.0,
      6.0, 9.0, 14.0, 13.0, 8.0, 6.0, 8.0, 10.0, 10.0, 7.0, 12.0, 8.0, 6.0, 11.0,
      8.0, 7.0, 11.0, 9.0, 9.0, 7.0, 8.0, 9.0, 13.0, 11.0, 9.0, 8.0, 9.0, 11.0, 12.0,
      10.0, 7.0, 9.0, 11.0, 8.0, 6.0, 8.0, 10.0, 12.0, 7.0, 6.0, 11.0, 14.0, 6.0,
      8.0, 13.0, 15.0, 12.0, 11.0, 10.0, 7.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06442149790540003
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025259839578207443
    mean_inference_ms: 1.2073492824227037
    mean_raw_obs_processing_ms: 0.27438767075507003
time_since_restore: 3683.1204359531403
time_this_iter_s: 10.1039879322052
time_total_s: 3683.1204359531403
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.042
timestamp: 1691997864
timesteps_total: 4508450
training_iteration: 363
trial_id: default
train step: 364
agent_timesteps_total: 4522050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01881887327949956
  StateBufferConnector_ms: 0.003356753655199735
  ViewRequirementAgentConnector_ms: 0.11490066096467792
counters:
  num_agent_steps_sampled: 4522050
  num_agent_steps_trained: 4505500
  num_env_steps_sampled: 4522050
  num_env_steps_trained: 4505500
  num_samples_added_to_queue: 4522000
  num_training_step_calls_since_last_synch_worker_weights: 1159
  num_weight_broadcasts: 88902
custom_metrics: {}
date: 2023-08-14_16-24-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.367924528301886
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 35329
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6480565667152405
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 68.32759857177734
        total_loss: 114.45201873779297
        var_gnorm: 64.9151611328125
        vf_explained_var: 0.8702529668807983
        vf_loss: 98.72940063476562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9011.0
  learner_queue:
    size_count: 9015
    size_mean: 15.62
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9141115905621151
  num_agent_steps_sampled: 4522050
  num_agent_steps_trained: 4505500
  num_env_steps_sampled: 4522050
  num_env_steps_trained: 4505500
  num_samples_added_to_queue: 4522000
  num_training_step_calls_since_last_synch_worker_weights: 1159
  num_weight_broadcasts: 88902
  timing_breakdown:
    learner_dequeue_time_ms: 0.017
    learner_grad_time_ms: 234.808
    learner_load_time_ms: 1.387
    learner_load_wait_time_ms: 1.596
iterations_since_restore: 364
node_ip: 127.0.0.1
num_agent_steps_sampled: 4522050
num_agent_steps_trained: 4505500
num_env_steps_sampled: 4522050
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9970169132816
num_env_steps_trained: 4505500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.996929175437
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.16428571428571
  ram_util_percent: 75.39999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06440328013133931
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02525081211750796
  mean_inference_ms: 1.2070138323088642
  mean_raw_obs_processing_ms: 0.2743153490189214
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01881887327949956
    StateBufferConnector_ms: 0.003356753655199735
    ViewRequirementAgentConnector_ms: 0.11490066096467792
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.367924528301886
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 13.0, 7.0, 10.0, 7.0, 11.0, 3.0, 6.0, 9.0, 8.0, 4.0, 5.0,
      6.0, 10.0, 8.0, 5.0, 16.0, 5.0, 14.0, 12.0, 7.0, 8.0, 11.0, 14.0, 13.0, 11.0,
      10.0, 17.0, 4.0, 14.0, 10.0, 11.0, 17.0, 8.0, 9.0, 10.0, 13.0, 6.0, 9.0, 10.0,
      9.0, 11.0, 9.0, 8.0, 12.0, 7.0, 7.0, 10.0, 9.0, 10.0, 8.0, 9.0, 12.0, 9.0, 11.0,
      9.0, 9.0, 6.0, 12.0, 8.0, 8.0, 7.0, 11.0, 10.0, 12.0, 7.0, 6.0, 10.0, 10.0,
      7.0, 12.0, 7.0, 7.0, 8.0, 11.0, 11.0, 9.0, 10.0, 10.0, 8.0, 8.0, 9.0, 11.0,
      11.0, 6.0, 8.0, 12.0, 8.0, 13.0, 8.0, 10.0, 11.0, 14.0, 10.0, 8.0, 11.0, 11.0,
      9.0, 8.0, 7.0, 10.0, 10.0, 5.0, 7.0, 12.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06440328013133931
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02525081211750796
    mean_inference_ms: 1.2070138323088642
    mean_raw_obs_processing_ms: 0.2743153490189214
time_since_restore: 3693.2082591056824
time_this_iter_s: 10.087823152542114
time_total_s: 3693.2082591056824
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691997874
timesteps_total: 4522050
training_iteration: 364
trial_id: default
train step: 365
agent_timesteps_total: 4535450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01929585750286396
  StateBufferConnector_ms: 0.003466927088223971
  ViewRequirementAgentConnector_ms: 0.11614904953883244
counters:
  num_agent_steps_sampled: 4535450
  num_agent_steps_trained: 4518500
  num_env_steps_sampled: 4535450
  num_env_steps_trained: 4518500
  num_samples_added_to_queue: 4535000
  num_training_step_calls_since_last_synch_worker_weights: 1249
  num_weight_broadcasts: 89162
custom_metrics: {}
date: 2023-08-14_16-24-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 20.0
episode_reward_mean: 9.509615384615385
episode_reward_min: 4.0
episodes_this_iter: 104
episodes_total: 35433
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6376214027404785
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 36.10710906982422
        total_loss: 112.09294128417969
        var_gnorm: 64.91898345947266
        vf_explained_var: 0.7998076677322388
        vf_loss: 158.34788513183594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9037.0
  learner_queue:
    size_count: 9041
    size_mean: 15.72
    size_quantiles: [13.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.7493997598078078
  num_agent_steps_sampled: 4535450
  num_agent_steps_trained: 4518500
  num_env_steps_sampled: 4535450
  num_env_steps_trained: 4518500
  num_samples_added_to_queue: 4535000
  num_training_step_calls_since_last_synch_worker_weights: 1249
  num_weight_broadcasts: 89162
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 269.416
    learner_load_time_ms: 1.381
    learner_load_wait_time_ms: 1.621
iterations_since_restore: 365
node_ip: 127.0.0.1
num_agent_steps_sampled: 4535450
num_agent_steps_trained: 4518500
num_env_steps_sampled: 4535450
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9966454589899
num_env_steps_trained: 4518500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9967455945423
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.17142857142858
  ram_util_percent: 75.50714285714285
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0643876000757356
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025243834787169423
  mean_inference_ms: 1.2067357509646812
  mean_raw_obs_processing_ms: 0.2742507423783506
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01929585750286396
    StateBufferConnector_ms: 0.003466927088223971
    ViewRequirementAgentConnector_ms: 0.11614904953883244
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 20.0
  episode_reward_mean: 9.509615384615385
  episode_reward_min: 4.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 11.0, 14.0, 11.0, 20.0, 10.0, 5.0, 14.0, 12.0, 14.0, 10.0,
      9.0, 11.0, 17.0, 11.0, 9.0, 6.0, 13.0, 11.0, 7.0, 10.0, 11.0, 7.0, 8.0, 11.0,
      7.0, 12.0, 9.0, 7.0, 8.0, 12.0, 8.0, 10.0, 14.0, 12.0, 8.0, 12.0, 5.0, 14.0,
      14.0, 8.0, 11.0, 14.0, 7.0, 9.0, 7.0, 10.0, 7.0, 10.0, 9.0, 14.0, 5.0, 12.0,
      14.0, 10.0, 10.0, 9.0, 10.0, 5.0, 13.0, 9.0, 11.0, 7.0, 6.0, 9.0, 8.0, 6.0,
      12.0, 8.0, 11.0, 7.0, 7.0, 11.0, 9.0, 6.0, 9.0, 7.0, 11.0, 10.0, 9.0, 6.0, 9.0,
      6.0, 9.0, 5.0, 9.0, 8.0, 7.0, 9.0, 6.0, 14.0, 9.0, 8.0, 9.0, 9.0, 4.0, 7.0,
      8.0, 12.0, 12.0, 4.0, 9.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0643876000757356
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025243834787169423
    mean_inference_ms: 1.2067357509646812
    mean_raw_obs_processing_ms: 0.2742507423783506
time_since_restore: 3703.295385122299
time_this_iter_s: 10.087126016616821
time_total_s: 3703.295385122299
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691997884
timesteps_total: 4535450
training_iteration: 365
trial_id: default
train step: 366
agent_timesteps_total: 4548550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01981744488466133
  StateBufferConnector_ms: 0.0034091542068037015
  ViewRequirementAgentConnector_ms: 0.11993241541593977
counters:
  num_agent_steps_sampled: 4548550
  num_agent_steps_trained: 4532000
  num_env_steps_sampled: 4548550
  num_env_steps_trained: 4532000
  num_samples_added_to_queue: 4548500
  num_training_step_calls_since_last_synch_worker_weights: 1351
  num_weight_broadcasts: 89418
custom_metrics: {}
date: 2023-08-14_16-24-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.116504854368932
episode_reward_min: 2.0
episodes_this_iter: 103
episodes_total: 35536
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6106887459754944
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -41.88079071044922
        total_loss: 22.398956298828125
        var_gnorm: 64.9234619140625
        vf_explained_var: 0.8440781831741333
        vf_loss: 134.6663818359375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9064.0
  learner_queue:
    size_count: 9069
    size_mean: 15.66
    size_quantiles: [12.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.8856635930193812
  num_agent_steps_sampled: 4548550
  num_agent_steps_trained: 4532000
  num_env_steps_sampled: 4548550
  num_env_steps_trained: 4532000
  num_samples_added_to_queue: 4548500
  num_training_step_calls_since_last_synch_worker_weights: 1351
  num_weight_broadcasts: 89418
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 224.453
    learner_load_time_ms: 1.368
    learner_load_wait_time_ms: 1.853
iterations_since_restore: 366
node_ip: 127.0.0.1
num_agent_steps_sampled: 4548550
num_agent_steps_trained: 4532000
num_env_steps_sampled: 4548550
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9977512398223
num_env_steps_trained: 4532000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9976825753893
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.08571428571428
  ram_util_percent: 75.97857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06437531447794077
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025239588736745016
  mean_inference_ms: 1.2065691716605567
  mean_raw_obs_processing_ms: 0.2742137020838985
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01981744488466133
    StateBufferConnector_ms: 0.0034091542068037015
    ViewRequirementAgentConnector_ms: 0.11993241541593977
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.116504854368932
  episode_reward_min: 2.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 5.0, 9.0, 15.0, 9.0, 10.0, 8.0, 7.0, 8.0, 10.0, 9.0, 11.0,
      10.0, 7.0, 14.0, 12.0, 9.0, 6.0, 5.0, 10.0, 8.0, 12.0, 13.0, 9.0, 8.0, 15.0,
      4.0, 9.0, 9.0, 12.0, 12.0, 8.0, 9.0, 9.0, 6.0, 10.0, 8.0, 6.0, 10.0, 8.0, 7.0,
      8.0, 11.0, 10.0, 9.0, 6.0, 14.0, 7.0, 8.0, 4.0, 7.0, 6.0, 6.0, 7.0, 8.0, 10.0,
      8.0, 11.0, 11.0, 2.0, 5.0, 11.0, 5.0, 12.0, 13.0, 9.0, 12.0, 8.0, 6.0, 11.0,
      5.0, 13.0, 12.0, 10.0, 6.0, 10.0, 11.0, 9.0, 10.0, 9.0, 9.0, 12.0, 9.0, 10.0,
      11.0, 9.0, 13.0, 9.0, 8.0, 4.0, 13.0, 11.0, 9.0, 10.0, 7.0, 9.0, 13.0, 13.0,
      8.0, 8.0, 12.0, 11.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06437531447794077
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025239588736745016
    mean_inference_ms: 1.2065691716605567
    mean_raw_obs_processing_ms: 0.2742137020838985
time_since_restore: 3713.4580023288727
time_this_iter_s: 10.162617206573486
time_total_s: 3713.4580023288727
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691997894
timesteps_total: 4548550
training_iteration: 366
trial_id: default
train step: 367
agent_timesteps_total: 4561450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01984114694123221
  StateBufferConnector_ms: 0.0035418142186533106
  ViewRequirementAgentConnector_ms: 0.12012566670332805
counters:
  num_agent_steps_sampled: 4561450
  num_agent_steps_trained: 4544500
  num_env_steps_sampled: 4561450
  num_env_steps_trained: 4544500
  num_samples_added_to_queue: 4561000
  num_training_step_calls_since_last_synch_worker_weights: 492
  num_weight_broadcasts: 89671
custom_metrics: {}
date: 2023-08-14_16-25-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 9.05940594059406
episode_reward_min: 1.0
episodes_this_iter: 101
episodes_total: 35637
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6462040543556213
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 31.186500549316406
        total_loss: 83.23350524902344
        var_gnorm: 64.92863464355469
        vf_explained_var: 0.872164249420166
        vf_loss: 110.55604553222656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9089.0
  learner_queue:
    size_count: 9095
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2631706139710503
  num_agent_steps_sampled: 4561450
  num_agent_steps_trained: 4544500
  num_env_steps_sampled: 4561450
  num_env_steps_trained: 4544500
  num_samples_added_to_queue: 4561000
  num_training_step_calls_since_last_synch_worker_weights: 492
  num_weight_broadcasts: 89671
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 204.955
    learner_load_time_ms: 1.501
    learner_load_wait_time_ms: 1.593
iterations_since_restore: 367
node_ip: 127.0.0.1
num_agent_steps_sampled: 4561450
num_agent_steps_trained: 4544500
num_env_steps_sampled: 4561450
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9932952275667
num_env_steps_trained: 4544500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9935031274872
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 54.41333333333334
  ram_util_percent: 77.56666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06437277805756698
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02523753672713282
  mean_inference_ms: 1.2064436930507612
  mean_raw_obs_processing_ms: 0.2741891747690617
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01984114694123221
    StateBufferConnector_ms: 0.0035418142186533106
    ViewRequirementAgentConnector_ms: 0.12012566670332805
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 9.05940594059406
  episode_reward_min: 1.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 11.0, 11.0, 7.0, 9.0, 5.0, 11.0, 9.0, 11.0, 8.0, 8.0, 12.0,
      4.0, 12.0, 14.0, 5.0, 9.0, 8.0, 8.0, 14.0, 9.0, 14.0, 8.0, 13.0, 6.0, 12.0,
      12.0, 6.0, 7.0, 11.0, 6.0, 11.0, 12.0, 8.0, 8.0, 10.0, 10.0, 9.0, 8.0, 10.0,
      13.0, 8.0, 7.0, 4.0, 10.0, 1.0, 10.0, 10.0, 13.0, 8.0, 9.0, 6.0, 7.0, 10.0,
      6.0, 10.0, 7.0, 9.0, 7.0, 8.0, 11.0, 9.0, 8.0, 8.0, 11.0, 13.0, 9.0, 7.0, 8.0,
      9.0, 11.0, 7.0, 9.0, 12.0, 6.0, 7.0, 12.0, 7.0, 13.0, 10.0, 8.0, 5.0, 8.0, 9.0,
      11.0, 5.0, 13.0, 6.0, 9.0, 13.0, 6.0, 10.0, 9.0, 5.0, 14.0, 8.0, 11.0, 12.0,
      12.0, 6.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06437277805756698
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02523753672713282
    mean_inference_ms: 1.2064436930507612
    mean_raw_obs_processing_ms: 0.2741891747690617
time_since_restore: 3723.629372358322
time_this_iter_s: 10.171370029449463
time_total_s: 3723.629372358322
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691997905
timesteps_total: 4561450
training_iteration: 367
trial_id: default
train step: 368
agent_timesteps_total: 4574250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019747018814086914
  StateBufferConnector_ms: 0.003659963607788086
  ViewRequirementAgentConnector_ms: 0.11977863311767578
counters:
  num_agent_steps_sampled: 4574250
  num_agent_steps_trained: 4557500
  num_env_steps_sampled: 4574250
  num_env_steps_trained: 4557500
  num_samples_added_to_queue: 4574000
  num_training_step_calls_since_last_synch_worker_weights: 807
  num_weight_broadcasts: 89919
custom_metrics: {}
date: 2023-08-14_16-25-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.47
episode_reward_min: 4.0
episodes_this_iter: 100
episodes_total: 35737
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6550495624542236
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.908849716186523
        total_loss: 37.27548599243164
        var_gnorm: 64.93006896972656
        vf_explained_var: 0.8610727190971375
        vf_loss: 120.91917419433594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9115.0
  learner_queue:
    size_count: 9120
    size_mean: 15.22
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4041367454774483
  num_agent_steps_sampled: 4574250
  num_agent_steps_trained: 4557500
  num_env_steps_sampled: 4574250
  num_env_steps_trained: 4557500
  num_samples_added_to_queue: 4574000
  num_training_step_calls_since_last_synch_worker_weights: 807
  num_weight_broadcasts: 89919
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 220.491
    learner_load_time_ms: 1.489
    learner_load_wait_time_ms: 1.525
iterations_since_restore: 368
node_ip: 127.0.0.1
num_agent_steps_sampled: 4574250
num_agent_steps_trained: 4557500
num_env_steps_sampled: 4574250
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9968261797446
num_env_steps_trained: 4557500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9967765888032
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.67142857142857
  ram_util_percent: 77.70714285714284
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06436291651852123
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025234680189229385
  mean_inference_ms: 1.2063663378138687
  mean_raw_obs_processing_ms: 0.27415780613806917
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019747018814086914
    StateBufferConnector_ms: 0.003659963607788086
    ViewRequirementAgentConnector_ms: 0.11977863311767578
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.47
  episode_reward_min: 4.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 11.0, 13.0, 12.0, 9.0, 12.0, 8.0, 11.0, 10.0, 10.0, 11.0,
      7.0, 7.0, 6.0, 9.0, 8.0, 10.0, 13.0, 13.0, 10.0, 6.0, 7.0, 11.0, 9.0, 9.0, 11.0,
      5.0, 9.0, 15.0, 9.0, 6.0, 7.0, 9.0, 14.0, 14.0, 9.0, 9.0, 11.0, 12.0, 11.0,
      8.0, 10.0, 9.0, 8.0, 11.0, 8.0, 7.0, 7.0, 9.0, 7.0, 7.0, 5.0, 8.0, 10.0, 11.0,
      6.0, 9.0, 11.0, 6.0, 11.0, 9.0, 11.0, 11.0, 7.0, 9.0, 12.0, 10.0, 11.0, 8.0,
      8.0, 13.0, 9.0, 13.0, 7.0, 9.0, 11.0, 9.0, 10.0, 13.0, 9.0, 12.0, 5.0, 7.0,
      4.0, 13.0, 11.0, 7.0, 17.0, 8.0, 5.0, 10.0, 10.0, 16.0, 8.0, 8.0, 14.0, 8.0,
      11.0, 9.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06436291651852123
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025234680189229385
    mean_inference_ms: 1.2063663378138687
    mean_raw_obs_processing_ms: 0.27415780613806917
time_since_restore: 3733.771235227585
time_this_iter_s: 10.141862869262695
time_total_s: 3733.771235227585
timers:
  sample_time_ms: 0.019
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.052
timestamp: 1691997915
timesteps_total: 4574250
training_iteration: 368
trial_id: default
train step: 369
agent_timesteps_total: 4587600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01954505076775184
  StateBufferConnector_ms: 0.003521259014423077
  ViewRequirementAgentConnector_ms: 0.117606153854957
counters:
  num_agent_steps_sampled: 4587600
  num_agent_steps_trained: 4571000
  num_env_steps_sampled: 4587600
  num_env_steps_trained: 4571000
  num_samples_added_to_queue: 4587500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 90180
custom_metrics: {}
date: 2023-08-14_16-25-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.701923076923077
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 35841
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6614387035369873
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -36.93791580200195
        total_loss: 11.269699096679688
        var_gnorm: 64.9273452758789
        vf_explained_var: 0.8614283800125122
        vf_loss: 103.02961730957031
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9142.0
  learner_queue:
    size_count: 9146
    size_mean: 15.42
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1151681487560519
  num_agent_steps_sampled: 4587600
  num_agent_steps_trained: 4571000
  num_env_steps_sampled: 4587600
  num_env_steps_trained: 4571000
  num_samples_added_to_queue: 4587500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 90180
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 243.183
    learner_load_time_ms: 1.498
    learner_load_wait_time_ms: 1.811
iterations_since_restore: 369
node_ip: 127.0.0.1
num_agent_steps_sampled: 4587600
num_agent_steps_trained: 4571000
num_env_steps_sampled: 4587600
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.8854258648607
num_env_steps_trained: 4571000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.8841385150276
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.9
  ram_util_percent: 76.54285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06434993185286667
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02522861836547182
  mean_inference_ms: 1.2061246192324075
  mean_raw_obs_processing_ms: 0.2741049887748901
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01954505076775184
    StateBufferConnector_ms: 0.003521259014423077
    ViewRequirementAgentConnector_ms: 0.117606153854957
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.701923076923077
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 10.0, 13.0, 8.0, 1.0, 12.0, 8.0, 14.0, 9.0, 12.0, 6.0,
      8.0, 10.0, 9.0, 11.0, 14.0, 4.0, 9.0, 8.0, 7.0, 8.0, 9.0, 8.0, 8.0, 12.0, 5.0,
      10.0, 12.0, 5.0, 10.0, 7.0, 9.0, 9.0, 15.0, 8.0, 8.0, 10.0, 6.0, 6.0, 7.0, 10.0,
      6.0, 13.0, 2.0, 11.0, 11.0, 8.0, 8.0, 9.0, 10.0, 7.0, 10.0, 7.0, 5.0, 14.0,
      7.0, 12.0, 11.0, 6.0, 7.0, 10.0, 11.0, 12.0, 9.0, 10.0, 10.0, 10.0, 11.0, 7.0,
      8.0, 12.0, 10.0, 6.0, 11.0, 4.0, 11.0, 8.0, 9.0, 9.0, 5.0, 10.0, 8.0, 6.0, 8.0,
      8.0, 11.0, 5.0, 8.0, 13.0, 6.0, 6.0, 9.0, 9.0, 6.0, 8.0, 8.0, 5.0, 5.0, 8.0,
      6.0, 9.0, 10.0, 9.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06434993185286667
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02522861836547182
    mean_inference_ms: 1.2061246192324075
    mean_raw_obs_processing_ms: 0.2741049887748901
time_since_restore: 3743.875825405121
time_this_iter_s: 10.10459017753601
time_total_s: 3743.875825405121
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.247
  training_iteration_time_ms: 0.344
timestamp: 1691997925
timesteps_total: 4587600
training_iteration: 369
trial_id: default
train step: 370
agent_timesteps_total: 4600550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020012434791116154
  StateBufferConnector_ms: 0.003510129218008004
  ViewRequirementAgentConnector_ms: 0.11857935026580212
counters:
  num_agent_steps_sampled: 4600550
  num_agent_steps_trained: 4584000
  num_env_steps_sampled: 4600550
  num_env_steps_trained: 4584000
  num_samples_added_to_queue: 4600500
  num_training_step_calls_since_last_synch_worker_weights: 1360
  num_weight_broadcasts: 90436
custom_metrics: {}
date: 2023-08-14_16-25-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.382352941176471
episode_reward_min: 1.0
episodes_this_iter: 102
episodes_total: 35943
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6638644933700562
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 35.862510681152344
        total_loss: 101.43314361572266
        var_gnorm: 64.9297866821289
        vf_explained_var: 0.8429133296012878
        vf_loss: 137.7799072265625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9168.0
  learner_queue:
    size_count: 9172
    size_mean: 15.68
    size_quantiles: [13.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.76
  num_agent_steps_sampled: 4600550
  num_agent_steps_trained: 4584000
  num_env_steps_sampled: 4600550
  num_env_steps_trained: 4584000
  num_samples_added_to_queue: 4600500
  num_training_step_calls_since_last_synch_worker_weights: 1360
  num_weight_broadcasts: 90436
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 262.994
    learner_load_time_ms: 1.524
    learner_load_wait_time_ms: 1.807
iterations_since_restore: 370
node_ip: 127.0.0.1
num_agent_steps_sampled: 4600550
num_agent_steps_trained: 4584000
num_env_steps_sampled: 4600550
num_env_steps_sampled_this_iter: 12950
num_env_steps_sampled_throughput_per_sec: 1294.9943189870191
num_env_steps_trained: 4584000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9942970526063
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 57.62
  ram_util_percent: 77.05333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06434059757563883
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02522583615412389
  mean_inference_ms: 1.205965977347474
  mean_raw_obs_processing_ms: 0.2740744194327524
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020012434791116154
    StateBufferConnector_ms: 0.003510129218008004
    ViewRequirementAgentConnector_ms: 0.11857935026580212
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.382352941176471
  episode_reward_min: 1.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 9.0, 7.0, 6.0, 11.0, 9.0, 10.0, 9.0, 11.0, 10.0, 13.0,
      10.0, 9.0, 10.0, 8.0, 8.0, 8.0, 14.0, 10.0, 11.0, 4.0, 8.0, 7.0, 9.0, 11.0,
      5.0, 11.0, 6.0, 14.0, 8.0, 17.0, 8.0, 10.0, 8.0, 10.0, 14.0, 9.0, 7.0, 6.0,
      5.0, 8.0, 10.0, 8.0, 10.0, 10.0, 11.0, 8.0, 7.0, 8.0, 7.0, 12.0, 13.0, 6.0,
      9.0, 7.0, 11.0, 7.0, 6.0, 10.0, 7.0, 10.0, 12.0, 11.0, 5.0, 8.0, 10.0, 12.0,
      9.0, 8.0, 12.0, 9.0, 14.0, 8.0, 10.0, 10.0, 13.0, 2.0, 9.0, 6.0, 11.0, 7.0,
      8.0, 12.0, 12.0, 11.0, 9.0, 12.0, 9.0, 15.0, 9.0, 14.0, 11.0, 13.0, 9.0, 9.0,
      7.0, 14.0, 1.0, 12.0, 10.0, 9.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06434059757563883
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02522583615412389
    mean_inference_ms: 1.205965977347474
    mean_raw_obs_processing_ms: 0.2740744194327524
time_since_restore: 3754.0098094940186
time_this_iter_s: 10.133984088897705
time_total_s: 3754.0098094940186
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1691997935
timesteps_total: 4600550
training_iteration: 370
trial_id: default
train step: 371
agent_timesteps_total: 4613750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019472720576267616
  StateBufferConnector_ms: 0.0035428533367082185
  ViewRequirementAgentConnector_ms: 0.1195842144536037
counters:
  num_agent_steps_sampled: 4613750
  num_agent_steps_trained: 4597000
  num_env_steps_sampled: 4613750
  num_env_steps_trained: 4597000
  num_samples_added_to_queue: 4613500
  num_training_step_calls_since_last_synch_worker_weights: 516
  num_weight_broadcasts: 90697
custom_metrics: {}
date: 2023-08-14_16-25-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.07843137254902
episode_reward_min: 5.0
episodes_this_iter: 102
episodes_total: 36045
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6761708855628967
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.4588675498962402
        total_loss: 69.91873168945312
        var_gnorm: 64.93208312988281
        vf_explained_var: 0.7992782592773438
        vf_loss: 151.51690673828125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9194.0
  learner_queue:
    size_count: 9200
    size_mean: 15.52
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1178550889985697
  num_agent_steps_sampled: 4613750
  num_agent_steps_trained: 4597000
  num_env_steps_sampled: 4613750
  num_env_steps_trained: 4597000
  num_samples_added_to_queue: 4613500
  num_training_step_calls_since_last_synch_worker_weights: 516
  num_weight_broadcasts: 90697
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 178.37
    learner_load_time_ms: 1.528
    learner_load_wait_time_ms: 1.736
iterations_since_restore: 371
node_ip: 127.0.0.1
num_agent_steps_sampled: 4613750
num_agent_steps_trained: 4597000
num_env_steps_sampled: 4613750
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.996695526766
num_env_steps_trained: 4597000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9967455945423
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.285714285714285
  ram_util_percent: 78.03571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06433035957944039
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02522099933417776
  mean_inference_ms: 1.2057617506449334
  mean_raw_obs_processing_ms: 0.27402958806931194
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019472720576267616
    StateBufferConnector_ms: 0.0035428533367082185
    ViewRequirementAgentConnector_ms: 0.1195842144536037
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.07843137254902
  episode_reward_min: 5.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 8.0, 10.0, 6.0, 7.0, 11.0, 9.0, 12.0, 9.0, 6.0, 8.0, 16.0,
      7.0, 10.0, 11.0, 10.0, 9.0, 5.0, 11.0, 5.0, 7.0, 5.0, 9.0, 11.0, 11.0, 12.0,
      11.0, 8.0, 9.0, 14.0, 11.0, 11.0, 8.0, 9.0, 10.0, 11.0, 8.0, 7.0, 11.0, 14.0,
      7.0, 6.0, 8.0, 11.0, 10.0, 10.0, 7.0, 7.0, 14.0, 10.0, 9.0, 7.0, 6.0, 14.0,
      9.0, 11.0, 8.0, 8.0, 9.0, 5.0, 9.0, 7.0, 7.0, 16.0, 11.0, 5.0, 9.0, 10.0, 8.0,
      9.0, 10.0, 9.0, 5.0, 13.0, 7.0, 7.0, 11.0, 7.0, 7.0, 10.0, 8.0, 10.0, 11.0,
      9.0, 6.0, 10.0, 6.0, 9.0, 11.0, 10.0, 10.0, 10.0, 13.0, 11.0, 7.0, 6.0, 11.0,
      8.0, 6.0, 8.0, 6.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06433035957944039
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02522099933417776
    mean_inference_ms: 1.2057617506449334
    mean_raw_obs_processing_ms: 0.27402958806931194
time_since_restore: 3764.1626965999603
time_this_iter_s: 10.152887105941772
time_total_s: 3764.1626965999603
timers:
  sample_time_ms: 0.018
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.051
timestamp: 1691997945
timesteps_total: 4613750
training_iteration: 371
trial_id: default
train step: 372
agent_timesteps_total: 4627550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018619166480170354
  StateBufferConnector_ms: 0.00329944822523329
  ViewRequirementAgentConnector_ms: 0.1135110855102539
counters:
  num_agent_steps_sampled: 4627550
  num_agent_steps_trained: 4611000
  num_env_steps_sampled: 4627550
  num_env_steps_trained: 4611000
  num_samples_added_to_queue: 4627500
  num_training_step_calls_since_last_synch_worker_weights: 658
  num_weight_broadcasts: 90969
custom_metrics: {}
date: 2023-08-14_16-25-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.768518518518519
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 36153
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6161320209503174
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 60.31831359863281
        total_loss: 115.54647827148438
        var_gnorm: 64.93590545654297
        vf_explained_var: 0.8637676239013672
        vf_loss: 116.6176528930664
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9222.0
  learner_queue:
    size_count: 9227
    size_mean: 15.22
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5269577597301114
  num_agent_steps_sampled: 4627550
  num_agent_steps_trained: 4611000
  num_env_steps_sampled: 4627550
  num_env_steps_trained: 4611000
  num_samples_added_to_queue: 4627500
  num_training_step_calls_since_last_synch_worker_weights: 658
  num_weight_broadcasts: 90969
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 195.698
    learner_load_time_ms: 1.531
    learner_load_wait_time_ms: 1.543
iterations_since_restore: 372
node_ip: 127.0.0.1
num_agent_steps_sampled: 4627550
num_agent_steps_trained: 4611000
num_env_steps_sampled: 4627550
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.998223307036
num_env_steps_trained: 4611000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9981975578626
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.85000000000001
  ram_util_percent: 76.8
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06431017707797244
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02521130773442204
  mean_inference_ms: 1.2053986386245183
  mean_raw_obs_processing_ms: 0.2739572609835508
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018619166480170354
    StateBufferConnector_ms: 0.00329944822523329
    ViewRequirementAgentConnector_ms: 0.1135110855102539
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.768518518518519
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 11.0, 7.0, 4.0, 5.0, 12.0, 8.0, 6.0, 9.0, 3.0, 4.0, 15.0,
      12.0, 7.0, 12.0, 9.0, 5.0, 9.0, 12.0, 8.0, 9.0, 11.0, 7.0, 7.0, 8.0, 9.0, 9.0,
      10.0, 10.0, 9.0, 17.0, 9.0, 7.0, 8.0, 12.0, 10.0, 7.0, 8.0, 10.0, 11.0, 8.0,
      7.0, 5.0, 6.0, 11.0, 11.0, 13.0, 11.0, 12.0, 9.0, 9.0, 12.0, 10.0, 9.0, 7.0,
      8.0, 6.0, 7.0, 7.0, 9.0, 10.0, 11.0, 8.0, 15.0, 11.0, 8.0, 8.0, 9.0, 12.0, 12.0,
      8.0, 3.0, 6.0, 6.0, 4.0, 10.0, 9.0, 9.0, 12.0, 8.0, 9.0, 4.0, 8.0, 10.0, 7.0,
      10.0, 6.0, 8.0, 10.0, 9.0, 8.0, 8.0, 15.0, 6.0, 8.0, 5.0, 10.0, 9.0, 8.0, 9.0,
      6.0, 6.0, 7.0, 8.0, 10.0, 11.0, 13.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06431017707797244
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02521130773442204
    mean_inference_ms: 1.2053986386245183
    mean_raw_obs_processing_ms: 0.2739572609835508
time_since_restore: 3774.3031759262085
time_this_iter_s: 10.140479326248169
time_total_s: 3774.3031759262085
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997955
timesteps_total: 4627550
training_iteration: 372
trial_id: default
train step: 373
agent_timesteps_total: 4641250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01872667559870967
  StateBufferConnector_ms: 0.0033345487382676867
  ViewRequirementAgentConnector_ms: 0.11403317804689761
counters:
  num_agent_steps_sampled: 4641250
  num_agent_steps_trained: 4624500
  num_env_steps_sampled: 4641250
  num_env_steps_trained: 4624500
  num_samples_added_to_queue: 4641000
  num_training_step_calls_since_last_synch_worker_weights: 1165
  num_weight_broadcasts: 91239
custom_metrics: {}
date: 2023-08-14_16-26-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.037037037037036
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 36261
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6797329187393188
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.078895568847656
        total_loss: 11.119611740112305
        var_gnorm: 64.9391860961914
        vf_explained_var: 0.9070718884468079
        vf_loss: 67.19434356689453
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9249.0
  learner_queue:
    size_count: 9254
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 4641250
  num_agent_steps_trained: 4624500
  num_env_steps_sampled: 4641250
  num_env_steps_trained: 4624500
  num_samples_added_to_queue: 4641000
  num_training_step_calls_since_last_synch_worker_weights: 1165
  num_weight_broadcasts: 91239
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 210.653
    learner_load_time_ms: 1.415
    learner_load_wait_time_ms: 1.615
iterations_since_restore: 373
node_ip: 127.0.0.1
num_agent_steps_sampled: 4641250
num_agent_steps_trained: 4624500
num_env_steps_sampled: 4641250
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.99464323231
num_env_steps_trained: 4624500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9947214332983
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.58666666666667
  ram_util_percent: 76.92666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06429143786628833
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02520201814970458
  mean_inference_ms: 1.2050622259700663
  mean_raw_obs_processing_ms: 0.27388906683418623
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01872667559870967
    StateBufferConnector_ms: 0.0033345487382676867
    ViewRequirementAgentConnector_ms: 0.11403317804689761
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.037037037037036
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 16.0, 10.0, 7.0, 10.0, 6.0, 12.0, 9.0, 6.0, 11.0, 10.0,
      15.0, 9.0, 6.0, 10.0, 10.0, 7.0, 7.0, 10.0, 6.0, 10.0, 11.0, 7.0, 8.0, 9.0,
      9.0, 8.0, 11.0, 6.0, 12.0, 11.0, 8.0, 8.0, 7.0, 3.0, 10.0, 7.0, 11.0, 8.0, 7.0,
      12.0, 12.0, 12.0, 12.0, 7.0, 4.0, 7.0, 4.0, 11.0, 9.0, 7.0, 12.0, 8.0, 8.0,
      12.0, 7.0, 11.0, 10.0, 8.0, 1.0, 3.0, 8.0, 12.0, 13.0, 6.0, 9.0, 11.0, 9.0,
      8.0, 6.0, 13.0, 10.0, 11.0, 10.0, 12.0, 11.0, 13.0, 11.0, 11.0, 11.0, 9.0, 13.0,
      8.0, 5.0, 10.0, 8.0, 9.0, 7.0, 7.0, 7.0, 11.0, 11.0, 9.0, 11.0, 6.0, 8.0, 9.0,
      11.0, 7.0, 7.0, 9.0, 9.0, 11.0, 10.0, 6.0, 6.0, 11.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06429143786628833
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02520201814970458
    mean_inference_ms: 1.2050622259700663
    mean_raw_obs_processing_ms: 0.27388906683418623
time_since_restore: 3784.4272289276123
time_this_iter_s: 10.124053001403809
time_total_s: 3784.4272289276123
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997965
timesteps_total: 4641250
training_iteration: 373
trial_id: default
train step: 374
agent_timesteps_total: 4654550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01956316140981821
  StateBufferConnector_ms: 0.0035943893285898063
  ViewRequirementAgentConnector_ms: 0.11921983498793381
counters:
  num_agent_steps_sampled: 4654550
  num_agent_steps_trained: 4638000
  num_env_steps_sampled: 4654550
  num_env_steps_trained: 4638000
  num_samples_added_to_queue: 4654500
  num_training_step_calls_since_last_synch_worker_weights: 307
  num_weight_broadcasts: 91502
custom_metrics: {}
date: 2023-08-14_16-26-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.971153846153846
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 36365
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6121465563774109
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 69.47360229492188
        total_loss: 111.88507080078125
        var_gnorm: 64.95198822021484
        vf_explained_var: 0.8982038497924805
        vf_loss: 90.94439697265625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9276.0
  learner_queue:
    size_count: 9283
    size_mean: 15.3
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4594519519326423
  num_agent_steps_sampled: 4654550
  num_agent_steps_trained: 4638000
  num_env_steps_sampled: 4654550
  num_env_steps_trained: 4638000
  num_samples_added_to_queue: 4654500
  num_training_step_calls_since_last_synch_worker_weights: 307
  num_weight_broadcasts: 91502
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 128.233
    learner_load_time_ms: 1.414
    learner_load_wait_time_ms: 1.447
iterations_since_restore: 374
node_ip: 127.0.0.1
num_agent_steps_sampled: 4654550
num_agent_steps_trained: 4638000
num_env_steps_sampled: 4654550
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.994260574313
num_env_steps_trained: 4638000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.99417426716
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 45.64999999999999
  ram_util_percent: 77.0642857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0642795600003659
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025196171152609064
  mean_inference_ms: 1.2048391457426157
  mean_raw_obs_processing_ms: 0.2738417471521753
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01956316140981821
    StateBufferConnector_ms: 0.0035943893285898063
    ViewRequirementAgentConnector_ms: 0.11921983498793381
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.971153846153846
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 8.0, 12.0, 4.0, 7.0, 8.0, 8.0, 11.0, 8.0, 4.0, 13.0, 5.0,
      11.0, 11.0, 4.0, 9.0, 8.0, 7.0, 5.0, 10.0, 7.0, 8.0, 8.0, 7.0, 8.0, 11.0, 7.0,
      11.0, 8.0, 11.0, 11.0, 9.0, 6.0, 8.0, 11.0, 7.0, 6.0, 7.0, 8.0, 9.0, 14.0, 10.0,
      6.0, 7.0, 6.0, 12.0, 13.0, 5.0, 5.0, 10.0, 9.0, 7.0, 6.0, 10.0, 8.0, 8.0, 8.0,
      7.0, 2.0, 9.0, 13.0, 5.0, 8.0, 7.0, 3.0, 9.0, 9.0, 7.0, 5.0, 5.0, 5.0, 10.0,
      11.0, 10.0, 6.0, 7.0, 4.0, 9.0, 8.0, 6.0, 11.0, 9.0, 4.0, 8.0, 6.0, 9.0, 4.0,
      9.0, 8.0, 11.0, 7.0, 7.0, 7.0, 7.0, 6.0, 6.0, 6.0, 6.0, 11.0, 8.0, 10.0, 8.0,
      7.0, 15.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0642795600003659
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025196171152609064
    mean_inference_ms: 1.2048391457426157
    mean_raw_obs_processing_ms: 0.2738417471521753
time_since_restore: 3794.591878890991
time_this_iter_s: 10.164649963378906
time_total_s: 3794.591878890991
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997976
timesteps_total: 4654550
training_iteration: 374
trial_id: default
train step: 375
agent_timesteps_total: 4667200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0216677188873291
  StateBufferConnector_ms: 0.0038509368896484375
  ViewRequirementAgentConnector_ms: 0.13038039207458496
counters:
  num_agent_steps_sampled: 4667200
  num_agent_steps_trained: 4650500
  num_env_steps_sampled: 4667200
  num_env_steps_trained: 4650500
  num_samples_added_to_queue: 4667000
  num_training_step_calls_since_last_synch_worker_weights: 359
  num_weight_broadcasts: 91752
custom_metrics: {}
date: 2023-08-14_16-26-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 3.36
episode_reward_min: 0.0
episodes_this_iter: 98
episodes_total: 36463
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.33387720584869385
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -4.114687919616699
        total_loss: 11.98898983001709
        var_gnorm: 64.96997833251953
        vf_explained_var: 0.9639924764633179
        vf_loss: 35.54612731933594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9301.0
  learner_queue:
    size_count: 9307
    size_mean: 15.0
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7320508075688772
  num_agent_steps_sampled: 4667200
  num_agent_steps_trained: 4650500
  num_env_steps_sampled: 4667200
  num_env_steps_trained: 4650500
  num_samples_added_to_queue: 4667000
  num_training_step_calls_since_last_synch_worker_weights: 359
  num_weight_broadcasts: 91752
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 194.621
    learner_load_time_ms: 1.423
    learner_load_wait_time_ms: 1.588
iterations_since_restore: 375
node_ip: 127.0.0.1
num_agent_steps_sampled: 4667200
num_agent_steps_trained: 4650500
num_env_steps_sampled: 4667200
num_env_steps_sampled_this_iter: 12650
num_env_steps_sampled_throughput_per_sec: 1264.9958077808074
num_env_steps_trained: 4650500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9958574909165
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 54.142857142857146
  ram_util_percent: 78.02857142857144
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06428266362132473
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025194416413584407
  mean_inference_ms: 1.2047820447074082
  mean_raw_obs_processing_ms: 0.27383173829573215
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0216677188873291
    StateBufferConnector_ms: 0.0038509368896484375
    ViewRequirementAgentConnector_ms: 0.13038039207458496
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 3.36
  episode_reward_min: 0.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 15.0, 4.0, 4.0, 1.0, 2.0, 1.0, 3.0, 8.0, 7.0, 5.0, 6.0,
      1.0, 1.0, 8.0, 2.0, 1.0, 10.0, 2.0, 0.0, 5.0, 8.0, 7.0, 4.0, 4.0, 5.0, 1.0,
      0.0, 3.0, 3.0, 3.0, 3.0, 4.0, 6.0, 1.0, 3.0, 6.0, 3.0, 0.0, 0.0, 1.0, 0.0, 0.0,
      0.0, 0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 4.0, 7.0, 8.0, 13.0, 4.0, 2.0, 0.0,
      6.0, 9.0, 7.0, 6.0, 6.0, 3.0, 10.0, 7.0, 3.0, 2.0, 4.0, 8.0, 5.0, 4.0, 4.0,
      6.0, 3.0, 9.0, 3.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 4.0,
      0.0, 0.0, 4.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06428266362132473
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025194416413584407
    mean_inference_ms: 1.2047820447074082
    mean_raw_obs_processing_ms: 0.27383173829573215
time_since_restore: 3804.7480521202087
time_this_iter_s: 10.15617322921753
time_total_s: 3804.7480521202087
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691997986
timesteps_total: 4667200
training_iteration: 375
trial_id: default
train step: 376
agent_timesteps_total: 4679400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023671388626098633
  StateBufferConnector_ms: 0.0038444995880126953
  ViewRequirementAgentConnector_ms: 0.13066577911376953
counters:
  num_agent_steps_sampled: 4679400
  num_agent_steps_trained: 4662500
  num_env_steps_sampled: 4679400
  num_env_steps_trained: 4662500
  num_samples_added_to_queue: 4679000
  num_training_step_calls_since_last_synch_worker_weights: 607
  num_weight_broadcasts: 91993
custom_metrics: {}
date: 2023-08-14_16-26-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.12
episode_reward_min: 0.0
episodes_this_iter: 95
episodes_total: 36558
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.039537061005830765
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.258407592773438
        total_loss: 94.45392608642578
        var_gnorm: 64.98971557617188
        vf_explained_var: 0.7708629369735718
        vf_loss: 205.82003784179688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9325.0
  learner_queue:
    size_count: 9331
    size_mean: 14.66
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.9037857022259623
  num_agent_steps_sampled: 4679400
  num_agent_steps_trained: 4662500
  num_env_steps_sampled: 4679400
  num_env_steps_trained: 4662500
  num_samples_added_to_queue: 4679000
  num_training_step_calls_since_last_synch_worker_weights: 607
  num_weight_broadcasts: 91993
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 188.409
    learner_load_time_ms: 1.404
    learner_load_wait_time_ms: 1.628
iterations_since_restore: 376
node_ip: 127.0.0.1
num_agent_steps_sampled: 4679400
num_agent_steps_trained: 4662500
num_env_steps_sampled: 4679400
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.9945025691752
num_env_steps_trained: 4662500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.994592690992
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 56.68666666666668
  ram_util_percent: 79.76
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06429019560406207
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025195504518321022
  mean_inference_ms: 1.2048254734500523
  mean_raw_obs_processing_ms: 0.273842173446115
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023671388626098633
    StateBufferConnector_ms: 0.0038444995880126953
    ViewRequirementAgentConnector_ms: 0.13066577911376953
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.12
  episode_reward_min: 0.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,
      0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06429019560406207
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025195504518321022
    mean_inference_ms: 1.2048254734500523
    mean_raw_obs_processing_ms: 0.273842173446115
time_since_restore: 3814.8761632442474
time_this_iter_s: 10.128111124038696
time_total_s: 3814.8761632442474
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691997996
timesteps_total: 4679400
training_iteration: 376
trial_id: default
train step: 377
agent_timesteps_total: 4691600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02123260498046875
  StateBufferConnector_ms: 0.0038111209869384766
  ViewRequirementAgentConnector_ms: 0.12647628784179688
counters:
  num_agent_steps_sampled: 4691600
  num_agent_steps_trained: 4675000
  num_env_steps_sampled: 4691600
  num_env_steps_trained: 4675000
  num_samples_added_to_queue: 4691500
  num_training_step_calls_since_last_synch_worker_weights: 226
  num_weight_broadcasts: 92234
custom_metrics: {}
date: 2023-08-14_16-26-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 36654
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00182146776933223
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.183232069015503
        total_loss: 179.9659881591797
        var_gnorm: 64.99364471435547
        vf_explained_var: 0.20187097787857056
        vf_loss: 364.316650390625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9350.0
  learner_queue:
    size_count: 9357
    size_mean: 14.96
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.72
  num_agent_steps_sampled: 4691600
  num_agent_steps_trained: 4675000
  num_env_steps_sampled: 4691600
  num_env_steps_trained: 4675000
  num_samples_added_to_queue: 4691500
  num_training_step_calls_since_last_synch_worker_weights: 226
  num_weight_broadcasts: 92234
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 154.586
    learner_load_time_ms: 1.425
    learner_load_wait_time_ms: 1.627
iterations_since_restore: 377
node_ip: 127.0.0.1
num_agent_steps_sampled: 4691600
num_agent_steps_trained: 4675000
num_env_steps_sampled: 4691600
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.996073258641
num_env_steps_trained: 4675000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9959766994273
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 56.17857142857143
  ram_util_percent: 79.44285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06429514698925944
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025196608787280264
  mean_inference_ms: 1.2048893559225402
  mean_raw_obs_processing_ms: 0.2738604764714225
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02123260498046875
    StateBufferConnector_ms: 0.0038111209869384766
    ViewRequirementAgentConnector_ms: 0.12647628784179688
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06429514698925944
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025196608787280264
    mean_inference_ms: 1.2048893559225402
    mean_raw_obs_processing_ms: 0.2738604764714225
time_since_restore: 3825.034811258316
time_this_iter_s: 10.158648014068604
time_total_s: 3825.034811258316
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691998006
timesteps_total: 4691600
training_iteration: 377
trial_id: default
train step: 378
agent_timesteps_total: 4704950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019197968336252067
  StateBufferConnector_ms: 0.003478389519911546
  ViewRequirementAgentConnector_ms: 0.11785832735208365
counters:
  num_agent_steps_sampled: 4704950
  num_agent_steps_trained: 4688000
  num_env_steps_sampled: 4704950
  num_env_steps_trained: 4688000
  num_samples_added_to_queue: 4704500
  num_training_step_calls_since_last_synch_worker_weights: 666
  num_weight_broadcasts: 92498
custom_metrics: {}
date: 2023-08-14_16-26-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 36758
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00020743042114190757
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.005621367134153843
        total_loss: 78.61427307128906
        var_gnorm: 65.0041275024414
        vf_explained_var: -0.7016264200210571
        vf_loss: 157.2418670654297
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9376.0
  learner_queue:
    size_count: 9381
    size_mean: 15.06
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6298466185503468
  num_agent_steps_sampled: 4704950
  num_agent_steps_trained: 4688000
  num_env_steps_sampled: 4704950
  num_env_steps_trained: 4688000
  num_samples_added_to_queue: 4704500
  num_training_step_calls_since_last_synch_worker_weights: 666
  num_weight_broadcasts: 92498
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 234.304
    learner_load_time_ms: 2.93
    learner_load_wait_time_ms: 1.592
iterations_since_restore: 378
node_ip: 127.0.0.1
num_agent_steps_sampled: 4704950
num_agent_steps_trained: 4688000
num_env_steps_sampled: 4704950
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9943981405718
num_env_steps_trained: 4688000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9945450058003
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.09285714285714
  ram_util_percent: 78.82857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06427278864727595
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025187982721437255
  mean_inference_ms: 1.2046780721693895
  mean_raw_obs_processing_ms: 0.2738078438330925
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019197968336252067
    StateBufferConnector_ms: 0.003478389519911546
    ViewRequirementAgentConnector_ms: 0.11785832735208365
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06427278864727595
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025187982721437255
    mean_inference_ms: 1.2046780721693895
    mean_raw_obs_processing_ms: 0.2738078438330925
time_since_restore: 3835.1528146266937
time_this_iter_s: 10.118003368377686
time_total_s: 3835.1528146266937
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998016
timesteps_total: 4704950
training_iteration: 378
trial_id: default
train step: 379
agent_timesteps_total: 4717750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02014446258544922
  StateBufferConnector_ms: 0.0037240982055664062
  ViewRequirementAgentConnector_ms: 0.1250755786895752
counters:
  num_agent_steps_sampled: 4717750
  num_agent_steps_trained: 4701000
  num_env_steps_sampled: 4717750
  num_env_steps_trained: 4701000
  num_samples_added_to_queue: 4717500
  num_training_step_calls_since_last_synch_worker_weights: 462
  num_weight_broadcasts: 92751
custom_metrics: {}
date: 2023-08-14_16-27-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 36858
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00020529025641735643
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0016849180683493614
        total_loss: 18.94261360168457
        var_gnorm: 65.01840209960938
        vf_explained_var: -1.0
        vf_loss: 37.8839111328125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9402.0
  learner_queue:
    size_count: 9408
    size_mean: 15.22
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.3898201322473351
  num_agent_steps_sampled: 4717750
  num_agent_steps_trained: 4701000
  num_env_steps_sampled: 4717750
  num_env_steps_trained: 4701000
  num_samples_added_to_queue: 4717500
  num_training_step_calls_since_last_synch_worker_weights: 462
  num_weight_broadcasts: 92751
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 174.337
    learner_load_time_ms: 2.911
    learner_load_wait_time_ms: 1.482
iterations_since_restore: 379
node_ip: 127.0.0.1
num_agent_steps_sampled: 4717750
num_agent_steps_trained: 4701000
num_env_steps_sampled: 4717750
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9979553255318
num_env_steps_trained: 4701000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9979233774932
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.692857142857136
  ram_util_percent: 79.16428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06426775408726647
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025183614315291054
  mean_inference_ms: 1.2045879832887274
  mean_raw_obs_processing_ms: 0.273785846865614
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02014446258544922
    StateBufferConnector_ms: 0.0037240982055664062
    ViewRequirementAgentConnector_ms: 0.1250755786895752
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06426775408726647
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025183614315291054
    mean_inference_ms: 1.2045879832887274
    mean_raw_obs_processing_ms: 0.273785846865614
time_since_restore: 3845.30157995224
time_this_iter_s: 10.148765325546265
time_total_s: 3845.30157995224
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998026
timesteps_total: 4717750
training_iteration: 379
trial_id: default
train step: 380
agent_timesteps_total: 4730500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020848989486694336
  StateBufferConnector_ms: 0.003656148910522461
  ViewRequirementAgentConnector_ms: 0.12536311149597168
counters:
  num_agent_steps_sampled: 4730500
  num_agent_steps_trained: 4714000
  num_env_steps_sampled: 4730500
  num_env_steps_trained: 4714000
  num_samples_added_to_queue: 4730500
  num_training_step_calls_since_last_synch_worker_weights: 260
  num_weight_broadcasts: 93003
custom_metrics: {}
date: 2023-08-14_16-27-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 36958
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011336903116898611
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00017115364607889205
        total_loss: 3.7709085941314697
        var_gnorm: 65.02213287353516
        vf_explained_var: -1.0
        vf_loss: 7.543293476104736
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9428.0
  learner_queue:
    size_count: 9434
    size_mean: 15.18
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5190786681406594
  num_agent_steps_sampled: 4730500
  num_agent_steps_trained: 4714000
  num_env_steps_sampled: 4730500
  num_env_steps_trained: 4714000
  num_samples_added_to_queue: 4730500
  num_training_step_calls_since_last_synch_worker_weights: 260
  num_weight_broadcasts: 93003
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 161.418
    learner_load_time_ms: 2.909
    learner_load_wait_time_ms: 1.618
iterations_since_restore: 380
node_ip: 127.0.0.1
num_agent_steps_sampled: 4730500
num_agent_steps_trained: 4714000
num_env_steps_sampled: 4730500
num_env_steps_sampled_this_iter: 12750
num_env_steps_sampled_throughput_per_sec: 1274.9950450851356
num_env_steps_trained: 4714000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9949479299423
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.12666666666666
  ram_util_percent: 78.58
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06426421413739916
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02517960024490164
  mean_inference_ms: 1.2045066332894416
  mean_raw_obs_processing_ms: 0.27377001417798064
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020848989486694336
    StateBufferConnector_ms: 0.003656148910522461
    ViewRequirementAgentConnector_ms: 0.12536311149597168
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06426421413739916
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02517960024490164
    mean_inference_ms: 1.2045066332894416
    mean_raw_obs_processing_ms: 0.27377001417798064
time_since_restore: 3855.435842037201
time_this_iter_s: 10.134262084960938
time_total_s: 3855.435842037201
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691998036
timesteps_total: 4730500
training_iteration: 380
trial_id: default
train step: 381
agent_timesteps_total: 4742850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020510196685791016
  StateBufferConnector_ms: 0.0037047863006591797
  ViewRequirementAgentConnector_ms: 0.1267993450164795
counters:
  num_agent_steps_sampled: 4742850
  num_agent_steps_trained: 4726000
  num_env_steps_sampled: 4742850
  num_env_steps_trained: 4726000
  num_samples_added_to_queue: 4742500
  num_training_step_calls_since_last_synch_worker_weights: 642
  num_weight_broadcasts: 93247
custom_metrics: {}
date: 2023-08-14_16-27-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 37054
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011278197052888572
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0016568406717851758
        total_loss: 23.179460525512695
        var_gnorm: 65.02481842041016
        vf_explained_var: -1.0
        vf_loss: 46.363365173339844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9452.0
  learner_queue:
    size_count: 9463
    size_mean: 14.44
    size_quantiles: [6.0, 10.9, 16.0, 16.0, 16.0]
    size_std: 2.624195114697076
  num_agent_steps_sampled: 4742850
  num_agent_steps_trained: 4726000
  num_env_steps_sampled: 4742850
  num_env_steps_trained: 4726000
  num_samples_added_to_queue: 4742500
  num_training_step_calls_since_last_synch_worker_weights: 642
  num_weight_broadcasts: 93247
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 22.574
    learner_load_time_ms: 2.886
    learner_load_wait_time_ms: 1.353
iterations_since_restore: 381
node_ip: 127.0.0.1
num_agent_steps_sampled: 4742850
num_agent_steps_trained: 4726000
num_env_steps_sampled: 4742850
num_env_steps_sampled_this_iter: 12350
num_env_steps_sampled_throughput_per_sec: 1234.9992638830759
num_env_steps_trained: 4726000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.999284744689
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.91428571428571
  ram_util_percent: 78.77142857142859
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06427515009662434
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025179114149452734
  mean_inference_ms: 1.2045411527943788
  mean_raw_obs_processing_ms: 0.2737845282899621
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020510196685791016
    StateBufferConnector_ms: 0.0037047863006591797
    ViewRequirementAgentConnector_ms: 0.1267993450164795
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06427515009662434
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025179114149452734
    mean_inference_ms: 1.2045411527943788
    mean_raw_obs_processing_ms: 0.2737845282899621
time_since_restore: 3865.7060170173645
time_this_iter_s: 10.270174980163574
time_total_s: 3865.7060170173645
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691998047
timesteps_total: 4742850
training_iteration: 381
trial_id: default
train step: 382
agent_timesteps_total: 4755550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020839452743530273
  StateBufferConnector_ms: 0.0038187503814697266
  ViewRequirementAgentConnector_ms: 0.12677764892578125
counters:
  num_agent_steps_sampled: 4755550
  num_agent_steps_trained: 4739000
  num_env_steps_sampled: 4755550
  num_env_steps_trained: 4739000
  num_samples_added_to_queue: 4755500
  num_training_step_calls_since_last_synch_worker_weights: 64
  num_weight_broadcasts: 93497
custom_metrics: {}
date: 2023-08-14_16-27-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 99
episodes_total: 37153
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0003778287209570408
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.003551748814061284
        total_loss: 8.693253517150879
        var_gnorm: 65.02727508544922
        vf_explained_var: -1.0
        vf_loss: 17.383182525634766
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9478.0
  learner_queue:
    size_count: 9484
    size_mean: 13.66
    size_quantiles: [6.0, 8.9, 15.5, 16.0, 16.0]
    size_std: 3.0958682142494376
  num_agent_steps_sampled: 4755550
  num_agent_steps_trained: 4739000
  num_env_steps_sampled: 4755550
  num_env_steps_trained: 4739000
  num_samples_added_to_queue: 4755500
  num_training_step_calls_since_last_synch_worker_weights: 64
  num_weight_broadcasts: 93497
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 167.879
    learner_load_time_ms: 2.9
    learner_load_wait_time_ms: 1.647
iterations_since_restore: 382
node_ip: 127.0.0.1
num_agent_steps_sampled: 4755550
num_agent_steps_trained: 4739000
num_env_steps_sampled: 4755550
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.9942772646332
num_env_steps_trained: 4739000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.994142081908
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.41428571428571
  ram_util_percent: 80.29285714285716
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06426318926777916
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02517611337999391
  mean_inference_ms: 1.2045073518689415
  mean_raw_obs_processing_ms: 0.27376511579721957
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020839452743530273
    StateBufferConnector_ms: 0.0038187503814697266
    ViewRequirementAgentConnector_ms: 0.12677764892578125
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06426318926777916
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02517611337999391
    mean_inference_ms: 1.2045073518689415
    mean_raw_obs_processing_ms: 0.27376511579721957
time_since_restore: 3875.8484048843384
time_this_iter_s: 10.142387866973877
time_total_s: 3875.8484048843384
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998057
timesteps_total: 4755550
training_iteration: 382
trial_id: default
train step: 383
agent_timesteps_total: 4768900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01933324904668899
  StateBufferConnector_ms: 0.0035133815947033112
  ViewRequirementAgentConnector_ms: 0.11759076799665179
counters:
  num_agent_steps_sampled: 4768900
  num_agent_steps_trained: 4752000
  num_env_steps_sampled: 4768900
  num_env_steps_trained: 4752000
  num_samples_added_to_queue: 4768500
  num_training_step_calls_since_last_synch_worker_weights: 929
  num_weight_broadcasts: 93761
custom_metrics: {}
date: 2023-08-14_16-27-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 37258
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00021709197608288378
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00045538577251136303
        total_loss: 1.1362496614456177
        var_gnorm: 65.0260009765625
        vf_explained_var: -1.0
        vf_loss: 2.275580883026123
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9504.0
  learner_queue:
    size_count: 9509
    size_mean: 13.9
    size_quantiles: [6.0, 8.9, 16.0, 16.0, 16.0]
    size_std: 3.054504869860253
  num_agent_steps_sampled: 4768900
  num_agent_steps_trained: 4752000
  num_env_steps_sampled: 4768900
  num_env_steps_trained: 4752000
  num_samples_added_to_queue: 4768500
  num_training_step_calls_since_last_synch_worker_weights: 929
  num_weight_broadcasts: 93761
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 232.385
    learner_load_time_ms: 2.872
    learner_load_wait_time_ms: 1.473
iterations_since_restore: 383
node_ip: 127.0.0.1
num_agent_steps_sampled: 4768900
num_agent_steps_trained: 4752000
num_env_steps_sampled: 4768900
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9975810094795
num_env_steps_trained: 4752000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9976444287067
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.300000000000004
  ram_util_percent: 78.21333333333335
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06424882760032816
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02516774128407314
  mean_inference_ms: 1.2042705696275147
  mean_raw_obs_processing_ms: 0.27371317966799186
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01933324904668899
    StateBufferConnector_ms: 0.0035133815947033112
    ViewRequirementAgentConnector_ms: 0.11759076799665179
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06424882760032816
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02516774128407314
    mean_inference_ms: 1.2042705696275147
    mean_raw_obs_processing_ms: 0.27371317966799186
time_since_restore: 3885.9556968212128
time_this_iter_s: 10.10729193687439
time_total_s: 3885.9556968212128
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998067
timesteps_total: 4768900
training_iteration: 383
trial_id: default
train step: 384
agent_timesteps_total: 4781650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02066802978515625
  StateBufferConnector_ms: 0.003737926483154297
  ViewRequirementAgentConnector_ms: 0.12452268600463867
counters:
  num_agent_steps_sampled: 4781650
  num_agent_steps_trained: 4765000
  num_env_steps_sampled: 4781650
  num_env_steps_trained: 4765000
  num_samples_added_to_queue: 4781500
  num_training_step_calls_since_last_synch_worker_weights: 469
  num_weight_broadcasts: 94012
custom_metrics: {}
date: 2023-08-14_16-27-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 99
episodes_total: 37357
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001128946096287109
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00011365961108822376
        total_loss: 0.7816947102546692
        var_gnorm: 65.02859497070312
        vf_explained_var: -1.0
        vf_loss: 1.5647456645965576
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9530.0
  learner_queue:
    size_count: 9536
    size_mean: 15.42
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.218031198286809
  num_agent_steps_sampled: 4781650
  num_agent_steps_trained: 4765000
  num_env_steps_sampled: 4781650
  num_env_steps_trained: 4765000
  num_samples_added_to_queue: 4781500
  num_training_step_calls_since_last_synch_worker_weights: 469
  num_weight_broadcasts: 94012
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 183.915
    learner_load_time_ms: 1.368
    learner_load_wait_time_ms: 1.506
iterations_since_restore: 384
node_ip: 127.0.0.1
num_agent_steps_sampled: 4781650
num_agent_steps_trained: 4765000
num_env_steps_sampled: 4781650
num_env_steps_sampled_this_iter: 12750
num_env_steps_sampled_throughput_per_sec: 1274.994893094491
num_env_steps_trained: 4765000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.994792959089
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.25714285714287
  ram_util_percent: 77.94285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06424726290739724
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025163808016506042
  mean_inference_ms: 1.2041864887942573
  mean_raw_obs_processing_ms: 0.27369645971935774
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02066802978515625
    StateBufferConnector_ms: 0.003737926483154297
    ViewRequirementAgentConnector_ms: 0.12452268600463867
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06424726290739724
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025163808016506042
    mean_inference_ms: 1.2041864887942573
    mean_raw_obs_processing_ms: 0.27369645971935774
time_since_restore: 3896.0880937576294
time_this_iter_s: 10.132396936416626
time_total_s: 3896.0880937576294
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998077
timesteps_total: 4781650
training_iteration: 384
trial_id: default
train step: 385
agent_timesteps_total: 4794300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020664691925048828
  StateBufferConnector_ms: 0.003724813461303711
  ViewRequirementAgentConnector_ms: 0.12294888496398926
counters:
  num_agent_steps_sampled: 4794300
  num_agent_steps_trained: 4777500
  num_env_steps_sampled: 4794300
  num_env_steps_trained: 4777500
  num_samples_added_to_queue: 4794000
  num_training_step_calls_since_last_synch_worker_weights: 828
  num_weight_broadcasts: 94262
custom_metrics: {}
date: 2023-08-14_16-28-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 99
episodes_total: 37456
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00013695310917682946
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0007492497679777443
        total_loss: 6.757981777191162
        var_gnorm: 65.02947235107422
        vf_explained_var: -1.0
        vf_loss: 13.51583480834961
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9555.0
  learner_queue:
    size_count: 9560
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3332666649999165
  num_agent_steps_sampled: 4794300
  num_agent_steps_trained: 4777500
  num_env_steps_sampled: 4794300
  num_env_steps_trained: 4777500
  num_samples_added_to_queue: 4794000
  num_training_step_calls_since_last_synch_worker_weights: 828
  num_weight_broadcasts: 94262
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 233.047
    learner_load_time_ms: 1.393
    learner_load_wait_time_ms: 1.715
iterations_since_restore: 385
node_ip: 127.0.0.1
num_agent_steps_sampled: 4794300
num_agent_steps_trained: 4777500
num_env_steps_sampled: 4794300
num_env_steps_sampled_this_iter: 12650
num_env_steps_sampled_throughput_per_sec: 1264.9949633083613
num_env_steps_trained: 4777500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9950230319776
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 54.53571428571428
  ram_util_percent: 78.72857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06424881189009056
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02516044690249827
  mean_inference_ms: 1.2041146219284464
  mean_raw_obs_processing_ms: 0.2736904711723414
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020664691925048828
    StateBufferConnector_ms: 0.003724813461303711
    ViewRequirementAgentConnector_ms: 0.12294888496398926
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06424881189009056
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02516044690249827
    mean_inference_ms: 1.2041146219284464
    mean_raw_obs_processing_ms: 0.2736904711723414
time_since_restore: 3906.198805809021
time_this_iter_s: 10.110712051391602
time_total_s: 3906.198805809021
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691998087
timesteps_total: 4794300
training_iteration: 385
trial_id: default
train step: 386
agent_timesteps_total: 4807700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01931076958065941
  StateBufferConnector_ms: 0.003468195597330729
  ViewRequirementAgentConnector_ms: 0.11771769750685919
counters:
  num_agent_steps_sampled: 4807700
  num_agent_steps_trained: 4791000
  num_env_steps_sampled: 4807700
  num_env_steps_trained: 4791000
  num_samples_added_to_queue: 4807500
  num_training_step_calls_since_last_synch_worker_weights: 104
  num_weight_broadcasts: 94527
custom_metrics: {}
date: 2023-08-14_16-28-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.009523809523809525
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 37561
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011808567069238052
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0006272125756368041
        total_loss: 3.732434034347534
        var_gnorm: 65.02857971191406
        vf_explained_var: -1.0
        vf_loss: 7.467303276062012
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9582.0
  learner_queue:
    size_count: 9589
    size_mean: 15.3
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4594519519326423
  num_agent_steps_sampled: 4807700
  num_agent_steps_trained: 4791000
  num_env_steps_sampled: 4807700
  num_env_steps_trained: 4791000
  num_samples_added_to_queue: 4807500
  num_training_step_calls_since_last_synch_worker_weights: 104
  num_weight_broadcasts: 94527
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 133.407
    learner_load_time_ms: 1.407
    learner_load_wait_time_ms: 1.483
iterations_since_restore: 386
node_ip: 127.0.0.1
num_agent_steps_sampled: 4807700
num_agent_steps_trained: 4791000
num_env_steps_sampled: 4807700
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.999456882697
num_env_steps_trained: 4791000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9994528295827
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.14
  ram_util_percent: 76.45333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0642295105813393
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025151365157251214
  mean_inference_ms: 1.2038937361780002
  mean_raw_obs_processing_ms: 0.27363881032054843
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01931076958065941
    StateBufferConnector_ms: 0.003468195597330729
    ViewRequirementAgentConnector_ms: 0.11771769750685919
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.009523809523809525
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0642295105813393
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025151365157251214
    mean_inference_ms: 1.2038937361780002
    mean_raw_obs_processing_ms: 0.27363881032054843
time_since_restore: 3916.349401950836
time_this_iter_s: 10.150596141815186
time_total_s: 3916.349401950836
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691998097
timesteps_total: 4807700
training_iteration: 386
trial_id: default
train step: 387
agent_timesteps_total: 4820000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020885229110717773
  StateBufferConnector_ms: 0.0038700103759765625
  ViewRequirementAgentConnector_ms: 0.12898802757263184
counters:
  num_agent_steps_sampled: 4820000
  num_agent_steps_trained: 4803500
  num_env_steps_sampled: 4820000
  num_env_steps_trained: 4803500
  num_samples_added_to_queue: 4820000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 94770
custom_metrics: {}
date: 2023-08-14_16-28-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 37657
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001264394959434867
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0004631456104107201
        total_loss: 3.617680072784424
        var_gnorm: 65.02873992919922
        vf_explained_var: -1.0
        vf_loss: 7.237551212310791
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9607.0
  learner_queue:
    size_count: 9613
    size_mean: 15.04
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.70833252032501
  num_agent_steps_sampled: 4820000
  num_agent_steps_trained: 4803500
  num_env_steps_sampled: 4820000
  num_env_steps_trained: 4803500
  num_samples_added_to_queue: 4820000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 94770
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 185.088
    learner_load_time_ms: 1.424
    learner_load_wait_time_ms: 1.589
iterations_since_restore: 387
node_ip: 127.0.0.1
num_agent_steps_sampled: 4820000
num_agent_steps_trained: 4803500
num_env_steps_sampled: 4820000
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.336048376468
num_env_steps_trained: 4803500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.3252524151096
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.11428571428571
  ram_util_percent: 77.16428571428573
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06424287911468077
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02515133804477425
  mean_inference_ms: 1.2039092857091735
  mean_raw_obs_processing_ms: 0.2736565622314907
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020885229110717773
    StateBufferConnector_ms: 0.0038700103759765625
    ViewRequirementAgentConnector_ms: 0.12898802757263184
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06424287911468077
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02515133804477425
    mean_inference_ms: 1.2039092857091735
    mean_raw_obs_processing_ms: 0.2736565622314907
time_since_restore: 3926.4944047927856
time_this_iter_s: 10.145002841949463
time_total_s: 3926.4944047927856
timers:
  sample_time_ms: 0.072
  synch_weights_time_ms: 0.697
  training_iteration_time_ms: 2.401
timestamp: 1691998108
timesteps_total: 4820000
training_iteration: 387
trial_id: default
train step: 388
agent_timesteps_total: 4832950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020338521145357943
  StateBufferConnector_ms: 0.0035592825105874846
  ViewRequirementAgentConnector_ms: 0.12185904059079614
counters:
  num_agent_steps_sampled: 4832950
  num_agent_steps_trained: 4816000
  num_env_steps_sampled: 4832950
  num_env_steps_trained: 4816000
  num_samples_added_to_queue: 4832500
  num_training_step_calls_since_last_synch_worker_weights: 888
  num_weight_broadcasts: 95024
custom_metrics: {}
date: 2023-08-14_16-28-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 101
episodes_total: 37758
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011852659372380003
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0003798225661739707
        total_loss: 1.5835199356079102
        var_gnorm: 65.02851867675781
        vf_explained_var: -1.0
        vf_loss: 3.1674654483795166
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9632.0
  learner_queue:
    size_count: 9637
    size_mean: 14.8
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8220867158288598
  num_agent_steps_sampled: 4832950
  num_agent_steps_trained: 4816000
  num_env_steps_sampled: 4832950
  num_env_steps_trained: 4816000
  num_samples_added_to_queue: 4832500
  num_training_step_calls_since_last_synch_worker_weights: 888
  num_weight_broadcasts: 95024
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 228.495
    learner_load_time_ms: 1.502
    learner_load_wait_time_ms: 1.583
iterations_since_restore: 388
node_ip: 127.0.0.1
num_agent_steps_sampled: 4832950
num_agent_steps_trained: 4816000
num_env_steps_sampled: 4832950
num_env_steps_sampled_this_iter: 12950
num_env_steps_sampled_throughput_per_sec: 1294.9944424867715
num_env_steps_trained: 4816000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9946356049918
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.82142857142856
  ram_util_percent: 77.17142857142856
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06422426725240221
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02514560431621582
  mean_inference_ms: 1.2037943932023838
  mean_raw_obs_processing_ms: 0.27361704790868085
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020338521145357943
    StateBufferConnector_ms: 0.0035592825105874846
    ViewRequirementAgentConnector_ms: 0.12185904059079614
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06422426725240221
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02514560431621582
    mean_inference_ms: 1.2037943932023838
    mean_raw_obs_processing_ms: 0.27361704790868085
time_since_restore: 3936.5998458862305
time_this_iter_s: 10.105441093444824
time_total_s: 3936.5998458862305
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691998118
timesteps_total: 4832950
training_iteration: 388
trial_id: default
train step: 389
agent_timesteps_total: 4846450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019125938415527344
  StateBufferConnector_ms: 0.0034350440615699405
  ViewRequirementAgentConnector_ms: 0.11655285244896299
counters:
  num_agent_steps_sampled: 4846450
  num_agent_steps_trained: 4829500
  num_env_steps_sampled: 4846450
  num_env_steps_trained: 4829500
  num_samples_added_to_queue: 4846000
  num_training_step_calls_since_last_synch_worker_weights: 279
  num_weight_broadcasts: 95291
custom_metrics: {}
date: 2023-08-14_16-28-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 37863
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00010110541916219518
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.70113115827553e-05
        total_loss: 0.37156444787979126
        var_gnorm: 65.02872467041016
        vf_explained_var: -1.0
        vf_loss: 0.7442539930343628
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9659.0
  learner_queue:
    size_count: 9665
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2611106216347558
  num_agent_steps_sampled: 4846450
  num_agent_steps_trained: 4829500
  num_env_steps_sampled: 4846450
  num_env_steps_trained: 4829500
  num_samples_added_to_queue: 4846000
  num_training_step_calls_since_last_synch_worker_weights: 279
  num_weight_broadcasts: 95291
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 197.12
    learner_load_time_ms: 1.494
    learner_load_wait_time_ms: 1.656
iterations_since_restore: 389
node_ip: 127.0.0.1
num_agent_steps_sampled: 4846450
num_agent_steps_trained: 4829500
num_env_steps_sampled: 4846450
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9938202187184
num_env_steps_trained: 4829500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9938202187184
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.193333333333335
  ram_util_percent: 76.88000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06421416569756178
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02513601181624643
  mean_inference_ms: 1.2035231612852944
  mean_raw_obs_processing_ms: 0.27356341630323333
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019125938415527344
    StateBufferConnector_ms: 0.0034350440615699405
    ViewRequirementAgentConnector_ms: 0.11655285244896299
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06421416569756178
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02513601181624643
    mean_inference_ms: 1.2035231612852944
    mean_raw_obs_processing_ms: 0.27356341630323333
time_since_restore: 3946.7412478923798
time_this_iter_s: 10.141402006149292
time_total_s: 3946.7412478923798
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998128
timesteps_total: 4846450
training_iteration: 389
trial_id: default
train step: 390
agent_timesteps_total: 4860050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018869930843137345
  StateBufferConnector_ms: 0.003351130575503943
  ViewRequirementAgentConnector_ms: 0.11479134829539173
counters:
  num_agent_steps_sampled: 4860050
  num_agent_steps_trained: 4843500
  num_env_steps_sampled: 4860050
  num_env_steps_trained: 4843500
  num_samples_added_to_queue: 4860000
  num_training_step_calls_since_last_synch_worker_weights: 901
  num_weight_broadcasts: 95557
custom_metrics: {}
date: 2023-08-14_16-28-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 37969
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00015958336007315665
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.15920117625501e-05
        total_loss: 1.0879930257797241
        var_gnorm: 65.02740478515625
        vf_explained_var: -1.0
        vf_loss: 2.1776249408721924
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9687.0
  learner_queue:
    size_count: 9692
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.40356688476182
  num_agent_steps_sampled: 4860050
  num_agent_steps_trained: 4843500
  num_env_steps_sampled: 4860050
  num_env_steps_trained: 4843500
  num_samples_added_to_queue: 4860000
  num_training_step_calls_since_last_synch_worker_weights: 901
  num_weight_broadcasts: 95557
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 199.256
    learner_load_time_ms: 1.482
    learner_load_wait_time_ms: 1.581
iterations_since_restore: 390
node_ip: 127.0.0.1
num_agent_steps_sampled: 4860050
num_agent_steps_trained: 4843500
num_env_steps_sampled: 4860050
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9934501963392
num_env_steps_trained: 4843500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.993257555055
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.942857142857136
  ram_util_percent: 76.69285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06419596311454957
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025125774721230943
  mean_inference_ms: 1.2032340448008483
  mean_raw_obs_processing_ms: 0.2734982985195917
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018869930843137345
    StateBufferConnector_ms: 0.003351130575503943
    ViewRequirementAgentConnector_ms: 0.11479134829539173
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06419596311454957
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025125774721230943
    mean_inference_ms: 1.2032340448008483
    mean_raw_obs_processing_ms: 0.2734982985195917
time_since_restore: 3956.8471128940582
time_this_iter_s: 10.105865001678467
time_total_s: 3956.8471128940582
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998138
timesteps_total: 4860050
training_iteration: 390
trial_id: default
train step: 391
agent_timesteps_total: 4873600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019175826378588407
  StateBufferConnector_ms: 0.0034402001578852817
  ViewRequirementAgentConnector_ms: 0.11611996956591336
counters:
  num_agent_steps_sampled: 4873600
  num_agent_steps_trained: 4857000
  num_env_steps_sampled: 4873600
  num_env_steps_trained: 4857000
  num_samples_added_to_queue: 4873500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 95823
custom_metrics: {}
date: 2023-08-14_16-29-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 38075
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 7.685507443966344e-05
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.000312368938466534
        total_loss: 1.7536025047302246
        var_gnorm: 65.02611541748047
        vf_explained_var: -1.0
        vf_loss: 3.5073490142822266
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9714.0
  learner_queue:
    size_count: 9717
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.938083151964686
  num_agent_steps_sampled: 4873600
  num_agent_steps_trained: 4857000
  num_env_steps_sampled: 4873600
  num_env_steps_trained: 4857000
  num_samples_added_to_queue: 4873500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 95823
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 277.781
    learner_load_time_ms: 1.467
    learner_load_wait_time_ms: 1.615
iterations_since_restore: 391
node_ip: 127.0.0.1
num_agent_steps_sampled: 4873600
num_agent_steps_trained: 4857000
num_env_steps_sampled: 4873600
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.8753437053833
num_env_steps_trained: 4857000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.8758036917104
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.44285714285714
  ram_util_percent: 76.32857142857142
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06418097827402004
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02511585398127631
  mean_inference_ms: 1.2029592768843036
  mean_raw_obs_processing_ms: 0.27344063183917794
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019175826378588407
    StateBufferConnector_ms: 0.0034402001578852817
    ViewRequirementAgentConnector_ms: 0.11611996956591336
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06418097827402004
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02511585398127631
    mean_inference_ms: 1.2029592768843036
    mean_raw_obs_processing_ms: 0.27344063183917794
time_since_restore: 3966.927969932556
time_this_iter_s: 10.080857038497925
time_total_s: 3966.927969932556
timers:
  sample_time_ms: 0.103
  synch_weights_time_ms: 0.282
  training_iteration_time_ms: 0.453
timestamp: 1691998148
timesteps_total: 4873600
training_iteration: 391
trial_id: default
train step: 392
agent_timesteps_total: 4887150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0190777598686938
  StateBufferConnector_ms: 0.0033864435159935142
  ViewRequirementAgentConnector_ms: 0.11563593486569962
counters:
  num_agent_steps_sampled: 4887150
  num_agent_steps_trained: 4870500
  num_env_steps_sampled: 4887150
  num_env_steps_trained: 4870500
  num_samples_added_to_queue: 4887000
  num_training_step_calls_since_last_synch_worker_weights: 384
  num_weight_broadcasts: 96091
custom_metrics: {}
date: 2023-08-14_16-29-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 38181
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00024369808670599014
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00016054727893788368
        total_loss: 0.11460170149803162
        var_gnorm: 65.02571105957031
        vf_explained_var: -1.0
        vf_loss: 0.2319614738225937
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9741.0
  learner_queue:
    size_count: 9747
    size_mean: 15.58
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.06
  num_agent_steps_sampled: 4887150
  num_agent_steps_trained: 4870500
  num_env_steps_sampled: 4887150
  num_env_steps_trained: 4870500
  num_samples_added_to_queue: 4887000
  num_training_step_calls_since_last_synch_worker_weights: 384
  num_weight_broadcasts: 96091
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 172.746
    learner_load_time_ms: 1.46
    learner_load_wait_time_ms: 1.508
iterations_since_restore: 392
node_ip: 127.0.0.1
num_agent_steps_sampled: 4887150
num_agent_steps_trained: 4870500
num_env_steps_sampled: 4887150
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9978032147737
num_env_steps_trained: 4870500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9978113209922
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.07857142857143
  ram_util_percent: 76.40714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06416575355731817
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02510611842222311
  mean_inference_ms: 1.2026776761141935
  mean_raw_obs_processing_ms: 0.27338417253265324
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0190777598686938
    StateBufferConnector_ms: 0.0033864435159935142
    ViewRequirementAgentConnector_ms: 0.11563593486569962
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06416575355731817
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02510611842222311
    mean_inference_ms: 1.2026776761141935
    mean_raw_obs_processing_ms: 0.27338417253265324
time_since_restore: 3977.065852880478
time_this_iter_s: 10.137882947921753
time_total_s: 3977.065852880478
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998158
timesteps_total: 4887150
training_iteration: 392
trial_id: default
train step: 393
agent_timesteps_total: 4900850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01872490953516077
  StateBufferConnector_ms: 0.0034109309867576317
  ViewRequirementAgentConnector_ms: 0.11488861507839626
counters:
  num_agent_steps_sampled: 4900850
  num_agent_steps_trained: 4884000
  num_env_steps_sampled: 4900850
  num_env_steps_trained: 4884000
  num_samples_added_to_queue: 4900500
  num_training_step_calls_since_last_synch_worker_weights: 448
  num_weight_broadcasts: 96362
custom_metrics: {}
date: 2023-08-14_16-29-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 38289
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00010603061673464254
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00011774894664995372
        total_loss: 0.3412884473800659
        var_gnorm: 65.02542114257812
        vf_explained_var: -1.0
        vf_loss: 0.6838726997375488
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9768.0
  learner_queue:
    size_count: 9774
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 4900850
  num_agent_steps_trained: 4884000
  num_env_steps_sampled: 4900850
  num_env_steps_trained: 4884000
  num_samples_added_to_queue: 4900500
  num_training_step_calls_since_last_synch_worker_weights: 448
  num_weight_broadcasts: 96362
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 185.237
    learner_load_time_ms: 1.44
    learner_load_wait_time_ms: 1.639
iterations_since_restore: 393
node_ip: 127.0.0.1
num_agent_steps_sampled: 4900850
num_agent_steps_trained: 4884000
num_env_steps_sampled: 4900850
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9984974877623
num_env_steps_trained: 4884000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9985194222475
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.78666666666666
  ram_util_percent: 76.42
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06414938352060241
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02509507239152013
  mean_inference_ms: 1.202367298226619
  mean_raw_obs_processing_ms: 0.2733234681817385
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01872490953516077
    StateBufferConnector_ms: 0.0034109309867576317
    ViewRequirementAgentConnector_ms: 0.11488861507839626
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06414938352060241
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02509507239152013
    mean_inference_ms: 1.202367298226619
    mean_raw_obs_processing_ms: 0.2733234681817385
time_since_restore: 3987.1963217258453
time_this_iter_s: 10.130468845367432
time_total_s: 3987.1963217258453
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998168
timesteps_total: 4900850
training_iteration: 393
trial_id: default
train step: 394
agent_timesteps_total: 4914550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01913039189464641
  StateBufferConnector_ms: 0.003371148739220961
  ViewRequirementAgentConnector_ms: 0.11338962698882481
counters:
  num_agent_steps_sampled: 4914550
  num_agent_steps_trained: 4898000
  num_env_steps_sampled: 4914550
  num_env_steps_trained: 4898000
  num_samples_added_to_queue: 4914500
  num_training_step_calls_since_last_synch_worker_weights: 691
  num_weight_broadcasts: 96629
custom_metrics: {}
date: 2023-08-14_16-29-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 38395
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002288477699039504
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0017485959688201547
        total_loss: 4.617470741271973
        var_gnorm: 65.02422332763672
        vf_explained_var: -1.0
        vf_loss: 9.240727424621582
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9796.0
  learner_queue:
    size_count: 9800
    size_mean: 15.5
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1532562594670797
  num_agent_steps_sampled: 4914550
  num_agent_steps_trained: 4898000
  num_env_steps_sampled: 4914550
  num_env_steps_trained: 4898000
  num_samples_added_to_queue: 4914500
  num_training_step_calls_since_last_synch_worker_weights: 691
  num_weight_broadcasts: 96629
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 232.654
    learner_load_time_ms: 1.527
    learner_load_wait_time_ms: 1.64
iterations_since_restore: 394
node_ip: 127.0.0.1
num_agent_steps_sampled: 4914550
num_agent_steps_trained: 4898000
num_env_steps_sampled: 4914550
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.995035189501
num_env_steps_trained: 4898000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.994926471023
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.535714285714285
  ram_util_percent: 76.26428571428572
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06413277361211286
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025084058899577502
  mean_inference_ms: 1.2020533367661181
  mean_raw_obs_processing_ms: 0.2732564539402671
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01913039189464641
    StateBufferConnector_ms: 0.003371148739220961
    ViewRequirementAgentConnector_ms: 0.11338962698882481
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06413277361211286
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025084058899577502
    mean_inference_ms: 1.2020533367661181
    mean_raw_obs_processing_ms: 0.2732564539402671
time_since_restore: 3997.296365737915
time_this_iter_s: 10.100044012069702
time_total_s: 3997.296365737915
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691998178
timesteps_total: 4914550
training_iteration: 394
trial_id: default
train step: 395
agent_timesteps_total: 4928050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01921541285964678
  StateBufferConnector_ms: 0.0034114099898428286
  ViewRequirementAgentConnector_ms: 0.11642878910280624
counters:
  num_agent_steps_sampled: 4928050
  num_agent_steps_trained: 4911500
  num_env_steps_sampled: 4928050
  num_env_steps_trained: 4911500
  num_samples_added_to_queue: 4928000
  num_training_step_calls_since_last_synch_worker_weights: 334
  num_weight_broadcasts: 96892
custom_metrics: {}
date: 2023-08-14_16-29-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 38501
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00019157648785039783
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0009685651166364551
        total_loss: 2.268214702606201
        var_gnorm: 65.02484130859375
        vf_explained_var: -1.0
        vf_loss: 4.536408424377441
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9823.0
  learner_queue:
    size_count: 9829
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1697863052711808
  num_agent_steps_sampled: 4928050
  num_agent_steps_trained: 4911500
  num_env_steps_sampled: 4928050
  num_env_steps_trained: 4911500
  num_samples_added_to_queue: 4928000
  num_training_step_calls_since_last_synch_worker_weights: 334
  num_weight_broadcasts: 96892
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 167.056
    learner_load_time_ms: 1.545
    learner_load_wait_time_ms: 1.597
iterations_since_restore: 395
node_ip: 127.0.0.1
num_agent_steps_sampled: 4928050
num_agent_steps_trained: 4911500
num_env_steps_sampled: 4928050
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9982297443714
num_env_steps_trained: 4911500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9982297443714
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.68571428571429
  ram_util_percent: 76.03571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06411787059011809
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025074519096547974
  mean_inference_ms: 1.2018064108929813
  mean_raw_obs_processing_ms: 0.2731937079880395
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01921541285964678
    StateBufferConnector_ms: 0.0034114099898428286
    ViewRequirementAgentConnector_ms: 0.11642878910280624
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06411787059011809
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025074519096547974
    mean_inference_ms: 1.2018064108929813
    mean_raw_obs_processing_ms: 0.2731937079880395
time_since_restore: 4007.432736635208
time_this_iter_s: 10.13637089729309
time_total_s: 4007.432736635208
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998189
timesteps_total: 4928050
training_iteration: 395
trial_id: default
train step: 396
agent_timesteps_total: 4941550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018834617902647774
  StateBufferConnector_ms: 0.0033918416725014743
  ViewRequirementAgentConnector_ms: 0.11499827762819687
counters:
  num_agent_steps_sampled: 4941550
  num_agent_steps_trained: 4925000
  num_env_steps_sampled: 4941550
  num_env_steps_trained: 4925000
  num_samples_added_to_queue: 4941500
  num_training_step_calls_since_last_synch_worker_weights: 825
  num_weight_broadcasts: 97152
custom_metrics: {}
date: 2023-08-14_16-29-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 38607
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.000107594758446794
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0006071235984563828
        total_loss: 3.692596197128296
        var_gnorm: 65.02178955078125
        vf_explained_var: -1.0
        vf_loss: 7.387482166290283
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9850.0
  learner_queue:
    size_count: 9854
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3249905660041508
  num_agent_steps_sampled: 4941550
  num_agent_steps_trained: 4925000
  num_env_steps_sampled: 4941550
  num_env_steps_trained: 4925000
  num_samples_added_to_queue: 4941500
  num_training_step_calls_since_last_synch_worker_weights: 825
  num_weight_broadcasts: 97152
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 233.242
    learner_load_time_ms: 1.558
    learner_load_wait_time_ms: 1.736
iterations_since_restore: 396
node_ip: 127.0.0.1
num_agent_steps_sampled: 4941550
num_agent_steps_trained: 4925000
num_env_steps_sampled: 4941550
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.99526859988
num_env_steps_trained: 4925000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.99526859988
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.00000000000001
  ram_util_percent: 75.20000000000002
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0641029969937375
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02506450912047165
  mean_inference_ms: 1.2015306771846561
  mean_raw_obs_processing_ms: 0.273136542409037
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018834617902647774
    StateBufferConnector_ms: 0.0033918416725014743
    ViewRequirementAgentConnector_ms: 0.11499827762819687
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0641029969937375
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02506450912047165
    mean_inference_ms: 1.2015306771846561
    mean_raw_obs_processing_ms: 0.273136542409037
time_since_restore: 4017.533586740494
time_this_iter_s: 10.100850105285645
time_total_s: 4017.533586740494
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998199
timesteps_total: 4941550
training_iteration: 396
trial_id: default
train step: 397
agent_timesteps_total: 4955150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01910890851702009
  StateBufferConnector_ms: 0.0033953076317196802
  ViewRequirementAgentConnector_ms: 0.11590435391380674
counters:
  num_agent_steps_sampled: 4955150
  num_agent_steps_trained: 4938500
  num_env_steps_sampled: 4955150
  num_env_steps_trained: 4938500
  num_samples_added_to_queue: 4955000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 97420
custom_metrics: {}
date: 2023-08-14_16-30-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 38712
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00018128615920431912
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0006557510350830853
        total_loss: 2.2326393127441406
        var_gnorm: 65.02272033691406
        vf_explained_var: -1.0
        vf_loss: 4.465780258178711
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9877.0
  learner_queue:
    size_count: 9884
    size_mean: 15.36
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3965672200076873
  num_agent_steps_sampled: 4955150
  num_agent_steps_trained: 4938500
  num_env_steps_sampled: 4955150
  num_env_steps_trained: 4938500
  num_samples_added_to_queue: 4955000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 97420
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 136.285
    learner_load_time_ms: 1.645
    learner_load_wait_time_ms: 1.581
iterations_since_restore: 397
node_ip: 127.0.0.1
num_agent_steps_sampled: 4955150
num_agent_steps_trained: 4938500
num_env_steps_sampled: 4955150
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.7590282235913
num_env_steps_trained: 4938500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.7608000748883
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.0
  ram_util_percent: 75.3
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06409023596696248
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025054727956240534
  mean_inference_ms: 1.2012583617426795
  mean_raw_obs_processing_ms: 0.2730833668948845
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01910890851702009
    StateBufferConnector_ms: 0.0033953076317196802
    ViewRequirementAgentConnector_ms: 0.11590435391380674
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06409023596696248
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025054727956240534
    mean_inference_ms: 1.2012583617426795
    mean_raw_obs_processing_ms: 0.2730833668948845
time_since_restore: 4027.681310892105
time_this_iter_s: 10.147724151611328
time_total_s: 4027.681310892105
timers:
  sample_time_ms: 0.041
  synch_weights_time_ms: 0.258
  training_iteration_time_ms: 0.369
timestamp: 1691998209
timesteps_total: 4955150
training_iteration: 397
trial_id: default
train step: 398
agent_timesteps_total: 4968600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019397150795414764
  StateBufferConnector_ms: 0.0035117257316157505
  ViewRequirementAgentConnector_ms: 0.11657476425170898
counters:
  num_agent_steps_sampled: 4968600
  num_agent_steps_trained: 4952000
  num_env_steps_sampled: 4968600
  num_env_steps_trained: 4952000
  num_samples_added_to_queue: 4968500
  num_training_step_calls_since_last_synch_worker_weights: 888
  num_weight_broadcasts: 97687
custom_metrics: {}
date: 2023-08-14_16-30-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 38818
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011563055159058422
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -6.0779089835705236e-05
        total_loss: 0.18099097907543182
        var_gnorm: 65.02067565917969
        vf_explained_var: -1.0
        vf_loss: 0.36325982213020325
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9904.0
  learner_queue:
    size_count: 9909
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6326665305566843
  num_agent_steps_sampled: 4968600
  num_agent_steps_trained: 4952000
  num_env_steps_sampled: 4968600
  num_env_steps_trained: 4952000
  num_samples_added_to_queue: 4968500
  num_training_step_calls_since_last_synch_worker_weights: 888
  num_weight_broadcasts: 97687
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 206.204
    learner_load_time_ms: 1.726
    learner_load_wait_time_ms: 1.615
iterations_since_restore: 398
node_ip: 127.0.0.1
num_agent_steps_sampled: 4968600
num_agent_steps_trained: 4952000
num_env_steps_sampled: 4968600
num_env_steps_sampled_this_iter: 13450
num_env_steps_sampled_throughput_per_sec: 1344.9993265870605
num_env_steps_trained: 4952000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9993240836666
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.835714285714275
  ram_util_percent: 75.05
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06407532458401981
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02504595762522504
  mean_inference_ms: 1.2010072537593401
  mean_raw_obs_processing_ms: 0.27302689343903946
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019397150795414764
    StateBufferConnector_ms: 0.0035117257316157505
    ViewRequirementAgentConnector_ms: 0.11657476425170898
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06407532458401981
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02504595762522504
    mean_inference_ms: 1.2010072537593401
    mean_raw_obs_processing_ms: 0.27302689343903946
time_since_restore: 4037.792090177536
time_this_iter_s: 10.110779285430908
time_total_s: 4037.792090177536
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998219
timesteps_total: 4968600
training_iteration: 398
trial_id: default
train step: 399
agent_timesteps_total: 4982000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01918951670328776
  StateBufferConnector_ms: 0.0034607024419875372
  ViewRequirementAgentConnector_ms: 0.11632987431117467
counters:
  num_agent_steps_sampled: 4982000
  num_agent_steps_trained: 4965500
  num_env_steps_sampled: 4982000
  num_env_steps_trained: 4965500
  num_samples_added_to_queue: 4982000
  num_training_step_calls_since_last_synch_worker_weights: 30
  num_weight_broadcasts: 97951
custom_metrics: {}
date: 2023-08-14_16-30-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 38923
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00010979634680552408
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00011019365047104657
        total_loss: 0.14572297036647797
        var_gnorm: 65.02091979980469
        vf_explained_var: -1.0
        vf_loss: 0.2927643060684204
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9931.0
  learner_queue:
    size_count: 9937
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2631706139710503
  num_agent_steps_sampled: 4982000
  num_agent_steps_trained: 4965500
  num_env_steps_sampled: 4982000
  num_env_steps_trained: 4965500
  num_samples_added_to_queue: 4982000
  num_training_step_calls_since_last_synch_worker_weights: 30
  num_weight_broadcasts: 97951
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 177.982
    learner_load_time_ms: 1.546
    learner_load_wait_time_ms: 1.638
iterations_since_restore: 399
node_ip: 127.0.0.1
num_agent_steps_sampled: 4982000
num_agent_steps_trained: 4965500
num_env_steps_sampled: 4982000
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9982748053828
num_env_steps_trained: 4965500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.998261930796
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.207142857142856
  ram_util_percent: 75.0
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06406152166482103
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025037816472883962
  mean_inference_ms: 1.2007896110600056
  mean_raw_obs_processing_ms: 0.27298103227097403
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01918951670328776
    StateBufferConnector_ms: 0.0034607024419875372
    ViewRequirementAgentConnector_ms: 0.11632987431117467
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06406152166482103
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025037816472883962
    mean_inference_ms: 1.2007896110600056
    mean_raw_obs_processing_ms: 0.27298103227097403
time_since_restore: 4047.931934118271
time_this_iter_s: 10.139843940734863
time_total_s: 4047.931934118271
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998229
timesteps_total: 4982000
training_iteration: 399
trial_id: default
train step: 400
agent_timesteps_total: 4992850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02360987663269043
  StateBufferConnector_ms: 0.008024454116821289
  ViewRequirementAgentConnector_ms: 0.14166975021362305
counters:
  num_agent_steps_sampled: 4992850
  num_agent_steps_trained: 4976000
  num_env_steps_sampled: 4992850
  num_env_steps_trained: 4976000
  num_samples_added_to_queue: 4992500
  num_training_step_calls_since_last_synch_worker_weights: 109
  num_weight_broadcasts: 98163
custom_metrics: {}
date: 2023-08-14_16-30-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 84
episodes_total: 39007
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00016504670202266425
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0006654231110587716
        total_loss: 1.5669320821762085
        var_gnorm: 65.02197265625
        vf_explained_var: -1.0
        vf_loss: 3.134183883666992
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9952.0
  learner_queue:
    size_count: 9959
    size_mean: 14.94
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7135927170713583
  num_agent_steps_sampled: 4992850
  num_agent_steps_trained: 4976000
  num_env_steps_sampled: 4992850
  num_env_steps_trained: 4976000
  num_samples_added_to_queue: 4992500
  num_training_step_calls_since_last_synch_worker_weights: 109
  num_weight_broadcasts: 98163
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 255.888
    learner_load_time_ms: 1.573
    learner_load_wait_time_ms: 1.678
iterations_since_restore: 400
node_ip: 127.0.0.1
num_agent_steps_sampled: 4992850
num_agent_steps_trained: 4976000
num_env_steps_sampled: 4992850
num_env_steps_sampled_this_iter: 10850
num_env_steps_sampled_throughput_per_sec: 1084.994257242081
num_env_steps_trained: 4976000
num_env_steps_trained_this_iter: 10500
num_env_steps_trained_throughput_per_sec: 1049.9944424923365
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10500
perf:
  cpu_util_percent: 67.18666666666665
  ram_util_percent: 76.14666666666668
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06411984972033351
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025044196269370583
  mean_inference_ms: 1.2010288059885006
  mean_raw_obs_processing_ms: 0.27307635255658474
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02360987663269043
    StateBufferConnector_ms: 0.008024454116821289
    ViewRequirementAgentConnector_ms: 0.14166975021362305
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 84
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06411984972033351
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025044196269370583
    mean_inference_ms: 1.2010288059885006
    mean_raw_obs_processing_ms: 0.27307635255658474
time_since_restore: 4058.0865638256073
time_this_iter_s: 10.154629707336426
time_total_s: 4058.0865638256073
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.047
timestamp: 1691998239
timesteps_total: 4992850
training_iteration: 400
trial_id: default
train step: 401
agent_timesteps_total: 5006150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019026031860938437
  StateBufferConnector_ms: 0.0034332275390625
  ViewRequirementAgentConnector_ms: 0.11690855026245117
counters:
  num_agent_steps_sampled: 5006150
  num_agent_steps_trained: 4989500
  num_env_steps_sampled: 5006150
  num_env_steps_trained: 4989500
  num_samples_added_to_queue: 5006000
  num_training_step_calls_since_last_synch_worker_weights: 715
  num_weight_broadcasts: 98425
custom_metrics: {}
date: 2023-08-14_16-30-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 39111
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001343809417448938
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0004448087129276246
        total_loss: 1.2537400722503662
        var_gnorm: 65.02099609375
        vf_explained_var: -1.0
        vf_loss: 2.5097134113311768
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 9979.0
  learner_queue:
    size_count: 9984
    size_mean: 14.72
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8334666618185342
  num_agent_steps_sampled: 5006150
  num_agent_steps_trained: 4989500
  num_env_steps_sampled: 5006150
  num_env_steps_trained: 4989500
  num_samples_added_to_queue: 5006000
  num_training_step_calls_since_last_synch_worker_weights: 715
  num_weight_broadcasts: 98425
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 224.602
    learner_load_time_ms: 1.61
    learner_load_wait_time_ms: 1.759
iterations_since_restore: 401
node_ip: 127.0.0.1
num_agent_steps_sampled: 5006150
num_agent_steps_trained: 4989500
num_env_steps_sampled: 5006150
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.993753224149
num_env_steps_trained: 4989500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9936592876702
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.96428571428572
  ram_util_percent: 75.89285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06407711406995306
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02503781181599822
  mean_inference_ms: 1.2009792260673513
  mean_raw_obs_processing_ms: 0.27303304303438924
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019026031860938437
    StateBufferConnector_ms: 0.0034332275390625
    ViewRequirementAgentConnector_ms: 0.11690855026245117
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06407711406995306
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02503781181599822
    mean_inference_ms: 1.2009792260673513
    mean_raw_obs_processing_ms: 0.27303304303438924
time_since_restore: 4068.247562646866
time_this_iter_s: 10.160998821258545
time_total_s: 4068.247562646866
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998249
timesteps_total: 5006150
training_iteration: 401
trial_id: default
train step: 402
agent_timesteps_total: 5019400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019302047215975247
  StateBufferConnector_ms: 0.003504294615525466
  ViewRequirementAgentConnector_ms: 0.11868729041172908
counters:
  num_agent_steps_sampled: 5019400
  num_agent_steps_trained: 5002500
  num_env_steps_sampled: 5019400
  num_env_steps_trained: 5002500
  num_samples_added_to_queue: 5019000
  num_training_step_calls_since_last_synch_worker_weights: 582
  num_weight_broadcasts: 98686
custom_metrics: {}
date: 2023-08-14_16-31-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 39215
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00022152788005769253
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0008009255980141461
        total_loss: 0.8917955160140991
        var_gnorm: 65.02035522460938
        vf_explained_var: -1.0
        vf_loss: 1.7874081134796143
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10005.0
  learner_queue:
    size_count: 10011
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3332666649999165
  num_agent_steps_sampled: 5019400
  num_agent_steps_trained: 5002500
  num_env_steps_sampled: 5019400
  num_env_steps_trained: 5002500
  num_samples_added_to_queue: 5019000
  num_training_step_calls_since_last_synch_worker_weights: 582
  num_weight_broadcasts: 98686
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 195.692
    learner_load_time_ms: 1.597
    learner_load_wait_time_ms: 1.54
iterations_since_restore: 402
node_ip: 127.0.0.1
num_agent_steps_sampled: 5019400
num_agent_steps_trained: 5002500
num_env_steps_sampled: 5019400
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.993650347621
num_env_steps_trained: 5002500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.993770152383
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 55.45
  ram_util_percent: 76.84285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06406680268210938
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025030626370405446
  mean_inference_ms: 1.2007851695779888
  mean_raw_obs_processing_ms: 0.27299419437819833
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019302047215975247
    StateBufferConnector_ms: 0.003504294615525466
    ViewRequirementAgentConnector_ms: 0.11868729041172908
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06406680268210938
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025030626370405446
    mean_inference_ms: 1.2007851695779888
    mean_raw_obs_processing_ms: 0.27299419437819833
time_since_restore: 4078.373361825943
time_this_iter_s: 10.125799179077148
time_total_s: 4078.373361825943
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998260
timesteps_total: 5019400
training_iteration: 402
trial_id: default
train step: 403
agent_timesteps_total: 5032850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018917368008540228
  StateBufferConnector_ms: 0.0033869193150446964
  ViewRequirementAgentConnector_ms: 0.11554108216212346
counters:
  num_agent_steps_sampled: 5032850
  num_agent_steps_trained: 5016000
  num_env_steps_sampled: 5032850
  num_env_steps_trained: 5016000
  num_samples_added_to_queue: 5032500
  num_training_step_calls_since_last_synch_worker_weights: 412
  num_weight_broadcasts: 98952
custom_metrics: {}
date: 2023-08-14_16-31-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 39319
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011858668585773557
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00016723859880585223
        total_loss: 0.6703222990036011
        var_gnorm: 65.01921081542969
        vf_explained_var: -1.0
        vf_loss: 1.3421649932861328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10032.0
  learner_queue:
    size_count: 10038
    size_mean: 15.14
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5749285698088027
  num_agent_steps_sampled: 5032850
  num_agent_steps_trained: 5016000
  num_env_steps_sampled: 5032850
  num_env_steps_trained: 5016000
  num_samples_added_to_queue: 5032500
  num_training_step_calls_since_last_synch_worker_weights: 412
  num_weight_broadcasts: 98952
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 192.666
    learner_load_time_ms: 1.754
    learner_load_wait_time_ms: 1.558
iterations_since_restore: 403
node_ip: 127.0.0.1
num_agent_steps_sampled: 5032850
num_agent_steps_trained: 5016000
num_env_steps_sampled: 5032850
num_env_steps_sampled_this_iter: 13450
num_env_steps_sampled_throughput_per_sec: 1344.9986531747952
num_env_steps_trained: 5016000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.99864816801
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.3
  ram_util_percent: 76.7
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06405397331994284
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025022684153161643
  mean_inference_ms: 1.2005460574792028
  mean_raw_obs_processing_ms: 0.2729458789955167
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018917368008540228
    StateBufferConnector_ms: 0.0033869193150446964
    ViewRequirementAgentConnector_ms: 0.11554108216212346
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06405397331994284
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025022684153161643
    mean_inference_ms: 1.2005460574792028
    mean_raw_obs_processing_ms: 0.2729458789955167
time_since_restore: 4088.5095739364624
time_this_iter_s: 10.13621211051941
time_total_s: 4088.5095739364624
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998270
timesteps_total: 5032850
training_iteration: 403
trial_id: default
train step: 404
agent_timesteps_total: 5045800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02042873232972388
  StateBufferConnector_ms: 0.003657855239568972
  ViewRequirementAgentConnector_ms: 0.12245435340731751
counters:
  num_agent_steps_sampled: 5045800
  num_agent_steps_trained: 5029000
  num_env_steps_sampled: 5045800
  num_env_steps_trained: 5029000
  num_samples_added_to_queue: 5045500
  num_training_step_calls_since_last_synch_worker_weights: 1283
  num_weight_broadcasts: 99208
custom_metrics: {}
date: 2023-08-14_16-31-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 39421
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011928384628845379
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00010057558392873034
        total_loss: 0.31707465648651123
        var_gnorm: 65.01953125
        vf_explained_var: -1.0
        vf_loss: 0.6355433464050293
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10058.0
  learner_queue:
    size_count: 10062
    size_mean: 15.22
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4323407415835103
  num_agent_steps_sampled: 5045800
  num_agent_steps_trained: 5029000
  num_env_steps_sampled: 5045800
  num_env_steps_trained: 5029000
  num_samples_added_to_queue: 5045500
  num_training_step_calls_since_last_synch_worker_weights: 1283
  num_weight_broadcasts: 99208
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 283.296
    learner_load_time_ms: 1.66
    learner_load_wait_time_ms: 1.573
iterations_since_restore: 404
node_ip: 127.0.0.1
num_agent_steps_sampled: 5045800
num_agent_steps_trained: 5029000
num_env_steps_sampled: 5045800
num_env_steps_sampled_this_iter: 12950
num_env_steps_sampled_throughput_per_sec: 1294.9968816117039
num_env_steps_trained: 5029000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9968695715945
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.707142857142856
  ram_util_percent: 76.99285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06404689988639675
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02501713163668004
  mean_inference_ms: 1.2004275230294235
  mean_raw_obs_processing_ms: 0.27291886031353807
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02042873232972388
    StateBufferConnector_ms: 0.003657855239568972
    ViewRequirementAgentConnector_ms: 0.12245435340731751
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06404689988639675
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02501713163668004
    mean_inference_ms: 1.2004275230294235
    mean_raw_obs_processing_ms: 0.27291886031353807
time_since_restore: 4098.604659080505
time_this_iter_s: 10.095085144042969
time_total_s: 4098.604659080505
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1691998280
timesteps_total: 5045800
training_iteration: 404
trial_id: default
train step: 405
agent_timesteps_total: 5058850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01943984834274443
  StateBufferConnector_ms: 0.0036041335304184715
  ViewRequirementAgentConnector_ms: 0.1202441678188815
counters:
  num_agent_steps_sampled: 5058850
  num_agent_steps_trained: 5042000
  num_env_steps_sampled: 5058850
  num_env_steps_trained: 5042000
  num_samples_added_to_queue: 5058500
  num_training_step_calls_since_last_synch_worker_weights: 737
  num_weight_broadcasts: 99466
custom_metrics: {}
date: 2023-08-14_16-31-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 101
episodes_total: 39522
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001190373586723581
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0006569961551576853
        total_loss: 3.3578763008117676
        var_gnorm: 65.01847839355469
        vf_explained_var: -1.0
        vf_loss: 6.715628623962402
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10084.0
  learner_queue:
    size_count: 10089
    size_mean: 15.52
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0047885349664376
  num_agent_steps_sampled: 5058850
  num_agent_steps_trained: 5042000
  num_env_steps_sampled: 5058850
  num_env_steps_trained: 5042000
  num_samples_added_to_queue: 5058500
  num_training_step_calls_since_last_synch_worker_weights: 737
  num_weight_broadcasts: 99466
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 227.364
    learner_load_time_ms: 1.742
    learner_load_wait_time_ms: 1.577
iterations_since_restore: 405
node_ip: 127.0.0.1
num_agent_steps_sampled: 5058850
num_agent_steps_trained: 5042000
num_env_steps_sampled: 5058850
num_env_steps_sampled_this_iter: 13050
num_env_steps_sampled_throughput_per_sec: 1304.9967330775983
num_env_steps_trained: 5042000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9967455945423
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.34285714285714
  ram_util_percent: 77.05714285714285
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06403655816730093
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.025011387933481417
  mean_inference_ms: 1.2002930214106078
  mean_raw_obs_processing_ms: 0.272889183468187
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01943984834274443
    StateBufferConnector_ms: 0.0036041335304184715
    ViewRequirementAgentConnector_ms: 0.1202441678188815
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06403655816730093
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.025011387933481417
    mean_inference_ms: 1.2002930214106078
    mean_raw_obs_processing_ms: 0.272889183468187
time_since_restore: 4108.722628116608
time_this_iter_s: 10.117969036102295
time_total_s: 4108.722628116608
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998290
timesteps_total: 5058850
training_iteration: 405
trial_id: default
train step: 406
agent_timesteps_total: 5072450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019286280480500694
  StateBufferConnector_ms: 0.0034867046035338784
  ViewRequirementAgentConnector_ms: 0.11767561190596251
counters:
  num_agent_steps_sampled: 5072450
  num_agent_steps_trained: 5055500
  num_env_steps_sampled: 5072450
  num_env_steps_trained: 5055500
  num_samples_added_to_queue: 5072000
  num_training_step_calls_since_last_synch_worker_weights: 65
  num_weight_broadcasts: 99731
custom_metrics: {}
date: 2023-08-14_16-31-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 39629
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00013555279292631894
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0003163232759106904
        total_loss: 0.635545551776886
        var_gnorm: 65.01826477050781
        vf_explained_var: -1.0
        vf_loss: 1.2730792760849
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10111.0
  learner_queue:
    size_count: 10118
    size_mean: 15.26
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5074481748969017
  num_agent_steps_sampled: 5072450
  num_agent_steps_trained: 5055500
  num_env_steps_sampled: 5072450
  num_env_steps_trained: 5055500
  num_samples_added_to_queue: 5072000
  num_training_step_calls_since_last_synch_worker_weights: 65
  num_weight_broadcasts: 99731
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 153.894
    learner_load_time_ms: 1.719
    learner_load_wait_time_ms: 1.456
iterations_since_restore: 406
node_ip: 127.0.0.1
num_agent_steps_sampled: 5072450
num_agent_steps_trained: 5055500
num_env_steps_sampled: 5072450
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.997146612432
num_env_steps_trained: 5055500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.997167593223
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.21428571428572
  ram_util_percent: 75.9
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06402750229135255
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02500204985731517
  mean_inference_ms: 1.200027401577039
  mean_raw_obs_processing_ms: 0.2728339533916864
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019286280480500694
    StateBufferConnector_ms: 0.0034867046035338784
    ViewRequirementAgentConnector_ms: 0.11767561190596251
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06402750229135255
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02500204985731517
    mean_inference_ms: 1.200027401577039
    mean_raw_obs_processing_ms: 0.2728339533916864
time_since_restore: 4118.875684022903
time_this_iter_s: 10.153055906295776
time_total_s: 4118.875684022903
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998300
timesteps_total: 5072450
training_iteration: 406
trial_id: default
train step: 407
agent_timesteps_total: 5086000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01891019209375921
  StateBufferConnector_ms: 0.0034316530767476783
  ViewRequirementAgentConnector_ms: 0.1166267215080981
counters:
  num_agent_steps_sampled: 5086000
  num_agent_steps_trained: 5069500
  num_env_steps_sampled: 5086000
  num_env_steps_trained: 5069500
  num_samples_added_to_queue: 5086000
  num_training_step_calls_since_last_synch_worker_weights: 283
  num_weight_broadcasts: 99998
custom_metrics: {}
date: 2023-08-14_16-31-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 39735
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00012570632679853588
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00018949387595057487
        total_loss: 0.9195963144302368
        var_gnorm: 65.01813507080078
        vf_explained_var: -1.0
        vf_loss: 1.8400707244873047
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10139.0
  learner_queue:
    size_count: 10144
    size_mean: 15.22
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5269577597301114
  num_agent_steps_sampled: 5086000
  num_agent_steps_trained: 5069500
  num_env_steps_sampled: 5086000
  num_env_steps_trained: 5069500
  num_samples_added_to_queue: 5086000
  num_training_step_calls_since_last_synch_worker_weights: 283
  num_weight_broadcasts: 99998
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 200.556
    learner_load_time_ms: 1.692
    learner_load_wait_time_ms: 1.666
iterations_since_restore: 407
node_ip: 127.0.0.1
num_agent_steps_sampled: 5086000
num_agent_steps_trained: 5069500
num_env_steps_sampled: 5086000
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9960910194632
num_env_steps_trained: 5069500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9959612009213
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.1
  ram_util_percent: 75.62000000000002
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06400733358803587
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02499276118940057
  mean_inference_ms: 1.1997915692710484
  mean_raw_obs_processing_ms: 0.27277641514958484
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01891019209375921
    StateBufferConnector_ms: 0.0034316530767476783
    ViewRequirementAgentConnector_ms: 0.1166267215080981
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06400733358803587
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02499276118940057
    mean_inference_ms: 1.1997915692710484
    mean_raw_obs_processing_ms: 0.27277641514958484
time_since_restore: 4129.005117177963
time_this_iter_s: 10.129433155059814
time_total_s: 4129.005117177963
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691998310
timesteps_total: 5086000
training_iteration: 407
trial_id: default
train step: 408
agent_timesteps_total: 5098500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020529747009277344
  StateBufferConnector_ms: 0.0036008358001708984
  ViewRequirementAgentConnector_ms: 0.12333345413208008
counters:
  num_agent_steps_sampled: 5098500
  num_agent_steps_trained: 5082000
  num_env_steps_sampled: 5098500
  num_env_steps_trained: 5082000
  num_samples_added_to_queue: 5098500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 100245
custom_metrics: {}
date: 2023-08-14_16-32-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 97
episodes_total: 39832
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00017416565970052034
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00023427825362887233
        total_loss: 0.8805490136146545
        var_gnorm: 65.01795959472656
        vf_explained_var: -1.0
        vf_loss: 1.7623710632324219
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10164.0
  learner_queue:
    size_count: 10167
    size_mean: 15.3
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.40356688476182
  num_agent_steps_sampled: 5098500
  num_agent_steps_trained: 5082000
  num_env_steps_sampled: 5098500
  num_env_steps_trained: 5082000
  num_samples_added_to_queue: 5098500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 100245
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 313.61
    learner_load_time_ms: 1.696
    learner_load_wait_time_ms: 1.675
iterations_since_restore: 408
node_ip: 127.0.0.1
num_agent_steps_sampled: 5098500
num_agent_steps_trained: 5082000
num_env_steps_sampled: 5098500
num_env_steps_sampled_this_iter: 12500
num_env_steps_sampled_throughput_per_sec: 1247.482077176818
num_env_steps_trained: 5082000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1247.482077176818
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.885714285714286
  ram_util_percent: 76.3714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06402153278441633
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024990374569297983
  mean_inference_ms: 1.1997810956010206
  mean_raw_obs_processing_ms: 0.27277301886746136
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020529747009277344
    StateBufferConnector_ms: 0.0036008358001708984
    ViewRequirementAgentConnector_ms: 0.12333345413208008
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06402153278441633
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024990374569297983
    mean_inference_ms: 1.1997810956010206
    mean_raw_obs_processing_ms: 0.27277301886746136
time_since_restore: 4139.107142210007
time_this_iter_s: 10.102025032043457
time_total_s: 4139.107142210007
timers:
  sample_time_ms: 0.05
  synch_weights_time_ms: 0.482
  training_iteration_time_ms: 2.182
timestamp: 1691998320
timesteps_total: 5098500
training_iteration: 408
trial_id: default
train step: 409
agent_timesteps_total: 5110250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022589683532714844
  StateBufferConnector_ms: 0.003960132598876953
  ViewRequirementAgentConnector_ms: 0.13286566734313965
counters:
  num_agent_steps_sampled: 5110250
  num_agent_steps_trained: 5093500
  num_env_steps_sampled: 5110250
  num_env_steps_trained: 5093500
  num_samples_added_to_queue: 5110000
  num_training_step_calls_since_last_synch_worker_weights: 1620
  num_weight_broadcasts: 100477
custom_metrics: {}
date: 2023-08-14_16-32-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 93
episodes_total: 39925
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011879569501616061
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.000193574363947846
        total_loss: 0.33776596188545227
        var_gnorm: 65.01746368408203
        vf_explained_var: -1.0
        vf_loss: 0.6763327717781067
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10187.0
  learner_queue:
    size_count: 10191
    size_mean: 15.44
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.116422858956229
  num_agent_steps_sampled: 5110250
  num_agent_steps_trained: 5093500
  num_env_steps_sampled: 5110250
  num_env_steps_trained: 5093500
  num_samples_added_to_queue: 5110000
  num_training_step_calls_since_last_synch_worker_weights: 1620
  num_weight_broadcasts: 100477
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 282.714
    learner_load_time_ms: 1.46
    learner_load_wait_time_ms: 1.725
iterations_since_restore: 409
node_ip: 127.0.0.1
num_agent_steps_sampled: 5110250
num_agent_steps_trained: 5093500
num_env_steps_sampled: 5110250
num_env_steps_sampled_this_iter: 11750
num_env_steps_sampled_throughput_per_sec: 1174.9978989400286
num_env_steps_trained: 5093500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9979436434323
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 57.857142857142854
  ram_util_percent: 77.37857142857145
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0640335578475532
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024992440636870963
  mean_inference_ms: 1.1999381318825582
  mean_raw_obs_processing_ms: 0.2727956208421088
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022589683532714844
    StateBufferConnector_ms: 0.003960132598876953
    ViewRequirementAgentConnector_ms: 0.13286566734313965
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 93
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0640335578475532
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024992440636870963
    mean_inference_ms: 1.1999381318825582
    mean_raw_obs_processing_ms: 0.2727956208421088
time_since_restore: 4149.219857215881
time_this_iter_s: 10.112715005874634
time_total_s: 4149.219857215881
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998331
timesteps_total: 5110250
training_iteration: 409
trial_id: default
train step: 410
agent_timesteps_total: 5122550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0218660831451416
  StateBufferConnector_ms: 0.003917217254638672
  ViewRequirementAgentConnector_ms: 0.12893915176391602
counters:
  num_agent_steps_sampled: 5122550
  num_agent_steps_trained: 5106000
  num_env_steps_sampled: 5122550
  num_env_steps_trained: 5106000
  num_samples_added_to_queue: 5122500
  num_training_step_calls_since_last_synch_worker_weights: 905
  num_weight_broadcasts: 100719
custom_metrics: {}
date: 2023-08-14_16-32-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 40021
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00012109705858165398
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0006096350844018161
        total_loss: 2.7558791637420654
        var_gnorm: 65.01691436767578
        vf_explained_var: -1.0
        vf_loss: 5.514188766479492
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10212.0
  learner_queue:
    size_count: 10219
    size_mean: 15.36
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3965672200076873
  num_agent_steps_sampled: 5122550
  num_agent_steps_trained: 5106000
  num_env_steps_sampled: 5122550
  num_env_steps_trained: 5106000
  num_samples_added_to_queue: 5122500
  num_training_step_calls_since_last_synch_worker_weights: 905
  num_weight_broadcasts: 100719
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 143.297
    learner_load_time_ms: 1.686
    learner_load_wait_time_ms: 2.065
iterations_since_restore: 410
node_ip: 127.0.0.1
num_agent_steps_sampled: 5122550
num_agent_steps_trained: 5106000
num_env_steps_sampled: 5122550
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.9951026634658
num_env_steps_trained: 5106000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9950230319776
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.83571428571429
  ram_util_percent: 78.05
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06403348636608408
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024993149865347074
  mean_inference_ms: 1.200019430218276
  mean_raw_obs_processing_ms: 0.27280598867245504
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0218660831451416
    StateBufferConnector_ms: 0.003917217254638672
    ViewRequirementAgentConnector_ms: 0.12893915176391602
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06403348636608408
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024993149865347074
    mean_inference_ms: 1.200019430218276
    mean_raw_obs_processing_ms: 0.27280598867245504
time_since_restore: 4159.418014287949
time_this_iter_s: 10.19815707206726
time_total_s: 4159.418014287949
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691998341
timesteps_total: 5122550
training_iteration: 410
trial_id: default
train step: 411
agent_timesteps_total: 5135450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019918203353881836
  StateBufferConnector_ms: 0.0035948753356933594
  ViewRequirementAgentConnector_ms: 0.12276649475097656
counters:
  num_agent_steps_sampled: 5135450
  num_agent_steps_trained: 5118500
  num_env_steps_sampled: 5135450
  num_env_steps_trained: 5118500
  num_samples_added_to_queue: 5135000
  num_training_step_calls_since_last_synch_worker_weights: 94
  num_weight_broadcasts: 100973
custom_metrics: {}
date: 2023-08-14_16-32-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 40121
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011946236918447539
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00012513709953054786
        total_loss: 0.16370519995689392
        var_gnorm: 65.01747131347656
        vf_explained_var: -1.0
        vf_loss: 0.32835474610328674
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10237.0
  learner_queue:
    size_count: 10245
    size_mean: 14.78
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.0128586636920143
  num_agent_steps_sampled: 5135450
  num_agent_steps_trained: 5118500
  num_env_steps_sampled: 5135450
  num_env_steps_trained: 5118500
  num_samples_added_to_queue: 5135000
  num_training_step_calls_since_last_synch_worker_weights: 94
  num_weight_broadcasts: 100973
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 125.687
    learner_load_time_ms: 5.666
    learner_load_wait_time_ms: 1.464
iterations_since_restore: 411
node_ip: 127.0.0.1
num_agent_steps_sampled: 5135450
num_agent_steps_trained: 5118500
num_env_steps_sampled: 5135450
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9940641199498
num_env_steps_trained: 5118500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9942481782462
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.553333333333335
  ram_util_percent: 77.76666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06401978867467933
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0249893814380816
  mean_inference_ms: 1.199947547064146
  mean_raw_obs_processing_ms: 0.2727809034504612
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019918203353881836
    StateBufferConnector_ms: 0.0035948753356933594
    ViewRequirementAgentConnector_ms: 0.12276649475097656
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06401978867467933
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0249893814380816
    mean_inference_ms: 1.199947547064146
    mean_raw_obs_processing_ms: 0.2727809034504612
time_since_restore: 4169.6014752388
time_this_iter_s: 10.18346095085144
time_total_s: 4169.6014752388
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998351
timesteps_total: 5135450
training_iteration: 411
trial_id: default
train step: 412
agent_timesteps_total: 5148050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020403623580932617
  StateBufferConnector_ms: 0.003806591033935547
  ViewRequirementAgentConnector_ms: 0.12306833267211914
counters:
  num_agent_steps_sampled: 5148050
  num_agent_steps_trained: 5131500
  num_env_steps_sampled: 5148050
  num_env_steps_trained: 5131500
  num_samples_added_to_queue: 5148000
  num_training_step_calls_since_last_synch_worker_weights: 555
  num_weight_broadcasts: 101222
custom_metrics: {}
date: 2023-08-14_16-32-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 99
episodes_total: 40220
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00014800588542129844
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00014011198072694242
        total_loss: 0.8642519116401672
        var_gnorm: 65.01779174804688
        vf_explained_var: -1.0
        vf_loss: 1.729703664779663
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10263.0
  learner_queue:
    size_count: 10270
    size_mean: 14.6
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.0784609690826525
  num_agent_steps_sampled: 5148050
  num_agent_steps_trained: 5131500
  num_env_steps_sampled: 5148050
  num_env_steps_trained: 5131500
  num_samples_added_to_queue: 5148000
  num_training_step_calls_since_last_synch_worker_weights: 555
  num_weight_broadcasts: 101222
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 128.797
    learner_load_time_ms: 5.67
    learner_load_wait_time_ms: 1.51
iterations_since_restore: 412
node_ip: 127.0.0.1
num_agent_steps_sampled: 5148050
num_agent_steps_trained: 5131500
num_env_steps_sampled: 5148050
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.998738290143
num_env_steps_trained: 5131500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9986982358616
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.064285714285724
  ram_util_percent: 77.59285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06402199723427592
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024986959565968067
  mean_inference_ms: 1.1999269936938453
  mean_raw_obs_processing_ms: 0.27277204121273513
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020403623580932617
    StateBufferConnector_ms: 0.003806591033935547
    ViewRequirementAgentConnector_ms: 0.12306833267211914
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06402199723427592
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024986959565968067
    mean_inference_ms: 1.1999269936938453
    mean_raw_obs_processing_ms: 0.27277204121273513
time_since_restore: 4179.7607481479645
time_this_iter_s: 10.159272909164429
time_total_s: 4179.7607481479645
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998361
timesteps_total: 5148050
training_iteration: 412
trial_id: default
train step: 413
agent_timesteps_total: 5161250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018930902668074064
  StateBufferConnector_ms: 0.0033579620660520067
  ViewRequirementAgentConnector_ms: 0.11660047605925915
counters:
  num_agent_steps_sampled: 5161250
  num_agent_steps_trained: 5144500
  num_env_steps_sampled: 5161250
  num_env_steps_trained: 5144500
  num_samples_added_to_queue: 5161000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 101483
custom_metrics: {}
date: 2023-08-14_16-32-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 40322
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00017711347027216107
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00021779430971946567
        total_loss: 0.4601810872554779
        var_gnorm: 65.01856994628906
        vf_explained_var: -1.0
        vf_loss: 0.9225689172744751
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10289.0
  learner_queue:
    size_count: 10293
    size_mean: 14.7
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.0615528128088303
  num_agent_steps_sampled: 5161250
  num_agent_steps_trained: 5144500
  num_env_steps_sampled: 5161250
  num_env_steps_trained: 5144500
  num_samples_added_to_queue: 5161000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 101483
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 269.064
    learner_load_time_ms: 7.092
    learner_load_wait_time_ms: 1.591
iterations_since_restore: 413
node_ip: 127.0.0.1
num_agent_steps_sampled: 5161250
num_agent_steps_trained: 5144500
num_env_steps_sampled: 5161250
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.8290702936688
num_env_steps_trained: 5144500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.8316601377041
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.471428571428575
  ram_util_percent: 77.87142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06401057143952019
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024979227649608166
  mean_inference_ms: 1.199785864301093
  mean_raw_obs_processing_ms: 0.27272472999754904
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018930902668074064
    StateBufferConnector_ms: 0.0033579620660520067
    ViewRequirementAgentConnector_ms: 0.11660047605925915
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06401057143952019
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024979227649608166
    mean_inference_ms: 1.199785864301093
    mean_raw_obs_processing_ms: 0.27272472999754904
time_since_restore: 4189.864945888519
time_this_iter_s: 10.10419774055481
time_total_s: 4189.864945888519
timers:
  sample_time_ms: 0.034
  synch_weights_time_ms: 0.255
  training_iteration_time_ms: 0.352
timestamp: 1691998371
timesteps_total: 5161250
training_iteration: 413
trial_id: default
train step: 414
agent_timesteps_total: 5173450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021834373474121094
  StateBufferConnector_ms: 0.0039031505584716797
  ViewRequirementAgentConnector_ms: 0.1297435760498047
counters:
  num_agent_steps_sampled: 5173450
  num_agent_steps_trained: 5156500
  num_env_steps_sampled: 5173450
  num_env_steps_trained: 5156500
  num_samples_added_to_queue: 5173000
  num_training_step_calls_since_last_synch_worker_weights: 463
  num_weight_broadcasts: 101725
custom_metrics: {}
date: 2023-08-14_16-33-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 40418
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001510505680926144
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00026333669666200876
        total_loss: 0.44328954815864563
        var_gnorm: 65.01832580566406
        vf_explained_var: -1.0
        vf_loss: 0.8875629305839539
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10313.0
  learner_queue:
    size_count: 10319
    size_mean: 15.14
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.587576769797291
  num_agent_steps_sampled: 5173450
  num_agent_steps_trained: 5156500
  num_env_steps_sampled: 5173450
  num_env_steps_trained: 5156500
  num_samples_added_to_queue: 5173000
  num_training_step_calls_since_last_synch_worker_weights: 463
  num_weight_broadcasts: 101725
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 192.965
    learner_load_time_ms: 7.076
    learner_load_wait_time_ms: 1.529
iterations_since_restore: 414
node_ip: 127.0.0.1
num_agent_steps_sampled: 5173450
num_agent_steps_trained: 5156500
num_env_steps_sampled: 5173450
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.9945316559804
num_env_steps_trained: 5156500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9946213009644
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 54.453333333333326
  ram_util_percent: 76.76666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06402397003921356
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024979683829330305
  mean_inference_ms: 1.1998301224435362
  mean_raw_obs_processing_ms: 0.27273880008720824
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021834373474121094
    StateBufferConnector_ms: 0.0039031505584716797
    ViewRequirementAgentConnector_ms: 0.1297435760498047
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06402397003921356
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024979683829330305
    mean_inference_ms: 1.1998301224435362
    mean_raw_obs_processing_ms: 0.27273880008720824
time_since_restore: 4200.007083892822
time_this_iter_s: 10.142138004302979
time_total_s: 4200.007083892822
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998381
timesteps_total: 5173450
training_iteration: 414
trial_id: default
train step: 415
agent_timesteps_total: 5187050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019653113383167196
  StateBufferConnector_ms: 0.0034215315332952537
  ViewRequirementAgentConnector_ms: 0.11705430048816609
counters:
  num_agent_steps_sampled: 5187050
  num_agent_steps_trained: 5170500
  num_env_steps_sampled: 5187050
  num_env_steps_trained: 5170500
  num_samples_added_to_queue: 5187000
  num_training_step_calls_since_last_synch_worker_weights: 235
  num_weight_broadcasts: 101994
custom_metrics: {}
date: 2023-08-14_16-33-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 40524
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00015689284191466868
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0008236112771555781
        total_loss: 2.6960556507110596
        var_gnorm: 65.01773834228516
        vf_explained_var: -1.0
        vf_loss: 5.395327091217041
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10341.0
  learner_queue:
    size_count: 10347
    size_mean: 15.24
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4636939570825591
  num_agent_steps_sampled: 5187050
  num_agent_steps_trained: 5170500
  num_env_steps_sampled: 5187050
  num_env_steps_trained: 5170500
  num_samples_added_to_queue: 5187000
  num_training_step_calls_since_last_synch_worker_weights: 235
  num_weight_broadcasts: 101994
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 159.389
    learner_load_time_ms: 7.223
    learner_load_wait_time_ms: 1.546
iterations_since_restore: 415
node_ip: 127.0.0.1
num_agent_steps_sampled: 5187050
num_agent_steps_trained: 5170500
num_env_steps_sampled: 5187050
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9951038536863
num_env_steps_trained: 5170500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.994959849383
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.9
  ram_util_percent: 76.0
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06400061053205006
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024970685673167757
  mean_inference_ms: 1.1995951730030325
  mean_raw_obs_processing_ms: 0.2726789791712985
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019653113383167196
    StateBufferConnector_ms: 0.0034215315332952537
    ViewRequirementAgentConnector_ms: 0.11705430048816609
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06400061053205006
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024970685673167757
    mean_inference_ms: 1.1995951730030325
    mean_raw_obs_processing_ms: 0.2726789791712985
time_since_restore: 4210.150466918945
time_this_iter_s: 10.143383026123047
time_total_s: 4210.150466918945
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691998392
timesteps_total: 5187050
training_iteration: 415
trial_id: default
train step: 416
agent_timesteps_total: 5200600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018970471508098097
  StateBufferConnector_ms: 0.0033495561131891213
  ViewRequirementAgentConnector_ms: 0.11534465933745762
counters:
  num_agent_steps_sampled: 5200600
  num_agent_steps_trained: 5184000
  num_env_steps_sampled: 5200600
  num_env_steps_trained: 5184000
  num_samples_added_to_queue: 5200500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 102255
custom_metrics: {}
date: 2023-08-14_16-33-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 40630
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00017531415505800396
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0004535798216238618
        total_loss: 0.7006754875183105
        var_gnorm: 65.0187759399414
        vf_explained_var: -1.0
        vf_loss: 1.4021968841552734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10368.0
  learner_queue:
    size_count: 10371
    size_mean: 15.5
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1704699910719625
  num_agent_steps_sampled: 5200600
  num_agent_steps_trained: 5184000
  num_env_steps_sampled: 5200600
  num_env_steps_trained: 5184000
  num_samples_added_to_queue: 5200500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 102255
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 267.372
    learner_load_time_ms: 7.004
    learner_load_wait_time_ms: 1.496
iterations_since_restore: 416
node_ip: 127.0.0.1
num_agent_steps_sampled: 5200600
num_agent_steps_trained: 5184000
num_env_steps_sampled: 5200600
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.6812175841915
num_env_steps_trained: 5184000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.682393903069
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.521428571428565
  ram_util_percent: 75.54285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06398836630603183
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024961252358283326
  mean_inference_ms: 1.199350577110203
  mean_raw_obs_processing_ms: 0.27262368823559235
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018970471508098097
    StateBufferConnector_ms: 0.0033495561131891213
    ViewRequirementAgentConnector_ms: 0.11534465933745762
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06398836630603183
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024961252358283326
    mean_inference_ms: 1.199350577110203
    mean_raw_obs_processing_ms: 0.27262368823559235
time_since_restore: 4220.234450101852
time_this_iter_s: 10.083983182907104
time_total_s: 4220.234450101852
timers:
  sample_time_ms: 0.058
  synch_weights_time_ms: 0.268
  training_iteration_time_ms: 0.39
timestamp: 1691998402
timesteps_total: 5200600
training_iteration: 416
trial_id: default
train step: 417
agent_timesteps_total: 5213850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02012000634120061
  StateBufferConnector_ms: 0.0035201127712543192
  ViewRequirementAgentConnector_ms: 0.1205293031839224
counters:
  num_agent_steps_sampled: 5213850
  num_agent_steps_trained: 5197000
  num_env_steps_sampled: 5213850
  num_env_steps_trained: 5197000
  num_samples_added_to_queue: 5213500
  num_training_step_calls_since_last_synch_worker_weights: 77
  num_weight_broadcasts: 102518
custom_metrics: {}
date: 2023-08-14_16-33-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 40734
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00019801965390797704
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0003870675282087177
        total_loss: 0.41590946912765503
        var_gnorm: 65.01588439941406
        vf_explained_var: -1.0
        vf_loss: 0.8345732688903809
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10394.0
  learner_queue:
    size_count: 10401
    size_mean: 15.42
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3577923257994944
  num_agent_steps_sampled: 5213850
  num_agent_steps_trained: 5197000
  num_env_steps_sampled: 5213850
  num_env_steps_trained: 5197000
  num_samples_added_to_queue: 5213500
  num_training_step_calls_since_last_synch_worker_weights: 77
  num_weight_broadcasts: 102518
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 154.774
    learner_load_time_ms: 2.944
    learner_load_wait_time_ms: 1.566
iterations_since_restore: 417
node_ip: 127.0.0.1
num_agent_steps_sampled: 5213850
num_agent_steps_trained: 5197000
num_env_steps_sampled: 5213850
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.9948507747488
num_env_steps_trained: 5197000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9949479299423
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.38
  ram_util_percent: 75.26666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06397835147897711
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02495464874084879
  mean_inference_ms: 1.1991680219803889
  mean_raw_obs_processing_ms: 0.27258251802258904
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02012000634120061
    StateBufferConnector_ms: 0.0035201127712543192
    ViewRequirementAgentConnector_ms: 0.1205293031839224
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06397835147897711
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02495464874084879
    mean_inference_ms: 1.1991680219803889
    mean_raw_obs_processing_ms: 0.27258251802258904
time_since_restore: 4230.392508029938
time_this_iter_s: 10.158057928085327
time_total_s: 4230.392508029938
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998412
timesteps_total: 5213850
training_iteration: 417
trial_id: default
train step: 418
agent_timesteps_total: 5225850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021886825561523438
  StateBufferConnector_ms: 0.004164218902587891
  ViewRequirementAgentConnector_ms: 0.13300657272338867
counters:
  num_agent_steps_sampled: 5225850
  num_agent_steps_trained: 5209000
  num_env_steps_sampled: 5225850
  num_env_steps_trained: 5209000
  num_samples_added_to_queue: 5225500
  num_training_step_calls_since_last_synch_worker_weights: 579
  num_weight_broadcasts: 102755
custom_metrics: {}
date: 2023-08-14_16-33-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 94
episodes_total: 40828
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011339828779455274
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0005698907771147788
        total_loss: 2.4889578819274902
        var_gnorm: 65.01602172851562
        vf_explained_var: -1.0
        vf_loss: 4.980189323425293
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10418.0
  learner_queue:
    size_count: 10424
    size_mean: 15.0
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7776388834631178
  num_agent_steps_sampled: 5225850
  num_agent_steps_trained: 5209000
  num_env_steps_sampled: 5225850
  num_env_steps_trained: 5209000
  num_samples_added_to_queue: 5225500
  num_training_step_calls_since_last_synch_worker_weights: 579
  num_weight_broadcasts: 102755
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 181.858
    learner_load_time_ms: 2.932
    learner_load_wait_time_ms: 1.679
iterations_since_restore: 418
node_ip: 127.0.0.1
num_agent_steps_sampled: 5225850
num_agent_steps_trained: 5209000
num_env_steps_sampled: 5225850
num_env_steps_sampled_this_iter: 12000
num_env_steps_sampled_throughput_per_sec: 1199.9978256264985
num_env_steps_trained: 5209000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9978256264985
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.464285714285715
  ram_util_percent: 75.58571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0639971212817456
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02495464068298392
  mean_inference_ms: 1.1992508381544968
  mean_raw_obs_processing_ms: 0.2726122905076203
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021886825561523438
    StateBufferConnector_ms: 0.004164218902587891
    ViewRequirementAgentConnector_ms: 0.13300657272338867
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0639971212817456
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02495464068298392
    mean_inference_ms: 1.1992508381544968
    mean_raw_obs_processing_ms: 0.2726122905076203
time_since_restore: 4240.518064022064
time_this_iter_s: 10.125555992126465
time_total_s: 4240.518064022064
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.06
timestamp: 1691998422
timesteps_total: 5225850
training_iteration: 418
trial_id: default
train step: 419
agent_timesteps_total: 5239050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019954232608570772
  StateBufferConnector_ms: 0.0034998444949879367
  ViewRequirementAgentConnector_ms: 0.12037076202093386
counters:
  num_agent_steps_sampled: 5239050
  num_agent_steps_trained: 5222500
  num_env_steps_sampled: 5239050
  num_env_steps_trained: 5222500
  num_samples_added_to_queue: 5239000
  num_training_step_calls_since_last_synch_worker_weights: 322
  num_weight_broadcasts: 103014
custom_metrics: {}
date: 2023-08-14_16-33-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 40930
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001255449024029076
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00040393928065896034
        total_loss: 1.0606307983398438
        var_gnorm: 65.01629638671875
        vf_explained_var: -1.0
        vf_loss: 2.1217093467712402
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10445.0
  learner_queue:
    size_count: 10450
    size_mean: 15.0
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7088007490635062
  num_agent_steps_sampled: 5239050
  num_agent_steps_trained: 5222500
  num_env_steps_sampled: 5239050
  num_env_steps_trained: 5222500
  num_samples_added_to_queue: 5239000
  num_training_step_calls_since_last_synch_worker_weights: 322
  num_weight_broadcasts: 103014
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 215.392
    learner_load_time_ms: 1.615
    learner_load_wait_time_ms: 1.804
iterations_since_restore: 419
node_ip: 127.0.0.1
num_agent_steps_sampled: 5239050
num_agent_steps_trained: 5222500
num_env_steps_sampled: 5239050
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9954996262443
num_env_steps_trained: 5222500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9953973450226
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.37857142857143
  ram_util_percent: 74.39285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06397463784994445
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02494875752386936
  mean_inference_ms: 1.199122373609456
  mean_raw_obs_processing_ms: 0.2725738478954978
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019954232608570772
    StateBufferConnector_ms: 0.0034998444949879367
    ViewRequirementAgentConnector_ms: 0.12037076202093386
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06397463784994445
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02494875752386936
    mean_inference_ms: 1.199122373609456
    mean_raw_obs_processing_ms: 0.2725738478954978
time_since_restore: 4250.663583993912
time_this_iter_s: 10.145519971847534
time_total_s: 4250.663583993912
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998432
timesteps_total: 5239050
training_iteration: 419
trial_id: default
train step: 420
agent_timesteps_total: 5252700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018962298598244925
  StateBufferConnector_ms: 0.0033683865983909537
  ViewRequirementAgentConnector_ms: 0.11562565776789299
counters:
  num_agent_steps_sampled: 5252700
  num_agent_steps_trained: 5236000
  num_env_steps_sampled: 5252700
  num_env_steps_trained: 5236000
  num_samples_added_to_queue: 5252500
  num_training_step_calls_since_last_synch_worker_weights: 694
  num_weight_broadcasts: 103284
custom_metrics: {}
date: 2023-08-14_16-34-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 41037
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00024497168487869203
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00023229996440932155
        total_loss: 0.16765521466732025
        var_gnorm: 65.01505279541016
        vf_explained_var: -1.0
        vf_loss: 0.3372955620288849
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10472.0
  learner_queue:
    size_count: 10477
    size_mean: 15.44
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.1859173664298874
  num_agent_steps_sampled: 5252700
  num_agent_steps_trained: 5236000
  num_env_steps_sampled: 5252700
  num_env_steps_trained: 5236000
  num_samples_added_to_queue: 5252500
  num_training_step_calls_since_last_synch_worker_weights: 694
  num_weight_broadcasts: 103284
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 209.475
    learner_load_time_ms: 1.6
    learner_load_wait_time_ms: 1.595
iterations_since_restore: 420
node_ip: 127.0.0.1
num_agent_steps_sampled: 5252700
num_agent_steps_trained: 5236000
num_env_steps_sampled: 5252700
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.9983727951374
num_env_steps_trained: 5236000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9983906765094
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.333333333333336
  ram_util_percent: 74.25999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06395752171803774
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024938923261817472
  mean_inference_ms: 1.1988563686653657
  mean_raw_obs_processing_ms: 0.2725162518307344
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018962298598244925
    StateBufferConnector_ms: 0.0033683865983909537
    ViewRequirementAgentConnector_ms: 0.11562565776789299
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06395752171803774
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024938923261817472
    mean_inference_ms: 1.1988563686653657
    mean_raw_obs_processing_ms: 0.2725162518307344
time_since_restore: 4260.779837846756
time_this_iter_s: 10.116253852844238
time_total_s: 4260.779837846756
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998442
timesteps_total: 5252700
training_iteration: 420
trial_id: default
train step: 421
agent_timesteps_total: 5265800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019961653403865482
  StateBufferConnector_ms: 0.0035644734947426807
  ViewRequirementAgentConnector_ms: 0.12380266652523893
counters:
  num_agent_steps_sampled: 5265800
  num_agent_steps_trained: 5249000
  num_env_steps_sampled: 5265800
  num_env_steps_trained: 5249000
  num_samples_added_to_queue: 5265500
  num_training_step_calls_since_last_synch_worker_weights: 341
  num_weight_broadcasts: 103543
custom_metrics: {}
date: 2023-08-14_16-34-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 103
episodes_total: 41140
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011693890701280907
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.627569852455053e-07
        total_loss: 0.5545452833175659
        var_gnorm: 65.01575469970703
        vf_explained_var: -1.0
        vf_loss: 1.1102619171142578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10498.0
  learner_queue:
    size_count: 10504
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3078226179417451
  num_agent_steps_sampled: 5265800
  num_agent_steps_trained: 5249000
  num_env_steps_sampled: 5265800
  num_env_steps_trained: 5249000
  num_samples_added_to_queue: 5265500
  num_training_step_calls_since_last_synch_worker_weights: 341
  num_weight_broadcasts: 103543
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 182.329
    learner_load_time_ms: 1.526
    learner_load_wait_time_ms: 1.457
iterations_since_restore: 421
node_ip: 127.0.0.1
num_agent_steps_sampled: 5265800
num_agent_steps_trained: 5249000
num_env_steps_sampled: 5265800
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.995689883108
num_env_steps_trained: 5249000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9957227847638
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.49285714285714
  ram_util_percent: 74.91428571428573
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0639543935759153
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024933753528485363
  mean_inference_ms: 1.1987123636402128
  mean_raw_obs_processing_ms: 0.27249123537978864
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019961653403865482
    StateBufferConnector_ms: 0.0035644734947426807
    ViewRequirementAgentConnector_ms: 0.12380266652523893
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0639543935759153
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024933753528485363
    mean_inference_ms: 1.1987123636402128
    mean_raw_obs_processing_ms: 0.27249123537978864
time_since_restore: 4270.918499708176
time_this_iter_s: 10.138661861419678
time_total_s: 4270.918499708176
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998452
timesteps_total: 5265800
training_iteration: 421
trial_id: default
train step: 422
agent_timesteps_total: 5278100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021566152572631836
  StateBufferConnector_ms: 0.004040718078613281
  ViewRequirementAgentConnector_ms: 0.1294417381286621
counters:
  num_agent_steps_sampled: 5278100
  num_agent_steps_trained: 5261500
  num_env_steps_sampled: 5278100
  num_env_steps_trained: 5261500
  num_samples_added_to_queue: 5278000
  num_training_step_calls_since_last_synch_worker_weights: 1118
  num_weight_broadcasts: 103786
custom_metrics: {}
date: 2023-08-14_16-34-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 41236
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011997002002317458
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00040214642649516463
        total_loss: 1.3868063688278198
        var_gnorm: 65.0150146484375
        vf_explained_var: -1.0
        vf_loss: 2.774008274078369
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10523.0
  learner_queue:
    size_count: 10528
    size_mean: 15.26
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3972830779766854
  num_agent_steps_sampled: 5278100
  num_agent_steps_trained: 5261500
  num_env_steps_sampled: 5278100
  num_env_steps_trained: 5261500
  num_samples_added_to_queue: 5278000
  num_training_step_calls_since_last_synch_worker_weights: 1118
  num_weight_broadcasts: 103786
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 233.355
    learner_load_time_ms: 1.556
    learner_load_wait_time_ms: 1.716
iterations_since_restore: 422
node_ip: 127.0.0.1
num_agent_steps_sampled: 5278100
num_agent_steps_trained: 5261500
num_env_steps_sampled: 5278100
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.993460451563
num_env_steps_trained: 5261500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9933541174419
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.800000000000004
  ram_util_percent: 75.21428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06396309222435347
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0249333205997604
  mean_inference_ms: 1.1987300505207252
  mean_raw_obs_processing_ms: 0.27250848016526047
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021566152572631836
    StateBufferConnector_ms: 0.004040718078613281
    ViewRequirementAgentConnector_ms: 0.1294417381286621
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06396309222435347
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0249333205997604
    mean_inference_ms: 1.1987300505207252
    mean_raw_obs_processing_ms: 0.27250848016526047
time_since_restore: 4281.031574010849
time_this_iter_s: 10.11307430267334
time_total_s: 4281.031574010849
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998462
timesteps_total: 5278100
training_iteration: 422
trial_id: default
train step: 423
agent_timesteps_total: 5291350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019601016368680786
  StateBufferConnector_ms: 0.00350081804886605
  ViewRequirementAgentConnector_ms: 0.12004491194937993
counters:
  num_agent_steps_sampled: 5291350
  num_agent_steps_trained: 5274500
  num_env_steps_sampled: 5291350
  num_env_steps_trained: 5274500
  num_samples_added_to_queue: 5291000
  num_training_step_calls_since_last_synch_worker_weights: 253
  num_weight_broadcasts: 104047
custom_metrics: {}
date: 2023-08-14_16-34-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 103
episodes_total: 41339
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00012269183935131878
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0001234069059137255
        total_loss: 0.3156074583530426
        var_gnorm: 65.01516723632812
        vf_explained_var: -1.0
        vf_loss: 0.6326886415481567
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10549.0
  learner_queue:
    size_count: 10555
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.290116273829611
  num_agent_steps_sampled: 5291350
  num_agent_steps_trained: 5274500
  num_env_steps_sampled: 5291350
  num_env_steps_trained: 5274500
  num_samples_added_to_queue: 5291000
  num_training_step_calls_since_last_synch_worker_weights: 253
  num_weight_broadcasts: 104047
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 191.993
    learner_load_time_ms: 1.556
    learner_load_wait_time_ms: 1.589
iterations_since_restore: 423
node_ip: 127.0.0.1
num_agent_steps_sampled: 5291350
num_agent_steps_trained: 5274500
num_env_steps_sampled: 5291350
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.9952298574517
num_env_steps_trained: 5274500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9953198601413
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.21333333333333
  ram_util_percent: 75.16666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06394296116184933
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024926986973253504
  mean_inference_ms: 1.198586324867001
  mean_raw_obs_processing_ms: 0.2724662677521567
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019601016368680786
    StateBufferConnector_ms: 0.00350081804886605
    ViewRequirementAgentConnector_ms: 0.12004491194937993
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06394296116184933
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024926986973253504
    mean_inference_ms: 1.198586324867001
    mean_raw_obs_processing_ms: 0.2724662677521567
time_since_restore: 4291.177141904831
time_this_iter_s: 10.145567893981934
time_total_s: 4291.177141904831
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998473
timesteps_total: 5291350
training_iteration: 423
trial_id: default
train step: 424
agent_timesteps_total: 5303950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02073383331298828
  StateBufferConnector_ms: 0.0036284923553466797
  ViewRequirementAgentConnector_ms: 0.12330317497253418
counters:
  num_agent_steps_sampled: 5303950
  num_agent_steps_trained: 5287000
  num_env_steps_sampled: 5303950
  num_env_steps_trained: 5287000
  num_samples_added_to_queue: 5303500
  num_training_step_calls_since_last_synch_worker_weights: 335
  num_weight_broadcasts: 104293
custom_metrics: {}
date: 2023-08-14_16-34-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 98
episodes_total: 41437
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00021018338156864047
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0003631060535553843
        total_loss: 0.5205720663070679
        var_gnorm: 65.01570892333984
        vf_explained_var: -1.0
        vf_loss: 1.0425196886062622
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10574.0
  learner_queue:
    size_count: 10580
    size_mean: 15.22
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5138031576133009
  num_agent_steps_sampled: 5303950
  num_agent_steps_trained: 5287000
  num_env_steps_sampled: 5303950
  num_env_steps_trained: 5287000
  num_samples_added_to_queue: 5303500
  num_training_step_calls_since_last_synch_worker_weights: 335
  num_weight_broadcasts: 104293
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 220.509
    learner_load_time_ms: 1.568
    learner_load_wait_time_ms: 1.626
iterations_since_restore: 424
node_ip: 127.0.0.1
num_agent_steps_sampled: 5303950
num_agent_steps_trained: 5287000
num_env_steps_sampled: 5303950
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.996875770686
num_env_steps_trained: 5287000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.996900566157
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.72857142857142
  ram_util_percent: 75.57142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06395002245705812
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024925087190519793
  mean_inference_ms: 1.1985550993893528
  mean_raw_obs_processing_ms: 0.27246753829272286
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02073383331298828
    StateBufferConnector_ms: 0.0036284923553466797
    ViewRequirementAgentConnector_ms: 0.12330317497253418
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06395002245705812
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024925087190519793
    mean_inference_ms: 1.1985550993893528
    mean_raw_obs_processing_ms: 0.27246753829272286
time_since_restore: 4301.313618898392
time_this_iter_s: 10.136476993560791
time_total_s: 4301.313618898392
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998483
timesteps_total: 5303950
training_iteration: 424
trial_id: default
train step: 425
agent_timesteps_total: 5316450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020493268966674805
  StateBufferConnector_ms: 0.0037724971771240234
  ViewRequirementAgentConnector_ms: 0.12625861167907715
counters:
  num_agent_steps_sampled: 5316450
  num_agent_steps_trained: 5299500
  num_env_steps_sampled: 5316450
  num_env_steps_trained: 5299500
  num_samples_added_to_queue: 5316000
  num_training_step_calls_since_last_synch_worker_weights: 971
  num_weight_broadcasts: 104536
custom_metrics: {}
date: 2023-08-14_16-34-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 98
episodes_total: 41535
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00013144116383045912
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.954691293183714e-05
        total_loss: 0.10093198716640472
        var_gnorm: 65.01433563232422
        vf_explained_var: -1.0
        vf_loss: 0.2033574879169464
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10599.0
  learner_queue:
    size_count: 10604
    size_mean: 15.04
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6365818036383029
  num_agent_steps_sampled: 5316450
  num_agent_steps_trained: 5299500
  num_env_steps_sampled: 5316450
  num_env_steps_trained: 5299500
  num_samples_added_to_queue: 5316000
  num_training_step_calls_since_last_synch_worker_weights: 971
  num_weight_broadcasts: 104536
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 249.001
    learner_load_time_ms: 1.56
    learner_load_wait_time_ms: 1.649
iterations_since_restore: 425
node_ip: 127.0.0.1
num_agent_steps_sampled: 5316450
num_agent_steps_trained: 5299500
num_env_steps_sampled: 5316450
num_env_steps_sampled_this_iter: 12500
num_env_steps_sampled_throughput_per_sec: 1249.9949038236487
num_env_steps_trained: 5299500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9949038236487
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.635714285714286
  ram_util_percent: 76.32142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0639499831920461
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024923704406467385
  mean_inference_ms: 1.1985541092904948
  mean_raw_obs_processing_ms: 0.2724671925001683
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020493268966674805
    StateBufferConnector_ms: 0.0037724971771240234
    ViewRequirementAgentConnector_ms: 0.12625861167907715
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0639499831920461
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024923704406467385
    mean_inference_ms: 1.1985541092904948
    mean_raw_obs_processing_ms: 0.2724671925001683
time_since_restore: 4311.439899921417
time_this_iter_s: 10.126281023025513
time_total_s: 4311.439899921417
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998493
timesteps_total: 5316450
training_iteration: 425
trial_id: default
train step: 426
agent_timesteps_total: 5329250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020815134048461914
  StateBufferConnector_ms: 0.003761768341064453
  ViewRequirementAgentConnector_ms: 0.12447786331176758
counters:
  num_agent_steps_sampled: 5329250
  num_agent_steps_trained: 5312500
  num_env_steps_sampled: 5329250
  num_env_steps_trained: 5312500
  num_samples_added_to_queue: 5329000
  num_training_step_calls_since_last_synch_worker_weights: 62
  num_weight_broadcasts: 104785
custom_metrics: {}
date: 2023-08-14_16-35-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 41635
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00022246014850679785
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0006717807846143842
        total_loss: 0.736992359161377
        var_gnorm: 65.01480102539062
        vf_explained_var: -1.0
        vf_loss: 1.4748656749725342
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10625.0
  learner_queue:
    size_count: 10632
    size_mean: 15.22
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5005332385522157
  num_agent_steps_sampled: 5329250
  num_agent_steps_trained: 5312500
  num_env_steps_sampled: 5329250
  num_env_steps_trained: 5312500
  num_samples_added_to_queue: 5329000
  num_training_step_calls_since_last_synch_worker_weights: 62
  num_weight_broadcasts: 104785
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 142.647
    learner_load_time_ms: 1.48
    learner_load_wait_time_ms: 1.496
iterations_since_restore: 426
node_ip: 127.0.0.1
num_agent_steps_sampled: 5329250
num_agent_steps_trained: 5312500
num_env_steps_sampled: 5329250
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9960327271401
num_env_steps_trained: 5312500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9959707385017
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.39333333333333
  ram_util_percent: 76.80666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06394206824048285
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024920773340856562
  mean_inference_ms: 1.1985030740669693
  mean_raw_obs_processing_ms: 0.27245282996832776
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020815134048461914
    StateBufferConnector_ms: 0.003761768341064453
    ViewRequirementAgentConnector_ms: 0.12447786331176758
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06394206824048285
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024920773340856562
    mean_inference_ms: 1.1985030740669693
    mean_raw_obs_processing_ms: 0.27245282996832776
time_since_restore: 4321.598566055298
time_this_iter_s: 10.158666133880615
time_total_s: 4321.598566055298
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691998503
timesteps_total: 5329250
training_iteration: 426
trial_id: default
train step: 427
agent_timesteps_total: 5342250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019368704627541936
  StateBufferConnector_ms: 0.003566461450913373
  ViewRequirementAgentConnector_ms: 0.11992548026290595
counters:
  num_agent_steps_sampled: 5342250
  num_agent_steps_trained: 5325500
  num_env_steps_sampled: 5342250
  num_env_steps_trained: 5325500
  num_samples_added_to_queue: 5342000
  num_training_step_calls_since_last_synch_worker_weights: 889
  num_weight_broadcasts: 105042
custom_metrics: {}
date: 2023-08-14_16-35-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 41737
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00020332522399257869
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0005101178539916873
        total_loss: 0.60981684923172
        var_gnorm: 65.01294708251953
        vf_explained_var: -1.0
        vf_loss: 1.2226871252059937
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10651.0
  learner_queue:
    size_count: 10656
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6079800993793425
  num_agent_steps_sampled: 5342250
  num_agent_steps_trained: 5325500
  num_env_steps_sampled: 5342250
  num_env_steps_trained: 5325500
  num_samples_added_to_queue: 5342000
  num_training_step_calls_since_last_synch_worker_weights: 889
  num_weight_broadcasts: 105042
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 226.647
    learner_load_time_ms: 1.399
    learner_load_wait_time_ms: 1.697
iterations_since_restore: 427
node_ip: 127.0.0.1
num_agent_steps_sampled: 5342250
num_agent_steps_trained: 5325500
num_env_steps_sampled: 5342250
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9975514458044
num_env_steps_trained: 5325500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9975514458044
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.54999999999999
  ram_util_percent: 76.15
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06393391258033287
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024915252597573986
  mean_inference_ms: 1.1983962996665956
  mean_raw_obs_processing_ms: 0.2724219053811879
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019368704627541936
    StateBufferConnector_ms: 0.003566461450913373
    ViewRequirementAgentConnector_ms: 0.11992548026290595
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06393391258033287
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024915252597573986
    mean_inference_ms: 1.1983962996665956
    mean_raw_obs_processing_ms: 0.2724219053811879
time_since_restore: 4331.708374738693
time_this_iter_s: 10.109808683395386
time_total_s: 4331.708374738693
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998513
timesteps_total: 5342250
training_iteration: 427
trial_id: default
train step: 428
agent_timesteps_total: 5355450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019546655508188102
  StateBufferConnector_ms: 0.003514381555410532
  ViewRequirementAgentConnector_ms: 0.11950456179105319
counters:
  num_agent_steps_sampled: 5355450
  num_agent_steps_trained: 5338500
  num_env_steps_sampled: 5355450
  num_env_steps_trained: 5338500
  num_samples_added_to_queue: 5355000
  num_training_step_calls_since_last_synch_worker_weights: 662
  num_weight_broadcasts: 105299
custom_metrics: {}
date: 2023-08-14_16-35-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.009615384615384616
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 41841
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001762409956427291
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0005255212308838964
        total_loss: 0.8494969010353088
        var_gnorm: 65.01358032226562
        vf_explained_var: -1.0
        vf_loss: 1.6997051239013672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10677.0
  learner_queue:
    size_count: 10683
    size_mean: 15.28
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3422369388450013
  num_agent_steps_sampled: 5355450
  num_agent_steps_trained: 5338500
  num_env_steps_sampled: 5355450
  num_env_steps_trained: 5338500
  num_samples_added_to_queue: 5355000
  num_training_step_calls_since_last_synch_worker_weights: 662
  num_weight_broadcasts: 105299
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 213.471
    learner_load_time_ms: 1.39
    learner_load_wait_time_ms: 1.688
iterations_since_restore: 428
node_ip: 127.0.0.1
num_agent_steps_sampled: 5355450
num_agent_steps_trained: 5338500
num_env_steps_sampled: 5355450
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9935484247821
num_env_steps_trained: 5338500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9936461759219
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 56.221428571428575
  ram_util_percent: 75.39999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06392511772293083
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02490899694830529
  mean_inference_ms: 1.198240928985744
  mean_raw_obs_processing_ms: 0.27239201939740776
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019546655508188102
    StateBufferConnector_ms: 0.003514381555410532
    ViewRequirementAgentConnector_ms: 0.11950456179105319
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.009615384615384616
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06392511772293083
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02490899694830529
    mean_inference_ms: 1.198240928985744
    mean_raw_obs_processing_ms: 0.27239201939740776
time_since_restore: 4341.849567890167
time_this_iter_s: 10.141193151473999
time_total_s: 4341.849567890167
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.051
timestamp: 1691998523
timesteps_total: 5355450
training_iteration: 428
trial_id: default
train step: 429
agent_timesteps_total: 5368550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019772847493489582
  StateBufferConnector_ms: 0.0036660362692440256
  ViewRequirementAgentConnector_ms: 0.1204228868671492
counters:
  num_agent_steps_sampled: 5368550
  num_agent_steps_trained: 5352000
  num_env_steps_sampled: 5368550
  num_env_steps_trained: 5352000
  num_samples_added_to_queue: 5368500
  num_training_step_calls_since_last_synch_worker_weights: 924
  num_weight_broadcasts: 105554
custom_metrics: {}
date: 2023-08-14_16-35-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 41943
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00015761143004056066
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0002532165963202715
        total_loss: 0.30890196561813354
        var_gnorm: 65.01126098632812
        vf_explained_var: -1.0
        vf_loss: 0.6198865175247192
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10704.0
  learner_queue:
    size_count: 10708
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1697863052711808
  num_agent_steps_sampled: 5368550
  num_agent_steps_trained: 5352000
  num_env_steps_sampled: 5368550
  num_env_steps_trained: 5352000
  num_samples_added_to_queue: 5368500
  num_training_step_calls_since_last_synch_worker_weights: 924
  num_weight_broadcasts: 105554
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 235.002
    learner_load_time_ms: 1.375
    learner_load_wait_time_ms: 1.581
iterations_since_restore: 429
node_ip: 127.0.0.1
num_agent_steps_sampled: 5368550
num_agent_steps_trained: 5352000
num_env_steps_sampled: 5368550
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9948778352746
num_env_steps_trained: 5352000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9947214332983
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 58.97857142857142
  ram_util_percent: 76.41428571428573
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06391820281862422
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024903351942294635
  mean_inference_ms: 1.1980940421001076
  mean_raw_obs_processing_ms: 0.27236294959977136
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019772847493489582
    StateBufferConnector_ms: 0.0036660362692440256
    ViewRequirementAgentConnector_ms: 0.1204228868671492
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06391820281862422
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024903351942294635
    mean_inference_ms: 1.1980940421001076
    mean_raw_obs_processing_ms: 0.27236294959977136
time_since_restore: 4351.9402549266815
time_this_iter_s: 10.090687036514282
time_total_s: 4351.9402549266815
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691998533
timesteps_total: 5368550
training_iteration: 429
trial_id: default
train step: 430
agent_timesteps_total: 5381900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019424007489131048
  StateBufferConnector_ms: 0.0034410219926100513
  ViewRequirementAgentConnector_ms: 0.11824094332181491
counters:
  num_agent_steps_sampled: 5381900
  num_agent_steps_trained: 5365000
  num_env_steps_sampled: 5381900
  num_env_steps_trained: 5365000
  num_samples_added_to_queue: 5381500
  num_training_step_calls_since_last_synch_worker_weights: 121
  num_weight_broadcasts: 105816
custom_metrics: {}
date: 2023-08-14_16-35-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 42047
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00015678443014621735
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00014315552834887058
        total_loss: 0.20302431285381317
        var_gnorm: 65.01121520996094
        vf_explained_var: -1.0
        vf_loss: 0.4079027771949768
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10730.0
  learner_queue:
    size_count: 10737
    size_mean: 15.4
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3564659966250536
  num_agent_steps_sampled: 5381900
  num_agent_steps_trained: 5365000
  num_env_steps_sampled: 5381900
  num_env_steps_trained: 5365000
  num_samples_added_to_queue: 5381500
  num_training_step_calls_since_last_synch_worker_weights: 121
  num_weight_broadcasts: 105816
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 161.401
    learner_load_time_ms: 1.379
    learner_load_wait_time_ms: 1.518
iterations_since_restore: 430
node_ip: 127.0.0.1
num_agent_steps_sampled: 5381900
num_agent_steps_trained: 5365000
num_env_steps_sampled: 5381900
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9942708261312
num_env_steps_trained: 5365000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9944210291915
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.72666666666667
  ram_util_percent: 76.32666666666665
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06390761277681942
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024895878586494755
  mean_inference_ms: 1.1979043293281886
  mean_raw_obs_processing_ms: 0.27232308510812425
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019424007489131048
    StateBufferConnector_ms: 0.0034410219926100513
    ViewRequirementAgentConnector_ms: 0.11824094332181491
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06390761277681942
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024895878586494755
    mean_inference_ms: 1.1979043293281886
    mean_raw_obs_processing_ms: 0.27232308510812425
time_since_restore: 4362.0869908332825
time_this_iter_s: 10.146735906600952
time_total_s: 4362.0869908332825
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691998544
timesteps_total: 5381900
training_iteration: 430
trial_id: default
train step: 431
agent_timesteps_total: 5395450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01884369623093378
  StateBufferConnector_ms: 0.0034577505929129465
  ViewRequirementAgentConnector_ms: 0.11618727729434059
counters:
  num_agent_steps_sampled: 5395450
  num_agent_steps_trained: 5378500
  num_env_steps_sampled: 5395450
  num_env_steps_trained: 5378500
  num_samples_added_to_queue: 5395000
  num_training_step_calls_since_last_synch_worker_weights: 27
  num_weight_broadcasts: 106084
custom_metrics: {}
date: 2023-08-14_16-35-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 42152
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00020262514590285718
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0008210971136577427
        total_loss: 1.5730544328689575
        var_gnorm: 65.01091003417969
        vf_explained_var: -1.0
        vf_loss: 3.1464929580688477
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10757.0
  learner_queue:
    size_count: 10764
    size_mean: 15.0
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7776388834631178
  num_agent_steps_sampled: 5395450
  num_agent_steps_trained: 5378500
  num_env_steps_sampled: 5395450
  num_env_steps_trained: 5378500
  num_samples_added_to_queue: 5395000
  num_training_step_calls_since_last_synch_worker_weights: 27
  num_weight_broadcasts: 106084
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 159.857
    learner_load_time_ms: 1.39
    learner_load_wait_time_ms: 1.52
iterations_since_restore: 431
node_ip: 127.0.0.1
num_agent_steps_sampled: 5395450
num_agent_steps_trained: 5378500
num_env_steps_sampled: 5395450
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9985139386263
num_env_steps_trained: 5378500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9985194222475
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.97857142857142
  ram_util_percent: 74.67142857142856
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06389274066992258
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024887398310921006
  mean_inference_ms: 1.197675853275697
  mean_raw_obs_processing_ms: 0.2722730225671202
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01884369623093378
    StateBufferConnector_ms: 0.0034577505929129465
    ViewRequirementAgentConnector_ms: 0.11618727729434059
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06389274066992258
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024887398310921006
    mean_inference_ms: 1.197675853275697
    mean_raw_obs_processing_ms: 0.2722730225671202
time_since_restore: 4372.239399909973
time_this_iter_s: 10.152409076690674
time_total_s: 4372.239399909973
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1691998554
timesteps_total: 5395450
training_iteration: 431
trial_id: default
train step: 432
agent_timesteps_total: 5408950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01917177776120744
  StateBufferConnector_ms: 0.0033913918261258107
  ViewRequirementAgentConnector_ms: 0.11721579533702922
counters:
  num_agent_steps_sampled: 5408950
  num_agent_steps_trained: 5392000
  num_env_steps_sampled: 5408950
  num_env_steps_trained: 5392000
  num_samples_added_to_queue: 5408500
  num_training_step_calls_since_last_synch_worker_weights: 311
  num_weight_broadcasts: 106351
custom_metrics: {}
date: 2023-08-14_16-36-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 42258
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00016694424266461283
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0006235298933461308
        total_loss: 1.2843106985092163
        var_gnorm: 65.0096664428711
        vf_explained_var: -1.0
        vf_loss: 2.571537971496582
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10784.0
  learner_queue:
    size_count: 10790
    size_mean: 15.1
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6401219466856727
  num_agent_steps_sampled: 5408950
  num_agent_steps_trained: 5392000
  num_env_steps_sampled: 5408950
  num_env_steps_trained: 5392000
  num_samples_added_to_queue: 5408500
  num_training_step_calls_since_last_synch_worker_weights: 311
  num_weight_broadcasts: 106351
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 193.507
    learner_load_time_ms: 1.65
    learner_load_wait_time_ms: 1.595
iterations_since_restore: 432
node_ip: 127.0.0.1
num_agent_steps_sampled: 5408950
num_agent_steps_trained: 5392000
num_env_steps_sampled: 5408950
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.999195337775
num_env_steps_trained: 5392000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.999195337775
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.957142857142856
  ram_util_percent: 74.65
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06388253477345794
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024878835958296777
  mean_inference_ms: 1.1974539541261389
  mean_raw_obs_processing_ms: 0.2722335844249564
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01917177776120744
    StateBufferConnector_ms: 0.0033913918261258107
    ViewRequirementAgentConnector_ms: 0.11721579533702922
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06388253477345794
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024878835958296777
    mean_inference_ms: 1.1974539541261389
    mean_raw_obs_processing_ms: 0.2722335844249564
time_since_restore: 4382.379447937012
time_this_iter_s: 10.140048027038574
time_total_s: 4382.379447937012
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998564
timesteps_total: 5408950
training_iteration: 432
trial_id: default
train step: 433
agent_timesteps_total: 5422650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01891662027234229
  StateBufferConnector_ms: 0.0033536804056613244
  ViewRequirementAgentConnector_ms: 0.11433062152327778
counters:
  num_agent_steps_sampled: 5422650
  num_agent_steps_trained: 5406000
  num_env_steps_sampled: 5422650
  num_env_steps_trained: 5406000
  num_samples_added_to_queue: 5422500
  num_training_step_calls_since_last_synch_worker_weights: 318
  num_weight_broadcasts: 106622
custom_metrics: {}
date: 2023-08-14_16-36-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 42365
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00016633883933536708
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0005356306210160255
        total_loss: 1.181363821029663
        var_gnorm: 65.0093002319336
        vf_explained_var: -1.0
        vf_loss: 2.3633198738098145
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10812.0
  learner_queue:
    size_count: 10818
    size_mean: 15.22
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4736349615830917
  num_agent_steps_sampled: 5422650
  num_agent_steps_trained: 5406000
  num_env_steps_sampled: 5422650
  num_env_steps_trained: 5406000
  num_samples_added_to_queue: 5422500
  num_training_step_calls_since_last_synch_worker_weights: 318
  num_weight_broadcasts: 106622
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 169.248
    learner_load_time_ms: 1.651
    learner_load_wait_time_ms: 1.48
iterations_since_restore: 433
node_ip: 127.0.0.1
num_agent_steps_sampled: 5422650
num_agent_steps_trained: 5406000
num_env_steps_sampled: 5422650
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.99464323231
num_env_steps_trained: 5406000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9945259308279
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.27333333333334
  ram_util_percent: 74.72666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0638701219696709
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024869380470752767
  mean_inference_ms: 1.197189933131961
  mean_raw_obs_processing_ms: 0.2721789574345854
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01891662027234229
    StateBufferConnector_ms: 0.0033536804056613244
    ViewRequirementAgentConnector_ms: 0.11433062152327778
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0638701219696709
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024869380470752767
    mean_inference_ms: 1.197189933131961
    mean_raw_obs_processing_ms: 0.2721789574345854
time_since_restore: 4392.517918109894
time_this_iter_s: 10.13847017288208
time_total_s: 4392.517918109894
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691998574
timesteps_total: 5422650
training_iteration: 433
trial_id: default
train step: 434
agent_timesteps_total: 5435950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0193329957815317
  StateBufferConnector_ms: 0.0034020497248722957
  ViewRequirementAgentConnector_ms: 0.11694408380068265
counters:
  num_agent_steps_sampled: 5435950
  num_agent_steps_trained: 5419000
  num_env_steps_sampled: 5435950
  num_env_steps_trained: 5419000
  num_samples_added_to_queue: 5435500
  num_training_step_calls_since_last_synch_worker_weights: 1105
  num_weight_broadcasts: 106883
custom_metrics: {}
date: 2023-08-14_16-36-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 42469
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.000149772604345344
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00015283440006896853
        total_loss: 0.1838325560092926
        var_gnorm: 65.00993347167969
        vf_explained_var: -1.0
        vf_loss: 0.3694685101509094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10838.0
  learner_queue:
    size_count: 10842
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3747727084867518
  num_agent_steps_sampled: 5435950
  num_agent_steps_trained: 5419000
  num_env_steps_sampled: 5435950
  num_env_steps_trained: 5419000
  num_samples_added_to_queue: 5435500
  num_training_step_calls_since_last_synch_worker_weights: 1105
  num_weight_broadcasts: 106883
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 278.526
    learner_load_time_ms: 1.66
    learner_load_wait_time_ms: 1.732
iterations_since_restore: 434
node_ip: 127.0.0.1
num_agent_steps_sampled: 5435950
num_agent_steps_trained: 5419000
num_env_steps_sampled: 5435950
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9960363029352
num_env_steps_trained: 5419000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9961257096359
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 48.79285714285714
  ram_util_percent: 75.25
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06385750880680588
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024861822066785826
  mean_inference_ms: 1.1970145972141728
  mean_raw_obs_processing_ms: 0.27213950400069403
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0193329957815317
    StateBufferConnector_ms: 0.0034020497248722957
    ViewRequirementAgentConnector_ms: 0.11694408380068265
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06385750880680588
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024861822066785826
    mean_inference_ms: 1.1970145972141728
    mean_raw_obs_processing_ms: 0.27213950400069403
time_since_restore: 4402.6179258823395
time_this_iter_s: 10.100007772445679
time_total_s: 4402.6179258823395
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691998584
timesteps_total: 5435950
training_iteration: 434
trial_id: default
train step: 435
agent_timesteps_total: 5448750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020651817321777344
  StateBufferConnector_ms: 0.00366973876953125
  ViewRequirementAgentConnector_ms: 0.1229712963104248
counters:
  num_agent_steps_sampled: 5448750
  num_agent_steps_trained: 5432000
  num_env_steps_sampled: 5448750
  num_env_steps_trained: 5432000
  num_samples_added_to_queue: 5448500
  num_training_step_calls_since_last_synch_worker_weights: 1057
  num_weight_broadcasts: 107133
custom_metrics: {}
date: 2023-08-14_16-36-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 42569
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00023592323123011738
        entropy_coeff: 0.01
        grad_gnorm: 19.16140365600586
        policy_loss: -0.0001367267977911979
        total_loss: 0.5600298643112183
        var_gnorm: 65.00945281982422
        vf_explained_var: -1.0
        vf_loss: 1.1226924657821655
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10864.0
  learner_queue:
    size_count: 10868
    size_mean: 15.46
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.135077089893017
  num_agent_steps_sampled: 5448750
  num_agent_steps_trained: 5432000
  num_env_steps_sampled: 5448750
  num_env_steps_trained: 5432000
  num_samples_added_to_queue: 5448500
  num_training_step_calls_since_last_synch_worker_weights: 1057
  num_weight_broadcasts: 107133
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 253.561
    learner_load_time_ms: 1.672
    learner_load_wait_time_ms: 1.754
iterations_since_restore: 435
node_ip: 127.0.0.1
num_agent_steps_sampled: 5448750
num_agent_steps_trained: 5432000
num_env_steps_sampled: 5448750
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9956360012068
num_env_steps_trained: 5432000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9955678137255
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.77142857142856
  ram_util_percent: 76.74285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0638533385787311
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02485818949896671
  mean_inference_ms: 1.1969405278559713
  mean_raw_obs_processing_ms: 0.27212710752862257
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020651817321777344
    StateBufferConnector_ms: 0.00366973876953125
    ViewRequirementAgentConnector_ms: 0.1229712963104248
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0638533385787311
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02485818949896671
    mean_inference_ms: 1.1969405278559713
    mean_raw_obs_processing_ms: 0.27212710752862257
time_since_restore: 4412.71851682663
time_this_iter_s: 10.100590944290161
time_total_s: 4412.71851682663
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998594
timesteps_total: 5448750
training_iteration: 435
trial_id: default
train step: 436
agent_timesteps_total: 5462150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019502412705194382
  StateBufferConnector_ms: 0.0034618377685546875
  ViewRequirementAgentConnector_ms: 0.1171693347749256
counters:
  num_agent_steps_sampled: 5462150
  num_agent_steps_trained: 5445500
  num_env_steps_sampled: 5462150
  num_env_steps_trained: 5445500
  num_samples_added_to_queue: 5462000
  num_training_step_calls_since_last_synch_worker_weights: 152
  num_weight_broadcasts: 107397
custom_metrics: {}
date: 2023-08-14_16-36-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 42674
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00011967589671257883
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00044254446402192116
        total_loss: 1.4535211324691772
        var_gnorm: 65.00912475585938
        vf_explained_var: -1.0
        vf_loss: 2.9073541164398193
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10891.0
  learner_queue:
    size_count: 10897
    size_mean: 15.5
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1532562594670797
  num_agent_steps_sampled: 5462150
  num_agent_steps_trained: 5445500
  num_env_steps_sampled: 5462150
  num_env_steps_trained: 5445500
  num_samples_added_to_queue: 5462000
  num_training_step_calls_since_last_synch_worker_weights: 152
  num_weight_broadcasts: 107397
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 180.152
    learner_load_time_ms: 1.648
    learner_load_wait_time_ms: 1.563
iterations_since_restore: 436
node_ip: 127.0.0.1
num_agent_steps_sampled: 5462150
num_agent_steps_trained: 5445500
num_env_steps_sampled: 5462150
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9996166230344
num_env_steps_trained: 5445500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9996137620124
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.633333333333326
  ram_util_percent: 76.96000000000001
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06384112500157421
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024851258219155948
  mean_inference_ms: 1.1967546363141235
  mean_raw_obs_processing_ms: 0.2720855231395879
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019502412705194382
    StateBufferConnector_ms: 0.0034618377685546875
    ViewRequirementAgentConnector_ms: 0.1171693347749256
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06384112500157421
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024851258219155948
    mean_inference_ms: 1.1967546363141235
    mean_raw_obs_processing_ms: 0.2720855231395879
time_since_restore: 4422.864562749863
time_this_iter_s: 10.146045923233032
time_total_s: 4422.864562749863
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691998604
timesteps_total: 5462150
training_iteration: 436
trial_id: default
train step: 437
agent_timesteps_total: 5474450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023202896118164062
  StateBufferConnector_ms: 0.0038318634033203125
  ViewRequirementAgentConnector_ms: 0.12996149063110352
counters:
  num_agent_steps_sampled: 5474450
  num_agent_steps_trained: 5457500
  num_env_steps_sampled: 5474450
  num_env_steps_trained: 5457500
  num_samples_added_to_queue: 5474000
  num_training_step_calls_since_last_synch_worker_weights: 979
  num_weight_broadcasts: 107639
custom_metrics: {}
date: 2023-08-14_16-36-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 42770
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001658764376770705
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00032432947773486376
        total_loss: 0.6185015439987183
        var_gnorm: 65.00994873046875
        vf_explained_var: -1.0
        vf_loss: 1.2393105030059814
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10915.0
  learner_queue:
    size_count: 10920
    size_mean: 15.24
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5041276541570532
  num_agent_steps_sampled: 5474450
  num_agent_steps_trained: 5457500
  num_env_steps_sampled: 5474450
  num_env_steps_trained: 5457500
  num_samples_added_to_queue: 5474000
  num_training_step_calls_since_last_synch_worker_weights: 979
  num_weight_broadcasts: 107639
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 291.34
    learner_load_time_ms: 1.649
    learner_load_wait_time_ms: 1.687
iterations_since_restore: 437
node_ip: 127.0.0.1
num_agent_steps_sampled: 5474450
num_agent_steps_trained: 5457500
num_env_steps_sampled: 5474450
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.9958064699094
num_env_steps_trained: 5457500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9959087511313
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.24285714285714
  ram_util_percent: 77.47857142857144
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06385412274042869
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024850614443728027
  mean_inference_ms: 1.1967835457162304
  mean_raw_obs_processing_ms: 0.2721077585823081
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023202896118164062
    StateBufferConnector_ms: 0.0038318634033203125
    ViewRequirementAgentConnector_ms: 0.12996149063110352
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06385412274042869
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024850614443728027
    mean_inference_ms: 1.1967835457162304
    mean_raw_obs_processing_ms: 0.2721077585823081
time_since_restore: 4432.989217758179
time_this_iter_s: 10.12465500831604
time_total_s: 4432.989217758179
timers:
  sample_time_ms: 0.019
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.052
timestamp: 1691998615
timesteps_total: 5474450
training_iteration: 437
trial_id: default
train step: 438
agent_timesteps_total: 5487550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019792481964709712
  StateBufferConnector_ms: 0.0036232611712287456
  ViewRequirementAgentConnector_ms: 0.11892575843661439
counters:
  num_agent_steps_sampled: 5487550
  num_agent_steps_trained: 5471000
  num_env_steps_sampled: 5487550
  num_env_steps_trained: 5471000
  num_samples_added_to_queue: 5487500
  num_training_step_calls_since_last_synch_worker_weights: 88
  num_weight_broadcasts: 107898
custom_metrics: {}
date: 2023-08-14_16-37-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 42872
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00020645091717597097
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00016538916679564863
        total_loss: 0.1696750819683075
        var_gnorm: 65.00932312011719
        vf_explained_var: -1.0
        vf_loss: 0.3410838842391968
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10942.0
  learner_queue:
    size_count: 10948
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3152946437965904
  num_agent_steps_sampled: 5487550
  num_agent_steps_trained: 5471000
  num_env_steps_sampled: 5487550
  num_env_steps_trained: 5471000
  num_samples_added_to_queue: 5487500
  num_training_step_calls_since_last_synch_worker_weights: 88
  num_weight_broadcasts: 107898
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 170.95
    learner_load_time_ms: 1.416
    learner_load_wait_time_ms: 1.741
iterations_since_restore: 438
node_ip: 127.0.0.1
num_agent_steps_sampled: 5487550
num_agent_steps_trained: 5471000
num_env_steps_sampled: 5487550
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.995002765645
num_env_steps_trained: 5471000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9948501783365
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.957142857142856
  ram_util_percent: 78.07142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06383838656940576
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02484557720008141
  mean_inference_ms: 1.196673681642565
  mean_raw_obs_processing_ms: 0.2720782567199583
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019792481964709712
    StateBufferConnector_ms: 0.0036232611712287456
    ViewRequirementAgentConnector_ms: 0.11892575843661439
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06383838656940576
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02484557720008141
    mean_inference_ms: 1.196673681642565
    mean_raw_obs_processing_ms: 0.2720782567199583
time_since_restore: 4443.125926494598
time_this_iter_s: 10.136708736419678
time_total_s: 4443.125926494598
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691998625
timesteps_total: 5487550
training_iteration: 438
trial_id: default
train step: 439
agent_timesteps_total: 5500950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019575082338773288
  StateBufferConnector_ms: 0.0034100734270535982
  ViewRequirementAgentConnector_ms: 0.11817239798032321
counters:
  num_agent_steps_sampled: 5500950
  num_agent_steps_trained: 5484000
  num_env_steps_sampled: 5500950
  num_env_steps_trained: 5484000
  num_samples_added_to_queue: 5500500
  num_training_step_calls_since_last_synch_worker_weights: 430
  num_weight_broadcasts: 108162
custom_metrics: {}
date: 2023-08-14_16-37-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 42976
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00013173164916224778
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0006148565444163978
        total_loss: 1.9351376295089722
        var_gnorm: 65.00926971435547
        vf_explained_var: -1.0
        vf_loss: 3.8703627586364746
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10968.0
  learner_queue:
    size_count: 10974
    size_mean: 15.24
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4636939570825591
  num_agent_steps_sampled: 5500950
  num_agent_steps_trained: 5484000
  num_env_steps_sampled: 5500950
  num_env_steps_trained: 5484000
  num_samples_added_to_queue: 5500500
  num_training_step_calls_since_last_synch_worker_weights: 430
  num_weight_broadcasts: 108162
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 193.049
    learner_load_time_ms: 1.42
    learner_load_wait_time_ms: 1.477
iterations_since_restore: 439
node_ip: 127.0.0.1
num_agent_steps_sampled: 5500950
num_agent_steps_trained: 5484000
num_env_steps_sampled: 5500950
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9958467612248
num_env_steps_trained: 5484000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9959707385017
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.56428571428571
  ram_util_percent: 78.08571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06382751064397502
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024838093269559457
  mean_inference_ms: 1.1964729156940823
  mean_raw_obs_processing_ms: 0.27204321350791427
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019575082338773288
    StateBufferConnector_ms: 0.0034100734270535982
    ViewRequirementAgentConnector_ms: 0.11817239798032321
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06382751064397502
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024838093269559457
    mean_inference_ms: 1.1964729156940823
    mean_raw_obs_processing_ms: 0.27204321350791427
time_since_restore: 4453.252102613449
time_this_iter_s: 10.126176118850708
time_total_s: 4453.252102613449
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998635
timesteps_total: 5500950
training_iteration: 439
trial_id: default
train step: 440
agent_timesteps_total: 5514650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019007258945041232
  StateBufferConnector_ms: 0.0035029870492440684
  ViewRequirementAgentConnector_ms: 0.11609483648229528
counters:
  num_agent_steps_sampled: 5514650
  num_agent_steps_trained: 5498000
  num_env_steps_sampled: 5514650
  num_env_steps_trained: 5498000
  num_samples_added_to_queue: 5514500
  num_training_step_calls_since_last_synch_worker_weights: 70
  num_weight_broadcasts: 108433
custom_metrics: {}
date: 2023-08-14_16-37-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 43084
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.000172085317899473
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0003165099478792399
        total_loss: 0.4643293023109436
        var_gnorm: 65.00877380371094
        vf_explained_var: -1.0
        vf_loss: 0.9310124516487122
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 10996.0
  learner_queue:
    size_count: 11003
    size_mean: 15.18
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5835403373454051
  num_agent_steps_sampled: 5514650
  num_agent_steps_trained: 5498000
  num_env_steps_sampled: 5514650
  num_env_steps_trained: 5498000
  num_samples_added_to_queue: 5514500
  num_training_step_calls_since_last_synch_worker_weights: 70
  num_weight_broadcasts: 108433
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 144.061
    learner_load_time_ms: 1.637
    learner_load_wait_time_ms: 1.529
iterations_since_restore: 440
node_ip: 127.0.0.1
num_agent_steps_sampled: 5514650
num_agent_steps_trained: 5498000
num_env_steps_sampled: 5514650
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.995884430851
num_env_steps_trained: 5498000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.995794308899
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.00000000000001
  ram_util_percent: 77.55333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06381327052904151
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02482909029936257
  mean_inference_ms: 1.1962198989519965
  mean_raw_obs_processing_ms: 0.2719892937151985
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019007258945041232
    StateBufferConnector_ms: 0.0035029870492440684
    ViewRequirementAgentConnector_ms: 0.11609483648229528
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06381327052904151
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02482909029936257
    mean_inference_ms: 1.1962198989519965
    mean_raw_obs_processing_ms: 0.2719892937151985
time_since_restore: 4463.408374547958
time_this_iter_s: 10.156271934509277
time_total_s: 4463.408374547958
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998645
timesteps_total: 5514650
training_iteration: 440
trial_id: default
train step: 441
agent_timesteps_total: 5528050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01917596046741192
  StateBufferConnector_ms: 0.003419014123769907
  ViewRequirementAgentConnector_ms: 0.11583429116469163
counters:
  num_agent_steps_sampled: 5528050
  num_agent_steps_trained: 5511500
  num_env_steps_sampled: 5528050
  num_env_steps_trained: 5511500
  num_samples_added_to_queue: 5528000
  num_training_step_calls_since_last_synch_worker_weights: 553
  num_weight_broadcasts: 108696
custom_metrics: {}
date: 2023-08-14_16-37-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 43188
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00022222175903152674
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0007789889932610095
        total_loss: 1.3383002281188965
        var_gnorm: 65.00943756103516
        vf_explained_var: -1.0
        vf_loss: 2.67726469039917
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11023.0
  learner_queue:
    size_count: 11028
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.632666530556684
  num_agent_steps_sampled: 5528050
  num_agent_steps_trained: 5511500
  num_env_steps_sampled: 5528050
  num_env_steps_trained: 5511500
  num_samples_added_to_queue: 5528000
  num_training_step_calls_since_last_synch_worker_weights: 553
  num_weight_broadcasts: 108696
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 198.968
    learner_load_time_ms: 1.697
    learner_load_wait_time_ms: 1.579
iterations_since_restore: 441
node_ip: 127.0.0.1
num_agent_steps_sampled: 5528050
num_agent_steps_trained: 5511500
num_env_steps_sampled: 5528050
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9957189696706
num_env_steps_trained: 5511500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9956870216831
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.07142857142857
  ram_util_percent: 76.76428571428572
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06380110211488575
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024820914697575087
  mean_inference_ms: 1.1960340501872684
  mean_raw_obs_processing_ms: 0.271944595826903
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01917596046741192
    StateBufferConnector_ms: 0.003419014123769907
    ViewRequirementAgentConnector_ms: 0.11583429116469163
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06380110211488575
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024820914697575087
    mean_inference_ms: 1.1960340501872684
    mean_raw_obs_processing_ms: 0.271944595826903
time_since_restore: 4473.522592544556
time_this_iter_s: 10.11421799659729
time_total_s: 4473.522592544556
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691998655
timesteps_total: 5528050
training_iteration: 441
trial_id: default
train step: 442
agent_timesteps_total: 5541450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019365319838890664
  StateBufferConnector_ms: 0.0035191957767193136
  ViewRequirementAgentConnector_ms: 0.11747364814464863
counters:
  num_agent_steps_sampled: 5541450
  num_agent_steps_trained: 5524500
  num_env_steps_sampled: 5541450
  num_env_steps_trained: 5524500
  num_samples_added_to_queue: 5541000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 108961
custom_metrics: {}
date: 2023-08-14_16-37-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 43292
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00019645673455670476
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0007358767325058579
        total_loss: 1.1349643468856812
        var_gnorm: 65.00741577148438
        vf_explained_var: -1.0
        vf_loss: 2.273365020751953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11049.0
  learner_queue:
    size_count: 11054
    size_mean: 15.36
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2289833196589774
  num_agent_steps_sampled: 5541450
  num_agent_steps_trained: 5524500
  num_env_steps_sampled: 5541450
  num_env_steps_trained: 5524500
  num_samples_added_to_queue: 5541000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 108961
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 236.085
    learner_load_time_ms: 1.707
    learner_load_wait_time_ms: 1.615
iterations_since_restore: 442
node_ip: 127.0.0.1
num_agent_steps_sampled: 5541450
num_agent_steps_trained: 5524500
num_env_steps_sampled: 5541450
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.80128040873
num_env_steps_trained: 5524500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.8072123368277
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 49.271428571428565
  ram_util_percent: 76.44285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06379119989776078
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024814220756081203
  mean_inference_ms: 1.1958520063740907
  mean_raw_obs_processing_ms: 0.27190426279987123
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019365319838890664
    StateBufferConnector_ms: 0.0035191957767193136
    ViewRequirementAgentConnector_ms: 0.11747364814464863
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06379119989776078
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024814220756081203
    mean_inference_ms: 1.1958520063740907
    mean_raw_obs_processing_ms: 0.27190426279987123
time_since_restore: 4483.647310733795
time_this_iter_s: 10.124718189239502
time_total_s: 4483.647310733795
timers:
  sample_time_ms: 0.045
  synch_weights_time_ms: 0.278
  training_iteration_time_ms: 0.399
timestamp: 1691998665
timesteps_total: 5541450
training_iteration: 442
trial_id: default
train step: 443
agent_timesteps_total: 5555000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019858039428140517
  StateBufferConnector_ms: 0.003522355979848131
  ViewRequirementAgentConnector_ms: 0.11716423747695495
counters:
  num_agent_steps_sampled: 5555000
  num_agent_steps_trained: 5538500
  num_env_steps_sampled: 5555000
  num_env_steps_trained: 5538500
  num_samples_added_to_queue: 5555000
  num_training_step_calls_since_last_synch_worker_weights: 109
  num_weight_broadcasts: 109230
custom_metrics: {}
date: 2023-08-14_16-37-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 43399
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001515577605459839
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00033363746479153633
        total_loss: 0.5464293360710144
        var_gnorm: 65.00872802734375
        vf_explained_var: -1.0
        vf_loss: 1.0937069654464722
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11077.0
  learner_queue:
    size_count: 11082
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2649110640673518
  num_agent_steps_sampled: 5555000
  num_agent_steps_trained: 5538500
  num_env_steps_sampled: 5555000
  num_env_steps_trained: 5538500
  num_samples_added_to_queue: 5555000
  num_training_step_calls_since_last_synch_worker_weights: 109
  num_weight_broadcasts: 109230
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 205.897
    learner_load_time_ms: 1.835
    learner_load_wait_time_ms: 1.576
iterations_since_restore: 443
node_ip: 127.0.0.1
num_agent_steps_sampled: 5555000
num_agent_steps_trained: 5538500
num_env_steps_sampled: 5555000
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9986431612251
num_env_steps_trained: 5538500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9985981001587
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.919999999999995
  ram_util_percent: 76.55333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06377706032595237
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024806778863295312
  mean_inference_ms: 1.1956294805285201
  mean_raw_obs_processing_ms: 0.27185580600698506
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019858039428140517
    StateBufferConnector_ms: 0.003522355979848131
    ViewRequirementAgentConnector_ms: 0.11716423747695495
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06377706032595237
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024806778863295312
    mean_inference_ms: 1.1956294805285201
    mean_raw_obs_processing_ms: 0.27185580600698506
time_since_restore: 4493.825210809708
time_this_iter_s: 10.177900075912476
time_total_s: 4493.825210809708
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998675
timesteps_total: 5555000
training_iteration: 443
trial_id: default
train step: 444
agent_timesteps_total: 5568550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01921946147702775
  StateBufferConnector_ms: 0.00342243122604658
  ViewRequirementAgentConnector_ms: 0.11694183889425026
counters:
  num_agent_steps_sampled: 5568550
  num_agent_steps_trained: 5552000
  num_env_steps_sampled: 5568550
  num_env_steps_trained: 5552000
  num_samples_added_to_queue: 5568500
  num_training_step_calls_since_last_synch_worker_weights: 373
  num_weight_broadcasts: 109498
custom_metrics: {}
date: 2023-08-14_16-38-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 43505
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00019092833099421114
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00040301517583429813
        total_loss: 0.6917542219161987
        var_gnorm: 65.0069580078125
        vf_explained_var: -1.0
        vf_loss: 1.3862236738204956
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11104.0
  learner_queue:
    size_count: 11109
    size_mean: 15.46
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1525623627379127
  num_agent_steps_sampled: 5568550
  num_agent_steps_trained: 5552000
  num_env_steps_sampled: 5568550
  num_env_steps_trained: 5552000
  num_samples_added_to_queue: 5568500
  num_training_step_calls_since_last_synch_worker_weights: 373
  num_weight_broadcasts: 109498
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 201.366
    learner_load_time_ms: 1.812
    learner_load_wait_time_ms: 1.515
iterations_since_restore: 444
node_ip: 127.0.0.1
num_agent_steps_sampled: 5568550
num_agent_steps_trained: 5552000
num_env_steps_sampled: 5568550
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9962202415998
num_env_steps_trained: 5552000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9962341890478
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.31428571428571
  ram_util_percent: 74.39285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06376703051644647
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024799149691131096
  mean_inference_ms: 1.195406351165963
  mean_raw_obs_processing_ms: 0.27180797306277676
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01921946147702775
    StateBufferConnector_ms: 0.00342243122604658
    ViewRequirementAgentConnector_ms: 0.11694183889425026
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06376703051644647
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024799149691131096
    mean_inference_ms: 1.195406351165963
    mean_raw_obs_processing_ms: 0.27180797306277676
time_since_restore: 4503.941959857941
time_this_iter_s: 10.116749048233032
time_total_s: 4503.941959857941
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691998686
timesteps_total: 5568550
training_iteration: 444
trial_id: default
train step: 445
agent_timesteps_total: 5582150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018707536301522883
  StateBufferConnector_ms: 0.003401288446390404
  ViewRequirementAgentConnector_ms: 0.11784580518614571
counters:
  num_agent_steps_sampled: 5582150
  num_agent_steps_trained: 5565500
  num_env_steps_sampled: 5582150
  num_env_steps_trained: 5565500
  num_samples_added_to_queue: 5582000
  num_training_step_calls_since_last_synch_worker_weights: 1017
  num_weight_broadcasts: 109767
custom_metrics: {}
date: 2023-08-14_16-38-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 43611
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002180839510401711
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 9.366793528897688e-05
        total_loss: 0.2765834331512451
        var_gnorm: 65.00902557373047
        vf_explained_var: -1.0
        vf_loss: 0.5551603436470032
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11131.0
  learner_queue:
    size_count: 11136
    size_mean: 15.46
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1525623627379127
  num_agent_steps_sampled: 5582150
  num_agent_steps_trained: 5565500
  num_env_steps_sampled: 5582150
  num_env_steps_trained: 5565500
  num_samples_added_to_queue: 5582000
  num_training_step_calls_since_last_synch_worker_weights: 1017
  num_weight_broadcasts: 109767
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 211.45
    learner_load_time_ms: 1.635
    learner_load_wait_time_ms: 1.635
iterations_since_restore: 445
node_ip: 127.0.0.1
num_agent_steps_sampled: 5582150
num_agent_steps_trained: 5565500
num_env_steps_sampled: 5582150
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9942608121833
num_env_steps_trained: 5565500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9943030120937
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.75714285714286
  ram_util_percent: 74.54285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06375362275220302
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024790824885909453
  mean_inference_ms: 1.1951729245309517
  mean_raw_obs_processing_ms: 0.27175873763299085
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018707536301522883
    StateBufferConnector_ms: 0.003401288446390404
    ViewRequirementAgentConnector_ms: 0.11784580518614571
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06375362275220302
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024790824885909453
    mean_inference_ms: 1.1951729245309517
    mean_raw_obs_processing_ms: 0.27175873763299085
time_since_restore: 4514.057088851929
time_this_iter_s: 10.115128993988037
time_total_s: 4514.057088851929
timers:
  sample_time_ms: 0.018
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.049
timestamp: 1691998696
timesteps_total: 5582150
training_iteration: 445
trial_id: default
train step: 446
agent_timesteps_total: 5595800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01868526890592755
  StateBufferConnector_ms: 0.003341908724802845
  ViewRequirementAgentConnector_ms: 0.11399601990321898
counters:
  num_agent_steps_sampled: 5595800
  num_agent_steps_trained: 5579000
  num_env_steps_sampled: 5595800
  num_env_steps_trained: 5579000
  num_samples_added_to_queue: 5595500
  num_training_step_calls_since_last_synch_worker_weights: 61
  num_weight_broadcasts: 110036
custom_metrics: {}
date: 2023-08-14_16-38-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 43717
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001457344915252179
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00020176175166852772
        total_loss: 0.318099707365036
        var_gnorm: 65.00596618652344
        vf_explained_var: -1.0
        vf_loss: 0.6380602717399597
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11158.0
  learner_queue:
    size_count: 11165
    size_mean: 15.3
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4594519519326423
  num_agent_steps_sampled: 5595800
  num_agent_steps_trained: 5579000
  num_env_steps_sampled: 5595800
  num_env_steps_trained: 5579000
  num_samples_added_to_queue: 5595500
  num_training_step_calls_since_last_synch_worker_weights: 61
  num_weight_broadcasts: 110036
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 148.631
    learner_load_time_ms: 1.635
    learner_load_wait_time_ms: 1.525
iterations_since_restore: 446
node_ip: 127.0.0.1
num_agent_steps_sampled: 5595800
num_agent_steps_trained: 5579000
num_env_steps_sampled: 5595800
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.9969734020585
num_env_steps_trained: 5579000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9970066613764
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.7
  ram_util_percent: 74.56666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06374045760117754
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024782118482377265
  mean_inference_ms: 1.1949377417812608
  mean_raw_obs_processing_ms: 0.2717097787950187
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01868526890592755
    StateBufferConnector_ms: 0.003341908724802845
    ViewRequirementAgentConnector_ms: 0.11399601990321898
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06374045760117754
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024782118482377265
    mean_inference_ms: 1.1949377417812608
    mean_raw_obs_processing_ms: 0.2717097787950187
time_since_restore: 4524.218623876572
time_this_iter_s: 10.161535024642944
time_total_s: 4524.218623876572
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691998706
timesteps_total: 5595800
training_iteration: 446
trial_id: default
train step: 447
agent_timesteps_total: 5609450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0185092290242513
  StateBufferConnector_ms: 0.00332880903173376
  ViewRequirementAgentConnector_ms: 0.11477956065425167
counters:
  num_agent_steps_sampled: 5609450
  num_agent_steps_trained: 5592500
  num_env_steps_sampled: 5609450
  num_env_steps_trained: 5592500
  num_samples_added_to_queue: 5609000
  num_training_step_calls_since_last_synch_worker_weights: 346
  num_weight_broadcasts: 110306
custom_metrics: {}
date: 2023-08-14_16-38-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 43825
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001491579896537587
        entropy_coeff: 0.01
        grad_gnorm: 16.477712631225586
        policy_loss: 4.126144995098002e-05
        total_loss: 0.16972588002681732
        var_gnorm: 65.0059585571289
        vf_explained_var: -1.0
        vf_loss: 0.3408608138561249
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11185.0
  learner_queue:
    size_count: 11192
    size_mean: 14.86
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9079832284378182
  num_agent_steps_sampled: 5609450
  num_agent_steps_trained: 5592500
  num_env_steps_sampled: 5609450
  num_env_steps_trained: 5592500
  num_samples_added_to_queue: 5609000
  num_training_step_calls_since_last_synch_worker_weights: 346
  num_weight_broadcasts: 110306
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 160.48
    learner_load_time_ms: 2.173
    learner_load_wait_time_ms: 1.605
iterations_since_restore: 447
node_ip: 127.0.0.1
num_agent_steps_sampled: 5609450
num_agent_steps_trained: 5592500
num_env_steps_sampled: 5609450
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.9951834848605
num_env_steps_trained: 5592500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9952364135984
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.26428571428572
  ram_util_percent: 74.72142857142858
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06372754330869489
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024774175186299072
  mean_inference_ms: 1.1947118012237807
  mean_raw_obs_processing_ms: 0.27166055005222733
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0185092290242513
    StateBufferConnector_ms: 0.00332880903173376
    ViewRequirementAgentConnector_ms: 0.11477956065425167
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06372754330869489
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024774175186299072
    mean_inference_ms: 1.1947118012237807
    mean_raw_obs_processing_ms: 0.27166055005222733
time_since_restore: 4534.382069826126
time_this_iter_s: 10.163445949554443
time_total_s: 4534.382069826126
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998716
timesteps_total: 5609450
training_iteration: 447
trial_id: default
train step: 448
agent_timesteps_total: 5623100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018859359453309257
  StateBufferConnector_ms: 0.003393865981191959
  ViewRequirementAgentConnector_ms: 0.1147029534825739
counters:
  num_agent_steps_sampled: 5623100
  num_agent_steps_trained: 5606500
  num_env_steps_sampled: 5623100
  num_env_steps_trained: 5606500
  num_samples_added_to_queue: 5623000
  num_training_step_calls_since_last_synch_worker_weights: 1750
  num_weight_broadcasts: 110574
custom_metrics: {}
date: 2023-08-14_16-38-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 43931
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00020731217227876186
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0005247031804174185
        total_loss: 0.5826708674430847
        var_gnorm: 65.00536346435547
        vf_explained_var: -1.0
        vf_loss: 1.1663655042648315
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11213.0
  learner_queue:
    size_count: 11217
    size_mean: 15.2
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4966629547095767
  num_agent_steps_sampled: 5623100
  num_agent_steps_trained: 5606500
  num_env_steps_sampled: 5623100
  num_env_steps_trained: 5606500
  num_samples_added_to_queue: 5623000
  num_training_step_calls_since_last_synch_worker_weights: 1750
  num_weight_broadcasts: 110574
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 244.54
    learner_load_time_ms: 2.043
    learner_load_wait_time_ms: 1.544
iterations_since_restore: 448
node_ip: 127.0.0.1
num_agent_steps_sampled: 5623100
num_agent_steps_trained: 5606500
num_env_steps_sampled: 5623100
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.9980798986742
num_env_steps_trained: 5606500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9980306653067
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.892857142857146
  ram_util_percent: 74.76428571428572
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06371411701477384
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024765669504115906
  mean_inference_ms: 1.194472805848291
  mean_raw_obs_processing_ms: 0.27160953488614026
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018859359453309257
    StateBufferConnector_ms: 0.003393865981191959
    ViewRequirementAgentConnector_ms: 0.1147029534825739
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06371411701477384
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024765669504115906
    mean_inference_ms: 1.194472805848291
    mean_raw_obs_processing_ms: 0.27160953488614026
time_since_restore: 4544.502532720566
time_this_iter_s: 10.120462894439697
time_total_s: 4544.502532720566
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691998726
timesteps_total: 5623100
training_iteration: 448
trial_id: default
train step: 449
agent_timesteps_total: 5634300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021986007690429688
  StateBufferConnector_ms: 0.003996133804321289
  ViewRequirementAgentConnector_ms: 0.1321096420288086
counters:
  num_agent_steps_sampled: 5634300
  num_agent_steps_trained: 5617500
  num_env_steps_sampled: 5634300
  num_env_steps_trained: 5617500
  num_samples_added_to_queue: 5634000
  num_training_step_calls_since_last_synch_worker_weights: 285
  num_weight_broadcasts: 110795
custom_metrics: {}
date: 2023-08-14_16-38-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 87
episodes_total: 44018
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001591827312950045
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0002527545439079404
        total_loss: 0.3112790286540985
        var_gnorm: 65.00494384765625
        vf_explained_var: -1.0
        vf_loss: 0.6246553659439087
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11235.0
  learner_queue:
    size_count: 11242
    size_mean: 15.24
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4636939570825591
  num_agent_steps_sampled: 5634300
  num_agent_steps_trained: 5617500
  num_env_steps_sampled: 5634300
  num_env_steps_trained: 5617500
  num_samples_added_to_queue: 5634000
  num_training_step_calls_since_last_synch_worker_weights: 285
  num_weight_broadcasts: 110795
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 143.252
    learner_load_time_ms: 2.038
    learner_load_wait_time_ms: 1.579
iterations_since_restore: 449
node_ip: 127.0.0.1
num_agent_steps_sampled: 5634300
num_agent_steps_trained: 5617500
num_env_steps_sampled: 5634300
num_env_steps_sampled_this_iter: 11200
num_env_steps_sampled_throughput_per_sec: 1119.9958610687622
num_env_steps_trained: 5617500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9959349782487
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 63.521428571428565
  ram_util_percent: 77.40714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06375602217319372
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024768305108942377
  mean_inference_ms: 1.1946912441321016
  mean_raw_obs_processing_ms: 0.27167591009867015
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021986007690429688
    StateBufferConnector_ms: 0.003996133804321289
    ViewRequirementAgentConnector_ms: 0.1321096420288086
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 87
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06375602217319372
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024768305108942377
    mean_inference_ms: 1.1946912441321016
    mean_raw_obs_processing_ms: 0.27167591009867015
time_since_restore: 4554.645359039307
time_this_iter_s: 10.142826318740845
time_total_s: 4554.645359039307
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691998736
timesteps_total: 5634300
training_iteration: 449
trial_id: default
train step: 450
agent_timesteps_total: 5648000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018608570098876953
  StateBufferConnector_ms: 0.003335873285929362
  ViewRequirementAgentConnector_ms: 0.11469390657213
counters:
  num_agent_steps_sampled: 5648000
  num_agent_steps_trained: 5631500
  num_env_steps_sampled: 5648000
  num_env_steps_trained: 5631500
  num_samples_added_to_queue: 5648000
  num_training_step_calls_since_last_synch_worker_weights: 161
  num_weight_broadcasts: 111066
custom_metrics: {}
date: 2023-08-14_16-39-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 44126
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00021316803758963943
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0003442258748691529
        total_loss: 0.3655085265636444
        var_gnorm: 65.00466918945312
        vf_explained_var: -1.0
        vf_loss: 0.7324603199958801
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11263.0
  learner_queue:
    size_count: 11269
    size_mean: 15.06
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.678213335663854
  num_agent_steps_sampled: 5648000
  num_agent_steps_trained: 5631500
  num_env_steps_sampled: 5648000
  num_env_steps_trained: 5631500
  num_samples_added_to_queue: 5648000
  num_training_step_calls_since_last_synch_worker_weights: 161
  num_weight_broadcasts: 111066
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 155.547
    learner_load_time_ms: 2.02
    learner_load_wait_time_ms: 1.395
iterations_since_restore: 450
node_ip: 127.0.0.1
num_agent_steps_sampled: 5648000
num_agent_steps_trained: 5631500
num_env_steps_sampled: 5648000
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9950678526104
num_env_steps_trained: 5631500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.994959849383
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.89333333333333
  ram_util_percent: 77.77999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06371812655108576
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024760931379208383
  mean_inference_ms: 1.194513754538784
  mean_raw_obs_processing_ms: 0.27161472265549097
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018608570098876953
    StateBufferConnector_ms: 0.003335873285929362
    ViewRequirementAgentConnector_ms: 0.11469390657213
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06371812655108576
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024760931379208383
    mean_inference_ms: 1.194513754538784
    mean_raw_obs_processing_ms: 0.27161472265549097
time_since_restore: 4564.783045768738
time_this_iter_s: 10.137686729431152
time_total_s: 4564.783045768738
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691998746
timesteps_total: 5648000
training_iteration: 450
trial_id: default
train step: 451
agent_timesteps_total: 5661300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01997191172379714
  StateBufferConnector_ms: 0.0035794881673959587
  ViewRequirementAgentConnector_ms: 0.11983215808868408
counters:
  num_agent_steps_sampled: 5661300
  num_agent_steps_trained: 5644500
  num_env_steps_sampled: 5661300
  num_env_steps_trained: 5644500
  num_samples_added_to_queue: 5661000
  num_training_step_calls_since_last_synch_worker_weights: 786
  num_weight_broadcasts: 111329
custom_metrics: {}
date: 2023-08-14_16-39-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 44230
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001901920622913167
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00026862829690799117
        total_loss: 0.5833616852760315
        var_gnorm: 65.00470733642578
        vf_explained_var: -1.0
        vf_loss: 1.1691625118255615
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11289.0
  learner_queue:
    size_count: 11294
    size_mean: 15.26
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3536617007214173
  num_agent_steps_sampled: 5661300
  num_agent_steps_trained: 5644500
  num_env_steps_sampled: 5661300
  num_env_steps_trained: 5644500
  num_samples_added_to_queue: 5661000
  num_training_step_calls_since_last_synch_worker_weights: 786
  num_weight_broadcasts: 111329
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 225.349
    learner_load_time_ms: 2.025
    learner_load_wait_time_ms: 1.589
iterations_since_restore: 451
node_ip: 127.0.0.1
num_agent_steps_sampled: 5661300
num_agent_steps_trained: 5644500
num_env_steps_sampled: 5661300
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9980022937264
num_env_steps_trained: 5644500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.99804735477
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.07857142857143
  ram_util_percent: 77.6857142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06370882019301918
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024754970153095655
  mean_inference_ms: 1.1943453055534823
  mean_raw_obs_processing_ms: 0.27158462382057375
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01997191172379714
    StateBufferConnector_ms: 0.0035794881673959587
    ViewRequirementAgentConnector_ms: 0.11983215808868408
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06370882019301918
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024754970153095655
    mean_inference_ms: 1.1943453055534823
    mean_raw_obs_processing_ms: 0.27158462382057375
time_since_restore: 4574.902822732925
time_this_iter_s: 10.119776964187622
time_total_s: 4574.902822732925
timers:
  sample_time_ms: 0.018
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.05
timestamp: 1691998757
timesteps_total: 5661300
training_iteration: 451
trial_id: default
train step: 452
agent_timesteps_total: 5674600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01961176212017353
  StateBufferConnector_ms: 0.003502002129187951
  ViewRequirementAgentConnector_ms: 0.11863204149099496
counters:
  num_agent_steps_sampled: 5674600
  num_agent_steps_trained: 5658000
  num_env_steps_sampled: 5674600
  num_env_steps_trained: 5658000
  num_samples_added_to_queue: 5674500
  num_training_step_calls_since_last_synch_worker_weights: 324
  num_weight_broadcasts: 111591
custom_metrics: {}
date: 2023-08-14_16-39-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 44334
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002130226494045928
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00043221129453741014
        total_loss: 0.5818416476249695
        var_gnorm: 65.00477600097656
        vf_explained_var: -1.0
        vf_loss: 1.1649491786956787
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11316.0
  learner_queue:
    size_count: 11322
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3098091464026353
  num_agent_steps_sampled: 5674600
  num_agent_steps_trained: 5658000
  num_env_steps_sampled: 5674600
  num_env_steps_trained: 5658000
  num_samples_added_to_queue: 5674500
  num_training_step_calls_since_last_synch_worker_weights: 324
  num_weight_broadcasts: 111591
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 166.916
    learner_load_time_ms: 3.441
    learner_load_wait_time_ms: 1.528
iterations_since_restore: 452
node_ip: 127.0.0.1
num_agent_steps_sampled: 5674600
num_agent_steps_trained: 5658000
num_env_steps_sampled: 5674600
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9947045060242
num_env_steps_trained: 5658000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9946248745357
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.22857142857144
  ram_util_percent: 78.07857142857144
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0636996475871928
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024748982177310627
  mean_inference_ms: 1.1941832948089242
  mean_raw_obs_processing_ms: 0.271552559595847
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01961176212017353
    StateBufferConnector_ms: 0.003502002129187951
    ViewRequirementAgentConnector_ms: 0.11863204149099496
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0636996475871928
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024748982177310627
    mean_inference_ms: 1.1941832948089242
    mean_raw_obs_processing_ms: 0.271552559595847
time_since_restore: 4585.040975570679
time_this_iter_s: 10.138152837753296
time_total_s: 4585.040975570679
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998767
timesteps_total: 5674600
training_iteration: 452
trial_id: default
train step: 453
agent_timesteps_total: 5688000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01939856089078463
  StateBufferConnector_ms: 0.0035597727848933293
  ViewRequirementAgentConnector_ms: 0.11716737196995662
counters:
  num_agent_steps_sampled: 5688000
  num_agent_steps_trained: 5671500
  num_env_steps_sampled: 5688000
  num_env_steps_trained: 5671500
  num_samples_added_to_queue: 5688000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 111855
custom_metrics: {}
date: 2023-08-14_16-39-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 44438
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00019131532462779433
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0004755223053507507
        total_loss: 0.7373340129852295
        var_gnorm: 65.00322723388672
        vf_explained_var: -1.0
        vf_loss: 1.4756301641464233
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11343.0
  learner_queue:
    size_count: 11349
    size_mean: 15.16
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5538339679644027
  num_agent_steps_sampled: 5688000
  num_agent_steps_trained: 5671500
  num_env_steps_sampled: 5688000
  num_env_steps_trained: 5671500
  num_samples_added_to_queue: 5688000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 111855
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 157.929
    learner_load_time_ms: 2.82
    learner_load_wait_time_ms: 1.388
iterations_since_restore: 453
node_ip: 127.0.0.1
num_agent_steps_sampled: 5688000
num_agent_steps_trained: 5671500
num_env_steps_sampled: 5688000
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.872571189726
num_env_steps_trained: 5671500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.8716202284552
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.940000000000005
  ram_util_percent: 76.92
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06368991653327899
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024742031582864567
  mean_inference_ms: 1.1940048177916833
  mean_raw_obs_processing_ms: 0.2715167202288684
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01939856089078463
    StateBufferConnector_ms: 0.0035597727848933293
    ViewRequirementAgentConnector_ms: 0.11716737196995662
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06368991653327899
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024742031582864567
    mean_inference_ms: 1.1940048177916833
    mean_raw_obs_processing_ms: 0.2715167202288684
time_since_restore: 4595.173201560974
time_this_iter_s: 10.13222599029541
time_total_s: 4595.173201560974
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.42
  training_iteration_time_ms: 2.161
timestamp: 1691998777
timesteps_total: 5688000
training_iteration: 453
trial_id: default
train step: 454
agent_timesteps_total: 5701250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019482007393470176
  StateBufferConnector_ms: 0.003583843891437237
  ViewRequirementAgentConnector_ms: 0.118483488376324
counters:
  num_agent_steps_sampled: 5701250
  num_agent_steps_trained: 5684500
  num_env_steps_sampled: 5701250
  num_env_steps_trained: 5684500
  num_samples_added_to_queue: 5701000
  num_training_step_calls_since_last_synch_worker_weights: 1
  num_weight_broadcasts: 112117
custom_metrics: {}
date: 2023-08-14_16-39-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 44542
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001766909845173359
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00019869279640261084
        total_loss: 0.28460633754730225
        var_gnorm: 65.0029525756836
        vf_explained_var: -1.0
        vf_loss: 0.5713769793510437
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11369.0
  learner_queue:
    size_count: 11376
    size_mean: 15.1
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6401219466856725
  num_agent_steps_sampled: 5701250
  num_agent_steps_trained: 5684500
  num_env_steps_sampled: 5701250
  num_env_steps_trained: 5684500
  num_samples_added_to_queue: 5701000
  num_training_step_calls_since_last_synch_worker_weights: 1
  num_weight_broadcasts: 112117
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 140.243
    learner_load_time_ms: 2.819
    learner_load_wait_time_ms: 1.506
iterations_since_restore: 454
node_ip: 127.0.0.1
num_agent_steps_sampled: 5701250
num_agent_steps_trained: 5684500
num_env_steps_sampled: 5701250
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.9876482446084
num_env_steps_trained: 5684500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.987881296597
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.23571428571428
  ram_util_percent: 76.32142857142856
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06368020506168709
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024735577508586425
  mean_inference_ms: 1.193858566211219
  mean_raw_obs_processing_ms: 0.27147894830964037
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019482007393470176
    StateBufferConnector_ms: 0.003583843891437237
    ViewRequirementAgentConnector_ms: 0.118483488376324
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06368020506168709
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024735577508586425
    mean_inference_ms: 1.193858566211219
    mean_raw_obs_processing_ms: 0.27147894830964037
time_since_restore: 4605.334196567535
time_this_iter_s: 10.16099500656128
time_total_s: 4605.334196567535
timers:
  sample_time_ms: 0.052
  synch_weights_time_ms: 0.265
  training_iteration_time_ms: 0.392
timestamp: 1691998787
timesteps_total: 5701250
training_iteration: 454
trial_id: default
train step: 455
agent_timesteps_total: 5714650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01930113022144024
  StateBufferConnector_ms: 0.003478848017179049
  ViewRequirementAgentConnector_ms: 0.11719511105464055
counters:
  num_agent_steps_sampled: 5714650
  num_agent_steps_trained: 5698000
  num_env_steps_sampled: 5714650
  num_env_steps_trained: 5698000
  num_samples_added_to_queue: 5714500
  num_training_step_calls_since_last_synch_worker_weights: 1020
  num_weight_broadcasts: 112378
custom_metrics: {}
date: 2023-08-14_16-39-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 44646
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002397318312432617
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00021182975615374744
        total_loss: 0.36310461163520813
        var_gnorm: 65.00225067138672
        vf_explained_var: -1.0
        vf_loss: 0.728182852268219
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11396.0
  learner_queue:
    size_count: 11400
    size_mean: 15.1
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.6401219466856727
  num_agent_steps_sampled: 5714650
  num_agent_steps_trained: 5698000
  num_env_steps_sampled: 5714650
  num_env_steps_trained: 5698000
  num_samples_added_to_queue: 5714500
  num_training_step_calls_since_last_synch_worker_weights: 1020
  num_weight_broadcasts: 112378
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 245.148
    learner_load_time_ms: 2.834
    learner_load_wait_time_ms: 1.638
iterations_since_restore: 455
node_ip: 127.0.0.1
num_agent_steps_sampled: 5714650
num_agent_steps_trained: 5698000
num_env_steps_sampled: 5714650
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9988179217276
num_env_steps_trained: 5698000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9988091002479
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.292857142857144
  ram_util_percent: 75.66428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06367000809956593
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024728660435204566
  mean_inference_ms: 1.1936731907839027
  mean_raw_obs_processing_ms: 0.271439799232309
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01930113022144024
    StateBufferConnector_ms: 0.003478848017179049
    ViewRequirementAgentConnector_ms: 0.11719511105464055
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06367000809956593
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024728660435204566
    mean_inference_ms: 1.1936731907839027
    mean_raw_obs_processing_ms: 0.271439799232309
time_since_restore: 4615.436245679855
time_this_iter_s: 10.102049112319946
time_total_s: 4615.436245679855
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998797
timesteps_total: 5714650
training_iteration: 455
trial_id: default
train step: 456
agent_timesteps_total: 5728050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01953011467343285
  StateBufferConnector_ms: 0.003501347133091518
  ViewRequirementAgentConnector_ms: 0.11767977759951637
counters:
  num_agent_steps_sampled: 5728050
  num_agent_steps_trained: 5711500
  num_env_steps_sampled: 5728050
  num_env_steps_trained: 5711500
  num_samples_added_to_queue: 5728000
  num_training_step_calls_since_last_synch_worker_weights: 146
  num_weight_broadcasts: 112643
custom_metrics: {}
date: 2023-08-14_16-40-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 44751
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002216621651314199
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.000485585886053741
        total_loss: 0.5865548849105835
        var_gnorm: 65.00248718261719
        vf_explained_var: -1.0
        vf_loss: 1.1762975454330444
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11423.0
  learner_queue:
    size_count: 11429
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1697863052711808
  num_agent_steps_sampled: 5728050
  num_agent_steps_trained: 5711500
  num_env_steps_sampled: 5728050
  num_env_steps_trained: 5711500
  num_samples_added_to_queue: 5728000
  num_training_step_calls_since_last_synch_worker_weights: 146
  num_weight_broadcasts: 112643
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 159.375
    learner_load_time_ms: 2.831
    learner_load_wait_time_ms: 1.596
iterations_since_restore: 456
node_ip: 127.0.0.1
num_agent_steps_sampled: 5728050
num_agent_steps_trained: 5711500
num_env_steps_sampled: 5728050
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9942493685512
num_env_steps_trained: 5711500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9942064533911
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.9357142857143
  ram_util_percent: 76.33571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06365810145638368
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02472244175742831
  mean_inference_ms: 1.193496266499492
  mean_raw_obs_processing_ms: 0.2713957177998287
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01953011467343285
    StateBufferConnector_ms: 0.003501347133091518
    ViewRequirementAgentConnector_ms: 0.11767977759951637
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06365810145638368
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02472244175742831
    mean_inference_ms: 1.193496266499492
    mean_raw_obs_processing_ms: 0.2713957177998287
time_since_restore: 4625.569997549057
time_this_iter_s: 10.13375186920166
time_total_s: 4625.569997549057
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998807
timesteps_total: 5728050
training_iteration: 456
trial_id: default
train step: 457
agent_timesteps_total: 5741350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019383199006608388
  StateBufferConnector_ms: 0.0034517454869538835
  ViewRequirementAgentConnector_ms: 0.11714523278393792
counters:
  num_agent_steps_sampled: 5741350
  num_agent_steps_trained: 5724500
  num_env_steps_sampled: 5741350
  num_env_steps_trained: 5724500
  num_samples_added_to_queue: 5741000
  num_training_step_calls_since_last_synch_worker_weights: 590
  num_weight_broadcasts: 112905
custom_metrics: {}
date: 2023-08-14_16-40-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 103
episodes_total: 44854
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002564340829849243
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00046132656279951334
        total_loss: 0.3382713794708252
        var_gnorm: 65.00092315673828
        vf_explained_var: -1.0
        vf_loss: 0.678184449672699
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11449.0
  learner_queue:
    size_count: 11454
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 5741350
  num_agent_steps_trained: 5724500
  num_env_steps_sampled: 5741350
  num_env_steps_trained: 5724500
  num_samples_added_to_queue: 5741000
  num_training_step_calls_since_last_synch_worker_weights: 590
  num_weight_broadcasts: 112905
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 222.338
    learner_load_time_ms: 2.826
    learner_load_wait_time_ms: 1.55
iterations_since_restore: 457
node_ip: 127.0.0.1
num_agent_steps_sampled: 5741350
num_agent_steps_trained: 5724500
num_env_steps_sampled: 5741350
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9936580960364
num_env_steps_trained: 5724500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9938011465017
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.693333333333335
  ram_util_percent: 76.55333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06365384766858684
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024715992975246785
  mean_inference_ms: 1.1933388257209518
  mean_raw_obs_processing_ms: 0.2713615601665435
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019383199006608388
    StateBufferConnector_ms: 0.0034517454869538835
    ViewRequirementAgentConnector_ms: 0.11714523278393792
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06365384766858684
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024715992975246785
    mean_inference_ms: 1.1933388257209518
    mean_raw_obs_processing_ms: 0.2713615601665435
time_since_restore: 4635.695297718048
time_this_iter_s: 10.125300168991089
time_total_s: 4635.695297718048
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998817
timesteps_total: 5741350
training_iteration: 457
trial_id: default
train step: 458
agent_timesteps_total: 5754350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019935766855875652
  StateBufferConnector_ms: 0.003954476001215916
  ViewRequirementAgentConnector_ms: 0.12280613768334482
counters:
  num_agent_steps_sampled: 5754350
  num_agent_steps_trained: 5737500
  num_env_steps_sampled: 5754350
  num_env_steps_trained: 5737500
  num_samples_added_to_queue: 5754000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 113161
custom_metrics: {}
date: 2023-08-14_16-40-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 44956
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00021061627194285393
        entropy_coeff: 0.01
        grad_gnorm: 7.641064167022705
        policy_loss: 1.7796312022255734e-05
        total_loss: 0.19110924005508423
        var_gnorm: 65.00030517578125
        vf_explained_var: -1.0
        vf_loss: 0.38428905606269836
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11475.0
  learner_queue:
    size_count: 11481
    size_mean: 15.28
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3422369388450013
  num_agent_steps_sampled: 5754350
  num_agent_steps_trained: 5737500
  num_env_steps_sampled: 5754350
  num_env_steps_trained: 5737500
  num_samples_added_to_queue: 5754000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 113161
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 190.832
    learner_load_time_ms: 2.294
    learner_load_wait_time_ms: 1.652
iterations_since_restore: 458
node_ip: 127.0.0.1
num_agent_steps_sampled: 5754350
num_agent_steps_trained: 5737500
num_env_steps_sampled: 5754350
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9776534107182
num_env_steps_trained: 5737500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9776534107182
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.892857142857146
  ram_util_percent: 77.16428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06364621132891789
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024712261050346428
  mean_inference_ms: 1.193256539716254
  mean_raw_obs_processing_ms: 0.27133878699993375
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019935766855875652
    StateBufferConnector_ms: 0.003954476001215916
    ViewRequirementAgentConnector_ms: 0.12280613768334482
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06364621132891789
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024712261050346428
    mean_inference_ms: 1.193256539716254
    mean_raw_obs_processing_ms: 0.27133878699993375
time_since_restore: 4645.825774908066
time_this_iter_s: 10.1304771900177
time_total_s: 4645.825774908066
timers:
  sample_time_ms: 0.041
  synch_weights_time_ms: 0.259
  training_iteration_time_ms: 0.365
timestamp: 1691998828
timesteps_total: 5754350
training_iteration: 458
trial_id: default
train step: 459
agent_timesteps_total: 5767700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019588378759530876
  StateBufferConnector_ms: 0.003551519834078275
  ViewRequirementAgentConnector_ms: 0.11761394830850455
counters:
  num_agent_steps_sampled: 5767700
  num_agent_steps_trained: 5751000
  num_env_steps_sampled: 5767700
  num_env_steps_trained: 5751000
  num_samples_added_to_queue: 5767500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 113423
custom_metrics: {}
date: 2023-08-14_16-40-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 45060
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00020438319188542664
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.72307157603791e-06
        total_loss: 0.16016077995300293
        var_gnorm: 65.00203704833984
        vf_explained_var: -1.0
        vf_loss: 0.32238084077835083
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11502.0
  learner_queue:
    size_count: 11509
    size_mean: 15.1
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6401219466856727
  num_agent_steps_sampled: 5767700
  num_agent_steps_trained: 5751000
  num_env_steps_sampled: 5767700
  num_env_steps_trained: 5751000
  num_samples_added_to_queue: 5767500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 113423
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 136.957
    learner_load_time_ms: 2.289
    learner_load_wait_time_ms: 1.437
iterations_since_restore: 459
node_ip: 127.0.0.1
num_agent_steps_sampled: 5767700
num_agent_steps_trained: 5751000
num_env_steps_sampled: 5767700
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.8995237875797
num_env_steps_trained: 5751000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.8983948413727
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.77142857142858
  ram_util_percent: 78.39285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06363740036975898
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024706278672564645
  mean_inference_ms: 1.193086785919006
  mean_raw_obs_processing_ms: 0.27130421074589506
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019588378759530876
    StateBufferConnector_ms: 0.003551519834078275
    ViewRequirementAgentConnector_ms: 0.11761394830850455
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06363740036975898
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024706278672564645
    mean_inference_ms: 1.193086785919006
    mean_raw_obs_processing_ms: 0.27130421074589506
time_since_restore: 4655.97643494606
time_this_iter_s: 10.150660037994385
time_total_s: 4655.97643494606
timers:
  sample_time_ms: 0.102
  synch_weights_time_ms: 0.506
  training_iteration_time_ms: 0.717
timestamp: 1691998838
timesteps_total: 5767700
training_iteration: 459
trial_id: default
train step: 460
agent_timesteps_total: 5781050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019287835984002976
  StateBufferConnector_ms: 0.0034541175478980655
  ViewRequirementAgentConnector_ms: 0.11844407944452195
counters:
  num_agent_steps_sampled: 5781050
  num_agent_steps_trained: 5764500
  num_env_steps_sampled: 5781050
  num_env_steps_trained: 5764500
  num_samples_added_to_queue: 5781000
  num_training_step_calls_since_last_synch_worker_weights: 165
  num_weight_broadcasts: 113685
custom_metrics: {}
date: 2023-08-14_16-40-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 45165
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001937097986228764
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0006554170977324247
        total_loss: 1.1060221195220947
        var_gnorm: 65.00040435791016
        vf_explained_var: -1.0
        vf_loss: 2.2126705646514893
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11529.0
  learner_queue:
    size_count: 11534
    size_mean: 15.14
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6125755796240993
  num_agent_steps_sampled: 5781050
  num_agent_steps_trained: 5764500
  num_env_steps_sampled: 5781050
  num_env_steps_trained: 5764500
  num_samples_added_to_queue: 5781000
  num_training_step_calls_since_last_synch_worker_weights: 165
  num_weight_broadcasts: 113685
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 197.926
    learner_load_time_ms: 2.297
    learner_load_wait_time_ms: 1.619
iterations_since_restore: 460
node_ip: 127.0.0.1
num_agent_steps_sampled: 5781050
num_agent_steps_trained: 5764500
num_env_steps_sampled: 5781050
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9994589092541
num_env_steps_trained: 5764500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9994528295827
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.806666666666665
  ram_util_percent: 77.78
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06362538538550973
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0246998892711474
  mean_inference_ms: 1.1929134558776695
  mean_raw_obs_processing_ms: 0.27126626144565497
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019287835984002976
    StateBufferConnector_ms: 0.0034541175478980655
    ViewRequirementAgentConnector_ms: 0.11844407944452195
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06362538538550973
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0246998892711474
    mean_inference_ms: 1.1929134558776695
    mean_raw_obs_processing_ms: 0.27126626144565497
time_since_restore: 4666.104759693146
time_this_iter_s: 10.128324747085571
time_total_s: 4666.104759693146
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998848
timesteps_total: 5781050
training_iteration: 460
trial_id: default
train step: 461
agent_timesteps_total: 5793650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020857810974121094
  StateBufferConnector_ms: 0.0036792755126953125
  ViewRequirementAgentConnector_ms: 0.12287354469299316
counters:
  num_agent_steps_sampled: 5793650
  num_agent_steps_trained: 5777000
  num_env_steps_sampled: 5793650
  num_env_steps_trained: 5777000
  num_samples_added_to_queue: 5793500
  num_training_step_calls_since_last_synch_worker_weights: 1158
  num_weight_broadcasts: 113932
custom_metrics: {}
date: 2023-08-14_16-40-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 99
episodes_total: 45264
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001833092828746885
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0002788697020150721
        total_loss: 0.27621492743492126
        var_gnorm: 65.00023651123047
        vf_explained_var: -1.0
        vf_loss: 0.5548206567764282
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11554.0
  learner_queue:
    size_count: 11557
    size_mean: 15.06
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6542067585401772
  num_agent_steps_sampled: 5793650
  num_agent_steps_trained: 5777000
  num_env_steps_sampled: 5793650
  num_env_steps_trained: 5777000
  num_samples_added_to_queue: 5793500
  num_training_step_calls_since_last_synch_worker_weights: 1158
  num_weight_broadcasts: 113932
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 308.314
    learner_load_time_ms: 2.458
    learner_load_wait_time_ms: 1.946
iterations_since_restore: 461
node_ip: 127.0.0.1
num_agent_steps_sampled: 5793650
num_agent_steps_trained: 5777000
num_env_steps_sampled: 5793650
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9992489819235
num_env_steps_trained: 5777000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9992549423844
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 59.478571428571435
  ram_util_percent: 77.20714285714284
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06363077686999116
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024695895082141078
  mean_inference_ms: 1.1928850177091914
  mean_raw_obs_processing_ms: 0.27126909465174237
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020857810974121094
    StateBufferConnector_ms: 0.0036792755126953125
    ViewRequirementAgentConnector_ms: 0.12287354469299316
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06363077686999116
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024695895082141078
    mean_inference_ms: 1.1928850177091914
    mean_raw_obs_processing_ms: 0.27126909465174237
time_since_restore: 4676.19597864151
time_this_iter_s: 10.091218948364258
time_total_s: 4676.19597864151
timers:
  sample_time_ms: 0.021
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.054
timestamp: 1691998858
timesteps_total: 5793650
training_iteration: 461
trial_id: default
train step: 462
agent_timesteps_total: 5806250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01995992660522461
  StateBufferConnector_ms: 0.003765106201171875
  ViewRequirementAgentConnector_ms: 0.12607026100158691
counters:
  num_agent_steps_sampled: 5806250
  num_agent_steps_trained: 5789500
  num_env_steps_sampled: 5806250
  num_env_steps_trained: 5789500
  num_samples_added_to_queue: 5806000
  num_training_step_calls_since_last_synch_worker_weights: 1024
  num_weight_broadcasts: 114181
custom_metrics: {}
date: 2023-08-14_16-41-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 98
episodes_total: 45362
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00018872451619245112
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0002452564949635416
        total_loss: 0.18266192078590393
        var_gnorm: 64.99979400634766
        vf_explained_var: -1.0
        vf_loss: 0.36770159006118774
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11579.0
  learner_queue:
    size_count: 11583
    size_mean: 15.5
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.118033988749895
  num_agent_steps_sampled: 5806250
  num_agent_steps_trained: 5789500
  num_env_steps_sampled: 5806250
  num_env_steps_trained: 5789500
  num_samples_added_to_queue: 5806000
  num_training_step_calls_since_last_synch_worker_weights: 1024
  num_weight_broadcasts: 114181
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 246.193
    learner_load_time_ms: 2.468
    learner_load_wait_time_ms: 1.506
iterations_since_restore: 462
node_ip: 127.0.0.1
num_agent_steps_sampled: 5806250
num_agent_steps_trained: 5789500
num_env_steps_sampled: 5806250
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.998227598776
num_env_steps_trained: 5789500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9982416654525
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 55.86428571428571
  ram_util_percent: 77.58571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06362980978707071
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024693055984368436
  mean_inference_ms: 1.1928667380046607
  mean_raw_obs_processing_ms: 0.27126343465495084
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01995992660522461
    StateBufferConnector_ms: 0.003765106201171875
    ViewRequirementAgentConnector_ms: 0.12607026100158691
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06362980978707071
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024693055984368436
    mean_inference_ms: 1.1928667380046607
    mean_raw_obs_processing_ms: 0.27126343465495084
time_since_restore: 4686.293738603592
time_this_iter_s: 10.09775996208191
time_total_s: 4686.293738603592
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691998868
timesteps_total: 5806250
training_iteration: 462
trial_id: default
train step: 463
agent_timesteps_total: 5819850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018965073351590138
  StateBufferConnector_ms: 0.0034309783071841834
  ViewRequirementAgentConnector_ms: 0.11590606761428546
counters:
  num_agent_steps_sampled: 5819850
  num_agent_steps_trained: 5803000
  num_env_steps_sampled: 5819850
  num_env_steps_trained: 5803000
  num_samples_added_to_queue: 5819500
  num_training_step_calls_since_last_synch_worker_weights: 74
  num_weight_broadcasts: 114449
custom_metrics: {}
date: 2023-08-14_16-41-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 45468
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00016471189155708998
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0002705601218622178
        total_loss: 0.46245652437210083
        var_gnorm: 65.00045013427734
        vf_explained_var: -1.0
        vf_loss: 0.9260190725326538
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11606.0
  learner_queue:
    size_count: 11613
    size_mean: 15.3
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4594519519326423
  num_agent_steps_sampled: 5819850
  num_agent_steps_trained: 5803000
  num_env_steps_sampled: 5819850
  num_env_steps_trained: 5803000
  num_samples_added_to_queue: 5819500
  num_training_step_calls_since_last_synch_worker_weights: 74
  num_weight_broadcasts: 114449
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 146.013
    learner_load_time_ms: 2.462
    learner_load_wait_time_ms: 1.491
iterations_since_restore: 463
node_ip: 127.0.0.1
num_agent_steps_sampled: 5819850
num_agent_steps_trained: 5803000
num_env_steps_sampled: 5819850
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9959144715017
num_env_steps_trained: 5803000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9959445121524
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.97142857142857
  ram_util_percent: 77.45
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06361361843515934
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0246853743403158
  mean_inference_ms: 1.1926626071677322
  mean_raw_obs_processing_ms: 0.2712163806951038
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018965073351590138
    StateBufferConnector_ms: 0.0034309783071841834
    ViewRequirementAgentConnector_ms: 0.11590606761428546
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06361361843515934
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0246853743403158
    mean_inference_ms: 1.1926626071677322
    mean_raw_obs_processing_ms: 0.2712163806951038
time_since_restore: 4696.441150665283
time_this_iter_s: 10.147412061691284
time_total_s: 4696.441150665283
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998878
timesteps_total: 5819850
training_iteration: 463
trial_id: default
train step: 464
agent_timesteps_total: 5833350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01917245253077093
  StateBufferConnector_ms: 0.00344132477382444
  ViewRequirementAgentConnector_ms: 0.11476165843459796
counters:
  num_agent_steps_sampled: 5833350
  num_agent_steps_trained: 5816500
  num_env_steps_sampled: 5833350
  num_env_steps_trained: 5816500
  num_samples_added_to_queue: 5833000
  num_training_step_calls_since_last_synch_worker_weights: 494
  num_weight_broadcasts: 114715
custom_metrics: {}
date: 2023-08-14_16-41-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 45574
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00022121542133390903
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0007534910691902041
        total_loss: 1.1900993585586548
        var_gnorm: 64.99970245361328
        vf_explained_var: -1.0
        vf_loss: 2.383917808532715
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11633.0
  learner_queue:
    size_count: 11639
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6326665305566843
  num_agent_steps_sampled: 5833350
  num_agent_steps_trained: 5816500
  num_env_steps_sampled: 5833350
  num_env_steps_trained: 5816500
  num_samples_added_to_queue: 5833000
  num_training_step_calls_since_last_synch_worker_weights: 494
  num_weight_broadcasts: 114715
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 199.484
    learner_load_time_ms: 2.068
    learner_load_wait_time_ms: 1.702
iterations_since_restore: 464
node_ip: 127.0.0.1
num_agent_steps_sampled: 5833350
num_agent_steps_trained: 5816500
num_env_steps_sampled: 5833350
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9946248745357
num_env_steps_trained: 5816500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9946248745357
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.120000000000005
  ram_util_percent: 77.34
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06360263792705041
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02467822916271706
  mean_inference_ms: 1.1924703881891443
  mean_raw_obs_processing_ms: 0.27117597361240375
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01917245253077093
    StateBufferConnector_ms: 0.00344132477382444
    ViewRequirementAgentConnector_ms: 0.11476165843459796
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06360263792705041
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02467822916271706
    mean_inference_ms: 1.1924703881891443
    mean_raw_obs_processing_ms: 0.27117597361240375
time_since_restore: 4706.573536634445
time_this_iter_s: 10.132385969161987
time_total_s: 4706.573536634445
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998888
timesteps_total: 5833350
training_iteration: 464
trial_id: default
train step: 465
agent_timesteps_total: 5846650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019128964497492865
  StateBufferConnector_ms: 0.003418784875136155
  ViewRequirementAgentConnector_ms: 0.11671712765326867
counters:
  num_agent_steps_sampled: 5846650
  num_agent_steps_trained: 5830000
  num_env_steps_sampled: 5846650
  num_env_steps_trained: 5830000
  num_samples_added_to_queue: 5846500
  num_training_step_calls_since_last_synch_worker_weights: 134
  num_weight_broadcasts: 114978
custom_metrics: {}
date: 2023-08-14_16-41-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 45678
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00021936220582574606
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0006679948419332504
        total_loss: 0.8918495774269104
        var_gnorm: 65.00025177001953
        vf_explained_var: -1.0
        vf_loss: 1.7845567464828491
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11660.0
  learner_queue:
    size_count: 11667
    size_mean: 15.18
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5835403373454051
  num_agent_steps_sampled: 5846650
  num_agent_steps_trained: 5830000
  num_env_steps_sampled: 5846650
  num_env_steps_trained: 5830000
  num_samples_added_to_queue: 5846500
  num_training_step_calls_since_last_synch_worker_weights: 134
  num_weight_broadcasts: 114978
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 146.055
    learner_load_time_ms: 2.081
    learner_load_wait_time_ms: 1.538
iterations_since_restore: 465
node_ip: 127.0.0.1
num_agent_steps_sampled: 5846650
num_agent_steps_trained: 5830000
num_env_steps_sampled: 5846650
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.998160841624
num_env_steps_trained: 5830000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.998133185107
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.20714285714286
  ram_util_percent: 78.44285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06359683700451287
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02467266423800657
  mean_inference_ms: 1.1923199982230739
  mean_raw_obs_processing_ms: 0.2711500629329807
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019128964497492865
    StateBufferConnector_ms: 0.003418784875136155
    ViewRequirementAgentConnector_ms: 0.11671712765326867
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06359683700451287
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02467266423800657
    mean_inference_ms: 1.1923199982230739
    mean_raw_obs_processing_ms: 0.2711500629329807
time_since_restore: 4716.725593805313
time_this_iter_s: 10.15205717086792
time_total_s: 4716.725593805313
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691998899
timesteps_total: 5846650
training_iteration: 465
trial_id: default
train step: 466
agent_timesteps_total: 5858850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022069931030273438
  StateBufferConnector_ms: 0.003818035125732422
  ViewRequirementAgentConnector_ms: 0.13108086585998535
counters:
  num_agent_steps_sampled: 5858850
  num_agent_steps_trained: 5842000
  num_env_steps_sampled: 5858850
  num_env_steps_trained: 5842000
  num_samples_added_to_queue: 5858500
  num_training_step_calls_since_last_synch_worker_weights: 38
  num_weight_broadcasts: 115219
custom_metrics: {}
date: 2023-08-14_16-41-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 94
episodes_total: 45772
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002495696535333991
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00023098882229533046
        total_loss: 0.12350977957248688
        var_gnorm: 64.9990005493164
        vf_explained_var: -1.0
        vf_loss: 0.24905326962471008
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11684.0
  learner_queue:
    size_count: 11691
    size_mean: 14.98
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8164801127455263
  num_agent_steps_sampled: 5858850
  num_agent_steps_trained: 5842000
  num_env_steps_sampled: 5858850
  num_env_steps_trained: 5842000
  num_samples_added_to_queue: 5858500
  num_training_step_calls_since_last_synch_worker_weights: 38
  num_weight_broadcasts: 115219
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 153.349
    learner_load_time_ms: 2.092
    learner_load_wait_time_ms: 1.573
iterations_since_restore: 466
node_ip: 127.0.0.1
num_agent_steps_sampled: 5858850
num_agent_steps_trained: 5842000
num_env_steps_sampled: 5858850
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.994648003215
num_env_steps_trained: 5842000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9947357408673
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 57.00000000000001
  ram_util_percent: 79.54285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06361374571103372
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024673692428909915
  mean_inference_ms: 1.1923804879377145
  mean_raw_obs_processing_ms: 0.2711771492526516
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022069931030273438
    StateBufferConnector_ms: 0.003818035125732422
    ViewRequirementAgentConnector_ms: 0.13108086585998535
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06361374571103372
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024673692428909915
    mean_inference_ms: 1.1923804879377145
    mean_raw_obs_processing_ms: 0.2711771492526516
time_since_restore: 4726.890429973602
time_this_iter_s: 10.164836168289185
time_total_s: 4726.890429973602
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691998909
timesteps_total: 5858850
training_iteration: 466
trial_id: default
train step: 467
agent_timesteps_total: 5872200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019620486668178012
  StateBufferConnector_ms: 0.003571283249627976
  ViewRequirementAgentConnector_ms: 0.11942976997012184
counters:
  num_agent_steps_sampled: 5872200
  num_agent_steps_trained: 5855500
  num_env_steps_sampled: 5872200
  num_env_steps_trained: 5855500
  num_samples_added_to_queue: 5872000
  num_training_step_calls_since_last_synch_worker_weights: 408
  num_weight_broadcasts: 115483
custom_metrics: {}
date: 2023-08-14_16-41-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 45877
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.000198968657059595
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0004190797626506537
        total_loss: 0.5902520418167114
        var_gnorm: 64.99832916259766
        vf_explained_var: -1.0
        vf_loss: 1.1833319664001465
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11711.0
  learner_queue:
    size_count: 11717
    size_mean: 14.82
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8621492958406962
  num_agent_steps_sampled: 5872200
  num_agent_steps_trained: 5855500
  num_env_steps_sampled: 5872200
  num_env_steps_trained: 5855500
  num_samples_added_to_queue: 5872000
  num_training_step_calls_since_last_synch_worker_weights: 408
  num_weight_broadcasts: 115483
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 178.609
    learner_load_time_ms: 10.521
    learner_load_wait_time_ms: 1.461
iterations_since_restore: 467
node_ip: 127.0.0.1
num_agent_steps_sampled: 5872200
num_agent_steps_trained: 5855500
num_env_steps_sampled: 5872200
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9992997650004
num_env_steps_trained: 5855500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9992918971914
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.693333333333335
  ram_util_percent: 78.11333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06359015230206223
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024667859254489673
  mean_inference_ms: 1.1922425942128252
  mean_raw_obs_processing_ms: 0.2711302032886476
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019620486668178012
    StateBufferConnector_ms: 0.003571283249627976
    ViewRequirementAgentConnector_ms: 0.11942976997012184
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06359015230206223
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024667859254489673
    mean_inference_ms: 1.1922425942128252
    mean_raw_obs_processing_ms: 0.2711302032886476
time_since_restore: 4737.023426055908
time_this_iter_s: 10.132996082305908
time_total_s: 4737.023426055908
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691998919
timesteps_total: 5872200
training_iteration: 467
trial_id: default
train step: 468
agent_timesteps_total: 5885500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01921699597285344
  StateBufferConnector_ms: 0.0035026898750892053
  ViewRequirementAgentConnector_ms: 0.11730469190157376
counters:
  num_agent_steps_sampled: 5885500
  num_agent_steps_trained: 5869000
  num_env_steps_sampled: 5885500
  num_env_steps_trained: 5869000
  num_samples_added_to_queue: 5885500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 115746
custom_metrics: {}
date: 2023-08-14_16-42-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 45981
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001943927345564589
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00037923187483102083
        total_loss: 0.5425475239753723
        var_gnorm: 64.99838256835938
        vf_explained_var: -1.0
        vf_loss: 1.0862805843353271
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11738.0
  learner_queue:
    size_count: 11743
    size_mean: 15.26
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3683566786477859
  num_agent_steps_sampled: 5885500
  num_agent_steps_trained: 5869000
  num_env_steps_sampled: 5885500
  num_env_steps_trained: 5869000
  num_samples_added_to_queue: 5885500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 115746
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 196.972
    learner_load_time_ms: 10.511
    learner_load_wait_time_ms: 1.514
iterations_since_restore: 468
node_ip: 127.0.0.1
num_agent_steps_sampled: 5885500
num_agent_steps_trained: 5869000
num_env_steps_sampled: 5885500
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.8534540494773
num_env_steps_trained: 5869000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.851250350973
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.464285714285715
  ram_util_percent: 77.2
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06358301938634349
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024661730791614413
  mean_inference_ms: 1.1921012943751044
  mean_raw_obs_processing_ms: 0.27109518734133986
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01921699597285344
    StateBufferConnector_ms: 0.0035026898750892053
    ViewRequirementAgentConnector_ms: 0.11730469190157376
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06358301938634349
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024661730791614413
    mean_inference_ms: 1.1921012943751044
    mean_raw_obs_processing_ms: 0.27109518734133986
time_since_restore: 4747.137847900391
time_this_iter_s: 10.114421844482422
time_total_s: 4747.137847900391
timers:
  sample_time_ms: 0.043
  synch_weights_time_ms: 0.436
  training_iteration_time_ms: 1.837
timestamp: 1691998929
timesteps_total: 5885500
training_iteration: 468
trial_id: default
train step: 469
agent_timesteps_total: 5898750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02003633058988131
  StateBufferConnector_ms: 0.0035320337002093974
  ViewRequirementAgentConnector_ms: 0.12077826720017654
counters:
  num_agent_steps_sampled: 5898750
  num_agent_steps_trained: 5882000
  num_env_steps_sampled: 5898750
  num_env_steps_trained: 5882000
  num_samples_added_to_queue: 5898500
  num_training_step_calls_since_last_synch_worker_weights: 927
  num_weight_broadcasts: 116006
custom_metrics: {}
date: 2023-08-14_16-42-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 46085
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00018653299775905907
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0003766596200875938
        total_loss: 0.5083431601524353
        var_gnorm: 64.99848937988281
        vf_explained_var: -1.0
        vf_loss: 1.0193049907684326
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11764.0
  learner_queue:
    size_count: 11769
    size_mean: 15.44
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1516944039110375
  num_agent_steps_sampled: 5898750
  num_agent_steps_trained: 5882000
  num_env_steps_sampled: 5898750
  num_env_steps_trained: 5882000
  num_samples_added_to_queue: 5898500
  num_training_step_calls_since_last_synch_worker_weights: 927
  num_weight_broadcasts: 116006
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 216.22
    learner_load_time_ms: 10.638
    learner_load_wait_time_ms: 1.7
iterations_since_restore: 469
node_ip: 127.0.0.1
num_agent_steps_sampled: 5898750
num_agent_steps_trained: 5882000
num_env_steps_sampled: 5898750
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.9986732019358
num_env_steps_trained: 5882000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9986982358616
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.607142857142854
  ram_util_percent: 76.57142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06357455755804275
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024655725013838732
  mean_inference_ms: 1.191948230936235
  mean_raw_obs_processing_ms: 0.27106341415168805
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02003633058988131
    StateBufferConnector_ms: 0.0035320337002093974
    ViewRequirementAgentConnector_ms: 0.12077826720017654
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06357455755804275
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024655725013838732
    mean_inference_ms: 1.191948230936235
    mean_raw_obs_processing_ms: 0.27106341415168805
time_since_restore: 4757.249142885208
time_this_iter_s: 10.111294984817505
time_total_s: 4757.249142885208
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691998939
timesteps_total: 5898750
training_iteration: 469
trial_id: default
train step: 470
agent_timesteps_total: 5911650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02054738998413086
  StateBufferConnector_ms: 0.003680706024169922
  ViewRequirementAgentConnector_ms: 0.1225898265838623
counters:
  num_agent_steps_sampled: 5911650
  num_agent_steps_trained: 5895000
  num_env_steps_sampled: 5911650
  num_env_steps_trained: 5895000
  num_samples_added_to_queue: 5911500
  num_training_step_calls_since_last_synch_worker_weights: 168
  num_weight_broadcasts: 116260
custom_metrics: {}
date: 2023-08-14_16-42-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 46185
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002861143439076841
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0005890005268156528
        total_loss: 0.48628178238868713
        var_gnorm: 64.99890899658203
        vf_explained_var: -1.0
        vf_loss: 0.9742466807365417
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11790.0
  learner_queue:
    size_count: 11797
    size_mean: 15.32
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4344336861632885
  num_agent_steps_sampled: 5911650
  num_agent_steps_trained: 5895000
  num_env_steps_sampled: 5911650
  num_env_steps_trained: 5895000
  num_samples_added_to_queue: 5911500
  num_training_step_calls_since_last_synch_worker_weights: 168
  num_weight_broadcasts: 116260
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 140.322
    learner_load_time_ms: 10.112
    learner_load_wait_time_ms: 1.581
iterations_since_restore: 470
node_ip: 127.0.0.1
num_agent_steps_sampled: 5911650
num_agent_steps_trained: 5895000
num_env_steps_sampled: 5911650
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9936950514916
num_env_steps_trained: 5895000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9936461759219
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.16428571428572
  ram_util_percent: 77.61428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0635710791704487
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02465248129046777
  mean_inference_ms: 1.1918938890321482
  mean_raw_obs_processing_ms: 0.2710504754830103
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02054738998413086
    StateBufferConnector_ms: 0.003680706024169922
    ViewRequirementAgentConnector_ms: 0.1225898265838623
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0635710791704487
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02465248129046777
    mean_inference_ms: 1.1918938890321482
    mean_raw_obs_processing_ms: 0.2710504754830103
time_since_restore: 4767.422023773193
time_this_iter_s: 10.17288088798523
time_total_s: 4767.422023773193
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691998949
timesteps_total: 5911650
training_iteration: 470
trial_id: default
train step: 471
agent_timesteps_total: 5925000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01956774638249324
  StateBufferConnector_ms: 0.003542808385995718
  ViewRequirementAgentConnector_ms: 0.11915885485135592
counters:
  num_agent_steps_sampled: 5925000
  num_agent_steps_trained: 5908500
  num_env_steps_sampled: 5925000
  num_env_steps_trained: 5908500
  num_samples_added_to_queue: 5925000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 116524
custom_metrics: {}
date: 2023-08-14_16-42-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 46289
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0001968437572941184
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00025530162383802235
        total_loss: 0.15652967989444733
        var_gnorm: 64.99713134765625
        vf_explained_var: -1.0
        vf_loss: 0.3155384063720703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11817.0
  learner_queue:
    size_count: 11821
    size_mean: 15.24
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.5173661390712527
  num_agent_steps_sampled: 5925000
  num_agent_steps_trained: 5908500
  num_env_steps_sampled: 5925000
  num_env_steps_trained: 5908500
  num_samples_added_to_queue: 5925000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 116524
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 231.012
    learner_load_time_ms: 10.117
    learner_load_wait_time_ms: 1.674
iterations_since_restore: 471
node_ip: 127.0.0.1
num_agent_steps_sampled: 5925000
num_agent_steps_trained: 5908500
num_env_steps_sampled: 5925000
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1333.1662187895627
num_env_steps_trained: 5908500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1348.1456145062991
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.05333333333335
  ram_util_percent: 78.13333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06356214949177857
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02465012877815315
  mean_inference_ms: 1.191739168867688
  mean_raw_obs_processing_ms: 0.27101542857006433
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01956774638249324
    StateBufferConnector_ms: 0.003542808385995718
    ViewRequirementAgentConnector_ms: 0.11915885485135592
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06356214949177857
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02465012877815315
    mean_inference_ms: 1.191739168867688
    mean_raw_obs_processing_ms: 0.27101542857006433
time_since_restore: 4777.537252902985
time_this_iter_s: 10.11522912979126
time_total_s: 4777.537252902985
timers:
  sample_time_ms: 0.087
  synch_weights_time_ms: 0.409
  training_iteration_time_ms: 1.889
timestamp: 1691998959
timesteps_total: 5925000
training_iteration: 471
trial_id: default
train step: 472
agent_timesteps_total: 5938550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01870821107108638
  StateBufferConnector_ms: 0.003352480114630933
  ViewRequirementAgentConnector_ms: 0.11428167235176519
counters:
  num_agent_steps_sampled: 5938550
  num_agent_steps_trained: 5922000
  num_env_steps_sampled: 5938550
  num_env_steps_trained: 5922000
  num_samples_added_to_queue: 5938500
  num_training_step_calls_since_last_synch_worker_weights: 846
  num_weight_broadcasts: 116792
custom_metrics: {}
date: 2023-08-14_16-42-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 46395
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00020481794490478933
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00025639060186222196
        total_loss: 0.17474517226219177
        var_gnorm: 64.99769592285156
        vf_explained_var: -1.0
        vf_loss: 0.352051317691803
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11844.0
  learner_queue:
    size_count: 11848
    size_mean: 15.5
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.004987562112089
  num_agent_steps_sampled: 5938550
  num_agent_steps_trained: 5922000
  num_env_steps_sampled: 5938550
  num_env_steps_trained: 5922000
  num_samples_added_to_queue: 5938500
  num_training_step_calls_since_last_synch_worker_weights: 846
  num_weight_broadcasts: 116792
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 231.724
    learner_load_time_ms: 10.159
    learner_load_wait_time_ms: 1.622
iterations_since_restore: 472
node_ip: 127.0.0.1
num_agent_steps_sampled: 5938550
num_agent_steps_trained: 5922000
num_env_steps_sampled: 5938550
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9933450548867
num_env_steps_trained: 5922000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9933696118799
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.721428571428575
  ram_util_percent: 77.79285714285713
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06355007977345585
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024642431284819466
  mean_inference_ms: 1.19152339076008
  mean_raw_obs_processing_ms: 0.27097064774015395
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01870821107108638
    StateBufferConnector_ms: 0.003352480114630933
    ViewRequirementAgentConnector_ms: 0.11428167235176519
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06355007977345585
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024642431284819466
    mean_inference_ms: 1.19152339076008
    mean_raw_obs_processing_ms: 0.27097064774015395
time_since_restore: 4787.629056930542
time_this_iter_s: 10.091804027557373
time_total_s: 4787.629056930542
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691998969
timesteps_total: 5938550
training_iteration: 472
trial_id: default
train step: 473
agent_timesteps_total: 5951950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01926826980878722
  StateBufferConnector_ms: 0.0034057869101470372
  ViewRequirementAgentConnector_ms: 0.11586603128685141
counters:
  num_agent_steps_sampled: 5951950
  num_agent_steps_trained: 5935000
  num_env_steps_sampled: 5951950
  num_env_steps_trained: 5935000
  num_samples_added_to_queue: 5951500
  num_training_step_calls_since_last_synch_worker_weights: 74
  num_weight_broadcasts: 117056
custom_metrics: {}
date: 2023-08-14_16-43-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 46501
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002623172476887703
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0010167991276830435
        total_loss: 1.1720372438430786
        var_gnorm: 64.99781799316406
        vf_explained_var: -1.0
        vf_loss: 2.3446638584136963
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11870.0
  learner_queue:
    size_count: 11877
    size_mean: 15.38
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3840520221436767
  num_agent_steps_sampled: 5951950
  num_agent_steps_trained: 5935000
  num_env_steps_sampled: 5951950
  num_env_steps_trained: 5935000
  num_samples_added_to_queue: 5951500
  num_training_step_calls_since_last_synch_worker_weights: 74
  num_weight_broadcasts: 117056
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 157.455
    learner_load_time_ms: 1.572
    learner_load_wait_time_ms: 1.528
iterations_since_restore: 473
node_ip: 127.0.0.1
num_agent_steps_sampled: 5951950
num_agent_steps_trained: 5935000
num_env_steps_sampled: 5951950
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9950480644118
num_env_steps_trained: 5935000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9951958833847
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 48.800000000000004
  ram_util_percent: 76.55714285714284
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06353921070685987
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02463547096586713
  mean_inference_ms: 1.191377799517786
  mean_raw_obs_processing_ms: 0.270928294812929
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01926826980878722
    StateBufferConnector_ms: 0.0034057869101470372
    ViewRequirementAgentConnector_ms: 0.11586603128685141
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06353921070685987
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02463547096586713
    mean_inference_ms: 1.191377799517786
    mean_raw_obs_processing_ms: 0.270928294812929
time_since_restore: 4797.783357858658
time_this_iter_s: 10.154300928115845
time_total_s: 4797.783357858658
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1691998980
timesteps_total: 5951950
training_iteration: 473
trial_id: default
train step: 474
agent_timesteps_total: 5965750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01892330490540121
  StateBufferConnector_ms: 0.0033772994424695166
  ViewRequirementAgentConnector_ms: 0.11287493126414647
counters:
  num_agent_steps_sampled: 5965750
  num_agent_steps_trained: 5949000
  num_env_steps_sampled: 5965750
  num_env_steps_trained: 5949000
  num_samples_added_to_queue: 5965500
  num_training_step_calls_since_last_synch_worker_weights: 19
  num_weight_broadcasts: 117328
custom_metrics: {}
date: 2023-08-14_16-43-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 46608
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002440668031340465
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0006367898895405233
        total_loss: 0.6988997459411621
        var_gnorm: 64.9963150024414
        vf_explained_var: -1.0
        vf_loss: 1.4015138149261475
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11898.0
  learner_queue:
    size_count: 11905
    size_mean: 15.02
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7605680901345453
  num_agent_steps_sampled: 5965750
  num_agent_steps_trained: 5949000
  num_env_steps_sampled: 5965750
  num_env_steps_trained: 5949000
  num_samples_added_to_queue: 5965500
  num_training_step_calls_since_last_synch_worker_weights: 19
  num_weight_broadcasts: 117328
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 140.788
    learner_load_time_ms: 1.463
    learner_load_wait_time_ms: 1.641
iterations_since_restore: 474
node_ip: 127.0.0.1
num_agent_steps_sampled: 5965750
num_agent_steps_trained: 5949000
num_env_steps_sampled: 5965750
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9980587986595
num_env_steps_trained: 5949000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9980306653067
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.39999999999999
  ram_util_percent: 76.44285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06352799766716288
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024627408858270583
  mean_inference_ms: 1.1911387819626291
  mean_raw_obs_processing_ms: 0.27087886691712093
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01892330490540121
    StateBufferConnector_ms: 0.0033772994424695166
    ViewRequirementAgentConnector_ms: 0.11287493126414647
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06352799766716288
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024627408858270583
    mean_inference_ms: 1.1911387819626291
    mean_raw_obs_processing_ms: 0.27087886691712093
time_since_restore: 4807.939880847931
time_this_iter_s: 10.156522989273071
time_total_s: 4807.939880847931
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691998990
timesteps_total: 5965750
training_iteration: 474
trial_id: default
train step: 475
agent_timesteps_total: 5979150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019048736208961123
  StateBufferConnector_ms: 0.0034268697102864585
  ViewRequirementAgentConnector_ms: 0.11510803585960752
counters:
  num_agent_steps_sampled: 5979150
  num_agent_steps_trained: 5962500
  num_env_steps_sampled: 5979150
  num_env_steps_trained: 5962500
  num_samples_added_to_queue: 5979000
  num_training_step_calls_since_last_synch_worker_weights: 831
  num_weight_broadcasts: 117593
custom_metrics: {}
date: 2023-08-14_16-43-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 46713
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00020534865325316787
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 5.3754843975184485e-05
        total_loss: 0.16064167022705078
        var_gnorm: 64.99661254882812
        vf_explained_var: -1.0
        vf_loss: 0.3232293426990509
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11925.0
  learner_queue:
    size_count: 11930
    size_mean: 15.16
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6169106345126192
  num_agent_steps_sampled: 5979150
  num_agent_steps_trained: 5962500
  num_env_steps_sampled: 5979150
  num_env_steps_trained: 5962500
  num_samples_added_to_queue: 5979000
  num_training_step_calls_since_last_synch_worker_weights: 831
  num_weight_broadcasts: 117593
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 207.14
    learner_load_time_ms: 1.467
    learner_load_wait_time_ms: 1.634
iterations_since_restore: 475
node_ip: 127.0.0.1
num_agent_steps_sampled: 5979150
num_agent_steps_trained: 5962500
num_env_steps_sampled: 5979150
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.995016116559
num_env_steps_trained: 5962500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9949789233992
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.733333333333334
  ram_util_percent: 75.82666666666667
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06351456711840227
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02462079188104344
  mean_inference_ms: 1.1909826089769646
  mean_raw_obs_processing_ms: 0.27083904341621395
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019048736208961123
    StateBufferConnector_ms: 0.0034268697102864585
    ViewRequirementAgentConnector_ms: 0.11510803585960752
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06351456711840227
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02462079188104344
    mean_inference_ms: 1.1909826089769646
    mean_raw_obs_processing_ms: 0.27083904341621395
time_since_restore: 4818.066574811935
time_this_iter_s: 10.126693964004517
time_total_s: 4818.066574811935
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691999000
timesteps_total: 5979150
training_iteration: 475
trial_id: default
train step: 476
agent_timesteps_total: 5992950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018531967092443397
  StateBufferConnector_ms: 0.0033480149728280528
  ViewRequirementAgentConnector_ms: 0.1129254146858498
counters:
  num_agent_steps_sampled: 5992950
  num_agent_steps_trained: 5976000
  num_env_steps_sampled: 5992950
  num_env_steps_trained: 5976000
  num_samples_added_to_queue: 5992500
  num_training_step_calls_since_last_synch_worker_weights: 1244
  num_weight_broadcasts: 117864
custom_metrics: {}
date: 2023-08-14_16-43-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 46821
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00021285537513904274
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0005291425622999668
        total_loss: 0.528320848941803
        var_gnorm: 64.99427032470703
        vf_explained_var: -1.0
        vf_loss: 1.0598286390304565
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11952.0
  learner_queue:
    size_count: 11956
    size_mean: 15.46
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1173182178770737
  num_agent_steps_sampled: 5992950
  num_agent_steps_trained: 5976000
  num_env_steps_sampled: 5992950
  num_env_steps_trained: 5976000
  num_samples_added_to_queue: 5992500
  num_training_step_calls_since_last_synch_worker_weights: 1244
  num_weight_broadcasts: 117864
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 261.905
    learner_load_time_ms: 1.449
    learner_load_wait_time_ms: 1.61
iterations_since_restore: 476
node_ip: 127.0.0.1
num_agent_steps_sampled: 5992950
num_agent_steps_trained: 5976000
num_env_steps_sampled: 5992950
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9930577627376
num_env_steps_trained: 5976000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.993208680939
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.3
  ram_util_percent: 75.39999999999999
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06350281053210978
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024612226730191842
  mean_inference_ms: 1.1907317408748892
  mean_raw_obs_processing_ms: 0.2707863747889706
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018531967092443397
    StateBufferConnector_ms: 0.0033480149728280528
    ViewRequirementAgentConnector_ms: 0.1129254146858498
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06350281053210978
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024612226730191842
    mean_inference_ms: 1.1907317408748892
    mean_raw_obs_processing_ms: 0.2707863747889706
time_since_restore: 4828.170118808746
time_this_iter_s: 10.103543996810913
time_total_s: 4828.170118808746
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691999010
timesteps_total: 5992950
training_iteration: 476
trial_id: default
train step: 477
agent_timesteps_total: 6006650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01901500629928877
  StateBufferConnector_ms: 0.0033954404435067808
  ViewRequirementAgentConnector_ms: 0.11497601023260152
counters:
  num_agent_steps_sampled: 6006650
  num_agent_steps_trained: 5990000
  num_env_steps_sampled: 6006650
  num_env_steps_trained: 5990000
  num_samples_added_to_queue: 6006500
  num_training_step_calls_since_last_synch_worker_weights: 489
  num_weight_broadcasts: 118133
custom_metrics: {}
date: 2023-08-14_16-43-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 46927
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00024228420807048678
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00034730168408714235
        total_loss: 0.16542454063892365
        var_gnorm: 64.99629211425781
        vf_explained_var: -1.0
        vf_loss: 0.33257731795310974
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 11980.0
  learner_queue:
    size_count: 11986
    size_mean: 15.52
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1178550889985697
  num_agent_steps_sampled: 6006650
  num_agent_steps_trained: 5990000
  num_env_steps_sampled: 6006650
  num_env_steps_trained: 5990000
  num_samples_added_to_queue: 6006500
  num_training_step_calls_since_last_synch_worker_weights: 489
  num_weight_broadcasts: 118133
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 169.889
    learner_load_time_ms: 1.386
    learner_load_wait_time_ms: 1.549
iterations_since_restore: 477
node_ip: 127.0.0.1
num_agent_steps_sampled: 6006650
num_agent_steps_trained: 5990000
num_env_steps_sampled: 6006650
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9964397046106
num_env_steps_trained: 5990000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9963617419378
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.87857142857143
  ram_util_percent: 75.77142857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06349080774451499
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02460423563835352
  mean_inference_ms: 1.1905142038551526
  mean_raw_obs_processing_ms: 0.2707405959398339
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01901500629928877
    StateBufferConnector_ms: 0.0033954404435067808
    ViewRequirementAgentConnector_ms: 0.11497601023260152
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06349080774451499
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02460423563835352
    mean_inference_ms: 1.1905142038551526
    mean_raw_obs_processing_ms: 0.2707405959398339
time_since_restore: 4838.314488649368
time_this_iter_s: 10.144369840621948
time_total_s: 4838.314488649368
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691999020
timesteps_total: 6006650
training_iteration: 477
trial_id: default
train step: 478
agent_timesteps_total: 6020400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01876552899678548
  StateBufferConnector_ms: 0.0033775965372721353
  ViewRequirementAgentConnector_ms: 0.11510959377995243
counters:
  num_agent_steps_sampled: 6020400
  num_agent_steps_trained: 6003500
  num_env_steps_sampled: 6020400
  num_env_steps_trained: 6003500
  num_samples_added_to_queue: 6020000
  num_training_step_calls_since_last_synch_worker_weights: 178
  num_weight_broadcasts: 118405
custom_metrics: {}
date: 2023-08-14_16-43-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 47035
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00018977632862515748
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00027236799360252917
        total_loss: 0.3251070976257324
        var_gnorm: 64.9962158203125
        vf_explained_var: -1.0
        vf_loss: 0.6515672206878662
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12007.0
  learner_queue:
    size_count: 12014
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6326665305566843
  num_agent_steps_sampled: 6020400
  num_agent_steps_trained: 6003500
  num_env_steps_sampled: 6020400
  num_env_steps_trained: 6003500
  num_samples_added_to_queue: 6020000
  num_training_step_calls_since_last_synch_worker_weights: 178
  num_weight_broadcasts: 118405
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 158.054
    learner_load_time_ms: 1.392
    learner_load_wait_time_ms: 1.614
iterations_since_restore: 478
node_ip: 127.0.0.1
num_agent_steps_sampled: 6020400
num_agent_steps_trained: 6003500
num_env_steps_sampled: 6020400
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.997508530363
num_env_steps_trained: 6003500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9975538298108
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.866666666666674
  ram_util_percent: 76.04
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06347853000743793
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024596464703324706
  mean_inference_ms: 1.1902906820224546
  mean_raw_obs_processing_ms: 0.2706909117853439
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01876552899678548
    StateBufferConnector_ms: 0.0033775965372721353
    ViewRequirementAgentConnector_ms: 0.11510959377995243
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06347853000743793
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024596464703324706
    mean_inference_ms: 1.1902906820224546
    mean_raw_obs_processing_ms: 0.2706909117853439
time_since_restore: 4848.479905605316
time_this_iter_s: 10.165416955947876
time_total_s: 4848.479905605316
timers:
  sample_time_ms: 0.019
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.052
timestamp: 1691999030
timesteps_total: 6020400
training_iteration: 478
trial_id: default
train step: 479
agent_timesteps_total: 6033900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019194045156802772
  StateBufferConnector_ms: 0.0034896832592082472
  ViewRequirementAgentConnector_ms: 0.1184175599296138
counters:
  num_agent_steps_sampled: 6033900
  num_agent_steps_trained: 6017000
  num_env_steps_sampled: 6033900
  num_env_steps_trained: 6017000
  num_samples_added_to_queue: 6033500
  num_training_step_calls_since_last_synch_worker_weights: 642
  num_weight_broadcasts: 118672
custom_metrics: {}
date: 2023-08-14_16-44-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 47141
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0003150395059492439
        entropy_coeff: 0.01
        grad_gnorm: 13.98613452911377
        policy_loss: 5.14957464474719e-05
        total_loss: 0.18327781558036804
        var_gnorm: 64.99577331542969
        vf_explained_var: -1.0
        vf_loss: 0.3696030378341675
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12034.0
  learner_queue:
    size_count: 12040
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6833300330000647
  num_agent_steps_sampled: 6033900
  num_agent_steps_trained: 6017000
  num_env_steps_sampled: 6033900
  num_env_steps_trained: 6017000
  num_samples_added_to_queue: 6033500
  num_training_step_calls_since_last_synch_worker_weights: 642
  num_weight_broadcasts: 118672
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 200.006
    learner_load_time_ms: 3.437
    learner_load_wait_time_ms: 1.621
iterations_since_restore: 479
node_ip: 127.0.0.1
num_agent_steps_sampled: 6033900
num_agent_steps_trained: 6017000
num_env_steps_sampled: 6033900
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9961054437456
num_env_steps_trained: 6017000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9961054437456
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.15714285714286
  ram_util_percent: 75.70714285714284
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06346936407395287
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024589966418703462
  mean_inference_ms: 1.1901158769523372
  mean_raw_obs_processing_ms: 0.2706524238266124
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019194045156802772
    StateBufferConnector_ms: 0.0034896832592082472
    ViewRequirementAgentConnector_ms: 0.1184175599296138
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06346936407395287
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024589966418703462
    mean_inference_ms: 1.1901158769523372
    mean_raw_obs_processing_ms: 0.2706524238266124
time_since_restore: 4858.633654594421
time_this_iter_s: 10.153748989105225
time_total_s: 4858.633654594421
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691999041
timesteps_total: 6033900
training_iteration: 479
trial_id: default
train step: 480
agent_timesteps_total: 6047600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018861608685187575
  StateBufferConnector_ms: 0.003358553040702388
  ViewRequirementAgentConnector_ms: 0.11366898158811173
counters:
  num_agent_steps_sampled: 6047600
  num_agent_steps_trained: 6031000
  num_env_steps_sampled: 6047600
  num_env_steps_trained: 6031000
  num_samples_added_to_queue: 6047500
  num_training_step_calls_since_last_synch_worker_weights: 1118
  num_weight_broadcasts: 118943
custom_metrics: {}
date: 2023-08-14_16-44-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 47247
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00038054760079830885
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0006241551600396633
        total_loss: 0.2688531279563904
        var_gnorm: 64.99549102783203
        vf_explained_var: -1.0
        vf_loss: 0.5402634143829346
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12062.0
  learner_queue:
    size_count: 12067
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.40356688476182
  num_agent_steps_sampled: 6047600
  num_agent_steps_trained: 6031000
  num_env_steps_sampled: 6047600
  num_env_steps_trained: 6031000
  num_samples_added_to_queue: 6047500
  num_training_step_calls_since_last_synch_worker_weights: 1118
  num_weight_broadcasts: 118943
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 211.226
    learner_load_time_ms: 3.432
    learner_load_wait_time_ms: 1.587
iterations_since_restore: 480
node_ip: 127.0.0.1
num_agent_steps_sampled: 6047600
num_agent_steps_trained: 6031000
num_env_steps_sampled: 6047600
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.994904537079
num_env_steps_trained: 6031000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9947929575992
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.82857142857143
  ram_util_percent: 75.41428571428571
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06345712486792981
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02458209043023336
  mean_inference_ms: 1.189896649890369
  mean_raw_obs_processing_ms: 0.27060576024748306
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018861608685187575
    StateBufferConnector_ms: 0.003358553040702388
    ViewRequirementAgentConnector_ms: 0.11366898158811173
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06345712486792981
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02458209043023336
    mean_inference_ms: 1.189896649890369
    mean_raw_obs_processing_ms: 0.27060576024748306
time_since_restore: 4868.759529352188
time_this_iter_s: 10.125874757766724
time_total_s: 4868.759529352188
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691999051
timesteps_total: 6047600
training_iteration: 480
trial_id: default
train step: 481
agent_timesteps_total: 6061100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018910417016947043
  StateBufferConnector_ms: 0.003414109068096809
  ViewRequirementAgentConnector_ms: 0.11551852496165149
counters:
  num_agent_steps_sampled: 6061100
  num_agent_steps_trained: 6044500
  num_env_steps_sampled: 6061100
  num_env_steps_trained: 6044500
  num_samples_added_to_queue: 6061000
  num_training_step_calls_since_last_synch_worker_weights: 1067
  num_weight_broadcasts: 119209
custom_metrics: {}
date: 2023-08-14_16-44-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 47353
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00031092879362404346
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0011683977209031582
        total_loss: 1.219347357749939
        var_gnorm: 64.99498748779297
        vf_explained_var: -1.0
        vf_loss: 2.444140672683716
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12089.0
  learner_queue:
    size_count: 12095
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2649110640673518
  num_agent_steps_sampled: 6061100
  num_agent_steps_trained: 6044500
  num_env_steps_sampled: 6061100
  num_env_steps_trained: 6044500
  num_samples_added_to_queue: 6061000
  num_training_step_calls_since_last_synch_worker_weights: 1067
  num_weight_broadcasts: 119209
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 170.554
    learner_load_time_ms: 3.429
    learner_load_wait_time_ms: 1.481
iterations_since_restore: 481
node_ip: 127.0.0.1
num_agent_steps_sampled: 6061100
num_agent_steps_trained: 6044500
num_env_steps_sampled: 6061100
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9953007861634
num_env_steps_trained: 6044500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9953007861634
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.4
  ram_util_percent: 75.51333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06344701109695847
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02457570016596268
  mean_inference_ms: 1.18972333040862
  mean_raw_obs_processing_ms: 0.2705652254048333
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018910417016947043
    StateBufferConnector_ms: 0.003414109068096809
    ViewRequirementAgentConnector_ms: 0.11551852496165149
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06344701109695847
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02457570016596268
    mean_inference_ms: 1.18972333040862
    mean_raw_obs_processing_ms: 0.2705652254048333
time_since_restore: 4878.901269197464
time_this_iter_s: 10.141739845275879
time_total_s: 4878.901269197464
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691999061
timesteps_total: 6061100
training_iteration: 481
trial_id: default
train step: 482
agent_timesteps_total: 6074300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01988387802272167
  StateBufferConnector_ms: 0.003658683554640094
  ViewRequirementAgentConnector_ms: 0.11834403843555635
counters:
  num_agent_steps_sampled: 6074300
  num_agent_steps_trained: 6057500
  num_env_steps_sampled: 6074300
  num_env_steps_trained: 6057500
  num_samples_added_to_queue: 6074000
  num_training_step_calls_since_last_synch_worker_weights: 726
  num_weight_broadcasts: 119470
custom_metrics: {}
date: 2023-08-14_16-44-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 103
episodes_total: 47456
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002725576632656157
        entropy_coeff: 0.01
        grad_gnorm: 7.003016948699951
        policy_loss: -3.572097193682566e-05
        total_loss: 0.07029516249895096
        var_gnorm: 64.99510955810547
        vf_explained_var: -1.0
        vf_loss: 0.1433873325586319
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12115.0
  learner_queue:
    size_count: 12121
    size_mean: 15.2
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5099668870541498
  num_agent_steps_sampled: 6074300
  num_agent_steps_trained: 6057500
  num_env_steps_sampled: 6074300
  num_env_steps_trained: 6057500
  num_samples_added_to_queue: 6074000
  num_training_step_calls_since_last_synch_worker_weights: 726
  num_weight_broadcasts: 119470
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 181.886
    learner_load_time_ms: 3.701
    learner_load_wait_time_ms: 1.565
iterations_since_restore: 482
node_ip: 127.0.0.1
num_agent_steps_sampled: 6074300
num_agent_steps_trained: 6057500
num_env_steps_sampled: 6074300
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9989299782844
num_env_steps_trained: 6057500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9989461907346
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.521428571428565
  ram_util_percent: 75.85714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06343772979547735
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024570196548571885
  mean_inference_ms: 1.1896085669431007
  mean_raw_obs_processing_ms: 0.2705417676517401
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01988387802272167
    StateBufferConnector_ms: 0.003658683554640094
    ViewRequirementAgentConnector_ms: 0.11834403843555635
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06343772979547735
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024570196548571885
    mean_inference_ms: 1.1896085669431007
    mean_raw_obs_processing_ms: 0.2705417676517401
time_since_restore: 4889.049567222595
time_this_iter_s: 10.148298025131226
time_total_s: 4889.049567222595
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691999071
timesteps_total: 6074300
training_iteration: 482
trial_id: default
train step: 483
agent_timesteps_total: 6087950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018908153070467656
  StateBufferConnector_ms: 0.003367718135085061
  ViewRequirementAgentConnector_ms: 0.11578720306681696
counters:
  num_agent_steps_sampled: 6087950
  num_agent_steps_trained: 6071000
  num_env_steps_sampled: 6087950
  num_env_steps_trained: 6071000
  num_samples_added_to_queue: 6087500
  num_training_step_calls_since_last_synch_worker_weights: 849
  num_weight_broadcasts: 119740
custom_metrics: {}
date: 2023-08-14_16-44-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 47563
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00027853704523295164
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00012815759691875428
        total_loss: 0.29239600896835327
        var_gnorm: 64.9936294555664
        vf_explained_var: -1.0
        vf_loss: 0.5878337025642395
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12142.0
  learner_queue:
    size_count: 12148
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 6087950
  num_agent_steps_trained: 6071000
  num_env_steps_sampled: 6087950
  num_env_steps_trained: 6071000
  num_samples_added_to_queue: 6087500
  num_training_step_calls_since_last_synch_worker_weights: 849
  num_weight_broadcasts: 119740
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 196.276
    learner_load_time_ms: 3.696
    learner_load_wait_time_ms: 1.586
iterations_since_restore: 483
node_ip: 127.0.0.1
num_agent_steps_sampled: 6087950
num_agent_steps_trained: 6071000
num_env_steps_sampled: 6087950
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.9907575279442
num_env_steps_trained: 6071000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.990859093571
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.75000000000001
  ram_util_percent: 76.02142857142856
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06343052094851304
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024562988186252445
  mean_inference_ms: 1.1894019754791911
  mean_raw_obs_processing_ms: 0.2705023877212483
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018908153070467656
    StateBufferConnector_ms: 0.003367718135085061
    ViewRequirementAgentConnector_ms: 0.11578720306681696
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06343052094851304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024562988186252445
    mean_inference_ms: 1.1894019754791911
    mean_raw_obs_processing_ms: 0.2705023877212483
time_since_restore: 4899.194330215454
time_this_iter_s: 10.144762992858887
time_total_s: 4899.194330215454
timers:
  sample_time_ms: 0.018
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.051
timestamp: 1691999081
timesteps_total: 6087950
training_iteration: 483
trial_id: default
train step: 484
agent_timesteps_total: 6101300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01925528049468994
  StateBufferConnector_ms: 0.003422682101909931
  ViewRequirementAgentConnector_ms: 0.1164101637326754
counters:
  num_agent_steps_sampled: 6101300
  num_agent_steps_trained: 6084500
  num_env_steps_sampled: 6101300
  num_env_steps_trained: 6084500
  num_samples_added_to_queue: 6101000
  num_training_step_calls_since_last_synch_worker_weights: 139
  num_weight_broadcasts: 120004
custom_metrics: {}
date: 2023-08-14_16-44-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 47667
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00023046426940709352
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00021798981470055878
        total_loss: 0.13500019907951355
        var_gnorm: 64.9947509765625
        vf_explained_var: -1.0
        vf_loss: 0.27186906337738037
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12169.0
  learner_queue:
    size_count: 12176
    size_mean: 15.18
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5835403373454051
  num_agent_steps_sampled: 6101300
  num_agent_steps_trained: 6084500
  num_env_steps_sampled: 6101300
  num_env_steps_trained: 6084500
  num_samples_added_to_queue: 6101000
  num_training_step_calls_since_last_synch_worker_weights: 139
  num_weight_broadcasts: 120004
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 145.554
    learner_load_time_ms: 1.618
    learner_load_wait_time_ms: 1.531
iterations_since_restore: 484
node_ip: 127.0.0.1
num_agent_steps_sampled: 6101300
num_agent_steps_trained: 6084500
num_env_steps_sampled: 6101300
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9958622583845
num_env_steps_trained: 6084500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9958157669055
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.85999999999999
  ram_util_percent: 75.94
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06341605363549054
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024557208090738705
  mean_inference_ms: 1.1892652627460973
  mean_raw_obs_processing_ms: 0.2704641572659108
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01925528049468994
    StateBufferConnector_ms: 0.003422682101909931
    ViewRequirementAgentConnector_ms: 0.1164101637326754
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06341605363549054
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024557208090738705
    mean_inference_ms: 1.1892652627460973
    mean_raw_obs_processing_ms: 0.2704641572659108
time_since_restore: 4909.357186317444
time_this_iter_s: 10.162856101989746
time_total_s: 4909.357186317444
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691999091
timesteps_total: 6101300
training_iteration: 484
trial_id: default
train step: 485
agent_timesteps_total: 6115000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018707614078699985
  StateBufferConnector_ms: 0.0033917828140971815
  ViewRequirementAgentConnector_ms: 0.1145289323040258
counters:
  num_agent_steps_sampled: 6115000
  num_agent_steps_trained: 6098500
  num_env_steps_sampled: 6115000
  num_env_steps_trained: 6098500
  num_samples_added_to_queue: 6115000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 120275
custom_metrics: {}
date: 2023-08-14_16-45-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 47774
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002559760177973658
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 9.522629261482507e-05
        total_loss: 0.02371811494231224
        var_gnorm: 64.9936752319336
        vf_explained_var: -1.0
        vf_loss: 0.04980553686618805
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12197.0
  learner_queue:
    size_count: 12200
    size_mean: 15.22
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.6527552752903256
  num_agent_steps_sampled: 6115000
  num_agent_steps_trained: 6098500
  num_env_steps_sampled: 6115000
  num_env_steps_trained: 6098500
  num_samples_added_to_queue: 6115000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 120275
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 269.978
    learner_load_time_ms: 1.614
    learner_load_wait_time_ms: 1.75
iterations_since_restore: 485
node_ip: 127.0.0.1
num_agent_steps_sampled: 6115000
num_agent_steps_trained: 6098500
num_env_steps_sampled: 6115000
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1368.674303001553
num_env_steps_trained: 6098500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1398.6452731402733
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.792857142857144
  ram_util_percent: 75.87142857142855
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06340997451025973
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0245497552435735
  mean_inference_ms: 1.189047322328357
  mean_raw_obs_processing_ms: 0.27042358340987466
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018707614078699985
    StateBufferConnector_ms: 0.0033917828140971815
    ViewRequirementAgentConnector_ms: 0.1145289323040258
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06340997451025973
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0245497552435735
    mean_inference_ms: 1.189047322328357
    mean_raw_obs_processing_ms: 0.27042358340987466
time_since_restore: 4919.453038454056
time_this_iter_s: 10.095852136611938
time_total_s: 4919.453038454056
timers:
  sample_time_ms: 0.06
  synch_weights_time_ms: 0.492
  training_iteration_time_ms: 2.197
timestamp: 1691999101
timesteps_total: 6115000
training_iteration: 485
trial_id: default
train step: 486
agent_timesteps_total: 6128350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019452663568349984
  StateBufferConnector_ms: 0.0034563816510714018
  ViewRequirementAgentConnector_ms: 0.11646999762608455
counters:
  num_agent_steps_sampled: 6128350
  num_agent_steps_trained: 6111500
  num_env_steps_sampled: 6128350
  num_env_steps_trained: 6111500
  num_samples_added_to_queue: 6128000
  num_training_step_calls_since_last_synch_worker_weights: 275
  num_weight_broadcasts: 120539
custom_metrics: {}
date: 2023-08-14_16-45-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 47878
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00019629027519840747
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00015735421038698405
        total_loss: 0.16883602738380432
        var_gnorm: 64.99357604980469
        vf_explained_var: -1.0
        vf_loss: 0.33932024240493774
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12223.0
  learner_queue:
    size_count: 12230
    size_mean: 15.46
    size_quantiles: [10.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.3146862743635837
  num_agent_steps_sampled: 6128350
  num_agent_steps_trained: 6111500
  num_env_steps_sampled: 6128350
  num_env_steps_trained: 6111500
  num_samples_added_to_queue: 6128000
  num_training_step_calls_since_last_synch_worker_weights: 275
  num_weight_broadcasts: 120539
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 146.753
    learner_load_time_ms: 1.602
    learner_load_wait_time_ms: 1.541
iterations_since_restore: 486
node_ip: 127.0.0.1
num_agent_steps_sampled: 6128350
num_agent_steps_trained: 6111500
num_env_steps_sampled: 6128350
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9942389975247
num_env_steps_trained: 6111500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.994390035043
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.471428571428575
  ram_util_percent: 75.4642857142857
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06339810095600087
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024543317936042634
  mean_inference_ms: 1.1889071189143168
  mean_raw_obs_processing_ms: 0.27038351062853927
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019452663568349984
    StateBufferConnector_ms: 0.0034563816510714018
    ViewRequirementAgentConnector_ms: 0.11646999762608455
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06339810095600087
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024543317936042634
    mean_inference_ms: 1.1889071189143168
    mean_raw_obs_processing_ms: 0.27038351062853927
time_since_restore: 4929.622558355331
time_this_iter_s: 10.169519901275635
time_total_s: 4929.622558355331
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.05
timestamp: 1691999112
timesteps_total: 6128350
training_iteration: 486
trial_id: default
train step: 487
agent_timesteps_total: 6141950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019106909493419613
  StateBufferConnector_ms: 0.0033998043737678884
  ViewRequirementAgentConnector_ms: 0.11537164171165395
counters:
  num_agent_steps_sampled: 6141950
  num_agent_steps_trained: 6125000
  num_env_steps_sampled: 6141950
  num_env_steps_trained: 6125000
  num_samples_added_to_queue: 6141500
  num_training_step_calls_since_last_synch_worker_weights: 217
  num_weight_broadcasts: 120805
custom_metrics: {}
date: 2023-08-14_16-45-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 47985
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00026619865093380213
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00043075907160528004
        total_loss: 0.29530081152915955
        var_gnorm: 64.99295043945312
        vf_explained_var: -1.0
        vf_loss: 0.5924021005630493
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12250.0
  learner_queue:
    size_count: 12257
    size_mean: 14.74
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.0669784711022032
  num_agent_steps_sampled: 6141950
  num_agent_steps_trained: 6125000
  num_env_steps_sampled: 6141950
  num_env_steps_trained: 6125000
  num_samples_added_to_queue: 6141500
  num_training_step_calls_since_last_synch_worker_weights: 217
  num_weight_broadcasts: 120805
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 150.951
    learner_load_time_ms: 1.348
    learner_load_wait_time_ms: 1.618
iterations_since_restore: 487
node_ip: 127.0.0.1
num_agent_steps_sampled: 6141950
num_agent_steps_trained: 6125000
num_env_steps_sampled: 6141950
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9992866519856
num_env_steps_trained: 6125000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9992918971914
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.57333333333334
  ram_util_percent: 75.33333333333333
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0633854421394129
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024536510495488526
  mean_inference_ms: 1.1887266791401763
  mean_raw_obs_processing_ms: 0.2703407713092062
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019106909493419613
    StateBufferConnector_ms: 0.0033998043737678884
    ViewRequirementAgentConnector_ms: 0.11537164171165395
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0633854421394129
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024536510495488526
    mean_inference_ms: 1.1887266791401763
    mean_raw_obs_processing_ms: 0.2703407713092062
time_since_restore: 4939.783233642578
time_this_iter_s: 10.160675287246704
time_total_s: 4939.783233642578
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.044
timestamp: 1691999122
timesteps_total: 6141950
training_iteration: 487
trial_id: default
train step: 488
agent_timesteps_total: 6155500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019325625221684295
  StateBufferConnector_ms: 0.0036370079472379862
  ViewRequirementAgentConnector_ms: 0.11794747046704562
counters:
  num_agent_steps_sampled: 6155500
  num_agent_steps_trained: 6139000
  num_env_steps_sampled: 6155500
  num_env_steps_trained: 6139000
  num_samples_added_to_queue: 6155500
  num_training_step_calls_since_last_synch_worker_weights: 16
  num_weight_broadcasts: 121073
custom_metrics: {}
date: 2023-08-14_16-45-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 48091
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002759998315013945
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00025061791529878974
        total_loss: 0.16390809416770935
        var_gnorm: 64.99217987060547
        vf_explained_var: -1.0
        vf_loss: 0.3300749361515045
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12278.0
  learner_queue:
    size_count: 12285
    size_mean: 15.0
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7776388834631178
  num_agent_steps_sampled: 6155500
  num_agent_steps_trained: 6139000
  num_env_steps_sampled: 6155500
  num_env_steps_trained: 6139000
  num_samples_added_to_queue: 6155500
  num_training_step_calls_since_last_synch_worker_weights: 16
  num_weight_broadcasts: 121073
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 134.899
    learner_load_time_ms: 1.363
    learner_load_wait_time_ms: 1.589
iterations_since_restore: 488
node_ip: 127.0.0.1
num_agent_steps_sampled: 6155500
num_agent_steps_trained: 6139000
num_env_steps_sampled: 6155500
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9996123315013
num_env_steps_trained: 6139000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9995994569017
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.792857142857144
  ram_util_percent: 75.62857142857145
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06337745379660986
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024530068346581866
  mean_inference_ms: 1.1885555042248122
  mean_raw_obs_processing_ms: 0.2703034019001135
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019325625221684295
    StateBufferConnector_ms: 0.0036370079472379862
    ViewRequirementAgentConnector_ms: 0.11794747046704562
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06337745379660986
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024530068346581866
    mean_inference_ms: 1.1885555042248122
    mean_raw_obs_processing_ms: 0.2703034019001135
time_since_restore: 4949.964375495911
time_this_iter_s: 10.18114185333252
time_total_s: 4949.964375495911
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691999132
timesteps_total: 6155500
training_iteration: 488
trial_id: default
train step: 489
agent_timesteps_total: 6167950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020799875259399414
  StateBufferConnector_ms: 0.0039365291595458984
  ViewRequirementAgentConnector_ms: 0.1291351318359375
counters:
  num_agent_steps_sampled: 6167950
  num_agent_steps_trained: 6151000
  num_env_steps_sampled: 6167950
  num_env_steps_trained: 6151000
  num_samples_added_to_queue: 6167500
  num_training_step_calls_since_last_synch_worker_weights: 799
  num_weight_broadcasts: 121319
custom_metrics: {}
date: 2023-08-14_16-45-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 48187
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0003532857808750123
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0010309385834261775
        total_loss: 0.7767218947410583
        var_gnorm: 64.99262237548828
        vf_explained_var: -1.0
        vf_loss: 1.5549148321151733
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12302.0
  learner_queue:
    size_count: 12308
    size_mean: 14.94
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7367786272291585
  num_agent_steps_sampled: 6167950
  num_agent_steps_trained: 6151000
  num_env_steps_sampled: 6167950
  num_env_steps_trained: 6151000
  num_samples_added_to_queue: 6167500
  num_training_step_calls_since_last_synch_worker_weights: 799
  num_weight_broadcasts: 121319
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 247.807
    learner_load_time_ms: 1.55
    learner_load_wait_time_ms: 1.847
iterations_since_restore: 489
node_ip: 127.0.0.1
num_agent_steps_sampled: 6167950
num_agent_steps_trained: 6151000
num_env_steps_sampled: 6167950
num_env_steps_sampled_this_iter: 12450
num_env_steps_sampled_throughput_per_sec: 1244.994241502694
num_env_steps_trained: 6151000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9944496411506
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 53.214285714285715
  ram_util_percent: 77.34285714285716
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0633892256926964
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024530453451837287
  mean_inference_ms: 1.1885858437574424
  mean_raw_obs_processing_ms: 0.2703171019162489
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020799875259399414
    StateBufferConnector_ms: 0.0039365291595458984
    ViewRequirementAgentConnector_ms: 0.1291351318359375
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0633892256926964
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024530453451837287
    mean_inference_ms: 1.1885858437574424
    mean_raw_obs_processing_ms: 0.2703171019162489
time_since_restore: 4960.126733541489
time_this_iter_s: 10.162358045578003
time_total_s: 4960.126733541489
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1691999142
timesteps_total: 6167950
training_iteration: 489
trial_id: default
train step: 490
agent_timesteps_total: 6180250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021937847137451172
  StateBufferConnector_ms: 0.00396275520324707
  ViewRequirementAgentConnector_ms: 0.13268041610717773
counters:
  num_agent_steps_sampled: 6180250
  num_agent_steps_trained: 6163500
  num_env_steps_sampled: 6180250
  num_env_steps_trained: 6163500
  num_samples_added_to_queue: 6180000
  num_training_step_calls_since_last_synch_worker_weights: 62
  num_weight_broadcasts: 121561
custom_metrics: {}
date: 2023-08-14_16-45-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 97
episodes_total: 48284
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00028304793522693217
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0006126241059973836
        total_loss: 0.4628812074661255
        var_gnorm: 64.99186706542969
        vf_explained_var: -1.0
        vf_loss: 0.9298181533813477
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12327.0
  learner_queue:
    size_count: 12334
    size_mean: 14.82
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.862149295840696
  num_agent_steps_sampled: 6180250
  num_agent_steps_trained: 6163500
  num_env_steps_sampled: 6180250
  num_env_steps_trained: 6163500
  num_samples_added_to_queue: 6180000
  num_training_step_calls_since_last_synch_worker_weights: 62
  num_weight_broadcasts: 121561
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 149.279
    learner_load_time_ms: 1.555
    learner_load_wait_time_ms: 1.582
iterations_since_restore: 490
node_ip: 127.0.0.1
num_agent_steps_sampled: 6180250
num_agent_steps_trained: 6163500
num_env_steps_sampled: 6180250
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.9973900373527
num_env_steps_trained: 6163500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9973475989357
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 51.14
  ram_util_percent: 77.77333333333334
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06338813286705852
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024531038500850953
  mean_inference_ms: 1.1886550094153585
  mean_raw_obs_processing_ms: 0.2703308323922789
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021937847137451172
    StateBufferConnector_ms: 0.00396275520324707
    ViewRequirementAgentConnector_ms: 0.13268041610717773
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06338813286705852
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024531038500850953
    mean_inference_ms: 1.1886550094153585
    mean_raw_obs_processing_ms: 0.2703308323922789
time_since_restore: 4970.304397583008
time_this_iter_s: 10.177664041519165
time_total_s: 4970.304397583008
timers:
  sample_time_ms: 0.021
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.053
timestamp: 1691999152
timesteps_total: 6180250
training_iteration: 490
trial_id: default
train step: 491
agent_timesteps_total: 6191750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022916555404663086
  StateBufferConnector_ms: 0.004178762435913086
  ViewRequirementAgentConnector_ms: 0.1371629238128662
counters:
  num_agent_steps_sampled: 6191750
  num_agent_steps_trained: 6175000
  num_env_steps_sampled: 6191750
  num_env_steps_trained: 6175000
  num_samples_added_to_queue: 6191500
  num_training_step_calls_since_last_synch_worker_weights: 1268
  num_weight_broadcasts: 121788
custom_metrics: {}
date: 2023-08-14_16-46-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 89
episodes_total: 48373
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002618521102704108
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0008376154000870883
        total_loss: 0.889731228351593
        var_gnorm: 64.99004364013672
        vf_explained_var: -1.0
        vf_loss: 1.7837562561035156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12350.0
  learner_queue:
    size_count: 12354
    size_mean: 14.76
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8282231811242302
  num_agent_steps_sampled: 6191750
  num_agent_steps_trained: 6175000
  num_env_steps_sampled: 6191750
  num_env_steps_trained: 6175000
  num_samples_added_to_queue: 6191500
  num_training_step_calls_since_last_synch_worker_weights: 1268
  num_weight_broadcasts: 121788
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 260.467
    learner_load_time_ms: 1.812
    learner_load_wait_time_ms: 1.616
iterations_since_restore: 491
node_ip: 127.0.0.1
num_agent_steps_sampled: 6191750
num_agent_steps_trained: 6175000
num_env_steps_sampled: 6191750
num_env_steps_sampled_this_iter: 11500
num_env_steps_sampled_throughput_per_sec: 1149.9969017589117
num_env_steps_trained: 6175000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9969017589117
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 57.21428571428572
  ram_util_percent: 79.9357142857143
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.063419975297102
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024535782597298505
  mean_inference_ms: 1.1888252582104795
  mean_raw_obs_processing_ms: 0.27039379368809713
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022916555404663086
    StateBufferConnector_ms: 0.004178762435913086
    ViewRequirementAgentConnector_ms: 0.1371629238128662
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 89
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.063419975297102
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024535782597298505
    mean_inference_ms: 1.1888252582104795
    mean_raw_obs_processing_ms: 0.27039379368809713
time_since_restore: 4980.424294471741
time_this_iter_s: 10.11989688873291
time_total_s: 4980.424294471741
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691999162
timesteps_total: 6191750
training_iteration: 491
trial_id: default
train step: 492
agent_timesteps_total: 6204100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021047353744506836
  StateBufferConnector_ms: 0.0038712024688720703
  ViewRequirementAgentConnector_ms: 0.12888550758361816
counters:
  num_agent_steps_sampled: 6204100
  num_agent_steps_trained: 6187500
  num_env_steps_sampled: 6204100
  num_env_steps_trained: 6187500
  num_samples_added_to_queue: 6204000
  num_training_step_calls_since_last_synch_worker_weights: 258
  num_weight_broadcasts: 122031
custom_metrics: {}
date: 2023-08-14_16-46-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 97
episodes_total: 48470
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00025097274919971824
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00012387693277560174
        total_loss: 0.03453052416443825
        var_gnorm: 64.9913558959961
        vf_explained_var: -1.0
        vf_loss: 0.07132302224636078
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12375.0
  learner_queue:
    size_count: 12382
    size_mean: 14.82
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.9046259475288054
  num_agent_steps_sampled: 6204100
  num_agent_steps_trained: 6187500
  num_env_steps_sampled: 6204100
  num_env_steps_trained: 6187500
  num_samples_added_to_queue: 6204000
  num_training_step_calls_since_last_synch_worker_weights: 258
  num_weight_broadcasts: 122031
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 137.094
    learner_load_time_ms: 1.825
    learner_load_wait_time_ms: 1.533
iterations_since_restore: 492
node_ip: 127.0.0.1
num_agent_steps_sampled: 6204100
num_agent_steps_trained: 6187500
num_env_steps_sampled: 6204100
num_env_steps_sampled_this_iter: 12350
num_env_steps_sampled_throughput_per_sec: 1234.9954360892154
num_env_steps_trained: 6187500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9953806571007
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 54.46428571428572
  ram_util_percent: 80.08571428571429
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06340331914559004
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024537483522505763
  mean_inference_ms: 1.1889265758250573
  mean_raw_obs_processing_ms: 0.270393987589135
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021047353744506836
    StateBufferConnector_ms: 0.0038712024688720703
    ViewRequirementAgentConnector_ms: 0.12888550758361816
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06340331914559004
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024537483522505763
    mean_inference_ms: 1.1889265758250573
    mean_raw_obs_processing_ms: 0.270393987589135
time_since_restore: 4990.618345737457
time_this_iter_s: 10.194051265716553
time_total_s: 4990.618345737457
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1691999173
timesteps_total: 6204100
training_iteration: 492
trial_id: default
train step: 493
agent_timesteps_total: 6216850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020511150360107422
  StateBufferConnector_ms: 0.003628969192504883
  ViewRequirementAgentConnector_ms: 0.12229657173156738
counters:
  num_agent_steps_sampled: 6216850
  num_agent_steps_trained: 6200000
  num_env_steps_sampled: 6216850
  num_env_steps_trained: 6200000
  num_samples_added_to_queue: 6216500
  num_training_step_calls_since_last_synch_worker_weights: 151
  num_weight_broadcasts: 122283
custom_metrics: {}
date: 2023-08-14_16-46-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 48570
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002763307129498571
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0002701532794162631
        total_loss: 0.16731396317481995
        var_gnorm: 64.99085235595703
        vf_explained_var: -1.0
        vf_loss: 0.3379315435886383
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12400.0
  learner_queue:
    size_count: 12407
    size_mean: 14.96
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8216476058777122
  num_agent_steps_sampled: 6216850
  num_agent_steps_trained: 6200000
  num_env_steps_sampled: 6216850
  num_env_steps_trained: 6200000
  num_samples_added_to_queue: 6216500
  num_training_step_calls_since_last_synch_worker_weights: 151
  num_weight_broadcasts: 122283
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 148.416
    learner_load_time_ms: 8.759
    learner_load_wait_time_ms: 1.482
iterations_since_restore: 493
node_ip: 127.0.0.1
num_agent_steps_sampled: 6216850
num_agent_steps_trained: 6200000
num_env_steps_sampled: 6216850
num_env_steps_sampled_this_iter: 12750
num_env_steps_sampled_throughput_per_sec: 1274.9964434007675
num_env_steps_trained: 6200000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9965131380072
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.42666666666667
  ram_util_percent: 79.8
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06339725319352954
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024535515532068803
  mean_inference_ms: 1.1889034724037566
  mean_raw_obs_processing_ms: 0.27038335975606603
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020511150360107422
    StateBufferConnector_ms: 0.003628969192504883
    ViewRequirementAgentConnector_ms: 0.12229657173156738
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06339725319352954
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024535515532068803
    mean_inference_ms: 1.1889034724037566
    mean_raw_obs_processing_ms: 0.27038335975606603
time_since_restore: 5000.764382839203
time_this_iter_s: 10.146037101745605
time_total_s: 5000.764382839203
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1691999183
timesteps_total: 6216850
training_iteration: 493
trial_id: default
train step: 494
agent_timesteps_total: 6229950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019590293659883386
  StateBufferConnector_ms: 0.0035938094643985525
  ViewRequirementAgentConnector_ms: 0.11800504198261336
counters:
  num_agent_steps_sampled: 6229950
  num_agent_steps_trained: 6213000
  num_env_steps_sampled: 6229950
  num_env_steps_trained: 6213000
  num_samples_added_to_queue: 6229500
  num_training_step_calls_since_last_synch_worker_weights: 931
  num_weight_broadcasts: 122542
custom_metrics: {}
date: 2023-08-14_16-46-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 48672
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.00036581067251972854
        entropy_coeff: 0.01
        grad_gnorm: 16.93456268310547
        policy_loss: 8.654466364532709e-05
        total_loss: 0.06866668909788132
        var_gnorm: 64.99076843261719
        vf_explained_var: -1.0
        vf_loss: 0.14081838726997375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12426.0
  learner_queue:
    size_count: 12431
    size_mean: 14.92
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7758378304338491
  num_agent_steps_sampled: 6229950
  num_agent_steps_trained: 6213000
  num_env_steps_sampled: 6229950
  num_env_steps_trained: 6213000
  num_samples_added_to_queue: 6229500
  num_training_step_calls_since_last_synch_worker_weights: 931
  num_weight_broadcasts: 122542
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 236.076
    learner_load_time_ms: 8.767
    learner_load_wait_time_ms: 1.527
iterations_since_restore: 494
node_ip: 127.0.0.1
num_agent_steps_sampled: 6229950
num_agent_steps_trained: 6213000
num_env_steps_sampled: 6229950
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9994690420394
num_env_steps_trained: 6213000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9994730951537
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.37142857142857
  ram_util_percent: 77.14285714285714
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06339245096389037
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02453102749990696
  mean_inference_ms: 1.1888020554481498
  mean_raw_obs_processing_ms: 0.27036445591038716
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019590293659883386
    StateBufferConnector_ms: 0.0035938094643985525
    ViewRequirementAgentConnector_ms: 0.11800504198261336
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06339245096389037
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02453102749990696
    mean_inference_ms: 1.1888020554481498
    mean_raw_obs_processing_ms: 0.27036445591038716
time_since_restore: 5010.873704910278
time_this_iter_s: 10.10932207107544
time_total_s: 5010.873704910278
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691999193
timesteps_total: 6229950
training_iteration: 494
trial_id: default
train step: 495
agent_timesteps_total: 6243150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01976329546708327
  StateBufferConnector_ms: 0.003536847921518179
  ViewRequirementAgentConnector_ms: 0.12077345297886775
counters:
  num_agent_steps_sampled: 6243150
  num_agent_steps_trained: 6226500
  num_env_steps_sampled: 6243150
  num_env_steps_trained: 6226500
  num_samples_added_to_queue: 6243000
  num_training_step_calls_since_last_synch_worker_weights: 657
  num_weight_broadcasts: 122803
custom_metrics: {}
date: 2023-08-14_16-46-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 48776
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0003889358486048877
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0006498009315691888
        total_loss: 0.2633165717124939
        var_gnorm: 64.98835754394531
        vf_explained_var: -1.0
        vf_loss: 0.531822144985199
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12453.0
  learner_queue:
    size_count: 12459
    size_mean: 15.44
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2191800523302536
  num_agent_steps_sampled: 6243150
  num_agent_steps_trained: 6226500
  num_env_steps_sampled: 6243150
  num_env_steps_trained: 6226500
  num_samples_added_to_queue: 6243000
  num_training_step_calls_since_last_synch_worker_weights: 657
  num_weight_broadcasts: 122803
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 176.086
    learner_load_time_ms: 9.039
    learner_load_wait_time_ms: 1.594
iterations_since_restore: 495
node_ip: 127.0.0.1
num_agent_steps_sampled: 6243150
num_agent_steps_trained: 6226500
num_env_steps_sampled: 6243150
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9972305355957
num_env_steps_trained: 6226500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.997167593223
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.8
  ram_util_percent: 78.05714285714286
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06338732484492199
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02452659266636883
  mean_inference_ms: 1.1886831407843617
  mean_raw_obs_processing_ms: 0.27034327466264385
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01976329546708327
    StateBufferConnector_ms: 0.003536847921518179
    ViewRequirementAgentConnector_ms: 0.12077345297886775
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06338732484492199
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02452659266636883
    mean_inference_ms: 1.1886831407843617
    mean_raw_obs_processing_ms: 0.27034327466264385
time_since_restore: 5021.013627767563
time_this_iter_s: 10.139922857284546
time_total_s: 5021.013627767563
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.044
timestamp: 1691999203
timesteps_total: 6243150
training_iteration: 495
trial_id: default
train step: 496
agent_timesteps_total: 6255350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021419286727905273
  StateBufferConnector_ms: 0.0038383007049560547
  ViewRequirementAgentConnector_ms: 0.12960076332092285
counters:
  num_agent_steps_sampled: 6255350
  num_agent_steps_trained: 6238500
  num_env_steps_sampled: 6255350
  num_env_steps_trained: 6238500
  num_samples_added_to_queue: 6255000
  num_training_step_calls_since_last_synch_worker_weights: 301
  num_weight_broadcasts: 123043
custom_metrics: {}
date: 2023-08-14_16-46-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 94
episodes_total: 48870
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0003306758007965982
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.00060283113270998
        total_loss: 0.3624613285064697
        var_gnorm: 64.98897552490234
        vf_explained_var: -1.0
        vf_loss: 0.727023720741272
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12477.0
  learner_queue:
    size_count: 12483
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 6255350
  num_agent_steps_trained: 6238500
  num_env_steps_sampled: 6255350
  num_env_steps_trained: 6238500
  num_samples_added_to_queue: 6255000
  num_training_step_calls_since_last_synch_worker_weights: 301
  num_weight_broadcasts: 123043
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 184.291
    learner_load_time_ms: 9.008
    learner_load_wait_time_ms: 1.593
iterations_since_restore: 496
node_ip: 127.0.0.1
num_agent_steps_sampled: 6255350
num_agent_steps_trained: 6238500
num_env_steps_sampled: 6255350
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.9973530826776
num_env_steps_trained: 6238500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9973964747649
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 53.92666666666666
  ram_util_percent: 78.34666666666666
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0634039929209214
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024527127183781472
  mean_inference_ms: 1.1887419112107873
  mean_raw_obs_processing_ms: 0.2703781433209352
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021419286727905273
    StateBufferConnector_ms: 0.0038383007049560547
    ViewRequirementAgentConnector_ms: 0.12960076332092285
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0634039929209214
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024527127183781472
    mean_inference_ms: 1.1887419112107873
    mean_raw_obs_processing_ms: 0.2703781433209352
time_since_restore: 5031.156903743744
time_this_iter_s: 10.14327597618103
time_total_s: 5031.156903743744
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691999213
timesteps_total: 6255350
training_iteration: 496
trial_id: default
train step: 497
agent_timesteps_total: 6268750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01914253774678932
  StateBufferConnector_ms: 0.0034802364853193176
  ViewRequirementAgentConnector_ms: 0.11779339808338093
counters:
  num_agent_steps_sampled: 6268750
  num_agent_steps_trained: 6252000
  num_env_steps_sampled: 6268750
  num_env_steps_trained: 6252000
  num_samples_added_to_queue: 6268500
  num_training_step_calls_since_last_synch_worker_weights: 144
  num_weight_broadcasts: 123305
custom_metrics: {}
date: 2023-08-14_16-47-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 48976
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0002821656526066363
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.00044747567153535783
        total_loss: 0.3119191825389862
        var_gnorm: 64.98777770996094
        vf_explained_var: -1.0
        vf_loss: 0.6275550127029419
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12504.0
  learner_queue:
    size_count: 12511
    size_mean: 15.04
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.70833252032501
  num_agent_steps_sampled: 6268750
  num_agent_steps_trained: 6252000
  num_env_steps_sampled: 6268750
  num_env_steps_trained: 6252000
  num_samples_added_to_queue: 6268500
  num_training_step_calls_since_last_synch_worker_weights: 144
  num_weight_broadcasts: 123305
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 137.191
    learner_load_time_ms: 8.777
    learner_load_wait_time_ms: 1.518
iterations_since_restore: 497
node_ip: 127.0.0.1
num_agent_steps_sampled: 6268750
num_agent_steps_trained: 6252000
num_env_steps_sampled: 6268750
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.993802099285
num_env_steps_trained: 6252000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9937558462946
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.48571428571428
  ram_util_percent: 78.3
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06338313566985114
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024521615227630064
  mean_inference_ms: 1.1886114854853478
  mean_raw_obs_processing_ms: 0.2703390325666006
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01914253774678932
    StateBufferConnector_ms: 0.0034802364853193176
    ViewRequirementAgentConnector_ms: 0.11779339808338093
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06338313566985114
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024521615227630064
    mean_inference_ms: 1.1886114854853478
    mean_raw_obs_processing_ms: 0.2703390325666006
time_since_restore: 5041.311879873276
time_this_iter_s: 10.15497612953186
time_total_s: 5041.311879873276
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1691999223
timesteps_total: 6268750
training_iteration: 497
trial_id: default
train step: 498
agent_timesteps_total: 6281650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0196685791015625
  StateBufferConnector_ms: 0.003504037857055664
  ViewRequirementAgentConnector_ms: 0.1197206974029541
counters:
  num_agent_steps_sampled: 6281650
  num_agent_steps_trained: 6265000
  num_env_steps_sampled: 6281650
  num_env_steps_trained: 6265000
  num_samples_added_to_queue: 6281500
  num_training_step_calls_since_last_synch_worker_weights: 938
  num_weight_broadcasts: 123557
custom_metrics: {}
date: 2023-08-14_16-47-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 49076
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0004071541188750416
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.0010208277963101864
        total_loss: 0.7340596914291382
        var_gnorm: 64.9865951538086
        vf_explained_var: -1.0
        vf_loss: 1.4742326736450195
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12530.0
  learner_queue:
    size_count: 12535
    size_mean: 15.14
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.587576769797291
  num_agent_steps_sampled: 6281650
  num_agent_steps_trained: 6265000
  num_env_steps_sampled: 6281650
  num_env_steps_trained: 6265000
  num_samples_added_to_queue: 6281500
  num_training_step_calls_since_last_synch_worker_weights: 938
  num_weight_broadcasts: 123557
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 252.616
    learner_load_time_ms: 8.873
    learner_load_wait_time_ms: 1.661
iterations_since_restore: 498
node_ip: 127.0.0.1
num_agent_steps_sampled: 6281650
num_agent_steps_trained: 6265000
num_env_steps_sampled: 6281650
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9963400467761
num_env_steps_trained: 6265000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9963116750457
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.08571428571429
  ram_util_percent: 78.24285714285715
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06338005823991491
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024518487036655535
  mean_inference_ms: 1.188554151800699
  mean_raw_obs_processing_ms: 0.27032438693616045
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0196685791015625
    StateBufferConnector_ms: 0.003504037857055664
    ViewRequirementAgentConnector_ms: 0.1197206974029541
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06338005823991491
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024518487036655535
    mean_inference_ms: 1.188554151800699
    mean_raw_obs_processing_ms: 0.27032438693616045
time_since_restore: 5051.431259870529
time_this_iter_s: 10.119379997253418
time_total_s: 5051.431259870529
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1691999234
timesteps_total: 6281650
training_iteration: 498
trial_id: default
train step: 499
agent_timesteps_total: 6292800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023192882537841797
  StateBufferConnector_ms: 0.004116535186767578
  ViewRequirementAgentConnector_ms: 0.1372847557067871
counters:
  num_agent_steps_sampled: 6292800
  num_agent_steps_trained: 6276000
  num_env_steps_sampled: 6292800
  num_env_steps_trained: 6276000
  num_samples_added_to_queue: 6292500
  num_training_step_calls_since_last_synch_worker_weights: 1133
  num_weight_broadcasts: 123777
custom_metrics: {}
date: 2023-08-14_16-47-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 87
episodes_total: 49163
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.000358810240868479
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.000754928681999445
        total_loss: 0.5120852589607239
        var_gnorm: 64.98749542236328
        vf_explained_var: -1.0
        vf_loss: 1.0262486934661865
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12552.0
  learner_queue:
    size_count: 12557
    size_mean: 14.96
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6728418933061189
  num_agent_steps_sampled: 6292800
  num_agent_steps_trained: 6276000
  num_env_steps_sampled: 6292800
  num_env_steps_trained: 6276000
  num_samples_added_to_queue: 6292500
  num_training_step_calls_since_last_synch_worker_weights: 1133
  num_weight_broadcasts: 123777
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 295.592
    learner_load_time_ms: 1.945
    learner_load_wait_time_ms: 1.839
iterations_since_restore: 499
node_ip: 127.0.0.1
num_agent_steps_sampled: 6292800
num_agent_steps_trained: 6276000
num_env_steps_sampled: 6292800
num_env_steps_sampled_this_iter: 11150
num_env_steps_sampled_throughput_per_sec: 1114.9989898213955
num_env_steps_trained: 6276000
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9990034112423
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 59.87333333333333
  ram_util_percent: 78.5
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0634192708364029
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024524377924902765
  mean_inference_ms: 1.188772186897972
  mean_raw_obs_processing_ms: 0.2703992852981684
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023192882537841797
    StateBufferConnector_ms: 0.004116535186767578
    ViewRequirementAgentConnector_ms: 0.1372847557067871
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 87
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0634192708364029
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024524377924902765
    mean_inference_ms: 1.188772186897972
    mean_raw_obs_processing_ms: 0.2703992852981684
time_since_restore: 5061.569171905518
time_this_iter_s: 10.137912034988403
time_total_s: 5061.569171905518
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1691999244
timesteps_total: 6292800
training_iteration: 499
trial_id: default
train step: 500
agent_timesteps_total: 6304300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023303985595703125
  StateBufferConnector_ms: 0.004340171813964844
  ViewRequirementAgentConnector_ms: 0.13905692100524902
counters:
  num_agent_steps_sampled: 6304300
  num_agent_steps_trained: 6287500
  num_env_steps_sampled: 6304300
  num_env_steps_trained: 6287500
  num_samples_added_to_queue: 6304000
  num_training_step_calls_since_last_synch_worker_weights: 833
  num_weight_broadcasts: 124004
custom_metrics: {}
date: 2023-08-14_16-47-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 90
episodes_total: 49253
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.29999999999927
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0003578218456823379
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.0011534342775121331
        total_loss: 0.9899712800979614
        var_gnorm: 64.98680114746094
        vf_explained_var: -1.0
        vf_loss: 1.981213927268982
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12575.0
  learner_queue:
    size_count: 12581
    size_mean: 15.1
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.445683229480096
  num_agent_steps_sampled: 6304300
  num_agent_steps_trained: 6287500
  num_env_steps_sampled: 6304300
  num_env_steps_trained: 6287500
  num_samples_added_to_queue: 6304000
  num_training_step_calls_since_last_synch_worker_weights: 833
  num_weight_broadcasts: 124004
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 202.465
    learner_load_time_ms: 2.809
    learner_load_wait_time_ms: 1.664
iterations_since_restore: 500
node_ip: 127.0.0.1
num_agent_steps_sampled: 6304300
num_agent_steps_trained: 6287500
num_env_steps_sampled: 6304300
num_env_steps_sampled_this_iter: 11500
num_env_steps_sampled_throughput_per_sec: 1149.9956405328073
num_env_steps_trained: 6287500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9956405328073
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 56.41428571428571
  ram_util_percent: 78.57857142857144
pid: 42550
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06342725692912649
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.024529898702280114
  mean_inference_ms: 1.1890113325363965
  mean_raw_obs_processing_ms: 0.27043975833481393
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023303985595703125
    StateBufferConnector_ms: 0.004340171813964844
    ViewRequirementAgentConnector_ms: 0.13905692100524902
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06342725692912649
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.024529898702280114
    mean_inference_ms: 1.1890113325363965
    mean_raw_obs_processing_ms: 0.27043975833481393
time_since_restore: 5071.71445274353
time_this_iter_s: 10.145280838012695
time_total_s: 5071.71445274353
timers:
  sample_time_ms: 0.018
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1691999254
timesteps_total: 6304300
training_iteration: 500
trial_id: default
train step: 501
Traceback (most recent call last):
  File "/Users/sangbin/Impala/launch.py", line 318, in <module>
    result = algo.train()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 372, in train
    result = self.step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 853, in step
    results, train_iter_ctx = self._run_one_training_iteration()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2837, in _run_one_training_iteration
    results = self.training_step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 697, in training_step
    unprocessed_sample_batches = self.get_samples_from_workers(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 907, in get_samples_from_workers
    ] = self.workers.fetch_ready_async_reqs(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py", line 782, in fetch_ready_async_reqs
    remote_results = self.__worker_manager.fetch_ready_async_reqs(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py", line 753, in fetch_ready_async_reqs
    ready, remote_results = self.__fetch_result(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py", line 460, in __fetch_result
    ready, _ = ray.wait(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/worker.py", line 2728, in wait
    ready_ids, remaining_ids = worker.core_worker.wait(
  File "python/ray/_raylet.pyx", line 3012, in ray._raylet.CoreWorker.wait
  File "python/ray/_raylet.pyx", line 400, in ray._raylet.check_status
KeyboardInterrupt
Traceback (most recent call last):
  File "/Users/sangbin/Impala/launch.py", line 318, in <module>
    result = algo.train()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 372, in train
    result = self.step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 853, in step
    results, train_iter_ctx = self._run_one_training_iteration()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2837, in _run_one_training_iteration
    results = self.training_step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 697, in training_step
    unprocessed_sample_batches = self.get_samples_from_workers(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 907, in get_samples_from_workers
    ] = self.workers.fetch_ready_async_reqs(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py", line 782, in fetch_ready_async_reqs
    remote_results = self.__worker_manager.fetch_ready_async_reqs(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py", line 753, in fetch_ready_async_reqs
    ready, remote_results = self.__fetch_result(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py", line 460, in __fetch_result
    ready, _ = ray.wait(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/worker.py", line 2728, in wait
    ready_ids, remaining_ids = worker.core_worker.wait(
  File "python/ray/_raylet.pyx", line 3012, in ray._raylet.CoreWorker.wait
  File "python/ray/_raylet.pyx", line 400, in ray._raylet.check_status
KeyboardInterrupt
[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
2023-08-14 16:57:08,541	INFO tensorboardx.py:48 -- pip install "ray[tune]" to see TensorBoard files.
2023-08-14 16:57:08,541	WARNING unified.py:56 -- Could not instantiate TBXLogger: No module named 'tensorboardX'.
[36m(pid=46416)[39m lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.
[36m(pid=46416)[39m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,367	WARNING env.py:162 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,371	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,371	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,373	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.AttentionWrapper` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,373	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,373	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,390	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.GTrXLNet` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,400	WARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,400	WARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,400	WARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,400	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=46415)[39m 2023-08-14 16:57:10,461	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/catalog.py:790: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  prep = cls(observation_space, options)
2023-08-14 16:57:10,491	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,491	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,493	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.AttentionWrapper` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,494	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,494	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/torch/attention_net.py:281: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  super().__init__(obs_space, action_space, None, model_config, name)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/torch/attention_net.py:281: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  super().__init__(obs_space, action_space, None, model_config, name)
2023-08-14 16:57:10,497	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.GTrXLNet` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,499	WARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,499	WARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,499	WARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,500	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/modelv2.py:440: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  prep = get_preprocessor(space)(space)
2023-08-14 16:57:10,520	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/connectors/agent/obs_preproc.py:40: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  self._preprocessor = get_preprocessor(obs_space)(
2023-08-14 16:57:10,538	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.multi_gpu_learner_thread.MultiGPULearnerThread` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,539	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.minibatch_buffer.MinibatchBuffer` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,539	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.learner_thread.LearnerThread` has been deprecated. This will raise an error in the future!
2023-08-14 16:57:10,540	WARNING util.py:68 -- Install gputil for GPU system monitoring.
2023-08-14 16:57:10,607	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.replay_ops.SimpleReplayBuffer` has been deprecated. This will raise an error in the future!
train step: 1
agent_timesteps_total: 14400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01753811287668954
  StateBufferConnector_ms: 0.003234264069953851
  ViewRequirementAgentConnector_ms: 0.10443240140391662
counters:
  num_agent_steps_sampled: 14400
  num_agent_steps_trained: 6000
  num_env_steps_sampled: 14400
  num_env_steps_trained: 6000
  num_samples_added_to_queue: 14000
  num_training_step_calls_since_last_synch_worker_weights: 418
  num_weight_broadcasts: 287
custom_metrics: {}
date: 2023-08-14_16-57-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.2300884955752212
episode_reward_min: 0.0
episodes_this_iter: 113
episodes_total: 113
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 6.7
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.5595821142196655
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.572782516479492
        total_loss: 3.6817426681518555
        var_gnorm: 63.325233459472656
        vf_explained_var: 0.00841742753982544
        vf_loss: 17.81374168395996
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 12.0
  learner_queue:
    size_count: 17
    size_mean: 0.0
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 0.0]
    size_std: 0.0
  num_agent_steps_sampled: 14400
  num_agent_steps_trained: 6000
  num_env_steps_sampled: 14400
  num_env_steps_trained: 6000
  num_samples_added_to_queue: 14000
  num_training_step_calls_since_last_synch_worker_weights: 418
  num_weight_broadcasts: 287
  timing_breakdown:
    learner_dequeue_time_ms: 2923.961
    learner_grad_time_ms: 460.694
    learner_load_time_ms: 9.545
    learner_load_wait_time_ms: 2.155
iterations_since_restore: 1
node_ip: 127.0.0.1
num_agent_steps_sampled: 14400
num_agent_steps_trained: 6000
num_env_steps_sampled: 14400
num_env_steps_sampled_this_iter: 14400
num_env_steps_sampled_throughput_per_sec: 1439.9997596741123
num_env_steps_trained: 6000
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9998998642135
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 51.3
  ram_util_percent: 77.48666666666666
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05447468099693662
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.020733475259672608
  mean_inference_ms: 1.0254715512587225
  mean_raw_obs_processing_ms: 0.23033006374776824
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01753811287668954
    StateBufferConnector_ms: 0.003234264069953851
    ViewRequirementAgentConnector_ms: 0.10443240140391662
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.2300884955752212
  episode_reward_min: 0.0
  episodes_this_iter: 113
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128]
    episode_reward: [0.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 0.0, 0.0,
      1.0, 0.0, 0.0, 4.0, 0.0, 1.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 4.0, 1.0, 2.0,
      0.0, 2.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 1.0,
      1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 2.0,
      1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 0.0, 1.0, 1.0, 0.0,
      1.0, 0.0, 5.0, 2.0, 0.0, 0.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 2.0, 0.0, 2.0, 3.0,
      0.0, 2.0, 0.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 3.0, 1.0,
      1.0, 0.0, 0.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05447468099693662
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.020733475259672608
    mean_inference_ms: 1.0254715512587225
    mean_raw_obs_processing_ms: 0.23033006374776824
time_since_restore: 10.121464014053345
time_this_iter_s: 10.121464014053345
time_total_s: 10.121464014053345
timers:
  sample_time_ms: 0.013
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.039
timestamp: 1691999840
timesteps_total: 14400
training_iteration: 1
trial_id: default
train step: 2
agent_timesteps_total: 29700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.017104943593343098
  StateBufferConnector_ms: 0.0029804309209187827
  ViewRequirementAgentConnector_ms: 0.10232587655385335
counters:
  num_agent_steps_sampled: 29700
  num_agent_steps_trained: 15000
  num_env_steps_sampled: 29700
  num_env_steps_trained: 15000
  num_samples_added_to_queue: 29500
  num_training_step_calls_since_last_synch_worker_weights: 1228
  num_weight_broadcasts: 589
custom_metrics: {}
date: 2023-08-14_16-57-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.65
episode_reward_min: 0.0
episodes_this_iter: 120
episodes_total: 233
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 13.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.4733569622039795
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 29.95953941345215
        total_loss: 30.222841262817383
        var_gnorm: 63.325355529785156
        vf_explained_var: 0.43361353874206543
        vf_loss: 15.260174751281738
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 30.0
  learner_queue:
    size_count: 34
    size_mean: 2.911764705882353
    size_quantiles: [0.0, 0.0, 0.0, 10.0, 12.0]
    size_std: 4.196410560430842
  num_agent_steps_sampled: 29700
  num_agent_steps_trained: 15000
  num_env_steps_sampled: 29700
  num_env_steps_trained: 15000
  num_samples_added_to_queue: 29500
  num_training_step_calls_since_last_synch_worker_weights: 1228
  num_weight_broadcasts: 589
  timing_breakdown:
    learner_dequeue_time_ms: 1815.18
    learner_grad_time_ms: 478.756
    learner_load_time_ms: 6.764
    learner_load_wait_time_ms: 10.319
iterations_since_restore: 2
node_ip: 127.0.0.1
num_agent_steps_sampled: 29700
num_agent_steps_trained: 15000
num_env_steps_sampled: 29700
num_env_steps_sampled_this_iter: 15300
num_env_steps_sampled_throughput_per_sec: 1529.9964616380505
num_env_steps_trained: 15000
num_env_steps_trained_this_iter: 9000
num_env_steps_trained_throughput_per_sec: 899.997918610618
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 9000
perf:
  cpu_util_percent: 47.31428571428571
  ram_util_percent: 78.05714285714286
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05293962129700743
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.020011571450743053
  mean_inference_ms: 0.9986471353363036
  mean_raw_obs_processing_ms: 0.2260588849672387
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.017104943593343098
    StateBufferConnector_ms: 0.0029804309209187827
    ViewRequirementAgentConnector_ms: 0.10232587655385335
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.65
  episode_reward_min: 0.0
  episodes_this_iter: 120
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 1.0, 0.0, 0.0, 3.0, 4.0, 1.0, 1.0, 4.0, 0.0, 0.0, 1.0,
      0.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 0.0, 3.0, 2.0, 1.0, 0.0,
      1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 1.0, 2.0, 5.0, 2.0, 1.0, 0.0, 4.0, 2.0,
      0.0, 5.0, 3.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 3.0, 2.0, 0.0, 1.0,
      2.0, 4.0, 0.0, 0.0, 0.0, 0.0, 2.0, 2.0, 3.0, 0.0, 3.0, 2.0, 0.0, 3.0, 2.0, 1.0,
      1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 4.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 1.0, 4.0,
      2.0, 2.0, 4.0, 2.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 4.0, 2.0, 1.0,
      1.0, 4.0, 4.0, 0.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05293962129700743
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.020011571450743053
    mean_inference_ms: 0.9986471353363036
    mean_raw_obs_processing_ms: 0.2260588849672387
time_since_restore: 20.204181909561157
time_this_iter_s: 10.082717895507812
time_total_s: 20.204181909561157
timers:
  sample_time_ms: 0.013
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.038
timestamp: 1691999850
timesteps_total: 29700
training_iteration: 2
trial_id: default
train step: 3
agent_timesteps_total: 45100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.016829172770182293
  StateBufferConnector_ms: 0.0028961896896362305
  ViewRequirementAgentConnector_ms: 0.09952267011006673
counters:
  num_agent_steps_sampled: 45100
  num_agent_steps_trained: 28500
  num_env_steps_sampled: 45100
  num_env_steps_trained: 28500
  num_samples_added_to_queue: 45000
  num_training_step_calls_since_last_synch_worker_weights: 422
  num_weight_broadcasts: 893
custom_metrics: {}
date: 2023-08-14_16-57-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.191666666666667
episode_reward_min: 0.0
episodes_this_iter: 120
episodes_total: 353
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 27.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3335257768630981
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 17.71727180480957
        total_loss: 18.99092674255371
        var_gnorm: 63.326786041259766
        vf_explained_var: 0.47857487201690674
        vf_loss: 15.882568359375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 57.0
  learner_queue:
    size_count: 62
    size_mean: 10.42
    size_quantiles: [0.0, 0.0, 12.5, 16.0, 16.0]
    size_std: 6.1614608657363075
  num_agent_steps_sampled: 45100
  num_agent_steps_trained: 28500
  num_env_steps_sampled: 45100
  num_env_steps_trained: 28500
  num_samples_added_to_queue: 45000
  num_training_step_calls_since_last_synch_worker_weights: 422
  num_weight_broadcasts: 893
  timing_breakdown:
    learner_dequeue_time_ms: 1452.145
    learner_grad_time_ms: 178.44
    learner_load_time_ms: 5.366
    learner_load_wait_time_ms: 1.297
iterations_since_restore: 3
node_ip: 127.0.0.1
num_agent_steps_sampled: 45100
num_agent_steps_trained: 28500
num_env_steps_sampled: 45100
num_env_steps_sampled_this_iter: 15400
num_env_steps_sampled_throughput_per_sec: 1539.993537929948
num_env_steps_trained: 28500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.994335198331
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.64285714285715
  ram_util_percent: 77.6857142857143
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05222196105849478
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.019686518224267115
  mean_inference_ms: 0.990311692543211
  mean_raw_obs_processing_ms: 0.22356584712906322
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.016829172770182293
    StateBufferConnector_ms: 0.0028961896896362305
    ViewRequirementAgentConnector_ms: 0.09952267011006673
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.191666666666667
  episode_reward_min: 0.0
  episodes_this_iter: 120
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 2.0, 4.0, 1.0, 3.0, 1.0, 4.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0,
      3.0, 4.0, 1.0, 1.0, 0.0, 4.0, 0.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0, 2.0,
      1.0, 3.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 3.0, 4.0, 1.0, 2.0, 4.0, 1.0, 2.0, 4.0,
      2.0, 7.0, 1.0, 2.0, 6.0, 5.0, 0.0, 2.0, 5.0, 2.0, 1.0, 3.0, 6.0, 0.0, 1.0, 1.0,
      0.0, 3.0, 2.0, 1.0, 3.0, 0.0, 5.0, 2.0, 2.0, 2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 5.0,
      1.0, 3.0, 1.0, 2.0, 3.0, 7.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 4.0, 2.0, 0.0, 5.0,
      1.0, 3.0, 3.0, 1.0, 1.0, 2.0, 1.0, 2.0, 3.0, 6.0, 1.0, 3.0, 3.0, 2.0, 4.0, 2.0,
      2.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 3.0, 5.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05222196105849478
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.019686518224267115
    mean_inference_ms: 0.990311692543211
    mean_raw_obs_processing_ms: 0.22356584712906322
time_since_restore: 30.33161687850952
time_this_iter_s: 10.127434968948364
time_total_s: 30.33161687850952
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.04
timestamp: 1691999860
timesteps_total: 45100
training_iteration: 3
trial_id: default
train step: 4
agent_timesteps_total: 60500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.017257134119669598
  StateBufferConnector_ms: 0.002960761388142904
  ViewRequirementAgentConnector_ms: 0.10412871837615967
counters:
  num_agent_steps_sampled: 60500
  num_agent_steps_trained: 44000
  num_env_steps_sampled: 60500
  num_env_steps_trained: 44000
  num_samples_added_to_queue: 60500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 1197
custom_metrics: {}
date: 2023-08-14_16-57-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 2.5083333333333333
episode_reward_min: 0.0
episodes_this_iter: 120
episodes_total: 473
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.3
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1537697315216064
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 7.256550312042236
        total_loss: 11.509721755981445
        var_gnorm: 63.332279205322266
        vf_explained_var: 0.6297332048416138
        vf_loss: 20.04404067993164
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 88.0
  learner_queue:
    size_count: 91
    size_mean: 15.58
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0215674231297707
  num_agent_steps_sampled: 60500
  num_agent_steps_trained: 44000
  num_env_steps_sampled: 60500
  num_env_steps_trained: 44000
  num_samples_added_to_queue: 60500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 1197
  timing_breakdown:
    learner_dequeue_time_ms: 1037.248
    learner_grad_time_ms: 233.538
    learner_load_time_ms: 4.222
    learner_load_wait_time_ms: 1.439
iterations_since_restore: 4
node_ip: 127.0.0.1
num_agent_steps_sampled: 60500
num_agent_steps_trained: 44000
num_env_steps_sampled: 60500
num_env_steps_sampled_this_iter: 15400
num_env_steps_sampled_throughput_per_sec: 1539.777493682165
num_env_steps_trained: 44000
num_env_steps_trained_this_iter: 15500
num_env_steps_trained_throughput_per_sec: 1549.7760488359452
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 15500
perf:
  cpu_util_percent: 49.88666666666666
  ram_util_percent: 77.50666666666666
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.051929945363574585
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.019594241265452884
  mean_inference_ms: 0.9854414996240615
  mean_raw_obs_processing_ms: 0.2228965138685859
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.017257134119669598
    StateBufferConnector_ms: 0.002960761388142904
    ViewRequirementAgentConnector_ms: 0.10412871837615967
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 2.5083333333333333
  episode_reward_min: 0.0
  episodes_this_iter: 120
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 3.0, 1.0, 1.0, 2.0, 4.0, 1.0, 6.0, 4.0, 1.0, 2.0, 5.0, 1.0,
      2.0, 2.0, 4.0, 1.0, 1.0, 5.0, 4.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 7.0, 7.0, 2.0,
      5.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 1.0,
      3.0, 1.0, 1.0, 7.0, 2.0, 3.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 4.0, 2.0, 1.0, 5.0,
      1.0, 2.0, 3.0, 0.0, 7.0, 0.0, 1.0, 1.0, 2.0, 5.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0,
      1.0, 1.0, 10.0, 3.0, 4.0, 2.0, 4.0, 1.0, 4.0, 2.0, 4.0, 3.0, 3.0, 7.0, 3.0,
      0.0, 5.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 1.0, 2.0, 1.0, 1.0, 4.0, 2.0, 2.0, 5.0,
      0.0, 2.0, 0.0, 3.0, 1.0, 4.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.051929945363574585
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.019594241265452884
    mean_inference_ms: 0.9854414996240615
    mean_raw_obs_processing_ms: 0.2228965138685859
time_since_restore: 40.41494798660278
time_this_iter_s: 10.083331108093262
time_total_s: 40.41494798660278
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.428
  training_iteration_time_ms: 1.063
timestamp: 1691999870
timesteps_total: 60500
training_iteration: 4
trial_id: default
train step: 5
agent_timesteps_total: 75700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01735146306142086
  StateBufferConnector_ms: 0.002963402692009421
  ViewRequirementAgentConnector_ms: 0.10288362743473854
counters:
  num_agent_steps_sampled: 75700
  num_agent_steps_trained: 59000
  num_env_steps_sampled: 75700
  num_env_steps_trained: 59000
  num_samples_added_to_queue: 75500
  num_training_step_calls_since_last_synch_worker_weights: 76
  num_weight_broadcasts: 1498
custom_metrics: {}
date: 2023-08-14_16-58-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.857142857142857
episode_reward_min: 0.0
episodes_this_iter: 119
episodes_total: 592
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.3
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9227782487869263
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.491292953491211
        total_loss: -7.814797401428223
        var_gnorm: 63.34095764160156
        vf_explained_var: 0.7497644424438477
        vf_loss: 10.58077335357666
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 118.0
  learner_queue:
    size_count: 124
    size_mean: 15.54
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1173182178770737
  num_agent_steps_sampled: 75700
  num_agent_steps_trained: 59000
  num_env_steps_sampled: 75700
  num_env_steps_trained: 59000
  num_samples_added_to_queue: 75500
  num_training_step_calls_since_last_synch_worker_weights: 76
  num_weight_broadcasts: 1498
  timing_breakdown:
    learner_dequeue_time_ms: 806.749
    learner_grad_time_ms: 156.558
    learner_load_time_ms: 3.565
    learner_load_wait_time_ms: 1.244
iterations_since_restore: 5
node_ip: 127.0.0.1
num_agent_steps_sampled: 75700
num_agent_steps_trained: 59000
num_env_steps_sampled: 75700
num_env_steps_sampled_this_iter: 15200
num_env_steps_sampled_throughput_per_sec: 1519.9942741609736
num_env_steps_trained: 59000
num_env_steps_trained_this_iter: 15000
num_env_steps_trained_throughput_per_sec: 1499.9943495009609
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 15000
perf:
  cpu_util_percent: 50.414285714285704
  ram_util_percent: 77.65
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05186798175038614
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.019610921639061925
  mean_inference_ms: 0.984668786707877
  mean_raw_obs_processing_ms: 0.2228724567522212
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01735146306142086
    StateBufferConnector_ms: 0.002963402692009421
    ViewRequirementAgentConnector_ms: 0.10288362743473854
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.857142857142857
  episode_reward_min: 0.0
  episodes_this_iter: 119
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 0.0, 2.0, 4.0, 3.0, 1.0, 3.0, 5.0, 5.0, 3.0, 5.0, 2.0,
      4.0, 4.0, 2.0, 2.0, 6.0, 4.0, 4.0, 1.0, 1.0, 1.0, 1.0, 7.0, 2.0, 3.0, 4.0, 0.0,
      5.0, 2.0, 4.0, 0.0, 0.0, 1.0, 4.0, 5.0, 5.0, 3.0, 4.0, 0.0, 4.0, 1.0, 6.0, 3.0,
      3.0, 6.0, 2.0, 5.0, 4.0, 1.0, 7.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 1.0, 4.0, 1.0,
      1.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 5.0, 3.0, 2.0, 1.0, 4.0, 1.0, 3.0, 3.0, 3.0,
      3.0, 6.0, 4.0, 0.0, 4.0, 2.0, 4.0, 8.0, 3.0, 5.0, 7.0, 3.0, 1.0, 7.0, 5.0, 0.0,
      0.0, 2.0, 2.0, 4.0, 3.0, 2.0, 5.0, 5.0, 2.0, 2.0, 3.0, 1.0, 2.0, 4.0, 4.0, 0.0,
      3.0, 4.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 1.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05186798175038614
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.019610921639061925
    mean_inference_ms: 0.984668786707877
    mean_raw_obs_processing_ms: 0.2228724567522212
time_since_restore: 50.557295083999634
time_this_iter_s: 10.14234709739685
time_total_s: 50.557295083999634
timers:
  sample_time_ms: 0.013
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.04
timestamp: 1691999881
timesteps_total: 75700
training_iteration: 5
trial_id: default
train step: 6
agent_timesteps_total: 90900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.016930547811217226
  StateBufferConnector_ms: 0.002942651005114539
  ViewRequirementAgentConnector_ms: 0.10135598101858366
counters:
  num_agent_steps_sampled: 90900
  num_agent_steps_trained: 74000
  num_env_steps_sampled: 90900
  num_env_steps_trained: 74000
  num_samples_added_to_queue: 90500
  num_training_step_calls_since_last_synch_worker_weights: 539
  num_weight_broadcasts: 1796
custom_metrics: {}
date: 2023-08-14_16-58-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.9915254237288136
episode_reward_min: 0.0
episodes_this_iter: 118
episodes_total: 710
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.3
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9518706202507019
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 21.272836685180664
        total_loss: 29.67721176147461
        var_gnorm: 63.342254638671875
        vf_explained_var: 0.6842332482337952
        vf_loss: 26.327455520629883
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 148.0
  learner_queue:
    size_count: 153
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 90900
  num_agent_steps_trained: 74000
  num_env_steps_sampled: 90900
  num_env_steps_trained: 74000
  num_samples_added_to_queue: 90500
  num_training_step_calls_since_last_synch_worker_weights: 539
  num_weight_broadcasts: 1796
  timing_breakdown:
    learner_dequeue_time_ms: 694.424
    learner_grad_time_ms: 207.069
    learner_load_time_ms: 3.312
    learner_load_wait_time_ms: 1.424
iterations_since_restore: 6
node_ip: 127.0.0.1
num_agent_steps_sampled: 90900
num_agent_steps_trained: 74000
num_env_steps_sampled: 90900
num_env_steps_sampled_this_iter: 15200
num_env_steps_sampled_throughput_per_sec: 1519.9977169071158
num_env_steps_trained: 74000
num_env_steps_trained_this_iter: 15000
num_env_steps_trained_throughput_per_sec: 1499.9977469478117
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 15000
perf:
  cpu_util_percent: 50.09285714285715
  ram_util_percent: 78.10714285714286
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05184118687677581
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.01959549299052802
  mean_inference_ms: 0.9845881821850835
  mean_raw_obs_processing_ms: 0.22314194600944565
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.016930547811217226
    StateBufferConnector_ms: 0.002942651005114539
    ViewRequirementAgentConnector_ms: 0.10135598101858366
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.9915254237288136
  episode_reward_min: 0.0
  episodes_this_iter: 118
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 3.0, 3.0, 1.0, 0.0, 1.0, 4.0, 4.0, 2.0, 1.0, 0.0, 4.0,
      5.0, 2.0, 3.0, 2.0, 2.0, 1.0, 7.0, 3.0, 4.0, 5.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0,
      2.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 4.0, 2.0, 7.0, 4.0, 5.0, 2.0, 4.0, 1.0, 2.0,
      3.0, 5.0, 5.0, 3.0, 3.0, 2.0, 6.0, 1.0, 3.0, 1.0, 2.0, 4.0, 2.0, 5.0, 1.0, 3.0,
      1.0, 2.0, 0.0, 1.0, 3.0, 2.0, 2.0, 2.0, 4.0, 4.0, 4.0, 3.0, 3.0, 4.0, 3.0, 8.0,
      1.0, 5.0, 2.0, 5.0, 5.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 1.0, 0.0, 5.0, 2.0, 5.0,
      2.0, 3.0, 2.0, 5.0, 1.0, 7.0, 4.0, 1.0, 6.0, 5.0, 2.0, 4.0, 4.0, 1.0, 1.0, 9.0,
      5.0, 4.0, 2.0, 5.0, 4.0, 2.0, 0.0, 9.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05184118687677581
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.01959549299052802
    mean_inference_ms: 0.9845881821850835
    mean_raw_obs_processing_ms: 0.22314194600944565
time_since_restore: 60.67803740501404
time_this_iter_s: 10.120742321014404
time_total_s: 60.67803740501404
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691999891
timesteps_total: 90900
training_iteration: 6
trial_id: default
train step: 7
agent_timesteps_total: 104100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020893261982844427
  StateBufferConnector_ms: 0.003621211418738732
  ViewRequirementAgentConnector_ms: 0.12448452986203708
counters:
  num_agent_steps_sampled: 104100
  num_agent_steps_trained: 87500
  num_env_steps_sampled: 104100
  num_env_steps_trained: 87500
  num_samples_added_to_queue: 104000
  num_training_step_calls_since_last_synch_worker_weights: 400
  num_weight_broadcasts: 2057
custom_metrics: {}
date: 2023-08-14_16-58-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 3.3365384615384617
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 814
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0098717212677002
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -22.454418182373047
        total_loss: -15.8504638671875
        var_gnorm: 63.34288024902344
        vf_explained_var: 0.6810142993927002
        vf_loss: 23.306625366210938
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 175.0
  learner_queue:
    size_count: 180
    size_mean: 15.46
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1525623627379127
  num_agent_steps_sampled: 104100
  num_agent_steps_trained: 87500
  num_env_steps_sampled: 104100
  num_env_steps_trained: 87500
  num_samples_added_to_queue: 104000
  num_training_step_calls_since_last_synch_worker_weights: 400
  num_weight_broadcasts: 2057
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 207.164
    learner_load_time_ms: 1.649
    learner_load_wait_time_ms: 1.479
iterations_since_restore: 7
node_ip: 127.0.0.1
num_agent_steps_sampled: 104100
num_agent_steps_trained: 87500
num_env_steps_sampled: 104100
num_env_steps_sampled_this_iter: 13200
num_env_steps_sampled_throughput_per_sec: 1319.9948702057875
num_env_steps_trained: 87500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9947536195555
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 57.3
  ram_util_percent: 79.52666666666667
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05288638293299446
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.020082622244011326
  mean_inference_ms: 1.0032814909189365
  mean_raw_obs_processing_ms: 0.22720126938303006
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020893261982844427
    StateBufferConnector_ms: 0.003621211418738732
    ViewRequirementAgentConnector_ms: 0.12448452986203708
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 3.3365384615384617
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 4.0, 2.0, 3.0, 2.0, 3.0, 4.0, 3.0, 5.0, 6.0, 5.0, 1.0,
      5.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 2.0, 6.0, 1.0, 2.0, 1.0, 6.0, 2.0, 2.0, 1.0,
      3.0, 2.0, 1.0, 1.0, 4.0, 5.0, 2.0, 2.0, 7.0, 1.0, 2.0, 6.0, 3.0, 3.0, 4.0, 4.0,
      1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 4.0, 5.0, 5.0, 7.0, 3.0, 6.0, 5.0, 4.0, 4.0,
      1.0, 2.0, 2.0, 5.0, 3.0, 2.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 5.0, 2.0, 6.0, 6.0,
      6.0, 5.0, 6.0, 6.0, 0.0, 2.0, 4.0, 5.0, 2.0, 4.0, 2.0, 4.0, 7.0, 4.0, 4.0, 4.0,
      2.0, 3.0, 4.0, 3.0, 3.0, 0.0, 3.0, 4.0, 4.0, 5.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05288638293299446
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.020082622244011326
    mean_inference_ms: 1.0032814909189365
    mean_raw_obs_processing_ms: 0.22720126938303006
time_since_restore: 70.8109335899353
time_this_iter_s: 10.132896184921265
time_total_s: 70.8109335899353
timers:
  sample_time_ms: 0.013
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.04
timestamp: 1691999901
timesteps_total: 104100
training_iteration: 7
trial_id: default
train step: 8
agent_timesteps_total: 118600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018001230139481395
  StateBufferConnector_ms: 0.003119728021454393
  ViewRequirementAgentConnector_ms: 0.10610233273422509
counters:
  num_agent_steps_sampled: 118600
  num_agent_steps_trained: 102000
  num_env_steps_sampled: 118600
  num_env_steps_trained: 102000
  num_samples_added_to_queue: 118500
  num_training_step_calls_since_last_synch_worker_weights: 681
  num_weight_broadcasts: 2343
custom_metrics: {}
date: 2023-08-14_16-58-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.8157894736842106
episode_reward_min: 0.0
episodes_this_iter: 114
episodes_total: 928
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9105381369590759
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.481708526611328
        total_loss: 19.479421615600586
        var_gnorm: 63.35074234008789
        vf_explained_var: 0.5064361691474915
        vf_loss: 31.100807189941406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 204.0
  learner_queue:
    size_count: 209
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2649110640673518
  num_agent_steps_sampled: 118600
  num_agent_steps_trained: 102000
  num_env_steps_sampled: 118600
  num_env_steps_trained: 102000
  num_samples_added_to_queue: 118500
  num_training_step_calls_since_last_synch_worker_weights: 681
  num_weight_broadcasts: 2343
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 194.2
    learner_load_time_ms: 1.652
    learner_load_wait_time_ms: 1.405
iterations_since_restore: 8
node_ip: 127.0.0.1
num_agent_steps_sampled: 118600
num_agent_steps_trained: 102000
num_env_steps_sampled: 118600
num_env_steps_sampled_this_iter: 14500
num_env_steps_sampled_throughput_per_sec: 1449.9946415622367
num_env_steps_trained: 102000
num_env_steps_trained_this_iter: 14500
num_env_steps_trained_throughput_per_sec: 1449.9946415622367
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14500
perf:
  cpu_util_percent: 50.75714285714286
  ram_util_percent: 78.81428571428572
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05313592803949163
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.020161173479805273
  mean_inference_ms: 1.006213959124237
  mean_raw_obs_processing_ms: 0.22829646603737797
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018001230139481395
    StateBufferConnector_ms: 0.003119728021454393
    ViewRequirementAgentConnector_ms: 0.10610233273422509
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.8157894736842106
  episode_reward_min: 0.0
  episodes_this_iter: 114
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 3.0, 4.0, 3.0, 4.0, 2.0, 6.0, 4.0, 2.0, 2.0, 4.0, 2.0,
      5.0, 6.0, 5.0, 3.0, 2.0, 3.0, 1.0, 6.0, 4.0, 2.0, 7.0, 1.0, 4.0, 0.0, 1.0, 3.0,
      1.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0, 6.0, 3.0, 4.0, 6.0, 5.0, 2.0, 6.0, 2.0, 6.0,
      4.0, 4.0, 7.0, 2.0, 3.0, 7.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 4.0, 6.0, 3.0, 5.0,
      3.0, 5.0, 2.0, 5.0, 1.0, 3.0, 5.0, 2.0, 7.0, 3.0, 4.0, 2.0, 5.0, 5.0, 5.0, 2.0,
      6.0, 6.0, 1.0, 4.0, 3.0, 5.0, 2.0, 2.0, 3.0, 3.0, 2.0, 6.0, 4.0, 4.0, 2.0, 2.0,
      3.0, 9.0, 5.0, 1.0, 10.0, 7.0, 5.0, 7.0, 3.0, 1.0, 5.0, 4.0, 2.0, 7.0, 8.0,
      4.0, 1.0, 8.0, 4.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05313592803949163
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.020161173479805273
    mean_inference_ms: 1.006213959124237
    mean_raw_obs_processing_ms: 0.22829646603737797
time_since_restore: 80.92573547363281
time_this_iter_s: 10.11480188369751
time_total_s: 80.92573547363281
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.04
timestamp: 1691999911
timesteps_total: 118600
training_iteration: 8
trial_id: default
train step: 9
agent_timesteps_total: 131500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021880388259887695
  StateBufferConnector_ms: 0.0037717819213867188
  ViewRequirementAgentConnector_ms: 0.12505602836608887
counters:
  num_agent_steps_sampled: 131500
  num_agent_steps_trained: 115000
  num_env_steps_sampled: 131500
  num_env_steps_trained: 115000
  num_samples_added_to_queue: 131500
  num_training_step_calls_since_last_synch_worker_weights: 148
  num_weight_broadcasts: 2598
custom_metrics: {}
date: 2023-08-14_16-58-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.13
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 1028
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9679439663887024
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 38.39076232910156
        total_loss: 52.181434631347656
        var_gnorm: 63.35590362548828
        vf_explained_var: 0.60455721616745
        vf_loss: 37.26078796386719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 230.0
  learner_queue:
    size_count: 235
    size_mean: 15.48
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.0998181667894016
  num_agent_steps_sampled: 131500
  num_agent_steps_trained: 115000
  num_env_steps_sampled: 131500
  num_env_steps_trained: 115000
  num_samples_added_to_queue: 131500
  num_training_step_calls_since_last_synch_worker_weights: 148
  num_weight_broadcasts: 2598
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 198.856
    learner_load_time_ms: 1.519
    learner_load_wait_time_ms: 1.514
iterations_since_restore: 9
node_ip: 127.0.0.1
num_agent_steps_sampled: 131500
num_agent_steps_trained: 115000
num_env_steps_sampled: 131500
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9965553375673
num_env_steps_trained: 115000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9965286347579
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 57.471428571428575
  ram_util_percent: 80.10000000000001
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05402010731851619
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02062541806150282
  mean_inference_ms: 1.0211829920777133
  mean_raw_obs_processing_ms: 0.23163038063616714
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021880388259887695
    StateBufferConnector_ms: 0.0037717819213867188
    ViewRequirementAgentConnector_ms: 0.12505602836608887
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.13
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 7.0, 2.0, 2.0, 2.0, 4.0, 6.0, 6.0, 6.0, 2.0, 3.0, 6.0, 6.0,
      2.0, 1.0, 4.0, 5.0, 8.0, 7.0, 4.0, 0.0, 3.0, 4.0, 4.0, 4.0, 4.0, 1.0, 2.0, 3.0,
      4.0, 1.0, 3.0, 5.0, 2.0, 4.0, 5.0, 4.0, 3.0, 4.0, 5.0, 5.0, 3.0, 5.0, 6.0, 6.0,
      3.0, 1.0, 3.0, 5.0, 5.0, 6.0, 0.0, 1.0, 5.0, 5.0, 9.0, 5.0, 4.0, 5.0, 4.0, 5.0,
      3.0, 3.0, 3.0, 5.0, 3.0, 4.0, 6.0, 3.0, 1.0, 1.0, 6.0, 2.0, 5.0, 3.0, 3.0, 3.0,
      3.0, 5.0, 6.0, 7.0, 6.0, 5.0, 10.0, 5.0, 7.0, 8.0, 5.0, 3.0, 5.0, 5.0, 6.0,
      4.0, 7.0, 2.0, 4.0, 5.0, 4.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05402010731851619
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02062541806150282
    mean_inference_ms: 1.0211829920777133
    mean_raw_obs_processing_ms: 0.23163038063616714
time_since_restore: 91.0492262840271
time_this_iter_s: 10.123490810394287
time_total_s: 91.0492262840271
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.04
timestamp: 1691999921
timesteps_total: 131500
training_iteration: 9
trial_id: default
train step: 10
agent_timesteps_total: 144450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020742888497834157
  StateBufferConnector_ms: 0.0036263229823348545
  ViewRequirementAgentConnector_ms: 0.12396845487084719
counters:
  num_agent_steps_sampled: 144450
  num_agent_steps_trained: 127500
  num_env_steps_sampled: 144450
  num_env_steps_trained: 127500
  num_samples_added_to_queue: 144000
  num_training_step_calls_since_last_synch_worker_weights: 834
  num_weight_broadcasts: 2854
custom_metrics: {}
date: 2023-08-14_16-58-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.079207920792079
episode_reward_min: 0.0
episodes_this_iter: 101
episodes_total: 1129
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.0000327825546265
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 67.6820068359375
        total_loss: 105.72102355957031
        var_gnorm: 63.36344528198242
        vf_explained_var: 0.546086311340332
        vf_loss: 86.07835388183594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 255.0
  learner_queue:
    size_count: 260
    size_mean: 15.32
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2073110618229255
  num_agent_steps_sampled: 144450
  num_agent_steps_trained: 127500
  num_env_steps_sampled: 144450
  num_env_steps_trained: 127500
  num_samples_added_to_queue: 144000
  num_training_step_calls_since_last_synch_worker_weights: 834
  num_weight_broadcasts: 2854
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 241.215
    learner_load_time_ms: 9.377
    learner_load_wait_time_ms: 1.511
iterations_since_restore: 10
node_ip: 127.0.0.1
num_agent_steps_sampled: 144450
num_agent_steps_trained: 127500
num_env_steps_sampled: 144450
num_env_steps_sampled_this_iter: 12950
num_env_steps_sampled_throughput_per_sec: 1294.9954613606258
num_env_steps_trained: 127500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.995619073963
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 58.67857142857143
  ram_util_percent: 80.92857142857142
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.054697832448246435
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02096777711315085
  mean_inference_ms: 1.0330008897629814
  mean_raw_obs_processing_ms: 0.2344111398270129
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020742888497834157
    StateBufferConnector_ms: 0.0036263229823348545
    ViewRequirementAgentConnector_ms: 0.12396845487084719
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.079207920792079
  episode_reward_min: 0.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 5.0, 2.0, 1.0, 5.0, 6.0, 4.0, 4.0, 3.0, 5.0, 4.0, 5.0,
      3.0, 3.0, 10.0, 5.0, 3.0, 4.0, 2.0, 2.0, 6.0, 2.0, 6.0, 3.0, 3.0, 3.0, 5.0,
      5.0, 1.0, 4.0, 4.0, 4.0, 7.0, 4.0, 7.0, 5.0, 8.0, 2.0, 5.0, 4.0, 4.0, 5.0, 6.0,
      2.0, 5.0, 4.0, 2.0, 6.0, 5.0, 4.0, 6.0, 2.0, 5.0, 5.0, 2.0, 6.0, 5.0, 3.0, 5.0,
      4.0, 3.0, 7.0, 3.0, 1.0, 3.0, 2.0, 2.0, 8.0, 0.0, 5.0, 4.0, 2.0, 5.0, 5.0, 7.0,
      4.0, 3.0, 2.0, 9.0, 3.0, 7.0, 1.0, 6.0, 5.0, 3.0, 2.0, 2.0, 6.0, 3.0, 3.0, 6.0,
      1.0, 6.0, 2.0, 8.0, 5.0, 4.0, 4.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.054697832448246435
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02096777711315085
    mean_inference_ms: 1.0330008897629814
    mean_raw_obs_processing_ms: 0.2344111398270129
time_since_restore: 101.17612648010254
time_this_iter_s: 10.12690019607544
time_total_s: 101.17612648010254
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1691999931
timesteps_total: 144450
training_iteration: 10
trial_id: default
train step: 11
agent_timesteps_total: 157900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019788060869489397
  StateBufferConnector_ms: 0.004088992164248512
  ViewRequirementAgentConnector_ms: 0.12576738993326822
counters:
  num_agent_steps_sampled: 157900
  num_agent_steps_trained: 141000
  num_env_steps_sampled: 157900
  num_env_steps_trained: 141000
  num_samples_added_to_queue: 157500
  num_training_step_calls_since_last_synch_worker_weights: 998
  num_weight_broadcasts: 3120
custom_metrics: {}
date: 2023-08-14_16-59-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.8095238095238093
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 1234
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7977018356323242
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 29.48792266845703
        total_loss: 65.86607360839844
        var_gnorm: 63.38739776611328
        vf_explained_var: 0.7100423574447632
        vf_loss: 80.73332977294922
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 282.0
  learner_queue:
    size_count: 286
    size_mean: 15.44
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.0613199329137282
  num_agent_steps_sampled: 157900
  num_agent_steps_trained: 141000
  num_env_steps_sampled: 157900
  num_env_steps_trained: 141000
  num_samples_added_to_queue: 157500
  num_training_step_calls_since_last_synch_worker_weights: 998
  num_weight_broadcasts: 3120
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 262.362
    learner_load_time_ms: 9.39
    learner_load_wait_time_ms: 1.616
iterations_since_restore: 11
node_ip: 127.0.0.1
num_agent_steps_sampled: 157900
num_agent_steps_trained: 141000
num_env_steps_sampled: 157900
num_env_steps_sampled_this_iter: 13450
num_env_steps_sampled_throughput_per_sec: 1344.9955747273132
num_env_steps_trained: 141000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9955582764853
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 57.76666666666665
  ram_util_percent: 80.93333333333332
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0551012289788956
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.021149022605881262
  mean_inference_ms: 1.0393465562041049
  mean_raw_obs_processing_ms: 0.23617252777315503
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019788060869489397
    StateBufferConnector_ms: 0.004088992164248512
    ViewRequirementAgentConnector_ms: 0.12576738993326822
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.8095238095238093
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 4.0, 4.0, 3.0, 5.0, 6.0, 4.0, 3.0, 5.0, 4.0, 5.0, 4.0, 2.0,
      3.0, 6.0, 2.0, 2.0, 4.0, 6.0, 10.0, 5.0, 2.0, 6.0, 4.0, 5.0, 4.0, 6.0, 1.0,
      3.0, 4.0, 4.0, 1.0, 4.0, 7.0, 7.0, 2.0, 7.0, 6.0, 6.0, 2.0, 3.0, 2.0, 9.0, 2.0,
      6.0, 5.0, 3.0, 5.0, 3.0, 3.0, 0.0, 1.0, 2.0, 3.0, 4.0, 1.0, 3.0, 6.0, 6.0, 3.0,
      3.0, 4.0, 5.0, 4.0, 3.0, 7.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 6.0, 0.0,
      6.0, 4.0, 2.0, 5.0, 5.0, 7.0, 6.0, 1.0, 4.0, 5.0, 4.0, 4.0, 2.0, 2.0, 2.0, 6.0,
      7.0, 2.0, 1.0, 2.0, 4.0, 5.0, 0.0, 2.0, 6.0, 6.0, 1.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0551012289788956
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.021149022605881262
    mean_inference_ms: 1.0393465562041049
    mean_raw_obs_processing_ms: 0.23617252777315503
time_since_restore: 111.27584218978882
time_this_iter_s: 10.09971570968628
time_total_s: 111.27584218978882
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1691999941
timesteps_total: 157900
training_iteration: 11
trial_id: default
train step: 12
agent_timesteps_total: 171500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019007308460841667
  StateBufferConnector_ms: 0.0034174072408230506
  ViewRequirementAgentConnector_ms: 0.1145904309281679
counters:
  num_agent_steps_sampled: 171500
  num_agent_steps_trained: 155000
  num_env_steps_sampled: 171500
  num_env_steps_trained: 155000
  num_samples_added_to_queue: 171500
  num_training_step_calls_since_last_synch_worker_weights: 734
  num_weight_broadcasts: 3389
custom_metrics: {}
date: 2023-08-14_16-59-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.9813084112149535
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 1341
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7598150372505188
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.06497573852539
        total_loss: 2.037811279296875
        var_gnorm: 63.39801025390625
        vf_explained_var: 0.8832082152366638
        vf_loss: 27.80372428894043
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 310.0
  learner_queue:
    size_count: 314
    size_mean: 15.66
    size_quantiles: [13.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.8392854103342915
  num_agent_steps_sampled: 171500
  num_agent_steps_trained: 155000
  num_env_steps_sampled: 171500
  num_env_steps_trained: 155000
  num_samples_added_to_queue: 171500
  num_training_step_calls_since_last_synch_worker_weights: 734
  num_weight_broadcasts: 3389
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 229.889
    learner_load_time_ms: 13.994
    learner_load_wait_time_ms: 1.595
iterations_since_restore: 12
node_ip: 127.0.0.1
num_agent_steps_sampled: 171500
num_agent_steps_trained: 155000
num_env_steps_sampled: 171500
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9966278159786
num_env_steps_trained: 155000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9965286340957
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 53.707142857142856
  ram_util_percent: 80.55
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05538713842454092
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02126818840223638
  mean_inference_ms: 1.0437863842719204
  mean_raw_obs_processing_ms: 0.23729583059708215
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019007308460841667
    StateBufferConnector_ms: 0.0034174072408230506
    ViewRequirementAgentConnector_ms: 0.1145904309281679
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.9813084112149535
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 3.0, 4.0, 4.0, 3.0, 4.0, 4.0, 3.0, 2.0, 1.0, 4.0, 2.0,
      2.0, 7.0, 5.0, 1.0, 5.0, 0.0, 5.0, 7.0, 2.0, 6.0, 4.0, 4.0, 4.0, 4.0, 3.0, 7.0,
      1.0, 3.0, 4.0, 3.0, 6.0, 4.0, 5.0, 4.0, 2.0, 2.0, 6.0, 7.0, 4.0, 5.0, 5.0, 1.0,
      3.0, 7.0, 5.0, 5.0, 5.0, 6.0, 4.0, 3.0, 4.0, 6.0, 3.0, 4.0, 4.0, 2.0, 6.0, 6.0,
      6.0, 8.0, 3.0, 6.0, 2.0, 2.0, 6.0, 3.0, 6.0, 2.0, 3.0, 6.0, 2.0, 1.0, 3.0, 6.0,
      5.0, 1.0, 5.0, 2.0, 3.0, 5.0, 3.0, 3.0, 3.0, 5.0, 4.0, 2.0, 2.0, 7.0, 5.0, 3.0,
      4.0, 4.0, 4.0, 9.0, 3.0, 7.0, 5.0, 3.0, 5.0, 4.0, 9.0, 3.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05538713842454092
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02126818840223638
    mean_inference_ms: 1.0437863842719204
    mean_raw_obs_processing_ms: 0.23729583059708215
time_since_restore: 121.37737393379211
time_this_iter_s: 10.101531744003296
time_total_s: 121.37737393379211
timers:
  sample_time_ms: 0.02
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.051
timestamp: 1691999952
timesteps_total: 171500
training_iteration: 12
trial_id: default
train step: 13
agent_timesteps_total: 184650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019859800151750154
  StateBufferConnector_ms: 0.003495169620887906
  ViewRequirementAgentConnector_ms: 0.11998134500840131
counters:
  num_agent_steps_sampled: 184650
  num_agent_steps_trained: 168000
  num_env_steps_sampled: 184650
  num_env_steps_trained: 168000
  num_samples_added_to_queue: 184500
  num_training_step_calls_since_last_synch_worker_weights: 193
  num_weight_broadcasts: 3648
custom_metrics: {}
date: 2023-08-14_16-59-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.2254901960784315
episode_reward_min: 1.0
episodes_this_iter: 102
episodes_total: 1443
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7471076250076294
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.873788833618164
        total_loss: 35.730587005615234
        var_gnorm: 63.398597717285156
        vf_explained_var: 0.6641794443130493
        vf_loss: 71.1846694946289
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 336.0
  learner_queue:
    size_count: 342
    size_mean: 15.5
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1532562594670797
  num_agent_steps_sampled: 184650
  num_agent_steps_trained: 168000
  num_env_steps_sampled: 184650
  num_env_steps_trained: 168000
  num_samples_added_to_queue: 184500
  num_training_step_calls_since_last_synch_worker_weights: 193
  num_weight_broadcasts: 3648
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 178.599
    learner_load_time_ms: 14.01
    learner_load_wait_time_ms: 1.513
iterations_since_restore: 13
node_ip: 127.0.0.1
num_agent_steps_sampled: 184650
num_agent_steps_trained: 168000
num_env_steps_sampled: 184650
num_env_steps_sampled_this_iter: 13150
num_env_steps_sampled_throughput_per_sec: 1314.9941998975996
num_env_steps_trained: 168000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9942660584636
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.1
  ram_util_percent: 78.82142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05579632710738086
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02146039546255211
  mean_inference_ms: 1.05051267862161
  mean_raw_obs_processing_ms: 0.23875596201732327
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019859800151750154
    StateBufferConnector_ms: 0.003495169620887906
    ViewRequirementAgentConnector_ms: 0.11998134500840131
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.2254901960784315
  episode_reward_min: 1.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 1.0, 5.0, 1.0, 5.0, 3.0, 1.0, 6.0, 4.0, 3.0, 5.0, 6.0, 6.0,
      4.0, 2.0, 2.0, 4.0, 2.0, 6.0, 5.0, 4.0, 9.0, 4.0, 10.0, 6.0, 4.0, 3.0, 1.0,
      4.0, 2.0, 6.0, 4.0, 6.0, 7.0, 2.0, 6.0, 7.0, 2.0, 4.0, 2.0, 1.0, 4.0, 6.0, 6.0,
      3.0, 4.0, 5.0, 5.0, 7.0, 1.0, 4.0, 9.0, 4.0, 5.0, 1.0, 4.0, 3.0, 5.0, 4.0, 4.0,
      5.0, 4.0, 5.0, 5.0, 3.0, 6.0, 6.0, 1.0, 2.0, 5.0, 6.0, 4.0, 4.0, 6.0, 3.0, 3.0,
      3.0, 4.0, 4.0, 5.0, 6.0, 3.0, 6.0, 11.0, 2.0, 8.0, 3.0, 2.0, 6.0, 4.0, 1.0,
      5.0, 4.0, 4.0, 4.0, 1.0, 5.0, 2.0, 2.0, 5.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05579632710738086
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02146039546255211
    mean_inference_ms: 1.05051267862161
    mean_raw_obs_processing_ms: 0.23875596201732327
time_since_restore: 131.5183069705963
time_this_iter_s: 10.1409330368042
time_total_s: 131.5183069705963
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.044
timestamp: 1691999962
timesteps_total: 184650
training_iteration: 13
trial_id: default
train step: 14
agent_timesteps_total: 198250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019183923613350345
  StateBufferConnector_ms: 0.0033162674813900354
  ViewRequirementAgentConnector_ms: 0.11487187079663547
counters:
  num_agent_steps_sampled: 198250
  num_agent_steps_trained: 181500
  num_env_steps_sampled: 198250
  num_env_steps_trained: 181500
  num_samples_added_to_queue: 198000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 3916
custom_metrics: {}
date: 2023-08-14_16-59-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.367924528301887
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 1549
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6869863271713257
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -4.433530807495117
        total_loss: 33.8856086730957
        var_gnorm: 63.40983200073242
        vf_explained_var: 0.6669484376907349
        vf_loss: 83.50814819335938
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 363.0
  learner_queue:
    size_count: 369
    size_mean: 15.24
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4636939570825591
  num_agent_steps_sampled: 198250
  num_agent_steps_trained: 181500
  num_env_steps_sampled: 198250
  num_env_steps_trained: 181500
  num_samples_added_to_queue: 198000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 3916
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 183.798
    learner_load_time_ms: 14.023
    learner_load_wait_time_ms: 1.488
iterations_since_restore: 14
node_ip: 127.0.0.1
num_agent_steps_sampled: 198250
num_agent_steps_trained: 181500
num_env_steps_sampled: 198250
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.8578963956857
num_env_steps_trained: 181500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.8589412751292
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 53.226666666666674
  ram_util_percent: 78.63333333333334
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05603468822512637
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.021543039538338225
  mean_inference_ms: 1.054013530336622
  mean_raw_obs_processing_ms: 0.23967741708831183
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019183923613350345
    StateBufferConnector_ms: 0.0033162674813900354
    ViewRequirementAgentConnector_ms: 0.11487187079663547
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.367924528301887
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 5.0, 3.0, 0.0, 2.0, 8.0, 8.0, 5.0, 3.0, 6.0, 3.0, 5.0, 6.0,
      5.0, 6.0, 6.0, 9.0, 7.0, 5.0, 2.0, 5.0, 1.0, 5.0, 7.0, 3.0, 6.0, 5.0, 8.0, 5.0,
      5.0, 2.0, 2.0, 6.0, 3.0, 5.0, 6.0, 9.0, 1.0, 2.0, 3.0, 2.0, 8.0, 5.0, 3.0, 4.0,
      3.0, 2.0, 4.0, 4.0, 6.0, 5.0, 3.0, 8.0, 2.0, 5.0, 3.0, 4.0, 5.0, 1.0, 4.0, 5.0,
      5.0, 7.0, 5.0, 3.0, 3.0, 0.0, 6.0, 6.0, 3.0, 6.0, 4.0, 8.0, 3.0, 3.0, 4.0, 4.0,
      4.0, 3.0, 5.0, 7.0, 5.0, 4.0, 2.0, 6.0, 4.0, 4.0, 5.0, 6.0, 5.0, 5.0, 6.0, 5.0,
      6.0, 4.0, 2.0, 1.0, 5.0, 4.0, 0.0, 3.0, 1.0, 6.0, 7.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05603468822512637
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.021543039538338225
    mean_inference_ms: 1.054013530336622
    mean_raw_obs_processing_ms: 0.23967741708831183
time_since_restore: 141.6660759449005
time_this_iter_s: 10.1477689743042
time_total_s: 141.6660759449005
timers:
  sample_time_ms: 0.13
  synch_weights_time_ms: 0.466
  training_iteration_time_ms: 0.701
timestamp: 1691999972
timesteps_total: 198250
training_iteration: 14
trial_id: default
train step: 15
agent_timesteps_total: 212050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018898425278840243
  StateBufferConnector_ms: 0.003233662358036748
  ViewRequirementAgentConnector_ms: 0.11963270328663013
counters:
  num_agent_steps_sampled: 212050
  num_agent_steps_trained: 195500
  num_env_steps_sampled: 212050
  num_env_steps_trained: 195500
  num_samples_added_to_queue: 212000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 4189
custom_metrics: {}
date: 2023-08-14_16-59-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 4.046296296296297
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 1657
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7954192161560059
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.38143253326416016
        total_loss: 18.373050689697266
        var_gnorm: 63.40797805786133
        vf_explained_var: 0.783202588558197
        vf_loss: 43.93742752075195
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 391.0
  learner_queue:
    size_count: 395
    size_mean: 15.32
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4344336861632885
  num_agent_steps_sampled: 212050
  num_agent_steps_trained: 195500
  num_env_steps_sampled: 212050
  num_env_steps_trained: 195500
  num_samples_added_to_queue: 212000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 4189
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 229.597
    learner_load_time_ms: 14.022
    learner_load_wait_time_ms: 1.566
iterations_since_restore: 15
node_ip: 127.0.0.1
num_agent_steps_sampled: 212050
num_agent_steps_trained: 195500
num_env_steps_sampled: 212050
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.7773238967548
num_env_steps_trained: 195500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.7740967068528
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 50.63571428571429
  ram_util_percent: 78.16428571428571
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05613681308282305
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02159514689392017
  mean_inference_ms: 1.055581733769258
  mean_raw_obs_processing_ms: 0.2402146946916084
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018898425278840243
    StateBufferConnector_ms: 0.003233662358036748
    ViewRequirementAgentConnector_ms: 0.11963270328663013
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 4.046296296296297
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 5.0, 4.0, 3.0, 1.0, 5.0, 3.0, 0.0, 6.0, 1.0, 6.0, 7.0,
      5.0, 7.0, 3.0, 2.0, 3.0, 6.0, 6.0, 4.0, 6.0, 5.0, 7.0, 3.0, 4.0, 7.0, 7.0, 2.0,
      2.0, 5.0, 1.0, 6.0, 3.0, 7.0, 6.0, 5.0, 1.0, 6.0, 4.0, 2.0, 3.0, 5.0, 5.0, 4.0,
      3.0, 6.0, 3.0, 2.0, 3.0, 3.0, 5.0, 4.0, 3.0, 4.0, 2.0, 8.0, 2.0, 3.0, 6.0, 2.0,
      7.0, 2.0, 3.0, 5.0, 5.0, 6.0, 4.0, 2.0, 4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 3.0, 7.0,
      4.0, 6.0, 3.0, 1.0, 5.0, 5.0, 6.0, 7.0, 3.0, 3.0, 2.0, 4.0, 3.0, 3.0, 2.0, 2.0,
      7.0, 6.0, 7.0, 5.0, 3.0, 3.0, 6.0, 1.0, 5.0, 2.0, 5.0, 4.0, 4.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05613681308282305
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02159514689392017
    mean_inference_ms: 1.055581733769258
    mean_raw_obs_processing_ms: 0.2402146946916084
time_since_restore: 151.77144360542297
time_this_iter_s: 10.105367660522461
time_total_s: 151.77144360542297
timers:
  sample_time_ms: 0.041
  synch_weights_time_ms: 0.273
  training_iteration_time_ms: 0.381
timestamp: 1691999982
timesteps_total: 212050
training_iteration: 15
trial_id: default
train step: 16
agent_timesteps_total: 225700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019172002684395267
  StateBufferConnector_ms: 0.0033776715116680795
  ViewRequirementAgentConnector_ms: 0.11460038850892265
counters:
  num_agent_steps_sampled: 225700
  num_agent_steps_trained: 209000
  num_env_steps_sampled: 225700
  num_env_steps_trained: 209000
  num_samples_added_to_queue: 225500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 4460
custom_metrics: {}
date: 2023-08-14_16-59-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.7735849056603774
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 1763
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.9256114363670349
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.5401854515075684
        total_loss: 3.4360547065734863
        var_gnorm: 63.41447067260742
        vf_explained_var: 0.9109827280044556
        vf_loss: 17.208595275878906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 418.0
  learner_queue:
    size_count: 423
    size_mean: 15.56
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9830564581955605
  num_agent_steps_sampled: 225700
  num_agent_steps_trained: 209000
  num_env_steps_sampled: 225700
  num_env_steps_trained: 209000
  num_samples_added_to_queue: 225500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 4460
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 206.292
    learner_load_time_ms: 6.11
    learner_load_wait_time_ms: 1.56
iterations_since_restore: 16
node_ip: 127.0.0.1
num_agent_steps_sampled: 225700
num_agent_steps_trained: 209000
num_env_steps_sampled: 225700
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.9320512265454
num_env_steps_trained: 209000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9327979163636
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.1
  ram_util_percent: 77.99285714285715
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05625886506517682
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.021627461590442078
  mean_inference_ms: 1.0580823304017222
  mean_raw_obs_processing_ms: 0.24064915168914283
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019172002684395267
    StateBufferConnector_ms: 0.0033776715116680795
    ViewRequirementAgentConnector_ms: 0.11460038850892265
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.7735849056603774
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 2.0, 5.0, 3.0, 3.0, 6.0, 4.0, 2.0, 3.0, 2.0, 2.0, 5.0,
      4.0, 0.0, 2.0, 6.0, 1.0, 3.0, 4.0, 5.0, 1.0, 4.0, 5.0, 10.0, 3.0, 5.0, 2.0,
      5.0, 4.0, 6.0, 1.0, 4.0, 3.0, 3.0, 6.0, 4.0, 5.0, 4.0, 6.0, 4.0, 4.0, 5.0, 1.0,
      9.0, 5.0, 3.0, 4.0, 7.0, 3.0, 3.0, 4.0, 3.0, 4.0, 8.0, 2.0, 5.0, 5.0, 3.0, 0.0,
      3.0, 4.0, 8.0, 3.0, 0.0, 5.0, 2.0, 6.0, 4.0, 2.0, 5.0, 4.0, 2.0, 2.0, 2.0, 6.0,
      2.0, 5.0, 6.0, 1.0, 4.0, 2.0, 6.0, 5.0, 10.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0,
      4.0, 5.0, 3.0, 7.0, 5.0, 0.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05625886506517682
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.021627461590442078
    mean_inference_ms: 1.0580823304017222
    mean_raw_obs_processing_ms: 0.24064915168914283
time_since_restore: 161.8876826763153
time_this_iter_s: 10.116239070892334
time_total_s: 161.8876826763153
timers:
  sample_time_ms: 0.071
  synch_weights_time_ms: 0.218
  training_iteration_time_ms: 0.362
timestamp: 1691999992
timesteps_total: 225700
training_iteration: 16
trial_id: default
train step: 17
agent_timesteps_total: 238950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019871959319481484
  StateBufferConnector_ms: 0.0034662393423227165
  ViewRequirementAgentConnector_ms: 0.11872442869039682
counters:
  num_agent_steps_sampled: 238950
  num_agent_steps_trained: 222000
  num_env_steps_sampled: 238950
  num_env_steps_trained: 222000
  num_samples_added_to_queue: 238500
  num_training_step_calls_since_last_synch_worker_weights: 788
  num_weight_broadcasts: 4721
custom_metrics: {}
date: 2023-08-14_17-00-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.3365384615384617
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 1867
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8543707728385925
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 55.188926696777344
        total_loss: 80.5263900756836
        var_gnorm: 63.423484802246094
        vf_explained_var: 0.6964203119277954
        vf_loss: 59.2186279296875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 444.0
  learner_queue:
    size_count: 449
    size_mean: 15.46
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1525623627379127
  num_agent_steps_sampled: 238950
  num_agent_steps_trained: 222000
  num_env_steps_sampled: 238950
  num_env_steps_trained: 222000
  num_samples_added_to_queue: 238500
  num_training_step_calls_since_last_synch_worker_weights: 788
  num_weight_broadcasts: 4721
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 232.519
    learner_load_time_ms: 1.309
    learner_load_wait_time_ms: 1.553
iterations_since_restore: 17
node_ip: 127.0.0.1
num_agent_steps_sampled: 238950
num_agent_steps_trained: 222000
num_env_steps_sampled: 238950
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.9980413942678
num_env_steps_trained: 222000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.998078349093
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.466666666666676
  ram_util_percent: 78.47333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.056490758976129235
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.021719117836727943
  mean_inference_ms: 1.0617745449083185
  mean_raw_obs_processing_ms: 0.24162651596209395
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019871959319481484
    StateBufferConnector_ms: 0.0034662393423227165
    ViewRequirementAgentConnector_ms: 0.11872442869039682
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.3365384615384617
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 3.0, 6.0, 5.0, 2.0, 1.0, 7.0, 4.0, 6.0, 2.0, 5.0, 9.0, 4.0,
      4.0, 5.0, 3.0, 1.0, 5.0, 1.0, 5.0, 4.0, 1.0, 3.0, 5.0, 4.0, 4.0, 3.0, 2.0, 4.0,
      3.0, 5.0, 2.0, 2.0, 5.0, 3.0, 1.0, 1.0, 4.0, 7.0, 2.0, 1.0, 6.0, 5.0, 2.0, 6.0,
      2.0, 7.0, 4.0, 5.0, 5.0, 5.0, 1.0, 1.0, 4.0, 0.0, 4.0, 3.0, 4.0, 3.0, 9.0, 3.0,
      2.0, 2.0, 2.0, 6.0, 7.0, 3.0, 4.0, 5.0, 3.0, 3.0, 4.0, 2.0, 4.0, 2.0, 1.0, 1.0,
      4.0, 2.0, 2.0, 1.0, 0.0, 5.0, 5.0, 4.0, 3.0, 3.0, 1.0, 4.0, 1.0, 2.0, 3.0, 3.0,
      2.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.056490758976129235
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.021719117836727943
    mean_inference_ms: 1.0617745449083185
    mean_raw_obs_processing_ms: 0.24162651596209395
time_since_restore: 172.0159969329834
time_this_iter_s: 10.12831425666809
time_total_s: 172.0159969329834
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000002
timesteps_total: 238950
training_iteration: 17
trial_id: default
train step: 18
agent_timesteps_total: 252750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0189838586030183
  StateBufferConnector_ms: 0.0032564004262288413
  ViewRequirementAgentConnector_ms: 0.11318590905931261
counters:
  num_agent_steps_sampled: 252750
  num_agent_steps_trained: 236000
  num_env_steps_sampled: 252750
  num_env_steps_trained: 236000
  num_samples_added_to_queue: 252500
  num_training_step_calls_since_last_synch_worker_weights: 365
  num_weight_broadcasts: 4990
custom_metrics: {}
date: 2023-08-14_17-00-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.25
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 1975
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6034685373306274
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.5378413200378418
        total_loss: 5.218550682067871
        var_gnorm: 63.43639373779297
        vf_explained_var: 0.8839477896690369
        vf_loss: 13.39610481262207
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 472.0
  learner_queue:
    size_count: 477
    size_mean: 15.46
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1525623627379127
  num_agent_steps_sampled: 252750
  num_agent_steps_trained: 236000
  num_env_steps_sampled: 252750
  num_env_steps_trained: 236000
  num_samples_added_to_queue: 252500
  num_training_step_calls_since_last_synch_worker_weights: 365
  num_weight_broadcasts: 4990
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 204.915
    learner_load_time_ms: 1.311
    learner_load_wait_time_ms: 1.507
iterations_since_restore: 18
node_ip: 127.0.0.1
num_agent_steps_sampled: 252750
num_agent_steps_trained: 236000
num_env_steps_sampled: 252750
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9936499887835
num_env_steps_trained: 236000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9935579596356
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 52.28571428571428
  ram_util_percent: 78.78571428571429
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05656898489415117
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.021728635092809
  mean_inference_ms: 1.0628894450804862
  mean_raw_obs_processing_ms: 0.2420228357598381
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0189838586030183
    StateBufferConnector_ms: 0.0032564004262288413
    ViewRequirementAgentConnector_ms: 0.11318590905931261
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.25
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 4.0, 4.0, 4.0, 5.0, 6.0, 7.0, 5.0, 4.0, 5.0, 5.0, 4.0,
      3.0, 1.0, 4.0, 1.0, 7.0, 6.0, 3.0, 4.0, 7.0, 6.0, 3.0, 5.0, 8.0, 8.0, 4.0, 4.0,
      7.0, 5.0, 3.0, 3.0, 6.0, 3.0, 6.0, 4.0, 3.0, 5.0, 4.0, 5.0, 3.0, 7.0, 7.0, 5.0,
      4.0, 6.0, 1.0, 3.0, 5.0, 5.0, 5.0, 5.0, 7.0, 5.0, 2.0, 6.0, 3.0, 3.0, 4.0, 8.0,
      9.0, 3.0, 2.0, 10.0, 3.0, 3.0, 5.0, 5.0, 2.0, 0.0, 2.0, 3.0, 3.0, 4.0, 2.0,
      6.0, 1.0, 8.0, 6.0, 1.0, 4.0, 4.0, 1.0, 4.0, 0.0, 3.0, 2.0, 1.0, 5.0, 7.0, 3.0,
      5.0, 7.0, 7.0, 7.0, 3.0, 5.0, 4.0, 4.0, 4.0, 4.0, 1.0, 4.0, 0.0, 5.0, 1.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05656898489415117
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.021728635092809
    mean_inference_ms: 1.0628894450804862
    mean_raw_obs_processing_ms: 0.2420228357598381
time_since_restore: 182.1466360092163
time_this_iter_s: 10.13063907623291
time_total_s: 182.1466360092163
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000012
timesteps_total: 252750
training_iteration: 18
trial_id: default
train step: 19
agent_timesteps_total: 264500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023218870162963867
  StateBufferConnector_ms: 0.004025459289550781
  ViewRequirementAgentConnector_ms: 0.13530850410461426
counters:
  num_agent_steps_sampled: 264500
  num_agent_steps_trained: 248000
  num_env_steps_sampled: 264500
  num_env_steps_trained: 248000
  num_samples_added_to_queue: 264500
  num_training_step_calls_since_last_synch_worker_weights: 68
  num_weight_broadcasts: 5222
custom_metrics: {}
date: 2023-08-14_17-00-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.31
episode_reward_min: 0.0
episodes_this_iter: 92
episodes_total: 2067
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.826050341129303
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -27.209318161010742
        total_loss: -2.906243324279785
        var_gnorm: 63.44522476196289
        vf_explained_var: 0.7621563673019409
        vf_loss: 56.86665344238281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 496.0
  learner_queue:
    size_count: 501
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2631706139710503
  num_agent_steps_sampled: 264500
  num_agent_steps_trained: 248000
  num_env_steps_sampled: 264500
  num_env_steps_trained: 248000
  num_samples_added_to_queue: 264500
  num_training_step_calls_since_last_synch_worker_weights: 68
  num_weight_broadcasts: 5222
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 227.255
    learner_load_time_ms: 1.584
    learner_load_wait_time_ms: 1.635
iterations_since_restore: 19
node_ip: 127.0.0.1
num_agent_steps_sampled: 264500
num_agent_steps_trained: 248000
num_env_steps_sampled: 264500
num_env_steps_sampled_this_iter: 11750
num_env_steps_sampled_throughput_per_sec: 1174.9957698735893
num_env_steps_trained: 248000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9956798708997
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 62.29285714285715
  ram_util_percent: 78.42857142857143
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.057035935777588594
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.021936924014201383
  mean_inference_ms: 1.0711317238169489
  mean_raw_obs_processing_ms: 0.24391028641631954
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023218870162963867
    StateBufferConnector_ms: 0.004025459289550781
    ViewRequirementAgentConnector_ms: 0.13530850410461426
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.31
  episode_reward_min: 0.0
  episodes_this_iter: 92
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 4.0, 1.0, 4.0, 0.0, 5.0, 1.0, 6.0, 5.0, 4.0, 3.0, 4.0, 4.0,
      3.0, 5.0, 1.0, 2.0, 8.0, 3.0, 4.0, 6.0, 2.0, 4.0, 4.0, 5.0, 2.0, 6.0, 4.0, 7.0,
      4.0, 1.0, 6.0, 5.0, 6.0, 3.0, 5.0, 3.0, 3.0, 4.0, 3.0, 3.0, 2.0, 6.0, 4.0, 5.0,
      5.0, 3.0, 2.0, 5.0, 4.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0, 7.0, 7.0, 5.0, 2.0, 4.0,
      8.0, 5.0, 2.0, 6.0, 3.0, 1.0, 5.0, 2.0, 5.0, 5.0, 11.0, 5.0, 5.0, 8.0, 3.0,
      5.0, 5.0, 11.0, 6.0, 6.0, 6.0, 2.0, 5.0, 7.0, 4.0, 2.0, 2.0, 6.0, 3.0, 3.0,
      5.0, 6.0, 7.0, 3.0, 7.0, 6.0, 3.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.057035935777588594
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.021936924014201383
    mean_inference_ms: 1.0711317238169489
    mean_raw_obs_processing_ms: 0.24391028641631954
time_since_restore: 192.2756290435791
time_this_iter_s: 10.128993034362793
time_total_s: 192.2756290435791
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1692000022
timesteps_total: 264500
training_iteration: 19
trial_id: default
train step: 20
agent_timesteps_total: 278200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01931391029714424
  StateBufferConnector_ms: 0.003369946346104702
  ViewRequirementAgentConnector_ms: 0.11485180008077175
counters:
  num_agent_steps_sampled: 278200
  num_agent_steps_trained: 261500
  num_env_steps_sampled: 278200
  num_env_steps_trained: 261500
  num_samples_added_to_queue: 278000
  num_training_step_calls_since_last_synch_worker_weights: 532
  num_weight_broadcasts: 5493
custom_metrics: {}
date: 2023-08-14_17-00-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.196261682242991
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 2174
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8337461948394775
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -46.169002532958984
        total_loss: -34.64921569824219
        var_gnorm: 63.45458221435547
        vf_explained_var: 0.8507051467895508
        vf_loss: 31.377033233642578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 523.0
  learner_queue:
    size_count: 528
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3152946437965904
  num_agent_steps_sampled: 278200
  num_agent_steps_trained: 261500
  num_env_steps_sampled: 278200
  num_env_steps_trained: 261500
  num_samples_added_to_queue: 278000
  num_training_step_calls_since_last_synch_worker_weights: 532
  num_weight_broadcasts: 5493
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 213.869
    learner_load_time_ms: 1.594
    learner_load_wait_time_ms: 1.424
iterations_since_restore: 20
node_ip: 127.0.0.1
num_agent_steps_sampled: 278200
num_agent_steps_trained: 261500
num_env_steps_sampled: 278200
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9943819276407
num_env_steps_trained: 261500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9944639432956
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.71333333333334
  ram_util_percent: 78.85333333333332
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05715738414460921
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.021983484168059078
  mean_inference_ms: 1.0729531343366883
  mean_raw_obs_processing_ms: 0.24437428339749612
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01931391029714424
    StateBufferConnector_ms: 0.003369946346104702
    ViewRequirementAgentConnector_ms: 0.11485180008077175
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.196261682242991
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 5.0, 2.0, 0.0, 5.0, 1.0, 4.0, 10.0, 7.0, 2.0, 4.0,
      5.0, 7.0, 1.0, 2.0, 4.0, 3.0, 3.0, 2.0, 6.0, 7.0, 3.0, 4.0, 6.0, 0.0, 2.0, 3.0,
      5.0, 7.0, 3.0, 2.0, 4.0, 5.0, 3.0, 5.0, 3.0, 5.0, 4.0, 4.0, 1.0, 2.0, 6.0, 6.0,
      4.0, 5.0, 5.0, 2.0, 6.0, 3.0, 2.0, 6.0, 3.0, 4.0, 7.0, 5.0, 3.0, 4.0, 4.0, 2.0,
      3.0, 7.0, 2.0, 5.0, 6.0, 3.0, 5.0, 5.0, 3.0, 6.0, 10.0, 7.0, 6.0, 7.0, 0.0,
      6.0, 5.0, 6.0, 3.0, 3.0, 4.0, 0.0, 5.0, 4.0, 5.0, 5.0, 2.0, 4.0, 4.0, 2.0, 6.0,
      3.0, 6.0, 4.0, 4.0, 6.0, 4.0, 3.0, 5.0, 3.0, 9.0, 7.0, 4.0, 4.0, 3.0, 5.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05715738414460921
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.021983484168059078
    mean_inference_ms: 1.0729531343366883
    mean_raw_obs_processing_ms: 0.24437428339749612
time_since_restore: 202.39727020263672
time_this_iter_s: 10.121641159057617
time_total_s: 202.39727020263672
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000033
timesteps_total: 278200
training_iteration: 20
trial_id: default
train step: 21
agent_timesteps_total: 291350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019167451297535616
  StateBufferConnector_ms: 0.003363338171267042
  ViewRequirementAgentConnector_ms: 0.11696675244499655
counters:
  num_agent_steps_sampled: 291350
  num_agent_steps_trained: 274500
  num_env_steps_sampled: 291350
  num_env_steps_trained: 274500
  num_samples_added_to_queue: 291000
  num_training_step_calls_since_last_synch_worker_weights: 141
  num_weight_broadcasts: 5753
custom_metrics: {}
date: 2023-08-14_17-00-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.980392156862745
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 2276
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8750095367431641
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.065530776977539
        total_loss: 20.08202362060547
        var_gnorm: 63.474090576171875
        vf_explained_var: 0.7432267665863037
        vf_loss: 63.045204162597656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 549.0
  learner_queue:
    size_count: 555
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 291350
  num_agent_steps_trained: 274500
  num_env_steps_sampled: 291350
  num_env_steps_trained: 274500
  num_samples_added_to_queue: 291000
  num_training_step_calls_since_last_synch_worker_weights: 141
  num_weight_broadcasts: 5753
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 187.968
    learner_load_time_ms: 1.623
    learner_load_wait_time_ms: 1.578
iterations_since_restore: 21
node_ip: 127.0.0.1
num_agent_steps_sampled: 291350
num_agent_steps_trained: 274500
num_env_steps_sampled: 291350
num_env_steps_sampled_this_iter: 13150
num_env_steps_sampled_throughput_per_sec: 1314.996300469316
num_env_steps_trained: 274500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.996342669286
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 56.07857142857142
  ram_util_percent: 76.45
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05734155198599663
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022054396631017412
  mean_inference_ms: 1.0758442017322416
  mean_raw_obs_processing_ms: 0.2451781162340268
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019167451297535616
    StateBufferConnector_ms: 0.003363338171267042
    ViewRequirementAgentConnector_ms: 0.11696675244499655
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.980392156862745
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 6.0, 0.0, 3.0, 6.0, 4.0, 5.0, 6.0, 2.0, 6.0, 2.0, 4.0, 3.0,
      4.0, 4.0, 3.0, 3.0, 5.0, 7.0, 5.0, 6.0, 8.0, 3.0, 0.0, 3.0, 3.0, 6.0, 4.0, 8.0,
      3.0, 6.0, 3.0, 3.0, 6.0, 1.0, 3.0, 6.0, 5.0, 3.0, 2.0, 5.0, 3.0, 3.0, 9.0, 8.0,
      4.0, 3.0, 4.0, 6.0, 2.0, 2.0, 5.0, 3.0, 7.0, 0.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0,
      4.0, 3.0, 4.0, 1.0, 6.0, 3.0, 6.0, 3.0, 2.0, 5.0, 2.0, 4.0, 2.0, 2.0, 4.0, 1.0,
      3.0, 6.0, 3.0, 9.0, 0.0, 5.0, 4.0, 3.0, 4.0, 4.0, 2.0, 2.0, 5.0, 4.0, 5.0, 5.0,
      6.0, 4.0, 6.0, 5.0, 6.0, 6.0, 2.0, 4.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05734155198599663
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022054396631017412
    mean_inference_ms: 1.0758442017322416
    mean_raw_obs_processing_ms: 0.2451781162340268
time_since_restore: 212.5524513721466
time_this_iter_s: 10.155181169509888
time_total_s: 212.5524513721466
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1692000043
timesteps_total: 291350
training_iteration: 21
trial_id: default
train step: 22
agent_timesteps_total: 305050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019226692340992117
  StateBufferConnector_ms: 0.0033705322830765334
  ViewRequirementAgentConnector_ms: 0.11447999212476942
counters:
  num_agent_steps_sampled: 305050
  num_agent_steps_trained: 288500
  num_env_steps_sampled: 305050
  num_env_steps_trained: 288500
  num_samples_added_to_queue: 305000
  num_training_step_calls_since_last_synch_worker_weights: 497
  num_weight_broadcasts: 6021
custom_metrics: {}
date: 2023-08-14_17-00-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.712962962962963
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 2384
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7092494964599609
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -22.454917907714844
        total_loss: -19.325115203857422
        var_gnorm: 63.487911224365234
        vf_explained_var: 0.9413667321205139
        vf_loss: 13.35210132598877
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 577.0
  learner_queue:
    size_count: 581
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3654303350958628
  num_agent_steps_sampled: 305050
  num_agent_steps_trained: 288500
  num_env_steps_sampled: 305050
  num_env_steps_trained: 288500
  num_samples_added_to_queue: 305000
  num_training_step_calls_since_last_synch_worker_weights: 497
  num_weight_broadcasts: 6021
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 229.702
    learner_load_time_ms: 1.626
    learner_load_wait_time_ms: 1.565
iterations_since_restore: 22
node_ip: 127.0.0.1
num_agent_steps_sampled: 305050
num_agent_steps_trained: 288500
num_env_steps_sampled: 305050
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9950678526104
num_env_steps_trained: 288500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.994959849383
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 51.307142857142864
  ram_util_percent: 76.29999999999998
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05739393652857087
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022054919087592207
  mean_inference_ms: 1.0763826440360869
  mean_raw_obs_processing_ms: 0.24544172065778055
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019226692340992117
    StateBufferConnector_ms: 0.0033705322830765334
    ViewRequirementAgentConnector_ms: 0.11447999212476942
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.712962962962963
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 8.0, 4.0, 5.0, 6.0, 5.0, 5.0, 3.0, 4.0, 8.0, 6.0, 2.0, 6.0,
      6.0, 4.0, 5.0, 5.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 8.0, 8.0, 2.0, 3.0, 3.0, 7.0,
      5.0, 8.0, 3.0, 5.0, 2.0, 8.0, 4.0, 2.0, 8.0, 7.0, 6.0, 3.0, 4.0, 4.0, 3.0, 7.0,
      3.0, 2.0, 8.0, 4.0, 2.0, 4.0, 6.0, 6.0, 3.0, 6.0, 8.0, 6.0, 2.0, 5.0, 6.0, 7.0,
      4.0, 3.0, 5.0, 3.0, 4.0, 6.0, 4.0, 2.0, 4.0, 3.0, 6.0, 6.0, 6.0, 4.0, 8.0, 6.0,
      2.0, 4.0, 3.0, 6.0, 5.0, 5.0, 6.0, 7.0, 2.0, 7.0, 5.0, 2.0, 4.0, 5.0, 6.0, 3.0,
      2.0, 3.0, 2.0, 7.0, 5.0, 3.0, 4.0, 3.0, 2.0, 6.0, 6.0, 2.0, 10.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05739393652857087
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022054919087592207
    mean_inference_ms: 1.0763826440360869
    mean_raw_obs_processing_ms: 0.24544172065778055
time_since_restore: 222.6600022315979
time_this_iter_s: 10.107550859451294
time_total_s: 222.6600022315979
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000053
timesteps_total: 305050
training_iteration: 22
trial_id: default
train step: 23
agent_timesteps_total: 318750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019627247216566553
  StateBufferConnector_ms: 0.003306595784313274
  ViewRequirementAgentConnector_ms: 0.11570701059305442
counters:
  num_agent_steps_sampled: 318750
  num_agent_steps_trained: 302000
  num_env_steps_sampled: 318750
  num_env_steps_trained: 302000
  num_samples_added_to_queue: 318500
  num_training_step_calls_since_last_synch_worker_weights: 334
  num_weight_broadcasts: 6290
custom_metrics: {}
date: 2023-08-14_17-01-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.830188679245283
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 2490
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6971126198768616
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -35.275875091552734
        total_loss: -5.703275680541992
        var_gnorm: 63.50394821166992
        vf_explained_var: 0.7167809009552002
        vf_loss: 66.11632537841797
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 604.0
  learner_queue:
    size_count: 609
    size_mean: 15.56
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0423051376636308
  num_agent_steps_sampled: 318750
  num_agent_steps_trained: 302000
  num_env_steps_sampled: 318750
  num_env_steps_trained: 302000
  num_samples_added_to_queue: 318500
  num_training_step_calls_since_last_synch_worker_weights: 334
  num_weight_broadcasts: 6290
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 206.856
    learner_load_time_ms: 1.63
    learner_load_wait_time_ms: 1.611
iterations_since_restore: 23
node_ip: 127.0.0.1
num_agent_steps_sampled: 318750
num_agent_steps_trained: 302000
num_env_steps_sampled: 318750
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9964070414358
num_env_steps_trained: 302000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9964594933856
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 54.53333333333333
  ram_util_percent: 74.47333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05744996265710841
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022055505997124553
  mean_inference_ms: 1.0770548064486978
  mean_raw_obs_processing_ms: 0.24564227589101403
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019627247216566553
    StateBufferConnector_ms: 0.003306595784313274
    ViewRequirementAgentConnector_ms: 0.11570701059305442
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.830188679245283
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 5.0, 7.0, 2.0, 5.0, 3.0, 7.0, 6.0, 1.0, 4.0, 5.0, 5.0,
      6.0, 7.0, 4.0, 8.0, 2.0, 4.0, 6.0, 5.0, 0.0, 1.0, 2.0, 3.0, 3.0, 6.0, 4.0, 8.0,
      6.0, 6.0, 3.0, 7.0, 3.0, 8.0, 7.0, 7.0, 6.0, 3.0, 4.0, 6.0, 4.0, 8.0, 6.0, 5.0,
      3.0, 4.0, 9.0, 1.0, 2.0, 4.0, 7.0, 4.0, 6.0, 8.0, 6.0, 5.0, 1.0, 9.0, 1.0, 5.0,
      5.0, 3.0, 2.0, 7.0, 4.0, 3.0, 4.0, 3.0, 6.0, 5.0, 3.0, 6.0, 4.0, 3.0, 12.0,
      4.0, 6.0, 7.0, 5.0, 4.0, 6.0, 5.0, 3.0, 3.0, 5.0, 4.0, 1.0, 4.0, 8.0, 4.0, 6.0,
      4.0, 3.0, 7.0, 9.0, 6.0, 8.0, 5.0, 4.0, 8.0, 5.0, 3.0, 6.0, 5.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05744996265710841
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022055505997124553
    mean_inference_ms: 1.0770548064486978
    mean_raw_obs_processing_ms: 0.24564227589101403
time_since_restore: 232.79017329216003
time_this_iter_s: 10.130171060562134
time_total_s: 232.79017329216003
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000063
timesteps_total: 318750
training_iteration: 23
trial_id: default
train step: 24
agent_timesteps_total: 332650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01899177377874201
  StateBufferConnector_ms: 0.0033109838312322445
  ViewRequirementAgentConnector_ms: 0.1143492351878773
counters:
  num_agent_steps_sampled: 332650
  num_agent_steps_trained: 316000
  num_env_steps_sampled: 332650
  num_env_steps_trained: 316000
  num_samples_added_to_queue: 332500
  num_training_step_calls_since_last_synch_worker_weights: 304
  num_weight_broadcasts: 6563
custom_metrics: {}
date: 2023-08-14_17-01-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.963636363636364
episode_reward_min: 1.0
episodes_this_iter: 110
episodes_total: 2600
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7154064774513245
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 17.23775291442871
        total_loss: 41.38344192504883
        var_gnorm: 63.51832962036133
        vf_explained_var: 0.8105006217956543
        vf_loss: 55.4454460144043
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 632.0
  learner_queue:
    size_count: 638
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3919770113044252
  num_agent_steps_sampled: 332650
  num_agent_steps_trained: 316000
  num_env_steps_sampled: 332650
  num_env_steps_trained: 316000
  num_samples_added_to_queue: 332500
  num_training_step_calls_since_last_synch_worker_weights: 304
  num_weight_broadcasts: 6563
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 171.75
    learner_load_time_ms: 1.625
    learner_load_wait_time_ms: 1.818
iterations_since_restore: 24
node_ip: 127.0.0.1
num_agent_steps_sampled: 332650
num_agent_steps_trained: 316000
num_env_steps_sampled: 332650
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.998177292353
num_env_steps_trained: 316000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9981641793481
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 50.68571428571429
  ram_util_percent: 74.2642857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05746341732199242
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02204811512126426
  mean_inference_ms: 1.0770315666029724
  mean_raw_obs_processing_ms: 0.24571018232456807
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01899177377874201
    StateBufferConnector_ms: 0.0033109838312322445
    ViewRequirementAgentConnector_ms: 0.1143492351878773
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.963636363636364
  episode_reward_min: 1.0
  episodes_this_iter: 110
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128]
    episode_reward: [11.0, 3.0, 5.0, 6.0, 3.0, 4.0, 5.0, 4.0, 5.0, 5.0, 3.0, 3.0,
      5.0, 7.0, 4.0, 3.0, 6.0, 5.0, 5.0, 4.0, 1.0, 4.0, 2.0, 7.0, 6.0, 11.0, 5.0,
      6.0, 3.0, 7.0, 9.0, 2.0, 3.0, 5.0, 6.0, 1.0, 8.0, 9.0, 1.0, 6.0, 3.0, 4.0, 5.0,
      3.0, 7.0, 2.0, 8.0, 7.0, 4.0, 3.0, 7.0, 4.0, 1.0, 8.0, 7.0, 6.0, 7.0, 3.0, 7.0,
      6.0, 10.0, 5.0, 2.0, 5.0, 4.0, 4.0, 6.0, 8.0, 5.0, 7.0, 2.0, 4.0, 7.0, 4.0,
      3.0, 3.0, 5.0, 7.0, 9.0, 2.0, 7.0, 5.0, 4.0, 3.0, 2.0, 4.0, 7.0, 4.0, 7.0, 6.0,
      11.0, 6.0, 4.0, 1.0, 2.0, 8.0, 6.0, 7.0, 6.0, 7.0, 4.0, 4.0, 4.0, 5.0, 2.0,
      1.0, 3.0, 3.0, 6.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05746341732199242
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02204811512126426
    mean_inference_ms: 1.0770315666029724
    mean_raw_obs_processing_ms: 0.24571018232456807
time_since_restore: 242.93352222442627
time_this_iter_s: 10.143348932266235
time_total_s: 242.93352222442627
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1692000073
timesteps_total: 332650
training_iteration: 24
trial_id: default
train step: 25
agent_timesteps_total: 346500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01892005955731427
  StateBufferConnector_ms: 0.0032012109403257018
  ViewRequirementAgentConnector_ms: 0.11233775703995316
counters:
  num_agent_steps_sampled: 346500
  num_agent_steps_trained: 330000
  num_env_steps_sampled: 346500
  num_env_steps_trained: 330000
  num_samples_added_to_queue: 346500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 6836
custom_metrics: {}
date: 2023-08-14_17-01-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.722222222222222
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 2708
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7685352563858032
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.065089225769043
        total_loss: 19.369157791137695
        var_gnorm: 63.535675048828125
        vf_explained_var: 0.791500449180603
        vf_loss: 48.55384826660156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 660.0
  learner_queue:
    size_count: 662
    size_mean: 15.52
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1872657663724664
  num_agent_steps_sampled: 346500
  num_agent_steps_trained: 330000
  num_env_steps_sampled: 346500
  num_env_steps_trained: 330000
  num_samples_added_to_queue: 346500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 6836
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 293.599
    learner_load_time_ms: 9.562
    learner_load_wait_time_ms: 1.649
iterations_since_restore: 25
node_ip: 127.0.0.1
num_agent_steps_sampled: 346500
num_agent_steps_trained: 330000
num_env_steps_sampled: 346500
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.572015376583
num_env_steps_trained: 330000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.5673801640553
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 50.207142857142856
  ram_util_percent: 74.54285714285713
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.057480275950605335
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02203798555142216
  mean_inference_ms: 1.0769872140503027
  mean_raw_obs_processing_ms: 0.2458054289937578
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01892005955731427
    StateBufferConnector_ms: 0.0032012109403257018
    ViewRequirementAgentConnector_ms: 0.11233775703995316
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.722222222222222
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 3.0, 4.0, 3.0, 2.0, 6.0, 3.0, 4.0, 9.0, 10.0, 10.0,
      8.0, 5.0, 2.0, 6.0, 8.0, 5.0, 4.0, 5.0, 6.0, 10.0, 4.0, 6.0, 7.0, 6.0, 3.0,
      1.0, 8.0, 5.0, 4.0, 4.0, 4.0, 8.0, 7.0, 5.0, 7.0, 1.0, 3.0, 5.0, 6.0, 2.0, 3.0,
      3.0, 4.0, 10.0, 6.0, 3.0, 6.0, 3.0, 5.0, 2.0, 4.0, 3.0, 1.0, 6.0, 6.0, 7.0,
      7.0, 3.0, 3.0, 5.0, 5.0, 9.0, 8.0, 6.0, 5.0, 3.0, 5.0, 2.0, 2.0, 4.0, 4.0, 3.0,
      5.0, 6.0, 6.0, 4.0, 5.0, 4.0, 6.0, 3.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 2.0, 5.0,
      6.0, 5.0, 5.0, 4.0, 4.0, 4.0, 3.0, 7.0, 4.0, 4.0, 3.0, 8.0, 3.0, 3.0, 3.0, 3.0,
      4.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.057480275950605335
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02203798555142216
    mean_inference_ms: 1.0769872140503027
    mean_raw_obs_processing_ms: 0.2458054289937578
time_since_restore: 253.0026421546936
time_this_iter_s: 10.069119930267334
time_total_s: 253.0026421546936
timers:
  sample_time_ms: 0.061
  synch_weights_time_ms: 0.462
  training_iteration_time_ms: 2.153
timestamp: 1692000083
timesteps_total: 346500
training_iteration: 25
trial_id: default
train step: 26
agent_timesteps_total: 360100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019168853759765625
  StateBufferConnector_ms: 0.0033308874885990933
  ViewRequirementAgentConnector_ms: 0.11449714876570792
counters:
  num_agent_steps_sampled: 360100
  num_agent_steps_trained: 343500
  num_env_steps_sampled: 360100
  num_env_steps_trained: 343500
  num_samples_added_to_queue: 360000
  num_training_step_calls_since_last_synch_worker_weights: 599
  num_weight_broadcasts: 7106
custom_metrics: {}
date: 2023-08-14_17-01-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 5.367924528301887
episode_reward_min: 1.0
episodes_this_iter: 106
episodes_total: 2814
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7709144353866577
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -13.766767501831055
        total_loss: -6.837062835693359
        var_gnorm: 63.54973602294922
        vf_explained_var: 0.9231283068656921
        vf_loss: 21.568553924560547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 687.0
  learner_queue:
    size_count: 692
    size_mean: 15.72
    size_quantiles: [12.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.8009993757800314
  num_agent_steps_sampled: 360100
  num_agent_steps_trained: 343500
  num_env_steps_sampled: 360100
  num_env_steps_trained: 343500
  num_samples_added_to_queue: 360000
  num_training_step_calls_since_last_synch_worker_weights: 599
  num_weight_broadcasts: 7106
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 200.832
    learner_load_time_ms: 9.573
    learner_load_wait_time_ms: 1.556
iterations_since_restore: 26
node_ip: 127.0.0.1
num_agent_steps_sampled: 360100
num_agent_steps_trained: 343500
num_env_steps_sampled: 360100
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9968547893784
num_env_steps_trained: 343500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.996877915927
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.41428571428572
  ram_util_percent: 76.3
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05751898966934169
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022050242235963774
  mean_inference_ms: 1.0776314507118523
  mean_raw_obs_processing_ms: 0.2459746220295521
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019168853759765625
    StateBufferConnector_ms: 0.0033308874885990933
    ViewRequirementAgentConnector_ms: 0.11449714876570792
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 5.367924528301887
  episode_reward_min: 1.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 8.0, 5.0, 10.0, 5.0, 7.0, 4.0, 4.0, 8.0, 3.0, 4.0, 4.0,
      2.0, 3.0, 6.0, 4.0, 4.0, 8.0, 3.0, 5.0, 3.0, 10.0, 6.0, 6.0, 10.0, 3.0, 5.0,
      2.0, 4.0, 3.0, 4.0, 5.0, 8.0, 5.0, 4.0, 5.0, 7.0, 10.0, 9.0, 3.0, 3.0, 4.0,
      4.0, 4.0, 9.0, 4.0, 6.0, 5.0, 9.0, 4.0, 4.0, 4.0, 5.0, 5.0, 7.0, 3.0, 7.0, 5.0,
      6.0, 5.0, 4.0, 5.0, 8.0, 4.0, 6.0, 4.0, 4.0, 5.0, 7.0, 4.0, 3.0, 5.0, 3.0, 6.0,
      6.0, 5.0, 6.0, 10.0, 6.0, 5.0, 5.0, 7.0, 2.0, 6.0, 5.0, 1.0, 6.0, 4.0, 9.0,
      8.0, 5.0, 8.0, 9.0, 6.0, 3.0, 4.0, 4.0, 7.0, 6.0, 8.0, 9.0, 9.0, 2.0, 6.0, 6.0,
      2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05751898966934169
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022050242235963774
    mean_inference_ms: 1.0776314507118523
    mean_raw_obs_processing_ms: 0.2459746220295521
time_since_restore: 263.12455129623413
time_this_iter_s: 10.121909141540527
time_total_s: 263.12455129623413
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000093
timesteps_total: 360100
training_iteration: 26
trial_id: default
train step: 27
agent_timesteps_total: 374050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018612835385383816
  StateBufferConnector_ms: 0.0032750838393465096
  ViewRequirementAgentConnector_ms: 0.11148912097335956
counters:
  num_agent_steps_sampled: 374050
  num_agent_steps_trained: 357500
  num_env_steps_sampled: 374050
  num_env_steps_trained: 357500
  num_samples_added_to_queue: 374000
  num_training_step_calls_since_last_synch_worker_weights: 183
  num_weight_broadcasts: 7382
custom_metrics: {}
date: 2023-08-14_17-01-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.89908256880734
episode_reward_min: 1.0
episodes_this_iter: 109
episodes_total: 2923
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8523563742637634
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -70.25080108642578
        total_loss: -49.25689697265625
        var_gnorm: 63.56697463989258
        vf_explained_var: 0.866219699382782
        vf_loss: 50.51136779785156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 715.0
  learner_queue:
    size_count: 721
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3078226179417451
  num_agent_steps_sampled: 374050
  num_agent_steps_trained: 357500
  num_env_steps_sampled: 374050
  num_env_steps_trained: 357500
  num_samples_added_to_queue: 374000
  num_training_step_calls_since_last_synch_worker_weights: 183
  num_weight_broadcasts: 7382
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 167.776
    learner_load_time_ms: 9.55
    learner_load_wait_time_ms: 1.482
iterations_since_restore: 27
node_ip: 127.0.0.1
num_agent_steps_sampled: 374050
num_agent_steps_trained: 357500
num_env_steps_sampled: 374050
num_env_steps_sampled_this_iter: 13950
num_env_steps_sampled_throughput_per_sec: 1394.996773846458
num_env_steps_trained: 357500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9967622831834
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.53333333333334
  ram_util_percent: 76.49333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.057508684233872044
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022032067930867396
  mean_inference_ms: 1.0773854278918245
  mean_raw_obs_processing_ms: 0.2459793475113161
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018612835385383816
    StateBufferConnector_ms: 0.0032750838393465096
    ViewRequirementAgentConnector_ms: 0.11148912097335956
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.89908256880734
  episode_reward_min: 1.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [3.0, 7.0, 5.0, 4.0, 6.0, 7.0, 7.0, 3.0, 6.0, 6.0, 4.0, 2.0, 4.0,
      3.0, 9.0, 4.0, 7.0, 7.0, 2.0, 4.0, 5.0, 5.0, 2.0, 3.0, 6.0, 6.0, 5.0, 8.0, 6.0,
      3.0, 2.0, 1.0, 5.0, 3.0, 8.0, 4.0, 6.0, 3.0, 5.0, 6.0, 4.0, 9.0, 4.0, 6.0, 6.0,
      7.0, 5.0, 5.0, 3.0, 6.0, 7.0, 3.0, 8.0, 3.0, 8.0, 2.0, 4.0, 10.0, 8.0, 4.0,
      4.0, 7.0, 6.0, 5.0, 4.0, 5.0, 3.0, 3.0, 7.0, 4.0, 4.0, 10.0, 4.0, 5.0, 7.0,
      4.0, 8.0, 6.0, 5.0, 5.0, 4.0, 5.0, 5.0, 8.0, 5.0, 3.0, 3.0, 1.0, 4.0, 3.0, 5.0,
      2.0, 4.0, 2.0, 2.0, 5.0, 3.0, 7.0, 3.0, 2.0, 6.0, 9.0, 2.0, 3.0, 4.0, 6.0, 7.0,
      7.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.057508684233872044
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022032067930867396
    mean_inference_ms: 1.0773854278918245
    mean_raw_obs_processing_ms: 0.2459793475113161
time_since_restore: 273.2762312889099
time_this_iter_s: 10.151679992675781
time_total_s: 273.2762312889099
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1692000104
timesteps_total: 374050
training_iteration: 27
trial_id: default
train step: 28
agent_timesteps_total: 387800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019061899630822866
  StateBufferConnector_ms: 0.0033282788000374196
  ViewRequirementAgentConnector_ms: 0.112921278053355
counters:
  num_agent_steps_sampled: 387800
  num_agent_steps_trained: 371000
  num_env_steps_sampled: 387800
  num_env_steps_trained: 371000
  num_samples_added_to_queue: 387500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 7654
custom_metrics: {}
date: 2023-08-14_17-01-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 5.401869158878505
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 3030
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7768771648406982
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.11800611019134521
        total_loss: 11.982223510742188
        var_gnorm: 63.58460235595703
        vf_explained_var: 0.918399453163147
        vf_loss: 31.497207641601562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 742.0
  learner_queue:
    size_count: 745
    size_mean: 15.4
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3266499161421599
  num_agent_steps_sampled: 387800
  num_agent_steps_trained: 371000
  num_env_steps_sampled: 387800
  num_env_steps_trained: 371000
  num_samples_added_to_queue: 387500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 7654
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 276.357
    learner_load_time_ms: 9.549
    learner_load_wait_time_ms: 1.601
iterations_since_restore: 28
node_ip: 127.0.0.1
num_agent_steps_sampled: 387800
num_agent_steps_trained: 371000
num_env_steps_sampled: 387800
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.7412632100159
num_env_steps_trained: 371000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.7459675152882
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.15714285714285
  ram_util_percent: 75.85714285714286
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05753986055834886
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022035300232507944
  mean_inference_ms: 1.077735700037472
  mean_raw_obs_processing_ms: 0.24613090832004583
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019061899630822866
    StateBufferConnector_ms: 0.0033282788000374196
    ViewRequirementAgentConnector_ms: 0.112921278053355
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 5.401869158878505
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 5.0, 7.0, 7.0, 0.0, 7.0, 4.0, 4.0, 5.0, 3.0, 5.0, 10.0,
      6.0, 3.0, 9.0, 6.0, 8.0, 6.0, 7.0, 6.0, 4.0, 5.0, 4.0, 4.0, 6.0, 2.0, 8.0, 5.0,
      2.0, 6.0, 6.0, 2.0, 5.0, 5.0, 4.0, 6.0, 8.0, 8.0, 4.0, 2.0, 5.0, 4.0, 4.0, 6.0,
      5.0, 8.0, 6.0, 3.0, 4.0, 3.0, 9.0, 3.0, 2.0, 6.0, 2.0, 6.0, 5.0, 5.0, 6.0, 7.0,
      3.0, 7.0, 4.0, 5.0, 5.0, 6.0, 10.0, 4.0, 10.0, 8.0, 7.0, 3.0, 3.0, 7.0, 3.0,
      5.0, 7.0, 7.0, 11.0, 4.0, 2.0, 5.0, 6.0, 5.0, 8.0, 5.0, 5.0, 8.0, 8.0, 7.0,
      10.0, 6.0, 2.0, 5.0, 6.0, 7.0, 5.0, 4.0, 2.0, 5.0, 5.0, 7.0, 5.0, 6.0, 5.0,
      4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05753986055834886
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022035300232507944
    mean_inference_ms: 1.077735700037472
    mean_raw_obs_processing_ms: 0.24613090832004583
time_since_restore: 283.3588924407959
time_this_iter_s: 10.082661151885986
time_total_s: 283.3588924407959
timers:
  sample_time_ms: 0.063
  synch_weights_time_ms: 0.259
  training_iteration_time_ms: 0.391
timestamp: 1692000114
timesteps_total: 387800
training_iteration: 28
trial_id: default
train step: 29
agent_timesteps_total: 401500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01871563563837069
  StateBufferConnector_ms: 0.003274801735566041
  ViewRequirementAgentConnector_ms: 0.11126839111898547
counters:
  num_agent_steps_sampled: 401500
  num_agent_steps_trained: 385000
  num_env_steps_sampled: 401500
  num_env_steps_trained: 385000
  num_samples_added_to_queue: 401500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 7926
custom_metrics: {}
date: 2023-08-14_17-02-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 6.130841121495327
episode_reward_min: 1.0
episodes_this_iter: 107
episodes_total: 3137
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8571709990501404
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.049335479736328
        total_loss: 10.654806137084961
        var_gnorm: 63.60218048095703
        vf_explained_var: 0.828253984451294
        vf_loss: 57.9799919128418
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 770.0
  learner_queue:
    size_count: 772
    size_mean: 15.72
    size_quantiles: [12.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.7493997598078078
  num_agent_steps_sampled: 401500
  num_agent_steps_trained: 385000
  num_env_steps_sampled: 401500
  num_env_steps_trained: 385000
  num_samples_added_to_queue: 401500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 7926
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 290.548
    learner_load_time_ms: 9.552
    learner_load_wait_time_ms: 1.736
iterations_since_restore: 29
node_ip: 127.0.0.1
num_agent_steps_sampled: 401500
num_agent_steps_trained: 385000
num_env_steps_sampled: 401500
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.2842955681863
num_env_steps_trained: 385000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.2686232083656
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.94285714285714
  ram_util_percent: 75.01428571428572
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0575424296234958
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022022712859077965
  mean_inference_ms: 1.0780759980179204
  mean_raw_obs_processing_ms: 0.2461430025536579
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01871563563837069
    StateBufferConnector_ms: 0.003274801735566041
    ViewRequirementAgentConnector_ms: 0.11126839111898547
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 6.130841121495327
  episode_reward_min: 1.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 3.0, 6.0, 9.0, 6.0, 6.0, 2.0, 9.0, 6.0, 5.0, 7.0, 7.0, 11.0,
      6.0, 5.0, 7.0, 5.0, 6.0, 10.0, 3.0, 7.0, 8.0, 9.0, 4.0, 9.0, 4.0, 5.0, 6.0,
      3.0, 3.0, 6.0, 7.0, 7.0, 8.0, 9.0, 7.0, 10.0, 6.0, 5.0, 7.0, 10.0, 5.0, 4.0,
      5.0, 5.0, 7.0, 6.0, 5.0, 6.0, 4.0, 8.0, 11.0, 5.0, 9.0, 8.0, 8.0, 6.0, 2.0,
      8.0, 4.0, 7.0, 4.0, 4.0, 3.0, 2.0, 8.0, 3.0, 3.0, 5.0, 5.0, 4.0, 7.0, 2.0, 8.0,
      5.0, 10.0, 7.0, 1.0, 9.0, 4.0, 9.0, 2.0, 5.0, 8.0, 8.0, 1.0, 5.0, 9.0, 7.0,
      5.0, 7.0, 10.0, 5.0, 10.0, 5.0, 5.0, 5.0, 10.0, 9.0, 5.0, 8.0, 5.0, 6.0, 6.0,
      7.0, 6.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0575424296234958
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022022712859077965
    mean_inference_ms: 1.0780759980179204
    mean_raw_obs_processing_ms: 0.2461430025536579
time_since_restore: 293.42594742774963
time_this_iter_s: 10.067054986953735
time_total_s: 293.42594742774963
timers:
  sample_time_ms: 0.076
  synch_weights_time_ms: 0.615
  training_iteration_time_ms: 2.141
timestamp: 1692000124
timesteps_total: 401500
training_iteration: 29
trial_id: default
train step: 30
agent_timesteps_total: 415050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019389053560652823
  StateBufferConnector_ms: 0.0034035376782687206
  ViewRequirementAgentConnector_ms: 0.11421554493454267
counters:
  num_agent_steps_sampled: 415050
  num_agent_steps_trained: 398500
  num_env_steps_sampled: 415050
  num_env_steps_trained: 398500
  num_samples_added_to_queue: 415000
  num_training_step_calls_since_last_synch_worker_weights: 713
  num_weight_broadcasts: 8195
custom_metrics: {}
date: 2023-08-14_17-02-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.59433962264151
episode_reward_min: 2.0
episodes_this_iter: 106
episodes_total: 3243
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8333358764648438
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 5.895181179046631
        total_loss: 18.580158233642578
        var_gnorm: 63.61336135864258
        vf_explained_var: 0.9266629219055176
        vf_loss: 33.703311920166016
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 797.0
  learner_queue:
    size_count: 801
    size_mean: 15.8
    size_quantiles: [13.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.6
  num_agent_steps_sampled: 415050
  num_agent_steps_trained: 398500
  num_env_steps_sampled: 415050
  num_env_steps_trained: 398500
  num_samples_added_to_queue: 415000
  num_training_step_calls_since_last_synch_worker_weights: 713
  num_weight_broadcasts: 8195
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 241.842
    learner_load_time_ms: 1.35
    learner_load_wait_time_ms: 1.517
iterations_since_restore: 30
node_ip: 127.0.0.1
num_agent_steps_sampled: 415050
num_agent_steps_trained: 398500
num_env_steps_sampled: 415050
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9959617973514
num_env_steps_trained: 398500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.995976698468
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.1
  ram_util_percent: 74.29285714285713
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05757817344230322
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022061189655499743
  mean_inference_ms: 1.0786872929982352
  mean_raw_obs_processing_ms: 0.24636325189396993
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019389053560652823
    StateBufferConnector_ms: 0.0034035376782687206
    ViewRequirementAgentConnector_ms: 0.11421554493454267
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.59433962264151
  episode_reward_min: 2.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 6.0, 7.0, 6.0, 6.0, 7.0, 8.0, 6.0, 5.0, 5.0, 5.0, 7.0, 7.0,
      7.0, 9.0, 6.0, 6.0, 5.0, 4.0, 4.0, 11.0, 8.0, 9.0, 6.0, 6.0, 3.0, 4.0, 6.0,
      5.0, 10.0, 5.0, 6.0, 9.0, 7.0, 8.0, 10.0, 4.0, 9.0, 8.0, 11.0, 7.0, 7.0, 6.0,
      7.0, 7.0, 8.0, 4.0, 8.0, 3.0, 8.0, 7.0, 8.0, 5.0, 6.0, 7.0, 6.0, 5.0, 4.0, 8.0,
      8.0, 7.0, 5.0, 6.0, 7.0, 7.0, 5.0, 10.0, 10.0, 8.0, 5.0, 5.0, 3.0, 6.0, 5.0,
      6.0, 5.0, 9.0, 11.0, 9.0, 6.0, 7.0, 10.0, 13.0, 9.0, 7.0, 4.0, 2.0, 9.0, 7.0,
      5.0, 10.0, 6.0, 2.0, 3.0, 7.0, 7.0, 9.0, 5.0, 2.0, 7.0, 4.0, 7.0, 3.0, 8.0,
      11.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05757817344230322
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022061189655499743
    mean_inference_ms: 1.0786872929982352
    mean_raw_obs_processing_ms: 0.24636325189396993
time_since_restore: 303.54448437690735
time_this_iter_s: 10.118536949157715
time_total_s: 303.54448437690735
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000134
timesteps_total: 415050
training_iteration: 30
trial_id: default
train step: 31
agent_timesteps_total: 428200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01984694424797507
  StateBufferConnector_ms: 0.0034883910534428617
  ViewRequirementAgentConnector_ms: 0.11976840449314491
counters:
  num_agent_steps_sampled: 428200
  num_agent_steps_trained: 411500
  num_env_steps_sampled: 428200
  num_env_steps_trained: 411500
  num_samples_added_to_queue: 428000
  num_training_step_calls_since_last_synch_worker_weights: 171
  num_weight_broadcasts: 8455
custom_metrics: {}
date: 2023-08-14_17-02-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.107843137254902
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 3345
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8581098318099976
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 14.343972206115723
        total_loss: 45.45267868041992
        var_gnorm: 63.624996185302734
        vf_explained_var: 0.8768236041069031
        vf_loss: 70.79851531982422
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 823.0
  learner_queue:
    size_count: 829
    size_mean: 15.42
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.250439922587247
  num_agent_steps_sampled: 428200
  num_agent_steps_trained: 411500
  num_env_steps_sampled: 428200
  num_env_steps_trained: 411500
  num_samples_added_to_queue: 428000
  num_training_step_calls_since_last_synch_worker_weights: 171
  num_weight_broadcasts: 8455
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 186.856
    learner_load_time_ms: 1.35
    learner_load_wait_time_ms: 1.599
iterations_since_restore: 31
node_ip: 127.0.0.1
num_agent_steps_sampled: 428200
num_agent_steps_trained: 411500
num_env_steps_sampled: 428200
num_env_steps_sampled_this_iter: 13150
num_env_steps_sampled_throughput_per_sec: 1314.995391265809
num_env_steps_trained: 411500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9954438369216
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.46000000000001
  ram_util_percent: 76.04666666666667
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05768712107254239
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022113915399351935
  mean_inference_ms: 1.0804898000393222
  mean_raw_obs_processing_ms: 0.24683919505274923
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01984694424797507
    StateBufferConnector_ms: 0.0034883910534428617
    ViewRequirementAgentConnector_ms: 0.11976840449314491
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.107843137254902
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 7.0, 7.0, 5.0, 8.0, 2.0, 14.0, 10.0, 11.0, 9.0, 7.0, 10.0,
      7.0, 15.0, 7.0, 9.0, 6.0, 10.0, 5.0, 10.0, 5.0, 6.0, 6.0, 8.0, 11.0, 10.0, 7.0,
      3.0, 6.0, 14.0, 6.0, 4.0, 8.0, 8.0, 8.0, 5.0, 9.0, 5.0, 7.0, 9.0, 7.0, 6.0,
      4.0, 9.0, 11.0, 2.0, 8.0, 10.0, 7.0, 9.0, 8.0, 6.0, 6.0, 6.0, 5.0, 6.0, 2.0,
      0.0, 9.0, 10.0, 4.0, 8.0, 5.0, 8.0, 9.0, 8.0, 9.0, 7.0, 2.0, 7.0, 5.0, 6.0,
      4.0, 9.0, 11.0, 6.0, 5.0, 10.0, 8.0, 6.0, 7.0, 8.0, 7.0, 4.0, 5.0, 3.0, 2.0,
      8.0, 6.0, 5.0, 8.0, 9.0, 11.0, 11.0, 11.0, 5.0, 8.0, 8.0, 11.0, 2.0, 6.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05768712107254239
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022113915399351935
    mean_inference_ms: 1.0804898000393222
    mean_raw_obs_processing_ms: 0.24683919505274923
time_since_restore: 313.7077934741974
time_this_iter_s: 10.163309097290039
time_total_s: 313.7077934741974
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000144
timesteps_total: 428200
training_iteration: 31
trial_id: default
train step: 32
agent_timesteps_total: 441300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020101895699134238
  StateBufferConnector_ms: 0.0035863656264085034
  ViewRequirementAgentConnector_ms: 0.12015448166773869
counters:
  num_agent_steps_sampled: 441300
  num_agent_steps_trained: 424500
  num_env_steps_sampled: 441300
  num_env_steps_trained: 424500
  num_samples_added_to_queue: 441000
  num_training_step_calls_since_last_synch_worker_weights: 606
  num_weight_broadcasts: 8709
custom_metrics: {}
date: 2023-08-14_17-02-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 6.461538461538462
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 3449
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8605011701583862
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -28.449472427368164
        total_loss: -15.676839828491211
        var_gnorm: 63.64303207397461
        vf_explained_var: 0.9463274478912354
        vf_loss: 34.15027618408203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 849.0
  learner_queue:
    size_count: 855
    size_mean: 15.1
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5779733838059502
  num_agent_steps_sampled: 441300
  num_agent_steps_trained: 424500
  num_env_steps_sampled: 441300
  num_env_steps_trained: 424500
  num_samples_added_to_queue: 441000
  num_training_step_calls_since_last_synch_worker_weights: 606
  num_weight_broadcasts: 8709
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 221.545
    learner_load_time_ms: 3.385
    learner_load_wait_time_ms: 1.749
iterations_since_restore: 32
node_ip: 127.0.0.1
num_agent_steps_sampled: 441300
num_agent_steps_trained: 424500
num_env_steps_sampled: 441300
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9959397441824
num_env_steps_trained: 424500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9959707385017
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.27857142857142
  ram_util_percent: 76.98571428571428
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.057802012360022206
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022169349361843112
  mean_inference_ms: 1.082316756814425
  mean_raw_obs_processing_ms: 0.24733381119994335
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020101895699134238
    StateBufferConnector_ms: 0.0035863656264085034
    ViewRequirementAgentConnector_ms: 0.12015448166773869
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 6.461538461538462
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 5.0, 7.0, 9.0, 5.0, 6.0, 7.0, 11.0, 6.0, 3.0, 4.0, 4.0,
      4.0, 10.0, 5.0, 6.0, 7.0, 7.0, 6.0, 9.0, 5.0, 9.0, 9.0, 9.0, 9.0, 3.0, 9.0,
      8.0, 2.0, 6.0, 8.0, 5.0, 8.0, 6.0, 5.0, 5.0, 8.0, 10.0, 5.0, 4.0, 2.0, 9.0,
      4.0, 7.0, 2.0, 10.0, 3.0, 7.0, 9.0, 3.0, 7.0, 4.0, 5.0, 5.0, 6.0, 9.0, 3.0,
      4.0, 7.0, 3.0, 9.0, 8.0, 8.0, 5.0, 3.0, 6.0, 1.0, 9.0, 4.0, 4.0, 9.0, 5.0, 5.0,
      10.0, 10.0, 5.0, 5.0, 8.0, 7.0, 3.0, 6.0, 9.0, 9.0, 8.0, 9.0, 6.0, 9.0, 5.0,
      5.0, 11.0, 6.0, 5.0, 7.0, 9.0, 9.0, 7.0, 6.0, 5.0, 9.0, 5.0, 9.0, 8.0, 8.0,
      6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.057802012360022206
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022169349361843112
    mean_inference_ms: 1.082316756814425
    mean_raw_obs_processing_ms: 0.24733381119994335
time_since_restore: 323.8647027015686
time_this_iter_s: 10.156909227371216
time_total_s: 323.8647027015686
timers:
  sample_time_ms: 0.013
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.042
timestamp: 1692000154
timesteps_total: 441300
training_iteration: 32
trial_id: default
train step: 33
agent_timesteps_total: 453900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022275686264038086
  StateBufferConnector_ms: 0.003987550735473633
  ViewRequirementAgentConnector_ms: 0.1302165985107422
counters:
  num_agent_steps_sampled: 453900
  num_agent_steps_trained: 437000
  num_env_steps_sampled: 453900
  num_env_steps_trained: 437000
  num_samples_added_to_queue: 453500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 8958
custom_metrics: {}
date: 2023-08-14_17-02-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 7.0
episode_reward_min: 1.0
episodes_this_iter: 97
episodes_total: 3546
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8630052208900452
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -24.59449005126953
        total_loss: -6.838534355163574
        var_gnorm: 63.65781784057617
        vf_explained_var: 0.9296539425849915
        vf_loss: 44.141963958740234
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 874.0
  learner_queue:
    size_count: 880
    size_mean: 15.02
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.555506348428061
  num_agent_steps_sampled: 453900
  num_agent_steps_trained: 437000
  num_env_steps_sampled: 453900
  num_env_steps_trained: 437000
  num_samples_added_to_queue: 453500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 8958
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 221.033
    learner_load_time_ms: 3.371
    learner_load_wait_time_ms: 1.544
iterations_since_restore: 33
node_ip: 127.0.0.1
num_agent_steps_sampled: 453900
num_agent_steps_trained: 437000
num_env_steps_sampled: 453900
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.5922688428384
num_env_steps_trained: 437000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.5955048044032
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 64.64000000000001
  ram_util_percent: 78.49333333333334
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.057973150213830725
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0222473892545649
  mean_inference_ms: 1.0851017496713207
  mean_raw_obs_processing_ms: 0.24798266582840142
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022275686264038086
    StateBufferConnector_ms: 0.003987550735473633
    ViewRequirementAgentConnector_ms: 0.1302165985107422
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 7.0
  episode_reward_min: 1.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 6.0, 5.0, 8.0, 4.0, 8.0, 9.0, 8.0, 5.0, 7.0, 7.0, 4.0,
      8.0, 7.0, 8.0, 5.0, 8.0, 9.0, 5.0, 5.0, 8.0, 6.0, 9.0, 9.0, 8.0, 8.0, 9.0, 4.0,
      7.0, 6.0, 12.0, 11.0, 11.0, 9.0, 8.0, 5.0, 8.0, 6.0, 6.0, 9.0, 4.0, 12.0, 10.0,
      7.0, 6.0, 7.0, 9.0, 11.0, 6.0, 5.0, 6.0, 5.0, 6.0, 10.0, 9.0, 1.0, 8.0, 5.0,
      7.0, 11.0, 6.0, 5.0, 6.0, 8.0, 8.0, 11.0, 5.0, 6.0, 6.0, 8.0, 7.0, 5.0, 7.0,
      8.0, 5.0, 5.0, 4.0, 5.0, 7.0, 9.0, 5.0, 7.0, 7.0, 6.0, 5.0, 4.0, 8.0, 5.0, 6.0,
      8.0, 9.0, 5.0, 4.0, 7.0, 7.0, 6.0, 6.0, 10.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.057973150213830725
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0222473892545649
    mean_inference_ms: 1.0851017496713207
    mean_raw_obs_processing_ms: 0.24798266582840142
time_since_restore: 334.01250290870667
time_this_iter_s: 10.147800207138062
time_total_s: 334.01250290870667
timers:
  sample_time_ms: 0.041
  synch_weights_time_ms: 0.283
  training_iteration_time_ms: 0.386
timestamp: 1692000164
timesteps_total: 453900
training_iteration: 33
trial_id: default
train step: 34
agent_timesteps_total: 467150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01963491623218243
  StateBufferConnector_ms: 0.0033869193150446964
  ViewRequirementAgentConnector_ms: 0.11753783776209904
counters:
  num_agent_steps_sampled: 467150
  num_agent_steps_trained: 450500
  num_env_steps_sampled: 467150
  num_env_steps_trained: 450500
  num_samples_added_to_queue: 467000
  num_training_step_calls_since_last_synch_worker_weights: 738
  num_weight_broadcasts: 9221
custom_metrics: {}
date: 2023-08-14_17-02-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.576923076923077
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 3650
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8992456197738647
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -26.71295166015625
        total_loss: -4.472385883331299
        var_gnorm: 63.67369842529297
        vf_explained_var: 0.9095832109451294
        vf_loss: 53.47358703613281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 901.0
  learner_queue:
    size_count: 906
    size_mean: 15.22
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4323407415835103
  num_agent_steps_sampled: 467150
  num_agent_steps_trained: 450500
  num_env_steps_sampled: 467150
  num_env_steps_trained: 450500
  num_samples_added_to_queue: 467000
  num_training_step_calls_since_last_synch_worker_weights: 738
  num_weight_broadcasts: 9221
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 211.654
    learner_load_time_ms: 3.39
    learner_load_wait_time_ms: 1.787
iterations_since_restore: 34
node_ip: 127.0.0.1
num_agent_steps_sampled: 467150
num_agent_steps_trained: 450500
num_env_steps_sampled: 467150
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.996588238918
num_env_steps_trained: 450500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9965238660675
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 54.09285714285714
  ram_util_percent: 77.77142857142859
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05804791578837916
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022287064233744602
  mean_inference_ms: 1.086328145714091
  mean_raw_obs_processing_ms: 0.24830615669762215
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01963491623218243
    StateBufferConnector_ms: 0.0033869193150446964
    ViewRequirementAgentConnector_ms: 0.11753783776209904
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.576923076923077
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 10.0, 12.0, 4.0, 9.0, 6.0, 7.0, 8.0, 9.0, 7.0, 10.0, 8.0,
      11.0, 12.0, 4.0, 6.0, 6.0, 8.0, 3.0, 8.0, 6.0, 13.0, 9.0, 11.0, 7.0, 6.0, 7.0,
      4.0, 6.0, 9.0, 5.0, 8.0, 8.0, 5.0, 9.0, 8.0, 9.0, 10.0, 11.0, 7.0, 12.0, 8.0,
      9.0, 5.0, 7.0, 10.0, 2.0, 13.0, 9.0, 7.0, 6.0, 4.0, 8.0, 10.0, 11.0, 10.0, 7.0,
      11.0, 3.0, 7.0, 3.0, 4.0, 7.0, 6.0, 7.0, 8.0, 7.0, 8.0, 4.0, 9.0, 8.0, 9.0,
      6.0, 7.0, 8.0, 8.0, 10.0, 6.0, 8.0, 5.0, 10.0, 6.0, 10.0, 6.0, 4.0, 8.0, 6.0,
      6.0, 8.0, 9.0, 7.0, 10.0, 5.0, 7.0, 10.0, 7.0, 10.0, 10.0, 5.0, 8.0, 9.0, 8.0,
      7.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05804791578837916
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022287064233744602
    mean_inference_ms: 1.086328145714091
    mean_raw_obs_processing_ms: 0.24830615669762215
time_since_restore: 344.1301848888397
time_this_iter_s: 10.117681980133057
time_total_s: 344.1301848888397
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000174
timesteps_total: 467150
training_iteration: 34
trial_id: default
train step: 35
agent_timesteps_total: 479950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020882129669189453
  StateBufferConnector_ms: 0.0036516189575195312
  ViewRequirementAgentConnector_ms: 0.12143254280090332
counters:
  num_agent_steps_sampled: 479950
  num_agent_steps_trained: 463000
  num_env_steps_sampled: 479950
  num_env_steps_trained: 463000
  num_samples_added_to_queue: 479500
  num_training_step_calls_since_last_synch_worker_weights: 621
  num_weight_broadcasts: 9473
custom_metrics: {}
date: 2023-08-14_17-03-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.22
episode_reward_min: 3.0
episodes_this_iter: 100
episodes_total: 3750
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8589067459106445
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 6.0876288414001465
        total_loss: 52.161834716796875
        var_gnorm: 63.683807373046875
        vf_explained_var: 0.8654416799545288
        vf_loss: 100.73748016357422
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 926.0
  learner_queue:
    size_count: 931
    size_mean: 15.38
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.1469960767151735
  num_agent_steps_sampled: 479950
  num_agent_steps_trained: 463000
  num_env_steps_sampled: 479950
  num_env_steps_trained: 463000
  num_samples_added_to_queue: 479500
  num_training_step_calls_since_last_synch_worker_weights: 621
  num_weight_broadcasts: 9473
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 230.606
    learner_load_time_ms: 3.399
    learner_load_wait_time_ms: 1.6
iterations_since_restore: 35
node_ip: 127.0.0.1
num_agent_steps_sampled: 479950
num_agent_steps_trained: 463000
num_env_steps_sampled: 479950
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.998840333082
num_env_steps_trained: 463000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9988675127752
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 56.0
  ram_util_percent: 78.61428571428573
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05817657050393432
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022348149392392058
  mean_inference_ms: 1.088450702768932
  mean_raw_obs_processing_ms: 0.2488115875342543
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020882129669189453
    StateBufferConnector_ms: 0.0036516189575195312
    ViewRequirementAgentConnector_ms: 0.12143254280090332
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.22
  episode_reward_min: 3.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 10.0, 6.0, 7.0, 7.0, 12.0, 7.0, 3.0, 8.0, 5.0, 6.0, 9.0,
      5.0, 5.0, 4.0, 11.0, 5.0, 9.0, 7.0, 10.0, 9.0, 5.0, 7.0, 6.0, 7.0, 8.0, 5.0,
      6.0, 5.0, 6.0, 6.0, 8.0, 5.0, 8.0, 6.0, 7.0, 4.0, 15.0, 10.0, 9.0, 11.0, 6.0,
      5.0, 4.0, 11.0, 8.0, 11.0, 6.0, 8.0, 9.0, 6.0, 7.0, 9.0, 7.0, 6.0, 3.0, 7.0,
      11.0, 3.0, 10.0, 3.0, 10.0, 6.0, 8.0, 9.0, 10.0, 7.0, 9.0, 6.0, 6.0, 4.0, 4.0,
      5.0, 9.0, 6.0, 3.0, 10.0, 8.0, 8.0, 11.0, 8.0, 5.0, 10.0, 6.0, 12.0, 6.0, 6.0,
      9.0, 6.0, 6.0, 6.0, 9.0, 11.0, 8.0, 7.0, 7.0, 4.0, 7.0, 4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05817657050393432
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022348149392392058
    mean_inference_ms: 1.088450702768932
    mean_raw_obs_processing_ms: 0.2488115875342543
time_since_restore: 354.24869894981384
time_this_iter_s: 10.118514060974121
time_total_s: 354.24869894981384
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000185
timesteps_total: 479950
training_iteration: 35
trial_id: default
train step: 36
agent_timesteps_total: 492750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02054595947265625
  StateBufferConnector_ms: 0.0036466121673583984
  ViewRequirementAgentConnector_ms: 0.12240481376647949
counters:
  num_agent_steps_sampled: 492750
  num_agent_steps_trained: 476000
  num_env_steps_sampled: 492750
  num_env_steps_trained: 476000
  num_samples_added_to_queue: 492500
  num_training_step_calls_since_last_synch_worker_weights: 500
  num_weight_broadcasts: 9725
custom_metrics: {}
date: 2023-08-14_17-03-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 19.0
episode_reward_mean: 7.93
episode_reward_min: 2.0
episodes_this_iter: 100
episodes_total: 3850
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8454897403717041
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 16.18699836730957
        total_loss: 77.38322448730469
        var_gnorm: 63.69016647338867
        vf_explained_var: 0.8291801810264587
        vf_loss: 130.84735107421875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 952.0
  learner_queue:
    size_count: 957
    size_mean: 15.4
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1135528725660042
  num_agent_steps_sampled: 492750
  num_agent_steps_trained: 476000
  num_env_steps_sampled: 492750
  num_env_steps_trained: 476000
  num_samples_added_to_queue: 492500
  num_training_step_calls_since_last_synch_worker_weights: 500
  num_weight_broadcasts: 9725
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 216.305
    learner_load_time_ms: 3.4
    learner_load_wait_time_ms: 1.555
iterations_since_restore: 36
node_ip: 127.0.0.1
num_agent_steps_sampled: 492750
num_agent_steps_trained: 476000
num_env_steps_sampled: 492750
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9996032716074
num_env_steps_trained: 476000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9995970727261
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 58.364285714285714
  ram_util_percent: 79.3142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05830449955549446
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02241052158629275
  mean_inference_ms: 1.090508403725109
  mean_raw_obs_processing_ms: 0.24927593285007726
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02054595947265625
    StateBufferConnector_ms: 0.0036466121673583984
    ViewRequirementAgentConnector_ms: 0.12240481376647949
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 19.0
  episode_reward_mean: 7.93
  episode_reward_min: 2.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 11.0, 8.0, 5.0, 5.0, 7.0, 11.0, 15.0, 9.0, 11.0, 12.0, 6.0,
      4.0, 9.0, 6.0, 7.0, 7.0, 4.0, 16.0, 9.0, 3.0, 5.0, 10.0, 9.0, 7.0, 7.0, 8.0,
      5.0, 7.0, 8.0, 7.0, 3.0, 7.0, 7.0, 7.0, 7.0, 15.0, 13.0, 6.0, 7.0, 6.0, 7.0,
      8.0, 10.0, 6.0, 12.0, 6.0, 8.0, 11.0, 12.0, 7.0, 5.0, 6.0, 3.0, 5.0, 7.0, 5.0,
      9.0, 6.0, 5.0, 8.0, 2.0, 14.0, 8.0, 8.0, 7.0, 6.0, 11.0, 8.0, 12.0, 6.0, 11.0,
      3.0, 12.0, 8.0, 8.0, 9.0, 9.0, 19.0, 5.0, 6.0, 8.0, 5.0, 9.0, 4.0, 11.0, 8.0,
      7.0, 7.0, 4.0, 7.0, 7.0, 13.0, 8.0, 10.0, 12.0, 9.0, 8.0, 11.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05830449955549446
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02241052158629275
    mean_inference_ms: 1.090508403725109
    mean_raw_obs_processing_ms: 0.24927593285007726
time_since_restore: 364.3774609565735
time_this_iter_s: 10.128762006759644
time_total_s: 364.3774609565735
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1692000195
timesteps_total: 492750
training_iteration: 36
trial_id: default
train step: 37
agent_timesteps_total: 506500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018726776693468897
  StateBufferConnector_ms: 0.0033153551761235032
  ViewRequirementAgentConnector_ms: 0.11249323871648201
counters:
  num_agent_steps_sampled: 506500
  num_agent_steps_trained: 490000
  num_env_steps_sampled: 506500
  num_env_steps_trained: 490000
  num_samples_added_to_queue: 506500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 9997
custom_metrics: {}
date: 2023-08-14_17-03-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.42056074766355
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 3957
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8325067758560181
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -17.037525177001953
        total_loss: -5.5220842361450195
        var_gnorm: 63.700923919677734
        vf_explained_var: 0.9566079378128052
        vf_loss: 31.35594940185547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 980.0
  learner_queue:
    size_count: 982
    size_mean: 15.58
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9816312953446421
  num_agent_steps_sampled: 506500
  num_agent_steps_trained: 490000
  num_env_steps_sampled: 506500
  num_env_steps_trained: 490000
  num_samples_added_to_queue: 506500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 9997
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 298.199
    learner_load_time_ms: 3.619
    learner_load_wait_time_ms: 1.58
iterations_since_restore: 37
node_ip: 127.0.0.1
num_agent_steps_sampled: 506500
num_agent_steps_trained: 490000
num_env_steps_sampled: 506500
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1373.4123403850576
num_env_steps_trained: 490000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1398.3834738466041
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 48.57999999999999
  ram_util_percent: 78.05333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05829722734324375
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022402912815151926
  mean_inference_ms: 1.0903807557790435
  mean_raw_obs_processing_ms: 0.24927428416920738
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018726776693468897
    StateBufferConnector_ms: 0.0033153551761235032
    ViewRequirementAgentConnector_ms: 0.11249323871648201
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.42056074766355
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 7.0, 5.0, 7.0, 8.0, 5.0, 11.0, 7.0, 11.0, 7.0, 11.0, 9.0,
      5.0, 11.0, 8.0, 8.0, 6.0, 12.0, 6.0, 12.0, 7.0, 7.0, 11.0, 7.0, 6.0, 4.0, 13.0,
      9.0, 8.0, 6.0, 10.0, 9.0, 9.0, 8.0, 10.0, 6.0, 8.0, 9.0, 9.0, 7.0, 11.0, 6.0,
      6.0, 10.0, 10.0, 9.0, 17.0, 9.0, 11.0, 11.0, 12.0, 5.0, 7.0, 7.0, 4.0, 9.0,
      8.0, 9.0, 8.0, 9.0, 12.0, 10.0, 7.0, 8.0, 9.0, 7.0, 10.0, 11.0, 8.0, 11.0, 9.0,
      10.0, 10.0, 6.0, 10.0, 12.0, 10.0, 7.0, 7.0, 8.0, 12.0, 12.0, 6.0, 5.0, 9.0,
      7.0, 10.0, 8.0, 3.0, 11.0, 5.0, 14.0, 7.0, 6.0, 4.0, 8.0, 4.0, 7.0, 11.0, 6.0,
      8.0, 5.0, 10.0, 10.0, 5.0, 9.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05829722734324375
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022402912815151926
    mean_inference_ms: 1.0903807557790435
    mean_raw_obs_processing_ms: 0.24927428416920738
time_since_restore: 374.45005083084106
time_this_iter_s: 10.072589874267578
time_total_s: 374.45005083084106
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.444
  training_iteration_time_ms: 1.994
timestamp: 1692000205
timesteps_total: 506500
training_iteration: 37
trial_id: default
train step: 38
agent_timesteps_total: 519850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019918850490025113
  StateBufferConnector_ms: 0.0033943993704659598
  ViewRequirementAgentConnector_ms: 0.11615344456263951
counters:
  num_agent_steps_sampled: 519850
  num_agent_steps_trained: 503000
  num_env_steps_sampled: 519850
  num_env_steps_trained: 503000
  num_samples_added_to_queue: 519500
  num_training_step_calls_since_last_synch_worker_weights: 196
  num_weight_broadcasts: 10260
custom_metrics: {}
date: 2023-08-14_17-03-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.9904761904761905
episode_reward_min: 2.0
episodes_this_iter: 105
episodes_total: 4062
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7928996682167053
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -29.840862274169922
        total_loss: -10.744329452514648
        var_gnorm: 63.71226501464844
        vf_explained_var: 0.9596507549285889
        vf_loss: 46.12206268310547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1006.0
  learner_queue:
    size_count: 1012
    size_mean: 15.66
    size_quantiles: [11.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 1.0121264743103997
  num_agent_steps_sampled: 519850
  num_agent_steps_trained: 503000
  num_env_steps_sampled: 519850
  num_env_steps_trained: 503000
  num_samples_added_to_queue: 519500
  num_training_step_calls_since_last_synch_worker_weights: 196
  num_weight_broadcasts: 10260
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 190.121
    learner_load_time_ms: 1.59
    learner_load_wait_time_ms: 1.569
iterations_since_restore: 38
node_ip: 127.0.0.1
num_agent_steps_sampled: 519850
num_agent_steps_trained: 503000
num_env_steps_sampled: 519850
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9930613401564
num_env_steps_trained: 503000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9932432525866
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.23571428571428
  ram_util_percent: 78.10000000000001
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0583320784618396
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02242068141614662
  mean_inference_ms: 1.0909995339964282
  mean_raw_obs_processing_ms: 0.24942258310999976
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019918850490025113
    StateBufferConnector_ms: 0.0033943993704659598
    ViewRequirementAgentConnector_ms: 0.11615344456263951
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.9904761904761905
  episode_reward_min: 2.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 6.0, 12.0, 8.0, 8.0, 10.0, 7.0, 5.0, 10.0, 9.0, 4.0, 6.0,
      8.0, 10.0, 8.0, 5.0, 6.0, 10.0, 8.0, 4.0, 6.0, 6.0, 7.0, 11.0, 7.0, 3.0, 11.0,
      9.0, 8.0, 15.0, 8.0, 10.0, 9.0, 14.0, 4.0, 5.0, 10.0, 12.0, 5.0, 7.0, 8.0, 7.0,
      9.0, 5.0, 4.0, 7.0, 9.0, 5.0, 7.0, 10.0, 8.0, 8.0, 9.0, 11.0, 4.0, 13.0, 8.0,
      5.0, 7.0, 6.0, 6.0, 7.0, 9.0, 10.0, 12.0, 9.0, 8.0, 7.0, 7.0, 6.0, 6.0, 8.0,
      7.0, 7.0, 12.0, 6.0, 2.0, 8.0, 10.0, 9.0, 12.0, 15.0, 6.0, 10.0, 8.0, 8.0, 4.0,
      8.0, 10.0, 9.0, 7.0, 7.0, 12.0, 9.0, 8.0, 9.0, 8.0, 14.0, 9.0, 8.0, 11.0, 7.0,
      6.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0583320784618396
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02242068141614662
    mean_inference_ms: 1.0909995339964282
    mean_raw_obs_processing_ms: 0.24942258310999976
time_since_restore: 384.5984127521515
time_this_iter_s: 10.148361921310425
time_total_s: 384.5984127521515
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000215
timesteps_total: 519850
training_iteration: 38
trial_id: default
train step: 39
agent_timesteps_total: 532450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020819425582885742
  StateBufferConnector_ms: 0.003589630126953125
  ViewRequirementAgentConnector_ms: 0.12371206283569336
counters:
  num_agent_steps_sampled: 532450
  num_agent_steps_trained: 515500
  num_env_steps_sampled: 532450
  num_env_steps_trained: 515500
  num_samples_added_to_queue: 532000
  num_training_step_calls_since_last_synch_worker_weights: 564
  num_weight_broadcasts: 10509
custom_metrics: {}
date: 2023-08-14_17-03-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.62
episode_reward_min: 0.0
episodes_this_iter: 98
episodes_total: 4160
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4924091398715973
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.983531951904297
        total_loss: 4.368188858032227
        var_gnorm: 63.73444366455078
        vf_explained_var: 0.9699058532714844
        vf_loss: 33.627532958984375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1031.0
  learner_queue:
    size_count: 1037
    size_mean: 15.2
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5231546211727816
  num_agent_steps_sampled: 532450
  num_agent_steps_trained: 515500
  num_env_steps_sampled: 532450
  num_env_steps_trained: 515500
  num_samples_added_to_queue: 532000
  num_training_step_calls_since_last_synch_worker_weights: 564
  num_weight_broadcasts: 10509
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 264.709
    learner_load_time_ms: 1.589
    learner_load_wait_time_ms: 2.244
iterations_since_restore: 39
node_ip: 127.0.0.1
num_agent_steps_sampled: 532450
num_agent_steps_trained: 515500
num_env_steps_sampled: 532450
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9960947157786
num_env_steps_trained: 515500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9961257100977
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 55.8142857142857
  ram_util_percent: 78.01428571428572
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05845253916011721
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022481001459451776
  mean_inference_ms: 1.0934789248486871
  mean_raw_obs_processing_ms: 0.2498795973341038
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020819425582885742
    StateBufferConnector_ms: 0.003589630126953125
    ViewRequirementAgentConnector_ms: 0.12371206283569336
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.62
  episode_reward_min: 0.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 6.0, 5.0, 5.0, 5.0, 8.0, 6.0, 6.0, 8.0, 3.0, 4.0, 4.0, 6.0,
      8.0, 7.0, 6.0, 7.0, 5.0, 3.0, 4.0, 6.0, 5.0, 6.0, 3.0, 8.0, 6.0, 5.0, 6.0, 4.0,
      3.0, 8.0, 5.0, 3.0, 6.0, 5.0, 4.0, 3.0, 6.0, 3.0, 2.0, 8.0, 4.0, 3.0, 3.0, 4.0,
      8.0, 3.0, 5.0, 7.0, 10.0, 6.0, 8.0, 6.0, 7.0, 9.0, 6.0, 6.0, 12.0, 4.0, 7.0,
      6.0, 8.0, 6.0, 11.0, 6.0, 8.0, 9.0, 12.0, 6.0, 6.0, 8.0, 4.0, 5.0, 4.0, 4.0,
      4.0, 5.0, 6.0, 2.0, 7.0, 7.0, 4.0, 4.0, 3.0, 5.0, 7.0, 6.0, 6.0, 10.0, 4.0,
      0.0, 5.0, 4.0, 4.0, 3.0, 8.0, 7.0, 6.0, 5.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05845253916011721
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022481001459451776
    mean_inference_ms: 1.0934789248486871
    mean_raw_obs_processing_ms: 0.2498795973341038
time_since_restore: 394.7959978580475
time_this_iter_s: 10.197585105895996
time_total_s: 394.7959978580475
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.044
timestamp: 1692000225
timesteps_total: 532450
training_iteration: 39
trial_id: default
train step: 40
agent_timesteps_total: 544450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022029876708984375
  StateBufferConnector_ms: 0.0038628578186035156
  ViewRequirementAgentConnector_ms: 0.1342470645904541
counters:
  num_agent_steps_sampled: 544450
  num_agent_steps_trained: 527500
  num_env_steps_sampled: 544450
  num_env_steps_trained: 527500
  num_samples_added_to_queue: 544000
  num_training_step_calls_since_last_synch_worker_weights: 992
  num_weight_broadcasts: 10745
custom_metrics: {}
date: 2023-08-14_17-03-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.75
episode_reward_min: 0.0
episodes_this_iter: 94
episodes_total: 4254
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.24273094534873962
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.3453874588012695
        total_loss: 5.681354522705078
        var_gnorm: 63.73839569091797
        vf_explained_var: 0.9185070991516113
        vf_loss: 24.480792999267578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1055.0
  learner_queue:
    size_count: 1059
    size_mean: 14.96
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6243152403397563
  num_agent_steps_sampled: 544450
  num_agent_steps_trained: 527500
  num_env_steps_sampled: 544450
  num_env_steps_trained: 527500
  num_samples_added_to_queue: 544000
  num_training_step_calls_since_last_synch_worker_weights: 992
  num_weight_broadcasts: 10745
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 315.6
    learner_load_time_ms: 1.663
    learner_load_wait_time_ms: 1.673
iterations_since_restore: 40
node_ip: 127.0.0.1
num_agent_steps_sampled: 544450
num_agent_steps_trained: 527500
num_env_steps_sampled: 544450
num_env_steps_sampled_this_iter: 12000
num_env_steps_sampled_throughput_per_sec: 1199.9986839308867
num_env_steps_trained: 527500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9986839308867
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 57.36000000000001
  ram_util_percent: 77.09333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05862672593744116
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022560592763196087
  mean_inference_ms: 1.0965999787056675
  mean_raw_obs_processing_ms: 0.2505919953330514
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022029876708984375
    StateBufferConnector_ms: 0.0038628578186035156
    ViewRequirementAgentConnector_ms: 0.1342470645904541
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.75
  episode_reward_min: 0.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 8.0, 7.0, 6.0, 5.0, 1.0, 3.0, 6.0, 7.0, 3.0, 4.0, 5.0, 7.0,
      6.0, 5.0, 7.0, 0.0, 3.0, 2.0, 5.0, 4.0, 3.0, 8.0, 4.0, 6.0, 10.0, 4.0, 5.0,
      5.0, 8.0, 9.0, 5.0, 7.0, 5.0, 4.0, 8.0, 5.0, 7.0, 2.0, 3.0, 5.0, 2.0, 6.0, 6.0,
      9.0, 3.0, 2.0, 4.0, 3.0, 1.0, 2.0, 2.0, 5.0, 2.0, 3.0, 5.0, 4.0, 3.0, 10.0,
      8.0, 6.0, 6.0, 4.0, 8.0, 6.0, 4.0, 9.0, 5.0, 2.0, 8.0, 5.0, 5.0, 3.0, 3.0, 0.0,
      3.0, 6.0, 7.0, 1.0, 4.0, 9.0, 8.0, 8.0, 6.0, 3.0, 11.0, 7.0, 5.0, 6.0, 1.0,
      2.0, 3.0, 3.0, 2.0, 4.0, 1.0, 3.0, 1.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05862672593744116
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022560592763196087
    mean_inference_ms: 1.0965999787056675
    mean_raw_obs_processing_ms: 0.2505919953330514
time_since_restore: 404.9104127883911
time_this_iter_s: 10.114414930343628
time_total_s: 404.9104127883911
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000235
timesteps_total: 544450
training_iteration: 40
trial_id: default
train step: 41
agent_timesteps_total: 555550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023762226104736328
  StateBufferConnector_ms: 0.00426793098449707
  ViewRequirementAgentConnector_ms: 0.143951416015625
counters:
  num_agent_steps_sampled: 555550
  num_agent_steps_trained: 539000
  num_env_steps_sampled: 555550
  num_env_steps_trained: 539000
  num_samples_added_to_queue: 555500
  num_training_step_calls_since_last_synch_worker_weights: 1135
  num_weight_broadcasts: 10964
custom_metrics: {}
date: 2023-08-14_17-04-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 1.24
episode_reward_min: 0.0
episodes_this_iter: 87
episodes_total: 4341
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.19544294476509094
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.981559753417969
        total_loss: 20.06709098815918
        var_gnorm: 63.74152755737305
        vf_explained_var: 0.9416200518608093
        vf_loss: 24.125492095947266
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1078.0
  learner_queue:
    size_count: 1082
    size_mean: 15.24
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3047605144240073
  num_agent_steps_sampled: 555550
  num_agent_steps_trained: 539000
  num_env_steps_sampled: 555550
  num_env_steps_trained: 539000
  num_samples_added_to_queue: 555500
  num_training_step_calls_since_last_synch_worker_weights: 1135
  num_weight_broadcasts: 10964
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 266.621
    learner_load_time_ms: 1.662
    learner_load_wait_time_ms: 1.734
iterations_since_restore: 41
node_ip: 127.0.0.1
num_agent_steps_sampled: 555550
num_agent_steps_trained: 539000
num_env_steps_sampled: 555550
num_env_steps_sampled_this_iter: 11100
num_env_steps_sampled_throughput_per_sec: 1109.9968507379238
num_env_steps_trained: 539000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.996737251002
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 60.07142857142858
  ram_util_percent: 79.12142857142858
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0588779330829772
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02267764189356341
  mean_inference_ms: 1.1010362693666915
  mean_raw_obs_processing_ms: 0.2515731399548643
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023762226104736328
    StateBufferConnector_ms: 0.00426793098449707
    ViewRequirementAgentConnector_ms: 0.143951416015625
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 1.24
  episode_reward_min: 0.0
  episodes_this_iter: 87
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 6.0, 1.0, 2.0, 3.0, 3.0, 2.0, 4.0, 1.0, 3.0, 1.0, 3.0, 4.0,
      1.0, 0.0, 2.0, 1.0, 0.0, 4.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 1.0, 4.0, 0.0,
      0.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0,
      0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 5.0, 1.0,
      1.0, 0.0, 1.0, 0.0, 1.0, 5.0, 3.0, 1.0, 0.0, 0.0, 3.0, 0.0, 0.0, 3.0, 0.0, 2.0,
      0.0, 1.0, 3.0, 0.0, 2.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 0.0, 0.0, 2.0, 1.0,
      1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0588779330829772
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02267764189356341
    mean_inference_ms: 1.1010362693666915
    mean_raw_obs_processing_ms: 0.2515731399548643
time_since_restore: 415.0152599811554
time_this_iter_s: 10.104847192764282
time_total_s: 415.0152599811554
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.044
timestamp: 1692000245
timesteps_total: 555550
training_iteration: 41
trial_id: default
train step: 42
agent_timesteps_total: 567850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021122455596923828
  StateBufferConnector_ms: 0.0036106109619140625
  ViewRequirementAgentConnector_ms: 0.1237037181854248
counters:
  num_agent_steps_sampled: 567850
  num_agent_steps_trained: 551000
  num_env_steps_sampled: 567850
  num_env_steps_trained: 551000
  num_samples_added_to_queue: 567500
  num_training_step_calls_since_last_synch_worker_weights: 485
  num_weight_broadcasts: 11204
custom_metrics: {}
date: 2023-08-14_17-04-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.11
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 4437
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4014573395252228
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.3132494688034058
        total_loss: 1.6521577835083008
        var_gnorm: 63.74253845214844
        vf_explained_var: 0.9922236800193787
        vf_loss: 4.692389965057373
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1102.0
  learner_queue:
    size_count: 1108
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2
  num_agent_steps_sampled: 567850
  num_agent_steps_trained: 551000
  num_env_steps_sampled: 567850
  num_env_steps_trained: 551000
  num_samples_added_to_queue: 567500
  num_training_step_calls_since_last_synch_worker_weights: 485
  num_weight_broadcasts: 11204
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 187.757
    learner_load_time_ms: 1.669
    learner_load_wait_time_ms: 1.626
iterations_since_restore: 42
node_ip: 127.0.0.1
num_agent_steps_sampled: 567850
num_agent_steps_trained: 551000
num_env_steps_sampled: 567850
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.9949560372247
num_env_steps_trained: 551000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9950790607072
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 56.5
  ram_util_percent: 78.83571428571429
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05903066560251499
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022754655000674376
  mean_inference_ms: 1.1039426605047558
  mean_raw_obs_processing_ms: 0.2522016290693966
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021122455596923828
    StateBufferConnector_ms: 0.0036106109619140625
    ViewRequirementAgentConnector_ms: 0.1237037181854248
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.11
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 2.0, 1.0, 4.0, 1.0, 0.0, 0.0,
      5.0, 2.0, 2.0, 0.0, 2.0, 3.0, 1.0, 5.0, 2.0, 2.0, 3.0, 3.0, 2.0, 5.0, 5.0, 0.0,
      2.0, 1.0, 5.0, 6.0, 4.0, 4.0, 4.0, 6.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0,
      1.0, 3.0, 3.0, 0.0, 0.0, 2.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0,
      0.0, 4.0, 4.0, 3.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 5.0, 4.0, 3.0, 1.0,
      4.0, 5.0, 0.0, 6.0, 3.0, 2.0, 2.0, 3.0, 5.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 0.0,
      0.0, 4.0, 3.0, 4.0, 1.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05903066560251499
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022754655000674376
    mean_inference_ms: 1.1039426605047558
    mean_raw_obs_processing_ms: 0.2522016290693966
time_since_restore: 425.16627192497253
time_this_iter_s: 10.151011943817139
time_total_s: 425.16627192497253
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000256
timesteps_total: 567850
training_iteration: 42
trial_id: default
train step: 43
agent_timesteps_total: 579950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021636962890625
  StateBufferConnector_ms: 0.003863811492919922
  ViewRequirementAgentConnector_ms: 0.13218164443969727
counters:
  num_agent_steps_sampled: 579950
  num_agent_steps_trained: 563000
  num_env_steps_sampled: 579950
  num_env_steps_trained: 563000
  num_samples_added_to_queue: 579500
  num_training_step_calls_since_last_synch_worker_weights: 891
  num_weight_broadcasts: 11443
custom_metrics: {}
date: 2023-08-14_17-04-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 2.64
episode_reward_min: 0.0
episodes_this_iter: 94
episodes_total: 4531
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8128393292427063
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.044225692749023
        total_loss: 11.194647789001465
        var_gnorm: 63.73465347290039
        vf_explained_var: 0.9643238186836243
        vf_loss: 14.429237365722656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1126.0
  learner_queue:
    size_count: 1131
    size_mean: 15.22
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3753544997563356
  num_agent_steps_sampled: 579950
  num_agent_steps_trained: 563000
  num_env_steps_sampled: 579950
  num_env_steps_trained: 563000
  num_samples_added_to_queue: 579500
  num_training_step_calls_since_last_synch_worker_weights: 891
  num_weight_broadcasts: 11443
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 221.962
    learner_load_time_ms: 1.453
    learner_load_wait_time_ms: 1.537
iterations_since_restore: 43
node_ip: 127.0.0.1
num_agent_steps_sampled: 579950
num_agent_steps_trained: 563000
num_env_steps_sampled: 579950
num_env_steps_sampled_this_iter: 12100
num_env_steps_sampled_throughput_per_sec: 1209.9973747787212
num_env_steps_trained: 563000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9973964747649
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.721428571428575
  ram_util_percent: 78.87857142857142
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05916550834286781
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022805570100386453
  mean_inference_ms: 1.1066514160129572
  mean_raw_obs_processing_ms: 0.25276477655830853
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021636962890625
    StateBufferConnector_ms: 0.003863811492919922
    ViewRequirementAgentConnector_ms: 0.13218164443969727
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 2.64
  episode_reward_min: 0.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 4.0, 1.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 1.0,
      0.0, 0.0, 3.0, 2.0, 1.0, 4.0, 3.0, 0.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0,
      1.0, 3.0, 0.0, 3.0, 4.0, 2.0, 6.0, 2.0, 8.0, 0.0, 5.0, 7.0, 2.0, 3.0, 3.0, 2.0,
      5.0, 4.0, 8.0, 6.0, 7.0, 2.0, 6.0, 7.0, 0.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 1.0,
      4.0, 0.0, 4.0, 1.0, 2.0, 2.0, 0.0, 2.0, 5.0, 2.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0,
      2.0, 0.0, 3.0, 4.0, 1.0, 0.0, 4.0, 1.0, 3.0, 4.0, 4.0, 2.0, 3.0, 4.0, 7.0, 4.0,
      5.0, 5.0, 10.0, 6.0, 9.0, 6.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05916550834286781
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022805570100386453
    mean_inference_ms: 1.1066514160129572
    mean_raw_obs_processing_ms: 0.25276477655830853
time_since_restore: 435.28722190856934
time_this_iter_s: 10.120949983596802
time_total_s: 435.28722190856934
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000266
timesteps_total: 579950
training_iteration: 43
trial_id: default
train step: 44
agent_timesteps_total: 593250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020137199988731973
  StateBufferConnector_ms: 0.003461883618281438
  ViewRequirementAgentConnector_ms: 0.11866940901829647
counters:
  num_agent_steps_sampled: 593250
  num_agent_steps_trained: 576500
  num_env_steps_sampled: 593250
  num_env_steps_trained: 576500
  num_samples_added_to_queue: 593000
  num_training_step_calls_since_last_synch_worker_weights: 717
  num_weight_broadcasts: 11705
custom_metrics: {}
date: 2023-08-14_17-04-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.403846153846154
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 4635
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7609619498252869
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 19.517152786254883
        total_loss: 29.09752655029297
        var_gnorm: 63.74231719970703
        vf_explained_var: 0.9536033272743225
        vf_loss: 26.770368576049805
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1153.0
  learner_queue:
    size_count: 1158
    size_mean: 15.36
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2126005112979295
  num_agent_steps_sampled: 593250
  num_agent_steps_trained: 576500
  num_env_steps_sampled: 593250
  num_env_steps_trained: 576500
  num_samples_added_to_queue: 593000
  num_training_step_calls_since_last_synch_worker_weights: 717
  num_weight_broadcasts: 11705
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 211.034
    learner_load_time_ms: 1.457
    learner_load_wait_time_ms: 1.511
iterations_since_restore: 44
node_ip: 127.0.0.1
num_agent_steps_sampled: 593250
num_agent_steps_trained: 576500
num_env_steps_sampled: 593250
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1329.9942922837113
num_env_steps_trained: 576500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9942064533911
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.833333333333336
  ram_util_percent: 79.24000000000001
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05920620100999992
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022827462506864404
  mean_inference_ms: 1.1072771008371465
  mean_raw_obs_processing_ms: 0.2529635671666582
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020137199988731973
    StateBufferConnector_ms: 0.003461883618281438
    ViewRequirementAgentConnector_ms: 0.11866940901829647
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.403846153846154
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 8.0, 8.0, 7.0, 8.0, 10.0, 4.0, 9.0, 5.0, 10.0, 2.0, 10.0,
      8.0, 7.0, 4.0, 6.0, 5.0, 9.0, 4.0, 11.0, 3.0, 8.0, 4.0, 6.0, 8.0, 8.0, 9.0,
      6.0, 8.0, 3.0, 6.0, 7.0, 7.0, 7.0, 7.0, 7.0, 2.0, 5.0, 4.0, 3.0, 6.0, 5.0, 4.0,
      6.0, 2.0, 7.0, 13.0, 10.0, 5.0, 6.0, 5.0, 5.0, 6.0, 6.0, 7.0, 5.0, 3.0, 7.0,
      8.0, 6.0, 5.0, 4.0, 6.0, 9.0, 7.0, 9.0, 10.0, 8.0, 1.0, 4.0, 9.0, 10.0, 9.0,
      3.0, 9.0, 4.0, 3.0, 4.0, 6.0, 6.0, 6.0, 11.0, 7.0, 7.0, 4.0, 6.0, 9.0, 7.0,
      7.0, 4.0, 7.0, 4.0, 5.0, 11.0, 3.0, 5.0, 6.0, 4.0, 7.0, 7.0, 9.0, 10.0, 6.0,
      3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05920620100999992
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022827462506864404
    mean_inference_ms: 1.1072771008371465
    mean_raw_obs_processing_ms: 0.2529635671666582
time_since_restore: 445.4278178215027
time_this_iter_s: 10.14059591293335
time_total_s: 445.4278178215027
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000276
timesteps_total: 593250
training_iteration: 44
trial_id: default
train step: 45
agent_timesteps_total: 604650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02370476722717285
  StateBufferConnector_ms: 0.003916501998901367
  ViewRequirementAgentConnector_ms: 0.13208603858947754
counters:
  num_agent_steps_sampled: 604650
  num_agent_steps_trained: 588000
  num_env_steps_sampled: 604650
  num_env_steps_trained: 588000
  num_samples_added_to_queue: 604500
  num_training_step_calls_since_last_synch_worker_weights: 160
  num_weight_broadcasts: 11930
custom_metrics: {}
date: 2023-08-14_17-04-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 3.99
episode_reward_min: 0.0
episodes_this_iter: 89
episodes_total: 4724
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4360486567020416
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.154409408569336
        total_loss: 6.317278861999512
        var_gnorm: 63.76106262207031
        vf_explained_var: 0.913992166519165
        vf_loss: 49.303863525390625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1176.0
  learner_queue:
    size_count: 1180
    size_mean: 15.34
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2427389106324787
  num_agent_steps_sampled: 604650
  num_agent_steps_trained: 588000
  num_env_steps_sampled: 604650
  num_env_steps_trained: 588000
  num_samples_added_to_queue: 604500
  num_training_step_calls_since_last_synch_worker_weights: 160
  num_weight_broadcasts: 11930
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 361.079
    learner_load_time_ms: 1.454
    learner_load_wait_time_ms: 2.083
iterations_since_restore: 45
node_ip: 127.0.0.1
num_agent_steps_sampled: 604650
num_agent_steps_trained: 588000
num_env_steps_sampled: 604650
num_env_steps_sampled_this_iter: 11400
num_env_steps_sampled_throughput_per_sec: 1139.9948630564422
num_env_steps_trained: 588000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9948179955338
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 60.585714285714296
  ram_util_percent: 80.42857142857144
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05943887070247307
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022909632480577532
  mean_inference_ms: 1.1106436290567674
  mean_raw_obs_processing_ms: 0.25368235310291193
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02370476722717285
    StateBufferConnector_ms: 0.003916501998901367
    ViewRequirementAgentConnector_ms: 0.13208603858947754
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 3.99
  episode_reward_min: 0.0
  episodes_this_iter: 89
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 3.0, 5.0, 6.0, 4.0, 7.0, 7.0, 9.0, 10.0, 6.0, 3.0, 8.0,
      5.0, 7.0, 6.0, 5.0, 9.0, 2.0, 2.0, 4.0, 2.0, 6.0, 1.0, 2.0, 9.0, 3.0, 2.0, 3.0,
      2.0, 6.0, 2.0, 6.0, 4.0, 1.0, 3.0, 4.0, 1.0, 2.0, 5.0, 2.0, 2.0, 3.0, 2.0, 1.0,
      2.0, 2.0, 1.0, 4.0, 1.0, 5.0, 3.0, 1.0, 3.0, 3.0, 3.0, 7.0, 1.0, 6.0, 6.0, 2.0,
      4.0, 6.0, 8.0, 4.0, 5.0, 4.0, 7.0, 5.0, 4.0, 5.0, 4.0, 5.0, 2.0, 6.0, 4.0, 5.0,
      4.0, 3.0, 5.0, 3.0, 0.0, 1.0, 2.0, 7.0, 0.0, 4.0, 6.0, 1.0, 5.0, 4.0, 0.0, 4.0,
      2.0, 2.0, 2.0, 3.0, 6.0, 5.0, 4.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05943887070247307
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022909632480577532
    mean_inference_ms: 1.1106436290567674
    mean_raw_obs_processing_ms: 0.25368235310291193
time_since_restore: 455.6129128932953
time_this_iter_s: 10.185095071792603
time_total_s: 455.6129128932953
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1692000286
timesteps_total: 604650
training_iteration: 45
trial_id: default
train step: 46
agent_timesteps_total: 617700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020668553371055453
  StateBufferConnector_ms: 0.0034374349257525277
  ViewRequirementAgentConnector_ms: 0.12106801949295343
counters:
  num_agent_steps_sampled: 617700
  num_agent_steps_trained: 601000
  num_env_steps_sampled: 617700
  num_env_steps_trained: 601000
  num_samples_added_to_queue: 617500
  num_training_step_calls_since_last_synch_worker_weights: 572
  num_weight_broadcasts: 12188
custom_metrics: {}
date: 2023-08-14_17-04-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 5.911764705882353
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 4826
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8527794480323792
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -5.697117805480957
        total_loss: -5.146135330200195
        var_gnorm: 63.75957489013672
        vf_explained_var: 0.9836480021476746
        vf_loss: 9.629758834838867
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1202.0
  learner_queue:
    size_count: 1207
    size_mean: 15.34
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2427389106324787
  num_agent_steps_sampled: 617700
  num_agent_steps_trained: 601000
  num_env_steps_sampled: 617700
  num_env_steps_trained: 601000
  num_samples_added_to_queue: 617500
  num_training_step_calls_since_last_synch_worker_weights: 572
  num_weight_broadcasts: 12188
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 204.266
    learner_load_time_ms: 1.399
    learner_load_wait_time_ms: 1.552
iterations_since_restore: 46
node_ip: 127.0.0.1
num_agent_steps_sampled: 617700
num_agent_steps_trained: 601000
num_env_steps_sampled: 617700
num_env_steps_sampled_this_iter: 13050
num_env_steps_sampled_throughput_per_sec: 1304.9993466142112
num_env_steps_trained: 601000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9993491176049
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.34
  ram_util_percent: 79.82
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.059514344889092526
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022953544707343756
  mean_inference_ms: 1.1119914720251314
  mean_raw_obs_processing_ms: 0.2539692580122981
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020668553371055453
    StateBufferConnector_ms: 0.0034374349257525277
    ViewRequirementAgentConnector_ms: 0.12106801949295343
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 5.911764705882353
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 2.0, 1.0, 3.0, 3.0, 8.0, 5.0, 5.0, 2.0, 6.0, 7.0, 3.0,
      6.0, 8.0, 4.0, 2.0, 4.0, 2.0, 5.0, 7.0, 7.0, 7.0, 2.0, 5.0, 7.0, 4.0, 8.0, 9.0,
      4.0, 8.0, 5.0, 12.0, 5.0, 9.0, 5.0, 5.0, 8.0, 8.0, 6.0, 6.0, 10.0, 9.0, 11.0,
      6.0, 7.0, 6.0, 14.0, 5.0, 5.0, 7.0, 9.0, 4.0, 2.0, 4.0, 4.0, 5.0, 3.0, 1.0,
      4.0, 2.0, 3.0, 5.0, 5.0, 1.0, 5.0, 5.0, 3.0, 7.0, 5.0, 3.0, 3.0, 6.0, 5.0, 4.0,
      6.0, 5.0, 6.0, 5.0, 5.0, 10.0, 0.0, 5.0, 7.0, 9.0, 6.0, 8.0, 13.0, 11.0, 7.0,
      7.0, 10.0, 8.0, 7.0, 7.0, 13.0, 9.0, 7.0, 9.0, 7.0, 5.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.059514344889092526
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022953544707343756
    mean_inference_ms: 1.1119914720251314
    mean_raw_obs_processing_ms: 0.2539692580122981
time_since_restore: 465.7371280193329
time_this_iter_s: 10.124215126037598
time_total_s: 465.7371280193329
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000296
timesteps_total: 617700
training_iteration: 46
trial_id: default
train step: 47
agent_timesteps_total: 631200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01978356883210956
  StateBufferConnector_ms: 0.0033862185928056824
  ViewRequirementAgentConnector_ms: 0.11697287829417102
counters:
  num_agent_steps_sampled: 631200
  num_agent_steps_trained: 614500
  num_env_steps_sampled: 631200
  num_env_steps_trained: 614500
  num_samples_added_to_queue: 631000
  num_training_step_calls_since_last_synch_worker_weights: 941
  num_weight_broadcasts: 12452
custom_metrics: {}
date: 2023-08-14_17-05-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.9245283018867925
episode_reward_min: 2.0
episodes_this_iter: 106
episodes_total: 4932
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5430506467819214
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.1896073818206787
        total_loss: 6.7110724449157715
        var_gnorm: 63.77879333496094
        vf_explained_var: 0.9713402986526489
        vf_loss: 18.47343635559082
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1229.0
  learner_queue:
    size_count: 1234
    size_mean: 15.42
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.201499063670047
  num_agent_steps_sampled: 631200
  num_agent_steps_trained: 614500
  num_env_steps_sampled: 631200
  num_env_steps_trained: 614500
  num_samples_added_to_queue: 631000
  num_training_step_calls_since_last_synch_worker_weights: 941
  num_weight_broadcasts: 12452
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 211.482
    learner_load_time_ms: 1.376
    learner_load_wait_time_ms: 1.576
iterations_since_restore: 47
node_ip: 127.0.0.1
num_agent_steps_sampled: 631200
num_agent_steps_trained: 614500
num_env_steps_sampled: 631200
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9948501783365
num_env_steps_trained: 614500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9948501783365
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.964285714285715
  ram_util_percent: 77.75714285714285
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05950642447438776
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022951157049851414
  mean_inference_ms: 1.1118996905198488
  mean_raw_obs_processing_ms: 0.25396103676580184
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01978356883210956
    StateBufferConnector_ms: 0.0033862185928056824
    ViewRequirementAgentConnector_ms: 0.11697287829417102
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.9245283018867925
  episode_reward_min: 2.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 5.0, 6.0, 6.0, 6.0, 6.0, 6.0, 6.0, 3.0, 10.0, 8.0,
      10.0, 6.0, 10.0, 9.0, 5.0, 8.0, 9.0, 8.0, 9.0, 10.0, 8.0, 11.0, 8.0, 2.0, 9.0,
      10.0, 7.0, 6.0, 8.0, 12.0, 8.0, 8.0, 12.0, 11.0, 7.0, 10.0, 7.0, 3.0, 6.0, 3.0,
      6.0, 5.0, 9.0, 9.0, 3.0, 10.0, 8.0, 9.0, 11.0, 8.0, 12.0, 13.0, 10.0, 5.0, 4.0,
      11.0, 6.0, 7.0, 7.0, 5.0, 6.0, 8.0, 9.0, 8.0, 7.0, 5.0, 9.0, 7.0, 11.0, 7.0,
      9.0, 9.0, 7.0, 12.0, 6.0, 9.0, 14.0, 7.0, 6.0, 15.0, 7.0, 8.0, 11.0, 9.0, 9.0,
      4.0, 6.0, 7.0, 8.0, 10.0, 5.0, 9.0, 10.0, 11.0, 9.0, 8.0, 10.0, 12.0, 8.0, 6.0,
      11.0, 8.0, 8.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05950642447438776
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022951157049851414
    mean_inference_ms: 1.1118996905198488
    mean_raw_obs_processing_ms: 0.25396103676580184
time_since_restore: 475.86854219436646
time_this_iter_s: 10.13141417503357
time_total_s: 475.86854219436646
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1692000306
timesteps_total: 631200
training_iteration: 47
trial_id: default
train step: 48
agent_timesteps_total: 643600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020808935165405273
  StateBufferConnector_ms: 0.0037336349487304688
  ViewRequirementAgentConnector_ms: 0.12390780448913574
counters:
  num_agent_steps_sampled: 643600
  num_agent_steps_trained: 627000
  num_env_steps_sampled: 643600
  num_env_steps_trained: 627000
  num_samples_added_to_queue: 643500
  num_training_step_calls_since_last_synch_worker_weights: 658
  num_weight_broadcasts: 12697
custom_metrics: {}
date: 2023-08-14_17-05-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.37
episode_reward_min: 3.0
episodes_this_iter: 96
episodes_total: 5028
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7587474584579468
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.948707580566406
        total_loss: 43.82964324951172
        var_gnorm: 63.79088592529297
        vf_explained_var: 0.894011378288269
        vf_loss: 113.14417266845703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1254.0
  learner_queue:
    size_count: 1259
    size_mean: 15.42
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1677328461596
  num_agent_steps_sampled: 643600
  num_agent_steps_trained: 627000
  num_env_steps_sampled: 643600
  num_env_steps_trained: 627000
  num_samples_added_to_queue: 643500
  num_training_step_calls_since_last_synch_worker_weights: 658
  num_weight_broadcasts: 12697
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 254.61
    learner_load_time_ms: 1.381
    learner_load_wait_time_ms: 1.723
iterations_since_restore: 48
node_ip: 127.0.0.1
num_agent_steps_sampled: 643600
num_agent_steps_trained: 627000
num_env_steps_sampled: 643600
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.999497413839
num_env_steps_trained: 627000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9994933607247
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 55.364285714285714
  ram_util_percent: 72.20714285714287
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05959969460477045
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023001790656583098
  mean_inference_ms: 1.1135619432433888
  mean_raw_obs_processing_ms: 0.2543226111988964
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020808935165405273
    StateBufferConnector_ms: 0.0037336349487304688
    ViewRequirementAgentConnector_ms: 0.12390780448913574
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.37
  episode_reward_min: 3.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 8.0, 8.0, 8.0, 7.0, 8.0, 11.0, 7.0, 7.0, 3.0, 7.0, 10.0,
      7.0, 6.0, 9.0, 9.0, 6.0, 4.0, 7.0, 6.0, 12.0, 7.0, 9.0, 13.0, 8.0, 10.0, 9.0,
      9.0, 10.0, 7.0, 8.0, 6.0, 13.0, 10.0, 12.0, 5.0, 8.0, 8.0, 8.0, 8.0, 10.0, 7.0,
      9.0, 9.0, 15.0, 6.0, 8.0, 7.0, 8.0, 9.0, 8.0, 13.0, 4.0, 7.0, 6.0, 9.0, 8.0,
      9.0, 8.0, 10.0, 7.0, 13.0, 9.0, 7.0, 8.0, 8.0, 11.0, 7.0, 6.0, 10.0, 6.0, 8.0,
      4.0, 9.0, 8.0, 8.0, 12.0, 11.0, 8.0, 8.0, 11.0, 8.0, 7.0, 7.0, 6.0, 9.0, 9.0,
      6.0, 10.0, 7.0, 9.0, 6.0, 13.0, 8.0, 8.0, 12.0, 7.0, 7.0, 11.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05959969460477045
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023001790656583098
    mean_inference_ms: 1.1135619432433888
    mean_raw_obs_processing_ms: 0.2543226111988964
time_since_restore: 485.9985764026642
time_this_iter_s: 10.13003420829773
time_total_s: 485.9985764026642
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000316
timesteps_total: 643600
training_iteration: 48
trial_id: default
train step: 49
agent_timesteps_total: 656500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020541163051829618
  StateBufferConnector_ms: 0.003512232911353018
  ViewRequirementAgentConnector_ms: 0.12168650533638749
counters:
  num_agent_steps_sampled: 656500
  num_agent_steps_trained: 640000
  num_env_steps_sampled: 656500
  num_env_steps_trained: 640000
  num_samples_added_to_queue: 656500
  num_training_step_calls_since_last_synch_worker_weights: 614
  num_weight_broadcasts: 12948
custom_metrics: {}
date: 2023-08-14_17-05-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.186274509803922
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 5130
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.49259984493255615
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.1181573867797852
        total_loss: 15.252351760864258
        var_gnorm: 63.8081169128418
        vf_explained_var: 0.9037295579910278
        vf_loss: 33.19438934326172
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1280.0
  learner_queue:
    size_count: 1284
    size_mean: 15.46
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.0992724866929038
  num_agent_steps_sampled: 656500
  num_agent_steps_trained: 640000
  num_env_steps_sampled: 656500
  num_env_steps_trained: 640000
  num_samples_added_to_queue: 656500
  num_training_step_calls_since_last_synch_worker_weights: 614
  num_weight_broadcasts: 12948
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 246.005
    learner_load_time_ms: 1.365
    learner_load_wait_time_ms: 1.47
iterations_since_restore: 49
node_ip: 127.0.0.1
num_agent_steps_sampled: 656500
num_agent_steps_trained: 640000
num_env_steps_sampled: 656500
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.999876976025
num_env_steps_trained: 640000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9998760223507
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.41428571428572
  ram_util_percent: 74.74285714285713
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.059650136047687395
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023036896161405824
  mean_inference_ms: 1.114576262622088
  mean_raw_obs_processing_ms: 0.2545157669512677
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020541163051829618
    StateBufferConnector_ms: 0.003512232911353018
    ViewRequirementAgentConnector_ms: 0.12168650533638749
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.186274509803922
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 8.0, 11.0, 9.0, 12.0, 8.0, 4.0, 10.0, 5.0, 9.0, 12.0, 8.0,
      5.0, 9.0, 7.0, 9.0, 5.0, 13.0, 7.0, 6.0, 11.0, 8.0, 6.0, 10.0, 5.0, 8.0, 8.0,
      3.0, 3.0, 6.0, 3.0, 6.0, 7.0, 8.0, 7.0, 7.0, 8.0, 6.0, 10.0, 5.0, 4.0, 2.0,
      7.0, 0.0, 9.0, 5.0, 6.0, 2.0, 5.0, 6.0, 9.0, 9.0, 9.0, 14.0, 8.0, 12.0, 7.0,
      9.0, 7.0, 9.0, 9.0, 5.0, 12.0, 6.0, 11.0, 10.0, 9.0, 9.0, 6.0, 12.0, 5.0, 11.0,
      5.0, 4.0, 5.0, 10.0, 10.0, 4.0, 8.0, 12.0, 6.0, 8.0, 6.0, 8.0, 5.0, 11.0, 1.0,
      13.0, 6.0, 5.0, 4.0, 3.0, 5.0, 8.0, 2.0, 4.0, 6.0, 5.0, 7.0, 8.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.059650136047687395
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023036896161405824
    mean_inference_ms: 1.114576262622088
    mean_raw_obs_processing_ms: 0.2545157669512677
time_since_restore: 496.10781741142273
time_this_iter_s: 10.109241008758545
time_total_s: 496.10781741142273
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000327
timesteps_total: 656500
training_iteration: 49
trial_id: default
train step: 50
agent_timesteps_total: 669900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01958471078139085
  StateBufferConnector_ms: 0.0033518442740807165
  ViewRequirementAgentConnector_ms: 0.11685628157395583
counters:
  num_agent_steps_sampled: 669900
  num_agent_steps_trained: 653000
  num_env_steps_sampled: 669900
  num_env_steps_trained: 653000
  num_samples_added_to_queue: 669500
  num_training_step_calls_since_last_synch_worker_weights: 1026
  num_weight_broadcasts: 13213
custom_metrics: {}
date: 2023-08-14_17-05-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.673076923076923
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 5234
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.1811593472957611
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -43.467044830322266
        total_loss: 105.19586944580078
        var_gnorm: 63.82876205444336
        vf_explained_var: 0.8391631245613098
        vf_loss: 299.1374206542969
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1306.0
  learner_queue:
    size_count: 1310
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9165151389911681
  num_agent_steps_sampled: 669900
  num_agent_steps_trained: 653000
  num_env_steps_sampled: 669900
  num_env_steps_trained: 653000
  num_samples_added_to_queue: 669500
  num_training_step_calls_since_last_synch_worker_weights: 1026
  num_weight_broadcasts: 13213
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 275.105
    learner_load_time_ms: 1.361
    learner_load_wait_time_ms: 1.591
iterations_since_restore: 50
node_ip: 127.0.0.1
num_agent_steps_sampled: 669900
num_agent_steps_trained: 653000
num_env_steps_sampled: 669900
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9982428573762
num_env_steps_trained: 653000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9982953093947
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.28666666666667
  ram_util_percent: 74.81333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05964771905953238
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02302738164449658
  mean_inference_ms: 1.114532660073412
  mean_raw_obs_processing_ms: 0.25454742995252205
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01958471078139085
    StateBufferConnector_ms: 0.0033518442740807165
    ViewRequirementAgentConnector_ms: 0.11685628157395583
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.673076923076923
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 6.0, 5.0,
      2.0, 9.0, 3.0, 3.0, 3.0, 5.0, 4.0, 6.0, 4.0, 6.0, 4.0, 4.0, 4.0, 1.0, 1.0, 5.0,
      1.0, 2.0, 2.0, 2.0, 2.0, 5.0, 1.0, 2.0, 0.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0,
      0.0, 1.0, 0.0, 1.0, 3.0, 2.0, 0.0, 4.0, 4.0, 7.0, 4.0, 4.0, 5.0, 4.0, 1.0, 7.0,
      3.0, 3.0, 4.0, 0.0, 5.0, 0.0, 6.0, 5.0, 2.0, 4.0, 1.0, 3.0, 0.0, 3.0, 3.0, 2.0,
      4.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 4.0, 5.0, 2.0, 0.0, 3.0, 3.0, 0.0,
      1.0, 1.0, 2.0, 0.0, 2.0, 1.0, 3.0, 0.0, 4.0, 0.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05964771905953238
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02302738164449658
    mean_inference_ms: 1.114532660073412
    mean_raw_obs_processing_ms: 0.25454742995252205
time_since_restore: 506.2157883644104
time_this_iter_s: 10.107970952987671
time_total_s: 506.2157883644104
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000337
timesteps_total: 669900
training_iteration: 50
trial_id: default
train step: 51
agent_timesteps_total: 682100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021857738494873047
  StateBufferConnector_ms: 0.003676891326904297
  ViewRequirementAgentConnector_ms: 0.12968754768371582
counters:
  num_agent_steps_sampled: 682100
  num_agent_steps_trained: 665500
  num_env_steps_sampled: 682100
  num_env_steps_trained: 665500
  num_samples_added_to_queue: 682000
  num_training_step_calls_since_last_synch_worker_weights: 1166
  num_weight_broadcasts: 13453
custom_metrics: {}
date: 2023-08-14_17-05-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.45
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 5330
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.2455137073993683
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.7284564971923828
        total_loss: 128.79397583007812
        var_gnorm: 63.821319580078125
        vf_explained_var: 0.7301409244537354
        vf_loss: 258.586181640625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1331.0
  learner_queue:
    size_count: 1335
    size_mean: 15.62
    size_quantiles: [13.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.845931439302264
  num_agent_steps_sampled: 682100
  num_agent_steps_trained: 665500
  num_env_steps_sampled: 682100
  num_env_steps_trained: 665500
  num_samples_added_to_queue: 682000
  num_training_step_calls_since_last_synch_worker_weights: 1166
  num_weight_broadcasts: 13453
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 265.375
    learner_load_time_ms: 1.427
    learner_load_wait_time_ms: 1.626
iterations_since_restore: 51
node_ip: 127.0.0.1
num_agent_steps_sampled: 682100
num_agent_steps_trained: 665500
num_env_steps_sampled: 682100
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.9993600848693
num_env_steps_trained: 665500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9993443492513
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 55.2
  ram_util_percent: 75.13571428571429
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05975362240371961
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023064357677226133
  mean_inference_ms: 1.1162715099565679
  mean_raw_obs_processing_ms: 0.25498998466555106
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021857738494873047
    StateBufferConnector_ms: 0.003676891326904297
    ViewRequirementAgentConnector_ms: 0.12968754768371582
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.45
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 4.0, 0.0, 2.0, 4.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 0.0, 4.0,
      3.0, 2.0, 0.0, 3.0, 3.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 2.0, 3.0, 0.0, 2.0, 2.0,
      3.0, 4.0, 2.0, 6.0, 4.0, 4.0, 0.0, 1.0, 2.0, 5.0, 1.0, 2.0, 3.0, 3.0, 3.0, 3.0,
      4.0, 8.0, 4.0, 4.0, 3.0, 6.0, 4.0, 0.0, 4.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0,
      2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 3.0, 2.0, 1.0, 5.0, 2.0, 1.0, 3.0, 1.0,
      2.0, 2.0, 6.0, 1.0, 2.0, 5.0, 3.0, 5.0, 3.0, 3.0, 1.0, 5.0, 3.0, 2.0, 4.0, 6.0,
      4.0, 3.0, 3.0, 5.0, 3.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05975362240371961
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023064357677226133
    mean_inference_ms: 1.1162715099565679
    mean_raw_obs_processing_ms: 0.25498998466555106
time_since_restore: 516.3066983222961
time_this_iter_s: 10.090909957885742
time_total_s: 516.3066983222961
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1692000347
timesteps_total: 682100
training_iteration: 51
trial_id: default
train step: 52
agent_timesteps_total: 694100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022370100021362305
  StateBufferConnector_ms: 0.003937244415283203
  ViewRequirementAgentConnector_ms: 0.13403582572937012
counters:
  num_agent_steps_sampled: 694100
  num_agent_steps_trained: 677500
  num_env_steps_sampled: 694100
  num_env_steps_trained: 677500
  num_samples_added_to_queue: 694000
  num_training_step_calls_since_last_synch_worker_weights: 320
  num_weight_broadcasts: 13690
custom_metrics: {}
date: 2023-08-14_17-05-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.76
episode_reward_min: 0.0
episodes_this_iter: 94
episodes_total: 5424
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4037408232688904
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.031320810317993
        total_loss: 15.387834548950195
        var_gnorm: 63.816951751708984
        vf_explained_var: 0.7683278322219849
        vf_loss: 28.75043487548828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1355.0
  learner_queue:
    size_count: 1361
    size_mean: 15.5
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.118033988749895
  num_agent_steps_sampled: 694100
  num_agent_steps_trained: 677500
  num_env_steps_sampled: 694100
  num_env_steps_trained: 677500
  num_samples_added_to_queue: 694000
  num_training_step_calls_since_last_synch_worker_weights: 320
  num_weight_broadcasts: 13690
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 190.396
    learner_load_time_ms: 1.42
    learner_load_wait_time_ms: 1.608
iterations_since_restore: 52
node_ip: 127.0.0.1
num_agent_steps_sampled: 694100
num_agent_steps_trained: 677500
num_env_steps_sampled: 694100
num_env_steps_sampled_this_iter: 12000
num_env_steps_sampled_throughput_per_sec: 1199.9983119988344
num_env_steps_trained: 677500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9983119988344
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.76428571428572
  ram_util_percent: 76.18571428571428
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.059885735301428954
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023125052819004475
  mean_inference_ms: 1.1185078313217314
  mean_raw_obs_processing_ms: 0.2555102023859838
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022370100021362305
    StateBufferConnector_ms: 0.003937244415283203
    ViewRequirementAgentConnector_ms: 0.13403582572937012
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.76
  episode_reward_min: 0.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 5.0, 3.0, 2.0, 1.0, 5.0, 5.0, 4.0, 5.0, 6.0, 7.0, 3.0,
      5.0, 3.0, 2.0, 8.0, 0.0, 3.0, 4.0, 2.0, 3.0, 2.0, 4.0, 1.0, 0.0, 6.0, 5.0, 2.0,
      4.0, 5.0, 6.0, 4.0, 2.0, 2.0, 5.0, 4.0, 6.0, 8.0, 4.0, 6.0, 1.0, 3.0, 7.0, 7.0,
      10.0, 5.0, 5.0, 2.0, 4.0, 6.0, 5.0, 4.0, 3.0, 2.0, 2.0, 3.0, 4.0, 1.0, 5.0,
      3.0, 7.0, 3.0, 4.0, 0.0, 1.0, 2.0, 3.0, 6.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 4.0,
      4.0, 5.0, 2.0, 1.0, 3.0, 9.0, 3.0, 5.0, 4.0, 7.0, 4.0, 1.0, 9.0, 4.0, 3.0, 6.0,
      6.0, 1.0, 2.0, 5.0, 1.0, 2.0, 4.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.059885735301428954
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023125052819004475
    mean_inference_ms: 1.1185078313217314
    mean_raw_obs_processing_ms: 0.2555102023859838
time_since_restore: 526.4775006771088
time_this_iter_s: 10.170802354812622
time_total_s: 526.4775006771088
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1692000357
timesteps_total: 694100
training_iteration: 52
trial_id: default
train step: 53
agent_timesteps_total: 706800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020970582962036133
  StateBufferConnector_ms: 0.0036001205444335938
  ViewRequirementAgentConnector_ms: 0.12500572204589844
counters:
  num_agent_steps_sampled: 706800
  num_agent_steps_trained: 690000
  num_env_steps_sampled: 706800
  num_env_steps_trained: 690000
  num_samples_added_to_queue: 706500
  num_training_step_calls_since_last_synch_worker_weights: 1369
  num_weight_broadcasts: 13939
custom_metrics: {}
date: 2023-08-14_17-06-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.75
episode_reward_min: 0.0
episodes_this_iter: 98
episodes_total: 5522
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4071789085865021
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.7514805793762207
        total_loss: 9.469413757324219
        var_gnorm: 63.822235107421875
        vf_explained_var: 0.8855964541435242
        vf_loss: 17.507654190063477
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1380.0
  learner_queue:
    size_count: 1383
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2718490476467716
  num_agent_steps_sampled: 706800
  num_agent_steps_trained: 690000
  num_env_steps_sampled: 706800
  num_env_steps_trained: 690000
  num_samples_added_to_queue: 706500
  num_training_step_calls_since_last_synch_worker_weights: 1369
  num_weight_broadcasts: 13939
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 306.827
    learner_load_time_ms: 1.423
    learner_load_wait_time_ms: 1.629
iterations_since_restore: 53
node_ip: 127.0.0.1
num_agent_steps_sampled: 706800
num_agent_steps_trained: 690000
num_env_steps_sampled: 706800
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.9978501833114
num_env_steps_trained: 690000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9978840386923
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 55.59333333333334
  ram_util_percent: 76.32
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05995253925239414
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023157410495580823
  mean_inference_ms: 1.1196580893966148
  mean_raw_obs_processing_ms: 0.255752806337812
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020970582962036133
    StateBufferConnector_ms: 0.0036001205444335938
    ViewRequirementAgentConnector_ms: 0.12500572204589844
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.75
  episode_reward_min: 0.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 0.0, 1.0, 2.0, 0.0, 1.0, 4.0, 3.0, 1.0, 2.0, 4.0, 2.0, 3.0,
      0.0, 0.0, 1.0, 2.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 5.0, 1.0, 1.0, 4.0, 5.0, 2.0,
      2.0, 2.0, 4.0, 7.0, 2.0, 2.0, 6.0, 3.0, 2.0, 7.0, 4.0, 7.0, 3.0, 4.0, 1.0, 7.0,
      6.0, 3.0, 4.0, 4.0, 7.0, 3.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 6.0, 3.0,
      3.0, 3.0, 0.0, 2.0, 2.0, 4.0, 4.0, 2.0, 4.0, 0.0, 3.0, 3.0, 3.0, 1.0, 1.0, 2.0,
      1.0, 0.0, 3.0, 5.0, 3.0, 2.0, 2.0, 3.0, 5.0, 2.0, 1.0, 3.0, 4.0, 3.0, 8.0, 2.0,
      4.0, 6.0, 5.0, 4.0, 4.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05995253925239414
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023157410495580823
    mean_inference_ms: 1.1196580893966148
    mean_raw_obs_processing_ms: 0.255752806337812
time_since_restore: 536.561642408371
time_this_iter_s: 10.084141731262207
time_total_s: 536.561642408371
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000367
timesteps_total: 706800
training_iteration: 53
trial_id: default
train step: 54
agent_timesteps_total: 719400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020914077758789062
  StateBufferConnector_ms: 0.0036759376525878906
  ViewRequirementAgentConnector_ms: 0.12428736686706543
counters:
  num_agent_steps_sampled: 719400
  num_agent_steps_trained: 702500
  num_env_steps_sampled: 719400
  num_env_steps_trained: 702500
  num_samples_added_to_queue: 719000
  num_training_step_calls_since_last_synch_worker_weights: 696
  num_weight_broadcasts: 14188
custom_metrics: {}
date: 2023-08-14_17-06-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.37
episode_reward_min: 0.0
episodes_this_iter: 99
episodes_total: 5621
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8033061623573303
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.5560202598571777
        total_loss: -0.8150253295898438
        var_gnorm: 63.83033752441406
        vf_explained_var: 0.9856273531913757
        vf_loss: 5.2909698486328125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1405.0
  learner_queue:
    size_count: 1411
    size_mean: 15.42
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.218031198286809
  num_agent_steps_sampled: 719400
  num_agent_steps_trained: 702500
  num_env_steps_sampled: 719400
  num_env_steps_trained: 702500
  num_samples_added_to_queue: 719000
  num_training_step_calls_since_last_synch_worker_weights: 696
  num_weight_broadcasts: 14188
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 223.384
    learner_load_time_ms: 1.416
    learner_load_wait_time_ms: 1.469
iterations_since_restore: 54
node_ip: 127.0.0.1
num_agent_steps_sampled: 719400
num_agent_steps_trained: 702500
num_env_steps_sampled: 719400
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9973564203415
num_env_steps_trained: 702500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9973774011323
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.199999999999996
  ram_util_percent: 76.37857142857142
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.060011509953440456
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0231863996157789
  mean_inference_ms: 1.1208694297534054
  mean_raw_obs_processing_ms: 0.25610204972427475
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020914077758789062
    StateBufferConnector_ms: 0.0036759376525878906
    ViewRequirementAgentConnector_ms: 0.12428736686706543
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.37
  episode_reward_min: 0.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 3.0, 8.0, 4.0, 1.0, 3.0, 9.0, 6.0, 8.0, 4.0, 4.0, 7.0,
      4.0, 6.0, 6.0, 5.0, 2.0, 4.0, 5.0, 5.0, 6.0, 4.0, 5.0, 11.0, 5.0, 4.0, 6.0,
      7.0, 0.0, 2.0, 6.0, 7.0, 5.0, 10.0, 7.0, 2.0, 6.0, 2.0, 2.0, 0.0, 0.0, 1.0,
      0.0, 1.0, 1.0, 6.0, 5.0, 7.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 9.0, 7.0, 7.0, 5.0,
      9.0, 6.0, 2.0, 6.0, 7.0, 2.0, 6.0, 2.0, 9.0, 5.0, 5.0, 4.0, 5.0, 5.0, 2.0, 5.0,
      7.0, 2.0, 9.0, 8.0, 3.0, 2.0, 2.0, 5.0, 5.0, 6.0, 3.0, 4.0, 4.0, 1.0, 5.0, 0.0,
      2.0, 4.0, 4.0, 3.0, 6.0, 2.0, 3.0, 2.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.060011509953440456
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0231863996157789
    mean_inference_ms: 1.1208694297534054
    mean_raw_obs_processing_ms: 0.25610204972427475
time_since_restore: 546.7094540596008
time_this_iter_s: 10.147811651229858
time_total_s: 546.7094540596008
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1692000377
timesteps_total: 719400
training_iteration: 54
trial_id: default
train step: 55
agent_timesteps_total: 732000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020791053771972656
  StateBufferConnector_ms: 0.003882169723510742
  ViewRequirementAgentConnector_ms: 0.1244208812713623
counters:
  num_agent_steps_sampled: 732000
  num_agent_steps_trained: 715500
  num_env_steps_sampled: 732000
  num_env_steps_trained: 715500
  num_samples_added_to_queue: 732000
  num_training_step_calls_since_last_synch_worker_weights: 929
  num_weight_broadcasts: 14435
custom_metrics: {}
date: 2023-08-14_17-06-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 7.24
episode_reward_min: 0.0
episodes_this_iter: 99
episodes_total: 5720
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7199034690856934
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 17.742338180541992
        total_loss: 46.42371368408203
        var_gnorm: 63.8443717956543
        vf_explained_var: 0.8894475102424622
        vf_loss: 64.5617904663086
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1431.0
  learner_queue:
    size_count: 1435
    size_mean: 15.5
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1532562594670797
  num_agent_steps_sampled: 732000
  num_agent_steps_trained: 715500
  num_env_steps_sampled: 732000
  num_env_steps_trained: 715500
  num_samples_added_to_queue: 732000
  num_training_step_calls_since_last_synch_worker_weights: 929
  num_weight_broadcasts: 14435
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 244.541
    learner_load_time_ms: 1.499
    learner_load_wait_time_ms: 1.53
iterations_since_restore: 55
node_ip: 127.0.0.1
num_agent_steps_sampled: 732000
num_agent_steps_trained: 715500
num_env_steps_sampled: 732000
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9940820018255
num_env_steps_trained: 715500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9938941288676
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.728571428571435
  ram_util_percent: 77.20000000000002
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06007180528328331
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02321661373906719
  mean_inference_ms: 1.1218899736804138
  mean_raw_obs_processing_ms: 0.256334694697359
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020791053771972656
    StateBufferConnector_ms: 0.003882169723510742
    ViewRequirementAgentConnector_ms: 0.1244208812713623
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 7.24
  episode_reward_min: 0.0
  episodes_this_iter: 99
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 3.0, 8.0, 6.0, 5.0, 11.0, 10.0, 6.0, 8.0, 3.0, 7.0,
      7.0, 7.0, 11.0, 7.0, 6.0, 8.0, 5.0, 11.0, 6.0, 5.0, 7.0, 5.0, 7.0, 8.0, 2.0,
      9.0, 7.0, 9.0, 8.0, 8.0, 8.0, 8.0, 7.0, 6.0, 7.0, 7.0, 7.0, 6.0, 6.0, 5.0, 6.0,
      9.0, 9.0, 5.0, 9.0, 6.0, 7.0, 9.0, 4.0, 14.0, 5.0, 3.0, 4.0, 5.0, 1.0, 5.0,
      5.0, 9.0, 7.0, 10.0, 6.0, 9.0, 9.0, 6.0, 8.0, 9.0, 11.0, 5.0, 6.0, 9.0, 4.0,
      9.0, 9.0, 10.0, 10.0, 8.0, 10.0, 11.0, 17.0, 4.0, 3.0, 11.0, 10.0, 9.0, 6.0,
      6.0, 6.0, 10.0, 9.0, 8.0, 4.0, 9.0, 8.0, 12.0, 9.0, 7.0, 9.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06007180528328331
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02321661373906719
    mean_inference_ms: 1.1218899736804138
    mean_raw_obs_processing_ms: 0.256334694697359
time_since_restore: 556.8047091960907
time_this_iter_s: 10.095255136489868
time_total_s: 556.8047091960907
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000387
timesteps_total: 732000
training_iteration: 55
trial_id: default
train step: 56
agent_timesteps_total: 745100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020151044808182063
  StateBufferConnector_ms: 0.003525088815128102
  ViewRequirementAgentConnector_ms: 0.12043293784646426
counters:
  num_agent_steps_sampled: 745100
  num_agent_steps_trained: 728500
  num_env_steps_sampled: 745100
  num_env_steps_trained: 728500
  num_samples_added_to_queue: 745000
  num_training_step_calls_since_last_synch_worker_weights: 817
  num_weight_broadcasts: 14692
custom_metrics: {}
date: 2023-08-14_17-06-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.549019607843137
episode_reward_min: 2.0
episodes_this_iter: 102
episodes_total: 5822
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.200000000000045
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6203658580780029
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 4.89234733581543
        total_loss: 34.24821472167969
        var_gnorm: 63.85555648803711
        vf_explained_var: 0.8281233310699463
        vf_loss: 64.91539001464844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1457.0
  learner_queue:
    size_count: 1462
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.916515138991168
  num_agent_steps_sampled: 745100
  num_agent_steps_trained: 728500
  num_env_steps_sampled: 745100
  num_env_steps_trained: 728500
  num_samples_added_to_queue: 745000
  num_training_step_calls_since_last_synch_worker_weights: 817
  num_weight_broadcasts: 14692
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 206.386
    learner_load_time_ms: 1.522
    learner_load_wait_time_ms: 1.633
iterations_since_restore: 56
node_ip: 127.0.0.1
num_agent_steps_sampled: 745100
num_agent_steps_trained: 728500
num_env_steps_sampled: 745100
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9964706992819
num_env_steps_trained: 728500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9964976405088
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.535714285714285
  ram_util_percent: 76.1857142857143
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06009162178321862
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02322673239630499
  mean_inference_ms: 1.1222521673699164
  mean_raw_obs_processing_ms: 0.2564260897352225
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020151044808182063
    StateBufferConnector_ms: 0.003525088815128102
    ViewRequirementAgentConnector_ms: 0.12043293784646426
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.549019607843137
  episode_reward_min: 2.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 7.0, 9.0, 5.0, 7.0, 14.0, 2.0, 10.0, 6.0, 7.0, 5.0,
      8.0, 9.0, 10.0, 8.0, 8.0, 6.0, 6.0, 7.0, 5.0, 10.0, 5.0, 4.0, 7.0, 8.0, 11.0,
      2.0, 5.0, 8.0, 6.0, 6.0, 8.0, 5.0, 8.0, 7.0, 5.0, 9.0, 7.0, 10.0, 9.0, 10.0,
      6.0, 3.0, 5.0, 13.0, 7.0, 9.0, 8.0, 9.0, 7.0, 5.0, 11.0, 10.0, 8.0, 11.0, 8.0,
      8.0, 12.0, 8.0, 12.0, 12.0, 9.0, 12.0, 7.0, 14.0, 9.0, 11.0, 4.0, 6.0, 8.0,
      4.0, 9.0, 4.0, 7.0, 12.0, 10.0, 6.0, 4.0, 6.0, 8.0, 5.0, 7.0, 5.0, 6.0, 5.0,
      8.0, 10.0, 4.0, 10.0, 8.0, 7.0, 4.0, 6.0, 11.0, 5.0, 11.0, 6.0, 3.0, 7.0, 10.0,
      4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06009162178321862
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02322673239630499
    mean_inference_ms: 1.1222521673699164
    mean_raw_obs_processing_ms: 0.2564260897352225
time_since_restore: 566.9275140762329
time_this_iter_s: 10.122804880142212
time_total_s: 566.9275140762329
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000398
timesteps_total: 745100
training_iteration: 56
trial_id: default
train step: 57
agent_timesteps_total: 758450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019001273008493278
  StateBufferConnector_ms: 0.0033188324708205005
  ViewRequirementAgentConnector_ms: 0.11559816507192758
counters:
  num_agent_steps_sampled: 758450
  num_agent_steps_trained: 741500
  num_env_steps_sampled: 758450
  num_env_steps_trained: 741500
  num_samples_added_to_queue: 758000
  num_training_step_calls_since_last_synch_worker_weights: 1006
  num_weight_broadcasts: 14955
custom_metrics: {}
date: 2023-08-14_17-06-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.711538461538462
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 5926
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6779217720031738
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -15.845719337463379
        total_loss: 6.807316780090332
        var_gnorm: 63.856266021728516
        vf_explained_var: 0.8270551562309265
        vf_loss: 52.085289001464844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1483.0
  learner_queue:
    size_count: 1487
    size_mean: 15.58
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9816312953446422
  num_agent_steps_sampled: 758450
  num_agent_steps_trained: 741500
  num_env_steps_sampled: 758450
  num_env_steps_trained: 741500
  num_samples_added_to_queue: 758000
  num_training_step_calls_since_last_synch_worker_weights: 1006
  num_weight_broadcasts: 14955
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 263.161
    learner_load_time_ms: 1.455
    learner_load_wait_time_ms: 1.617
iterations_since_restore: 57
node_ip: 127.0.0.1
num_agent_steps_sampled: 758450
num_agent_steps_trained: 741500
num_env_steps_sampled: 758450
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9949392272154
num_env_steps_trained: 741500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9950719066517
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.18666666666666
  ram_util_percent: 75.14666666666668
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.06007610357327513
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023218937671533716
  mean_inference_ms: 1.122210029692159
  mean_raw_obs_processing_ms: 0.2563639416251786
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019001273008493278
    StateBufferConnector_ms: 0.0033188324708205005
    ViewRequirementAgentConnector_ms: 0.11559816507192758
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.711538461538462
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 6.0, 8.0, 6.0, 2.0, 4.0, 5.0, 10.0, 9.0, 8.0, 9.0, 9.0,
      6.0, 4.0, 11.0, 11.0, 5.0, 5.0, 6.0, 9.0, 7.0, 5.0, 8.0, 11.0, 5.0, 6.0, 9.0,
      6.0, 8.0, 13.0, 5.0, 11.0, 8.0, 8.0, 6.0, 8.0, 9.0, 3.0, 7.0, 6.0, 8.0, 5.0,
      8.0, 7.0, 4.0, 5.0, 12.0, 7.0, 2.0, 5.0, 7.0, 6.0, 5.0, 3.0, 5.0, 6.0, 3.0,
      4.0, 8.0, 6.0, 5.0, 7.0, 6.0, 6.0, 7.0, 10.0, 6.0, 1.0, 8.0, 7.0, 9.0, 2.0,
      9.0, 6.0, 4.0, 10.0, 7.0, 7.0, 10.0, 5.0, 9.0, 8.0, 7.0, 4.0, 5.0, 8.0, 7.0,
      8.0, 12.0, 6.0, 6.0, 2.0, 7.0, 8.0, 9.0, 6.0, 8.0, 5.0, 7.0, 7.0, 4.0, 4.0,
      8.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.06007610357327513
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023218937671533716
    mean_inference_ms: 1.122210029692159
    mean_raw_obs_processing_ms: 0.2563639416251786
time_since_restore: 577.0239679813385
time_this_iter_s: 10.09645390510559
time_total_s: 577.0239679813385
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1692000408
timesteps_total: 758450
training_iteration: 57
trial_id: default
train step: 58
agent_timesteps_total: 774450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019876480102539062
  StateBufferConnector_ms: 0.003452110290527344
  ViewRequirementAgentConnector_ms: 0.11709213256835938
counters:
  num_agent_steps_sampled: 774450
  num_agent_steps_trained: 757500
  num_env_steps_sampled: 774450
  num_env_steps_trained: 757500
  num_samples_added_to_queue: 774000
  num_training_step_calls_since_last_synch_worker_weights: 86
  num_weight_broadcasts: 15270
custom_metrics: {}
date: 2023-08-14_17-06-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.872
episode_reward_min: 0.0
episodes_this_iter: 125
episodes_total: 6051
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8007161617279053
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 12.80112075805664
        total_loss: 36.39182662963867
        var_gnorm: 63.8562126159668
        vf_explained_var: 0.9096665978431702
        vf_loss: 55.188575744628906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1515.0
  learner_queue:
    size_count: 1521
    size_mean: 15.5
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1532562594670797
  num_agent_steps_sampled: 774450
  num_agent_steps_trained: 757500
  num_env_steps_sampled: 774450
  num_env_steps_trained: 757500
  num_samples_added_to_queue: 774000
  num_training_step_calls_since_last_synch_worker_weights: 86
  num_weight_broadcasts: 15270
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 186.669
    learner_load_time_ms: 1.669
    learner_load_wait_time_ms: 1.439
iterations_since_restore: 58
node_ip: 127.0.0.1
num_agent_steps_sampled: 774450
num_agent_steps_trained: 757500
num_env_steps_sampled: 774450
num_env_steps_sampled_this_iter: 16000
num_env_steps_sampled_throughput_per_sec: 1599.9963760458058
num_env_steps_trained: 757500
num_env_steps_trained_this_iter: 16000
num_env_steps_trained_throughput_per_sec: 1599.9963760458058
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 16000
perf:
  cpu_util_percent: 53.57058823529411
  ram_util_percent: 74.35882352941177
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.057344313396353125
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02321986375487992
  mean_inference_ms: 1.1196929009593526
  mean_raw_obs_processing_ms: 0.2564058524962051
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019876480102539062
    StateBufferConnector_ms: 0.003452110290527344
    ViewRequirementAgentConnector_ms: 0.11709213256835938
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.872
  episode_reward_min: 0.0
  episodes_this_iter: 125
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [6.0, 12.0, 10.0, 10.0, 6.0, 8.0, 10.0, 6.0, 7.0, 2.0, 4.0, 8.0,
      8.0, 8.0, 13.0, 7.0, 10.0, 10.0, 9.0, 9.0, 10.0, 9.0, 4.0, 7.0, 7.0, 9.0, 5.0,
      8.0, 0.0, 12.0, 10.0, 8.0, 8.0, 8.0, 5.0, 6.0, 11.0, 8.0, 9.0, 6.0, 7.0, 8.0,
      8.0, 15.0, 8.0, 6.0, 9.0, 9.0, 8.0, 13.0, 10.0, 10.0, 11.0, 4.0, 7.0, 15.0,
      10.0, 7.0, 8.0, 6.0, 9.0, 5.0, 9.0, 11.0, 8.0, 2.0, 8.0, 6.0, 5.0, 4.0, 12.0,
      6.0, 6.0, 3.0, 7.0, 6.0, 7.0, 5.0, 9.0, 9.0, 8.0, 11.0, 7.0, 5.0, 1.0, 11.0,
      8.0, 8.0, 7.0, 7.0, 6.0, 7.0, 9.0, 8.0, 12.0, 9.0, 5.0, 6.0, 5.0, 10.0, 11.0,
      7.0, 7.0, 9.0, 10.0, 8.0, 6.0, 11.0, 8.0, 6.0, 7.0, 10.0, 4.0, 7.0, 14.0, 10.0,
      9.0, 4.0, 3.0, 10.0, 7.0, 7.0, 13.0, 8.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.057344313396353125
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02321986375487992
    mean_inference_ms: 1.1196929009593526
    mean_raw_obs_processing_ms: 0.2564058524962051
time_since_restore: 587.172523021698
time_this_iter_s: 10.148555040359497
time_total_s: 587.172523021698
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000418
timesteps_total: 774450
training_iteration: 58
trial_id: default
train step: 59
agent_timesteps_total: 788050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01908551866763106
  StateBufferConnector_ms: 0.003302431552209587
  ViewRequirementAgentConnector_ms: 0.11289431670001734
counters:
  num_agent_steps_sampled: 788050
  num_agent_steps_trained: 771500
  num_env_steps_sampled: 788050
  num_env_steps_trained: 771500
  num_samples_added_to_queue: 788000
  num_training_step_calls_since_last_synch_worker_weights: 965
  num_weight_broadcasts: 15539
custom_metrics: {}
date: 2023-08-14_17-07-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.74766355140187
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 6158
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8297367691993713
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 66.55217742919922
        total_loss: 116.88833618164062
        var_gnorm: 63.86174774169922
        vf_explained_var: 0.8667776584625244
        vf_loss: 108.96968078613281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1543.0
  learner_queue:
    size_count: 1546
    size_mean: 15.44
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.283121194587635
  num_agent_steps_sampled: 788050
  num_agent_steps_trained: 771500
  num_env_steps_sampled: 788050
  num_env_steps_trained: 771500
  num_samples_added_to_queue: 788000
  num_training_step_calls_since_last_synch_worker_weights: 965
  num_weight_broadcasts: 15539
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 280.469
    learner_load_time_ms: 1.671
    learner_load_wait_time_ms: 1.544
iterations_since_restore: 59
node_ip: 127.0.0.1
num_agent_steps_sampled: 788050
num_agent_steps_trained: 771500
num_env_steps_sampled: 788050
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9994812013697
num_env_steps_trained: 771500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9994659425865
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.6
  ram_util_percent: 74.95000000000002
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05730104310604143
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023205122346078265
  mean_inference_ms: 1.1194130689410797
  mean_raw_obs_processing_ms: 0.2562632099917686
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01908551866763106
    StateBufferConnector_ms: 0.003302431552209587
    ViewRequirementAgentConnector_ms: 0.11289431670001734
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.74766355140187
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 11.0, 6.0, 10.0, 6.0, 8.0, 11.0, 7.0, 7.0, 7.0, 8.0, 12.0,
      11.0, 12.0, 4.0, 7.0, 14.0, 7.0, 11.0, 9.0, 6.0, 7.0, 5.0, 8.0, 10.0, 12.0,
      8.0, 3.0, 9.0, 8.0, 11.0, 8.0, 8.0, 5.0, 7.0, 11.0, 10.0, 6.0, 12.0, 6.0, 8.0,
      6.0, 6.0, 11.0, 7.0, 6.0, 10.0, 8.0, 9.0, 7.0, 14.0, 7.0, 8.0, 6.0, 11.0, 13.0,
      11.0, 9.0, 10.0, 12.0, 10.0, 11.0, 7.0, 3.0, 7.0, 6.0, 6.0, 8.0, 8.0, 11.0,
      6.0, 10.0, 4.0, 11.0, 14.0, 12.0, 10.0, 9.0, 9.0, 11.0, 5.0, 9.0, 11.0, 5.0,
      13.0, 12.0, 11.0, 7.0, 9.0, 13.0, 12.0, 9.0, 8.0, 7.0, 9.0, 9.0, 9.0, 9.0, 10.0,
      9.0, 14.0, 7.0, 7.0, 7.0, 9.0, 7.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05730104310604143
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023205122346078265
    mean_inference_ms: 1.1194130689410797
    mean_raw_obs_processing_ms: 0.2562632099917686
time_since_restore: 597.2526412010193
time_this_iter_s: 10.080118179321289
time_total_s: 597.2526412010193
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.041
timestamp: 1692000428
timesteps_total: 788050
training_iteration: 59
trial_id: default
train step: 60
agent_timesteps_total: 801450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01979218079493596
  StateBufferConnector_ms: 0.0033747691374558667
  ViewRequirementAgentConnector_ms: 0.11845895877251258
counters:
  num_agent_steps_sampled: 801450
  num_agent_steps_trained: 784500
  num_env_steps_sampled: 801450
  num_env_steps_trained: 784500
  num_samples_added_to_queue: 801000
  num_training_step_calls_since_last_synch_worker_weights: 501
  num_weight_broadcasts: 15804
custom_metrics: {}
date: 2023-08-14_17-07-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.067307692307692
episode_reward_min: 3.0
episodes_this_iter: 104
episodes_total: 6262
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8739516139030457
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 32.993736267089844
        total_loss: 81.28609466552734
        var_gnorm: 63.86534881591797
        vf_explained_var: 0.903315544128418
        vf_loss: 105.32423400878906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1569.0
  learner_queue:
    size_count: 1574
    size_mean: 15.68
    size_quantiles: [12.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.835224520712844
  num_agent_steps_sampled: 801450
  num_agent_steps_trained: 784500
  num_env_steps_sampled: 801450
  num_env_steps_trained: 784500
  num_samples_added_to_queue: 801000
  num_training_step_calls_since_last_synch_worker_weights: 501
  num_weight_broadcasts: 15804
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 228.538
    learner_load_time_ms: 1.692
    learner_load_wait_time_ms: 1.504
iterations_since_restore: 60
node_ip: 127.0.0.1
num_agent_steps_sampled: 801450
num_agent_steps_trained: 784500
num_env_steps_sampled: 801450
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9973163658483
num_env_steps_trained: 784500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9973964743303
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.26
  ram_util_percent: 74.58666666666666
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05735907636588448
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023200835902778823
  mean_inference_ms: 1.1193203120553692
  mean_raw_obs_processing_ms: 0.25624350235328186
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01979218079493596
    StateBufferConnector_ms: 0.0033747691374558667
    ViewRequirementAgentConnector_ms: 0.11845895877251258
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.067307692307692
  episode_reward_min: 3.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 10.0, 9.0, 8.0, 13.0, 14.0, 7.0, 5.0, 5.0, 7.0, 11.0,
      5.0, 5.0, 13.0, 5.0, 9.0, 7.0, 9.0, 13.0, 8.0, 7.0, 6.0, 4.0, 7.0, 4.0, 7.0,
      7.0, 7.0, 11.0, 7.0, 9.0, 7.0, 10.0, 7.0, 8.0, 13.0, 6.0, 6.0, 9.0, 8.0, 10.0,
      5.0, 11.0, 6.0, 10.0, 7.0, 10.0, 8.0, 10.0, 5.0, 8.0, 11.0, 9.0, 3.0, 8.0, 6.0,
      4.0, 4.0, 5.0, 5.0, 7.0, 8.0, 5.0, 13.0, 8.0, 6.0, 8.0, 10.0, 8.0, 6.0, 8.0,
      6.0, 7.0, 8.0, 8.0, 8.0, 11.0, 9.0, 4.0, 9.0, 11.0, 9.0, 10.0, 7.0, 13.0, 6.0,
      10.0, 9.0, 11.0, 6.0, 11.0, 14.0, 8.0, 7.0, 10.0, 8.0, 7.0, 10.0, 7.0, 12.0,
      5.0, 6.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05735907636588448
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023200835902778823
    mean_inference_ms: 1.1193203120553692
    mean_raw_obs_processing_ms: 0.25624350235328186
time_since_restore: 607.3826761245728
time_this_iter_s: 10.130034923553467
time_total_s: 607.3826761245728
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000438
timesteps_total: 801450
training_iteration: 60
trial_id: default
train step: 61
agent_timesteps_total: 814800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019323367338914137
  StateBufferConnector_ms: 0.003333733632014348
  ViewRequirementAgentConnector_ms: 0.11641039298130916
counters:
  num_agent_steps_sampled: 814800
  num_agent_steps_trained: 798000
  num_env_steps_sampled: 814800
  num_env_steps_trained: 798000
  num_samples_added_to_queue: 814500
  num_training_step_calls_since_last_synch_worker_weights: 41
  num_weight_broadcasts: 16066
custom_metrics: {}
date: 2023-08-14_17-07-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.798076923076923
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 6366
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8140054941177368
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 72.64169311523438
        total_loss: 115.74077606201172
        var_gnorm: 63.87174987792969
        vf_explained_var: 0.9174505472183228
        vf_loss: 94.33821868896484
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1596.0
  learner_queue:
    size_count: 1602
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3098091464026351
  num_agent_steps_sampled: 814800
  num_agent_steps_trained: 798000
  num_env_steps_sampled: 814800
  num_env_steps_trained: 798000
  num_samples_added_to_queue: 814500
  num_training_step_calls_since_last_synch_worker_weights: 41
  num_weight_broadcasts: 16066
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 182.881
    learner_load_time_ms: 1.596
    learner_load_wait_time_ms: 1.563
iterations_since_restore: 61
node_ip: 127.0.0.1
num_agent_steps_sampled: 814800
num_agent_steps_trained: 798000
num_env_steps_sampled: 814800
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9929340259705
num_env_steps_trained: 798000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.992854633004
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.27857142857143
  ram_util_percent: 74.75
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.057392390843329144
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02319593504567913
  mean_inference_ms: 1.1193371102747929
  mean_raw_obs_processing_ms: 0.2562335268171403
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019323367338914137
    StateBufferConnector_ms: 0.003333733632014348
    ViewRequirementAgentConnector_ms: 0.11641039298130916
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.798076923076923
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 12.0, 7.0, 6.0, 7.0, 7.0, 10.0, 5.0, 5.0, 7.0, 9.0, 5.0,
      11.0, 4.0, 7.0, 13.0, 7.0, 11.0, 10.0, 8.0, 7.0, 7.0, 10.0, 11.0, 13.0, 7.0,
      4.0, 7.0, 5.0, 6.0, 11.0, 6.0, 2.0, 7.0, 6.0, 5.0, 6.0, 10.0, 9.0, 9.0, 8.0,
      8.0, 9.0, 5.0, 10.0, 12.0, 8.0, 2.0, 5.0, 5.0, 4.0, 12.0, 7.0, 8.0, 10.0, 5.0,
      7.0, 13.0, 6.0, 11.0, 13.0, 9.0, 4.0, 8.0, 9.0, 8.0, 7.0, 10.0, 8.0, 7.0, 1.0,
      11.0, 5.0, 7.0, 6.0, 15.0, 10.0, 11.0, 9.0, 9.0, 7.0, 8.0, 9.0, 9.0, 7.0, 5.0,
      11.0, 5.0, 9.0, 8.0, 5.0, 5.0, 9.0, 9.0, 5.0, 5.0, 13.0, 12.0, 4.0, 8.0, 9.0,
      9.0, 6.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.057392390843329144
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02319593504567913
    mean_inference_ms: 1.1193371102747929
    mean_raw_obs_processing_ms: 0.2562335268171403
time_since_restore: 617.527309179306
time_this_iter_s: 10.144633054733276
time_total_s: 617.527309179306
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1692000448
timesteps_total: 814800
training_iteration: 61
trial_id: default
train step: 62
agent_timesteps_total: 828200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019363902864002046
  StateBufferConnector_ms: 0.0034000760033017115
  ViewRequirementAgentConnector_ms: 0.11631556919642858
counters:
  num_agent_steps_sampled: 828200
  num_agent_steps_trained: 811500
  num_env_steps_sampled: 828200
  num_env_steps_trained: 811500
  num_samples_added_to_queue: 828000
  num_training_step_calls_since_last_synch_worker_weights: 1074
  num_weight_broadcasts: 16329
custom_metrics: {}
date: 2023-08-14_17-07-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.59047619047619
episode_reward_min: 2.0
episodes_this_iter: 105
episodes_total: 6471
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8082366585731506
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -43.74725341796875
        total_loss: -8.93017578125
        var_gnorm: 63.8789176940918
        vf_explained_var: 0.8878298997879028
        vf_loss: 77.71652221679688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1623.0
  learner_queue:
    size_count: 1627
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3676256797823005
  num_agent_steps_sampled: 828200
  num_agent_steps_trained: 811500
  num_env_steps_sampled: 828200
  num_env_steps_trained: 811500
  num_samples_added_to_queue: 828000
  num_training_step_calls_since_last_synch_worker_weights: 1074
  num_weight_broadcasts: 16329
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 251.551
    learner_load_time_ms: 1.593
    learner_load_wait_time_ms: 1.562
iterations_since_restore: 62
node_ip: 127.0.0.1
num_agent_steps_sampled: 828200
num_agent_steps_trained: 811500
num_env_steps_sampled: 828200
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9986581815804
num_env_steps_trained: 811500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.99864816801
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.57142857142856
  ram_util_percent: 77.57142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05744201528673775
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023189064214883037
  mean_inference_ms: 1.119175173850125
  mean_raw_obs_processing_ms: 0.2561980717044534
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019363902864002046
    StateBufferConnector_ms: 0.0034000760033017115
    ViewRequirementAgentConnector_ms: 0.11631556919642858
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.59047619047619
  episode_reward_min: 2.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 7.0, 4.0, 10.0, 7.0, 4.0, 8.0, 5.0, 7.0, 8.0, 8.0, 6.0,
      10.0, 3.0, 13.0, 5.0, 16.0, 9.0, 7.0, 11.0, 3.0, 4.0, 7.0, 8.0, 7.0, 11.0, 10.0,
      8.0, 6.0, 3.0, 5.0, 8.0, 5.0, 9.0, 2.0, 9.0, 7.0, 8.0, 9.0, 7.0, 8.0, 7.0, 8.0,
      14.0, 5.0, 7.0, 8.0, 9.0, 9.0, 10.0, 7.0, 3.0, 5.0, 8.0, 5.0, 8.0, 6.0, 9.0,
      9.0, 9.0, 8.0, 8.0, 9.0, 9.0, 10.0, 11.0, 12.0, 14.0, 5.0, 4.0, 7.0, 6.0, 6.0,
      6.0, 5.0, 7.0, 6.0, 5.0, 10.0, 9.0, 6.0, 2.0, 13.0, 7.0, 3.0, 9.0, 7.0, 5.0,
      7.0, 10.0, 5.0, 4.0, 6.0, 11.0, 9.0, 7.0, 10.0, 4.0, 11.0, 6.0, 10.0, 12.0,
      10.0, 11.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05744201528673775
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023189064214883037
    mean_inference_ms: 1.119175173850125
    mean_raw_obs_processing_ms: 0.2561980717044534
time_since_restore: 627.6197865009308
time_this_iter_s: 10.092477321624756
time_total_s: 627.6197865009308
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000458
timesteps_total: 828200
training_iteration: 62
trial_id: default
train step: 63
agent_timesteps_total: 840400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02146458625793457
  StateBufferConnector_ms: 0.0037086009979248047
  ViewRequirementAgentConnector_ms: 0.1301891803741455
counters:
  num_agent_steps_sampled: 840400
  num_agent_steps_trained: 823500
  num_env_steps_sampled: 840400
  num_env_steps_trained: 823500
  num_samples_added_to_queue: 840000
  num_training_step_calls_since_last_synch_worker_weights: 810
  num_weight_broadcasts: 16568
custom_metrics: {}
date: 2023-08-14_17-07-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.52
episode_reward_min: 3.0
episodes_this_iter: 95
episodes_total: 6566
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8001602292060852
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -42.461509704589844
        total_loss: -13.345134735107422
        var_gnorm: 63.88209533691406
        vf_explained_var: 0.9191893339157104
        vf_loss: 66.2343521118164
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1647.0
  learner_queue:
    size_count: 1652
    size_mean: 15.4
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2328828005937953
  num_agent_steps_sampled: 840400
  num_agent_steps_trained: 823500
  num_env_steps_sampled: 840400
  num_env_steps_trained: 823500
  num_samples_added_to_queue: 840000
  num_training_step_calls_since_last_synch_worker_weights: 810
  num_weight_broadcasts: 16568
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 238.183
    learner_load_time_ms: 1.424
    learner_load_wait_time_ms: 1.6
iterations_since_restore: 63
node_ip: 127.0.0.1
num_agent_steps_sampled: 840400
num_agent_steps_trained: 823500
num_env_steps_sampled: 840400
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.9996218682506
num_env_steps_trained: 823500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9996280671319
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.435714285714276
  ram_util_percent: 77.26428571428573
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05763175931782828
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023222381834399314
  mean_inference_ms: 1.1205272621413065
  mean_raw_obs_processing_ms: 0.25652915523370495
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02146458625793457
    StateBufferConnector_ms: 0.0037086009979248047
    ViewRequirementAgentConnector_ms: 0.1301891803741455
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.52
  episode_reward_min: 3.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 12.0, 10.0, 11.0, 8.0, 9.0, 10.0, 8.0, 11.0, 8.0, 7.0,
      10.0, 7.0, 14.0, 9.0, 6.0, 6.0, 9.0, 10.0, 11.0, 12.0, 8.0, 6.0, 7.0, 10.0,
      4.0, 10.0, 10.0, 10.0, 8.0, 7.0, 9.0, 8.0, 6.0, 16.0, 8.0, 10.0, 13.0, 7.0,
      9.0, 7.0, 8.0, 13.0, 3.0, 11.0, 11.0, 9.0, 11.0, 10.0, 6.0, 9.0, 7.0, 4.0, 8.0,
      10.0, 8.0, 5.0, 8.0, 8.0, 8.0, 5.0, 11.0, 4.0, 5.0, 8.0, 11.0, 11.0, 4.0, 3.0,
      5.0, 4.0, 3.0, 7.0, 8.0, 10.0, 7.0, 6.0, 7.0, 13.0, 9.0, 11.0, 6.0, 9.0, 9.0,
      7.0, 12.0, 10.0, 10.0, 8.0, 12.0, 11.0, 8.0, 7.0, 10.0, 10.0, 7.0, 11.0, 9.0,
      9.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05763175931782828
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023222381834399314
    mean_inference_ms: 1.1205272621413065
    mean_raw_obs_processing_ms: 0.25652915523370495
time_since_restore: 637.7500743865967
time_this_iter_s: 10.130287885665894
time_total_s: 637.7500743865967
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1692000468
timesteps_total: 840400
training_iteration: 63
trial_id: default
train step: 64
agent_timesteps_total: 854200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018793344497680664
  StateBufferConnector_ms: 0.0032316755365442346
  ViewRequirementAgentConnector_ms: 0.11267993185255262
counters:
  num_agent_steps_sampled: 854200
  num_agent_steps_trained: 837500
  num_env_steps_sampled: 854200
  num_env_steps_trained: 837500
  num_samples_added_to_queue: 854000
  num_training_step_calls_since_last_synch_worker_weights: 1163
  num_weight_broadcasts: 16840
custom_metrics: {}
date: 2023-08-14_17-07-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.462962962962964
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 6674
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7652380466461182
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 33.21992874145508
        total_loss: 63.74839401245117
        var_gnorm: 63.884490966796875
        vf_explained_var: 0.8994369506835938
        vf_loss: 68.70930480957031
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1675.0
  learner_queue:
    size_count: 1680
    size_mean: 15.48
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.153082824431966
  num_agent_steps_sampled: 854200
  num_agent_steps_trained: 837500
  num_env_steps_sampled: 854200
  num_env_steps_trained: 837500
  num_samples_added_to_queue: 854000
  num_training_step_calls_since_last_synch_worker_weights: 1163
  num_weight_broadcasts: 16840
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 210.313
    learner_load_time_ms: 1.416
    learner_load_wait_time_ms: 1.583
iterations_since_restore: 64
node_ip: 127.0.0.1
num_agent_steps_sampled: 854200
num_agent_steps_trained: 837500
num_env_steps_sampled: 854200
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.993386777145
num_env_steps_trained: 837500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9932909333354
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.28666666666666
  ram_util_percent: 76.57333333333334
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.057534702405662115
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023210823467893573
  mean_inference_ms: 1.1201612963310932
  mean_raw_obs_processing_ms: 0.25641663917975427
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018793344497680664
    StateBufferConnector_ms: 0.0032316755365442346
    ViewRequirementAgentConnector_ms: 0.11267993185255262
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.462962962962964
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 12.0, 10.0, 7.0, 7.0, 12.0, 10.0, 8.0, 11.0, 8.0, 10.0,
      9.0, 9.0, 5.0, 10.0, 8.0, 7.0, 12.0, 7.0, 6.0, 8.0, 12.0, 9.0, 11.0, 12.0, 9.0,
      6.0, 10.0, 13.0, 6.0, 6.0, 10.0, 10.0, 7.0, 12.0, 14.0, 7.0, 5.0, 13.0, 8.0,
      13.0, 5.0, 7.0, 5.0, 8.0, 7.0, 8.0, 8.0, 13.0, 6.0, 10.0, 6.0, 4.0, 9.0, 8.0,
      6.0, 8.0, 7.0, 7.0, 8.0, 12.0, 14.0, 9.0, 8.0, 9.0, 6.0, 7.0, 10.0, 9.0, 3.0,
      10.0, 9.0, 7.0, 13.0, 6.0, 6.0, 10.0, 6.0, 7.0, 6.0, 8.0, 2.0, 10.0, 12.0, 5.0,
      12.0, 8.0, 9.0, 9.0, 13.0, 10.0, 4.0, 6.0, 9.0, 6.0, 7.0, 11.0, 8.0, 6.0, 11.0,
      6.0, 8.0, 8.0, 6.0, 8.0, 7.0, 13.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.057534702405662115
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023210823467893573
    mean_inference_ms: 1.1201612963310932
    mean_raw_obs_processing_ms: 0.25641663917975427
time_since_restore: 647.8750884532928
time_this_iter_s: 10.125014066696167
time_total_s: 647.8750884532928
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000479
timesteps_total: 854200
training_iteration: 64
trial_id: default
train step: 65
agent_timesteps_total: 867450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020192896278159133
  StateBufferConnector_ms: 0.003548038815989078
  ViewRequirementAgentConnector_ms: 0.11979931766547046
counters:
  num_agent_steps_sampled: 867450
  num_agent_steps_trained: 850500
  num_env_steps_sampled: 867450
  num_env_steps_trained: 850500
  num_samples_added_to_queue: 867000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 17100
custom_metrics: {}
date: 2023-08-14_17-08-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.990291262135923
episode_reward_min: 3.0
episodes_this_iter: 103
episodes_total: 6777
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8076297044754028
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 5.340824604034424
        total_loss: 75.90966033935547
        var_gnorm: 63.889163970947266
        vf_explained_var: 0.7940038442611694
        vf_loss: 149.21395874023438
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1701.0
  learner_queue:
    size_count: 1705
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9591663046625439
  num_agent_steps_sampled: 867450
  num_agent_steps_trained: 850500
  num_env_steps_sampled: 867450
  num_env_steps_trained: 850500
  num_samples_added_to_queue: 867000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 17100
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 272.699
    learner_load_time_ms: 1.648
    learner_load_wait_time_ms: 1.574
iterations_since_restore: 65
node_ip: 127.0.0.1
num_agent_steps_sampled: 867450
num_agent_steps_trained: 850500
num_env_steps_sampled: 867450
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.5897985245458
num_env_steps_trained: 850500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.597538175026
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.04285714285715
  ram_util_percent: 76.38571428571427
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05760508818312464
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02321428672610555
  mean_inference_ms: 1.1202558845551314
  mean_raw_obs_processing_ms: 0.2564567031812999
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020192896278159133
    StateBufferConnector_ms: 0.003548038815989078
    ViewRequirementAgentConnector_ms: 0.11979931766547046
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.990291262135923
  episode_reward_min: 3.0
  episodes_this_iter: 103
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 15.0, 10.0, 13.0, 8.0, 7.0, 7.0, 3.0, 11.0, 10.0, 7.0,
      8.0, 10.0, 12.0, 6.0, 7.0, 10.0, 8.0, 6.0, 9.0, 8.0, 9.0, 8.0, 10.0, 10.0, 15.0,
      4.0, 7.0, 10.0, 12.0, 8.0, 9.0, 9.0, 13.0, 10.0, 11.0, 9.0, 7.0, 9.0, 7.0, 4.0,
      8.0, 7.0, 7.0, 8.0, 12.0, 10.0, 8.0, 6.0, 9.0, 8.0, 5.0, 8.0, 10.0, 10.0, 15.0,
      11.0, 7.0, 9.0, 9.0, 6.0, 9.0, 13.0, 11.0, 14.0, 4.0, 11.0, 9.0, 10.0, 10.0,
      8.0, 10.0, 7.0, 5.0, 9.0, 9.0, 16.0, 9.0, 12.0, 7.0, 7.0, 10.0, 8.0, 8.0, 8.0,
      9.0, 10.0, 6.0, 10.0, 12.0, 16.0, 10.0, 13.0, 12.0, 6.0, 5.0, 5.0, 9.0, 10.0,
      6.0, 9.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05760508818312464
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02321428672610555
    mean_inference_ms: 1.1202558845551314
    mean_raw_obs_processing_ms: 0.2564567031812999
time_since_restore: 657.9747912883759
time_this_iter_s: 10.099702835083008
time_total_s: 657.9747912883759
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.255
  training_iteration_time_ms: 0.352
timestamp: 1692000489
timesteps_total: 867450
training_iteration: 65
trial_id: default
train step: 66
agent_timesteps_total: 881000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019488694532862248
  StateBufferConnector_ms: 0.0033724982783479513
  ViewRequirementAgentConnector_ms: 0.116684301844183
counters:
  num_agent_steps_sampled: 881000
  num_agent_steps_trained: 864500
  num_env_steps_sampled: 881000
  num_env_steps_trained: 864500
  num_samples_added_to_queue: 881000
  num_training_step_calls_since_last_synch_worker_weights: 472
  num_weight_broadcasts: 17366
custom_metrics: {}
date: 2023-08-14_17-08-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.584905660377359
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 6883
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7148664593696594
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -29.133373260498047
        total_loss: 0.6687135696411133
        var_gnorm: 63.891944885253906
        vf_explained_var: 0.9245513677597046
        vf_loss: 66.75283813476562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1729.0
  learner_queue:
    size_count: 1734
    size_mean: 15.66
    size_quantiles: [12.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.8856635930193811
  num_agent_steps_sampled: 881000
  num_agent_steps_trained: 864500
  num_env_steps_sampled: 881000
  num_env_steps_trained: 864500
  num_samples_added_to_queue: 881000
  num_training_step_calls_since_last_synch_worker_weights: 472
  num_weight_broadcasts: 17366
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 196.298
    learner_load_time_ms: 1.624
    learner_load_wait_time_ms: 1.492
iterations_since_restore: 66
node_ip: 127.0.0.1
num_agent_steps_sampled: 881000
num_agent_steps_trained: 864500
num_env_steps_sampled: 881000
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9965109914974
num_env_steps_trained: 864500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9963951203663
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 51.364285714285714
  ram_util_percent: 76.62142857142855
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05759497115976541
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023208046314695613
  mean_inference_ms: 1.119957703897982
  mean_raw_obs_processing_ms: 0.2564294652971124
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019488694532862248
    StateBufferConnector_ms: 0.0033724982783479513
    ViewRequirementAgentConnector_ms: 0.116684301844183
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.584905660377359
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 14.0, 14.0, 6.0, 10.0, 15.0, 11.0, 9.0, 11.0, 7.0,
      14.0, 12.0, 8.0, 9.0, 8.0, 6.0, 11.0, 10.0, 11.0, 11.0, 5.0, 8.0, 13.0, 10.0,
      11.0, 13.0, 6.0, 13.0, 17.0, 7.0, 9.0, 3.0, 9.0, 10.0, 8.0, 10.0, 5.0, 4.0,
      16.0, 5.0, 11.0, 4.0, 3.0, 9.0, 10.0, 9.0, 7.0, 9.0, 8.0, 8.0, 9.0, 11.0, 13.0,
      10.0, 9.0, 15.0, 17.0, 7.0, 8.0, 10.0, 9.0, 10.0, 10.0, 4.0, 11.0, 9.0, 12.0,
      11.0, 11.0, 8.0, 10.0, 6.0, 8.0, 9.0, 9.0, 8.0, 8.0, 8.0, 9.0, 8.0, 13.0, 11.0,
      12.0, 14.0, 14.0, 11.0, 8.0, 10.0, 12.0, 12.0, 11.0, 12.0, 8.0, 11.0, 8.0, 7.0,
      9.0, 11.0, 8.0, 8.0, 10.0, 8.0, 10.0, 9.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05759497115976541
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023208046314695613
    mean_inference_ms: 1.119957703897982
    mean_raw_obs_processing_ms: 0.2564294652971124
time_since_restore: 668.1097981929779
time_this_iter_s: 10.13500690460205
time_total_s: 668.1097981929779
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000499
timesteps_total: 881000
training_iteration: 66
trial_id: default
train step: 67
agent_timesteps_total: 894500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01981325869290334
  StateBufferConnector_ms: 0.0033994890608877505
  ViewRequirementAgentConnector_ms: 0.11674930464546636
counters:
  num_agent_steps_sampled: 894500
  num_agent_steps_trained: 878000
  num_env_steps_sampled: 894500
  num_env_steps_trained: 878000
  num_samples_added_to_queue: 894500
  num_training_step_calls_since_last_synch_worker_weights: 719
  num_weight_broadcasts: 17632
custom_metrics: {}
date: 2023-08-14_17-08-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.915094339622641
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 6989
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7562938928604126
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 31.43722915649414
        total_loss: 101.36365509033203
        var_gnorm: 63.8980827331543
        vf_explained_var: 0.822763979434967
        vf_loss: 147.41580200195312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1756.0
  learner_queue:
    size_count: 1761
    size_mean: 15.44
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.1859173664298874
  num_agent_steps_sampled: 894500
  num_agent_steps_trained: 878000
  num_env_steps_sampled: 894500
  num_env_steps_trained: 878000
  num_samples_added_to_queue: 894500
  num_training_step_calls_since_last_synch_worker_weights: 719
  num_weight_broadcasts: 17632
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 196.6
    learner_load_time_ms: 1.62
    learner_load_wait_time_ms: 1.61
iterations_since_restore: 67
node_ip: 127.0.0.1
num_agent_steps_sampled: 894500
num_agent_steps_trained: 878000
num_env_steps_sampled: 894500
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.992854633004
num_env_steps_trained: 878000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.992854633004
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.02666666666665
  ram_util_percent: 75.09333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.057616990365416475
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023202506064928238
  mean_inference_ms: 1.1197619000202832
  mean_raw_obs_processing_ms: 0.2563991123939493
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01981325869290334
    StateBufferConnector_ms: 0.0033994890608877505
    ViewRequirementAgentConnector_ms: 0.11674930464546636
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.915094339622641
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 8.0, 10.0, 6.0, 6.0, 11.0, 10.0, 4.0, 10.0, 7.0, 13.0,
      13.0, 6.0, 10.0, 10.0, 4.0, 8.0, 9.0, 8.0, 7.0, 8.0, 9.0, 9.0, 9.0, 8.0, 7.0,
      7.0, 8.0, 7.0, 6.0, 8.0, 7.0, 10.0, 6.0, 12.0, 11.0, 12.0, 13.0, 10.0, 10.0,
      8.0, 12.0, 7.0, 15.0, 7.0, 16.0, 6.0, 11.0, 11.0, 13.0, 6.0, 11.0, 6.0, 10.0,
      9.0, 3.0, 6.0, 8.0, 12.0, 12.0, 9.0, 7.0, 5.0, 8.0, 15.0, 10.0, 6.0, 6.0, 7.0,
      11.0, 10.0, 10.0, 7.0, 10.0, 12.0, 12.0, 8.0, 8.0, 10.0, 8.0, 8.0, 5.0, 9.0,
      10.0, 10.0, 6.0, 10.0, 11.0, 7.0, 10.0, 8.0, 11.0, 11.0, 5.0, 12.0, 8.0, 8.0,
      10.0, 12.0, 8.0, 6.0, 9.0, 12.0, 7.0, 8.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.057616990365416475
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023202506064928238
    mean_inference_ms: 1.1197619000202832
    mean_raw_obs_processing_ms: 0.2563991123939493
time_since_restore: 678.2411251068115
time_this_iter_s: 10.131326913833618
time_total_s: 678.2411251068115
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000509
timesteps_total: 894500
training_iteration: 67
trial_id: default
train step: 68
agent_timesteps_total: 908000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01970995040166946
  StateBufferConnector_ms: 0.0033916745867047992
  ViewRequirementAgentConnector_ms: 0.11798926762172154
counters:
  num_agent_steps_sampled: 908000
  num_agent_steps_trained: 891500
  num_env_steps_sampled: 908000
  num_env_steps_trained: 891500
  num_samples_added_to_queue: 908000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 17898
custom_metrics: {}
date: 2023-08-14_17-08-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.095238095238095
episode_reward_min: 2.0
episodes_this_iter: 105
episodes_total: 7094
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.60776686668396
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.5009729862213135
        total_loss: 11.152057647705078
        var_gnorm: 63.906494140625
        vf_explained_var: 0.9659981727600098
        vf_loss: 33.38372802734375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1783.0
  learner_queue:
    size_count: 1789
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2649110640673518
  num_agent_steps_sampled: 908000
  num_agent_steps_trained: 891500
  num_env_steps_sampled: 908000
  num_env_steps_trained: 891500
  num_samples_added_to_queue: 908000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 17898
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 159.217
    learner_load_time_ms: 1.625
    learner_load_wait_time_ms: 1.414
iterations_since_restore: 68
node_ip: 127.0.0.1
num_agent_steps_sampled: 908000
num_agent_steps_trained: 891500
num_env_steps_sampled: 908000
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1347.7076813294
num_env_steps_trained: 891500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1347.7076813294
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.199999999999996
  ram_util_percent: 75.77142857142859
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0576155316448514
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023199410484873527
  mean_inference_ms: 1.1196842586821383
  mean_raw_obs_processing_ms: 0.2563793483139742
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01970995040166946
    StateBufferConnector_ms: 0.0033916745867047992
    ViewRequirementAgentConnector_ms: 0.11798926762172154
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.095238095238095
  episode_reward_min: 2.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 7.0, 4.0, 8.0, 5.0, 6.0, 8.0, 4.0, 8.0, 8.0, 12.0, 12.0,
      11.0, 9.0, 8.0, 8.0, 11.0, 6.0, 8.0, 8.0, 11.0, 13.0, 8.0, 10.0, 6.0, 5.0, 11.0,
      7.0, 9.0, 14.0, 11.0, 10.0, 6.0, 7.0, 11.0, 6.0, 2.0, 10.0, 10.0, 9.0, 12.0,
      6.0, 9.0, 9.0, 7.0, 7.0, 10.0, 7.0, 7.0, 5.0, 8.0, 9.0, 12.0, 12.0, 8.0, 7.0,
      7.0, 10.0, 8.0, 7.0, 6.0, 12.0, 8.0, 10.0, 5.0, 8.0, 8.0, 4.0, 8.0, 8.0, 6.0,
      5.0, 11.0, 10.0, 3.0, 8.0, 11.0, 9.0, 7.0, 7.0, 7.0, 6.0, 5.0, 6.0, 9.0, 7.0,
      12.0, 6.0, 8.0, 11.0, 8.0, 7.0, 13.0, 4.0, 6.0, 7.0, 7.0, 6.0, 6.0, 8.0, 14.0,
      8.0, 10.0, 7.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0576155316448514
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023199410484873527
    mean_inference_ms: 1.1196842586821383
    mean_raw_obs_processing_ms: 0.2563793483139742
time_since_restore: 688.4114580154419
time_this_iter_s: 10.170332908630371
time_total_s: 688.4114580154419
timers:
  sample_time_ms: 0.094
  synch_weights_time_ms: 0.672
  training_iteration_time_ms: 2.554
timestamp: 1692000519
timesteps_total: 908000
training_iteration: 68
trial_id: default
train step: 69
agent_timesteps_total: 921850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018733298337018048
  StateBufferConnector_ms: 0.0032473493505407263
  ViewRequirementAgentConnector_ms: 0.11195606655544704
counters:
  num_agent_steps_sampled: 921850
  num_agent_steps_trained: 905000
  num_env_steps_sampled: 921850
  num_env_steps_trained: 905000
  num_samples_added_to_queue: 921500
  num_training_step_calls_since_last_synch_worker_weights: 1
  num_weight_broadcasts: 18172
custom_metrics: {}
date: 2023-08-14_17-08-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.148148148148149
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 7202
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6875002384185791
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 17.21159553527832
        total_loss: 65.91344451904297
        var_gnorm: 63.91347122192383
        vf_explained_var: 0.8940443992614746
        vf_loss: 104.27869415283203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1810.0
  learner_queue:
    size_count: 1817
    size_mean: 15.02
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.726151789385858
  num_agent_steps_sampled: 921850
  num_agent_steps_trained: 905000
  num_env_steps_sampled: 921850
  num_env_steps_trained: 905000
  num_samples_added_to_queue: 921500
  num_training_step_calls_since_last_synch_worker_weights: 1
  num_weight_broadcasts: 18172
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 145.465
    learner_load_time_ms: 1.708
    learner_load_wait_time_ms: 1.552
iterations_since_restore: 69
node_ip: 127.0.0.1
num_agent_steps_sampled: 921850
num_agent_steps_trained: 905000
num_env_steps_sampled: 921850
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.97021572269
num_env_steps_trained: 905000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9709683939577
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 48.292857142857144
  ram_util_percent: 75.51428571428572
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05763894629646341
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023180501455467135
  mean_inference_ms: 1.119060984948349
  mean_raw_obs_processing_ms: 0.2562552839050279
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018733298337018048
    StateBufferConnector_ms: 0.0032473493505407263
    ViewRequirementAgentConnector_ms: 0.11195606655544704
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.148148148148149
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 13.0, 10.0, 10.0, 7.0, 9.0, 13.0, 12.0, 6.0, 9.0, 8.0, 15.0,
      10.0, 7.0, 9.0, 6.0, 5.0, 7.0, 9.0, 11.0, 6.0, 11.0, 5.0, 10.0, 7.0, 9.0, 4.0,
      8.0, 10.0, 7.0, 8.0, 7.0, 14.0, 10.0, 6.0, 6.0, 6.0, 6.0, 9.0, 8.0, 8.0, 16.0,
      8.0, 3.0, 3.0, 9.0, 4.0, 3.0, 5.0, 14.0, 8.0, 4.0, 4.0, 7.0, 8.0, 13.0, 9.0,
      9.0, 5.0, 10.0, 10.0, 8.0, 6.0, 9.0, 5.0, 9.0, 8.0, 10.0, 6.0, 3.0, 6.0, 7.0,
      8.0, 6.0, 8.0, 10.0, 9.0, 9.0, 9.0, 5.0, 8.0, 6.0, 10.0, 9.0, 11.0, 8.0, 10.0,
      7.0, 11.0, 10.0, 9.0, 10.0, 11.0, 13.0, 7.0, 10.0, 9.0, 10.0, 4.0, 5.0, 8.0,
      6.0, 8.0, 9.0, 10.0, 7.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05763894629646341
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023180501455467135
    mean_inference_ms: 1.119060984948349
    mean_raw_obs_processing_ms: 0.2562552839050279
time_since_restore: 698.5895688533783
time_this_iter_s: 10.178110837936401
time_total_s: 698.5895688533783
timers:
  sample_time_ms: 0.09
  synch_weights_time_ms: 0.268
  training_iteration_time_ms: 0.429
timestamp: 1692000529
timesteps_total: 921850
training_iteration: 69
trial_id: default
train step: 70
agent_timesteps_total: 934850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02007624682258157
  StateBufferConnector_ms: 0.0035428533367082185
  ViewRequirementAgentConnector_ms: 0.11942223006603765
counters:
  num_agent_steps_sampled: 934850
  num_agent_steps_trained: 918000
  num_env_steps_sampled: 934850
  num_env_steps_trained: 918000
  num_samples_added_to_queue: 934500
  num_training_step_calls_since_last_synch_worker_weights: 1099
  num_weight_broadcasts: 18426
custom_metrics: {}
date: 2023-08-14_17-09-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.07843137254902
episode_reward_min: 3.0
episodes_this_iter: 102
episodes_total: 7304
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6414316296577454
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.413610458374023
        total_loss: 11.097716331481934
        var_gnorm: 63.91975402832031
        vf_explained_var: 0.9471392631530762
        vf_loss: 47.43696975708008
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1836.0
  learner_queue:
    size_count: 1842
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.671406593262094
  num_agent_steps_sampled: 934850
  num_agent_steps_trained: 918000
  num_env_steps_sampled: 934850
  num_env_steps_trained: 918000
  num_samples_added_to_queue: 934500
  num_training_step_calls_since_last_synch_worker_weights: 1099
  num_weight_broadcasts: 18426
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 206.633
    learner_load_time_ms: 1.498
    learner_load_wait_time_ms: 1.632
iterations_since_restore: 70
node_ip: 127.0.0.1
num_agent_steps_sampled: 934850
num_agent_steps_trained: 918000
num_env_steps_sampled: 934850
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.99528886595
num_env_steps_trained: 918000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.99528886595
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 52.413333333333334
  ram_util_percent: 75.84666666666666
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05770428200750055
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0231946008811243
  mean_inference_ms: 1.1196582511660365
  mean_raw_obs_processing_ms: 0.2563690555688359
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02007624682258157
    StateBufferConnector_ms: 0.0035428533367082185
    ViewRequirementAgentConnector_ms: 0.11942223006603765
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.07843137254902
  episode_reward_min: 3.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 7.0, 5.0, 9.0, 5.0, 9.0, 9.0, 11.0, 6.0, 7.0, 9.0, 5.0,
      7.0, 8.0, 9.0, 7.0, 6.0, 12.0, 7.0, 8.0, 10.0, 9.0, 9.0, 7.0, 6.0, 6.0, 10.0,
      7.0, 9.0, 8.0, 6.0, 13.0, 7.0, 8.0, 10.0, 6.0, 7.0, 8.0, 11.0, 4.0, 15.0, 11.0,
      7.0, 10.0, 8.0, 5.0, 5.0, 6.0, 9.0, 10.0, 11.0, 9.0, 6.0, 7.0, 3.0, 4.0, 7.0,
      8.0, 10.0, 10.0, 4.0, 6.0, 7.0, 7.0, 6.0, 9.0, 9.0, 8.0, 7.0, 8.0, 7.0, 8.0,
      11.0, 12.0, 6.0, 8.0, 3.0, 9.0, 10.0, 9.0, 8.0, 8.0, 12.0, 9.0, 6.0, 10.0, 9.0,
      4.0, 8.0, 7.0, 8.0, 8.0, 9.0, 12.0, 7.0, 11.0, 9.0, 7.0, 9.0, 12.0, 14.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05770428200750055
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0231946008811243
    mean_inference_ms: 1.1196582511660365
    mean_raw_obs_processing_ms: 0.2563690555688359
time_since_restore: 708.8132538795471
time_this_iter_s: 10.223685026168823
time_total_s: 708.8132538795471
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.049
timestamp: 1692000540
timesteps_total: 934850
training_iteration: 70
trial_id: default
train step: 71
agent_timesteps_total: 945950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024457454681396484
  StateBufferConnector_ms: 0.004190206527709961
  ViewRequirementAgentConnector_ms: 0.13902664184570312
counters:
  num_agent_steps_sampled: 945950
  num_agent_steps_trained: 929000
  num_env_steps_sampled: 945950
  num_env_steps_trained: 929000
  num_samples_added_to_queue: 945500
  num_training_step_calls_since_last_synch_worker_weights: 1319
  num_weight_broadcasts: 18645
custom_metrics: {}
date: 2023-08-14_17-09-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.79
episode_reward_min: 2.0
episodes_this_iter: 87
episodes_total: 7391
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6744062900543213
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 15.988380432128906
        total_loss: 58.00909423828125
        var_gnorm: 63.920692443847656
        vf_explained_var: 0.8835111856460571
        vf_loss: 90.78549194335938
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1858.0
  learner_queue:
    size_count: 1861
    size_mean: 14.84
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.724644890984808
  num_agent_steps_sampled: 945950
  num_agent_steps_trained: 929000
  num_env_steps_sampled: 945950
  num_env_steps_trained: 929000
  num_samples_added_to_queue: 945500
  num_training_step_calls_since_last_synch_worker_weights: 1319
  num_weight_broadcasts: 18645
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 340.658
    learner_load_time_ms: 1.503
    learner_load_wait_time_ms: 1.828
iterations_since_restore: 71
node_ip: 127.0.0.1
num_agent_steps_sampled: 945950
num_agent_steps_trained: 929000
num_env_steps_sampled: 945950
num_env_steps_sampled_this_iter: 11100
num_env_steps_sampled_throughput_per_sec: 1109.9963479162213
num_env_steps_trained: 929000
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.996380817877
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 60.464285714285715
  ram_util_percent: 77.92857142857143
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05816914221921431
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023241861978305307
  mean_inference_ms: 1.1214506991225306
  mean_raw_obs_processing_ms: 0.25684334969146194
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024457454681396484
    StateBufferConnector_ms: 0.004190206527709961
    ViewRequirementAgentConnector_ms: 0.13902664184570312
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.79
  episode_reward_min: 2.0
  episodes_this_iter: 87
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 8.0, 8.0, 9.0, 12.0, 7.0, 11.0, 9.0, 7.0, 9.0, 12.0, 14.0,
      6.0, 5.0, 11.0, 6.0, 11.0, 8.0, 12.0, 9.0, 7.0, 6.0, 8.0, 8.0, 11.0, 8.0, 6.0,
      11.0, 6.0, 12.0, 7.0, 7.0, 4.0, 11.0, 7.0, 11.0, 11.0, 7.0, 9.0, 6.0, 16.0,
      13.0, 11.0, 3.0, 8.0, 7.0, 8.0, 12.0, 11.0, 8.0, 12.0, 10.0, 5.0, 11.0, 9.0,
      9.0, 8.0, 11.0, 2.0, 7.0, 12.0, 7.0, 9.0, 8.0, 8.0, 8.0, 5.0, 12.0, 9.0, 9.0,
      8.0, 7.0, 4.0, 9.0, 8.0, 9.0, 8.0, 10.0, 8.0, 13.0, 10.0, 10.0, 11.0, 6.0, 7.0,
      8.0, 12.0, 10.0, 9.0, 4.0, 10.0, 12.0, 9.0, 11.0, 11.0, 7.0, 6.0, 14.0, 7.0,
      9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05816914221921431
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023241861978305307
    mean_inference_ms: 1.1214506991225306
    mean_raw_obs_processing_ms: 0.25684334969146194
time_since_restore: 718.8999419212341
time_this_iter_s: 10.086688041687012
time_total_s: 718.8999419212341
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1692000550
timesteps_total: 945950
training_iteration: 71
trial_id: default
train step: 72
agent_timesteps_total: 959050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020070870717366535
  StateBufferConnector_ms: 0.0034888585408528647
  ViewRequirementAgentConnector_ms: 0.12119517606847427
counters:
  num_agent_steps_sampled: 959050
  num_agent_steps_trained: 942500
  num_env_steps_sampled: 959050
  num_env_steps_trained: 942500
  num_samples_added_to_queue: 959000
  num_training_step_calls_since_last_synch_worker_weights: 289
  num_weight_broadcasts: 18904
custom_metrics: {}
date: 2023-08-14_17-09-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 18.0
episode_reward_mean: 9.166666666666666
episode_reward_min: 2.0
episodes_this_iter: 102
episodes_total: 7493
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6940503120422363
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 32.67597198486328
        total_loss: 118.90612030029297
        var_gnorm: 63.91998291015625
        vf_explained_var: 0.8437466025352478
        vf_loss: 179.4008026123047
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1885.0
  learner_queue:
    size_count: 1890
    size_mean: 15.32
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3181805642627265
  num_agent_steps_sampled: 959050
  num_agent_steps_trained: 942500
  num_env_steps_sampled: 959050
  num_env_steps_trained: 942500
  num_samples_added_to_queue: 959000
  num_training_step_calls_since_last_synch_worker_weights: 289
  num_weight_broadcasts: 18904
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 209.553
    learner_load_time_ms: 1.512
    learner_load_wait_time_ms: 1.455
iterations_since_restore: 72
node_ip: 127.0.0.1
num_agent_steps_sampled: 959050
num_agent_steps_trained: 942500
num_env_steps_sampled: 959050
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.9959397441824
num_env_steps_trained: 942500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9958157669055
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 52.192857142857136
  ram_util_percent: 76.94285714285715
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05791074938170929
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02328277087641146
  mean_inference_ms: 1.1226111761376136
  mean_raw_obs_processing_ms: 0.25696809128327164
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020070870717366535
    StateBufferConnector_ms: 0.0034888585408528647
    ViewRequirementAgentConnector_ms: 0.12119517606847427
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 18.0
  episode_reward_mean: 9.166666666666666
  episode_reward_min: 2.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 8.0, 11.0, 6.0, 9.0, 8.0, 13.0, 5.0, 14.0, 2.0, 13.0, 8.0,
      7.0, 6.0, 9.0, 10.0, 9.0, 7.0, 10.0, 8.0, 9.0, 7.0, 11.0, 10.0, 11.0, 7.0, 11.0,
      12.0, 10.0, 7.0, 11.0, 8.0, 12.0, 11.0, 11.0, 13.0, 6.0, 10.0, 7.0, 12.0, 11.0,
      12.0, 7.0, 8.0, 9.0, 8.0, 5.0, 7.0, 4.0, 3.0, 5.0, 12.0, 12.0, 8.0, 6.0, 12.0,
      12.0, 7.0, 11.0, 9.0, 12.0, 7.0, 11.0, 11.0, 5.0, 10.0, 13.0, 9.0, 11.0, 6.0,
      13.0, 7.0, 18.0, 5.0, 13.0, 4.0, 13.0, 7.0, 14.0, 12.0, 9.0, 9.0, 11.0, 16.0,
      7.0, 11.0, 7.0, 12.0, 6.0, 3.0, 7.0, 10.0, 6.0, 9.0, 10.0, 7.0, 7.0, 9.0, 10.0,
      11.0, 9.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05791074938170929
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02328277087641146
    mean_inference_ms: 1.1226111761376136
    mean_raw_obs_processing_ms: 0.25696809128327164
time_since_restore: 729.0443689823151
time_this_iter_s: 10.144427061080933
time_total_s: 729.0443689823151
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1692000560
timesteps_total: 959050
training_iteration: 72
trial_id: default
train step: 73
agent_timesteps_total: 970150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.024561166763305664
  StateBufferConnector_ms: 0.004140615463256836
  ViewRequirementAgentConnector_ms: 0.13851332664489746
counters:
  num_agent_steps_sampled: 970150
  num_agent_steps_trained: 953500
  num_env_steps_sampled: 970150
  num_env_steps_trained: 953500
  num_samples_added_to_queue: 970000
  num_training_step_calls_since_last_synch_worker_weights: 1125
  num_weight_broadcasts: 19119
custom_metrics: {}
date: 2023-08-14_17-09-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.09
episode_reward_min: 3.0
episodes_this_iter: 87
episodes_total: 7580
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6397530436515808
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 37.26634979248047
        total_loss: 112.71231842041016
        var_gnorm: 63.922027587890625
        vf_explained_var: 0.8380171060562134
        vf_loss: 157.2894744873047
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1907.0
  learner_queue:
    size_count: 1911
    size_mean: 15.42
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2343419299367577
  num_agent_steps_sampled: 970150
  num_agent_steps_trained: 953500
  num_env_steps_sampled: 970150
  num_env_steps_trained: 953500
  num_samples_added_to_queue: 970000
  num_training_step_calls_since_last_synch_worker_weights: 1125
  num_weight_broadcasts: 19119
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 271.316
    learner_load_time_ms: 1.528
    learner_load_wait_time_ms: 1.776
iterations_since_restore: 73
node_ip: 127.0.0.1
num_agent_steps_sampled: 970150
num_agent_steps_trained: 953500
num_env_steps_sampled: 970150
num_env_steps_sampled_this_iter: 11100
num_env_steps_sampled_throughput_per_sec: 1109.9957657021878
num_env_steps_trained: 953500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.995803849015
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 60.19333333333332
  ram_util_percent: 78.31999999999998
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05831255608631869
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023332256282943203
  mean_inference_ms: 1.1245012549458189
  mean_raw_obs_processing_ms: 0.2573678343218607
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.024561166763305664
    StateBufferConnector_ms: 0.004140615463256836
    ViewRequirementAgentConnector_ms: 0.13851332664489746
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.09
  episode_reward_min: 3.0
  episodes_this_iter: 87
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 7.0, 10.0, 6.0, 9.0, 10.0, 7.0, 7.0, 9.0, 10.0, 11.0, 9.0,
      11.0, 12.0, 16.0, 8.0, 7.0, 12.0, 8.0, 8.0, 5.0, 9.0, 11.0, 6.0, 6.0, 4.0, 13.0,
      5.0, 9.0, 5.0, 8.0, 12.0, 11.0, 11.0, 12.0, 10.0, 8.0, 10.0, 9.0, 15.0, 8.0,
      10.0, 7.0, 7.0, 6.0, 5.0, 12.0, 9.0, 8.0, 10.0, 11.0, 11.0, 11.0, 8.0, 12.0,
      7.0, 8.0, 6.0, 8.0, 11.0, 8.0, 9.0, 11.0, 7.0, 13.0, 14.0, 10.0, 8.0, 7.0, 12.0,
      6.0, 5.0, 7.0, 11.0, 8.0, 8.0, 6.0, 13.0, 10.0, 13.0, 12.0, 13.0, 9.0, 11.0,
      8.0, 10.0, 9.0, 9.0, 5.0, 8.0, 9.0, 11.0, 7.0, 12.0, 8.0, 12.0, 11.0, 10.0,
      7.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05831255608631869
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023332256282943203
    mean_inference_ms: 1.1245012549458189
    mean_raw_obs_processing_ms: 0.2573678343218607
time_since_restore: 739.1544342041016
time_this_iter_s: 10.110065221786499
time_total_s: 739.1544342041016
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000570
timesteps_total: 970150
training_iteration: 73
trial_id: default
train step: 74
agent_timesteps_total: 982050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022490262985229492
  StateBufferConnector_ms: 0.0038657188415527344
  ViewRequirementAgentConnector_ms: 0.1361076831817627
counters:
  num_agent_steps_sampled: 982050
  num_agent_steps_trained: 965500
  num_env_steps_sampled: 982050
  num_env_steps_trained: 965500
  num_samples_added_to_queue: 982000
  num_training_step_calls_since_last_synch_worker_weights: 512
  num_weight_broadcasts: 19352
custom_metrics: {}
date: 2023-08-14_17-09-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.09
episode_reward_min: 2.0
episodes_this_iter: 93
episodes_total: 7673
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6216171979904175
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 11.064038276672363
        total_loss: 68.19151306152344
        var_gnorm: 63.92344284057617
        vf_explained_var: 0.8451100587844849
        vf_loss: 120.47111511230469
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1931.0
  learner_queue:
    size_count: 1935
    size_mean: 15.26
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3085870242364472
  num_agent_steps_sampled: 982050
  num_agent_steps_trained: 965500
  num_env_steps_sampled: 982050
  num_env_steps_trained: 965500
  num_samples_added_to_queue: 982000
  num_training_step_calls_since_last_synch_worker_weights: 512
  num_weight_broadcasts: 19352
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 250.666
    learner_load_time_ms: 1.543
    learner_load_wait_time_ms: 1.765
iterations_since_restore: 74
node_ip: 127.0.0.1
num_agent_steps_sampled: 982050
num_agent_steps_trained: 965500
num_env_steps_sampled: 982050
num_env_steps_sampled_this_iter: 11900
num_env_steps_sampled_throughput_per_sec: 1189.9951484401136
num_env_steps_trained: 965500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9951076707027
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 55.80714285714286
  ram_util_percent: 78.67857142857143
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0583445471574311
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023395334608459814
  mean_inference_ms: 1.126490730022833
  mean_raw_obs_processing_ms: 0.257719749762774
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022490262985229492
    StateBufferConnector_ms: 0.0038657188415527344
    ViewRequirementAgentConnector_ms: 0.1361076831817627
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.09
  episode_reward_min: 2.0
  episodes_this_iter: 93
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 8.0, 12.0, 11.0, 10.0, 7.0, 8.0, 8.0, 10.0, 10.0, 6.0,
      13.0, 8.0, 12.0, 10.0, 10.0, 2.0, 10.0, 13.0, 9.0, 9.0, 10.0, 10.0, 8.0, 8.0,
      7.0, 9.0, 10.0, 10.0, 10.0, 7.0, 10.0, 8.0, 12.0, 5.0, 9.0, 11.0, 6.0, 9.0,
      10.0, 11.0, 10.0, 7.0, 7.0, 9.0, 10.0, 12.0, 9.0, 7.0, 7.0, 6.0, 8.0, 11.0,
      13.0, 8.0, 7.0, 6.0, 8.0, 11.0, 15.0, 10.0, 11.0, 9.0, 6.0, 10.0, 11.0, 11.0,
      8.0, 7.0, 12.0, 12.0, 9.0, 8.0, 9.0, 10.0, 8.0, 11.0, 13.0, 8.0, 8.0, 9.0, 8.0,
      10.0, 3.0, 6.0, 11.0, 10.0, 13.0, 3.0, 13.0, 5.0, 8.0, 10.0, 8.0, 11.0, 7.0,
      7.0, 4.0, 15.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0583445471574311
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023395334608459814
    mean_inference_ms: 1.126490730022833
    mean_raw_obs_processing_ms: 0.257719749762774
time_since_restore: 749.2689032554626
time_this_iter_s: 10.114469051361084
time_total_s: 749.2689032554626
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000580
timesteps_total: 982050
training_iteration: 74
trial_id: default
train step: 75
agent_timesteps_total: 994950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020912142083196358
  StateBufferConnector_ms: 0.00374765679387763
  ViewRequirementAgentConnector_ms: 0.12287267363897644
counters:
  num_agent_steps_sampled: 994950
  num_agent_steps_trained: 978000
  num_env_steps_sampled: 994950
  num_env_steps_trained: 978000
  num_samples_added_to_queue: 994500
  num_training_step_calls_since_last_synch_worker_weights: 1385
  num_weight_broadcasts: 19605
custom_metrics: {}
date: 2023-08-14_17-09-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.376237623762377
episode_reward_min: 3.0
episodes_this_iter: 101
episodes_total: 7774
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6776000261306763
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -49.47660827636719
        total_loss: -11.170368194580078
        var_gnorm: 63.926353454589844
        vf_explained_var: 0.9087302088737488
        vf_loss: 83.38848114013672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1956.0
  learner_queue:
    size_count: 1960
    size_mean: 15.42
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.1504781614615724
  num_agent_steps_sampled: 994950
  num_agent_steps_trained: 978000
  num_env_steps_sampled: 994950
  num_env_steps_trained: 978000
  num_samples_added_to_queue: 994500
  num_training_step_calls_since_last_synch_worker_weights: 1385
  num_weight_broadcasts: 19605
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 296.006
    learner_load_time_ms: 1.443
    learner_load_wait_time_ms: 1.649
iterations_since_restore: 75
node_ip: 127.0.0.1
num_agent_steps_sampled: 994950
num_agent_steps_trained: 978000
num_env_steps_sampled: 994950
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9952020823591
num_env_steps_trained: 978000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9953508549993
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.25714285714286
  ram_util_percent: 78.39285714285712
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058206419503876394
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023423874569902015
  mean_inference_ms: 1.1272885665340426
  mean_raw_obs_processing_ms: 0.2578261032124688
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020912142083196358
    StateBufferConnector_ms: 0.00374765679387763
    ViewRequirementAgentConnector_ms: 0.12287267363897644
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.376237623762377
  episode_reward_min: 3.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 5.0, 10.0, 11.0, 12.0, 4.0, 9.0, 6.0, 9.0, 7.0, 8.0, 8.0,
      9.0, 9.0, 11.0, 12.0, 8.0, 14.0, 11.0, 14.0, 7.0, 12.0, 8.0, 11.0, 12.0, 6.0,
      11.0, 8.0, 7.0, 6.0, 10.0, 7.0, 8.0, 3.0, 7.0, 12.0, 12.0, 8.0, 6.0, 8.0, 9.0,
      11.0, 10.0, 7.0, 9.0, 8.0, 8.0, 13.0, 10.0, 8.0, 15.0, 8.0, 7.0, 7.0, 10.0,
      12.0, 12.0, 9.0, 11.0, 12.0, 9.0, 6.0, 6.0, 10.0, 6.0, 9.0, 7.0, 12.0, 13.0,
      10.0, 9.0, 12.0, 15.0, 6.0, 7.0, 7.0, 15.0, 10.0, 10.0, 8.0, 8.0, 7.0, 10.0,
      13.0, 15.0, 10.0, 14.0, 13.0, 10.0, 12.0, 9.0, 11.0, 7.0, 8.0, 9.0, 10.0, 10.0,
      9.0, 6.0, 6.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058206419503876394
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023423874569902015
    mean_inference_ms: 1.1272885665340426
    mean_raw_obs_processing_ms: 0.2578261032124688
time_since_restore: 759.3694512844086
time_this_iter_s: 10.100548028945923
time_total_s: 759.3694512844086
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000590
timesteps_total: 994950
training_iteration: 75
trial_id: default
train step: 76
agent_timesteps_total: 1006850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02348184585571289
  StateBufferConnector_ms: 0.004128694534301758
  ViewRequirementAgentConnector_ms: 0.13420987129211426
counters:
  num_agent_steps_sampled: 1006850
  num_agent_steps_trained: 990000
  num_env_steps_sampled: 1006850
  num_env_steps_trained: 990000
  num_samples_added_to_queue: 1006500
  num_training_step_calls_since_last_synch_worker_weights: 176
  num_weight_broadcasts: 19837
custom_metrics: {}
date: 2023-08-14_17-10-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.35
episode_reward_min: 3.0
episodes_this_iter: 92
episodes_total: 7866
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6649271249771118
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 11.9808988571167
        total_loss: 57.415592193603516
        var_gnorm: 63.928470611572266
        vf_explained_var: 0.8924226760864258
        vf_loss: 97.5186538696289
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1980.0
  learner_queue:
    size_count: 1986
    size_mean: 15.44
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2191800523302536
  num_agent_steps_sampled: 1006850
  num_agent_steps_trained: 990000
  num_env_steps_sampled: 1006850
  num_env_steps_trained: 990000
  num_samples_added_to_queue: 1006500
  num_training_step_calls_since_last_synch_worker_weights: 176
  num_weight_broadcasts: 19837
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 200.452
    learner_load_time_ms: 1.414
    learner_load_wait_time_ms: 1.518
iterations_since_restore: 76
node_ip: 127.0.0.1
num_agent_steps_sampled: 1006850
num_agent_steps_trained: 990000
num_env_steps_sampled: 1006850
num_env_steps_sampled_this_iter: 11900
num_env_steps_sampled_throughput_per_sec: 1189.9965386491367
num_env_steps_trained: 990000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9965095621546
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 56.80666666666666
  ram_util_percent: 78.90666666666668
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05850624208380775
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02345940981721628
  mean_inference_ms: 1.1284094372959539
  mean_raw_obs_processing_ms: 0.25815332372221766
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02348184585571289
    StateBufferConnector_ms: 0.004128694534301758
    ViewRequirementAgentConnector_ms: 0.13420987129211426
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.35
  episode_reward_min: 3.0
  episodes_this_iter: 92
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 10.0, 10.0, 9.0, 6.0, 6.0, 11.0, 11.0, 9.0, 9.0, 11.0,
      10.0, 8.0, 5.0, 12.0, 5.0, 7.0, 11.0, 13.0, 7.0, 14.0, 10.0, 11.0, 6.0, 9.0,
      5.0, 6.0, 13.0, 8.0, 8.0, 4.0, 3.0, 13.0, 7.0, 14.0, 14.0, 12.0, 9.0, 5.0, 10.0,
      8.0, 6.0, 11.0, 11.0, 16.0, 9.0, 10.0, 10.0, 7.0, 9.0, 10.0, 10.0, 7.0, 10.0,
      14.0, 14.0, 12.0, 11.0, 6.0, 8.0, 10.0, 12.0, 11.0, 9.0, 12.0, 13.0, 13.0, 12.0,
      5.0, 7.0, 15.0, 8.0, 5.0, 5.0, 10.0, 7.0, 9.0, 8.0, 10.0, 13.0, 8.0, 15.0, 7.0,
      7.0, 8.0, 6.0, 10.0, 7.0, 13.0, 13.0, 8.0, 13.0, 15.0, 8.0, 10.0, 8.0, 7.0,
      6.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05850624208380775
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02345940981721628
    mean_inference_ms: 1.1284094372959539
    mean_raw_obs_processing_ms: 0.25815332372221766
time_since_restore: 769.5247573852539
time_this_iter_s: 10.155306100845337
time_total_s: 769.5247573852539
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000600
timesteps_total: 1006850
training_iteration: 76
trial_id: default
train step: 77
agent_timesteps_total: 1019550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020735740661621094
  StateBufferConnector_ms: 0.0035505294799804688
  ViewRequirementAgentConnector_ms: 0.1242523193359375
counters:
  num_agent_steps_sampled: 1019550
  num_agent_steps_trained: 1003000
  num_env_steps_sampled: 1019550
  num_env_steps_trained: 1003000
  num_samples_added_to_queue: 1019500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 20086
custom_metrics: {}
date: 2023-08-14_17-10-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.27
episode_reward_min: 4.0
episodes_this_iter: 100
episodes_total: 7966
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6603008508682251
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.089176177978516
        total_loss: 31.671186447143555
        var_gnorm: 63.929927825927734
        vf_explained_var: 0.8735619783401489
        vf_loss: 102.12373352050781
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2006.0
  learner_queue:
    size_count: 2010
    size_mean: 15.24
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.5173661390712527
  num_agent_steps_sampled: 1019550
  num_agent_steps_trained: 1003000
  num_env_steps_sampled: 1019550
  num_env_steps_trained: 1003000
  num_samples_added_to_queue: 1019500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 20086
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 251.657
    learner_load_time_ms: 1.405
    learner_load_wait_time_ms: 1.648
iterations_since_restore: 77
node_ip: 127.0.0.1
num_agent_steps_sampled: 1019550
num_agent_steps_trained: 1003000
num_env_steps_sampled: 1019550
num_env_steps_sampled_this_iter: 12700
num_env_steps_sampled_throughput_per_sec: 1269.980318851298
num_env_steps_trained: 1003000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9798539422736
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 54.55
  ram_util_percent: 78.66428571428571
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05840428319102866
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02349602469557924
  mean_inference_ms: 1.1294574654098581
  mean_raw_obs_processing_ms: 0.2583160301912565
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020735740661621094
    StateBufferConnector_ms: 0.0035505294799804688
    ViewRequirementAgentConnector_ms: 0.1242523193359375
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.27
  episode_reward_min: 4.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 10.0, 9.0, 9.0, 11.0, 7.0, 11.0, 5.0, 6.0, 10.0, 11.0,
      15.0, 4.0, 8.0, 7.0, 12.0, 12.0, 11.0, 10.0, 11.0, 13.0, 11.0, 10.0, 8.0, 8.0,
      9.0, 8.0, 7.0, 9.0, 8.0, 11.0, 11.0, 8.0, 14.0, 11.0, 7.0, 9.0, 9.0, 6.0, 12.0,
      8.0, 11.0, 10.0, 5.0, 11.0, 6.0, 12.0, 9.0, 5.0, 7.0, 8.0, 8.0, 8.0, 10.0, 7.0,
      15.0, 6.0, 6.0, 7.0, 11.0, 8.0, 10.0, 7.0, 8.0, 10.0, 7.0, 10.0, 6.0, 12.0,
      11.0, 13.0, 11.0, 9.0, 7.0, 12.0, 11.0, 6.0, 12.0, 6.0, 9.0, 6.0, 11.0, 8.0,
      10.0, 12.0, 12.0, 8.0, 7.0, 9.0, 12.0, 7.0, 5.0, 11.0, 10.0, 10.0, 7.0, 12.0,
      11.0, 13.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05840428319102866
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02349602469557924
    mean_inference_ms: 1.1294574654098581
    mean_raw_obs_processing_ms: 0.2583160301912565
time_since_restore: 779.6745812892914
time_this_iter_s: 10.149823904037476
time_total_s: 779.6745812892914
timers:
  sample_time_ms: 0.075
  synch_weights_time_ms: 0.923
  training_iteration_time_ms: 2.575
timestamp: 1692000610
timesteps_total: 1019550
training_iteration: 77
trial_id: default
train step: 78
agent_timesteps_total: 1031200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023400068283081055
  StateBufferConnector_ms: 0.0040700435638427734
  ViewRequirementAgentConnector_ms: 0.13966917991638184
counters:
  num_agent_steps_sampled: 1031200
  num_agent_steps_trained: 1014500
  num_env_steps_sampled: 1031200
  num_env_steps_trained: 1014500
  num_samples_added_to_queue: 1031000
  num_training_step_calls_since_last_synch_worker_weights: 402
  num_weight_broadcasts: 20316
custom_metrics: {}
date: 2023-08-14_17-10-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.65
episode_reward_min: 3.0
episodes_this_iter: 91
episodes_total: 8057
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6491289138793945
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.316411018371582
        total_loss: 18.476806640625
        var_gnorm: 63.93433380126953
        vf_explained_var: 0.9364119172096252
        vf_loss: 40.81208038330078
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2029.0
  learner_queue:
    size_count: 2035
    size_mean: 15.08
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.64730082255792
  num_agent_steps_sampled: 1031200
  num_agent_steps_trained: 1014500
  num_env_steps_sampled: 1031200
  num_env_steps_trained: 1014500
  num_samples_added_to_queue: 1031000
  num_training_step_calls_since_last_synch_worker_weights: 402
  num_weight_broadcasts: 20316
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 232.747
    learner_load_time_ms: 1.409
    learner_load_wait_time_ms: 1.651
iterations_since_restore: 78
node_ip: 127.0.0.1
num_agent_steps_sampled: 1031200
num_agent_steps_trained: 1014500
num_env_steps_sampled: 1031200
num_env_steps_sampled_this_iter: 11650
num_env_steps_sampled_throughput_per_sec: 1164.9941948941532
num_env_steps_trained: 1014500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9942696380053
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 55.79285714285714
  ram_util_percent: 76.82857142857144
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05868399618475536
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023536568026972224
  mean_inference_ms: 1.1307682408711193
  mean_raw_obs_processing_ms: 0.258664002037227
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023400068283081055
    StateBufferConnector_ms: 0.0040700435638427734
    ViewRequirementAgentConnector_ms: 0.13966917991638184
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.65
  episode_reward_min: 3.0
  episodes_this_iter: 91
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 11.0, 10.0, 10.0, 7.0, 12.0, 11.0, 13.0, 11.0, 9.0, 13.0,
      7.0, 11.0, 11.0, 9.0, 9.0, 4.0, 9.0, 9.0, 11.0, 3.0, 9.0, 13.0, 6.0, 9.0, 7.0,
      12.0, 9.0, 10.0, 12.0, 10.0, 9.0, 11.0, 11.0, 7.0, 11.0, 7.0, 12.0, 11.0, 7.0,
      12.0, 15.0, 8.0, 9.0, 10.0, 8.0, 9.0, 8.0, 10.0, 8.0, 12.0, 17.0, 11.0, 10.0,
      10.0, 7.0, 7.0, 13.0, 11.0, 11.0, 6.0, 12.0, 8.0, 7.0, 9.0, 10.0, 9.0, 8.0,
      8.0, 9.0, 9.0, 8.0, 10.0, 13.0, 5.0, 6.0, 12.0, 10.0, 8.0, 6.0, 7.0, 9.0, 11.0,
      6.0, 11.0, 12.0, 8.0, 8.0, 11.0, 14.0, 12.0, 4.0, 9.0, 15.0, 14.0, 12.0, 10.0,
      11.0, 12.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05868399618475536
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023536568026972224
    mean_inference_ms: 1.1307682408711193
    mean_raw_obs_processing_ms: 0.258664002037227
time_since_restore: 789.8357453346252
time_this_iter_s: 10.161164045333862
time_total_s: 789.8357453346252
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000621
timesteps_total: 1031200
training_iteration: 78
trial_id: default
train step: 79
agent_timesteps_total: 1044300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02014917485854205
  StateBufferConnector_ms: 0.0035982505947935815
  ViewRequirementAgentConnector_ms: 0.12087798586078718
counters:
  num_agent_steps_sampled: 1044300
  num_agent_steps_trained: 1027500
  num_env_steps_sampled: 1044300
  num_env_steps_trained: 1027500
  num_samples_added_to_queue: 1044000
  num_training_step_calls_since_last_synch_worker_weights: 653
  num_weight_broadcasts: 20571
custom_metrics: {}
date: 2023-08-14_17-10-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 9.333333333333334
episode_reward_min: 4.0
episodes_this_iter: 102
episodes_total: 8159
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6442559957504272
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 135.26869201660156
        total_loss: 296.0340576171875
        var_gnorm: 63.93851852416992
        vf_explained_var: 0.7408310174942017
        vf_loss: 327.9732971191406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2055.0
  learner_queue:
    size_count: 2060
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.345362404707371
  num_agent_steps_sampled: 1044300
  num_agent_steps_trained: 1027500
  num_env_steps_sampled: 1044300
  num_env_steps_trained: 1027500
  num_samples_added_to_queue: 1044000
  num_training_step_calls_since_last_synch_worker_weights: 653
  num_weight_broadcasts: 20571
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 217.067
    learner_load_time_ms: 1.407
    learner_load_wait_time_ms: 1.484
iterations_since_restore: 79
node_ip: 127.0.0.1
num_agent_steps_sampled: 1044300
num_agent_steps_trained: 1027500
num_env_steps_sampled: 1044300
num_env_steps_sampled_this_iter: 13100
num_env_steps_sampled_throughput_per_sec: 1309.99425318378
num_env_steps_trained: 1027500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9942970526063
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.75333333333333
  ram_util_percent: 76.58666666666666
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058557072441189725
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02355797031152192
  mean_inference_ms: 1.1313113115267672
  mean_raw_obs_processing_ms: 0.25871134505682863
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02014917485854205
    StateBufferConnector_ms: 0.0035982505947935815
    ViewRequirementAgentConnector_ms: 0.12087798586078718
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 9.333333333333334
  episode_reward_min: 4.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 6.0, 11.0, 10.0, 9.0, 10.0, 13.0, 13.0, 8.0, 4.0, 7.0, 7.0,
      6.0, 11.0, 10.0, 9.0, 11.0, 8.0, 11.0, 13.0, 7.0, 10.0, 6.0, 11.0, 12.0, 7.0,
      8.0, 9.0, 7.0, 7.0, 10.0, 9.0, 9.0, 9.0, 4.0, 9.0, 7.0, 5.0, 7.0, 14.0, 8.0,
      13.0, 9.0, 8.0, 9.0, 10.0, 9.0, 14.0, 8.0, 9.0, 10.0, 10.0, 12.0, 7.0, 14.0,
      10.0, 12.0, 7.0, 11.0, 13.0, 7.0, 8.0, 10.0, 14.0, 6.0, 12.0, 8.0, 14.0, 8.0,
      12.0, 8.0, 12.0, 10.0, 9.0, 4.0, 10.0, 10.0, 8.0, 9.0, 7.0, 10.0, 12.0, 8.0,
      9.0, 14.0, 8.0, 7.0, 5.0, 12.0, 14.0, 11.0, 10.0, 14.0, 8.0, 9.0, 7.0, 14.0,
      7.0, 9.0, 6.0, 10.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058557072441189725
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02355797031152192
    mean_inference_ms: 1.1313113115267672
    mean_raw_obs_processing_ms: 0.25871134505682863
time_since_restore: 799.9529073238373
time_this_iter_s: 10.117161989212036
time_total_s: 799.9529073238373
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000631
timesteps_total: 1044300
training_iteration: 79
trial_id: default
train step: 80
agent_timesteps_total: 1056700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02187514305114746
  StateBufferConnector_ms: 0.0036156177520751953
  ViewRequirementAgentConnector_ms: 0.12590646743774414
counters:
  num_agent_steps_sampled: 1056700
  num_agent_steps_trained: 1040000
  num_env_steps_sampled: 1056700
  num_env_steps_trained: 1040000
  num_samples_added_to_queue: 1056500
  num_training_step_calls_since_last_synch_worker_weights: 1348
  num_weight_broadcasts: 20816
custom_metrics: {}
date: 2023-08-14_17-10-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.95
episode_reward_min: 3.0
episodes_this_iter: 97
episodes_total: 8256
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6676150560379028
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 11.148743629455566
        total_loss: 81.92904663085938
        var_gnorm: 63.93955993652344
        vf_explained_var: 0.8459017872810364
        vf_loss: 148.23675537109375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2080.0
  learner_queue:
    size_count: 2085
    size_mean: 15.4
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2
  num_agent_steps_sampled: 1056700
  num_agent_steps_trained: 1040000
  num_env_steps_sampled: 1056700
  num_env_steps_trained: 1040000
  num_samples_added_to_queue: 1056500
  num_training_step_calls_since_last_synch_worker_weights: 1348
  num_weight_broadcasts: 20816
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 246.238
    learner_load_time_ms: 1.375
    learner_load_wait_time_ms: 1.668
iterations_since_restore: 80
node_ip: 127.0.0.1
num_agent_steps_sampled: 1056700
num_agent_steps_trained: 1040000
num_env_steps_sampled: 1056700
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.9981374768577
num_env_steps_trained: 1040000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9981224565097
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.77142857142858
  ram_util_percent: 77.57142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05870929420984141
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023583547061808208
  mean_inference_ms: 1.1320939974154502
  mean_raw_obs_processing_ms: 0.258902192042693
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02187514305114746
    StateBufferConnector_ms: 0.0036156177520751953
    ViewRequirementAgentConnector_ms: 0.12590646743774414
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.95
  episode_reward_min: 3.0
  episodes_this_iter: 97
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 10.0, 9.0, 6.0, 5.0, 6.0, 8.0, 11.0, 10.0, 3.0, 7.0, 8.0,
      12.0, 4.0, 9.0, 15.0, 11.0, 6.0, 10.0, 10.0, 11.0, 10.0, 7.0, 6.0, 10.0, 11.0,
      10.0, 11.0, 6.0, 9.0, 11.0, 12.0, 7.0, 11.0, 6.0, 6.0, 9.0, 7.0, 9.0, 8.0, 13.0,
      8.0, 9.0, 8.0, 9.0, 7.0, 7.0, 14.0, 13.0, 9.0, 12.0, 10.0, 11.0, 9.0, 6.0, 14.0,
      7.0, 12.0, 5.0, 11.0, 8.0, 9.0, 7.0, 3.0, 5.0, 7.0, 6.0, 8.0, 12.0, 9.0, 10.0,
      7.0, 15.0, 6.0, 12.0, 7.0, 12.0, 8.0, 11.0, 10.0, 10.0, 11.0, 12.0, 10.0, 10.0,
      7.0, 10.0, 12.0, 8.0, 12.0, 9.0, 16.0, 8.0, 3.0, 6.0, 5.0, 11.0, 9.0, 9.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05870929420984141
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023583547061808208
    mean_inference_ms: 1.1320939974154502
    mean_raw_obs_processing_ms: 0.258902192042693
time_since_restore: 810.1159951686859
time_this_iter_s: 10.163087844848633
time_total_s: 810.1159951686859
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000641
timesteps_total: 1056700
training_iteration: 80
trial_id: default
train step: 81
agent_timesteps_total: 1070100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01957439459287203
  StateBufferConnector_ms: 0.0033974647521972656
  ViewRequirementAgentConnector_ms: 0.11823016863602859
counters:
  num_agent_steps_sampled: 1070100
  num_agent_steps_trained: 1053500
  num_env_steps_sampled: 1070100
  num_env_steps_trained: 1053500
  num_samples_added_to_queue: 1070000
  num_training_step_calls_since_last_synch_worker_weights: 190
  num_weight_broadcasts: 21078
custom_metrics: {}
date: 2023-08-14_17-10-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.951923076923077
episode_reward_min: 3.0
episodes_this_iter: 104
episodes_total: 8360
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.679003119468689
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 11.723311424255371
        total_loss: 48.024593353271484
        var_gnorm: 63.94213104248047
        vf_explained_var: 0.9160441160202026
        vf_loss: 79.39259338378906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2107.0
  learner_queue:
    size_count: 2113
    size_mean: 15.44
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2191800523302536
  num_agent_steps_sampled: 1070100
  num_agent_steps_trained: 1053500
  num_env_steps_sampled: 1070100
  num_env_steps_trained: 1053500
  num_samples_added_to_queue: 1070000
  num_training_step_calls_since_last_synch_worker_weights: 190
  num_weight_broadcasts: 21078
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 166.87
    learner_load_time_ms: 1.33
    learner_load_wait_time_ms: 1.466
iterations_since_restore: 81
node_ip: 127.0.0.1
num_agent_steps_sampled: 1070100
num_agent_steps_trained: 1053500
num_env_steps_sampled: 1070100
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9963898756014
num_env_steps_trained: 1053500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9963629343745
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.12142857142857
  ram_util_percent: 77.32142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05864543266935085
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023585891274746102
  mean_inference_ms: 1.13207598270704
  mean_raw_obs_processing_ms: 0.25885715492438766
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01957439459287203
    StateBufferConnector_ms: 0.0033974647521972656
    ViewRequirementAgentConnector_ms: 0.11823016863602859
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.951923076923077
  episode_reward_min: 3.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 9.0, 6.0, 11.0, 5.0, 10.0, 10.0, 10.0, 13.0, 9.0, 5.0, 12.0,
      8.0, 11.0, 10.0, 10.0, 8.0, 11.0, 15.0, 8.0, 7.0, 5.0, 8.0, 13.0, 4.0, 7.0,
      6.0, 10.0, 7.0, 6.0, 11.0, 6.0, 3.0, 11.0, 8.0, 8.0, 12.0, 12.0, 10.0, 8.0,
      9.0, 8.0, 6.0, 7.0, 6.0, 7.0, 10.0, 17.0, 8.0, 8.0, 5.0, 12.0, 10.0, 8.0, 6.0,
      11.0, 8.0, 10.0, 7.0, 10.0, 13.0, 11.0, 6.0, 6.0, 11.0, 6.0, 11.0, 10.0, 6.0,
      15.0, 8.0, 6.0, 8.0, 8.0, 10.0, 9.0, 11.0, 11.0, 9.0, 12.0, 12.0, 10.0, 11.0,
      7.0, 7.0, 9.0, 9.0, 10.0, 7.0, 7.0, 9.0, 9.0, 11.0, 7.0, 11.0, 9.0, 10.0, 12.0,
      8.0, 6.0, 12.0, 10.0, 9.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05864543266935085
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023585891274746102
    mean_inference_ms: 1.13207598270704
    mean_raw_obs_processing_ms: 0.25885715492438766
time_since_restore: 820.2570650577545
time_this_iter_s: 10.141069889068604
time_total_s: 820.2570650577545
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000651
timesteps_total: 1070100
training_iteration: 81
trial_id: default
train step: 82
agent_timesteps_total: 1083500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019462378519885946
  StateBufferConnector_ms: 0.003408710911588849
  ViewRequirementAgentConnector_ms: 0.11683927392059902
counters:
  num_agent_steps_sampled: 1083500
  num_agent_steps_trained: 1067000
  num_env_steps_sampled: 1083500
  num_env_steps_trained: 1067000
  num_samples_added_to_queue: 1083500
  num_training_step_calls_since_last_synch_worker_weights: 902
  num_weight_broadcasts: 21342
custom_metrics: {}
date: 2023-08-14_17-11-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.443396226415095
episode_reward_min: 1.0
episodes_this_iter: 106
episodes_total: 8466
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5988209843635559
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 7.0230607986450195
        total_loss: 26.32599449157715
        var_gnorm: 63.945762634277344
        vf_explained_var: 0.8471652865409851
        vf_loss: 44.594078063964844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2134.0
  learner_queue:
    size_count: 2137
    size_mean: 15.48
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2039933554633928
  num_agent_steps_sampled: 1083500
  num_agent_steps_trained: 1067000
  num_env_steps_sampled: 1083500
  num_env_steps_trained: 1067000
  num_samples_added_to_queue: 1083500
  num_training_step_calls_since_last_synch_worker_weights: 902
  num_weight_broadcasts: 21342
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 272.366
    learner_load_time_ms: 1.328
    learner_load_wait_time_ms: 1.549
iterations_since_restore: 82
node_ip: 127.0.0.1
num_agent_steps_sampled: 1083500
num_agent_steps_trained: 1067000
num_env_steps_sampled: 1083500
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9986581815804
num_env_steps_trained: 1067000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.99864816801
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.75
  ram_util_percent: 77.35714285714286
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058655624167360115
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02357524652060882
  mean_inference_ms: 1.1318181279970314
  mean_raw_obs_processing_ms: 0.25881623340662147
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019462378519885946
    StateBufferConnector_ms: 0.003408710911588849
    ViewRequirementAgentConnector_ms: 0.11683927392059902
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.443396226415095
  episode_reward_min: 1.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 9.0, 10.0, 2.0, 10.0, 8.0, 6.0, 8.0, 6.0, 10.0, 8.0, 7.0,
      9.0, 10.0, 6.0, 6.0, 6.0, 9.0, 7.0, 6.0, 15.0, 10.0, 5.0, 7.0, 4.0, 2.0, 8.0,
      8.0, 12.0, 1.0, 4.0, 2.0, 5.0, 12.0, 10.0, 9.0, 8.0, 6.0, 11.0, 5.0, 7.0, 6.0,
      6.0, 7.0, 8.0, 7.0, 4.0, 7.0, 3.0, 11.0, 12.0, 7.0, 10.0, 9.0, 9.0, 5.0, 9.0,
      14.0, 7.0, 11.0, 8.0, 3.0, 9.0, 8.0, 11.0, 9.0, 9.0, 10.0, 15.0, 7.0, 8.0, 8.0,
      9.0, 6.0, 7.0, 8.0, 12.0, 8.0, 6.0, 7.0, 8.0, 6.0, 6.0, 5.0, 8.0, 9.0, 3.0,
      7.0, 3.0, 10.0, 4.0, 10.0, 5.0, 1.0, 10.0, 2.0, 6.0, 7.0, 6.0, 9.0, 7.0, 6.0,
      6.0, 10.0, 8.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058655624167360115
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02357524652060882
    mean_inference_ms: 1.1318181279970314
    mean_raw_obs_processing_ms: 0.25881623340662147
time_since_restore: 830.346951007843
time_this_iter_s: 10.089885950088501
time_total_s: 830.346951007843
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000661
timesteps_total: 1083500
training_iteration: 82
trial_id: default
train step: 83
agent_timesteps_total: 1097000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019550096421014695
  StateBufferConnector_ms: 0.003330139886765253
  ViewRequirementAgentConnector_ms: 0.11653650374639601
counters:
  num_agent_steps_sampled: 1097000
  num_agent_steps_trained: 1080500
  num_env_steps_sampled: 1097000
  num_env_steps_trained: 1080500
  num_samples_added_to_queue: 1097000
  num_training_step_calls_since_last_synch_worker_weights: 457
  num_weight_broadcasts: 21609
custom_metrics: {}
date: 2023-08-14_17-11-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.923809523809524
episode_reward_min: 2.0
episodes_this_iter: 105
episodes_total: 8571
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.636777937412262
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -12.040512084960938
        total_loss: 3.7874505519866943
        var_gnorm: 63.95521926879883
        vf_explained_var: 0.7716671824455261
        vf_loss: 38.023704528808594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2161.0
  learner_queue:
    size_count: 2165
    size_mean: 15.68
    size_quantiles: [13.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.7599999999999999
  num_agent_steps_sampled: 1097000
  num_agent_steps_trained: 1080500
  num_env_steps_sampled: 1097000
  num_env_steps_trained: 1080500
  num_samples_added_to_queue: 1097000
  num_training_step_calls_since_last_synch_worker_weights: 457
  num_weight_broadcasts: 21609
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 230.664
    learner_load_time_ms: 1.332
    learner_load_wait_time_ms: 1.647
iterations_since_restore: 83
node_ip: 127.0.0.1
num_agent_steps_sampled: 1097000
num_agent_steps_trained: 1080500
num_env_steps_sampled: 1097000
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9948823645998
num_env_steps_trained: 1080500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9948823645998
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 51.20666666666668
  ram_util_percent: 75.88666666666667
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058643857119546346
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02356242232385109
  mean_inference_ms: 1.1315341495460547
  mean_raw_obs_processing_ms: 0.2587491626624972
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019550096421014695
    StateBufferConnector_ms: 0.003330139886765253
    ViewRequirementAgentConnector_ms: 0.11653650374639601
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.923809523809524
  episode_reward_min: 2.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 7.0, 5.0, 7.0, 7.0, 4.0, 9.0, 8.0, 5.0, 13.0, 10.0,
      9.0, 11.0, 2.0, 7.0, 6.0, 7.0, 6.0, 9.0, 5.0, 8.0, 9.0, 10.0, 3.0, 3.0, 6.0,
      13.0, 4.0, 5.0, 9.0, 6.0, 6.0, 7.0, 9.0, 7.0, 2.0, 3.0, 9.0, 5.0, 6.0, 7.0,
      10.0, 13.0, 10.0, 4.0, 7.0, 11.0, 6.0, 5.0, 6.0, 12.0, 8.0, 4.0, 8.0, 7.0, 6.0,
      13.0, 9.0, 5.0, 7.0, 9.0, 10.0, 8.0, 9.0, 6.0, 3.0, 4.0, 9.0, 8.0, 11.0, 5.0,
      3.0, 7.0, 5.0, 4.0, 5.0, 7.0, 5.0, 5.0, 5.0, 9.0, 5.0, 8.0, 8.0, 9.0, 6.0, 8.0,
      2.0, 7.0, 5.0, 3.0, 9.0, 4.0, 8.0, 9.0, 8.0, 8.0, 4.0, 10.0, 4.0, 11.0, 8.0,
      9.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058643857119546346
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02356242232385109
    mean_inference_ms: 1.1315341495460547
    mean_raw_obs_processing_ms: 0.2587491626624972
time_since_restore: 840.4598371982574
time_this_iter_s: 10.112886190414429
time_total_s: 840.4598371982574
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.042
timestamp: 1692000671
timesteps_total: 1097000
training_iteration: 83
trial_id: default
train step: 84
agent_timesteps_total: 1110900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018459066338495377
  StateBufferConnector_ms: 0.003203339532974663
  ViewRequirementAgentConnector_ms: 0.11248304209577928
counters:
  num_agent_steps_sampled: 1110900
  num_agent_steps_trained: 1094000
  num_env_steps_sampled: 1110900
  num_env_steps_trained: 1094000
  num_samples_added_to_queue: 1110500
  num_training_step_calls_since_last_synch_worker_weights: 83
  num_weight_broadcasts: 21883
custom_metrics: {}
date: 2023-08-14_17-11-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.1192660550458715
episode_reward_min: 0.0
episodes_this_iter: 109
episodes_total: 8680
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6670669913291931
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -3.9021103382110596
        total_loss: 8.555115699768066
        var_gnorm: 63.96544647216797
        vf_explained_var: 0.9693725109100342
        vf_loss: 31.585121154785156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2188.0
  learner_queue:
    size_count: 2194
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.22
  num_agent_steps_sampled: 1110900
  num_agent_steps_trained: 1094000
  num_env_steps_sampled: 1110900
  num_env_steps_trained: 1094000
  num_samples_added_to_queue: 1110500
  num_training_step_calls_since_last_synch_worker_weights: 83
  num_weight_broadcasts: 21883
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 189.527
    learner_load_time_ms: 1.323
    learner_load_wait_time_ms: 1.492
iterations_since_restore: 84
node_ip: 127.0.0.1
num_agent_steps_sampled: 1110900
num_agent_steps_trained: 1094000
num_env_steps_sampled: 1110900
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.997812751397
num_env_steps_trained: 1094000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9978756938028
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.95714285714286
  ram_util_percent: 74.5
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05866200117933779
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02353632666836284
  mean_inference_ms: 1.1307926128270467
  mean_raw_obs_processing_ms: 0.25862714993007135
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018459066338495377
    StateBufferConnector_ms: 0.003203339532974663
    ViewRequirementAgentConnector_ms: 0.11248304209577928
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.1192660550458715
  episode_reward_min: 0.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [7.0, 7.0, 3.0, 4.0, 7.0, 4.0, 10.0, 4.0, 2.0, 2.0, 3.0, 8.0,
      10.0, 2.0, 1.0, 5.0, 2.0, 8.0, 6.0, 3.0, 4.0, 5.0, 4.0, 9.0, 4.0, 9.0, 3.0,
      11.0, 13.0, 13.0, 6.0, 15.0, 7.0, 12.0, 8.0, 10.0, 9.0, 9.0, 10.0, 7.0, 5.0,
      9.0, 5.0, 4.0, 6.0, 8.0, 8.0, 9.0, 8.0, 9.0, 12.0, 7.0, 8.0, 8.0, 5.0, 3.0,
      5.0, 4.0, 6.0, 7.0, 2.0, 3.0, 7.0, 4.0, 3.0, 0.0, 6.0, 5.0, 5.0, 9.0, 5.0, 6.0,
      9.0, 7.0, 2.0, 5.0, 4.0, 9.0, 6.0, 10.0, 11.0, 8.0, 8.0, 10.0, 8.0, 8.0, 8.0,
      5.0, 16.0, 7.0, 11.0, 12.0, 10.0, 11.0, 7.0, 12.0, 7.0, 11.0, 12.0, 10.0, 8.0,
      5.0, 10.0, 11.0, 9.0, 7.0, 9.0, 4.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05866200117933779
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02353632666836284
    mean_inference_ms: 1.1307926128270467
    mean_raw_obs_processing_ms: 0.25862714993007135
time_since_restore: 850.6073410511017
time_this_iter_s: 10.147503852844238
time_total_s: 850.6073410511017
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1692000682
timesteps_total: 1110900
training_iteration: 84
trial_id: default
train step: 85
agent_timesteps_total: 1124750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01887325887326841
  StateBufferConnector_ms: 0.003224611282348633
  ViewRequirementAgentConnector_ms: 0.1128201131467466
counters:
  num_agent_steps_sampled: 1124750
  num_agent_steps_trained: 1108000
  num_env_steps_sampled: 1124750
  num_env_steps_trained: 1108000
  num_samples_added_to_queue: 1124500
  num_training_step_calls_since_last_synch_worker_weights: 31
  num_weight_broadcasts: 22155
custom_metrics: {}
date: 2023-08-14_17-11-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.824074074074074
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 8788
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6780732274055481
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -13.870969772338867
        total_loss: 34.004486083984375
        var_gnorm: 63.97147750854492
        vf_explained_var: 0.8658705353736877
        vf_loss: 102.5316390991211
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2216.0
  learner_queue:
    size_count: 2223
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6833300330000647
  num_agent_steps_sampled: 1124750
  num_agent_steps_trained: 1108000
  num_env_steps_sampled: 1124750
  num_env_steps_trained: 1108000
  num_samples_added_to_queue: 1124500
  num_training_step_calls_since_last_synch_worker_weights: 31
  num_weight_broadcasts: 22155
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 146.811
    learner_load_time_ms: 1.34
    learner_load_wait_time_ms: 1.468
iterations_since_restore: 85
node_ip: 127.0.0.1
num_agent_steps_sampled: 1124750
num_agent_steps_trained: 1108000
num_env_steps_sampled: 1124750
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.999141455229
num_env_steps_trained: 1108000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.99913215691
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.55714285714286
  ram_util_percent: 74.66428571428573
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058629181001830295
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023515756798625845
  mean_inference_ms: 1.1301883573963052
  mean_raw_obs_processing_ms: 0.25848492220142816
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01887325887326841
    StateBufferConnector_ms: 0.003224611282348633
    ViewRequirementAgentConnector_ms: 0.1128201131467466
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.824074074074074
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [14.0, 11.0, 11.0, 12.0, 6.0, 8.0, 4.0, 13.0, 6.0, 7.0, 6.0, 6.0,
      7.0, 10.0, 5.0, 7.0, 11.0, 12.0, 14.0, 7.0, 6.0, 12.0, 6.0, 7.0, 9.0, 7.0, 7.0,
      10.0, 2.0, 6.0, 6.0, 14.0, 7.0, 12.0, 8.0, 11.0, 6.0, 9.0, 7.0, 6.0, 14.0, 11.0,
      11.0, 7.0, 10.0, 9.0, 9.0, 10.0, 8.0, 6.0, 8.0, 12.0, 13.0, 7.0, 11.0, 5.0,
      13.0, 9.0, 9.0, 9.0, 8.0, 13.0, 15.0, 12.0, 11.0, 7.0, 12.0, 6.0, 11.0, 6.0,
      9.0, 7.0, 9.0, 13.0, 8.0, 7.0, 10.0, 8.0, 13.0, 5.0, 13.0, 8.0, 9.0, 7.0, 4.0,
      8.0, 6.0, 10.0, 7.0, 7.0, 7.0, 12.0, 9.0, 11.0, 13.0, 5.0, 10.0, 5.0, 8.0, 11.0,
      6.0, 8.0, 11.0, 8.0, 12.0, 8.0, 5.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058629181001830295
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023515756798625845
    mean_inference_ms: 1.1301883573963052
    mean_raw_obs_processing_ms: 0.25848492220142816
time_since_restore: 860.7581870555878
time_this_iter_s: 10.150846004486084
time_total_s: 860.7581870555878
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000692
timesteps_total: 1124750
training_iteration: 85
trial_id: default
train step: 86
agent_timesteps_total: 1138750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018613272850666572
  StateBufferConnector_ms: 0.0032626160787879873
  ViewRequirementAgentConnector_ms: 0.11284701321103158
counters:
  num_agent_steps_sampled: 1138750
  num_agent_steps_trained: 1122000
  num_env_steps_sampled: 1138750
  num_env_steps_trained: 1122000
  num_samples_added_to_queue: 1138500
  num_training_step_calls_since_last_synch_worker_weights: 279
  num_weight_broadcasts: 22431
custom_metrics: {}
date: 2023-08-14_17-11-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 9.8348623853211
episode_reward_min: 3.0
episodes_this_iter: 109
episodes_total: 8897
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6657149195671082
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 25.79717445373535
        total_loss: 93.63423156738281
        var_gnorm: 63.98015594482422
        vf_explained_var: 0.8564903140068054
        vf_loss: 142.33126831054688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2244.0
  learner_queue:
    size_count: 2250
    size_mean: 15.1
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.676305461424021
  num_agent_steps_sampled: 1138750
  num_agent_steps_trained: 1122000
  num_env_steps_sampled: 1138750
  num_env_steps_trained: 1122000
  num_samples_added_to_queue: 1138500
  num_training_step_calls_since_last_synch_worker_weights: 279
  num_weight_broadcasts: 22431
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 173.461
    learner_load_time_ms: 7.646
    learner_load_wait_time_ms: 1.528
iterations_since_restore: 86
node_ip: 127.0.0.1
num_agent_steps_sampled: 1138750
num_agent_steps_trained: 1122000
num_env_steps_sampled: 1138750
num_env_steps_sampled_this_iter: 14000
num_env_steps_sampled_throughput_per_sec: 1399.9956941737044
num_env_steps_trained: 1122000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9956941737044
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.76
  ram_util_percent: 74.47333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058592287358088135
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023495282239881662
  mean_inference_ms: 1.1294693347463018
  mean_raw_obs_processing_ms: 0.25832398944052926
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018613272850666572
    StateBufferConnector_ms: 0.0032626160787879873
    ViewRequirementAgentConnector_ms: 0.11284701321103158
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 9.8348623853211
  episode_reward_min: 3.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [11.0, 10.0, 7.0, 10.0, 5.0, 11.0, 16.0, 6.0, 6.0, 12.0, 14.0,
      12.0, 10.0, 14.0, 7.0, 11.0, 13.0, 6.0, 7.0, 14.0, 12.0, 11.0, 6.0, 16.0, 8.0,
      13.0, 8.0, 11.0, 8.0, 14.0, 4.0, 12.0, 9.0, 11.0, 9.0, 8.0, 12.0, 9.0, 10.0,
      14.0, 7.0, 10.0, 10.0, 4.0, 7.0, 9.0, 12.0, 15.0, 12.0, 6.0, 10.0, 10.0, 10.0,
      8.0, 8.0, 13.0, 9.0, 15.0, 9.0, 12.0, 17.0, 8.0, 12.0, 10.0, 5.0, 13.0, 13.0,
      3.0, 12.0, 12.0, 4.0, 8.0, 8.0, 9.0, 10.0, 12.0, 9.0, 8.0, 9.0, 12.0, 8.0, 8.0,
      13.0, 12.0, 10.0, 12.0, 9.0, 13.0, 7.0, 10.0, 8.0, 5.0, 4.0, 10.0, 10.0, 14.0,
      8.0, 14.0, 7.0, 9.0, 8.0, 14.0, 7.0, 14.0, 7.0, 8.0, 9.0, 9.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058592287358088135
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023495282239881662
    mean_inference_ms: 1.1294693347463018
    mean_raw_obs_processing_ms: 0.25832398944052926
time_since_restore: 870.9006128311157
time_this_iter_s: 10.142425775527954
time_total_s: 870.9006128311157
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000702
timesteps_total: 1138750
training_iteration: 86
trial_id: default
train step: 87
agent_timesteps_total: 1152500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01857280731201172
  StateBufferConnector_ms: 0.0032551934785932024
  ViewRequirementAgentConnector_ms: 0.11333906761953765
counters:
  num_agent_steps_sampled: 1152500
  num_agent_steps_trained: 1136000
  num_env_steps_sampled: 1152500
  num_env_steps_trained: 1136000
  num_samples_added_to_queue: 1152500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 22702
custom_metrics: {}
date: 2023-08-14_17-11-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 9.074766355140186
episode_reward_min: 4.0
episodes_this_iter: 107
episodes_total: 9004
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6569967269897461
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -42.29850769042969
        total_loss: 2.107091188430786
        var_gnorm: 63.991024017333984
        vf_explained_var: 0.8775606155395508
        vf_loss: 95.38116455078125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2272.0
  learner_queue:
    size_count: 2274
    size_mean: 15.48
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2039933554633928
  num_agent_steps_sampled: 1152500
  num_agent_steps_trained: 1136000
  num_env_steps_sampled: 1152500
  num_env_steps_trained: 1136000
  num_samples_added_to_queue: 1152500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 22702
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 292.172
    learner_load_time_ms: 7.653
    learner_load_wait_time_ms: 1.505
iterations_since_restore: 87
node_ip: 127.0.0.1
num_agent_steps_sampled: 1152500
num_agent_steps_trained: 1136000
num_env_steps_sampled: 1152500
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1372.7444308295374
num_env_steps_trained: 1136000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1397.7034204809836
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.45714285714286
  ram_util_percent: 73.84285714285716
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05861515935847147
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023473562329123343
  mean_inference_ms: 1.1289429280919965
  mean_raw_obs_processing_ms: 0.2581997835581247
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01857280731201172
    StateBufferConnector_ms: 0.0032551934785932024
    ViewRequirementAgentConnector_ms: 0.11333906761953765
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 9.074766355140186
  episode_reward_min: 4.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 14.0, 7.0, 6.0, 8.0, 5.0, 11.0, 9.0, 8.0, 10.0, 5.0, 8.0,
      10.0, 13.0, 10.0, 9.0, 11.0, 6.0, 7.0, 10.0, 11.0, 8.0, 11.0, 10.0, 10.0, 12.0,
      7.0, 5.0, 9.0, 12.0, 8.0, 8.0, 13.0, 10.0, 14.0, 11.0, 7.0, 14.0, 12.0, 8.0,
      4.0, 9.0, 11.0, 8.0, 12.0, 13.0, 12.0, 12.0, 5.0, 5.0, 10.0, 9.0, 11.0, 7.0,
      9.0, 12.0, 8.0, 7.0, 9.0, 11.0, 7.0, 10.0, 12.0, 6.0, 4.0, 10.0, 7.0, 8.0, 9.0,
      10.0, 10.0, 10.0, 11.0, 9.0, 14.0, 9.0, 10.0, 4.0, 9.0, 5.0, 9.0, 5.0, 8.0,
      4.0, 9.0, 8.0, 10.0, 10.0, 8.0, 10.0, 6.0, 11.0, 12.0, 9.0, 9.0, 10.0, 5.0,
      8.0, 8.0, 6.0, 11.0, 8.0, 12.0, 9.0, 12.0, 10.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05861515935847147
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023473562329123343
    mean_inference_ms: 1.1289429280919965
    mean_raw_obs_processing_ms: 0.2581997835581247
time_since_restore: 880.9811379909515
time_this_iter_s: 10.080525159835815
time_total_s: 880.9811379909515
timers:
  sample_time_ms: 0.039
  synch_weights_time_ms: 0.271
  training_iteration_time_ms: 1.882
timestamp: 1692000712
timesteps_total: 1152500
training_iteration: 87
trial_id: default
train step: 88
agent_timesteps_total: 1166350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01875698019605164
  StateBufferConnector_ms: 0.003346828145718356
  ViewRequirementAgentConnector_ms: 0.11341112469314435
counters:
  num_agent_steps_sampled: 1166350
  num_agent_steps_trained: 1149500
  num_env_steps_sampled: 1166350
  num_env_steps_trained: 1149500
  num_samples_added_to_queue: 1166000
  num_training_step_calls_since_last_synch_worker_weights: 126
  num_weight_broadcasts: 22977
custom_metrics: {}
date: 2023-08-14_17-12-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.412844036697248
episode_reward_min: 3.0
episodes_this_iter: 109
episodes_total: 9113
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7043370604515076
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -31.719451904296875
        total_loss: 2.2953314781188965
        var_gnorm: 63.999507904052734
        vf_explained_var: 0.9208596348762512
        vf_loss: 75.07293701171875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2299.0
  learner_queue:
    size_count: 2305
    size_mean: 15.62
    size_quantiles: [11.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 1.037111372997134
  num_agent_steps_sampled: 1166350
  num_agent_steps_trained: 1149500
  num_env_steps_sampled: 1166350
  num_env_steps_trained: 1149500
  num_samples_added_to_queue: 1166000
  num_training_step_calls_since_last_synch_worker_weights: 126
  num_weight_broadcasts: 22977
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 185.183
    learner_load_time_ms: 7.653
    learner_load_wait_time_ms: 1.524
iterations_since_restore: 88
node_ip: 127.0.0.1
num_agent_steps_sampled: 1166350
num_agent_steps_trained: 1149500
num_env_steps_sampled: 1166350
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.9964997856862
num_env_steps_trained: 1149500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9965882387553
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.635714285714286
  ram_util_percent: 73.71428571428571
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05856716671890275
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023456492134477366
  mean_inference_ms: 1.1283795131212808
  mean_raw_obs_processing_ms: 0.25805524362835053
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01875698019605164
    StateBufferConnector_ms: 0.003346828145718356
    ViewRequirementAgentConnector_ms: 0.11341112469314435
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.412844036697248
  episode_reward_min: 3.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [6.0, 8.0, 10.0, 9.0, 10.0, 14.0, 7.0, 8.0, 6.0, 10.0, 5.0, 5.0,
      8.0, 6.0, 14.0, 7.0, 8.0, 7.0, 7.0, 5.0, 6.0, 10.0, 9.0, 3.0, 13.0, 6.0, 12.0,
      6.0, 12.0, 9.0, 13.0, 7.0, 9.0, 8.0, 9.0, 11.0, 12.0, 8.0, 12.0, 14.0, 9.0,
      9.0, 6.0, 6.0, 11.0, 8.0, 3.0, 12.0, 7.0, 11.0, 9.0, 8.0, 7.0, 10.0, 16.0, 5.0,
      5.0, 7.0, 9.0, 11.0, 7.0, 10.0, 7.0, 5.0, 6.0, 6.0, 7.0, 13.0, 9.0, 10.0, 11.0,
      7.0, 12.0, 9.0, 8.0, 14.0, 7.0, 11.0, 6.0, 11.0, 6.0, 10.0, 6.0, 11.0, 4.0,
      6.0, 8.0, 9.0, 5.0, 9.0, 9.0, 6.0, 9.0, 7.0, 9.0, 3.0, 6.0, 8.0, 6.0, 4.0, 8.0,
      9.0, 8.0, 7.0, 10.0, 10.0, 10.0, 10.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05856716671890275
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023456492134477366
    mean_inference_ms: 1.1283795131212808
    mean_raw_obs_processing_ms: 0.25805524362835053
time_since_restore: 891.1243238449097
time_this_iter_s: 10.14318585395813
time_total_s: 891.1243238449097
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000722
timesteps_total: 1166350
training_iteration: 88
trial_id: default
train step: 89
agent_timesteps_total: 1180350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01854109107901197
  StateBufferConnector_ms: 0.0031873720501540996
  ViewRequirementAgentConnector_ms: 0.11088607508108156
counters:
  num_agent_steps_sampled: 1180350
  num_agent_steps_trained: 1163500
  num_env_steps_sampled: 1180350
  num_env_steps_trained: 1163500
  num_samples_added_to_queue: 1180000
  num_training_step_calls_since_last_synch_worker_weights: 479
  num_weight_broadcasts: 23254
custom_metrics: {}
date: 2023-08-14_17-12-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.36697247706422
episode_reward_min: 3.0
episodes_this_iter: 109
episodes_total: 9222
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6509591937065125
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -34.22166442871094
        total_loss: -15.589432716369629
        var_gnorm: 64.00330352783203
        vf_explained_var: 0.9518213272094727
        vf_loss: 43.77405548095703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2327.0
  learner_queue:
    size_count: 2332
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.40356688476182
  num_agent_steps_sampled: 1180350
  num_agent_steps_trained: 1163500
  num_env_steps_sampled: 1180350
  num_env_steps_trained: 1163500
  num_samples_added_to_queue: 1180000
  num_training_step_calls_since_last_synch_worker_weights: 479
  num_weight_broadcasts: 23254
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 215.077
    learner_load_time_ms: 7.648
    learner_load_wait_time_ms: 1.528
iterations_since_restore: 89
node_ip: 127.0.0.1
num_agent_steps_sampled: 1180350
num_agent_steps_trained: 1163500
num_env_steps_sampled: 1180350
num_env_steps_sampled_this_iter: 14000
num_env_steps_sampled_throughput_per_sec: 1399.9941253908619
num_env_steps_trained: 1163500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9941253908619
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.733333333333334
  ram_util_percent: 73.74666666666667
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05858056144036361
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023432632868142147
  mean_inference_ms: 1.1276175753813884
  mean_raw_obs_processing_ms: 0.2578927760963743
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01854109107901197
    StateBufferConnector_ms: 0.0031873720501540996
    ViewRequirementAgentConnector_ms: 0.11088607508108156
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.36697247706422
  episode_reward_min: 3.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [8.0, 9.0, 7.0, 4.0, 11.0, 11.0, 8.0, 14.0, 11.0, 12.0, 9.0, 9.0,
      12.0, 7.0, 13.0, 13.0, 12.0, 10.0, 12.0, 7.0, 9.0, 6.0, 4.0, 10.0, 9.0, 10.0,
      11.0, 5.0, 10.0, 7.0, 6.0, 10.0, 11.0, 10.0, 13.0, 9.0, 12.0, 11.0, 11.0, 13.0,
      9.0, 16.0, 10.0, 7.0, 10.0, 10.0, 6.0, 15.0, 8.0, 8.0, 11.0, 15.0, 12.0, 5.0,
      8.0, 10.0, 9.0, 3.0, 10.0, 9.0, 7.0, 9.0, 10.0, 16.0, 7.0, 10.0, 10.0, 13.0,
      10.0, 6.0, 12.0, 6.0, 8.0, 10.0, 5.0, 12.0, 6.0, 11.0, 8.0, 5.0, 10.0, 8.0,
      9.0, 11.0, 12.0, 9.0, 10.0, 11.0, 8.0, 9.0, 10.0, 8.0, 9.0, 9.0, 11.0, 8.0,
      13.0, 10.0, 6.0, 6.0, 15.0, 9.0, 8.0, 8.0, 9.0, 6.0, 11.0, 3.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05858056144036361
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023432632868142147
    mean_inference_ms: 1.1276175753813884
    mean_raw_obs_processing_ms: 0.2578927760963743
time_since_restore: 901.2496390342712
time_this_iter_s: 10.125315189361572
time_total_s: 901.2496390342712
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000732
timesteps_total: 1180350
training_iteration: 89
trial_id: default
train step: 90
agent_timesteps_total: 1194200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018489360809326172
  StateBufferConnector_ms: 0.0032186508178710938
  ViewRequirementAgentConnector_ms: 0.11292033725314671
counters:
  num_agent_steps_sampled: 1194200
  num_agent_steps_trained: 1177500
  num_env_steps_sampled: 1194200
  num_env_steps_trained: 1177500
  num_samples_added_to_queue: 1194000
  num_training_step_calls_since_last_synch_worker_weights: 351
  num_weight_broadcasts: 23528
custom_metrics: {}
date: 2023-08-14_17-12-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.777777777777779
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 9330
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6640488505363464
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 24.266225814819336
        total_loss: 104.17761993408203
        var_gnorm: 64.0039291381836
        vf_explained_var: 0.8618534803390503
        vf_loss: 166.46327209472656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2355.0
  learner_queue:
    size_count: 2361
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3098091464026353
  num_agent_steps_sampled: 1194200
  num_agent_steps_trained: 1177500
  num_env_steps_sampled: 1194200
  num_env_steps_trained: 1177500
  num_samples_added_to_queue: 1194000
  num_training_step_calls_since_last_synch_worker_weights: 351
  num_weight_broadcasts: 23528
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 177.632
    learner_load_time_ms: 7.659
    learner_load_wait_time_ms: 1.546
iterations_since_restore: 90
node_ip: 127.0.0.1
num_agent_steps_sampled: 1194200
num_agent_steps_trained: 1177500
num_env_steps_sampled: 1194200
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.9975234314381
num_env_steps_trained: 1177500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9974966093957
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 41.68571428571429
  ram_util_percent: 73.85
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05855090167087483
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023415003612202386
  mean_inference_ms: 1.1270826448352511
  mean_raw_obs_processing_ms: 0.2577712497267691
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018489360809326172
    StateBufferConnector_ms: 0.0032186508178710938
    ViewRequirementAgentConnector_ms: 0.11292033725314671
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.777777777777779
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [14.0, 10.0, 10.0, 9.0, 6.0, 12.0, 10.0, 13.0, 8.0, 6.0, 14.0,
      10.0, 10.0, 14.0, 15.0, 9.0, 5.0, 8.0, 5.0, 11.0, 6.0, 5.0, 5.0, 6.0, 5.0, 5.0,
      7.0, 6.0, 8.0, 14.0, 11.0, 7.0, 7.0, 7.0, 8.0, 10.0, 6.0, 13.0, 11.0, 7.0, 9.0,
      6.0, 8.0, 13.0, 7.0, 16.0, 9.0, 8.0, 9.0, 6.0, 9.0, 10.0, 6.0, 4.0, 8.0, 12.0,
      10.0, 7.0, 6.0, 4.0, 8.0, 7.0, 10.0, 10.0, 5.0, 11.0, 6.0, 10.0, 12.0, 12.0,
      5.0, 7.0, 8.0, 10.0, 9.0, 7.0, 8.0, 6.0, 12.0, 10.0, 11.0, 3.0, 14.0, 9.0, 4.0,
      11.0, 10.0, 11.0, 6.0, 12.0, 10.0, 11.0, 6.0, 10.0, 6.0, 15.0, 8.0, 11.0, 5.0,
      8.0, 14.0, 12.0, 9.0, 8.0, 4.0, 6.0, 11.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05855090167087483
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023415003612202386
    mean_inference_ms: 1.1270826448352511
    mean_raw_obs_processing_ms: 0.2577712497267691
time_since_restore: 911.3843381404877
time_this_iter_s: 10.13469910621643
time_total_s: 911.3843381404877
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000742
timesteps_total: 1194200
training_iteration: 90
trial_id: default
train step: 91
agent_timesteps_total: 1208150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018336339430375534
  StateBufferConnector_ms: 0.003213232213800604
  ViewRequirementAgentConnector_ms: 0.11139176108620384
counters:
  num_agent_steps_sampled: 1208150
  num_agent_steps_trained: 1191500
  num_env_steps_sampled: 1208150
  num_env_steps_trained: 1191500
  num_samples_added_to_queue: 1208000
  num_training_step_calls_since_last_synch_worker_weights: 80
  num_weight_broadcasts: 23804
custom_metrics: {}
date: 2023-08-14_17-12-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 8.0
episode_reward_min: 2.0
episodes_this_iter: 110
episodes_total: 9440
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6908454298973083
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 27.813432693481445
        total_loss: 56.97378158569336
        var_gnorm: 64.01502227783203
        vf_explained_var: 0.9282683730125427
        vf_loss: 65.22915649414062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2383.0
  learner_queue:
    size_count: 2389
    size_mean: 15.22
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4736349615830917
  num_agent_steps_sampled: 1208150
  num_agent_steps_trained: 1191500
  num_env_steps_sampled: 1208150
  num_env_steps_trained: 1191500
  num_samples_added_to_queue: 1208000
  num_training_step_calls_since_last_synch_worker_weights: 80
  num_weight_broadcasts: 23804
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 167.348
    learner_load_time_ms: 1.347
    learner_load_wait_time_ms: 1.494
iterations_since_restore: 91
node_ip: 127.0.0.1
num_agent_steps_sampled: 1208150
num_agent_steps_trained: 1191500
num_env_steps_sampled: 1208150
num_env_steps_sampled_this_iter: 13950
num_env_steps_sampled_throughput_per_sec: 1394.9995676280407
num_env_steps_trained: 1191500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9995660783204
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.478571428571435
  ram_util_percent: 73.87142857142855
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0585334322694951
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02339395221056612
  mean_inference_ms: 1.126486172819604
  mean_raw_obs_processing_ms: 0.25762515642126155
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018336339430375534
    StateBufferConnector_ms: 0.003213232213800604
    ViewRequirementAgentConnector_ms: 0.11139176108620384
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 8.0
  episode_reward_min: 2.0
  episodes_this_iter: 110
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128]
    episode_reward: [8.0, 7.0, 10.0, 9.0, 9.0, 5.0, 10.0, 5.0, 12.0, 6.0, 7.0, 11.0,
      7.0, 8.0, 10.0, 12.0, 10.0, 11.0, 13.0, 8.0, 8.0, 11.0, 13.0, 11.0, 4.0, 6.0,
      6.0, 11.0, 7.0, 9.0, 11.0, 8.0, 9.0, 6.0, 9.0, 11.0, 3.0, 13.0, 12.0, 6.0, 7.0,
      10.0, 10.0, 7.0, 5.0, 9.0, 8.0, 5.0, 8.0, 9.0, 13.0, 4.0, 5.0, 9.0, 7.0, 8.0,
      8.0, 3.0, 6.0, 7.0, 10.0, 6.0, 7.0, 9.0, 7.0, 8.0, 6.0, 9.0, 4.0, 8.0, 11.0,
      8.0, 6.0, 8.0, 7.0, 12.0, 8.0, 13.0, 8.0, 6.0, 7.0, 9.0, 6.0, 6.0, 10.0, 10.0,
      11.0, 7.0, 4.0, 9.0, 10.0, 7.0, 9.0, 7.0, 3.0, 2.0, 9.0, 10.0, 4.0, 7.0, 6.0,
      7.0, 8.0, 7.0, 9.0, 6.0, 13.0, 4.0, 4.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0585334322694951
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02339395221056612
    mean_inference_ms: 1.126486172819604
    mean_raw_obs_processing_ms: 0.25762515642126155
time_since_restore: 921.5318942070007
time_this_iter_s: 10.147556066513062
time_total_s: 921.5318942070007
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000752
timesteps_total: 1208150
training_iteration: 91
trial_id: default
train step: 92
agent_timesteps_total: 1221950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018851333689466815
  StateBufferConnector_ms: 0.0032462806345146394
  ViewRequirementAgentConnector_ms: 0.11289498516332323
counters:
  num_agent_steps_sampled: 1221950
  num_agent_steps_trained: 1205000
  num_env_steps_sampled: 1221950
  num_env_steps_trained: 1205000
  num_samples_added_to_queue: 1221500
  num_training_step_calls_since_last_synch_worker_weights: 475
  num_weight_broadcasts: 24077
custom_metrics: {}
date: 2023-08-14_17-12-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.345794392523365
episode_reward_min: 2.0
episodes_this_iter: 107
episodes_total: 9547
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6239581108093262
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -6.388113975524902
        total_loss: 8.872358322143555
        var_gnorm: 64.0246353149414
        vf_explained_var: 0.9715740084648132
        vf_loss: 36.76052474975586
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2410.0
  learner_queue:
    size_count: 2415
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.40356688476182
  num_agent_steps_sampled: 1221950
  num_agent_steps_trained: 1205000
  num_env_steps_sampled: 1221950
  num_env_steps_trained: 1205000
  num_samples_added_to_queue: 1221500
  num_training_step_calls_since_last_synch_worker_weights: 475
  num_weight_broadcasts: 24077
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 226.922
    learner_load_time_ms: 1.348
    learner_load_wait_time_ms: 1.544
iterations_since_restore: 92
node_ip: 127.0.0.1
num_agent_steps_sampled: 1221950
num_agent_steps_trained: 1205000
num_env_steps_sampled: 1221950
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9981904053575
num_env_steps_trained: 1205000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9982297443714
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 45.56666666666667
  ram_util_percent: 73.9
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05853777367258585
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023373033162579975
  mean_inference_ms: 1.125991518735266
  mean_raw_obs_processing_ms: 0.25751881029887247
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018851333689466815
    StateBufferConnector_ms: 0.0032462806345146394
    ViewRequirementAgentConnector_ms: 0.11289498516332323
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.345794392523365
  episode_reward_min: 2.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 4.0, 10.0, 14.0, 4.0, 9.0, 7.0, 9.0, 5.0, 6.0, 8.0, 7.0,
      6.0, 6.0, 4.0, 7.0, 10.0, 10.0, 9.0, 7.0, 6.0, 8.0, 5.0, 11.0, 7.0, 6.0, 12.0,
      5.0, 4.0, 7.0, 4.0, 10.0, 4.0, 4.0, 12.0, 5.0, 5.0, 10.0, 9.0, 6.0, 8.0, 8.0,
      8.0, 10.0, 10.0, 7.0, 3.0, 9.0, 5.0, 8.0, 7.0, 11.0, 7.0, 11.0, 11.0, 9.0, 7.0,
      7.0, 7.0, 7.0, 11.0, 4.0, 5.0, 5.0, 9.0, 9.0, 7.0, 7.0, 6.0, 8.0, 9.0, 12.0,
      10.0, 9.0, 5.0, 7.0, 5.0, 5.0, 4.0, 8.0, 7.0, 14.0, 3.0, 6.0, 9.0, 8.0, 8.0,
      5.0, 10.0, 6.0, 5.0, 7.0, 7.0, 7.0, 5.0, 6.0, 7.0, 8.0, 8.0, 4.0, 6.0, 13.0,
      6.0, 2.0, 8.0, 4.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05853777367258585
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023373033162579975
    mean_inference_ms: 1.125991518735266
    mean_raw_obs_processing_ms: 0.25751881029887247
time_since_restore: 931.6597883701324
time_this_iter_s: 10.127894163131714
time_total_s: 931.6597883701324
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000763
timesteps_total: 1221950
training_iteration: 92
trial_id: default
train step: 93
agent_timesteps_total: 1235850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018335919861399798
  StateBufferConnector_ms: 0.0031875907827954774
  ViewRequirementAgentConnector_ms: 0.11274267774109446
counters:
  num_agent_steps_sampled: 1235850
  num_agent_steps_trained: 1219000
  num_env_steps_sampled: 1235850
  num_env_steps_trained: 1219000
  num_samples_added_to_queue: 1235500
  num_training_step_calls_since_last_synch_worker_weights: 516
  num_weight_broadcasts: 24351
custom_metrics: {}
date: 2023-08-14_17-12-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.412844036697248
episode_reward_min: 2.0
episodes_this_iter: 109
episodes_total: 9656
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5759369134902954
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.510852813720703
        total_loss: -1.4211997985839844
        var_gnorm: 64.03437042236328
        vf_explained_var: 0.9614185690879822
        vf_loss: 31.938674926757812
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2438.0
  learner_queue:
    size_count: 2443
    size_mean: 15.46
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1525623627379127
  num_agent_steps_sampled: 1235850
  num_agent_steps_trained: 1219000
  num_env_steps_sampled: 1235850
  num_env_steps_trained: 1219000
  num_samples_added_to_queue: 1235500
  num_training_step_calls_since_last_synch_worker_weights: 516
  num_weight_broadcasts: 24351
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 219.014
    learner_load_time_ms: 1.412
    learner_load_wait_time_ms: 1.47
iterations_since_restore: 93
node_ip: 127.0.0.1
num_agent_steps_sampled: 1235850
num_agent_steps_trained: 1219000
num_env_steps_sampled: 1235850
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9948964306343
num_env_steps_trained: 1219000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.994859714308
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.464285714285715
  ram_util_percent: 73.8142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05848849217295399
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023355100639941864
  mean_inference_ms: 1.1254853049345213
  mean_raw_obs_processing_ms: 0.2573760254512073
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018335919861399798
    StateBufferConnector_ms: 0.0031875907827954774
    ViewRequirementAgentConnector_ms: 0.11274267774109446
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.412844036697248
  episode_reward_min: 2.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [6.0, 9.0, 8.0, 12.0, 9.0, 10.0, 4.0, 9.0, 4.0, 6.0, 8.0, 5.0,
      9.0, 3.0, 7.0, 6.0, 10.0, 6.0, 5.0, 10.0, 6.0, 7.0, 4.0, 4.0, 5.0, 10.0, 8.0,
      8.0, 3.0, 8.0, 8.0, 14.0, 9.0, 7.0, 5.0, 6.0, 10.0, 7.0, 10.0, 10.0, 2.0, 4.0,
      7.0, 11.0, 8.0, 8.0, 8.0, 8.0, 3.0, 9.0, 10.0, 10.0, 10.0, 6.0, 5.0, 3.0, 8.0,
      10.0, 11.0, 11.0, 6.0, 5.0, 8.0, 8.0, 12.0, 5.0, 10.0, 7.0, 11.0, 8.0, 8.0,
      9.0, 11.0, 2.0, 5.0, 5.0, 11.0, 6.0, 7.0, 6.0, 8.0, 5.0, 6.0, 10.0, 7.0, 3.0,
      3.0, 13.0, 5.0, 12.0, 9.0, 4.0, 8.0, 8.0, 4.0, 10.0, 4.0, 10.0, 6.0, 7.0, 8.0,
      7.0, 11.0, 10.0, 6.0, 6.0, 10.0, 5.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05848849217295399
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023355100639941864
    mean_inference_ms: 1.1254853049345213
    mean_raw_obs_processing_ms: 0.2573760254512073
time_since_restore: 941.7838673591614
time_this_iter_s: 10.12407898902893
time_total_s: 941.7838673591614
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000773
timesteps_total: 1235850
training_iteration: 93
trial_id: default
train step: 94
agent_timesteps_total: 1249650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01869267887539334
  StateBufferConnector_ms: 0.003231896294487847
  ViewRequirementAgentConnector_ms: 0.11197703856009024
counters:
  num_agent_steps_sampled: 1249650
  num_agent_steps_trained: 1233000
  num_env_steps_sampled: 1249650
  num_env_steps_trained: 1233000
  num_samples_added_to_queue: 1249500
  num_training_step_calls_since_last_synch_worker_weights: 1218
  num_weight_broadcasts: 24624
custom_metrics: {}
date: 2023-08-14_17-13-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.7592592592592595
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 9764
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6159584522247314
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -7.767977237701416
        total_loss: 18.950035095214844
        var_gnorm: 64.0459213256836
        vf_explained_var: 0.9429035782814026
        vf_loss: 59.59560775756836
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2466.0
  learner_queue:
    size_count: 2470
    size_mean: 15.5
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0630145812734648
  num_agent_steps_sampled: 1249650
  num_agent_steps_trained: 1233000
  num_env_steps_sampled: 1249650
  num_env_steps_trained: 1233000
  num_samples_added_to_queue: 1249500
  num_training_step_calls_since_last_synch_worker_weights: 1218
  num_weight_broadcasts: 24624
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 241.336
    learner_load_time_ms: 1.423
    learner_load_wait_time_ms: 1.616
iterations_since_restore: 94
node_ip: 127.0.0.1
num_agent_steps_sampled: 1249650
num_agent_steps_trained: 1233000
num_env_steps_sampled: 1249650
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.994340919813
num_env_steps_trained: 1233000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9942589041584
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.635714285714286
  ram_util_percent: 73.82857142857142
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05848792641890443
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02333403836358972
  mean_inference_ms: 1.1249611730866496
  mean_raw_obs_processing_ms: 0.25726847451475415
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01869267887539334
    StateBufferConnector_ms: 0.003231896294487847
    ViewRequirementAgentConnector_ms: 0.11197703856009024
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.7592592592592595
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 10.0, 6.0, 9.0, 8.0, 8.0, 7.0, 11.0, 8.0, 7.0, 5.0, 7.0,
      10.0, 9.0, 5.0, 8.0, 7.0, 8.0, 12.0, 9.0, 7.0, 7.0, 11.0, 6.0, 10.0, 7.0, 10.0,
      5.0, 9.0, 8.0, 6.0, 4.0, 9.0, 10.0, 3.0, 11.0, 9.0, 9.0, 9.0, 5.0, 7.0, 4.0,
      7.0, 11.0, 7.0, 9.0, 9.0, 4.0, 12.0, 7.0, 7.0, 7.0, 5.0, 8.0, 9.0, 6.0, 8.0,
      7.0, 8.0, 11.0, 6.0, 6.0, 9.0, 5.0, 10.0, 5.0, 7.0, 8.0, 8.0, 8.0, 9.0, 10.0,
      8.0, 9.0, 9.0, 5.0, 8.0, 7.0, 10.0, 4.0, 10.0, 9.0, 10.0, 9.0, 7.0, 7.0, 15.0,
      4.0, 5.0, 8.0, 9.0, 5.0, 12.0, 5.0, 6.0, 5.0, 6.0, 4.0, 7.0, 5.0, 9.0, 11.0,
      5.0, 13.0, 7.0, 6.0, 11.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05848792641890443
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02333403836358972
    mean_inference_ms: 1.1249611730866496
    mean_raw_obs_processing_ms: 0.25726847451475415
time_since_restore: 951.8737642765045
time_this_iter_s: 10.08989691734314
time_total_s: 951.8737642765045
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1692000783
timesteps_total: 1249650
training_iteration: 94
trial_id: default
train step: 95
agent_timesteps_total: 1263450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01870293483555874
  StateBufferConnector_ms: 0.003288616643887814
  ViewRequirementAgentConnector_ms: 0.11238517048202942
counters:
  num_agent_steps_sampled: 1263450
  num_agent_steps_trained: 1246500
  num_env_steps_sampled: 1263450
  num_env_steps_trained: 1246500
  num_samples_added_to_queue: 1263000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 24897
custom_metrics: {}
date: 2023-08-14_17-13-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.981308411214953
episode_reward_min: 1.0
episodes_this_iter: 107
episodes_total: 9871
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7209742665290833
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -18.32107162475586
        total_loss: -4.000374794006348
        var_gnorm: 64.04730987548828
        vf_explained_var: 0.9424033164978027
        vf_loss: 35.85113525390625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2493.0
  learner_queue:
    size_count: 2496
    size_mean: 15.74
    size_quantiles: [13.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.6575712889109439
  num_agent_steps_sampled: 1263450
  num_agent_steps_trained: 1246500
  num_env_steps_sampled: 1263450
  num_env_steps_trained: 1246500
  num_samples_added_to_queue: 1263000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 24897
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 298.838
    learner_load_time_ms: 1.419
    learner_load_wait_time_ms: 1.599
iterations_since_restore: 95
node_ip: 127.0.0.1
num_agent_steps_sampled: 1263450
num_agent_steps_trained: 1246500
num_env_steps_sampled: 1263450
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.703092572366
num_env_steps_trained: 1246500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.709547081662
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.76428571428572
  ram_util_percent: 73.79999999999998
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058491129683952287
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023315731755677027
  mean_inference_ms: 1.1244992838152255
  mean_raw_obs_processing_ms: 0.25715947536975065
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01870293483555874
    StateBufferConnector_ms: 0.003288616643887814
    ViewRequirementAgentConnector_ms: 0.11238517048202942
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.981308411214953
  episode_reward_min: 1.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 7.0, 12.0, 9.0, 8.0, 9.0, 11.0, 8.0, 8.0, 9.0, 9.0, 11.0,
      6.0, 2.0, 5.0, 10.0, 8.0, 10.0, 9.0, 9.0, 10.0, 7.0, 8.0, 7.0, 8.0, 4.0, 7.0,
      6.0, 10.0, 9.0, 8.0, 10.0, 13.0, 11.0, 9.0, 10.0, 10.0, 3.0, 6.0, 5.0, 11.0,
      6.0, 6.0, 5.0, 9.0, 8.0, 8.0, 8.0, 5.0, 14.0, 7.0, 11.0, 13.0, 7.0, 9.0, 9.0,
      7.0, 8.0, 10.0, 5.0, 9.0, 9.0, 9.0, 13.0, 8.0, 6.0, 7.0, 11.0, 5.0, 8.0, 9.0,
      4.0, 6.0, 5.0, 10.0, 10.0, 6.0, 9.0, 16.0, 12.0, 9.0, 5.0, 11.0, 3.0, 3.0, 8.0,
      7.0, 13.0, 8.0, 12.0, 7.0, 8.0, 7.0, 8.0, 4.0, 4.0, 7.0, 5.0, 9.0, 4.0, 9.0,
      8.0, 8.0, 1.0, 8.0, 7.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058491129683952287
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023315731755677027
    mean_inference_ms: 1.1244992838152255
    mean_raw_obs_processing_ms: 0.25715947536975065
time_since_restore: 961.9546012878418
time_this_iter_s: 10.08083701133728
time_total_s: 961.9546012878418
timers:
  sample_time_ms: 0.066
  synch_weights_time_ms: 0.256
  training_iteration_time_ms: 0.391
timestamp: 1692000793
timesteps_total: 1263450
training_iteration: 95
trial_id: default
train step: 96
agent_timesteps_total: 1277200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018843677308824327
  StateBufferConnector_ms: 0.0032526475411874278
  ViewRequirementAgentConnector_ms: 0.1133596455609357
counters:
  num_agent_steps_sampled: 1277200
  num_agent_steps_trained: 1260500
  num_env_steps_sampled: 1277200
  num_env_steps_trained: 1260500
  num_samples_added_to_queue: 1277000
  num_training_step_calls_since_last_synch_worker_weights: 899
  num_weight_broadcasts: 25169
custom_metrics: {}
date: 2023-08-14_17-13-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.712962962962964
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 9979
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6646454930305481
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -47.95990753173828
        total_loss: -2.7166905403137207
        var_gnorm: 64.0535888671875
        vf_explained_var: 0.8900984525680542
        vf_loss: 97.13288879394531
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2521.0
  learner_queue:
    size_count: 2526
    size_mean: 15.72
    size_quantiles: [12.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.8009993757800314
  num_agent_steps_sampled: 1277200
  num_agent_steps_trained: 1260500
  num_env_steps_sampled: 1277200
  num_env_steps_trained: 1260500
  num_samples_added_to_queue: 1277000
  num_training_step_calls_since_last_synch_worker_weights: 899
  num_weight_broadcasts: 25169
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 212.251
    learner_load_time_ms: 1.42
    learner_load_wait_time_ms: 1.636
iterations_since_restore: 96
node_ip: 127.0.0.1
num_agent_steps_sampled: 1277200
num_agent_steps_trained: 1260500
num_env_steps_sampled: 1277200
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9956071517145
num_env_steps_trained: 1260500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9955272817456
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 45.22
  ram_util_percent: 73.9
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058465927879627524
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023301415554156366
  mean_inference_ms: 1.1240997901044973
  mean_raw_obs_processing_ms: 0.25705511951399196
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018843677308824327
    StateBufferConnector_ms: 0.0032526475411874278
    ViewRequirementAgentConnector_ms: 0.1133596455609357
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.712962962962964
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 9.0, 6.0, 12.0, 12.0, 8.0, 7.0, 8.0, 8.0, 5.0, 4.0, 11.0,
      5.0, 12.0, 8.0, 5.0, 13.0, 5.0, 14.0, 15.0, 8.0, 10.0, 5.0, 9.0, 10.0, 8.0,
      7.0, 13.0, 8.0, 6.0, 11.0, 7.0, 6.0, 11.0, 6.0, 9.0, 11.0, 13.0, 13.0, 6.0,
      11.0, 8.0, 6.0, 9.0, 9.0, 5.0, 11.0, 7.0, 8.0, 9.0, 9.0, 9.0, 13.0, 9.0, 5.0,
      9.0, 10.0, 4.0, 12.0, 12.0, 9.0, 10.0, 14.0, 13.0, 9.0, 13.0, 11.0, 5.0, 7.0,
      11.0, 8.0, 6.0, 4.0, 6.0, 5.0, 5.0, 4.0, 8.0, 11.0, 7.0, 11.0, 11.0, 8.0, 8.0,
      10.0, 6.0, 7.0, 11.0, 7.0, 7.0, 12.0, 10.0, 8.0, 8.0, 17.0, 4.0, 7.0, 9.0, 3.0,
      7.0, 15.0, 14.0, 5.0, 6.0, 10.0, 9.0, 15.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058465927879627524
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023301415554156366
    mean_inference_ms: 1.1240997901044973
    mean_raw_obs_processing_ms: 0.25705511951399196
time_since_restore: 972.080016374588
time_this_iter_s: 10.125415086746216
time_total_s: 972.080016374588
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692000803
timesteps_total: 1277200
training_iteration: 96
trial_id: default
train step: 97
agent_timesteps_total: 1291000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018812108922887733
  StateBufferConnector_ms: 0.0032497776879204642
  ViewRequirementAgentConnector_ms: 0.11340313487582737
counters:
  num_agent_steps_sampled: 1291000
  num_agent_steps_trained: 1274500
  num_env_steps_sampled: 1291000
  num_env_steps_trained: 1274500
  num_samples_added_to_queue: 1291000
  num_training_step_calls_since_last_synch_worker_weights: 820
  num_weight_broadcasts: 25442
custom_metrics: {}
date: 2023-08-14_17-13-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.675925925925926
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 10087
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.693522572517395
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -12.002318382263184
        total_loss: 24.692520141601562
        var_gnorm: 64.05867004394531
        vf_explained_var: 0.8855039477348328
        vf_loss: 80.32490539550781
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2549.0
  learner_queue:
    size_count: 2553
    size_mean: 15.56
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9830564581955605
  num_agent_steps_sampled: 1291000
  num_agent_steps_trained: 1274500
  num_env_steps_sampled: 1291000
  num_env_steps_trained: 1274500
  num_samples_added_to_queue: 1291000
  num_training_step_calls_since_last_synch_worker_weights: 820
  num_weight_broadcasts: 25442
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 231.97
    learner_load_time_ms: 1.487
    learner_load_wait_time_ms: 1.48
iterations_since_restore: 97
node_ip: 127.0.0.1
num_agent_steps_sampled: 1291000
num_agent_steps_trained: 1274500
num_env_steps_sampled: 1291000
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9958872917673
num_env_steps_trained: 1274500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9958276873
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.364285714285714
  ram_util_percent: 73.82857142857142
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05845414913375043
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023285367485745573
  mean_inference_ms: 1.1236615556758838
  mean_raw_obs_processing_ms: 0.25695274146885966
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018812108922887733
    StateBufferConnector_ms: 0.0032497776879204642
    ViewRequirementAgentConnector_ms: 0.11340313487582737
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.675925925925926
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 10.0, 7.0, 11.0, 8.0, 13.0, 8.0, 8.0, 7.0, 7.0, 8.0, 11.0,
      6.0, 12.0, 8.0, 7.0, 10.0, 11.0, 15.0, 7.0, 7.0, 9.0, 10.0, 15.0, 6.0, 7.0,
      11.0, 7.0, 8.0, 11.0, 11.0, 16.0, 6.0, 13.0, 10.0, 9.0, 10.0, 5.0, 4.0, 11.0,
      12.0, 6.0, 11.0, 8.0, 7.0, 6.0, 3.0, 9.0, 8.0, 7.0, 8.0, 9.0, 9.0, 8.0, 6.0,
      7.0, 10.0, 12.0, 8.0, 8.0, 9.0, 11.0, 12.0, 13.0, 5.0, 10.0, 5.0, 9.0, 10.0,
      7.0, 4.0, 10.0, 7.0, 10.0, 9.0, 11.0, 12.0, 9.0, 8.0, 7.0, 10.0, 10.0, 5.0,
      14.0, 7.0, 7.0, 8.0, 8.0, 4.0, 9.0, 8.0, 10.0, 9.0, 10.0, 9.0, 8.0, 13.0, 7.0,
      6.0, 8.0, 1.0, 10.0, 11.0, 3.0, 9.0, 7.0, 13.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05845414913375043
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023285367485745573
    mean_inference_ms: 1.1236615556758838
    mean_raw_obs_processing_ms: 0.25695274146885966
time_since_restore: 982.1938345432281
time_this_iter_s: 10.113818168640137
time_total_s: 982.1938345432281
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000813
timesteps_total: 1291000
training_iteration: 97
trial_id: default
train step: 98
agent_timesteps_total: 1304900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01877480083041721
  StateBufferConnector_ms: 0.0032912801813196253
  ViewRequirementAgentConnector_ms: 0.11313182336312753
counters:
  num_agent_steps_sampled: 1304900
  num_agent_steps_trained: 1288000
  num_env_steps_sampled: 1304900
  num_env_steps_trained: 1288000
  num_samples_added_to_queue: 1304500
  num_training_step_calls_since_last_synch_worker_weights: 272
  num_weight_broadcasts: 25714
custom_metrics: {}
date: 2023-08-14_17-13-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.064814814814815
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 10195
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6455883383750916
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.678096771240234
        total_loss: 27.66294288635254
        var_gnorm: 64.0638198852539
        vf_explained_var: 0.9158160090446472
        vf_loss: 81.1379623413086
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2576.0
  learner_queue:
    size_count: 2582
    size_mean: 15.46
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.22
  num_agent_steps_sampled: 1304900
  num_agent_steps_trained: 1288000
  num_env_steps_sampled: 1304900
  num_env_steps_trained: 1288000
  num_samples_added_to_queue: 1304500
  num_training_step_calls_since_last_synch_worker_weights: 272
  num_weight_broadcasts: 25714
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 189.59
    learner_load_time_ms: 1.428
    learner_load_wait_time_ms: 1.634
iterations_since_restore: 98
node_ip: 127.0.0.1
num_agent_steps_sampled: 1304900
num_agent_steps_trained: 1288000
num_env_steps_sampled: 1304900
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9996023179237
num_env_steps_trained: 1288000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9996137620124
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.66428571428571
  ram_util_percent: 73.89285714285714
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05844311993244678
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02326831720962146
  mean_inference_ms: 1.123204506679996
  mean_raw_obs_processing_ms: 0.25683887611949235
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01877480083041721
    StateBufferConnector_ms: 0.0032912801813196253
    ViewRequirementAgentConnector_ms: 0.11313182336312753
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.064814814814815
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 8.0, 10.0, 8.0, 7.0, 4.0, 9.0, 7.0, 8.0, 10.0, 10.0,
      9.0, 2.0, 9.0, 9.0, 15.0, 9.0, 9.0, 11.0, 3.0, 10.0, 10.0, 5.0, 6.0, 4.0, 6.0,
      7.0, 8.0, 11.0, 8.0, 8.0, 6.0, 5.0, 5.0, 10.0, 7.0, 6.0, 6.0, 10.0, 9.0, 9.0,
      10.0, 7.0, 7.0, 10.0, 10.0, 9.0, 11.0, 9.0, 5.0, 8.0, 10.0, 6.0, 8.0, 11.0,
      7.0, 6.0, 10.0, 7.0, 8.0, 8.0, 9.0, 7.0, 6.0, 8.0, 7.0, 9.0, 10.0, 10.0, 5.0,
      7.0, 9.0, 9.0, 12.0, 7.0, 8.0, 12.0, 5.0, 6.0, 9.0, 6.0, 10.0, 10.0, 8.0, 4.0,
      11.0, 7.0, 10.0, 5.0, 10.0, 11.0, 8.0, 8.0, 10.0, 13.0, 11.0, 8.0, 3.0, 6.0,
      13.0, 8.0, 7.0, 2.0, 11.0, 5.0, 7.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05844311993244678
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02326831720962146
    mean_inference_ms: 1.123204506679996
    mean_raw_obs_processing_ms: 0.25683887611949235
time_since_restore: 992.3517796993256
time_this_iter_s: 10.157945156097412
time_total_s: 992.3517796993256
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000823
timesteps_total: 1304900
training_iteration: 98
trial_id: default
train step: 99
agent_timesteps_total: 1318800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018648270073286986
  StateBufferConnector_ms: 0.0033046127459324826
  ViewRequirementAgentConnector_ms: 0.1130447475188369
counters:
  num_agent_steps_sampled: 1318800
  num_agent_steps_trained: 1302000
  num_env_steps_sampled: 1318800
  num_env_steps_trained: 1302000
  num_samples_added_to_queue: 1318500
  num_training_step_calls_since_last_synch_worker_weights: 237
  num_weight_broadcasts: 25989
custom_metrics: {}
date: 2023-08-14_17-13-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.376146788990826
episode_reward_min: 1.0
episodes_this_iter: 109
episodes_total: 10304
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6386655569076538
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 43.87303924560547
        total_loss: 94.60137939453125
        var_gnorm: 64.07355499267578
        vf_explained_var: 0.9054303765296936
        vf_loss: 107.84333038330078
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2604.0
  learner_queue:
    size_count: 2611
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6351146748775753
  num_agent_steps_sampled: 1318800
  num_agent_steps_trained: 1302000
  num_env_steps_sampled: 1318800
  num_env_steps_trained: 1302000
  num_samples_added_to_queue: 1318500
  num_training_step_calls_since_last_synch_worker_weights: 237
  num_weight_broadcasts: 25989
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 148.922
    learner_load_time_ms: 1.429
    learner_load_wait_time_ms: 1.484
iterations_since_restore: 99
node_ip: 127.0.0.1
num_agent_steps_sampled: 1318800
num_agent_steps_trained: 1302000
num_env_steps_sampled: 1318800
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9933388552402
num_env_steps_trained: 1302000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9932909333354
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.580000000000005
  ram_util_percent: 73.81999999999998
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05841528916445114
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023252409410985483
  mean_inference_ms: 1.1227786349341573
  mean_raw_obs_processing_ms: 0.2567267548299286
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018648270073286986
    StateBufferConnector_ms: 0.0033046127459324826
    ViewRequirementAgentConnector_ms: 0.1130447475188369
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.376146788990826
  episode_reward_min: 1.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [8.0, 11.0, 7.0, 10.0, 7.0, 10.0, 8.0, 6.0, 4.0, 3.0, 8.0, 9.0,
      9.0, 11.0, 3.0, 6.0, 5.0, 3.0, 5.0, 7.0, 8.0, 8.0, 6.0, 6.0, 11.0, 9.0, 7.0,
      10.0, 6.0, 6.0, 11.0, 6.0, 11.0, 9.0, 11.0, 8.0, 8.0, 10.0, 2.0, 5.0, 7.0, 11.0,
      10.0, 6.0, 14.0, 8.0, 4.0, 5.0, 13.0, 6.0, 8.0, 7.0, 6.0, 8.0, 7.0, 5.0, 6.0,
      7.0, 7.0, 10.0, 7.0, 8.0, 7.0, 8.0, 7.0, 8.0, 5.0, 7.0, 8.0, 7.0, 5.0, 7.0,
      8.0, 11.0, 6.0, 9.0, 6.0, 6.0, 10.0, 7.0, 11.0, 8.0, 3.0, 8.0, 4.0, 3.0, 10.0,
      4.0, 9.0, 9.0, 7.0, 1.0, 4.0, 7.0, 8.0, 8.0, 6.0, 4.0, 9.0, 7.0, 5.0, 9.0, 12.0,
      7.0, 5.0, 12.0, 8.0, 8.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05841528916445114
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023252409410985483
    mean_inference_ms: 1.1227786349341573
    mean_raw_obs_processing_ms: 0.2567267548299286
time_since_restore: 1002.6272506713867
time_this_iter_s: 10.275470972061157
time_total_s: 1002.6272506713867
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000834
timesteps_total: 1318800
training_iteration: 99
trial_id: default
train step: 100
agent_timesteps_total: 1332500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018684663505197686
  StateBufferConnector_ms: 0.003327164694527599
  ViewRequirementAgentConnector_ms: 0.11335199124345155
counters:
  num_agent_steps_sampled: 1332500
  num_agent_steps_trained: 1316000
  num_env_steps_sampled: 1332500
  num_env_steps_trained: 1316000
  num_samples_added_to_queue: 1332500
  num_training_step_calls_since_last_synch_worker_weights: 41
  num_weight_broadcasts: 26260
custom_metrics: {}
date: 2023-08-14_17-14-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.514018691588785
episode_reward_min: 1.0
episodes_this_iter: 107
episodes_total: 10411
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6729869246482849
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.9006404876709
        total_loss: 69.268310546875
        var_gnorm: 64.09545135498047
        vf_explained_var: 0.8799948692321777
        vf_loss: 107.4652099609375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2632.0
  learner_queue:
    size_count: 2637
    size_mean: 15.1
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6401219466856727
  num_agent_steps_sampled: 1332500
  num_agent_steps_trained: 1316000
  num_env_steps_sampled: 1332500
  num_env_steps_trained: 1316000
  num_samples_added_to_queue: 1332500
  num_training_step_calls_since_last_synch_worker_weights: 41
  num_weight_broadcasts: 26260
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 197.422
    learner_load_time_ms: 1.441
    learner_load_wait_time_ms: 1.545
iterations_since_restore: 100
node_ip: 127.0.0.1
num_agent_steps_sampled: 1332500
num_agent_steps_trained: 1316000
num_env_steps_sampled: 1332500
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9964397046106
num_env_steps_trained: 1316000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9963617419378
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 41.02857142857143
  ram_util_percent: 73.5
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05843589049664742
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023234775785965545
  mean_inference_ms: 1.1224711720060352
  mean_raw_obs_processing_ms: 0.25664035465687485
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018684663505197686
    StateBufferConnector_ms: 0.003327164694527599
    ViewRequirementAgentConnector_ms: 0.11335199124345155
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.514018691588785
  episode_reward_min: 1.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 10.0, 9.0, 5.0, 6.0, 5.0, 9.0, 5.0, 1.0, 13.0, 11.0, 6.0,
      6.0, 7.0, 5.0, 7.0, 13.0, 9.0, 3.0, 13.0, 6.0, 7.0, 8.0, 11.0, 7.0, 4.0, 11.0,
      12.0, 6.0, 8.0, 5.0, 8.0, 7.0, 6.0, 7.0, 12.0, 13.0, 5.0, 6.0, 6.0, 8.0, 11.0,
      5.0, 12.0, 6.0, 7.0, 5.0, 3.0, 8.0, 7.0, 7.0, 7.0, 7.0, 9.0, 6.0, 4.0, 7.0,
      10.0, 15.0, 8.0, 5.0, 5.0, 6.0, 6.0, 8.0, 9.0, 10.0, 5.0, 13.0, 4.0, 8.0, 4.0,
      5.0, 5.0, 6.0, 9.0, 10.0, 5.0, 8.0, 3.0, 6.0, 5.0, 11.0, 5.0, 5.0, 3.0, 4.0,
      7.0, 7.0, 9.0, 3.0, 6.0, 8.0, 9.0, 11.0, 7.0, 13.0, 9.0, 1.0, 11.0, 7.0, 13.0,
      9.0, 14.0, 9.0, 10.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05843589049664742
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023234775785965545
    mean_inference_ms: 1.1224711720060352
    mean_raw_obs_processing_ms: 0.25664035465687485
time_since_restore: 1012.7690536975861
time_this_iter_s: 10.14180302619934
time_total_s: 1012.7690536975861
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000844
timesteps_total: 1332500
training_iteration: 100
trial_id: default
train step: 101
agent_timesteps_total: 1346300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018648085770783602
  StateBufferConnector_ms: 0.0032133526272243923
  ViewRequirementAgentConnector_ms: 0.11210309134589301
counters:
  num_agent_steps_sampled: 1346300
  num_agent_steps_trained: 1329500
  num_env_steps_sampled: 1346300
  num_env_steps_trained: 1329500
  num_samples_added_to_queue: 1346000
  num_training_step_calls_since_last_synch_worker_weights: 619
  num_weight_broadcasts: 26533
custom_metrics: {}
date: 2023-08-14_17-14-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.055555555555555
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 10519
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6898630857467651
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -17.80837631225586
        total_loss: 40.66523361206055
        var_gnorm: 64.11279296875
        vf_explained_var: 0.8457838892936707
        vf_loss: 123.8458480834961
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2659.0
  learner_queue:
    size_count: 2664
    size_mean: 15.28
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.35705563629499
  num_agent_steps_sampled: 1346300
  num_agent_steps_trained: 1329500
  num_env_steps_sampled: 1346300
  num_env_steps_trained: 1329500
  num_samples_added_to_queue: 1346000
  num_training_step_calls_since_last_synch_worker_weights: 619
  num_weight_broadcasts: 26533
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 218.839
    learner_load_time_ms: 1.5
    learner_load_wait_time_ms: 1.574
iterations_since_restore: 101
node_ip: 127.0.0.1
num_agent_steps_sampled: 1346300
num_agent_steps_trained: 1329500
num_env_steps_sampled: 1346300
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.996282110694
num_env_steps_trained: 1329500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9963629343745
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.35
  ram_util_percent: 73.57857142857142
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058410358681049254
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023220958153578653
  mean_inference_ms: 1.1221204310155417
  mean_raw_obs_processing_ms: 0.2565303905314252
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018648085770783602
    StateBufferConnector_ms: 0.0032133526272243923
    ViewRequirementAgentConnector_ms: 0.11210309134589301
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.055555555555555
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 6.0, 8.0, 10.0, 7.0, 4.0, 3.0, 5.0, 8.0, 10.0, 4.0, 7.0,
      9.0, 5.0, 6.0, 9.0, 11.0, 7.0, 4.0, 5.0, 9.0, 9.0, 3.0, 9.0, 8.0, 8.0, 6.0,
      8.0, 7.0, 8.0, 11.0, 11.0, 7.0, 9.0, 5.0, 6.0, 9.0, 10.0, 11.0, 11.0, 5.0, 13.0,
      9.0, 14.0, 3.0, 5.0, 6.0, 13.0, 12.0, 7.0, 10.0, 11.0, 13.0, 7.0, 10.0, 4.0,
      10.0, 1.0, 8.0, 6.0, 9.0, 10.0, 7.0, 10.0, 8.0, 7.0, 9.0, 2.0, 13.0, 7.0, 10.0,
      6.0, 5.0, 15.0, 4.0, 10.0, 11.0, 7.0, 5.0, 11.0, 2.0, 10.0, 8.0, 8.0, 11.0,
      8.0, 7.0, 7.0, 9.0, 5.0, 10.0, 7.0, 7.0, 5.0, 12.0, 13.0, 14.0, 9.0, 13.0, 3.0,
      12.0, 5.0, 8.0, 8.0, 9.0, 14.0, 4.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058410358681049254
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023220958153578653
    mean_inference_ms: 1.1221204310155417
    mean_raw_obs_processing_ms: 0.2565303905314252
time_since_restore: 1022.8999955654144
time_this_iter_s: 10.13094186782837
time_total_s: 1022.8999955654144
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.06
timestamp: 1692000854
timesteps_total: 1346300
training_iteration: 101
trial_id: default
train step: 102
agent_timesteps_total: 1360100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01863475157835773
  StateBufferConnector_ms: 0.0032150856802396683
  ViewRequirementAgentConnector_ms: 0.1127004623413086
counters:
  num_agent_steps_sampled: 1360100
  num_agent_steps_trained: 1343500
  num_env_steps_sampled: 1360100
  num_env_steps_trained: 1343500
  num_samples_added_to_queue: 1360000
  num_training_step_calls_since_last_synch_worker_weights: 1085
  num_weight_broadcasts: 26805
custom_metrics: {}
date: 2023-08-14_17-14-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.336448598130842
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 10626
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7046839594841003
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 125.02951049804688
        total_loss: 229.37339782714844
        var_gnorm: 64.12464904785156
        vf_explained_var: 0.8266372084617615
        vf_loss: 215.73463439941406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2687.0
  learner_queue:
    size_count: 2691
    size_mean: 15.54
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0432641084595982
  num_agent_steps_sampled: 1360100
  num_agent_steps_trained: 1343500
  num_env_steps_sampled: 1360100
  num_env_steps_trained: 1343500
  num_samples_added_to_queue: 1360000
  num_training_step_calls_since_last_synch_worker_weights: 1085
  num_weight_broadcasts: 26805
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 238.63
    learner_load_time_ms: 1.427
    learner_load_wait_time_ms: 1.626
iterations_since_restore: 102
node_ip: 127.0.0.1
num_agent_steps_sampled: 1360100
num_agent_steps_trained: 1343500
num_env_steps_sampled: 1360100
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.993386777145
num_env_steps_trained: 1343500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9932909333354
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.7
  ram_util_percent: 73.53333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058382873791432525
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02320714984246517
  mean_inference_ms: 1.1217567552153
  mean_raw_obs_processing_ms: 0.2564341918803289
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01863475157835773
    StateBufferConnector_ms: 0.0032150856802396683
    ViewRequirementAgentConnector_ms: 0.1127004623413086
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.336448598130842
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 10.0, 8.0, 6.0, 6.0, 11.0, 6.0, 6.0, 7.0, 6.0, 6.0, 3.0,
      5.0, 5.0, 8.0, 10.0, 11.0, 11.0, 11.0, 8.0, 14.0, 6.0, 9.0, 5.0, 7.0, 4.0, 4.0,
      8.0, 5.0, 10.0, 7.0, 12.0, 8.0, 15.0, 8.0, 6.0, 6.0, 11.0, 7.0, 7.0, 8.0, 6.0,
      4.0, 7.0, 4.0, 11.0, 10.0, 8.0, 10.0, 12.0, 8.0, 12.0, 12.0, 11.0, 13.0, 6.0,
      10.0, 6.0, 10.0, 7.0, 5.0, 5.0, 9.0, 6.0, 9.0, 9.0, 8.0, 9.0, 9.0, 6.0, 11.0,
      12.0, 11.0, 9.0, 11.0, 8.0, 9.0, 9.0, 8.0, 9.0, 4.0, 7.0, 6.0, 6.0, 9.0, 8.0,
      5.0, 13.0, 5.0, 14.0, 10.0, 12.0, 10.0, 6.0, 11.0, 8.0, 9.0, 11.0, 8.0, 10.0,
      8.0, 4.0, 10.0, 13.0, 8.0, 11.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058382873791432525
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02320714984246517
    mean_inference_ms: 1.1217567552153
    mean_raw_obs_processing_ms: 0.2564341918803289
time_since_restore: 1033.009994506836
time_this_iter_s: 10.109998941421509
time_total_s: 1033.009994506836
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1692000864
timesteps_total: 1360100
training_iteration: 102
trial_id: default
train step: 103
agent_timesteps_total: 1373900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01860834934093334
  StateBufferConnector_ms: 0.0032323378103750722
  ViewRequirementAgentConnector_ms: 0.11332896020677355
counters:
  num_agent_steps_sampled: 1373900
  num_agent_steps_trained: 1357000
  num_env_steps_sampled: 1373900
  num_env_steps_trained: 1357000
  num_samples_added_to_queue: 1373500
  num_training_step_calls_since_last_synch_worker_weights: 77
  num_weight_broadcasts: 27076
custom_metrics: {}
date: 2023-08-14_17-14-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.0
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 10734
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7565838694572449
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.342248916625977
        total_loss: 37.84806823730469
        var_gnorm: 64.13483428955078
        vf_explained_var: 0.8605170249938965
        vf_loss: 101.94647216796875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2714.0
  learner_queue:
    size_count: 2721
    size_mean: 15.34
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3944174410842687
  num_agent_steps_sampled: 1373900
  num_agent_steps_trained: 1357000
  num_env_steps_sampled: 1373900
  num_env_steps_trained: 1357000
  num_samples_added_to_queue: 1373500
  num_training_step_calls_since_last_synch_worker_weights: 77
  num_weight_broadcasts: 27076
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 155.848
    learner_load_time_ms: 1.426
    learner_load_wait_time_ms: 1.524
iterations_since_restore: 103
node_ip: 127.0.0.1
num_agent_steps_sampled: 1373900
num_agent_steps_trained: 1357000
num_env_steps_sampled: 1373900
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9949989500085
num_env_steps_trained: 1357000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9951076684865
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.43571428571429
  ram_util_percent: 73.5142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05838889500721729
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023192853249956
  mean_inference_ms: 1.121414642501942
  mean_raw_obs_processing_ms: 0.25635029917761426
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01860834934093334
    StateBufferConnector_ms: 0.0032323378103750722
    ViewRequirementAgentConnector_ms: 0.11332896020677355
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.0
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 9.0, 9.0, 16.0, 6.0, 6.0, 6.0, 8.0, 10.0, 8.0, 10.0, 10.0,
      6.0, 7.0, 7.0, 10.0, 8.0, 9.0, 12.0, 16.0, 10.0, 10.0, 6.0, 9.0, 10.0, 7.0,
      9.0, 9.0, 10.0, 7.0, 3.0, 12.0, 13.0, 7.0, 7.0, 7.0, 9.0, 9.0, 7.0, 8.0, 10.0,
      7.0, 8.0, 8.0, 8.0, 8.0, 6.0, 6.0, 11.0, 14.0, 7.0, 6.0, 15.0, 8.0, 9.0, 6.0,
      9.0, 8.0, 6.0, 7.0, 12.0, 9.0, 11.0, 6.0, 5.0, 7.0, 12.0, 8.0, 9.0, 9.0, 13.0,
      10.0, 9.0, 6.0, 16.0, 12.0, 9.0, 13.0, 10.0, 11.0, 5.0, 10.0, 12.0, 6.0, 12.0,
      7.0, 6.0, 8.0, 12.0, 7.0, 7.0, 13.0, 14.0, 7.0, 8.0, 6.0, 13.0, 7.0, 11.0, 11.0,
      8.0, 15.0, 10.0, 7.0, 7.0, 7.0, 10.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05838889500721729
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023192853249956
    mean_inference_ms: 1.121414642501942
    mean_raw_obs_processing_ms: 0.25635029917761426
time_since_restore: 1043.177143573761
time_this_iter_s: 10.167149066925049
time_total_s: 1043.177143573761
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1692000874
timesteps_total: 1373900
training_iteration: 103
trial_id: default
train step: 104
agent_timesteps_total: 1387700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018794448287398728
  StateBufferConnector_ms: 0.003272074240225333
  ViewRequirementAgentConnector_ms: 0.11248279500890661
counters:
  num_agent_steps_sampled: 1387700
  num_agent_steps_trained: 1371000
  num_env_steps_sampled: 1387700
  num_env_steps_trained: 1371000
  num_samples_added_to_queue: 1387500
  num_training_step_calls_since_last_synch_worker_weights: 147
  num_weight_broadcasts: 27349
custom_metrics: {}
date: 2023-08-14_17-14-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.583333333333334
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 10842
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7333288192749023
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.347622871398926
        total_loss: 59.31695556640625
        var_gnorm: 64.15056610107422
        vf_explained_var: 0.8346661329269409
        vf_loss: 146.66244506835938
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2742.0
  learner_queue:
    size_count: 2748
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6326665305566843
  num_agent_steps_sampled: 1387700
  num_agent_steps_trained: 1371000
  num_env_steps_sampled: 1387700
  num_env_steps_trained: 1371000
  num_samples_added_to_queue: 1387500
  num_training_step_calls_since_last_synch_worker_weights: 147
  num_weight_broadcasts: 27349
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 175.161
    learner_load_time_ms: 1.413
    learner_load_wait_time_ms: 1.475
iterations_since_restore: 104
node_ip: 127.0.0.1
num_agent_steps_sampled: 1387700
num_agent_steps_trained: 1371000
num_env_steps_sampled: 1387700
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9934854814976
num_env_steps_trained: 1371000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.993391068186
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.49285714285713
  ram_util_percent: 73.59285714285714
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058380026722656644
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02318023072663655
  mean_inference_ms: 1.121105479441282
  mean_raw_obs_processing_ms: 0.2562563962583324
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018794448287398728
    StateBufferConnector_ms: 0.003272074240225333
    ViewRequirementAgentConnector_ms: 0.11248279500890661
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.583333333333334
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 7.0, 15.0, 11.0, 9.0, 10.0, 9.0, 6.0, 11.0, 8.0, 11.0, 9.0,
      9.0, 11.0, 7.0, 9.0, 9.0, 9.0, 9.0, 5.0, 5.0, 7.0, 8.0, 8.0, 10.0, 5.0, 6.0,
      11.0, 9.0, 5.0, 5.0, 8.0, 11.0, 9.0, 9.0, 5.0, 11.0, 16.0, 11.0, 8.0, 11.0,
      3.0, 11.0, 9.0, 10.0, 7.0, 5.0, 9.0, 7.0, 10.0, 6.0, 10.0, 7.0, 9.0, 6.0, 8.0,
      6.0, 11.0, 10.0, 10.0, 8.0, 11.0, 10.0, 9.0, 6.0, 8.0, 12.0, 7.0, 8.0, 13.0,
      11.0, 7.0, 12.0, 5.0, 8.0, 9.0, 9.0, 11.0, 8.0, 8.0, 9.0, 10.0, 13.0, 9.0, 6.0,
      9.0, 10.0, 6.0, 9.0, 9.0, 11.0, 5.0, 10.0, 13.0, 4.0, 9.0, 5.0, 8.0, 7.0, 8.0,
      7.0, 9.0, 7.0, 9.0, 5.0, 6.0, 6.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058380026722656644
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02318023072663655
    mean_inference_ms: 1.121105479441282
    mean_raw_obs_processing_ms: 0.2562563962583324
time_since_restore: 1053.3375325202942
time_this_iter_s: 10.160388946533203
time_total_s: 1053.3375325202942
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000884
timesteps_total: 1387700
training_iteration: 104
trial_id: default
train step: 105
agent_timesteps_total: 1401550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018743200039644855
  StateBufferConnector_ms: 0.0033037378153669725
  ViewRequirementAgentConnector_ms: 0.11297190954925818
counters:
  num_agent_steps_sampled: 1401550
  num_agent_steps_trained: 1385000
  num_env_steps_sampled: 1401550
  num_env_steps_trained: 1385000
  num_samples_added_to_queue: 1401500
  num_training_step_calls_since_last_synch_worker_weights: 262
  num_weight_broadcasts: 27622
custom_metrics: {}
date: 2023-08-14_17-14-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.779816513761467
episode_reward_min: 3.0
episodes_this_iter: 109
episodes_total: 10951
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7416092753410339
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -28.201923370361328
        total_loss: 28.38106918334961
        var_gnorm: 64.1834945678711
        vf_explained_var: 0.8775707483291626
        vf_loss: 120.58207702636719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2770.0
  learner_queue:
    size_count: 2776
    size_mean: 15.2
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5231546211727816
  num_agent_steps_sampled: 1401550
  num_agent_steps_trained: 1385000
  num_env_steps_sampled: 1401550
  num_env_steps_trained: 1385000
  num_samples_added_to_queue: 1401500
  num_training_step_calls_since_last_synch_worker_weights: 262
  num_weight_broadcasts: 27622
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 165.186
    learner_load_time_ms: 1.741
    learner_load_wait_time_ms: 1.517
iterations_since_restore: 105
node_ip: 127.0.0.1
num_agent_steps_sampled: 1401550
num_agent_steps_trained: 1385000
num_env_steps_sampled: 1401550
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.9968299938278
num_env_steps_trained: 1385000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.996795661631
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 45.01999999999999
  ram_util_percent: 73.42666666666668
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05838344901144743
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023166276717588228
  mean_inference_ms: 1.1207070512164017
  mean_raw_obs_processing_ms: 0.2561632043243091
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018743200039644855
    StateBufferConnector_ms: 0.0033037378153669725
    ViewRequirementAgentConnector_ms: 0.11297190954925818
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.779816513761467
  episode_reward_min: 3.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [8.0, 8.0, 9.0, 7.0, 4.0, 9.0, 6.0, 15.0, 10.0, 10.0, 13.0, 8.0,
      12.0, 8.0, 11.0, 6.0, 10.0, 9.0, 10.0, 7.0, 14.0, 8.0, 13.0, 9.0, 11.0, 10.0,
      7.0, 8.0, 7.0, 6.0, 9.0, 10.0, 5.0, 9.0, 9.0, 6.0, 9.0, 8.0, 7.0, 6.0, 7.0,
      10.0, 10.0, 15.0, 15.0, 9.0, 6.0, 8.0, 7.0, 9.0, 9.0, 6.0, 7.0, 10.0, 8.0, 12.0,
      10.0, 3.0, 4.0, 9.0, 10.0, 10.0, 9.0, 5.0, 12.0, 6.0, 4.0, 9.0, 5.0, 10.0, 7.0,
      10.0, 6.0, 7.0, 12.0, 7.0, 8.0, 6.0, 6.0, 10.0, 10.0, 8.0, 9.0, 10.0, 5.0, 6.0,
      9.0, 8.0, 14.0, 8.0, 8.0, 7.0, 11.0, 3.0, 11.0, 10.0, 12.0, 5.0, 8.0, 9.0, 11.0,
      12.0, 17.0, 5.0, 13.0, 13.0, 8.0, 10.0, 13.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05838344901144743
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023166276717588228
    mean_inference_ms: 1.1207070512164017
    mean_raw_obs_processing_ms: 0.2561632043243091
time_since_restore: 1063.49928855896
time_this_iter_s: 10.161756038665771
time_total_s: 1063.49928855896
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000895
timesteps_total: 1401550
training_iteration: 105
trial_id: default
train step: 106
agent_timesteps_total: 1415350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018471869352821992
  StateBufferConnector_ms: 0.00320149359301986
  ViewRequirementAgentConnector_ms: 0.11150146199163989
counters:
  num_agent_steps_sampled: 1415350
  num_agent_steps_trained: 1398500
  num_env_steps_sampled: 1415350
  num_env_steps_trained: 1398500
  num_samples_added_to_queue: 1415000
  num_training_step_calls_since_last_synch_worker_weights: 48
  num_weight_broadcasts: 27893
custom_metrics: {}
date: 2023-08-14_17-15-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.94392523364486
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 11058
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6944233775138855
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 41.67814254760742
        total_loss: 100.75414276123047
        var_gnorm: 64.21395874023438
        vf_explained_var: 0.8811351656913757
        vf_loss: 125.09622192382812
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2797.0
  learner_queue:
    size_count: 2803
    size_mean: 15.14
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5749285698088027
  num_agent_steps_sampled: 1415350
  num_agent_steps_trained: 1398500
  num_env_steps_sampled: 1415350
  num_env_steps_trained: 1398500
  num_samples_added_to_queue: 1415000
  num_training_step_calls_since_last_synch_worker_weights: 48
  num_weight_broadcasts: 27893
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 181.286
    learner_load_time_ms: 1.656
    learner_load_wait_time_ms: 1.506
iterations_since_restore: 106
node_ip: 127.0.0.1
num_agent_steps_sampled: 1415350
num_agent_steps_trained: 1398500
num_env_steps_sampled: 1415350
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9951634576553
num_env_steps_trained: 1398500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.99526859988
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.33571428571428
  ram_util_percent: 73.49285714285715
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0583470262805346
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023155613712928774
  mean_inference_ms: 1.12045440302359
  mean_raw_obs_processing_ms: 0.25607740197922396
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018471869352821992
    StateBufferConnector_ms: 0.00320149359301986
    ViewRequirementAgentConnector_ms: 0.11150146199163989
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.94392523364486
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 13.0, 10.0, 9.0, 6.0, 11.0, 8.0, 7.0, 11.0, 8.0, 15.0,
      5.0, 13.0, 7.0, 9.0, 4.0, 10.0, 13.0, 6.0, 10.0, 8.0, 9.0, 6.0, 13.0, 7.0, 5.0,
      6.0, 10.0, 14.0, 8.0, 12.0, 8.0, 13.0, 7.0, 14.0, 6.0, 9.0, 9.0, 5.0, 4.0, 6.0,
      12.0, 9.0, 11.0, 5.0, 10.0, 9.0, 8.0, 9.0, 13.0, 12.0, 9.0, 9.0, 3.0, 8.0, 5.0,
      8.0, 16.0, 8.0, 5.0, 9.0, 10.0, 9.0, 13.0, 13.0, 10.0, 10.0, 8.0, 8.0, 13.0,
      10.0, 17.0, 6.0, 10.0, 4.0, 8.0, 7.0, 11.0, 8.0, 5.0, 9.0, 11.0, 10.0, 9.0,
      10.0, 8.0, 8.0, 9.0, 7.0, 9.0, 8.0, 4.0, 9.0, 12.0, 8.0, 5.0, 4.0, 9.0, 8.0,
      10.0, 6.0, 11.0, 11.0, 12.0, 9.0, 9.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0583470262805346
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023155613712928774
    mean_inference_ms: 1.12045440302359
    mean_raw_obs_processing_ms: 0.25607740197922396
time_since_restore: 1073.661361694336
time_this_iter_s: 10.162073135375977
time_total_s: 1073.661361694336
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000905
timesteps_total: 1415350
training_iteration: 106
trial_id: default
train step: 107
agent_timesteps_total: 1429100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018702712014456776
  StateBufferConnector_ms: 0.003277029946585682
  ViewRequirementAgentConnector_ms: 0.11227955327969845
counters:
  num_agent_steps_sampled: 1429100
  num_agent_steps_trained: 1412500
  num_env_steps_sampled: 1429100
  num_env_steps_trained: 1412500
  num_samples_added_to_queue: 1429000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 28162
custom_metrics: {}
date: 2023-08-14_17-15-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.429906542056075
episode_reward_min: 4.0
episodes_this_iter: 107
episodes_total: 11165
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7012994885444641
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.234245538711548
        total_loss: 32.19248580932617
        var_gnorm: 64.24826049804688
        vf_explained_var: 0.9303913116455078
        vf_loss: 66.92947387695312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2825.0
  learner_queue:
    size_count: 2828
    size_mean: 15.3
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4317821063276353
  num_agent_steps_sampled: 1429100
  num_agent_steps_trained: 1412500
  num_env_steps_sampled: 1429100
  num_env_steps_trained: 1412500
  num_samples_added_to_queue: 1429000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 28162
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 277.285
    learner_load_time_ms: 1.658
    learner_load_wait_time_ms: 1.684
iterations_since_restore: 107
node_ip: 127.0.0.1
num_agent_steps_sampled: 1429100
num_agent_steps_trained: 1412500
num_env_steps_sampled: 1429100
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.919162973025
num_env_steps_trained: 1412500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9176932088983
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 45.121428571428574
  ram_util_percent: 73.5
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058365250212307526
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023140070716384926
  mean_inference_ms: 1.1201079328442773
  mean_raw_obs_processing_ms: 0.2560026545142874
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018702712014456776
    StateBufferConnector_ms: 0.003277029946585682
    ViewRequirementAgentConnector_ms: 0.11227955327969845
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.429906542056075
  episode_reward_min: 4.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 5.0, 10.0, 10.0, 11.0, 5.0, 9.0, 7.0, 10.0, 9.0, 7.0, 7.0,
      11.0, 14.0, 5.0, 12.0, 9.0, 12.0, 12.0, 5.0, 6.0, 4.0, 6.0, 5.0, 6.0, 8.0, 10.0,
      9.0, 7.0, 8.0, 7.0, 9.0, 8.0, 9.0, 7.0, 8.0, 9.0, 5.0, 9.0, 6.0, 9.0, 8.0, 6.0,
      7.0, 7.0, 6.0, 7.0, 10.0, 7.0, 8.0, 10.0, 9.0, 11.0, 12.0, 9.0, 9.0, 12.0, 11.0,
      12.0, 14.0, 6.0, 11.0, 8.0, 10.0, 8.0, 7.0, 7.0, 7.0, 7.0, 8.0, 7.0, 8.0, 8.0,
      9.0, 8.0, 10.0, 16.0, 10.0, 13.0, 13.0, 4.0, 6.0, 7.0, 13.0, 11.0, 11.0, 5.0,
      9.0, 10.0, 11.0, 9.0, 10.0, 6.0, 7.0, 7.0, 5.0, 5.0, 5.0, 8.0, 8.0, 11.0, 8.0,
      10.0, 10.0, 5.0, 5.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058365250212307526
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023140070716384926
    mean_inference_ms: 1.1201079328442773
    mean_raw_obs_processing_ms: 0.2560026545142874
time_since_restore: 1083.7480568885803
time_this_iter_s: 10.086695194244385
time_total_s: 1083.7480568885803
timers:
  sample_time_ms: 0.057
  synch_weights_time_ms: 0.239
  training_iteration_time_ms: 0.359
timestamp: 1692000915
timesteps_total: 1429100
training_iteration: 107
trial_id: default
train step: 108
agent_timesteps_total: 1442750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018482958828961407
  StateBufferConnector_ms: 0.003187965463708948
  ViewRequirementAgentConnector_ms: 0.11284263045699508
counters:
  num_agent_steps_sampled: 1442750
  num_agent_steps_trained: 1426000
  num_env_steps_sampled: 1442750
  num_env_steps_trained: 1426000
  num_samples_added_to_queue: 1442500
  num_training_step_calls_since_last_synch_worker_weights: 1163
  num_weight_broadcasts: 28433
custom_metrics: {}
date: 2023-08-14_17-15-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.148148148148149
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 11273
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7060990929603577
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -26.978317260742188
        total_loss: 47.61628723144531
        var_gnorm: 64.2752685546875
        vf_explained_var: 0.8540647029876709
        vf_loss: 156.2501983642578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2852.0
  learner_queue:
    size_count: 2857
    size_mean: 15.7
    size_quantiles: [12.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.8306623862918076
  num_agent_steps_sampled: 1442750
  num_agent_steps_trained: 1426000
  num_env_steps_sampled: 1442750
  num_env_steps_trained: 1426000
  num_samples_added_to_queue: 1442500
  num_training_step_calls_since_last_synch_worker_weights: 1163
  num_weight_broadcasts: 28433
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 213.139
    learner_load_time_ms: 1.657
    learner_load_wait_time_ms: 1.587
iterations_since_restore: 108
node_ip: 127.0.0.1
num_agent_steps_sampled: 1442750
num_agent_steps_trained: 1426000
num_env_steps_sampled: 1442750
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.9939793613867
num_env_steps_trained: 1426000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9940455222506
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.82000000000001
  ram_util_percent: 73.54
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05834472355933377
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0231292250015293
  mean_inference_ms: 1.1198822793851275
  mean_raw_obs_processing_ms: 0.25593222718962694
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018482958828961407
    StateBufferConnector_ms: 0.003187965463708948
    ViewRequirementAgentConnector_ms: 0.11284263045699508
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.148148148148149
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 10.0, 7.0, 9.0, 7.0, 8.0, 11.0, 9.0, 7.0, 9.0, 7.0, 8.0,
      10.0, 7.0, 11.0, 6.0, 6.0, 8.0, 6.0, 6.0, 8.0, 7.0, 10.0, 6.0, 10.0, 11.0, 10.0,
      8.0, 6.0, 7.0, 10.0, 8.0, 5.0, 5.0, 9.0, 12.0, 11.0, 14.0, 7.0, 8.0, 7.0, 7.0,
      7.0, 8.0, 9.0, 11.0, 10.0, 7.0, 8.0, 13.0, 7.0, 10.0, 8.0, 7.0, 8.0, 10.0, 6.0,
      8.0, 4.0, 9.0, 8.0, 5.0, 4.0, 10.0, 4.0, 5.0, 9.0, 8.0, 3.0, 4.0, 9.0, 12.0,
      11.0, 10.0, 9.0, 4.0, 9.0, 11.0, 10.0, 5.0, 9.0, 9.0, 6.0, 12.0, 9.0, 8.0, 8.0,
      12.0, 6.0, 6.0, 6.0, 10.0, 10.0, 6.0, 5.0, 8.0, 7.0, 7.0, 5.0, 9.0, 9.0, 10.0,
      9.0, 10.0, 8.0, 9.0, 11.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05834472355933377
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0231292250015293
    mean_inference_ms: 1.1198822793851275
    mean_raw_obs_processing_ms: 0.25593222718962694
time_since_restore: 1093.8713977336884
time_this_iter_s: 10.123340845108032
time_total_s: 1093.8713977336884
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1692000925
timesteps_total: 1442750
training_iteration: 108
trial_id: default
train step: 109
agent_timesteps_total: 1456550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018510503588982347
  StateBufferConnector_ms: 0.003189185880265146
  ViewRequirementAgentConnector_ms: 0.11183135914352704
counters:
  num_agent_steps_sampled: 1456550
  num_agent_steps_trained: 1440000
  num_env_steps_sampled: 1456550
  num_env_steps_trained: 1440000
  num_samples_added_to_queue: 1456500
  num_training_step_calls_since_last_synch_worker_weights: 1088
  num_weight_broadcasts: 28705
custom_metrics: {}
date: 2023-08-14_17-15-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.38679245283019
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 11379
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7142292857170105
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.478561401367188
        total_loss: 28.1516056060791
        var_gnorm: 64.3049087524414
        vf_explained_var: 0.9411474466323853
        vf_loss: 80.40262603759766
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2880.0
  learner_queue:
    size_count: 2884
    size_mean: 15.58
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9816312953446422
  num_agent_steps_sampled: 1456550
  num_agent_steps_trained: 1440000
  num_env_steps_sampled: 1456550
  num_env_steps_trained: 1440000
  num_samples_added_to_queue: 1456500
  num_training_step_calls_since_last_synch_worker_weights: 1088
  num_weight_broadcasts: 28705
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 231.433
    learner_load_time_ms: 1.656
    learner_load_wait_time_ms: 1.464
iterations_since_restore: 109
node_ip: 127.0.0.1
num_agent_steps_sampled: 1456550
num_agent_steps_trained: 1440000
num_env_steps_sampled: 1456550
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9984536188288
num_env_steps_trained: 1440000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9984312075073
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.35714285714285
  ram_util_percent: 73.42142857142858
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058334866189204304
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02311577654673739
  mean_inference_ms: 1.1195393431587441
  mean_raw_obs_processing_ms: 0.25585011851766554
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018510503588982347
    StateBufferConnector_ms: 0.003189185880265146
    ViewRequirementAgentConnector_ms: 0.11183135914352704
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.38679245283019
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 13.0, 10.0, 6.0, 7.0, 8.0, 7.0, 11.0, 5.0, 12.0, 7.0, 5.0,
      7.0, 9.0, 13.0, 9.0, 10.0, 3.0, 7.0, 7.0, 7.0, 5.0, 15.0, 6.0, 14.0, 5.0, 13.0,
      9.0, 12.0, 9.0, 9.0, 8.0, 11.0, 4.0, 11.0, 5.0, 7.0, 7.0, 8.0, 9.0, 9.0, 11.0,
      7.0, 8.0, 12.0, 4.0, 8.0, 12.0, 6.0, 10.0, 6.0, 6.0, 5.0, 13.0, 14.0, 8.0, 9.0,
      14.0, 8.0, 8.0, 6.0, 9.0, 11.0, 7.0, 3.0, 7.0, 5.0, 6.0, 8.0, 10.0, 5.0, 4.0,
      13.0, 14.0, 4.0, 12.0, 5.0, 11.0, 6.0, 4.0, 8.0, 9.0, 13.0, 7.0, 9.0, 10.0,
      7.0, 13.0, 5.0, 9.0, 7.0, 7.0, 5.0, 9.0, 9.0, 9.0, 11.0, 7.0, 8.0, 10.0, 9.0,
      9.0, 8.0, 9.0, 6.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058334866189204304
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02311577654673739
    mean_inference_ms: 1.1195393431587441
    mean_raw_obs_processing_ms: 0.25585011851766554
time_since_restore: 1103.9826936721802
time_this_iter_s: 10.111295938491821
time_total_s: 1103.9826936721802
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692000935
timesteps_total: 1456550
training_iteration: 109
trial_id: default
train step: 110
agent_timesteps_total: 1470350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01862049102783203
  StateBufferConnector_ms: 0.0031678764908402053
  ViewRequirementAgentConnector_ms: 0.11258522669474284
counters:
  num_agent_steps_sampled: 1470350
  num_agent_steps_trained: 1453500
  num_env_steps_sampled: 1470350
  num_env_steps_trained: 1453500
  num_samples_added_to_queue: 1470000
  num_training_step_calls_since_last_synch_worker_weights: 1269
  num_weight_broadcasts: 28978
custom_metrics: {}
date: 2023-08-14_17-15-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.527777777777778
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 11487
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7125553488731384
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -9.982882499694824
        total_loss: 40.044132232666016
        var_gnorm: 64.31122589111328
        vf_explained_var: 0.8085579872131348
        vf_loss: 107.1795883178711
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2907.0
  learner_queue:
    size_count: 2911
    size_mean: 15.68
    size_quantiles: [13.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.8109253973085317
  num_agent_steps_sampled: 1470350
  num_agent_steps_trained: 1453500
  num_env_steps_sampled: 1470350
  num_env_steps_trained: 1453500
  num_samples_added_to_queue: 1470000
  num_training_step_calls_since_last_synch_worker_weights: 1269
  num_weight_broadcasts: 28978
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 251.599
    learner_load_time_ms: 1.654
    learner_load_wait_time_ms: 1.564
iterations_since_restore: 110
node_ip: 127.0.0.1
num_agent_steps_sampled: 1470350
num_agent_steps_trained: 1453500
num_env_steps_sampled: 1470350
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9954266699717
num_env_steps_trained: 1453500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9955260901897
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 45.57142857142858
  ram_util_percent: 73.58571428571429
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05832633366351708
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02310265621004628
  mean_inference_ms: 1.1192118378715792
  mean_raw_obs_processing_ms: 0.25576707226590445
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01862049102783203
    StateBufferConnector_ms: 0.0031678764908402053
    ViewRequirementAgentConnector_ms: 0.11258522669474284
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.527777777777778
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 8.0, 11.0, 5.0, 5.0, 15.0, 6.0, 6.0, 5.0, 10.0, 5.0, 12.0,
      7.0, 5.0, 14.0, 5.0, 6.0, 8.0, 5.0, 8.0, 10.0, 11.0, 7.0, 10.0, 8.0, 7.0, 8.0,
      6.0, 8.0, 8.0, 7.0, 6.0, 7.0, 14.0, 4.0, 6.0, 8.0, 8.0, 3.0, 7.0, 11.0, 10.0,
      8.0, 7.0, 7.0, 6.0, 5.0, 4.0, 10.0, 7.0, 10.0, 6.0, 10.0, 5.0, 11.0, 11.0, 8.0,
      6.0, 9.0, 7.0, 5.0, 8.0, 3.0, 7.0, 8.0, 5.0, 9.0, 9.0, 6.0, 7.0, 9.0, 8.0, 8.0,
      6.0, 7.0, 11.0, 9.0, 8.0, 5.0, 7.0, 11.0, 7.0, 12.0, 6.0, 6.0, 7.0, 4.0, 5.0,
      9.0, 8.0, 7.0, 6.0, 4.0, 8.0, 11.0, 7.0, 7.0, 9.0, 8.0, 5.0, 6.0, 5.0, 7.0,
      9.0, 7.0, 4.0, 9.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05832633366351708
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02310265621004628
    mean_inference_ms: 1.1192118378715792
    mean_raw_obs_processing_ms: 0.25576707226590445
time_since_restore: 1114.0973947048187
time_this_iter_s: 10.11470103263855
time_total_s: 1114.0973947048187
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1692000945
timesteps_total: 1470350
training_iteration: 110
trial_id: default
train step: 111
agent_timesteps_total: 1484250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018257227810946377
  StateBufferConnector_ms: 0.0031800703568892045
  ViewRequirementAgentConnector_ms: 0.11041489514437589
counters:
  num_agent_steps_sampled: 1484250
  num_agent_steps_trained: 1467500
  num_env_steps_sampled: 1484250
  num_env_steps_trained: 1467500
  num_samples_added_to_queue: 1484000
  num_training_step_calls_since_last_synch_worker_weights: 907
  num_weight_broadcasts: 29252
custom_metrics: {}
date: 2023-08-14_17-15-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.972727272727273
episode_reward_min: 0.0
episodes_this_iter: 110
episodes_total: 11597
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6968704462051392
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 20.25185775756836
        total_loss: 61.12586212158203
        var_gnorm: 64.29742431640625
        vf_explained_var: 0.898674726486206
        vf_loss: 88.71672058105469
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2935.0
  learner_queue:
    size_count: 2940
    size_mean: 15.56
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0423051376636308
  num_agent_steps_sampled: 1484250
  num_agent_steps_trained: 1467500
  num_env_steps_sampled: 1484250
  num_env_steps_trained: 1467500
  num_samples_added_to_queue: 1484000
  num_training_step_calls_since_last_synch_worker_weights: 907
  num_weight_broadcasts: 29252
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 207.078
    learner_load_time_ms: 1.405
    learner_load_wait_time_ms: 1.555
iterations_since_restore: 111
node_ip: 127.0.0.1
num_agent_steps_sampled: 1484250
num_agent_steps_trained: 1467500
num_env_steps_sampled: 1484250
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9991714959315
num_env_steps_trained: 1467500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9991655354704
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.533333333333324
  ram_util_percent: 73.53333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058314038790882955
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023085436415072467
  mean_inference_ms: 1.1188032512731358
  mean_raw_obs_processing_ms: 0.25567165576590223
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018257227810946377
    StateBufferConnector_ms: 0.0031800703568892045
    ViewRequirementAgentConnector_ms: 0.11041489514437589
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.972727272727273
  episode_reward_min: 0.0
  episodes_this_iter: 110
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128]
    episode_reward: [4.0, 6.0, 10.0, 10.0, 1.0, 4.0, 6.0, 6.0, 5.0, 10.0, 9.0, 8.0,
      9.0, 6.0, 6.0, 4.0, 10.0, 9.0, 4.0, 7.0, 1.0, 6.0, 1.0, 1.0, 7.0, 4.0, 4.0,
      5.0, 2.0, 8.0, 2.0, 3.0, 1.0, 4.0, 3.0, 7.0, 2.0, 4.0, 0.0, 2.0, 8.0, 2.0, 2.0,
      6.0, 5.0, 4.0, 0.0, 1.0, 5.0, 0.0, 6.0, 3.0, 7.0, 3.0, 6.0, 6.0, 9.0, 7.0, 9.0,
      6.0, 6.0, 4.0, 5.0, 7.0, 8.0, 6.0, 10.0, 6.0, 3.0, 7.0, 6.0, 4.0, 8.0, 3.0,
      1.0, 6.0, 6.0, 3.0, 3.0, 2.0, 6.0, 3.0, 7.0, 8.0, 6.0, 7.0, 6.0, 5.0, 4.0, 4.0,
      4.0, 5.0, 3.0, 2.0, 3.0, 0.0, 5.0, 4.0, 6.0, 1.0, 6.0, 5.0, 7.0, 7.0, 4.0, 5.0,
      3.0, 5.0, 7.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058314038790882955
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023085436415072467
    mean_inference_ms: 1.1188032512731358
    mean_raw_obs_processing_ms: 0.25567165576590223
time_since_restore: 1124.2202787399292
time_this_iter_s: 10.122884035110474
time_total_s: 1124.2202787399292
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1692000955
timesteps_total: 1484250
training_iteration: 111
trial_id: default
train step: 112
agent_timesteps_total: 1497950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018928635795161408
  StateBufferConnector_ms: 0.0033682247377791494
  ViewRequirementAgentConnector_ms: 0.11431001267343197
counters:
  num_agent_steps_sampled: 1497950
  num_agent_steps_trained: 1481000
  num_env_steps_sampled: 1497950
  num_env_steps_trained: 1481000
  num_samples_added_to_queue: 1497500
  num_training_step_calls_since_last_synch_worker_weights: 476
  num_weight_broadcasts: 29522
custom_metrics: {}
date: 2023-08-14_17-16-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 6.745283018867925
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 11703
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.839542806148529
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -16.36098861694336
        total_loss: -10.088525772094727
        var_gnorm: 64.31590270996094
        vf_explained_var: 0.9788700938224792
        vf_loss: 20.940353393554688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2962.0
  learner_queue:
    size_count: 2968
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2649110640673518
  num_agent_steps_sampled: 1497950
  num_agent_steps_trained: 1481000
  num_env_steps_sampled: 1497950
  num_env_steps_trained: 1481000
  num_samples_added_to_queue: 1497500
  num_training_step_calls_since_last_synch_worker_weights: 476
  num_weight_broadcasts: 29522
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 190.233
    learner_load_time_ms: 1.43
    learner_load_wait_time_ms: 1.661
iterations_since_restore: 112
node_ip: 127.0.0.1
num_agent_steps_sampled: 1497950
num_agent_steps_trained: 1481000
num_env_steps_sampled: 1497950
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9978115593583
num_env_steps_trained: 1481000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9978435073967
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 55.11428571428571
  ram_util_percent: 73.78571428571429
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058313853180616874
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023075641756137556
  mean_inference_ms: 1.1186079066142909
  mean_raw_obs_processing_ms: 0.25562347943938885
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018928635795161408
    StateBufferConnector_ms: 0.0033682247377791494
    ViewRequirementAgentConnector_ms: 0.11431001267343197
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 6.745283018867925
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 6.0, 8.0, 4.0, 6.0, 4.0, 7.0, 9.0, 2.0, 4.0, 7.0, 7.0,
      8.0, 6.0, 3.0, 9.0, 9.0, 5.0, 3.0, 3.0, 3.0, 6.0, 4.0, 10.0, 1.0, 8.0, 9.0,
      6.0, 6.0, 10.0, 7.0, 4.0, 10.0, 9.0, 8.0, 10.0, 8.0, 8.0, 7.0, 6.0, 6.0, 10.0,
      5.0, 11.0, 4.0, 13.0, 6.0, 8.0, 6.0, 7.0, 6.0, 8.0, 7.0, 8.0, 5.0, 11.0, 4.0,
      4.0, 4.0, 3.0, 4.0, 6.0, 10.0, 6.0, 5.0, 6.0, 0.0, 8.0, 7.0, 8.0, 4.0, 6.0,
      5.0, 5.0, 6.0, 7.0, 5.0, 5.0, 7.0, 6.0, 8.0, 9.0, 5.0, 10.0, 9.0, 7.0, 9.0,
      7.0, 6.0, 7.0, 5.0, 5.0, 3.0, 7.0, 5.0, 6.0, 6.0, 13.0, 17.0, 5.0, 9.0, 7.0,
      9.0, 10.0, 10.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058313853180616874
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023075641756137556
    mean_inference_ms: 1.1186079066142909
    mean_raw_obs_processing_ms: 0.25562347943938885
time_since_restore: 1134.3936207294464
time_this_iter_s: 10.173341989517212
time_total_s: 1134.3936207294464
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000966
timesteps_total: 1497950
training_iteration: 112
trial_id: default
train step: 113
agent_timesteps_total: 1510850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02042849858601888
  StateBufferConnector_ms: 0.003534672307033165
  ViewRequirementAgentConnector_ms: 0.12114982978970397
counters:
  num_agent_steps_sampled: 1510850
  num_agent_steps_trained: 1494000
  num_env_steps_sampled: 1510850
  num_env_steps_trained: 1494000
  num_samples_added_to_queue: 1510500
  num_training_step_calls_since_last_synch_worker_weights: 38
  num_weight_broadcasts: 29775
custom_metrics: {}
date: 2023-08-14_17-16-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.882352941176471
episode_reward_min: 2.0
episodes_this_iter: 102
episodes_total: 11805
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7111548185348511
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.77377700805664
        total_loss: 80.34709167480469
        var_gnorm: 64.33251190185547
        vf_explained_var: 0.8898669481277466
        vf_loss: 130.25816345214844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2988.0
  learner_queue:
    size_count: 2995
    size_mean: 15.06
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.666253282067285
  num_agent_steps_sampled: 1510850
  num_agent_steps_trained: 1494000
  num_env_steps_sampled: 1510850
  num_env_steps_trained: 1494000
  num_samples_added_to_queue: 1510500
  num_training_step_calls_since_last_synch_worker_weights: 38
  num_weight_broadcasts: 29775
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 151.05
    learner_load_time_ms: 1.438
    learner_load_wait_time_ms: 1.546
iterations_since_restore: 113
node_ip: 127.0.0.1
num_agent_steps_sampled: 1510850
num_agent_steps_trained: 1494000
num_env_steps_sampled: 1510850
num_env_steps_sampled_this_iter: 12900
num_env_steps_sampled_throughput_per_sec: 1289.9925263361001
num_env_steps_trained: 1494000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.992468400721
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 90.32857142857142
  ram_util_percent: 75.96428571428571
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058344893415829574
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023084414583101318
  mean_inference_ms: 1.119014896760971
  mean_raw_obs_processing_ms: 0.25570764779051025
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02042849858601888
    StateBufferConnector_ms: 0.003534672307033165
    ViewRequirementAgentConnector_ms: 0.12114982978970397
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.882352941176471
  episode_reward_min: 2.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 5.0, 8.0, 12.0, 11.0, 9.0, 6.0, 6.0, 9.0, 7.0, 11.0, 6.0,
      3.0, 11.0, 5.0, 13.0, 9.0, 6.0, 11.0, 11.0, 11.0, 9.0, 8.0, 10.0, 6.0, 9.0,
      12.0, 11.0, 5.0, 13.0, 6.0, 6.0, 10.0, 6.0, 5.0, 5.0, 5.0, 12.0, 9.0, 9.0, 14.0,
      10.0, 8.0, 10.0, 13.0, 9.0, 10.0, 8.0, 9.0, 9.0, 12.0, 11.0, 11.0, 6.0, 4.0,
      8.0, 12.0, 7.0, 8.0, 7.0, 9.0, 8.0, 8.0, 8.0, 14.0, 12.0, 7.0, 7.0, 3.0, 6.0,
      7.0, 13.0, 17.0, 6.0, 13.0, 14.0, 6.0, 8.0, 10.0, 14.0, 11.0, 11.0, 2.0, 3.0,
      12.0, 9.0, 9.0, 8.0, 9.0, 4.0, 12.0, 11.0, 10.0, 6.0, 7.0, 11.0, 10.0, 16.0,
      9.0, 7.0, 13.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058344893415829574
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023084414583101318
    mean_inference_ms: 1.119014896760971
    mean_raw_obs_processing_ms: 0.25570764779051025
time_since_restore: 1144.574550628662
time_this_iter_s: 10.180929899215698
time_total_s: 1144.574550628662
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692000976
timesteps_total: 1510850
training_iteration: 113
trial_id: default
train step: 114
agent_timesteps_total: 1522550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022587299346923828
  StateBufferConnector_ms: 0.00406193733215332
  ViewRequirementAgentConnector_ms: 0.13031268119812012
counters:
  num_agent_steps_sampled: 1522550
  num_agent_steps_trained: 1506000
  num_env_steps_sampled: 1522550
  num_env_steps_trained: 1506000
  num_samples_added_to_queue: 1522500
  num_training_step_calls_since_last_synch_worker_weights: 224
  num_weight_broadcasts: 30006
custom_metrics: {}
date: 2023-08-14_17-16-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.86
episode_reward_min: 1.0
episodes_this_iter: 90
episodes_total: 11895
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7379843592643738
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -20.495716094970703
        total_loss: 11.715885162353516
        var_gnorm: 64.33940887451172
        vf_explained_var: 0.947142481803894
        vf_loss: 71.80304718017578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3012.0
  learner_queue:
    size_count: 3019
    size_mean: 14.8
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8439088914585773
  num_agent_steps_sampled: 1522550
  num_agent_steps_trained: 1506000
  num_env_steps_sampled: 1522550
  num_env_steps_trained: 1506000
  num_samples_added_to_queue: 1522500
  num_training_step_calls_since_last_synch_worker_weights: 224
  num_weight_broadcasts: 30006
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 146.371
    learner_load_time_ms: 1.463
    learner_load_wait_time_ms: 1.684
iterations_since_restore: 114
node_ip: 127.0.0.1
num_agent_steps_sampled: 1522550
num_agent_steps_trained: 1506000
num_env_steps_sampled: 1522550
num_env_steps_sampled_this_iter: 11700
num_env_steps_sampled_throughput_per_sec: 1169.9975452474598
num_env_steps_trained: 1506000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.997482305087
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 91.65
  ram_util_percent: 77.57142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058556995826519964
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02310004074718326
  mean_inference_ms: 1.1198389993182598
  mean_raw_obs_processing_ms: 0.256024056871582
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022587299346923828
    StateBufferConnector_ms: 0.00406193733215332
    ViewRequirementAgentConnector_ms: 0.13031268119812012
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.86
  episode_reward_min: 1.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 6.0, 7.0, 11.0, 10.0, 16.0, 9.0, 7.0, 13.0, 6.0, 8.0, 12.0,
      8.0, 9.0, 8.0, 6.0, 15.0, 7.0, 10.0, 8.0, 9.0, 7.0, 1.0, 11.0, 7.0, 7.0, 6.0,
      10.0, 7.0, 10.0, 5.0, 16.0, 10.0, 9.0, 9.0, 8.0, 11.0, 8.0, 4.0, 7.0, 10.0,
      6.0, 8.0, 5.0, 9.0, 8.0, 9.0, 7.0, 9.0, 7.0, 6.0, 10.0, 10.0, 5.0, 8.0, 10.0,
      11.0, 8.0, 8.0, 8.0, 11.0, 3.0, 5.0, 7.0, 8.0, 9.0, 7.0, 7.0, 9.0, 9.0, 7.0,
      8.0, 14.0, 12.0, 10.0, 8.0, 6.0, 9.0, 11.0, 11.0, 14.0, 14.0, 13.0, 12.0, 13.0,
      13.0, 7.0, 13.0, 5.0, 9.0, 6.0, 9.0, 6.0, 9.0, 10.0, 11.0, 14.0, 12.0, 12.0,
      3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058556995826519964
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02310004074718326
    mean_inference_ms: 1.1198389993182598
    mean_raw_obs_processing_ms: 0.256024056871582
time_since_restore: 1154.7443554401398
time_this_iter_s: 10.169804811477661
time_total_s: 1154.7443554401398
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692000986
timesteps_total: 1522550
training_iteration: 114
trial_id: default
train step: 115
agent_timesteps_total: 1534550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023018360137939453
  StateBufferConnector_ms: 0.003973245620727539
  ViewRequirementAgentConnector_ms: 0.1349318027496338
counters:
  num_agent_steps_sampled: 1534550
  num_agent_steps_trained: 1518000
  num_env_steps_sampled: 1534550
  num_env_steps_trained: 1518000
  num_samples_added_to_queue: 1534500
  num_training_step_calls_since_last_synch_worker_weights: 633
  num_weight_broadcasts: 30243
custom_metrics: {}
date: 2023-08-14_17-16-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.05
episode_reward_min: 1.0
episodes_this_iter: 94
episodes_total: 11989
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5682339668273926
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 25.511577606201172
        total_loss: 42.97676086425781
        var_gnorm: 64.34403228759766
        vf_explained_var: 0.966877818107605
        vf_loss: 40.61271286010742
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3036.0
  learner_queue:
    size_count: 3041
    size_mean: 14.6
    size_quantiles: [10.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 1.9287301521985911
  num_agent_steps_sampled: 1534550
  num_agent_steps_trained: 1518000
  num_env_steps_sampled: 1534550
  num_env_steps_trained: 1518000
  num_samples_added_to_queue: 1534500
  num_training_step_calls_since_last_synch_worker_weights: 633
  num_weight_broadcasts: 30243
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 203.059
    learner_load_time_ms: 1.481
    learner_load_wait_time_ms: 1.515
iterations_since_restore: 115
node_ip: 127.0.0.1
num_agent_steps_sampled: 1534550
num_agent_steps_trained: 1518000
num_env_steps_sampled: 1534550
num_env_steps_sampled_this_iter: 12000
num_env_steps_sampled_throughput_per_sec: 1199.9973678646602
num_env_steps_trained: 1518000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9973678646602
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 78.24666666666667
  ram_util_percent: 79.08666666666666
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058568243818277715
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023134444704073873
  mean_inference_ms: 1.1209689808262098
  mean_raw_obs_processing_ms: 0.2562588507196136
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023018360137939453
    StateBufferConnector_ms: 0.003973245620727539
    ViewRequirementAgentConnector_ms: 0.1349318027496338
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.05
  episode_reward_min: 1.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 11.0, 14.0, 12.0, 12.0, 3.0, 12.0, 2.0, 7.0, 5.0, 12.0,
      4.0, 7.0, 10.0, 11.0, 4.0, 13.0, 8.0, 8.0, 5.0, 10.0, 7.0, 9.0, 5.0, 10.0, 12.0,
      8.0, 4.0, 5.0, 6.0, 5.0, 6.0, 7.0, 4.0, 6.0, 5.0, 5.0, 8.0, 7.0, 3.0, 5.0, 5.0,
      6.0, 5.0, 7.0, 10.0, 8.0, 1.0, 6.0, 4.0, 6.0, 5.0, 6.0, 7.0, 9.0, 7.0, 2.0,
      8.0, 8.0, 8.0, 9.0, 7.0, 3.0, 5.0, 8.0, 10.0, 7.0, 12.0, 6.0, 11.0, 6.0, 10.0,
      9.0, 7.0, 11.0, 8.0, 4.0, 7.0, 6.0, 8.0, 4.0, 9.0, 5.0, 7.0, 6.0, 9.0, 7.0,
      6.0, 10.0, 12.0, 3.0, 6.0, 5.0, 8.0, 8.0, 3.0, 3.0, 3.0, 7.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058568243818277715
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023134444704073873
    mean_inference_ms: 1.1209689808262098
    mean_raw_obs_processing_ms: 0.2562588507196136
time_since_restore: 1164.8656034469604
time_this_iter_s: 10.121248006820679
time_total_s: 1164.8656034469604
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1692000996
timesteps_total: 1534550
training_iteration: 115
trial_id: default
train step: 116
agent_timesteps_total: 1548150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019239029794369103
  StateBufferConnector_ms: 0.003363051504459021
  ViewRequirementAgentConnector_ms: 0.1151051161424169
counters:
  num_agent_steps_sampled: 1548150
  num_agent_steps_trained: 1531500
  num_env_steps_sampled: 1548150
  num_env_steps_trained: 1531500
  num_samples_added_to_queue: 1548000
  num_training_step_calls_since_last_synch_worker_weights: 282
  num_weight_broadcasts: 30512
custom_metrics: {}
date: 2023-08-14_17-16-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 1.2924528301886793
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 12095
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.018661819398403168
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.115311861038208
        total_loss: 35.774871826171875
        var_gnorm: 64.35552215576172
        vf_explained_var: 0.9205936789512634
        vf_loss: 73.96697998046875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3063.0
  learner_queue:
    size_count: 3069
    size_mean: 15.2
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4422205101855958
  num_agent_steps_sampled: 1548150
  num_agent_steps_trained: 1531500
  num_env_steps_sampled: 1548150
  num_env_steps_trained: 1531500
  num_samples_added_to_queue: 1548000
  num_training_step_calls_since_last_synch_worker_weights: 282
  num_weight_broadcasts: 30512
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 168.259
    learner_load_time_ms: 1.492
    learner_load_wait_time_ms: 1.452
iterations_since_restore: 116
node_ip: 127.0.0.1
num_agent_steps_sampled: 1548150
num_agent_steps_trained: 1531500
num_env_steps_sampled: 1548150
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9967250902835
num_env_steps_trained: 1531500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.996749170502
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 58.48571428571429
  ram_util_percent: 78.95
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058490024535656986
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0231280881389558
  mean_inference_ms: 1.1209952469883693
  mean_raw_obs_processing_ms: 0.2562234693247638
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019239029794369103
    StateBufferConnector_ms: 0.003363051504459021
    ViewRequirementAgentConnector_ms: 0.1151051161424169
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 1.2924528301886793
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 1.0, 0.0, 3.0, 0.0, 3.0, 4.0, 2.0, 0.0, 0.0, 3.0, 1.0, 4.0,
      3.0, 3.0, 0.0, 1.0, 2.0, 1.0, 3.0, 4.0, 4.0, 1.0, 2.0, 2.0, 0.0, 0.0, 2.0, 1.0,
      1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 5.0, 5.0, 2.0, 2.0, 6.0, 4.0, 3.0,
      5.0, 2.0, 4.0, 3.0, 4.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 3.0, 2.0, 2.0, 0.0, 2.0,
      2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058490024535656986
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0231280881389558
    mean_inference_ms: 1.1209952469883693
    mean_raw_obs_processing_ms: 0.2562234693247638
time_since_restore: 1175.0051052570343
time_this_iter_s: 10.139501810073853
time_total_s: 1175.0051052570343
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1692001006
timesteps_total: 1548150
training_iteration: 116
trial_id: default
train step: 117
agent_timesteps_total: 1561850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018562111899117443
  StateBufferConnector_ms: 0.0032166454279534172
  ViewRequirementAgentConnector_ms: 0.11341148447767596
counters:
  num_agent_steps_sampled: 1561850
  num_agent_steps_trained: 1545000
  num_env_steps_sampled: 1561850
  num_env_steps_trained: 1545000
  num_samples_added_to_queue: 1561500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 30783
custom_metrics: {}
date: 2023-08-14_17-16-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.04672897196261682
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 12202
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.005814866162836552
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -1.3170539140701294
        total_loss: 812.5122680664062
        var_gnorm: 64.37040710449219
        vf_explained_var: 0.3573794960975647
        vf_loss: 1627.716796875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3090.0
  learner_queue:
    size_count: 3094
    size_mean: 15.42
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.250439922587247
  num_agent_steps_sampled: 1561850
  num_agent_steps_trained: 1545000
  num_env_steps_sampled: 1561850
  num_env_steps_trained: 1545000
  num_samples_added_to_queue: 1561500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 30783
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 254.406
    learner_load_time_ms: 1.63
    learner_load_wait_time_ms: 1.597
iterations_since_restore: 117
node_ip: 127.0.0.1
num_agent_steps_sampled: 1561850
num_agent_steps_trained: 1545000
num_env_steps_sampled: 1561850
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9854649655363
num_env_steps_trained: 1545000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9856771558204
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 53.664285714285704
  ram_util_percent: 78.50714285714287
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0584995716143843
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02310934137380052
  mean_inference_ms: 1.1207218160852057
  mean_raw_obs_processing_ms: 0.25617480001559767
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018562111899117443
    StateBufferConnector_ms: 0.0032166454279534172
    ViewRequirementAgentConnector_ms: 0.11341148447767596
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.04672897196261682
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0584995716143843
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02310934137380052
    mean_inference_ms: 1.1207218160852057
    mean_raw_obs_processing_ms: 0.25617480001559767
time_since_restore: 1185.0951244831085
time_this_iter_s: 10.090019226074219
time_total_s: 1185.0951244831085
timers:
  sample_time_ms: 0.043
  synch_weights_time_ms: 0.3
  training_iteration_time_ms: 0.407
timestamp: 1692001016
timesteps_total: 1561850
training_iteration: 117
trial_id: default
train step: 118
agent_timesteps_total: 1575350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018905468706814747
  StateBufferConnector_ms: 0.003273307152514188
  ViewRequirementAgentConnector_ms: 0.1133156272600282
counters:
  num_agent_steps_sampled: 1575350
  num_agent_steps_trained: 1558500
  num_env_steps_sampled: 1575350
  num_env_steps_trained: 1558500
  num_samples_added_to_queue: 1575000
  num_training_step_calls_since_last_synch_worker_weights: 345
  num_weight_broadcasts: 31051
custom_metrics: {}
date: 2023-08-14_17-17-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.03773584905660377
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 12308
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0338108204305172
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 7.501192569732666
        total_loss: 184.24720764160156
        var_gnorm: 64.37128448486328
        vf_explained_var: 0.46879345178604126
        vf_loss: 353.83013916015625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3117.0
  learner_queue:
    size_count: 3123
    size_mean: 15.54
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1173182178770737
  num_agent_steps_sampled: 1575350
  num_agent_steps_trained: 1558500
  num_env_steps_sampled: 1575350
  num_env_steps_trained: 1558500
  num_samples_added_to_queue: 1575000
  num_training_step_calls_since_last_synch_worker_weights: 345
  num_weight_broadcasts: 31051
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 201.161
    learner_load_time_ms: 1.601
    learner_load_wait_time_ms: 1.481
iterations_since_restore: 118
node_ip: 127.0.0.1
num_agent_steps_sampled: 1575350
num_agent_steps_trained: 1558500
num_env_steps_sampled: 1575350
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9959445121524
num_env_steps_trained: 1558500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9959445121524
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 45.02
  ram_util_percent: 78.23333333333333
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0584791403334429
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023092277796261
  mean_inference_ms: 1.1205686527904324
  mean_raw_obs_processing_ms: 0.2562090725509698
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018905468706814747
    StateBufferConnector_ms: 0.003273307152514188
    ViewRequirementAgentConnector_ms: 0.1133156272600282
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.03773584905660377
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,
      0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0584791403334429
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023092277796261
    mean_inference_ms: 1.1205686527904324
    mean_raw_obs_processing_ms: 0.2562090725509698
time_since_restore: 1195.231681585312
time_this_iter_s: 10.13655710220337
time_total_s: 1195.231681585312
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001026
timesteps_total: 1575350
training_iteration: 118
trial_id: default
train step: 119
agent_timesteps_total: 1589150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018703054498743127
  StateBufferConnector_ms: 0.00321401490105523
  ViewRequirementAgentConnector_ms: 0.11325875918070476
counters:
  num_agent_steps_sampled: 1589150
  num_agent_steps_trained: 1572500
  num_env_steps_sampled: 1589150
  num_env_steps_trained: 1572500
  num_samples_added_to_queue: 1589000
  num_training_step_calls_since_last_synch_worker_weights: 726
  num_weight_broadcasts: 31324
custom_metrics: {}
date: 2023-08-14_17-17-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 3.0
episode_reward_mean: 0.1574074074074074
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 12416
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7378237247467041
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 5.749054431915283
        total_loss: 13.463868141174316
        var_gnorm: 64.37396240234375
        vf_explained_var: 0.8843342065811157
        vf_loss: 22.807865142822266
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3145.0
  learner_queue:
    size_count: 3150
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.40356688476182
  num_agent_steps_sampled: 1589150
  num_agent_steps_trained: 1572500
  num_env_steps_sampled: 1589150
  num_env_steps_trained: 1572500
  num_samples_added_to_queue: 1589000
  num_training_step_calls_since_last_synch_worker_weights: 726
  num_weight_broadcasts: 31324
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 204.894
    learner_load_time_ms: 1.593
    learner_load_wait_time_ms: 1.591
iterations_since_restore: 119
node_ip: 127.0.0.1
num_agent_steps_sampled: 1589150
num_agent_steps_trained: 1572500
num_env_steps_sampled: 1589150
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9934854814976
num_env_steps_trained: 1572500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.993391068186
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 45.85714285714287
  ram_util_percent: 77.0
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058472920820587505
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023073796339374324
  mean_inference_ms: 1.120253545325214
  mean_raw_obs_processing_ms: 0.25613578971822126
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018703054498743127
    StateBufferConnector_ms: 0.00321401490105523
    ViewRequirementAgentConnector_ms: 0.11325875918070476
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 3.0
  episode_reward_mean: 0.1574074074074074
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058472920820587505
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023073796339374324
    mean_inference_ms: 1.120253545325214
    mean_raw_obs_processing_ms: 0.25613578971822126
time_since_restore: 1205.349568605423
time_this_iter_s: 10.117887020111084
time_total_s: 1205.349568605423
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001037
timesteps_total: 1589150
training_iteration: 119
trial_id: default
train step: 120
agent_timesteps_total: 1602850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018929321075154243
  StateBufferConnector_ms: 0.003199265382000219
  ViewRequirementAgentConnector_ms: 0.11306878562285522
counters:
  num_agent_steps_sampled: 1602850
  num_agent_steps_trained: 1586000
  num_env_steps_sampled: 1602850
  num_env_steps_trained: 1586000
  num_samples_added_to_queue: 1602500
  num_training_step_calls_since_last_synch_worker_weights: 1146
  num_weight_broadcasts: 31595
custom_metrics: {}
date: 2023-08-14_17-17-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 2.0
episode_reward_mean: 0.11214953271028037
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 12523
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.014764911495149136
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.8196346759796143
        total_loss: 40.246952056884766
        var_gnorm: 64.37446594238281
        vf_explained_var: 0.5002661943435669
        vf_loss: 82.28082275390625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3172.0
  learner_queue:
    size_count: 3176
    size_mean: 15.58
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9816312953446421
  num_agent_steps_sampled: 1602850
  num_agent_steps_trained: 1586000
  num_env_steps_sampled: 1602850
  num_env_steps_trained: 1586000
  num_samples_added_to_queue: 1602500
  num_training_step_calls_since_last_synch_worker_weights: 1146
  num_weight_broadcasts: 31595
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 257.379
    learner_load_time_ms: 2.233
    learner_load_wait_time_ms: 1.57
iterations_since_restore: 120
node_ip: 127.0.0.1
num_agent_steps_sampled: 1602850
num_agent_steps_trained: 1586000
num_env_steps_sampled: 1602850
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9952311681807
num_env_steps_trained: 1586000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9953007861634
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 41.49285714285714
  ram_util_percent: 76.89999999999999
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0584557927032106
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023057060278810177
  mean_inference_ms: 1.120012524562093
  mean_raw_obs_processing_ms: 0.2560791708025053
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018929321075154243
    StateBufferConnector_ms: 0.003199265382000219
    ViewRequirementAgentConnector_ms: 0.11306878562285522
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 2.0
  episode_reward_mean: 0.11214953271028037
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 2.0, 1.0, 0.0, 0.0,
      0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,
      0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0584557927032106
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023057060278810177
    mean_inference_ms: 1.120012524562093
    mean_raw_obs_processing_ms: 0.2560791708025053
time_since_restore: 1215.4409205913544
time_this_iter_s: 10.091351985931396
time_total_s: 1215.4409205913544
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001047
timesteps_total: 1602850
training_iteration: 120
trial_id: default
train step: 121
agent_timesteps_total: 1616650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018659484720675745
  StateBufferConnector_ms: 0.003226003914235908
  ViewRequirementAgentConnector_ms: 0.11293308757175909
counters:
  num_agent_steps_sampled: 1616650
  num_agent_steps_trained: 1600000
  num_env_steps_sampled: 1616650
  num_env_steps_trained: 1600000
  num_samples_added_to_queue: 1616500
  num_training_step_calls_since_last_synch_worker_weights: 784
  num_weight_broadcasts: 31865
custom_metrics: {}
date: 2023-08-14_17-17-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.07476635514018691
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 12630
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.0888315737247467
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -6.632509231567383
        total_loss: 107.6325454711914
        var_gnorm: 64.37495422363281
        vf_explained_var: 0.1656917929649353
        vf_loss: 229.41842651367188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3200.0
  learner_queue:
    size_count: 3205
    size_mean: 15.58
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9816312953446421
  num_agent_steps_sampled: 1616650
  num_agent_steps_trained: 1600000
  num_env_steps_sampled: 1616650
  num_env_steps_trained: 1600000
  num_samples_added_to_queue: 1616500
  num_training_step_calls_since_last_synch_worker_weights: 784
  num_weight_broadcasts: 31865
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 206.772
    learner_load_time_ms: 2.216
    learner_load_wait_time_ms: 1.616
iterations_since_restore: 121
node_ip: 127.0.0.1
num_agent_steps_sampled: 1616650
num_agent_steps_trained: 1600000
num_env_steps_sampled: 1616650
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.997762683681
num_env_steps_trained: 1600000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9977302588068
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.621428571428574
  ram_util_percent: 76.85
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058472370077059334
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02303717264610741
  mean_inference_ms: 1.119655319224307
  mean_raw_obs_processing_ms: 0.25600136583843724
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018659484720675745
    StateBufferConnector_ms: 0.003226003914235908
    ViewRequirementAgentConnector_ms: 0.11293308757175909
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.07476635514018691
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0,
      1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058472370077059334
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02303717264610741
    mean_inference_ms: 1.119655319224307
    mean_raw_obs_processing_ms: 0.25600136583843724
time_since_restore: 1225.5520734786987
time_this_iter_s: 10.11115288734436
time_total_s: 1225.5520734786987
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001057
timesteps_total: 1616650
training_iteration: 121
trial_id: default
train step: 122
agent_timesteps_total: 1630400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01877833295751501
  StateBufferConnector_ms: 0.0032173262702094186
  ViewRequirementAgentConnector_ms: 0.11290378040737575
counters:
  num_agent_steps_sampled: 1630400
  num_agent_steps_trained: 1613500
  num_env_steps_sampled: 1630400
  num_env_steps_trained: 1613500
  num_samples_added_to_queue: 1630000
  num_training_step_calls_since_last_synch_worker_weights: 77
  num_weight_broadcasts: 32137
custom_metrics: {}
date: 2023-08-14_17-17-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 2.0
episode_reward_mean: 0.1574074074074074
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 12738
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.3814314007759094
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.23981571197509766
        total_loss: 56.21040344238281
        var_gnorm: 64.37447357177734
        vf_explained_var: 0.7046945691108704
        vf_loss: 115.7554931640625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3227.0
  learner_queue:
    size_count: 3233
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2631706139710503
  num_agent_steps_sampled: 1630400
  num_agent_steps_trained: 1613500
  num_env_steps_sampled: 1630400
  num_env_steps_trained: 1613500
  num_samples_added_to_queue: 1630000
  num_training_step_calls_since_last_synch_worker_weights: 77
  num_weight_broadcasts: 32137
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 190.159
    learner_load_time_ms: 1.994
    learner_load_wait_time_ms: 1.492
iterations_since_restore: 122
node_ip: 127.0.0.1
num_agent_steps_sampled: 1630400
num_agent_steps_trained: 1613500
num_env_steps_sampled: 1630400
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9958694105258
num_env_steps_trained: 1613500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9959445121524
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 45.74285714285714
  ram_util_percent: 76.84285714285713
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05845476003141145
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02302143860258303
  mean_inference_ms: 1.119426327477263
  mean_raw_obs_processing_ms: 0.25593204190428814
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01877833295751501
    StateBufferConnector_ms: 0.0032173262702094186
    ViewRequirementAgentConnector_ms: 0.11290378040737575
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 2.0
  episode_reward_mean: 0.1574074074074074
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05845476003141145
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02302143860258303
    mean_inference_ms: 1.119426327477263
    mean_raw_obs_processing_ms: 0.25593204190428814
time_since_restore: 1235.7008483409882
time_this_iter_s: 10.148774862289429
time_total_s: 1235.7008483409882
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001067
timesteps_total: 1630400
training_iteration: 122
trial_id: default
train step: 123
agent_timesteps_total: 1644300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018728441662258573
  StateBufferConnector_ms: 0.0032173262702094186
  ViewRequirementAgentConnector_ms: 0.11214371080751773
counters:
  num_agent_steps_sampled: 1644300
  num_agent_steps_trained: 1627500
  num_env_steps_sampled: 1644300
  num_env_steps_trained: 1627500
  num_samples_added_to_queue: 1644000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 32412
custom_metrics: {}
date: 2023-08-14_17-17-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 2.8425925925925926
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 12846
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7104056477546692
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 5.7539381980896
        total_loss: 18.228565216064453
        var_gnorm: 64.37247467041016
        vf_explained_var: 0.8697206974029541
        vf_loss: 32.05331039428711
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3255.0
  learner_queue:
    size_count: 3262
    size_mean: 15.0
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7776388834631178
  num_agent_steps_sampled: 1644300
  num_agent_steps_trained: 1627500
  num_env_steps_sampled: 1644300
  num_env_steps_trained: 1627500
  num_samples_added_to_queue: 1644000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 32412
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 146.23
    learner_load_time_ms: 1.987
    learner_load_wait_time_ms: 1.409
iterations_since_restore: 123
node_ip: 127.0.0.1
num_agent_steps_sampled: 1644300
num_agent_steps_trained: 1627500
num_env_steps_sampled: 1644300
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9704064471016
num_env_steps_trained: 1627500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9701935438434
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 42.36666666666667
  ram_util_percent: 76.63333333333335
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058444915017187134
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023005581730639078
  mean_inference_ms: 1.1190906711890534
  mean_raw_obs_processing_ms: 0.255856921404191
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018728441662258573
    StateBufferConnector_ms: 0.0032173262702094186
    ViewRequirementAgentConnector_ms: 0.11214371080751773
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 2.8425925925925926
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 3.0, 2.0, 3.0, 1.0, 1.0,
      1.0, 0.0, 0.0, 2.0, 5.0, 3.0, 6.0, 0.0, 2.0, 1.0, 0.0, 0.0, 4.0, 6.0, 1.0, 4.0,
      6.0, 4.0, 3.0, 6.0, 6.0, 3.0, 6.0, 6.0, 1.0, 2.0, 6.0, 4.0, 6.0, 5.0, 3.0, 9.0,
      5.0, 3.0, 4.0, 7.0, 3.0, 5.0, 2.0, 4.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0,
      4.0, 0.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 1.0, 1.0, 3.0, 2.0,
      3.0, 2.0, 4.0, 8.0, 4.0, 1.0, 1.0, 5.0, 3.0, 10.0, 3.0, 4.0, 4.0, 4.0, 1.0,
      5.0, 3.0, 5.0, 1.0, 5.0, 7.0, 8.0, 3.0, 4.0, 3.0, 5.0, 1.0, 4.0, 4.0, 7.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058444915017187134
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023005581730639078
    mean_inference_ms: 1.1190906711890534
    mean_raw_obs_processing_ms: 0.255856921404191
time_since_restore: 1245.8472075462341
time_this_iter_s: 10.146359205245972
time_total_s: 1245.8472075462341
timers:
  sample_time_ms: 0.057
  synch_weights_time_ms: 0.239
  training_iteration_time_ms: 0.358
timestamp: 1692001077
timesteps_total: 1644300
training_iteration: 123
trial_id: default
train step: 124
agent_timesteps_total: 1658050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01839752550478335
  StateBufferConnector_ms: 0.003249998445864077
  ViewRequirementAgentConnector_ms: 0.11195606655544704
counters:
  num_agent_steps_sampled: 1658050
  num_agent_steps_trained: 1641500
  num_env_steps_sampled: 1658050
  num_env_steps_trained: 1641500
  num_samples_added_to_queue: 1658000
  num_training_step_calls_since_last_synch_worker_weights: 922
  num_weight_broadcasts: 32683
custom_metrics: {}
date: 2023-08-14_17-18-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.9537037037037037
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 12954
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7843196988105774
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.41890287399292
        total_loss: 16.318382263183594
        var_gnorm: 64.37492370605469
        vf_explained_var: 0.9078744649887085
        vf_loss: 45.31776809692383
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3283.0
  learner_queue:
    size_count: 3286
    size_mean: 15.36
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3965672200076873
  num_agent_steps_sampled: 1658050
  num_agent_steps_trained: 1641500
  num_env_steps_sampled: 1658050
  num_env_steps_trained: 1641500
  num_samples_added_to_queue: 1658000
  num_training_step_calls_since_last_synch_worker_weights: 922
  num_weight_broadcasts: 32683
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 265.841
    learner_load_time_ms: 2.129
    learner_load_wait_time_ms: 1.621
iterations_since_restore: 124
node_ip: 127.0.0.1
num_agent_steps_sampled: 1658050
num_agent_steps_trained: 1641500
num_env_steps_sampled: 1658050
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9976724425615
num_env_steps_trained: 1641500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9976301233353
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 45.27857142857143
  ram_util_percent: 76.79285714285713
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05843511667994183
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02298978012665573
  mean_inference_ms: 1.1187758514348214
  mean_raw_obs_processing_ms: 0.25578863482611225
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01839752550478335
    StateBufferConnector_ms: 0.003249998445864077
    ViewRequirementAgentConnector_ms: 0.11195606655544704
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.9537037037037037
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 2.0, 2.0, 0.0, 1.0, 3.0, 1.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0,
      1.0, 2.0, 0.0, 2.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 1.0, 1.0, 1.0, 0.0, 6.0, 3.0,
      1.0, 2.0, 2.0, 8.0, 5.0, 4.0, 4.0, 3.0, 3.0, 2.0, 5.0, 6.0, 3.0, 5.0, 4.0, 7.0,
      4.0, 7.0, 2.0, 7.0, 8.0, 5.0, 2.0, 7.0, 9.0, 0.0, 3.0, 0.0, 1.0, 0.0, 0.0, 2.0,
      0.0, 0.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 3.0, 2.0, 0.0, 1.0,
      1.0, 4.0, 0.0, 2.0, 5.0, 1.0, 2.0, 4.0, 4.0, 5.0, 5.0, 2.0, 2.0, 4.0, 4.0, 3.0,
      6.0, 3.0, 6.0, 8.0, 5.0, 7.0, 5.0, 7.0, 7.0, 2.0, 8.0, 6.0, 7.0, 5.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05843511667994183
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02298978012665573
    mean_inference_ms: 1.1187758514348214
    mean_raw_obs_processing_ms: 0.25578863482611225
time_since_restore: 1255.9358658790588
time_this_iter_s: 10.088658332824707
time_total_s: 1255.9358658790588
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001087
timesteps_total: 1658050
training_iteration: 124
trial_id: default
train step: 125
agent_timesteps_total: 1671850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01897259994789406
  StateBufferConnector_ms: 0.003352871647587529
  ViewRequirementAgentConnector_ms: 0.11311747409679272
counters:
  num_agent_steps_sampled: 1671850
  num_agent_steps_trained: 1655000
  num_env_steps_sampled: 1671850
  num_env_steps_trained: 1655000
  num_samples_added_to_queue: 1671500
  num_training_step_calls_since_last_synch_worker_weights: 154
  num_weight_broadcasts: 32955
custom_metrics: {}
date: 2023-08-14_17-18-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 5.666666666666667
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 13062
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7170151472091675
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.84909725189209
        total_loss: 17.50676155090332
        var_gnorm: 64.3853759765625
        vf_explained_var: 0.9628243446350098
        vf_loss: 24.4854793548584
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3310.0
  learner_queue:
    size_count: 3316
    size_mean: 15.56
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0983624174196784
  num_agent_steps_sampled: 1671850
  num_agent_steps_trained: 1655000
  num_env_steps_sampled: 1671850
  num_env_steps_trained: 1655000
  num_samples_added_to_queue: 1671500
  num_training_step_calls_since_last_synch_worker_weights: 154
  num_weight_broadcasts: 32955
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 180.571
    learner_load_time_ms: 1.461
    learner_load_wait_time_ms: 1.588
iterations_since_restore: 125
node_ip: 127.0.0.1
num_agent_steps_sampled: 1671850
num_agent_steps_trained: 1655000
num_env_steps_sampled: 1671850
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9950318515346
num_env_steps_trained: 1655000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.995139854762
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.67857142857143
  ram_util_percent: 76.70000000000002
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05843030231091332
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022978721990749976
  mean_inference_ms: 1.1185224312937707
  mean_raw_obs_processing_ms: 0.25571172566810707
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01897259994789406
    StateBufferConnector_ms: 0.003352871647587529
    ViewRequirementAgentConnector_ms: 0.11311747409679272
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 5.666666666666667
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 9.0, 4.0, 5.0, 3.0, 5.0, 3.0, 3.0, 1.0, 3.0, 3.0, 6.0, 3.0,
      5.0, 3.0, 5.0, 1.0, 5.0, 7.0, 1.0, 7.0, 5.0, 4.0, 3.0, 5.0, 6.0, 7.0, 8.0, 7.0,
      3.0, 7.0, 3.0, 8.0, 9.0, 10.0, 11.0, 6.0, 9.0, 6.0, 6.0, 4.0, 8.0, 4.0, 5.0,
      8.0, 6.0, 6.0, 8.0, 5.0, 9.0, 7.0, 2.0, 7.0, 9.0, 4.0, 3.0, 3.0, 3.0, 5.0, 8.0,
      6.0, 6.0, 1.0, 2.0, 5.0, 7.0, 7.0, 8.0, 3.0, 1.0, 5.0, 4.0, 3.0, 6.0, 3.0, 4.0,
      3.0, 7.0, 5.0, 9.0, 6.0, 7.0, 4.0, 6.0, 5.0, 5.0, 6.0, 8.0, 8.0, 10.0, 6.0,
      6.0, 3.0, 4.0, 6.0, 8.0, 7.0, 6.0, 5.0, 11.0, 9.0, 9.0, 11.0, 9.0, 6.0, 8.0,
      10.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05843030231091332
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022978721990749976
    mean_inference_ms: 1.1185224312937707
    mean_raw_obs_processing_ms: 0.25571172566810707
time_since_restore: 1266.0783808231354
time_this_iter_s: 10.142514944076538
time_total_s: 1266.0783808231354
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001097
timesteps_total: 1671850
training_iteration: 125
trial_id: default
train step: 126
agent_timesteps_total: 1685650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01874742684540925
  StateBufferConnector_ms: 0.0032550758785671657
  ViewRequirementAgentConnector_ms: 0.11249537821169253
counters:
  num_agent_steps_sampled: 1685650
  num_agent_steps_trained: 1669000
  num_env_steps_sampled: 1685650
  num_env_steps_trained: 1669000
  num_samples_added_to_queue: 1685500
  num_training_step_calls_since_last_synch_worker_weights: 918
  num_weight_broadcasts: 33226
custom_metrics: {}
date: 2023-08-14_17-18-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.148148148148149
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 13170
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7076602578163147
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -12.816303253173828
        total_loss: 38.96723175048828
        var_gnorm: 64.39723205566406
        vf_explained_var: 0.8666819930076599
        vf_loss: 110.64366912841797
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3338.0
  learner_queue:
    size_count: 3342
    size_mean: 15.42
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.250439922587247
  num_agent_steps_sampled: 1685650
  num_agent_steps_trained: 1669000
  num_env_steps_sampled: 1685650
  num_env_steps_trained: 1669000
  num_samples_added_to_queue: 1685500
  num_training_step_calls_since_last_synch_worker_weights: 918
  num_weight_broadcasts: 33226
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 241.078
    learner_load_time_ms: 1.461
    learner_load_wait_time_ms: 1.504
iterations_since_restore: 126
node_ip: 127.0.0.1
num_agent_steps_sampled: 1685650
num_agent_steps_trained: 1669000
num_env_steps_sampled: 1685650
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9969730443593
num_env_steps_trained: 1669000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.996929175437
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 45.16428571428571
  ram_util_percent: 76.69285714285715
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05842178531793872
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022968632834069896
  mean_inference_ms: 1.1182261690162327
  mean_raw_obs_processing_ms: 0.2556425487359556
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01874742684540925
    StateBufferConnector_ms: 0.0032550758785671657
    ViewRequirementAgentConnector_ms: 0.11249537821169253
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.148148148148149
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 9.0, 8.0, 8.0, 8.0, 10.0, 8.0, 8.0, 6.0, 9.0, 7.0, 15.0,
      7.0, 4.0, 11.0, 10.0, 10.0, 4.0, 9.0, 7.0, 10.0, 7.0, 3.0, 4.0, 8.0, 5.0, 7.0,
      4.0, 8.0, 5.0, 6.0, 5.0, 11.0, 12.0, 7.0, 12.0, 12.0, 9.0, 12.0, 7.0, 12.0,
      7.0, 9.0, 7.0, 7.0, 17.0, 12.0, 12.0, 7.0, 9.0, 9.0, 10.0, 7.0, 11.0, 7.0, 10.0,
      7.0, 7.0, 9.0, 5.0, 10.0, 6.0, 9.0, 11.0, 5.0, 6.0, 10.0, 8.0, 6.0, 8.0, 6.0,
      4.0, 11.0, 6.0, 6.0, 11.0, 7.0, 12.0, 8.0, 8.0, 6.0, 9.0, 6.0, 7.0, 7.0, 12.0,
      7.0, 12.0, 7.0, 7.0, 10.0, 5.0, 9.0, 5.0, 6.0, 8.0, 5.0, 6.0, 8.0, 11.0, 14.0,
      9.0, 6.0, 9.0, 7.0, 6.0, 8.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05842178531793872
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022968632834069896
    mean_inference_ms: 1.1182261690162327
    mean_raw_obs_processing_ms: 0.2556425487359556
time_since_restore: 1276.1811428070068
time_this_iter_s: 10.10276198387146
time_total_s: 1276.1811428070068
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1692001108
timesteps_total: 1685650
training_iteration: 126
trial_id: default
train step: 127
agent_timesteps_total: 1699450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01873175303141276
  StateBufferConnector_ms: 0.0032736195458306205
  ViewRequirementAgentConnector_ms: 0.11233709476612232
counters:
  num_agent_steps_sampled: 1699450
  num_agent_steps_trained: 1682500
  num_env_steps_sampled: 1699450
  num_env_steps_trained: 1682500
  num_samples_added_to_queue: 1699000
  num_training_step_calls_since_last_synch_worker_weights: 433
  num_weight_broadcasts: 33495
custom_metrics: {}
date: 2023-08-14_17-18-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.203703703703704
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 13278
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6660249829292297
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -71.56431579589844
        total_loss: 20.17896270751953
        var_gnorm: 64.40472412109375
        vf_explained_var: 0.8004187345504761
        vf_loss: 190.1468048095703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3365.0
  learner_queue:
    size_count: 3371
    size_mean: 15.48
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1702991070662232
  num_agent_steps_sampled: 1699450
  num_agent_steps_trained: 1682500
  num_env_steps_sampled: 1699450
  num_env_steps_trained: 1682500
  num_samples_added_to_queue: 1699000
  num_training_step_calls_since_last_synch_worker_weights: 433
  num_weight_broadcasts: 33495
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 193.031
    learner_load_time_ms: 1.531
    learner_load_wait_time_ms: 1.483
iterations_since_restore: 127
node_ip: 127.0.0.1
num_agent_steps_sampled: 1699450
num_agent_steps_trained: 1682500
num_env_steps_sampled: 1699450
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9990129477885
num_env_steps_trained: 1682500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9990344054452
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.57142857142857
  ram_util_percent: 76.69285714285716
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0584146002471829
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02295931970412444
  mean_inference_ms: 1.1179625863618368
  mean_raw_obs_processing_ms: 0.25558014579446514
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01873175303141276
    StateBufferConnector_ms: 0.0032736195458306205
    ViewRequirementAgentConnector_ms: 0.11233709476612232
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.203703703703704
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 9.0, 13.0, 11.0, 7.0, 7.0, 4.0, 12.0, 8.0, 7.0, 5.0,
      8.0, 7.0, 11.0, 9.0, 9.0, 9.0, 9.0, 8.0, 8.0, 9.0, 9.0, 7.0, 3.0, 8.0, 13.0,
      11.0, 11.0, 6.0, 7.0, 10.0, 17.0, 6.0, 11.0, 6.0, 14.0, 8.0, 7.0, 8.0, 11.0,
      8.0, 6.0, 4.0, 6.0, 9.0, 8.0, 8.0, 10.0, 9.0, 6.0, 9.0, 10.0, 8.0, 11.0, 7.0,
      4.0, 8.0, 8.0, 13.0, 9.0, 8.0, 6.0, 8.0, 8.0, 9.0, 4.0, 6.0, 9.0, 8.0, 9.0,
      5.0, 8.0, 6.0, 12.0, 7.0, 9.0, 12.0, 10.0, 10.0, 8.0, 7.0, 8.0, 6.0, 3.0, 5.0,
      9.0, 6.0, 9.0, 7.0, 11.0, 8.0, 9.0, 7.0, 7.0, 8.0, 12.0, 7.0, 5.0, 10.0, 8.0,
      7.0, 8.0, 6.0, 3.0, 8.0, 8.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0584146002471829
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02295931970412444
    mean_inference_ms: 1.1179625863618368
    mean_raw_obs_processing_ms: 0.25558014579446514
time_since_restore: 1286.3185420036316
time_this_iter_s: 10.137399196624756
time_total_s: 1286.3185420036316
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001118
timesteps_total: 1699450
training_iteration: 127
trial_id: default
train step: 128
agent_timesteps_total: 1713150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018950678267568914
  StateBufferConnector_ms: 0.003301197627805314
  ViewRequirementAgentConnector_ms: 0.11360307909407706
counters:
  num_agent_steps_sampled: 1713150
  num_agent_steps_trained: 1696500
  num_env_steps_sampled: 1713150
  num_env_steps_trained: 1696500
  num_samples_added_to_queue: 1713000
  num_training_step_calls_since_last_synch_worker_weights: 1128
  num_weight_broadcasts: 33764
custom_metrics: {}
date: 2023-08-14_17-18-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.273584905660377
episode_reward_min: 2.0
episodes_this_iter: 106
episodes_total: 13384
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.3232462704181671
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.877614974975586
        total_loss: 37.56025314331055
        var_gnorm: 64.4117202758789
        vf_explained_var: 0.9533849954605103
        vf_loss: 60.597740173339844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3393.0
  learner_queue:
    size_count: 3397
    size_mean: 15.48
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1702991070662232
  num_agent_steps_sampled: 1713150
  num_agent_steps_trained: 1696500
  num_env_steps_sampled: 1713150
  num_env_steps_trained: 1696500
  num_samples_added_to_queue: 1713000
  num_training_step_calls_since_last_synch_worker_weights: 1128
  num_weight_broadcasts: 33764
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 240.598
    learner_load_time_ms: 1.519
    learner_load_wait_time_ms: 1.589
iterations_since_restore: 128
node_ip: 127.0.0.1
num_agent_steps_sampled: 1713150
num_agent_steps_trained: 1696500
num_env_steps_sampled: 1713150
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9987914572887
num_env_steps_trained: 1696500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9987649928496
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.12666666666667
  ram_util_percent: 76.73333333333335
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0584109445013196
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02295037941105959
  mean_inference_ms: 1.1177283210614286
  mean_raw_obs_processing_ms: 0.25552776088269835
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018950678267568914
    StateBufferConnector_ms: 0.003301197627805314
    ViewRequirementAgentConnector_ms: 0.11360307909407706
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.273584905660377
  episode_reward_min: 2.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 4.0, 8.0, 9.0, 10.0, 10.0, 11.0, 11.0, 7.0, 6.0, 10.0,
      11.0, 8.0, 7.0, 12.0, 9.0, 9.0, 11.0, 11.0, 3.0, 5.0, 8.0, 8.0, 5.0, 10.0, 9.0,
      9.0, 6.0, 10.0, 11.0, 8.0, 5.0, 3.0, 5.0, 5.0, 4.0, 5.0, 8.0, 11.0, 8.0, 11.0,
      7.0, 2.0, 5.0, 6.0, 3.0, 6.0, 5.0, 6.0, 5.0, 4.0, 6.0, 6.0, 14.0, 9.0, 10.0,
      7.0, 7.0, 6.0, 7.0, 10.0, 8.0, 4.0, 12.0, 6.0, 10.0, 3.0, 13.0, 7.0, 7.0, 8.0,
      9.0, 5.0, 8.0, 8.0, 13.0, 6.0, 9.0, 9.0, 6.0, 6.0, 9.0, 6.0, 4.0, 6.0, 5.0,
      10.0, 2.0, 6.0, 11.0, 3.0, 6.0, 8.0, 4.0, 5.0, 7.0, 7.0, 10.0, 5.0, 7.0, 4.0,
      2.0, 7.0, 5.0, 5.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0584109445013196
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02295037941105959
    mean_inference_ms: 1.1177283210614286
    mean_raw_obs_processing_ms: 0.25552776088269835
time_since_restore: 1296.413497209549
time_this_iter_s: 10.094955205917358
time_total_s: 1296.413497209549
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.047
timestamp: 1692001128
timesteps_total: 1713150
training_iteration: 128
trial_id: default
train step: 129
agent_timesteps_total: 1726900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0188836344966182
  StateBufferConnector_ms: 0.0031901730431450736
  ViewRequirementAgentConnector_ms: 0.11296360581009476
counters:
  num_agent_steps_sampled: 1726900
  num_agent_steps_trained: 1710000
  num_env_steps_sampled: 1726900
  num_env_steps_trained: 1710000
  num_samples_added_to_queue: 1726500
  num_training_step_calls_since_last_synch_worker_weights: 395
  num_weight_broadcasts: 34035
custom_metrics: {}
date: 2023-08-14_17-18-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.6666666666666665
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 13492
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.29232609272003174
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.880505561828613
        total_loss: 100.49531555175781
        var_gnorm: 64.41846466064453
        vf_explained_var: 0.8619948625564575
        vf_loss: 225.67491149902344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3420.0
  learner_queue:
    size_count: 3426
    size_mean: 15.5
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1532562594670797
  num_agent_steps_sampled: 1726900
  num_agent_steps_trained: 1710000
  num_env_steps_sampled: 1726900
  num_env_steps_trained: 1710000
  num_samples_added_to_queue: 1726500
  num_training_step_calls_since_last_synch_worker_weights: 395
  num_weight_broadcasts: 34035
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 194.016
    learner_load_time_ms: 1.392
    learner_load_wait_time_ms: 1.458
iterations_since_restore: 129
node_ip: 127.0.0.1
num_agent_steps_sampled: 1726900
num_agent_steps_trained: 1710000
num_env_steps_sampled: 1726900
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9942302945965
num_env_steps_trained: 1710000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.994335198331
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.75714285714286
  ram_util_percent: 76.71428571428574
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058405573864089684
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022938463503336483
  mean_inference_ms: 1.1174882755523523
  mean_raw_obs_processing_ms: 0.2554733311864863
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0188836344966182
    StateBufferConnector_ms: 0.0031901730431450736
    ViewRequirementAgentConnector_ms: 0.11296360581009476
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.6666666666666665
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 3.0, 4.0, 6.0, 3.0, 4.0, 4.0, 4.0, 8.0, 4.0, 2.0, 3.0,
      3.0, 4.0, 5.0, 6.0, 5.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 6.0, 4.0, 4.0, 3.0, 6.0,
      5.0, 3.0, 3.0, 1.0, 4.0, 4.0, 4.0, 2.0, 3.0, 1.0, 2.0, 7.0, 3.0, 5.0, 4.0, 4.0,
      3.0, 3.0, 4.0, 0.0, 3.0, 3.0, 5.0, 7.0, 2.0, 6.0, 4.0, 6.0, 4.0, 6.0, 2.0, 3.0,
      2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 4.0, 2.0, 4.0, 6.0, 3.0, 3.0, 2.0, 4.0, 4.0, 7.0,
      3.0, 5.0, 1.0, 5.0, 3.0, 3.0, 2.0, 5.0, 2.0, 2.0, 3.0, 4.0, 5.0, 6.0, 3.0, 6.0,
      5.0, 4.0, 2.0, 1.0, 5.0, 2.0, 3.0, 4.0, 6.0, 6.0, 6.0, 3.0, 5.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058405573864089684
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022938463503336483
    mean_inference_ms: 1.1174882755523523
    mean_raw_obs_processing_ms: 0.2554733311864863
time_since_restore: 1306.5458452701569
time_this_iter_s: 10.13234806060791
time_total_s: 1306.5458452701569
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001138
timesteps_total: 1726900
training_iteration: 129
trial_id: default
train step: 130
agent_timesteps_total: 1740750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0190968907207524
  StateBufferConnector_ms: 0.0032844893429257453
  ViewRequirementAgentConnector_ms: 0.11262149985777128
counters:
  num_agent_steps_sampled: 1740750
  num_agent_steps_trained: 1724000
  num_env_steps_sampled: 1740750
  num_env_steps_trained: 1724000
  num_samples_added_to_queue: 1740500
  num_training_step_calls_since_last_synch_worker_weights: 367
  num_weight_broadcasts: 34309
custom_metrics: {}
date: 2023-08-14_17-19-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.137614678899083
episode_reward_min: 0.0
episodes_this_iter: 109
episodes_total: 13601
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.37162506580352783
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.4176900386810303
        total_loss: 25.583154678344727
        var_gnorm: 64.413818359375
        vf_explained_var: 0.8886249661445618
        vf_loss: 48.04718017578125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3448.0
  learner_queue:
    size_count: 3454
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.40356688476182
  num_agent_steps_sampled: 1740750
  num_agent_steps_trained: 1724000
  num_env_steps_sampled: 1740750
  num_env_steps_trained: 1724000
  num_samples_added_to_queue: 1740500
  num_training_step_calls_since_last_synch_worker_weights: 367
  num_weight_broadcasts: 34309
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 180.05
    learner_load_time_ms: 1.388
    learner_load_wait_time_ms: 1.513
iterations_since_restore: 130
node_ip: 127.0.0.1
num_agent_steps_sampled: 1740750
num_agent_steps_trained: 1724000
num_env_steps_sampled: 1740750
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.999174476162
num_env_steps_trained: 1724000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9991655354704
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.357142857142854
  ram_util_percent: 76.73571428571428
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058385577746714455
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022926942627639387
  mean_inference_ms: 1.1171969885189115
  mean_raw_obs_processing_ms: 0.2554057894041985
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0190968907207524
    StateBufferConnector_ms: 0.0032844893429257453
    ViewRequirementAgentConnector_ms: 0.11262149985777128
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.137614678899083
  episode_reward_min: 0.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [5.0, 6.0, 10.0, 5.0, 5.0, 7.0, 5.0, 6.0, 2.0, 4.0, 7.0, 5.0,
      2.0, 1.0, 3.0, 5.0, 3.0, 2.0, 3.0, 7.0, 2.0, 2.0, 6.0, 3.0, 4.0, 5.0, 2.0, 7.0,
      3.0, 5.0, 2.0, 3.0, 4.0, 4.0, 7.0, 6.0, 7.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 0.0,
      7.0, 0.0, 3.0, 3.0, 3.0, 5.0, 4.0, 1.0, 5.0, 5.0, 5.0, 3.0, 2.0, 3.0, 6.0, 7.0,
      3.0, 3.0, 2.0, 4.0, 7.0, 2.0, 6.0, 5.0, 4.0, 3.0, 7.0, 1.0, 4.0, 7.0, 2.0, 10.0,
      3.0, 7.0, 8.0, 3.0, 6.0, 7.0, 4.0, 5.0, 6.0, 0.0, 1.0, 3.0, 1.0, 6.0, 2.0, 7.0,
      7.0, 1.0, 1.0, 4.0, 6.0, 2.0, 5.0, 2.0, 8.0, 4.0, 4.0, 0.0, 2.0, 4.0, 7.0, 4.0,
      4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058385577746714455
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022926942627639387
    mean_inference_ms: 1.1171969885189115
    mean_raw_obs_processing_ms: 0.2554057894041985
time_since_restore: 1316.6778552532196
time_this_iter_s: 10.132009983062744
time_total_s: 1316.6778552532196
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001148
timesteps_total: 1740750
training_iteration: 130
trial_id: default
train step: 131
agent_timesteps_total: 1754550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01837739320558922
  StateBufferConnector_ms: 0.0032382590748439325
  ViewRequirementAgentConnector_ms: 0.11185240522723332
counters:
  num_agent_steps_sampled: 1754550
  num_agent_steps_trained: 1738000
  num_env_steps_sampled: 1754550
  num_env_steps_trained: 1738000
  num_samples_added_to_queue: 1754500
  num_training_step_calls_since_last_synch_worker_weights: 548
  num_weight_broadcasts: 34581
custom_metrics: {}
date: 2023-08-14_17-19-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 5.130841121495327
episode_reward_min: 1.0
episodes_this_iter: 107
episodes_total: 13708
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5927399396896362
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.422565221786499
        total_loss: 9.514504432678223
        var_gnorm: 64.41316986083984
        vf_explained_var: 0.9659930467605591
        vf_loss: 18.111276626586914
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3476.0
  learner_queue:
    size_count: 3481
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3078226179417451
  num_agent_steps_sampled: 1754550
  num_agent_steps_trained: 1738000
  num_env_steps_sampled: 1754550
  num_env_steps_trained: 1738000
  num_samples_added_to_queue: 1754500
  num_training_step_calls_since_last_synch_worker_weights: 548
  num_weight_broadcasts: 34581
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 203.002
    learner_load_time_ms: 3.039
    learner_load_wait_time_ms: 1.411
iterations_since_restore: 131
node_ip: 127.0.0.1
num_agent_steps_sampled: 1754550
num_agent_steps_trained: 1738000
num_env_steps_sampled: 1754550
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9991774563923
num_env_steps_trained: 1738000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9991655354704
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 45.106666666666676
  ram_util_percent: 76.72666666666669
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05837606363148377
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022915794397124815
  mean_inference_ms: 1.1169538704996689
  mean_raw_obs_processing_ms: 0.2553358492032432
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01837739320558922
    StateBufferConnector_ms: 0.0032382590748439325
    ViewRequirementAgentConnector_ms: 0.11185240522723332
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 5.130841121495327
  episode_reward_min: 1.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 6.0, 5.0, 4.0, 5.0, 3.0, 3.0, 5.0, 3.0, 5.0, 6.0, 8.0,
      6.0, 3.0, 6.0, 6.0, 4.0, 4.0, 5.0, 6.0, 2.0, 5.0, 4.0, 4.0, 3.0, 4.0, 6.0, 8.0,
      4.0, 5.0, 5.0, 4.0, 3.0, 5.0, 3.0, 5.0, 3.0, 7.0, 8.0, 6.0, 4.0, 6.0, 7.0, 8.0,
      10.0, 3.0, 5.0, 8.0, 8.0, 6.0, 5.0, 8.0, 11.0, 4.0, 9.0, 3.0, 3.0, 5.0, 8.0,
      8.0, 4.0, 9.0, 2.0, 1.0, 7.0, 6.0, 5.0, 5.0, 4.0, 7.0, 5.0, 4.0, 5.0, 5.0, 8.0,
      6.0, 5.0, 1.0, 2.0, 5.0, 3.0, 2.0, 4.0, 9.0, 7.0, 3.0, 4.0, 4.0, 4.0, 4.0, 7.0,
      4.0, 9.0, 6.0, 1.0, 4.0, 5.0, 5.0, 3.0, 4.0, 6.0, 12.0, 3.0, 7.0, 5.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05837606363148377
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022915794397124815
    mean_inference_ms: 1.1169538704996689
    mean_raw_obs_processing_ms: 0.2553358492032432
time_since_restore: 1326.7974953651428
time_this_iter_s: 10.119640111923218
time_total_s: 1326.7974953651428
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001158
timesteps_total: 1754550
training_iteration: 131
trial_id: default
train step: 132
agent_timesteps_total: 1768300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018745270844931914
  StateBufferConnector_ms: 0.003305105405433156
  ViewRequirementAgentConnector_ms: 0.11522502542656159
counters:
  num_agent_steps_sampled: 1768300
  num_agent_steps_trained: 1751500
  num_env_steps_sampled: 1768300
  num_env_steps_trained: 1751500
  num_samples_added_to_queue: 1768000
  num_training_step_calls_since_last_synch_worker_weights: 14
  num_weight_broadcasts: 34853
custom_metrics: {}
date: 2023-08-14_17-19-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.5327102803738315
episode_reward_min: 2.0
episodes_this_iter: 107
episodes_total: 13815
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6795670390129089
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -0.07687997817993164
        total_loss: 33.48622512817383
        var_gnorm: 64.41852569580078
        vf_explained_var: 0.8971626162528992
        vf_loss: 73.92188262939453
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3503.0
  learner_queue:
    size_count: 3509
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2649110640673518
  num_agent_steps_sampled: 1768300
  num_agent_steps_trained: 1751500
  num_env_steps_sampled: 1768300
  num_env_steps_trained: 1751500
  num_samples_added_to_queue: 1768000
  num_training_step_calls_since_last_synch_worker_weights: 14
  num_weight_broadcasts: 34853
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 181.188
    learner_load_time_ms: 2.991
    learner_load_wait_time_ms: 1.564
iterations_since_restore: 132
node_ip: 127.0.0.1
num_agent_steps_sampled: 1768300
num_agent_steps_trained: 1751500
num_env_steps_sampled: 1768300
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9938041250948
num_env_steps_trained: 1751500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.993916777366
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 45.3
  ram_util_percent: 76.80714285714284
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05839341449906508
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022905465706320585
  mean_inference_ms: 1.1167136115316505
  mean_raw_obs_processing_ms: 0.2552892159847323
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018745270844931914
    StateBufferConnector_ms: 0.003305105405433156
    ViewRequirementAgentConnector_ms: 0.11522502542656159
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.5327102803738315
  episode_reward_min: 2.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 8.0, 8.0, 8.0, 7.0, 8.0, 9.0, 8.0, 6.0, 11.0, 9.0, 5.0,
      4.0, 4.0, 6.0, 4.0, 9.0, 9.0, 3.0, 13.0, 6.0, 4.0, 6.0, 7.0, 6.0, 8.0, 4.0,
      10.0, 7.0, 7.0, 5.0, 5.0, 5.0, 3.0, 9.0, 8.0, 8.0, 7.0, 5.0, 9.0, 8.0, 2.0,
      9.0, 8.0, 7.0, 4.0, 8.0, 6.0, 8.0, 8.0, 6.0, 6.0, 4.0, 6.0, 3.0, 9.0, 10.0,
      8.0, 10.0, 6.0, 5.0, 4.0, 5.0, 6.0, 3.0, 4.0, 6.0, 4.0, 10.0, 2.0, 10.0, 7.0,
      3.0, 5.0, 4.0, 5.0, 5.0, 6.0, 3.0, 5.0, 8.0, 5.0, 11.0, 11.0, 4.0, 10.0, 5.0,
      6.0, 10.0, 7.0, 6.0, 9.0, 4.0, 8.0, 6.0, 4.0, 8.0, 9.0, 9.0, 10.0, 3.0, 7.0,
      11.0, 3.0, 3.0, 5.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05839341449906508
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022905465706320585
    mean_inference_ms: 1.1167136115316505
    mean_raw_obs_processing_ms: 0.2552892159847323
time_since_restore: 1336.9466683864594
time_this_iter_s: 10.149173021316528
time_total_s: 1336.9466683864594
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.045
timestamp: 1692001168
timesteps_total: 1768300
training_iteration: 132
trial_id: default
train step: 133
agent_timesteps_total: 1782100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018735726674397785
  StateBufferConnector_ms: 0.0032458040449354383
  ViewRequirementAgentConnector_ms: 0.11308016600432219
counters:
  num_agent_steps_sampled: 1782100
  num_agent_steps_trained: 1765500
  num_env_steps_sampled: 1782100
  num_env_steps_trained: 1765500
  num_samples_added_to_queue: 1782000
  num_training_step_calls_since_last_synch_worker_weights: 558
  num_weight_broadcasts: 35125
custom_metrics: {}
date: 2023-08-14_17-19-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.12962962962963
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 13923
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6792914867401123
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -20.76097297668457
        total_loss: 0.4423048496246338
        var_gnorm: 64.42478942871094
        vf_explained_var: 0.9096240997314453
        vf_loss: 49.19947052001953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3531.0
  learner_queue:
    size_count: 3536
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 1782100
  num_agent_steps_trained: 1765500
  num_env_steps_sampled: 1782100
  num_env_steps_trained: 1765500
  num_samples_added_to_queue: 1782000
  num_training_step_calls_since_last_synch_worker_weights: 558
  num_weight_broadcasts: 35125
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 203.433
    learner_load_time_ms: 2.987
    learner_load_wait_time_ms: 1.451
iterations_since_restore: 133
node_ip: 127.0.0.1
num_agent_steps_sampled: 1782100
num_agent_steps_trained: 1765500
num_env_steps_sampled: 1782100
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.993386777145
num_env_steps_trained: 1765500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9932909333354
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.278571428571425
  ram_util_percent: 76.77857142857142
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05837514727640767
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02289788597008126
  mean_inference_ms: 1.1164880535043527
  mean_raw_obs_processing_ms: 0.255223255025831
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018735726674397785
    StateBufferConnector_ms: 0.0032458040449354383
    ViewRequirementAgentConnector_ms: 0.11308016600432219
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.12962962962963
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 6.0, 5.0, 12.0, 6.0, 13.0, 6.0, 11.0, 7.0, 7.0, 6.0, 5.0,
      7.0, 2.0, 7.0, 6.0, 4.0, 8.0, 10.0, 6.0, 10.0, 8.0, 7.0, 13.0, 8.0, 6.0, 9.0,
      8.0, 5.0, 7.0, 3.0, 5.0, 12.0, 9.0, 2.0, 12.0, 15.0, 10.0, 7.0, 9.0, 10.0, 12.0,
      7.0, 10.0, 10.0, 5.0, 7.0, 5.0, 9.0, 9.0, 6.0, 11.0, 9.0, 14.0, 7.0, 9.0, 10.0,
      8.0, 7.0, 6.0, 5.0, 8.0, 8.0, 12.0, 6.0, 5.0, 9.0, 9.0, 6.0, 3.0, 11.0, 6.0,
      9.0, 4.0, 2.0, 8.0, 9.0, 12.0, 6.0, 6.0, 10.0, 10.0, 13.0, 4.0, 17.0, 8.0, 10.0,
      5.0, 8.0, 11.0, 10.0, 8.0, 5.0, 10.0, 7.0, 11.0, 10.0, 11.0, 10.0, 11.0, 5.0,
      7.0, 12.0, 11.0, 10.0, 9.0, 7.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05837514727640767
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02289788597008126
    mean_inference_ms: 1.1164880535043527
    mean_raw_obs_processing_ms: 0.255223255025831
time_since_restore: 1347.067541360855
time_this_iter_s: 10.120872974395752
time_total_s: 1347.067541360855
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001178
timesteps_total: 1782100
training_iteration: 133
trial_id: default
train step: 134
agent_timesteps_total: 1795750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019120724401741385
  StateBufferConnector_ms: 0.003308224900860653
  ViewRequirementAgentConnector_ms: 0.11490260329201957
counters:
  num_agent_steps_sampled: 1795750
  num_agent_steps_trained: 1779000
  num_env_steps_sampled: 1795750
  num_env_steps_trained: 1779000
  num_samples_added_to_queue: 1795500
  num_training_step_calls_since_last_synch_worker_weights: 344
  num_weight_broadcasts: 35395
custom_metrics: {}
date: 2023-08-14_17-19-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.897196261682243
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 14030
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6645509004592896
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 19.410768508911133
        total_loss: 99.51345825195312
        var_gnorm: 64.42817687988281
        vf_explained_var: 0.7903718948364258
        vf_loss: 166.85089111328125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3558.0
  learner_queue:
    size_count: 3564
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3098091464026353
  num_agent_steps_sampled: 1795750
  num_agent_steps_trained: 1779000
  num_env_steps_sampled: 1795750
  num_env_steps_trained: 1779000
  num_samples_added_to_queue: 1795500
  num_training_step_calls_since_last_synch_worker_weights: 344
  num_weight_broadcasts: 35395
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 180.369
    learner_load_time_ms: 2.996
    learner_load_wait_time_ms: 1.514
iterations_since_restore: 134
node_ip: 127.0.0.1
num_agent_steps_sampled: 1795750
num_agent_steps_trained: 1779000
num_env_steps_sampled: 1795750
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.9950533092474
num_env_steps_trained: 1779000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9951076684865
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 45.114285714285714
  ram_util_percent: 76.76428571428572
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05836215648146285
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022893795520683404
  mean_inference_ms: 1.1163631213661371
  mean_raw_obs_processing_ms: 0.2551840490618095
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019120724401741385
    StateBufferConnector_ms: 0.003308224900860653
    ViewRequirementAgentConnector_ms: 0.11490260329201957
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.897196261682243
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [14.0, 6.0, 11.0, 11.0, 12.0, 10.0, 13.0, 7.0, 7.0, 10.0, 5.0,
      9.0, 6.0, 6.0, 6.0, 12.0, 9.0, 10.0, 3.0, 13.0, 4.0, 4.0, 13.0, 8.0, 11.0, 7.0,
      10.0, 9.0, 11.0, 7.0, 12.0, 10.0, 7.0, 12.0, 11.0, 9.0, 8.0, 8.0, 11.0, 7.0,
      15.0, 10.0, 9.0, 10.0, 12.0, 7.0, 7.0, 8.0, 6.0, 6.0, 6.0, 9.0, 7.0, 8.0, 9.0,
      11.0, 8.0, 10.0, 9.0, 11.0, 9.0, 11.0, 8.0, 8.0, 14.0, 5.0, 10.0, 6.0, 7.0,
      14.0, 7.0, 8.0, 12.0, 11.0, 10.0, 8.0, 11.0, 12.0, 8.0, 7.0, 10.0, 9.0, 7.0,
      8.0, 7.0, 7.0, 8.0, 10.0, 9.0, 6.0, 9.0, 7.0, 9.0, 12.0, 8.0, 8.0, 10.0, 13.0,
      10.0, 8.0, 7.0, 8.0, 8.0, 10.0, 6.0, 5.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05836215648146285
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022893795520683404
    mean_inference_ms: 1.1163631213661371
    mean_raw_obs_processing_ms: 0.2551840490618095
time_since_restore: 1357.2023215293884
time_this_iter_s: 10.134780168533325
time_total_s: 1357.2023215293884
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001189
timesteps_total: 1795750
training_iteration: 134
trial_id: default
train step: 135
agent_timesteps_total: 1809650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01853594073542842
  StateBufferConnector_ms: 0.0032153394487169054
  ViewRequirementAgentConnector_ms: 0.11226910131948965
counters:
  num_agent_steps_sampled: 1809650
  num_agent_steps_trained: 1793000
  num_env_steps_sampled: 1809650
  num_env_steps_trained: 1793000
  num_samples_added_to_queue: 1809500
  num_training_step_calls_since_last_synch_worker_weights: 489
  num_weight_broadcasts: 35670
custom_metrics: {}
date: 2023-08-14_17-19-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.75
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 14138
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5770983099937439
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -13.453720092773438
        total_loss: 21.732946395874023
        var_gnorm: 64.43212890625
        vf_explained_var: 0.9074622988700867
        vf_loss: 76.14431762695312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3586.0
  learner_queue:
    size_count: 3591
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3078226179417451
  num_agent_steps_sampled: 1809650
  num_agent_steps_trained: 1793000
  num_env_steps_sampled: 1809650
  num_env_steps_trained: 1793000
  num_samples_added_to_queue: 1809500
  num_training_step_calls_since_last_synch_worker_weights: 489
  num_weight_broadcasts: 35670
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 203.285
    learner_load_time_ms: 2.999
    learner_load_wait_time_ms: 1.578
iterations_since_restore: 135
node_ip: 127.0.0.1
num_agent_steps_sampled: 1809650
num_agent_steps_trained: 1793000
num_env_steps_sampled: 1809650
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.996652849628
num_env_steps_trained: 1793000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9966287694094
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.49999999999999
  ram_util_percent: 76.7357142857143
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05836255140602363
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022883061952246125
  mean_inference_ms: 1.1160374103589232
  mean_raw_obs_processing_ms: 0.2551239051246285
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01853594073542842
    StateBufferConnector_ms: 0.0032153394487169054
    ViewRequirementAgentConnector_ms: 0.11226910131948965
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.75
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 5.0, 10.0, 8.0, 7.0, 8.0, 10.0, 13.0, 9.0, 11.0, 9.0, 10.0,
      11.0, 9.0, 8.0, 9.0, 5.0, 10.0, 5.0, 10.0, 4.0, 8.0, 6.0, 7.0, 7.0, 6.0, 10.0,
      6.0, 7.0, 4.0, 7.0, 7.0, 8.0, 7.0, 11.0, 12.0, 10.0, 13.0, 10.0, 7.0, 9.0, 13.0,
      8.0, 8.0, 10.0, 10.0, 7.0, 8.0, 9.0, 6.0, 7.0, 12.0, 7.0, 13.0, 10.0, 13.0,
      10.0, 11.0, 9.0, 7.0, 11.0, 10.0, 8.0, 8.0, 9.0, 7.0, 10.0, 4.0, 14.0, 7.0,
      10.0, 8.0, 11.0, 12.0, 5.0, 12.0, 7.0, 5.0, 11.0, 5.0, 12.0, 10.0, 8.0, 11.0,
      7.0, 7.0, 15.0, 11.0, 11.0, 9.0, 5.0, 9.0, 8.0, 8.0, 3.0, 9.0, 8.0, 8.0, 10.0,
      9.0, 7.0, 7.0, 8.0, 9.0, 10.0, 8.0, 12.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05836255140602363
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022883061952246125
    mean_inference_ms: 1.1160374103589232
    mean_raw_obs_processing_ms: 0.2551239051246285
time_since_restore: 1367.3278596401215
time_this_iter_s: 10.125538110733032
time_total_s: 1367.3278596401215
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1692001199
timesteps_total: 1809650
training_iteration: 135
trial_id: default
train step: 136
agent_timesteps_total: 1823350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018735505916454172
  StateBufferConnector_ms: 0.0032212999131944445
  ViewRequirementAgentConnector_ms: 0.11282651512711137
counters:
  num_agent_steps_sampled: 1823350
  num_agent_steps_trained: 1806500
  num_env_steps_sampled: 1823350
  num_env_steps_trained: 1806500
  num_samples_added_to_queue: 1823000
  num_training_step_calls_since_last_synch_worker_weights: 488
  num_weight_broadcasts: 35939
custom_metrics: {}
date: 2023-08-14_17-20-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 5.9907407407407405
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 14246
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5205252766609192
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 28.621335983276367
        total_loss: 79.26033020019531
        var_gnorm: 64.44017791748047
        vf_explained_var: 0.9150360226631165
        vf_loss: 106.48323822021484
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3613.0
  learner_queue:
    size_count: 3619
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 1823350
  num_agent_steps_trained: 1806500
  num_env_steps_sampled: 1823350
  num_env_steps_trained: 1806500
  num_samples_added_to_queue: 1823000
  num_training_step_calls_since_last_synch_worker_weights: 488
  num_weight_broadcasts: 35939
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 187.125
    learner_load_time_ms: 1.358
    learner_load_wait_time_ms: 1.543
iterations_since_restore: 136
node_ip: 127.0.0.1
num_agent_steps_sampled: 1823350
num_agent_steps_trained: 1806500
num_env_steps_sampled: 1823350
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9993140700913
num_env_steps_trained: 1806500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9993240836666
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.74666666666667
  ram_util_percent: 76.85333333333331
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0583606809510175
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022874328181309397
  mean_inference_ms: 1.1158641956543345
  mean_raw_obs_processing_ms: 0.25509206220034497
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018735505916454172
    StateBufferConnector_ms: 0.0032212999131944445
    ViewRequirementAgentConnector_ms: 0.11282651512711137
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 5.9907407407407405
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 7.0, 5.0, 11.0, 2.0, 7.0, 4.0, 6.0, 2.0, 12.0, 5.0, 4.0,
      4.0, 6.0, 3.0, 5.0, 5.0, 6.0, 6.0, 5.0, 3.0, 8.0, 7.0, 6.0, 6.0, 4.0, 7.0, 6.0,
      14.0, 4.0, 4.0, 2.0, 2.0, 5.0, 7.0, 5.0, 4.0, 7.0, 8.0, 7.0, 9.0, 7.0, 10.0,
      7.0, 6.0, 6.0, 9.0, 4.0, 6.0, 6.0, 11.0, 9.0, 9.0, 7.0, 6.0, 3.0, 5.0, 4.0,
      8.0, 4.0, 6.0, 7.0, 12.0, 6.0, 6.0, 7.0, 8.0, 3.0, 5.0, 1.0, 4.0, 4.0, 6.0,
      5.0, 4.0, 9.0, 3.0, 6.0, 3.0, 6.0, 1.0, 11.0, 5.0, 3.0, 4.0, 7.0, 7.0, 8.0,
      5.0, 8.0, 9.0, 8.0, 5.0, 7.0, 5.0, 4.0, 5.0, 8.0, 8.0, 11.0, 6.0, 1.0, 5.0,
      3.0, 6.0, 5.0, 9.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0583606809510175
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022874328181309397
    mean_inference_ms: 1.1158641956543345
    mean_raw_obs_processing_ms: 0.25509206220034497
time_since_restore: 1377.4627938270569
time_this_iter_s: 10.134934186935425
time_total_s: 1377.4627938270569
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001209
timesteps_total: 1823350
training_iteration: 136
trial_id: default
train step: 137
agent_timesteps_total: 1837100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018781813505654023
  StateBufferConnector_ms: 0.0032527424464715974
  ViewRequirementAgentConnector_ms: 0.1122811130274122
counters:
  num_agent_steps_sampled: 1837100
  num_agent_steps_trained: 1820500
  num_env_steps_sampled: 1837100
  num_env_steps_trained: 1820500
  num_samples_added_to_queue: 1837000
  num_training_step_calls_since_last_synch_worker_weights: 1
  num_weight_broadcasts: 36210
custom_metrics: {}
date: 2023-08-14_17-20-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 3.803738317757009
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 14353
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5343270301818848
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -26.13084602355957
        total_loss: -14.491939544677734
        var_gnorm: 64.44579315185547
        vf_explained_var: 0.9581149816513062
        vf_loss: 28.621084213256836
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3641.0
  learner_queue:
    size_count: 3647
    size_mean: 15.26
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4395832730342486
  num_agent_steps_sampled: 1837100
  num_agent_steps_trained: 1820500
  num_env_steps_sampled: 1837100
  num_env_steps_trained: 1820500
  num_samples_added_to_queue: 1837000
  num_training_step_calls_since_last_synch_worker_weights: 1
  num_weight_broadcasts: 36210
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 169.683
    learner_load_time_ms: 1.356
    learner_load_wait_time_ms: 1.425
iterations_since_restore: 137
node_ip: 127.0.0.1
num_agent_steps_sampled: 1837100
num_agent_steps_trained: 1820500
num_env_steps_sampled: 1837100
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9803635302126
num_env_steps_trained: 1820500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9800065034892
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.46428571428572
  ram_util_percent: 76.84285714285714
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05834555959272918
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022864973879207207
  mean_inference_ms: 1.1156794247385728
  mean_raw_obs_processing_ms: 0.25504346340793804
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018781813505654023
    StateBufferConnector_ms: 0.0032527424464715974
    ViewRequirementAgentConnector_ms: 0.1122811130274122
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 3.803738317757009
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 3.0, 10.0, 8.0, 7.0, 5.0, 6.0, 5.0, 2.0, 6.0, 5.0, 6.0,
      7.0, 4.0, 7.0, 3.0, 4.0, 7.0, 9.0, 8.0, 7.0, 9.0, 5.0, 2.0, 5.0, 8.0, 5.0, 6.0,
      11.0, 2.0, 0.0, 3.0, 7.0, 0.0, 3.0, 1.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 0.0,
      0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 7.0, 3.0, 8.0, 5.0, 5.0,
      4.0, 7.0, 8.0, 9.0, 7.0, 7.0, 8.0, 4.0, 9.0, 2.0, 3.0, 6.0, 5.0, 8.0, 8.0, 7.0,
      2.0, 9.0, 1.0, 6.0, 8.0, 3.0, 9.0, 6.0, 7.0, 5.0, 3.0, 2.0, 5.0, 3.0, 1.0, 1.0,
      2.0, 1.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05834555959272918
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022864973879207207
    mean_inference_ms: 1.1156794247385728
    mean_raw_obs_processing_ms: 0.25504346340793804
time_since_restore: 1387.6176359653473
time_this_iter_s: 10.154842138290405
time_total_s: 1387.6176359653473
timers:
  sample_time_ms: 0.09
  synch_weights_time_ms: 0.271
  training_iteration_time_ms: 0.432
timestamp: 1692001219
timesteps_total: 1837100
training_iteration: 137
trial_id: default
train step: 138
agent_timesteps_total: 1851000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018746764571578416
  StateBufferConnector_ms: 0.003224832040292245
  ViewRequirementAgentConnector_ms: 0.11246425134164316
counters:
  num_agent_steps_sampled: 1851000
  num_agent_steps_trained: 1834500
  num_env_steps_sampled: 1851000
  num_env_steps_trained: 1834500
  num_samples_added_to_queue: 1851000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 36485
custom_metrics: {}
date: 2023-08-14_17-20-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 14461
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.2443741261959076
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.5550343990325928
        total_loss: 10.618327140808105
        var_gnorm: 64.44964599609375
        vf_explained_var: 0.9151244163513184
        vf_loss: 20.57032585144043
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3669.0
  learner_queue:
    size_count: 3675
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.632666530556684
  num_agent_steps_sampled: 1851000
  num_agent_steps_trained: 1834500
  num_env_steps_sampled: 1851000
  num_env_steps_trained: 1834500
  num_samples_added_to_queue: 1851000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 36485
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 158.9
    learner_load_time_ms: 1.55
    learner_load_wait_time_ms: 1.466
iterations_since_restore: 138
node_ip: 127.0.0.1
num_agent_steps_sampled: 1851000
num_agent_steps_trained: 1834500
num_env_steps_sampled: 1851000
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.080703207025
num_env_steps_trained: 1834500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.0740895610325
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.46428571428572
  ram_util_percent: 76.61428571428571
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058370165899886174
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022846372966141556
  mean_inference_ms: 1.1153483551686583
  mean_raw_obs_processing_ms: 0.2549884680474581
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018746764571578416
    StateBufferConnector_ms: 0.003224832040292245
    ViewRequirementAgentConnector_ms: 0.11246425134164316
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058370165899886174
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022846372966141556
    mean_inference_ms: 1.1153483551686583
    mean_raw_obs_processing_ms: 0.2549884680474581
time_since_restore: 1397.7652859687805
time_this_iter_s: 10.147650003433228
time_total_s: 1397.7652859687805
timers:
  sample_time_ms: 0.085
  synch_weights_time_ms: 0.702
  training_iteration_time_ms: 2.33
timestamp: 1692001229
timesteps_total: 1851000
training_iteration: 138
trial_id: default
train step: 139
agent_timesteps_total: 1864750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018619387238113967
  StateBufferConnector_ms: 0.0031848748524983725
  ViewRequirementAgentConnector_ms: 0.11289848221672906
counters:
  num_agent_steps_sampled: 1864750
  num_agent_steps_trained: 1848000
  num_env_steps_sampled: 1864750
  num_env_steps_trained: 1848000
  num_samples_added_to_queue: 1864500
  num_training_step_calls_since_last_synch_worker_weights: 25
  num_weight_broadcasts: 36756
custom_metrics: {}
date: 2023-08-14_17-20-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 0.0
episode_reward_mean: 0.0
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 14569
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6234790086746216
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -2.287614583969116
        total_loss: 1.4967799186706543
        var_gnorm: 64.44900512695312
        vf_explained_var: 0.9264804124832153
        vf_loss: 13.803579330444336
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3696.0
  learner_queue:
    size_count: 3702
    size_mean: 15.24
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4636939570825591
  num_agent_steps_sampled: 1864750
  num_agent_steps_trained: 1848000
  num_env_steps_sampled: 1864750
  num_env_steps_trained: 1848000
  num_samples_added_to_queue: 1864500
  num_training_step_calls_since_last_synch_worker_weights: 25
  num_weight_broadcasts: 36756
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 181.737
    learner_load_time_ms: 1.585
    learner_load_wait_time_ms: 1.657
iterations_since_restore: 139
node_ip: 127.0.0.1
num_agent_steps_sampled: 1864750
num_agent_steps_trained: 1848000
num_env_steps_sampled: 1864750
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9948859404992
num_env_steps_trained: 1848000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9949789233992
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.07857142857143
  ram_util_percent: 76.96428571428571
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05834518625949182
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02283572620224617
  mean_inference_ms: 1.1151888856475902
  mean_raw_obs_processing_ms: 0.25494113496848797
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018619387238113967
    StateBufferConnector_ms: 0.0031848748524983725
    ViewRequirementAgentConnector_ms: 0.11289848221672906
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 0.0
  episode_reward_mean: 0.0
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05834518625949182
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02283572620224617
    mean_inference_ms: 1.1151888856475902
    mean_raw_obs_processing_ms: 0.25494113496848797
time_since_restore: 1407.9288730621338
time_this_iter_s: 10.163587093353271
time_total_s: 1407.9288730621338
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692001239
timesteps_total: 1864750
training_iteration: 139
trial_id: default
train step: 140
agent_timesteps_total: 1878200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019235838027227493
  StateBufferConnector_ms: 0.003368740990048363
  ViewRequirementAgentConnector_ms: 0.11736733572823661
counters:
  num_agent_steps_sampled: 1878200
  num_agent_steps_trained: 1861500
  num_env_steps_sampled: 1878200
  num_env_steps_trained: 1861500
  num_samples_added_to_queue: 1878000
  num_training_step_calls_since_last_synch_worker_weights: 1452
  num_weight_broadcasts: 37021
custom_metrics: {}
date: 2023-08-14_17-20-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.009523809523809525
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 14674
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7993184328079224
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -3.8480348587036133
        total_loss: -6.164855003356934
        var_gnorm: 64.44245147705078
        vf_explained_var: 0.9739605188369751
        vf_loss: 3.359543800354004
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3723.0
  learner_queue:
    size_count: 3726
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3230268326832981
  num_agent_steps_sampled: 1878200
  num_agent_steps_trained: 1861500
  num_env_steps_sampled: 1878200
  num_env_steps_trained: 1861500
  num_samples_added_to_queue: 1878000
  num_training_step_calls_since_last_synch_worker_weights: 1452
  num_weight_broadcasts: 37021
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 284.687
    learner_load_time_ms: 1.58
    learner_load_wait_time_ms: 1.627
iterations_since_restore: 140
node_ip: 127.0.0.1
num_agent_steps_sampled: 1878200
num_agent_steps_trained: 1861500
num_env_steps_sampled: 1878200
num_env_steps_sampled_this_iter: 13450
num_env_steps_sampled_throughput_per_sec: 1344.99393930782
num_env_steps_trained: 1861500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.993916777366
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 59.919999999999995
  ram_util_percent: 78.31333333333332
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058339456717716
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022828257220399488
  mean_inference_ms: 1.1151642694463513
  mean_raw_obs_processing_ms: 0.2549314586384118
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019235838027227493
    StateBufferConnector_ms: 0.003368740990048363
    ViewRequirementAgentConnector_ms: 0.11736733572823661
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.009523809523809525
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058339456717716
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022828257220399488
    mean_inference_ms: 1.1151642694463513
    mean_raw_obs_processing_ms: 0.2549314586384118
time_since_restore: 1418.0139849185944
time_this_iter_s: 10.085111856460571
time_total_s: 1418.0139849185944
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001249
timesteps_total: 1878200
training_iteration: 140
trial_id: default
train step: 141
agent_timesteps_total: 1891950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01908284481440749
  StateBufferConnector_ms: 0.0032957469191506644
  ViewRequirementAgentConnector_ms: 0.11435557748669777
counters:
  num_agent_steps_sampled: 1891950
  num_agent_steps_trained: 1875000
  num_env_steps_sampled: 1891950
  num_env_steps_trained: 1875000
  num_samples_added_to_queue: 1891500
  num_training_step_calls_since_last_synch_worker_weights: 219
  num_weight_broadcasts: 37293
custom_metrics: {}
date: 2023-08-14_17-21-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 1.0
episode_reward_mean: 0.028037383177570093
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 14781
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.121972680091858
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.6360206604003906
        total_loss: -2.917275905609131
        var_gnorm: 64.43667602539062
        vf_explained_var: 0.9853639602661133
        vf_loss: 2.113133430480957
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3750.0
  learner_queue:
    size_count: 3756
    size_mean: 15.56
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0983624174196784
  num_agent_steps_sampled: 1891950
  num_agent_steps_trained: 1875000
  num_env_steps_sampled: 1891950
  num_env_steps_trained: 1875000
  num_samples_added_to_queue: 1891500
  num_training_step_calls_since_last_synch_worker_weights: 219
  num_weight_broadcasts: 37293
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 191.238
    learner_load_time_ms: 1.666
    learner_load_wait_time_ms: 1.57
iterations_since_restore: 141
node_ip: 127.0.0.1
num_agent_steps_sampled: 1891950
num_agent_steps_trained: 1875000
num_env_steps_sampled: 1891950
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9979347021606
num_env_steps_trained: 1875000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9979722530304
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.55
  ram_util_percent: 76.99285714285715
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058357405381671244
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02281370566473565
  mean_inference_ms: 1.11495571949787
  mean_raw_obs_processing_ms: 0.25489700613394883
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01908284481440749
    StateBufferConnector_ms: 0.0032957469191506644
    ViewRequirementAgentConnector_ms: 0.11435557748669777
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 1.0
  episode_reward_mean: 0.028037383177570093
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058357405381671244
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02281370566473565
    mean_inference_ms: 1.11495571949787
    mean_raw_obs_processing_ms: 0.25489700613394883
time_since_restore: 1428.1664719581604
time_this_iter_s: 10.15248703956604
time_total_s: 1428.1664719581604
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692001260
timesteps_total: 1891950
training_iteration: 141
trial_id: default
train step: 142
agent_timesteps_total: 1905750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0183562437693278
  StateBufferConnector_ms: 0.0031848748524983725
  ViewRequirementAgentConnector_ms: 0.11265255786754468
counters:
  num_agent_steps_sampled: 1905750
  num_agent_steps_trained: 1889000
  num_env_steps_sampled: 1905750
  num_env_steps_trained: 1889000
  num_samples_added_to_queue: 1905500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 37566
custom_metrics: {}
date: 2023-08-14_17-21-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 3.0
episode_reward_mean: 0.5277777777777778
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 14889
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.41096830368042
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -11.72697925567627
        total_loss: -15.833550453186035
        var_gnorm: 64.42996978759766
        vf_explained_var: 0.9663284420967102
        vf_loss: 5.89654016494751
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3778.0
  learner_queue:
    size_count: 3781
    size_mean: 15.48
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.2039933554633928
  num_agent_steps_sampled: 1905750
  num_agent_steps_trained: 1889000
  num_env_steps_sampled: 1905750
  num_env_steps_trained: 1889000
  num_samples_added_to_queue: 1905500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 37566
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 280.373
    learner_load_time_ms: 1.672
    learner_load_wait_time_ms: 1.486
iterations_since_restore: 142
node_ip: 127.0.0.1
num_agent_steps_sampled: 1905750
num_agent_steps_trained: 1889000
num_env_steps_sampled: 1905750
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.8985713173063
num_env_steps_trained: 1889000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.8971013363976
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.56428571428571
  ram_util_percent: 77.02142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058342057504063766
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02280221148405556
  mean_inference_ms: 1.1147580421738992
  mean_raw_obs_processing_ms: 0.25484646326134325
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0183562437693278
    StateBufferConnector_ms: 0.0031848748524983725
    ViewRequirementAgentConnector_ms: 0.11265255786754468
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 3.0
  episode_reward_mean: 0.5277777777777778
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0,
      0.0, 2.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0,
      1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0,
      1.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0,
      0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 3.0,
      0.0, 1.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0, 2.0, 0.0, 1.0, 0.0, 0.0,
      1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058342057504063766
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02280221148405556
    mean_inference_ms: 1.1147580421738992
    mean_raw_obs_processing_ms: 0.25484646326134325
time_since_restore: 1438.2531781196594
time_this_iter_s: 10.086706161499023
time_total_s: 1438.2531781196594
timers:
  sample_time_ms: 0.037
  synch_weights_time_ms: 0.272
  training_iteration_time_ms: 0.373
timestamp: 1692001270
timesteps_total: 1905750
training_iteration: 142
trial_id: default
train step: 143
agent_timesteps_total: 1919500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018707028141728154
  StateBufferConnector_ms: 0.0032301302309389467
  ViewRequirementAgentConnector_ms: 0.11235718373899106
counters:
  num_agent_steps_sampled: 1919500
  num_agent_steps_trained: 1903000
  num_env_steps_sampled: 1919500
  num_env_steps_trained: 1903000
  num_samples_added_to_queue: 1919500
  num_training_step_calls_since_last_synch_worker_weights: 449
  num_weight_broadcasts: 37837
custom_metrics: {}
date: 2023-08-14_17-21-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.212962962962963
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 14997
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.3443456888198853
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.9560728073120117
        total_loss: -3.3712832927703857
        var_gnorm: 64.42748260498047
        vf_explained_var: 0.9795502424240112
        vf_loss: 2.7887444496154785
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3806.0
  learner_queue:
    size_count: 3811
    size_mean: 15.68
    size_quantiles: [12.0, 14.9, 16.0, 16.0, 16.0]
    size_std: 0.835224520712844
  num_agent_steps_sampled: 1919500
  num_agent_steps_trained: 1903000
  num_env_steps_sampled: 1919500
  num_env_steps_trained: 1903000
  num_samples_added_to_queue: 1919500
  num_training_step_calls_since_last_synch_worker_weights: 449
  num_weight_broadcasts: 37837
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 194.931
    learner_load_time_ms: 1.485
    learner_load_wait_time_ms: 1.59
iterations_since_restore: 143
node_ip: 127.0.0.1
num_agent_steps_sampled: 1919500
num_agent_steps_trained: 1903000
num_env_steps_sampled: 1919500
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9963939284485
num_env_steps_trained: 1903000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.996328363511
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 50.406666666666666
  ram_util_percent: 77.18
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058337187835224034
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022790711782954203
  mean_inference_ms: 1.1145376264743179
  mean_raw_obs_processing_ms: 0.25480004660595257
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018707028141728154
    StateBufferConnector_ms: 0.0032301302309389467
    ViewRequirementAgentConnector_ms: 0.11235718373899106
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.212962962962963
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 0.0, 2.0, 0.0, 3.0,
      3.0, 2.0, 2.0, 0.0, 0.0, 4.0, 4.0, 4.0, 3.0, 0.0, 3.0, 0.0, 3.0, 1.0, 1.0, 0.0,
      0.0, 2.0, 5.0, 2.0, 1.0, 0.0, 3.0, 0.0, 4.0, 1.0, 5.0, 1.0, 2.0, 3.0, 2.0, 2.0,
      4.0, 2.0, 3.0, 4.0, 5.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 2.0, 3.0, 0.0, 2.0, 2.0,
      1.0, 1.0, 0.0, 1.0, 3.0, 3.0, 4.0, 1.0, 2.0, 0.0, 4.0, 0.0, 2.0, 3.0, 2.0, 4.0,
      4.0, 3.0, 2.0, 2.0, 2.0, 7.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 2.0, 1.0, 5.0,
      3.0, 7.0, 2.0, 3.0, 1.0, 3.0, 5.0, 1.0, 1.0, 2.0, 3.0, 2.0, 1.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058337187835224034
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022790711782954203
    mean_inference_ms: 1.1145376264743179
    mean_raw_obs_processing_ms: 0.25480004660595257
time_since_restore: 1448.3842837810516
time_this_iter_s: 10.131105661392212
time_total_s: 1448.3842837810516
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692001280
timesteps_total: 1919500
training_iteration: 143
trial_id: default
train step: 144
agent_timesteps_total: 1933050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018936338878813245
  StateBufferConnector_ms: 0.003329685756138393
  ViewRequirementAgentConnector_ms: 0.11333897000267393
counters:
  num_agent_steps_sampled: 1933050
  num_agent_steps_trained: 1916500
  num_env_steps_sampled: 1933050
  num_env_steps_trained: 1916500
  num_samples_added_to_queue: 1933000
  num_training_step_calls_since_last_synch_worker_weights: 190
  num_weight_broadcasts: 38105
custom_metrics: {}
date: 2023-08-14_17-21-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.019047619047619
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 15102
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.242077112197876
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 20.129316329956055
        total_loss: 25.646804809570312
        var_gnorm: 64.435302734375
        vf_explained_var: 0.926214873790741
        vf_loss: 23.45574951171875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3833.0
  learner_queue:
    size_count: 3840
    size_mean: 15.22
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5269577597301114
  num_agent_steps_sampled: 1933050
  num_agent_steps_trained: 1916500
  num_env_steps_sampled: 1933050
  num_env_steps_trained: 1916500
  num_samples_added_to_queue: 1933000
  num_training_step_calls_since_last_synch_worker_weights: 190
  num_weight_broadcasts: 38105
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 138.562
    learner_load_time_ms: 1.473
    learner_load_wait_time_ms: 1.478
iterations_since_restore: 144
node_ip: 127.0.0.1
num_agent_steps_sampled: 1933050
num_agent_steps_trained: 1916500
num_env_steps_sampled: 1933050
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.998610855573
num_env_steps_trained: 1916500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9986159815671
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 46.057142857142864
  ram_util_percent: 76.63571428571429
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05834646435528461
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022780829189108235
  mean_inference_ms: 1.1144866629192567
  mean_raw_obs_processing_ms: 0.25477373426256017
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018936338878813245
    StateBufferConnector_ms: 0.003329685756138393
    ViewRequirementAgentConnector_ms: 0.11333897000267393
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.019047619047619
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 7.0, 2.0, 1.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 3.0, 0.0,
      4.0, 4.0, 1.0, 5.0, 2.0, 1.0, 7.0, 3.0, 2.0, 4.0, 1.0, 1.0, 3.0, 3.0, 3.0, 4.0,
      3.0, 5.0, 6.0, 1.0, 3.0, 5.0, 4.0, 5.0, 2.0, 4.0, 4.0, 9.0, 3.0, 5.0, 1.0, 3.0,
      2.0, 3.0, 3.0, 1.0, 5.0, 5.0, 1.0, 2.0, 0.0, 4.0, 5.0, 2.0, 2.0, 3.0, 1.0, 1.0,
      3.0, 4.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 4.0, 2.0, 4.0, 4.0, 6.0, 4.0, 5.0,
      3.0, 0.0, 3.0, 4.0, 4.0, 3.0, 2.0, 4.0, 3.0, 2.0, 5.0, 5.0, 2.0, 9.0, 4.0, 4.0,
      1.0, 0.0, 4.0, 2.0, 3.0, 2.0, 2.0, 7.0, 2.0, 4.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05834646435528461
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022780829189108235
    mean_inference_ms: 1.1144866629192567
    mean_raw_obs_processing_ms: 0.25477373426256017
time_since_restore: 1458.5553588867188
time_this_iter_s: 10.171075105667114
time_total_s: 1458.5553588867188
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1692001290
timesteps_total: 1933050
training_iteration: 144
trial_id: default
train step: 145
agent_timesteps_total: 1946950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018477439880371094
  StateBufferConnector_ms: 0.0031913092376988964
  ViewRequirementAgentConnector_ms: 0.11266174666378476
counters:
  num_agent_steps_sampled: 1946950
  num_agent_steps_trained: 1930000
  num_env_steps_sampled: 1946950
  num_env_steps_trained: 1930000
  num_samples_added_to_queue: 1946500
  num_training_step_calls_since_last_synch_worker_weights: 152
  num_weight_broadcasts: 38380
custom_metrics: {}
date: 2023-08-14_17-21-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.3944954128440368
episode_reward_min: 0.0
episodes_this_iter: 109
episodes_total: 15211
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8079304099082947
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 19.087675094604492
        total_loss: 37.546836853027344
        var_gnorm: 64.44252014160156
        vf_explained_var: 0.8774929046630859
        vf_loss: 44.99762725830078
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3860.0
  learner_queue:
    size_count: 3867
    size_mean: 14.94
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8483506160899235
  num_agent_steps_sampled: 1946950
  num_agent_steps_trained: 1930000
  num_env_steps_sampled: 1946950
  num_env_steps_trained: 1930000
  num_samples_added_to_queue: 1946500
  num_training_step_calls_since_last_synch_worker_weights: 152
  num_weight_broadcasts: 38380
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 156.094
    learner_load_time_ms: 1.445
    learner_load_wait_time_ms: 1.446
iterations_since_restore: 145
node_ip: 127.0.0.1
num_agent_steps_sampled: 1946950
num_agent_steps_trained: 1930000
num_env_steps_sampled: 1946950
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.999569177761
num_env_steps_trained: 1930000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9995815755233
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.642857142857146
  ram_util_percent: 76.87142857142855
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058317331764801465
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02277172110591421
  mean_inference_ms: 1.1142673765874693
  mean_raw_obs_processing_ms: 0.2547090702340738
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018477439880371094
    StateBufferConnector_ms: 0.0031913092376988964
    ViewRequirementAgentConnector_ms: 0.11266174666378476
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.3944954128440368
  episode_reward_min: 0.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [1.0, 1.0, 6.0, 5.0, 3.0, 2.0, 4.0, 3.0, 10.0, 4.0, 3.0, 1.0,
      2.0, 5.0, 4.0, 5.0, 6.0, 1.0, 3.0, 4.0, 4.0, 7.0, 3.0, 3.0, 5.0, 3.0, 5.0, 5.0,
      3.0, 2.0, 5.0, 4.0, 3.0, 4.0, 2.0, 5.0, 5.0, 5.0, 3.0, 4.0, 4.0, 2.0, 1.0, 0.0,
      4.0, 2.0, 2.0, 0.0, 2.0, 5.0, 5.0, 1.0, 0.0, 2.0, 0.0, 4.0, 4.0, 4.0, 3.0, 2.0,
      2.0, 3.0, 4.0, 2.0, 5.0, 2.0, 5.0, 4.0, 3.0, 5.0, 3.0, 4.0, 2.0, 1.0, 4.0, 3.0,
      4.0, 6.0, 5.0, 5.0, 6.0, 7.0, 3.0, 4.0, 1.0, 5.0, 5.0, 4.0, 3.0, 6.0, 2.0, 5.0,
      2.0, 1.0, 4.0, 6.0, 1.0, 4.0, 4.0, 1.0, 1.0, 5.0, 4.0, 5.0, 1.0, 1.0, 2.0, 2.0,
      3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058317331764801465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02277172110591421
    mean_inference_ms: 1.1142673765874693
    mean_raw_obs_processing_ms: 0.2547090702340738
time_since_restore: 1468.714992761612
time_this_iter_s: 10.159633874893188
time_total_s: 1468.714992761612
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1692001300
timesteps_total: 1946950
training_iteration: 145
trial_id: default
train step: 146
agent_timesteps_total: 1960750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01876442520706742
  StateBufferConnector_ms: 0.0032431549496120876
  ViewRequirementAgentConnector_ms: 0.11319253179762098
counters:
  num_agent_steps_sampled: 1960750
  num_agent_steps_trained: 1944000
  num_env_steps_sampled: 1960750
  num_env_steps_trained: 1944000
  num_samples_added_to_queue: 1960500
  num_training_step_calls_since_last_synch_worker_weights: 46
  num_weight_broadcasts: 38653
custom_metrics: {}
date: 2023-08-14_17-21-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.6296296296296298
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 15319
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 1.1048249006271362
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -35.309120178222656
        total_loss: -27.754901885986328
        var_gnorm: 64.44782257080078
        vf_explained_var: 0.9297133088111877
        vf_loss: 26.15668487548828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3888.0
  learner_queue:
    size_count: 3895
    size_mean: 14.98
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7831432920547916
  num_agent_steps_sampled: 1960750
  num_agent_steps_trained: 1944000
  num_env_steps_sampled: 1960750
  num_env_steps_trained: 1944000
  num_samples_added_to_queue: 1960500
  num_training_step_calls_since_last_synch_worker_weights: 46
  num_weight_broadcasts: 38653
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 142.167
    learner_load_time_ms: 1.382
    learner_load_wait_time_ms: 1.666
iterations_since_restore: 146
node_ip: 127.0.0.1
num_agent_steps_sampled: 1960750
num_agent_steps_trained: 1944000
num_env_steps_sampled: 1960750
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9950318515346
num_env_steps_trained: 1944000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.994959849383
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 52.69285714285714
  ram_util_percent: 76.75714285714287
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05832445626485314
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022761376888993306
  mean_inference_ms: 1.114079105834823
  mean_raw_obs_processing_ms: 0.2546689260115261
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01876442520706742
    StateBufferConnector_ms: 0.0032431549496120876
    ViewRequirementAgentConnector_ms: 0.11319253179762098
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.6296296296296298
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 4.0, 3.0, 7.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 2.0, 2.0,
      6.0, 2.0, 4.0, 4.0, 1.0, 5.0, 4.0, 3.0, 1.0, 4.0, 6.0, 1.0, 2.0, 5.0, 6.0, 6.0,
      6.0, 3.0, 7.0, 4.0, 6.0, 3.0, 5.0, 6.0, 4.0, 1.0, 5.0, 6.0, 1.0, 4.0, 4.0, 3.0,
      3.0, 5.0, 3.0, 2.0, 6.0, 3.0, 7.0, 6.0, 6.0, 2.0, 0.0, 0.0, 2.0, 2.0, 4.0, 1.0,
      2.0, 1.0, 3.0, 4.0, 0.0, 2.0, 5.0, 3.0, 2.0, 4.0, 6.0, 1.0, 2.0, 3.0, 8.0, 2.0,
      0.0, 5.0, 1.0, 4.0, 6.0, 4.0, 5.0, 6.0, 0.0, 7.0, 7.0, 4.0, 2.0, 5.0, 5.0, 4.0,
      2.0, 6.0, 6.0, 1.0, 2.0, 3.0, 4.0, 2.0, 4.0, 5.0, 6.0, 3.0, 3.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05832445626485314
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022761376888993306
    mean_inference_ms: 1.114079105834823
    mean_raw_obs_processing_ms: 0.2546689260115261
time_since_restore: 1478.894960641861
time_this_iter_s: 10.179967880249023
time_total_s: 1478.894960641861
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001310
timesteps_total: 1960750
training_iteration: 146
trial_id: default
train step: 147
agent_timesteps_total: 1974500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018826823368250766
  StateBufferConnector_ms: 0.0032110749004043153
  ViewRequirementAgentConnector_ms: 0.11427759010101034
counters:
  num_agent_steps_sampled: 1974500
  num_agent_steps_trained: 1958000
  num_env_steps_sampled: 1974500
  num_env_steps_trained: 1958000
  num_samples_added_to_queue: 1974500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 38923
custom_metrics: {}
date: 2023-08-14_17-22-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 5.981308411214953
episode_reward_min: 1.0
episodes_this_iter: 107
episodes_total: 15426
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.834875226020813
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.400970697402954
        total_loss: 15.230470657348633
        var_gnorm: 64.4629898071289
        vf_explained_var: 0.9146192073822021
        vf_loss: 34.00775146484375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3916.0
  learner_queue:
    size_count: 3920
    size_mean: 15.26
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.520657752421629
  num_agent_steps_sampled: 1974500
  num_agent_steps_trained: 1958000
  num_env_steps_sampled: 1974500
  num_env_steps_trained: 1958000
  num_samples_added_to_queue: 1974500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 38923
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 226.242
    learner_load_time_ms: 1.374
    learner_load_wait_time_ms: 1.516
iterations_since_restore: 147
node_ip: 127.0.0.1
num_agent_steps_sampled: 1974500
num_agent_steps_trained: 1958000
num_env_steps_sampled: 1974500
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1373.6078245967958
num_env_steps_trained: 1958000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1398.5825123167376
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 47.22
  ram_util_percent: 76.64000000000001
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05833049778289993
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02275246509645466
  mean_inference_ms: 1.1138938954509228
  mean_raw_obs_processing_ms: 0.2546333775322701
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018826823368250766
    StateBufferConnector_ms: 0.0032110749004043153
    ViewRequirementAgentConnector_ms: 0.11427759010101034
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 5.981308411214953
  episode_reward_min: 1.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 9.0, 6.0, 8.0, 4.0, 8.0, 11.0, 3.0, 3.0, 6.0, 5.0, 7.0,
      6.0, 2.0, 1.0, 6.0, 3.0, 12.0, 7.0, 5.0, 2.0, 3.0, 2.0, 3.0, 7.0, 4.0, 2.0,
      6.0, 7.0, 6.0, 5.0, 8.0, 11.0, 5.0, 15.0, 8.0, 7.0, 4.0, 11.0, 4.0, 4.0, 8.0,
      7.0, 7.0, 5.0, 5.0, 8.0, 8.0, 7.0, 6.0, 12.0, 2.0, 6.0, 4.0, 6.0, 6.0, 4.0,
      8.0, 2.0, 3.0, 6.0, 4.0, 2.0, 6.0, 10.0, 3.0, 5.0, 4.0, 3.0, 5.0, 8.0, 4.0,
      9.0, 6.0, 8.0, 9.0, 3.0, 1.0, 3.0, 13.0, 6.0, 4.0, 8.0, 7.0, 10.0, 3.0, 7.0,
      4.0, 2.0, 3.0, 7.0, 6.0, 9.0, 4.0, 1.0, 4.0, 8.0, 8.0, 8.0, 10.0, 6.0, 7.0,
      7.0, 6.0, 9.0, 9.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05833049778289993
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02275246509645466
    mean_inference_ms: 1.1138938954509228
    mean_raw_obs_processing_ms: 0.2546333775322701
time_since_restore: 1489.0081865787506
time_this_iter_s: 10.113225936889648
time_total_s: 1489.0081865787506
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.27
  training_iteration_time_ms: 2.188
timestamp: 1692001321
timesteps_total: 1974500
training_iteration: 147
trial_id: default
train step: 148
agent_timesteps_total: 1988300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01879488980328595
  StateBufferConnector_ms: 0.0032475701084843387
  ViewRequirementAgentConnector_ms: 0.11304661079689309
counters:
  num_agent_steps_sampled: 1988300
  num_agent_steps_trained: 1971500
  num_env_steps_sampled: 1988300
  num_env_steps_trained: 1971500
  num_samples_added_to_queue: 1988000
  num_training_step_calls_since_last_synch_worker_weights: 443
  num_weight_broadcasts: 39197
custom_metrics: {}
date: 2023-08-14_17-22-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.86111111111111
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 15534
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.8794377446174622
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -83.45777893066406
        total_loss: -38.367698669433594
        var_gnorm: 64.46678924560547
        vf_explained_var: 0.8072389960289001
        vf_loss: 98.97454071044922
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3943.0
  learner_queue:
    size_count: 3950
    size_mean: 15.42
    size_quantiles: [10.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.3577923257994944
  num_agent_steps_sampled: 1988300
  num_agent_steps_trained: 1971500
  num_env_steps_sampled: 1988300
  num_env_steps_trained: 1971500
  num_samples_added_to_queue: 1988000
  num_training_step_calls_since_last_synch_worker_weights: 443
  num_weight_broadcasts: 39197
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 148.36
    learner_load_time_ms: 1.369
    learner_load_wait_time_ms: 1.468
iterations_since_restore: 148
node_ip: 127.0.0.1
num_agent_steps_sampled: 1988300
num_agent_steps_trained: 1971500
num_env_steps_sampled: 1988300
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.997236257366
num_env_steps_trained: 1971500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9972963387277
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 47.74285714285713
  ram_util_percent: 76.89285714285714
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058316245603651715
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02274826601014273
  mean_inference_ms: 1.1137026295773989
  mean_raw_obs_processing_ms: 0.25459117693568306
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01879488980328595
    StateBufferConnector_ms: 0.0032475701084843387
    ViewRequirementAgentConnector_ms: 0.11304661079689309
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.86111111111111
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 11.0, 9.0, 8.0, 10.0, 7.0, 6.0, 7.0, 8.0, 11.0, 10.0, 11.0,
      12.0, 5.0, 10.0, 6.0, 3.0, 10.0, 11.0, 9.0, 10.0, 6.0, 12.0, 5.0, 7.0, 7.0,
      7.0, 13.0, 13.0, 9.0, 10.0, 13.0, 13.0, 11.0, 12.0, 13.0, 3.0, 7.0, 10.0, 2.0,
      9.0, 8.0, 8.0, 10.0, 11.0, 4.0, 12.0, 7.0, 7.0, 9.0, 9.0, 13.0, 7.0, 12.0, 10.0,
      7.0, 8.0, 12.0, 7.0, 9.0, 10.0, 7.0, 11.0, 9.0, 11.0, 6.0, 10.0, 6.0, 7.0, 8.0,
      5.0, 11.0, 10.0, 10.0, 14.0, 7.0, 12.0, 8.0, 12.0, 8.0, 8.0, 12.0, 11.0, 8.0,
      4.0, 14.0, 7.0, 4.0, 14.0, 2.0, 12.0, 10.0, 8.0, 7.0, 7.0, 11.0, 8.0, 13.0,
      10.0, 9.0, 9.0, 8.0, 8.0, 8.0, 5.0, 5.0, 5.0, 12.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058316245603651715
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02274826601014273
    mean_inference_ms: 1.1137026295773989
    mean_raw_obs_processing_ms: 0.25459117693568306
time_since_restore: 1499.17169880867
time_this_iter_s: 10.163512229919434
time_total_s: 1499.17169880867
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001331
timesteps_total: 1988300
training_iteration: 148
trial_id: default
train step: 149
agent_timesteps_total: 2002150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019060020093564636
  StateBufferConnector_ms: 0.003231013262713397
  ViewRequirementAgentConnector_ms: 0.11403891775343153
counters:
  num_agent_steps_sampled: 2002150
  num_agent_steps_trained: 1985500
  num_env_steps_sampled: 2002150
  num_env_steps_trained: 1985500
  num_samples_added_to_queue: 2002000
  num_training_step_calls_since_last_synch_worker_weights: 226
  num_weight_broadcasts: 39471
custom_metrics: {}
date: 2023-08-14_17-22-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.157407407407407
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 15642
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7967658042907715
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -29.65023422241211
        total_loss: 40.34199523925781
        var_gnorm: 64.47050476074219
        vf_explained_var: 0.7548699975013733
        vf_loss: 147.95211791992188
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3971.0
  learner_queue:
    size_count: 3977
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.632666530556684
  num_agent_steps_sampled: 2002150
  num_agent_steps_trained: 1985500
  num_env_steps_sampled: 2002150
  num_env_steps_trained: 1985500
  num_samples_added_to_queue: 2002000
  num_training_step_calls_since_last_synch_worker_weights: 226
  num_weight_broadcasts: 39471
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 163.757
    learner_load_time_ms: 7.51
    learner_load_wait_time_ms: 1.568
iterations_since_restore: 149
node_ip: 127.0.0.1
num_agent_steps_sampled: 2002150
num_agent_steps_trained: 1985500
num_env_steps_sampled: 2002150
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.9968630146507
num_env_steps_trained: 1985500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.99682904008
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.40714285714285
  ram_util_percent: 76.57142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05831227940715363
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02274252632370221
  mean_inference_ms: 1.1135020891586727
  mean_raw_obs_processing_ms: 0.2545492394485688
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019060020093564636
    StateBufferConnector_ms: 0.003231013262713397
    ViewRequirementAgentConnector_ms: 0.11403891775343153
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.157407407407407
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 6.0, 10.0, 8.0, 7.0, 8.0, 8.0, 5.0, 7.0, 10.0, 6.0, 10.0,
      8.0, 9.0, 4.0, 13.0, 9.0, 10.0, 12.0, 7.0, 11.0, 11.0, 14.0, 12.0, 6.0, 10.0,
      4.0, 8.0, 5.0, 7.0, 7.0, 11.0, 8.0, 3.0, 9.0, 4.0, 11.0, 10.0, 7.0, 4.0, 10.0,
      9.0, 9.0, 8.0, 10.0, 6.0, 11.0, 10.0, 9.0, 8.0, 11.0, 9.0, 9.0, 8.0, 9.0, 8.0,
      10.0, 5.0, 10.0, 10.0, 9.0, 11.0, 10.0, 6.0, 9.0, 6.0, 5.0, 6.0, 8.0, 5.0, 10.0,
      7.0, 3.0, 14.0, 9.0, 9.0, 11.0, 9.0, 6.0, 4.0, 9.0, 7.0, 9.0, 9.0, 6.0, 8.0,
      7.0, 5.0, 6.0, 5.0, 9.0, 14.0, 10.0, 8.0, 9.0, 12.0, 6.0, 8.0, 7.0, 7.0, 11.0,
      6.0, 7.0, 8.0, 6.0, 10.0, 6.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05831227940715363
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02274252632370221
    mean_inference_ms: 1.1135020891586727
    mean_raw_obs_processing_ms: 0.2545492394485688
time_since_restore: 1509.3360300064087
time_this_iter_s: 10.164331197738647
time_total_s: 1509.3360300064087
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692001341
timesteps_total: 2002150
training_iteration: 149
trial_id: default
train step: 150
agent_timesteps_total: 2016000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01902337427492495
  StateBufferConnector_ms: 0.0033226278093126086
  ViewRequirementAgentConnector_ms: 0.1141859425438775
counters:
  num_agent_steps_sampled: 2016000
  num_agent_steps_trained: 1999500
  num_env_steps_sampled: 2016000
  num_env_steps_trained: 1999500
  num_samples_added_to_queue: 2016000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 39745
custom_metrics: {}
date: 2023-08-14_17-22-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.064814814814815
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 15750
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7991988658905029
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 16.468063354492188
        total_loss: 132.28860473632812
        var_gnorm: 64.47537994384766
        vf_explained_var: 0.7167209982872009
        vf_loss: 239.633056640625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3999.0
  learner_queue:
    size_count: 4005
    size_mean: 15.16
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5538339679644027
  num_agent_steps_sampled: 2016000
  num_agent_steps_trained: 1999500
  num_env_steps_sampled: 2016000
  num_env_steps_trained: 1999500
  num_samples_added_to_queue: 2016000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 39745
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 153.584
    learner_load_time_ms: 7.538
    learner_load_wait_time_ms: 1.444
iterations_since_restore: 150
node_ip: 127.0.0.1
num_agent_steps_sampled: 2016000
num_agent_steps_trained: 1999500
num_env_steps_sampled: 2016000
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1383.7088629300954
num_env_steps_trained: 1999500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1398.6948794961252
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 45.521428571428565
  ram_util_percent: 76.18571428571428
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058326979929395686
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022733871151365583
  mean_inference_ms: 1.1132557182872107
  mean_raw_obs_processing_ms: 0.2545117378247702
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01902337427492495
    StateBufferConnector_ms: 0.0033226278093126086
    ViewRequirementAgentConnector_ms: 0.1141859425438775
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.064814814814815
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 9.0, 8.0, 3.0, 7.0, 5.0, 10.0, 4.0, 9.0, 15.0, 8.0, 11.0,
      13.0, 7.0, 4.0, 10.0, 10.0, 5.0, 8.0, 6.0, 8.0, 4.0, 10.0, 10.0, 9.0, 14.0,
      9.0, 6.0, 10.0, 8.0, 9.0, 11.0, 7.0, 7.0, 8.0, 7.0, 5.0, 8.0, 8.0, 11.0, 8.0,
      16.0, 8.0, 6.0, 5.0, 6.0, 10.0, 6.0, 4.0, 11.0, 7.0, 4.0, 8.0, 13.0, 10.0, 3.0,
      10.0, 8.0, 5.0, 10.0, 4.0, 9.0, 6.0, 2.0, 7.0, 6.0, 11.0, 8.0, 7.0, 3.0, 9.0,
      7.0, 5.0, 9.0, 6.0, 6.0, 7.0, 7.0, 14.0, 15.0, 7.0, 10.0, 8.0, 13.0, 6.0, 8.0,
      6.0, 6.0, 10.0, 10.0, 5.0, 6.0, 7.0, 5.0, 13.0, 8.0, 11.0, 4.0, 8.0, 8.0, 11.0,
      10.0, 6.0, 12.0, 11.0, 8.0, 9.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058326979929395686
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022733871151365583
    mean_inference_ms: 1.1132557182872107
    mean_raw_obs_processing_ms: 0.2545117378247702
time_since_restore: 1519.48997092247
time_this_iter_s: 10.153940916061401
time_total_s: 1519.48997092247
timers:
  sample_time_ms: 0.074
  synch_weights_time_ms: 0.547
  training_iteration_time_ms: 2.359
timestamp: 1692001351
timesteps_total: 2016000
training_iteration: 150
trial_id: default
train step: 151
agent_timesteps_total: 2029900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01861086679161142
  StateBufferConnector_ms: 0.003203339532974663
  ViewRequirementAgentConnector_ms: 0.11179359681015714
counters:
  num_agent_steps_sampled: 2029900
  num_agent_steps_trained: 2013000
  num_env_steps_sampled: 2029900
  num_env_steps_trained: 2013000
  num_samples_added_to_queue: 2029500
  num_training_step_calls_since_last_synch_worker_weights: 737
  num_weight_broadcasts: 40021
custom_metrics: {}
date: 2023-08-14_17-22-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.100917431192661
episode_reward_min: 3.0
episodes_this_iter: 109
episodes_total: 15859
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.812110185623169
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 57.654701232910156
        total_loss: 127.81195068359375
        var_gnorm: 64.4773941040039
        vf_explained_var: 0.8051666021347046
        vf_loss: 148.4355926513672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4026.0
  learner_queue:
    size_count: 4031
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 2029900
  num_agent_steps_trained: 2013000
  num_env_steps_sampled: 2029900
  num_env_steps_trained: 2013000
  num_samples_added_to_queue: 2029500
  num_training_step_calls_since_last_synch_worker_weights: 737
  num_weight_broadcasts: 40021
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 217.206
    learner_load_time_ms: 7.534
    learner_load_wait_time_ms: 1.446
iterations_since_restore: 151
node_ip: 127.0.0.1
num_agent_steps_sampled: 2029900
num_agent_steps_trained: 2013000
num_env_steps_sampled: 2029900
num_env_steps_sampled_this_iter: 13900
num_env_steps_sampled_throughput_per_sec: 1389.9973156504018
num_env_steps_trained: 2013000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9973928978723
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.53333333333333
  ram_util_percent: 76.44666666666667
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05829069736475609
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022729355671299717
  mean_inference_ms: 1.11303552006419
  mean_raw_obs_processing_ms: 0.2544547985946292
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01861086679161142
    StateBufferConnector_ms: 0.003203339532974663
    ViewRequirementAgentConnector_ms: 0.11179359681015714
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.100917431192661
  episode_reward_min: 3.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [10.0, 11.0, 9.0, 10.0, 10.0, 8.0, 9.0, 5.0, 6.0, 9.0, 11.0, 10.0,
      10.0, 11.0, 7.0, 11.0, 4.0, 7.0, 8.0, 9.0, 4.0, 13.0, 7.0, 5.0, 8.0, 9.0, 5.0,
      7.0, 8.0, 6.0, 7.0, 3.0, 5.0, 10.0, 14.0, 13.0, 4.0, 6.0, 7.0, 5.0, 13.0, 5.0,
      8.0, 4.0, 8.0, 13.0, 7.0, 7.0, 11.0, 4.0, 11.0, 8.0, 7.0, 7.0, 11.0, 10.0, 9.0,
      8.0, 5.0, 9.0, 9.0, 9.0, 4.0, 5.0, 9.0, 10.0, 8.0, 7.0, 7.0, 10.0, 10.0, 9.0,
      10.0, 8.0, 9.0, 12.0, 7.0, 6.0, 5.0, 6.0, 10.0, 7.0, 9.0, 6.0, 7.0, 6.0, 7.0,
      14.0, 8.0, 9.0, 10.0, 6.0, 5.0, 10.0, 9.0, 10.0, 4.0, 6.0, 11.0, 9.0, 9.0, 8.0,
      7.0, 4.0, 9.0, 9.0, 7.0, 16.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05829069736475609
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022729355671299717
    mean_inference_ms: 1.11303552006419
    mean_raw_obs_processing_ms: 0.2544547985946292
time_since_restore: 1529.6212470531464
time_this_iter_s: 10.13127613067627
time_total_s: 1529.6212470531464
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001361
timesteps_total: 2029900
training_iteration: 151
trial_id: default
train step: 152
agent_timesteps_total: 2043750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01887903300994033
  StateBufferConnector_ms: 0.003296300905560135
  ViewRequirementAgentConnector_ms: 0.11410997548234572
counters:
  num_agent_steps_sampled: 2043750
  num_agent_steps_trained: 2027000
  num_env_steps_sampled: 2043750
  num_env_steps_trained: 2027000
  num_samples_added_to_queue: 2043500
  num_training_step_calls_since_last_synch_worker_weights: 227
  num_weight_broadcasts: 40295
custom_metrics: {}
date: 2023-08-14_17-22-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 7.6422018348623855
episode_reward_min: 3.0
episodes_this_iter: 109
episodes_total: 15968
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7093445062637329
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.262786865234375
        total_loss: 25.980083465576172
        var_gnorm: 64.48125457763672
        vf_explained_var: 0.8965613842010498
        vf_loss: 97.57918548583984
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4054.0
  learner_queue:
    size_count: 4060
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3098091464026353
  num_agent_steps_sampled: 2043750
  num_agent_steps_trained: 2027000
  num_env_steps_sampled: 2043750
  num_env_steps_trained: 2027000
  num_samples_added_to_queue: 2043500
  num_training_step_calls_since_last_synch_worker_weights: 227
  num_weight_broadcasts: 40295
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 170.279
    learner_load_time_ms: 7.915
    learner_load_wait_time_ms: 1.418
iterations_since_restore: 152
node_ip: 127.0.0.1
num_agent_steps_sampled: 2043750
num_agent_steps_trained: 2027000
num_env_steps_sampled: 2043750
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.9969950979578
num_env_steps_trained: 2027000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9969625538922
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 45.95
  ram_util_percent: 76.7642857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05830539019598259
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022721070067588035
  mean_inference_ms: 1.1127867445094184
  mean_raw_obs_processing_ms: 0.2544094177654428
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01887903300994033
    StateBufferConnector_ms: 0.003296300905560135
    ViewRequirementAgentConnector_ms: 0.11410997548234572
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 7.6422018348623855
  episode_reward_min: 3.0
  episodes_this_iter: 109
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [7.0, 4.0, 12.0, 11.0, 10.0, 12.0, 9.0, 9.0, 12.0, 7.0, 8.0, 4.0,
      12.0, 4.0, 3.0, 6.0, 4.0, 12.0, 7.0, 12.0, 9.0, 9.0, 7.0, 7.0, 11.0, 3.0, 6.0,
      9.0, 7.0, 9.0, 7.0, 8.0, 7.0, 8.0, 6.0, 6.0, 7.0, 9.0, 17.0, 10.0, 6.0, 7.0,
      9.0, 7.0, 5.0, 6.0, 3.0, 10.0, 8.0, 7.0, 5.0, 6.0, 6.0, 8.0, 12.0, 9.0, 5.0,
      9.0, 9.0, 8.0, 11.0, 7.0, 7.0, 6.0, 8.0, 8.0, 4.0, 4.0, 8.0, 14.0, 8.0, 6.0,
      5.0, 12.0, 6.0, 7.0, 7.0, 11.0, 12.0, 4.0, 7.0, 11.0, 7.0, 9.0, 6.0, 5.0, 6.0,
      5.0, 9.0, 9.0, 7.0, 6.0, 5.0, 12.0, 10.0, 10.0, 4.0, 7.0, 4.0, 3.0, 10.0, 7.0,
      9.0, 3.0, 8.0, 4.0, 8.0, 8.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05830539019598259
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022721070067588035
    mean_inference_ms: 1.1127867445094184
    mean_raw_obs_processing_ms: 0.2544094177654428
time_since_restore: 1539.7750880718231
time_this_iter_s: 10.153841018676758
time_total_s: 1539.7750880718231
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001371
timesteps_total: 2043750
training_iteration: 152
trial_id: default
train step: 153
agent_timesteps_total: 2057700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018756036405210143
  StateBufferConnector_ms: 0.00323211705243146
  ViewRequirementAgentConnector_ms: 0.11302188590720848
counters:
  num_agent_steps_sampled: 2057700
  num_agent_steps_trained: 2041000
  num_env_steps_sampled: 2057700
  num_env_steps_trained: 2041000
  num_samples_added_to_queue: 2057500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 40569
custom_metrics: {}
date: 2023-08-14_17-23-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.0
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 16076
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6637876033782959
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -15.683152198791504
        total_loss: 10.577751159667969
        var_gnorm: 64.48714447021484
        vf_explained_var: 0.9242133498191833
        vf_loss: 59.15968322753906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4082.0
  learner_queue:
    size_count: 4087
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.40356688476182
  num_agent_steps_sampled: 2057700
  num_agent_steps_trained: 2041000
  num_env_steps_sampled: 2057700
  num_env_steps_trained: 2041000
  num_samples_added_to_queue: 2057500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 40569
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 201.641
    learner_load_time_ms: 8.127
    learner_load_wait_time_ms: 1.533
iterations_since_restore: 153
node_ip: 127.0.0.1
num_agent_steps_sampled: 2057700
num_agent_steps_trained: 2041000
num_env_steps_sampled: 2057700
num_env_steps_sampled_this_iter: 13950
num_env_steps_sampled_throughput_per_sec: 1394.631649746516
num_env_steps_trained: 2041000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.6303294947113
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.85714285714285
  ram_util_percent: 76.88571428571427
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05828894488487423
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02271462791512411
  mean_inference_ms: 1.1125473977823732
  mean_raw_obs_processing_ms: 0.25435460531027804
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018756036405210143
    StateBufferConnector_ms: 0.00323211705243146
    ViewRequirementAgentConnector_ms: 0.11302188590720848
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.0
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 10.0, 6.0, 10.0, 11.0, 7.0, 13.0, 13.0, 10.0, 9.0, 7.0,
      5.0, 7.0, 6.0, 13.0, 5.0, 7.0, 8.0, 11.0, 11.0, 8.0, 8.0, 9.0, 7.0, 4.0, 6.0,
      7.0, 8.0, 6.0, 5.0, 7.0, 4.0, 6.0, 10.0, 7.0, 5.0, 2.0, 8.0, 6.0, 2.0, 10.0,
      13.0, 5.0, 8.0, 4.0, 8.0, 8.0, 6.0, 4.0, 3.0, 7.0, 7.0, 11.0, 7.0, 4.0, 8.0,
      4.0, 9.0, 5.0, 8.0, 5.0, 4.0, 8.0, 6.0, 6.0, 3.0, 7.0, 9.0, 10.0, 7.0, 7.0,
      8.0, 7.0, 7.0, 7.0, 8.0, 5.0, 7.0, 11.0, 2.0, 10.0, 6.0, 7.0, 12.0, 4.0, 6.0,
      2.0, 9.0, 9.0, 3.0, 12.0, 6.0, 5.0, 7.0, 11.0, 4.0, 7.0, 7.0, 5.0, 3.0, 2.0,
      4.0, 10.0, 4.0, 7.0, 9.0, 5.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05828894488487423
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02271462791512411
    mean_inference_ms: 1.1125473977823732
    mean_raw_obs_processing_ms: 0.25435460531027804
time_since_restore: 1549.8951880931854
time_this_iter_s: 10.120100021362305
time_total_s: 1549.8951880931854
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.266
  training_iteration_time_ms: 0.373
timestamp: 1692001382
timesteps_total: 2057700
training_iteration: 153
trial_id: default
train step: 154
agent_timesteps_total: 2071300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019042068552748065
  StateBufferConnector_ms: 0.003300648983393874
  ViewRequirementAgentConnector_ms: 0.11447656934506426
counters:
  num_agent_steps_sampled: 2071300
  num_agent_steps_trained: 2054500
  num_env_steps_sampled: 2071300
  num_env_steps_trained: 2054500
  num_samples_added_to_queue: 2071000
  num_training_step_calls_since_last_synch_worker_weights: 1040
  num_weight_broadcasts: 40839
custom_metrics: {}
date: 2023-08-14_17-23-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.4953271028037385
episode_reward_min: 0.0
episodes_this_iter: 107
episodes_total: 16183
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7316713333129883
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -8.147687911987305
        total_loss: 61.321746826171875
        var_gnorm: 64.4932632446289
        vf_explained_var: 0.8172891736030579
        vf_loss: 146.25558471679688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4109.0
  learner_queue:
    size_count: 4113
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9591663046625439
  num_agent_steps_sampled: 2071300
  num_agent_steps_trained: 2054500
  num_env_steps_sampled: 2071300
  num_env_steps_trained: 2054500
  num_samples_added_to_queue: 2071000
  num_training_step_calls_since_last_synch_worker_weights: 1040
  num_weight_broadcasts: 40839
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 251.183
    learner_load_time_ms: 1.973
    learner_load_wait_time_ms: 1.657
iterations_since_restore: 154
node_ip: 127.0.0.1
num_agent_steps_sampled: 2071300
num_agent_steps_trained: 2054500
num_env_steps_sampled: 2071300
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.994422935468
num_env_steps_trained: 2054500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9944639432956
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 60.307142857142864
  ram_util_percent: 77.07857142857144
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05829996620481233
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02270930448649479
  mean_inference_ms: 1.1123940769751128
  mean_raw_obs_processing_ms: 0.2543337597979997
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019042068552748065
    StateBufferConnector_ms: 0.003300648983393874
    ViewRequirementAgentConnector_ms: 0.11447656934506426
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.4953271028037385
  episode_reward_min: 0.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 6.0, 7.0, 8.0, 8.0, 11.0, 9.0, 9.0, 9.0, 9.0, 7.0,
      6.0, 11.0, 9.0, 13.0, 5.0, 6.0, 7.0, 7.0, 11.0, 2.0, 7.0, 9.0, 6.0, 9.0, 7.0,
      11.0, 10.0, 7.0, 10.0, 11.0, 7.0, 10.0, 7.0, 4.0, 8.0, 8.0, 9.0, 7.0, 7.0, 5.0,
      4.0, 9.0, 9.0, 13.0, 8.0, 7.0, 4.0, 8.0, 7.0, 7.0, 7.0, 0.0, 5.0, 4.0, 4.0,
      7.0, 10.0, 8.0, 6.0, 6.0, 7.0, 6.0, 9.0, 9.0, 6.0, 5.0, 7.0, 7.0, 8.0, 4.0,
      9.0, 6.0, 14.0, 10.0, 8.0, 12.0, 9.0, 4.0, 9.0, 10.0, 10.0, 5.0, 11.0, 9.0,
      10.0, 7.0, 6.0, 6.0, 2.0, 4.0, 7.0, 8.0, 5.0, 6.0, 7.0, 7.0, 7.0, 8.0, 10.0,
      2.0, 9.0, 10.0, 8.0, 5.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05829996620481233
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02270930448649479
    mean_inference_ms: 1.1123940769751128
    mean_raw_obs_processing_ms: 0.2543337597979997
time_since_restore: 1559.9961080551147
time_this_iter_s: 10.100919961929321
time_total_s: 1559.9961080551147
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1692001392
timesteps_total: 2071300
training_iteration: 154
trial_id: default
train step: 155
agent_timesteps_total: 2085050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018881860180435892
  StateBufferConnector_ms: 0.003283046116338712
  ViewRequirementAgentConnector_ms: 0.11477158448406469
counters:
  num_agent_steps_sampled: 2085050
  num_agent_steps_trained: 2068500
  num_env_steps_sampled: 2085050
  num_env_steps_trained: 2068500
  num_samples_added_to_queue: 2085000
  num_training_step_calls_since_last_synch_worker_weights: 321
  num_weight_broadcasts: 41111
custom_metrics: {}
date: 2023-08-14_17-23-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.878504672897196
episode_reward_min: 1.0
episodes_this_iter: 107
episodes_total: 16290
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.37094566226005554
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 20.750503540039062
        total_loss: 43.74626922607422
        var_gnorm: 64.4984359741211
        vf_explained_var: 0.9280115962028503
        vf_loss: 49.70098876953125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4137.0
  learner_queue:
    size_count: 4142
    size_mean: 15.64
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9112628599915613
  num_agent_steps_sampled: 2085050
  num_agent_steps_trained: 2068500
  num_env_steps_sampled: 2085050
  num_env_steps_trained: 2068500
  num_samples_added_to_queue: 2085000
  num_training_step_calls_since_last_synch_worker_weights: 321
  num_weight_broadcasts: 41111
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 192.328
    learner_load_time_ms: 1.972
    learner_load_wait_time_ms: 1.603
iterations_since_restore: 155
node_ip: 127.0.0.1
num_agent_steps_sampled: 2085050
num_agent_steps_trained: 2068500
num_env_steps_sampled: 2085050
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.998492004141
num_env_steps_trained: 2068500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9984645860345
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 57.53333333333334
  ram_util_percent: 77.1
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058299005592054275
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022703673552451495
  mean_inference_ms: 1.112233232326178
  mean_raw_obs_processing_ms: 0.25430440128663495
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018881860180435892
    StateBufferConnector_ms: 0.003283046116338712
    ViewRequirementAgentConnector_ms: 0.11477158448406469
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.878504672897196
  episode_reward_min: 1.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 9.0, 4.0, 11.0, 9.0, 10.0, 11.0, 6.0, 6.0, 9.0, 10.0, 9.0,
      13.0, 3.0, 6.0, 6.0, 9.0, 9.0, 11.0, 6.0, 10.0, 8.0, 7.0, 6.0, 6.0, 4.0, 10.0,
      11.0, 12.0, 3.0, 12.0, 7.0, 6.0, 4.0, 4.0, 8.0, 7.0, 10.0, 9.0, 10.0, 8.0, 5.0,
      5.0, 11.0, 1.0, 7.0, 4.0, 8.0, 13.0, 7.0, 7.0, 9.0, 7.0, 5.0, 9.0, 10.0, 7.0,
      6.0, 3.0, 11.0, 8.0, 9.0, 7.0, 8.0, 5.0, 8.0, 6.0, 1.0, 7.0, 4.0, 6.0, 4.0,
      7.0, 10.0, 3.0, 7.0, 10.0, 7.0, 11.0, 8.0, 4.0, 7.0, 6.0, 12.0, 6.0, 4.0, 6.0,
      5.0, 4.0, 9.0, 3.0, 9.0, 4.0, 6.0, 3.0, 5.0, 2.0, 1.0, 2.0, 3.0, 6.0, 4.0, 4.0,
      7.0, 5.0, 3.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058299005592054275
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022703673552451495
    mean_inference_ms: 1.112233232326178
    mean_raw_obs_processing_ms: 0.25430440128663495
time_since_restore: 1570.1323809623718
time_this_iter_s: 10.13627290725708
time_total_s: 1570.1323809623718
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1692001402
timesteps_total: 2085050
training_iteration: 155
trial_id: default
train step: 156
agent_timesteps_total: 2098800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018822926062124747
  StateBufferConnector_ms: 0.0032831121374059607
  ViewRequirementAgentConnector_ms: 0.11385303956490976
counters:
  num_agent_steps_sampled: 2098800
  num_agent_steps_trained: 2082000
  num_env_steps_sampled: 2098800
  num_env_steps_trained: 2082000
  num_samples_added_to_queue: 2098500
  num_training_step_calls_since_last_synch_worker_weights: 436
  num_weight_broadcasts: 41383
custom_metrics: {}
date: 2023-08-14_17-23-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 5.398148148148148
episode_reward_min: 1.0
episodes_this_iter: 108
episodes_total: 16398
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4375334680080414
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.60676383972168
        total_loss: 19.176820755004883
        var_gnorm: 64.50434875488281
        vf_explained_var: 0.8668951988220215
        vf_loss: 63.9425048828125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4164.0
  learner_queue:
    size_count: 4169
    size_mean: 15.44
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.1859173664298874
  num_agent_steps_sampled: 2098800
  num_agent_steps_trained: 2082000
  num_env_steps_sampled: 2098800
  num_env_steps_trained: 2082000
  num_samples_added_to_queue: 2098500
  num_training_step_calls_since_last_synch_worker_weights: 436
  num_weight_broadcasts: 41383
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 209.155
    learner_load_time_ms: 2.032
    learner_load_wait_time_ms: 1.47
iterations_since_restore: 156
node_ip: 127.0.0.1
num_agent_steps_sampled: 2098800
num_agent_steps_trained: 2082000
num_env_steps_sampled: 2098800
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9953121106712
num_env_steps_trained: 2082000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9953973450226
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 58.07857142857143
  ram_util_percent: 77.05714285714286
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05828876172784035
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022698224436312527
  mean_inference_ms: 1.1120990226156426
  mean_raw_obs_processing_ms: 0.2542750541062051
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018822926062124747
    StateBufferConnector_ms: 0.0032831121374059607
    ViewRequirementAgentConnector_ms: 0.11385303956490976
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 5.398148148148148
  episode_reward_min: 1.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 5.0, 6.0, 10.0, 4.0, 10.0, 3.0, 5.0, 8.0, 3.0, 2.0, 10.0,
      5.0, 7.0, 8.0, 8.0, 8.0, 7.0, 3.0, 4.0, 1.0, 4.0, 7.0, 5.0, 4.0, 5.0, 3.0, 4.0,
      3.0, 6.0, 8.0, 3.0, 3.0, 5.0, 3.0, 5.0, 6.0, 7.0, 5.0, 5.0, 5.0, 3.0, 9.0, 4.0,
      3.0, 2.0, 5.0, 8.0, 6.0, 3.0, 6.0, 8.0, 7.0, 3.0, 9.0, 5.0, 5.0, 4.0, 6.0, 4.0,
      6.0, 8.0, 7.0, 4.0, 3.0, 5.0, 10.0, 5.0, 4.0, 6.0, 10.0, 3.0, 7.0, 7.0, 4.0,
      6.0, 6.0, 8.0, 6.0, 5.0, 5.0, 3.0, 4.0, 4.0, 7.0, 4.0, 10.0, 5.0, 6.0, 7.0,
      5.0, 6.0, 5.0, 2.0, 5.0, 2.0, 4.0, 6.0, 5.0, 9.0, 6.0, 6.0, 6.0, 4.0, 5.0, 4.0,
      3.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05828876172784035
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022698224436312527
    mean_inference_ms: 1.1120990226156426
    mean_raw_obs_processing_ms: 0.2542750541062051
time_since_restore: 1580.264070034027
time_this_iter_s: 10.131689071655273
time_total_s: 1580.264070034027
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001412
timesteps_total: 2098800
training_iteration: 156
trial_id: default
train step: 157
agent_timesteps_total: 2112450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018978118896484375
  StateBufferConnector_ms: 0.0033635013508346847
  ViewRequirementAgentConnector_ms: 0.11458644327127708
counters:
  num_agent_steps_sampled: 2112450
  num_agent_steps_trained: 2095500
  num_env_steps_sampled: 2112450
  num_env_steps_trained: 2095500
  num_samples_added_to_queue: 2112000
  num_training_step_calls_since_last_synch_worker_weights: 554
  num_weight_broadcasts: 41653
custom_metrics: {}
date: 2023-08-14_17-23-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.59433962264151
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 16504
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4917495846748352
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.1215155124664307
        total_loss: 31.045608520507812
        var_gnorm: 64.51040649414062
        vf_explained_var: 0.8606525659561157
        vf_loss: 64.76567840576172
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4191.0
  learner_queue:
    size_count: 4197
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 2112450
  num_agent_steps_trained: 2095500
  num_env_steps_sampled: 2112450
  num_env_steps_trained: 2095500
  num_samples_added_to_queue: 2112000
  num_training_step_calls_since_last_synch_worker_weights: 554
  num_weight_broadcasts: 41653
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 192.02
    learner_load_time_ms: 1.642
    learner_load_wait_time_ms: 1.499
iterations_since_restore: 157
node_ip: 127.0.0.1
num_agent_steps_sampled: 2112450
num_agent_steps_trained: 2095500
num_env_steps_sampled: 2112450
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1364.9989260443554
num_env_steps_trained: 2095500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9989378460657
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 45.33571428571429
  ram_util_percent: 77.16428571428573
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05828806935273833
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02269239719737683
  mean_inference_ms: 1.1120245037955012
  mean_raw_obs_processing_ms: 0.25424871487001044
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018978118896484375
    StateBufferConnector_ms: 0.0033635013508346847
    ViewRequirementAgentConnector_ms: 0.11458644327127708
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.59433962264151
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 2.0, 7.0, 7.0, 6.0, 8.0, 4.0, 4.0, 9.0, 5.0, 7.0, 3.0, 5.0,
      6.0, 5.0, 8.0, 4.0, 6.0, 6.0, 2.0, 3.0, 3.0, 8.0, 3.0, 3.0, 1.0, 4.0, 7.0, 4.0,
      3.0, 5.0, 3.0, 4.0, 2.0, 4.0, 2.0, 3.0, 2.0, 5.0, 7.0, 4.0, 7.0, 7.0, 6.0, 5.0,
      0.0, 1.0, 3.0, 4.0, 3.0, 2.0, 3.0, 8.0, 6.0, 3.0, 6.0, 3.0, 1.0, 4.0, 3.0, 7.0,
      5.0, 4.0, 8.0, 3.0, 5.0, 5.0, 3.0, 2.0, 4.0, 7.0, 7.0, 5.0, 5.0, 2.0, 5.0, 5.0,
      6.0, 4.0, 6.0, 5.0, 6.0, 4.0, 5.0, 3.0, 4.0, 2.0, 7.0, 9.0, 3.0, 4.0, 2.0, 5.0,
      4.0, 1.0, 9.0, 6.0, 7.0, 6.0, 5.0, 9.0, 1.0, 5.0, 5.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05828806935273833
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02269239719737683
    mean_inference_ms: 1.1120245037955012
    mean_raw_obs_processing_ms: 0.25424871487001044
time_since_restore: 1590.4123392105103
time_this_iter_s: 10.148269176483154
time_total_s: 1590.4123392105103
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001422
timesteps_total: 2112450
training_iteration: 157
trial_id: default
train step: 158
agent_timesteps_total: 2126250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018871934325606736
  StateBufferConnector_ms: 0.0032716327243381077
  ViewRequirementAgentConnector_ms: 0.11291062390362774
counters:
  num_agent_steps_sampled: 2126250
  num_agent_steps_trained: 2109500
  num_env_steps_sampled: 2126250
  num_env_steps_trained: 2109500
  num_samples_added_to_queue: 2126000
  num_training_step_calls_since_last_synch_worker_weights: 399
  num_weight_broadcasts: 41925
custom_metrics: {}
date: 2023-08-14_17-23-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.314814814814815
episode_reward_min: 2.0
episodes_this_iter: 108
episodes_total: 16612
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.48042067885398865
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 7.934028148651123
        total_loss: 12.56814193725586
        var_gnorm: 64.51447296142578
        vf_explained_var: 0.9667866826057434
        vf_loss: 14.072434425354004
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4219.0
  learner_queue:
    size_count: 4224
    size_mean: 15.36
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3078226179417451
  num_agent_steps_sampled: 2126250
  num_agent_steps_trained: 2109500
  num_env_steps_sampled: 2126250
  num_env_steps_trained: 2109500
  num_samples_added_to_queue: 2126000
  num_training_step_calls_since_last_synch_worker_weights: 399
  num_weight_broadcasts: 41925
  timing_breakdown:
    learner_dequeue_time_ms: 0.004
    learner_grad_time_ms: 206.266
    learner_load_time_ms: 1.408
    learner_load_wait_time_ms: 1.653
iterations_since_restore: 158
node_ip: 127.0.0.1
num_agent_steps_sampled: 2126250
num_agent_steps_trained: 2109500
num_env_steps_sampled: 2126250
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9941106093931
num_env_steps_trained: 2109500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.994025255906
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.79333333333334
  ram_util_percent: 77.13333333333335
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05828436732017834
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022685436113056796
  mean_inference_ms: 1.1118405963241111
  mean_raw_obs_processing_ms: 0.2542160800684592
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018871934325606736
    StateBufferConnector_ms: 0.0032716327243381077
    ViewRequirementAgentConnector_ms: 0.11291062390362774
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.314814814814815
  episode_reward_min: 2.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 8.0, 11.0, 5.0, 4.0, 6.0, 8.0, 6.0, 4.0, 6.0, 6.0, 7.0,
      6.0, 4.0, 6.0, 9.0, 4.0, 4.0, 6.0, 5.0, 5.0, 6.0, 5.0, 6.0, 4.0, 7.0, 5.0, 8.0,
      6.0, 12.0, 6.0, 7.0, 6.0, 3.0, 5.0, 8.0, 8.0, 5.0, 9.0, 4.0, 9.0, 8.0, 8.0,
      8.0, 7.0, 6.0, 4.0, 6.0, 6.0, 8.0, 7.0, 10.0, 8.0, 4.0, 5.0, 6.0, 5.0, 7.0,
      9.0, 5.0, 5.0, 9.0, 8.0, 12.0, 7.0, 5.0, 10.0, 6.0, 8.0, 6.0, 5.0, 6.0, 4.0,
      5.0, 11.0, 9.0, 4.0, 7.0, 8.0, 5.0, 6.0, 6.0, 7.0, 3.0, 6.0, 2.0, 6.0, 4.0,
      6.0, 6.0, 2.0, 10.0, 4.0, 8.0, 7.0, 5.0, 6.0, 4.0, 7.0, 5.0, 8.0, 4.0, 11.0,
      5.0, 4.0, 7.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05828436732017834
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022685436113056796
    mean_inference_ms: 1.1118405963241111
    mean_raw_obs_processing_ms: 0.2542160800684592
time_since_restore: 1600.5416324138641
time_this_iter_s: 10.129293203353882
time_total_s: 1600.5416324138641
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001432
timesteps_total: 2126250
training_iteration: 158
trial_id: default
train step: 159
agent_timesteps_total: 2139950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018680207083158405
  StateBufferConnector_ms: 0.003269008386914975
  ViewRequirementAgentConnector_ms: 0.11324726532552844
counters:
  num_agent_steps_sampled: 2139950
  num_agent_steps_trained: 2123000
  num_env_steps_sampled: 2139950
  num_env_steps_trained: 2123000
  num_samples_added_to_queue: 2139500
  num_training_step_calls_since_last_synch_worker_weights: 245
  num_weight_broadcasts: 42193
custom_metrics: {}
date: 2023-08-14_17-24-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.05607476635514
episode_reward_min: 1.0
episodes_this_iter: 107
episodes_total: 16719
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5414736866950989
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.5650620460510254
        total_loss: 13.310400009155273
        var_gnorm: 64.52397155761719
        vf_explained_var: 0.9262359142303467
        vf_loss: 30.905414581298828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4246.0
  learner_queue:
    size_count: 4252
    size_mean: 15.28
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4005713120009275
  num_agent_steps_sampled: 2139950
  num_agent_steps_trained: 2123000
  num_env_steps_sampled: 2139950
  num_env_steps_trained: 2123000
  num_samples_added_to_queue: 2139500
  num_training_step_calls_since_last_synch_worker_weights: 245
  num_weight_broadcasts: 42193
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 186.305
    learner_load_time_ms: 1.407
    learner_load_wait_time_ms: 1.528
iterations_since_restore: 159
node_ip: 127.0.0.1
num_agent_steps_sampled: 2139950
num_agent_steps_trained: 2123000
num_env_steps_sampled: 2139950
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9936633403138
num_env_steps_trained: 2123000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9937558462946
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 41.82857142857143
  ram_util_percent: 77.07142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058290710439397174
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022678185300581886
  mean_inference_ms: 1.1116657114641335
  mean_raw_obs_processing_ms: 0.2541845123442171
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018680207083158405
    StateBufferConnector_ms: 0.003269008386914975
    ViewRequirementAgentConnector_ms: 0.11324726532552844
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.05607476635514
  episode_reward_min: 1.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 9.0, 9.0, 7.0, 8.0, 2.0, 7.0, 3.0, 5.0, 7.0, 8.0, 4.0,
      10.0, 6.0, 9.0, 5.0, 6.0, 8.0, 8.0, 5.0, 5.0, 8.0, 5.0, 12.0, 12.0, 10.0, 10.0,
      8.0, 5.0, 9.0, 12.0, 12.0, 7.0, 9.0, 11.0, 8.0, 6.0, 6.0, 2.0, 6.0, 8.0, 9.0,
      10.0, 8.0, 11.0, 8.0, 6.0, 13.0, 12.0, 9.0, 9.0, 11.0, 4.0, 4.0, 6.0, 8.0, 2.0,
      6.0, 7.0, 5.0, 4.0, 8.0, 2.0, 1.0, 10.0, 6.0, 4.0, 8.0, 4.0, 8.0, 6.0, 5.0,
      10.0, 4.0, 5.0, 2.0, 7.0, 10.0, 10.0, 4.0, 5.0, 6.0, 9.0, 10.0, 2.0, 11.0, 2.0,
      3.0, 10.0, 6.0, 11.0, 5.0, 5.0, 7.0, 7.0, 8.0, 8.0, 8.0, 7.0, 9.0, 9.0, 6.0,
      7.0, 10.0, 9.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058290710439397174
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022678185300581886
    mean_inference_ms: 1.1116657114641335
    mean_raw_obs_processing_ms: 0.2541845123442171
time_since_restore: 1610.6838200092316
time_this_iter_s: 10.142187595367432
time_total_s: 1610.6838200092316
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001442
timesteps_total: 2139950
training_iteration: 159
trial_id: default
train step: 160
agent_timesteps_total: 2153750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01863174968295627
  StateBufferConnector_ms: 0.003219975365532769
  ViewRequirementAgentConnector_ms: 0.11250685762476038
counters:
  num_agent_steps_sampled: 2153750
  num_agent_steps_trained: 2137000
  num_env_steps_sampled: 2153750
  num_env_steps_trained: 2137000
  num_samples_added_to_queue: 2153500
  num_training_step_calls_since_last_synch_worker_weights: 938
  num_weight_broadcasts: 42465
custom_metrics: {}
date: 2023-08-14_17-24-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.555555555555555
episode_reward_min: 4.0
episodes_this_iter: 108
episodes_total: 16827
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6894773840904236
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -21.15522003173828
        total_loss: 32.551544189453125
        var_gnorm: 64.52851867675781
        vf_explained_var: 0.7759956121444702
        vf_loss: 114.30830383300781
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4274.0
  learner_queue:
    size_count: 4278
    size_mean: 15.48
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1702991070662234
  num_agent_steps_sampled: 2153750
  num_agent_steps_trained: 2137000
  num_env_steps_sampled: 2153750
  num_env_steps_trained: 2137000
  num_samples_added_to_queue: 2153500
  num_training_step_calls_since_last_synch_worker_weights: 938
  num_weight_broadcasts: 42465
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 245.489
    learner_load_time_ms: 1.404
    learner_load_wait_time_ms: 1.584
iterations_since_restore: 160
node_ip: 127.0.0.1
num_agent_steps_sampled: 2153750
num_agent_steps_trained: 2137000
num_env_steps_sampled: 2153750
num_env_steps_sampled_this_iter: 13800
num_env_steps_sampled_throughput_per_sec: 1379.9978284869985
num_env_steps_trained: 2137000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9977970157956
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 46.271428571428565
  ram_util_percent: 76.90714285714284
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058276189073296
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02267334088938455
  mean_inference_ms: 1.1114946656107016
  mean_raw_obs_processing_ms: 0.2541444616293063
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01863174968295627
    StateBufferConnector_ms: 0.003219975365532769
    ViewRequirementAgentConnector_ms: 0.11250685762476038
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.555555555555555
  episode_reward_min: 4.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 9.0, 14.0, 9.0, 6.0, 7.0, 7.0, 8.0, 14.0, 5.0, 9.0, 9.0,
      6.0, 5.0, 8.0, 13.0, 8.0, 10.0, 9.0, 8.0, 11.0, 9.0, 7.0, 9.0, 10.0, 9.0, 9.0,
      9.0, 7.0, 8.0, 9.0, 11.0, 11.0, 5.0, 8.0, 11.0, 5.0, 9.0, 8.0, 11.0, 7.0, 9.0,
      4.0, 10.0, 11.0, 10.0, 9.0, 10.0, 4.0, 7.0, 10.0, 9.0, 14.0, 8.0, 9.0, 8.0,
      11.0, 9.0, 8.0, 5.0, 6.0, 14.0, 7.0, 8.0, 9.0, 8.0, 8.0, 5.0, 5.0, 10.0, 8.0,
      10.0, 5.0, 10.0, 8.0, 9.0, 6.0, 11.0, 5.0, 15.0, 12.0, 14.0, 8.0, 8.0, 5.0,
      12.0, 8.0, 7.0, 10.0, 10.0, 7.0, 8.0, 7.0, 8.0, 8.0, 7.0, 8.0, 9.0, 8.0, 9.0,
      9.0, 9.0, 8.0, 11.0, 6.0, 9.0, 8.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058276189073296
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02267334088938455
    mean_inference_ms: 1.1114946656107016
    mean_raw_obs_processing_ms: 0.2541444616293063
time_since_restore: 1620.7872080802917
time_this_iter_s: 10.10338807106018
time_total_s: 1620.7872080802917
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001452
timesteps_total: 2153750
training_iteration: 160
trial_id: default
train step: 161
agent_timesteps_total: 2167450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018909489997079438
  StateBufferConnector_ms: 0.0032768071254837177
  ViewRequirementAgentConnector_ms: 0.114360256729839
counters:
  num_agent_steps_sampled: 2167450
  num_agent_steps_trained: 2150500
  num_env_steps_sampled: 2167450
  num_env_steps_trained: 2150500
  num_samples_added_to_queue: 2167000
  num_training_step_calls_since_last_synch_worker_weights: 229
  num_weight_broadcasts: 42736
custom_metrics: {}
date: 2023-08-14_17-24-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.953271028037383
episode_reward_min: 2.0
episodes_this_iter: 107
episodes_total: 16934
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6208993792533875
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 26.20677947998047
        total_loss: 67.239013671875
        var_gnorm: 64.52906799316406
        vf_explained_var: 0.8416372537612915
        vf_loss: 88.27346801757812
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4301.0
  learner_queue:
    size_count: 4307
    size_mean: 15.5
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1532562594670797
  num_agent_steps_sampled: 2167450
  num_agent_steps_trained: 2150500
  num_env_steps_sampled: 2167450
  num_env_steps_trained: 2150500
  num_samples_added_to_queue: 2167000
  num_training_step_calls_since_last_synch_worker_weights: 229
  num_weight_broadcasts: 42736
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 194.133
    learner_load_time_ms: 1.354
    learner_load_wait_time_ms: 1.489
iterations_since_restore: 161
node_ip: 127.0.0.1
num_agent_steps_sampled: 2167450
num_agent_steps_trained: 2150500
num_env_steps_sampled: 2167450
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.995492473174
num_env_steps_trained: 2150500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9955582764853
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 41.25
  ram_util_percent: 76.91428571428571
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058264673246145635
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022669950706137632
  mean_inference_ms: 1.111406176304551
  mean_raw_obs_processing_ms: 0.2541085393588388
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018909489997079438
    StateBufferConnector_ms: 0.0032768071254837177
    ViewRequirementAgentConnector_ms: 0.114360256729839
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.953271028037383
  episode_reward_min: 2.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 10.0, 5.0, 8.0, 9.0, 10.0, 7.0, 12.0, 5.0, 11.0, 9.0, 12.0,
      4.0, 11.0, 14.0, 5.0, 7.0, 11.0, 5.0, 14.0, 9.0, 8.0, 8.0, 5.0, 8.0, 7.0, 8.0,
      8.0, 4.0, 9.0, 10.0, 4.0, 6.0, 4.0, 8.0, 9.0, 4.0, 7.0, 8.0, 9.0, 10.0, 4.0,
      3.0, 7.0, 10.0, 7.0, 6.0, 5.0, 9.0, 6.0, 4.0, 13.0, 9.0, 12.0, 9.0, 8.0, 7.0,
      10.0, 8.0, 7.0, 11.0, 9.0, 9.0, 9.0, 13.0, 12.0, 8.0, 8.0, 8.0, 3.0, 6.0, 6.0,
      8.0, 8.0, 7.0, 9.0, 6.0, 9.0, 6.0, 12.0, 7.0, 12.0, 5.0, 12.0, 13.0, 7.0, 12.0,
      5.0, 10.0, 4.0, 8.0, 9.0, 7.0, 7.0, 9.0, 4.0, 4.0, 7.0, 8.0, 13.0, 5.0, 10.0,
      5.0, 9.0, 5.0, 9.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058264673246145635
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022669950706137632
    mean_inference_ms: 1.111406176304551
    mean_raw_obs_processing_ms: 0.2541085393588388
time_since_restore: 1630.9273719787598
time_this_iter_s: 10.140163898468018
time_total_s: 1630.9273719787598
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001463
timesteps_total: 2167450
training_iteration: 161
trial_id: default
train step: 162
agent_timesteps_total: 2181200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018497270958445895
  StateBufferConnector_ms: 0.0032081782260787823
  ViewRequirementAgentConnector_ms: 0.11293353321396302
counters:
  num_agent_steps_sampled: 2181200
  num_agent_steps_trained: 2164500
  num_env_steps_sampled: 2181200
  num_env_steps_trained: 2164500
  num_samples_added_to_queue: 2181000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 43008
custom_metrics: {}
date: 2023-08-14_17-24-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.345794392523365
episode_reward_min: 1.0
episodes_this_iter: 107
episodes_total: 17041
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6448203921318054
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.104310989379883
        total_loss: 32.635494232177734
        var_gnorm: 64.52986907958984
        vf_explained_var: 0.8250150680541992
        vf_loss: 109.92781829833984
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4329.0
  learner_queue:
    size_count: 4334
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2631706139710503
  num_agent_steps_sampled: 2181200
  num_agent_steps_trained: 2164500
  num_env_steps_sampled: 2181200
  num_env_steps_trained: 2164500
  num_samples_added_to_queue: 2181000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 43008
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 208.454
    learner_load_time_ms: 1.344
    learner_load_wait_time_ms: 1.596
iterations_since_restore: 162
node_ip: 127.0.0.1
num_agent_steps_sampled: 2181200
num_agent_steps_trained: 2164500
num_env_steps_sampled: 2181200
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9921650140896
num_env_steps_trained: 2164500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9920225598003
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 49.771428571428565
  ram_util_percent: 77.1
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0582801451002377
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022663909900621095
  mean_inference_ms: 1.1112315606022856
  mean_raw_obs_processing_ms: 0.2540782780193901
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018497270958445895
    StateBufferConnector_ms: 0.0032081782260787823
    ViewRequirementAgentConnector_ms: 0.11293353321396302
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.345794392523365
  episode_reward_min: 1.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 12.0, 8.0, 7.0, 7.0, 11.0, 10.0, 8.0, 6.0, 12.0, 5.0, 7.0,
      11.0, 12.0, 10.0, 11.0, 10.0, 9.0, 8.0, 11.0, 3.0, 8.0, 7.0, 3.0, 7.0, 9.0,
      7.0, 8.0, 7.0, 8.0, 4.0, 8.0, 14.0, 10.0, 10.0, 8.0, 10.0, 13.0, 7.0, 1.0, 9.0,
      8.0, 7.0, 12.0, 7.0, 3.0, 9.0, 11.0, 6.0, 9.0, 15.0, 6.0, 6.0, 8.0, 8.0, 7.0,
      9.0, 13.0, 9.0, 8.0, 13.0, 15.0, 8.0, 11.0, 5.0, 10.0, 6.0, 7.0, 9.0, 9.0, 10.0,
      11.0, 2.0, 13.0, 8.0, 7.0, 8.0, 11.0, 10.0, 4.0, 8.0, 7.0, 9.0, 10.0, 8.0, 7.0,
      8.0, 11.0, 14.0, 8.0, 9.0, 8.0, 5.0, 8.0, 9.0, 3.0, 6.0, 5.0, 9.0, 5.0, 11.0,
      6.0, 10.0, 8.0, 4.0, 8.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0582801451002377
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022663909900621095
    mean_inference_ms: 1.1112315606022856
    mean_raw_obs_processing_ms: 0.2540782780193901
time_since_restore: 1641.0548787117004
time_this_iter_s: 10.127506732940674
time_total_s: 1641.0548787117004
timers:
  sample_time_ms: 0.039
  synch_weights_time_ms: 0.263
  training_iteration_time_ms: 0.366
timestamp: 1692001473
timesteps_total: 2181200
training_iteration: 162
trial_id: default
train step: 163
agent_timesteps_total: 2194650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01930327642531622
  StateBufferConnector_ms: 0.0033380871727353052
  ViewRequirementAgentConnector_ms: 0.11725403013683501
counters:
  num_agent_steps_sampled: 2194650
  num_agent_steps_trained: 2178000
  num_env_steps_sampled: 2194650
  num_env_steps_trained: 2178000
  num_samples_added_to_queue: 2194500
  num_training_step_calls_since_last_synch_worker_weights: 144
  num_weight_broadcasts: 43275
custom_metrics: {}
date: 2023-08-14_17-24-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.961904761904762
episode_reward_min: 2.0
episodes_this_iter: 105
episodes_total: 17146
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6179002523422241
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -26.28426742553711
        total_loss: 21.20047378540039
        var_gnorm: 64.53999328613281
        vf_explained_var: 0.8494606018066406
        vf_loss: 101.14848327636719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4356.0
  learner_queue:
    size_count: 4362
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3358143583597235
  num_agent_steps_sampled: 2194650
  num_agent_steps_trained: 2178000
  num_env_steps_sampled: 2194650
  num_env_steps_trained: 2178000
  num_samples_added_to_queue: 2194500
  num_training_step_calls_since_last_synch_worker_weights: 144
  num_weight_broadcasts: 43275
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 166.06
    learner_load_time_ms: 7.069
    learner_load_wait_time_ms: 1.574
iterations_since_restore: 163
node_ip: 127.0.0.1
num_agent_steps_sampled: 2194650
num_agent_steps_trained: 2178000
num_env_steps_sampled: 2194650
num_env_steps_sampled_this_iter: 13450
num_env_steps_sampled_throughput_per_sec: 1344.9919511561457
num_env_steps_trained: 2178000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.991921234793
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 57.58
  ram_util_percent: 80.49333333333334
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05826751680782153
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022665450710044836
  mean_inference_ms: 1.1112741876435903
  mean_raw_obs_processing_ms: 0.254080690955931
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01930327642531622
    StateBufferConnector_ms: 0.0033380871727353052
    ViewRequirementAgentConnector_ms: 0.11725403013683501
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.961904761904762
  episode_reward_min: 2.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 9.0, 10.0, 5.0, 10.0, 9.0, 10.0, 10.0, 7.0, 7.0, 10.0, 15.0,
      7.0, 13.0, 9.0, 6.0, 5.0, 10.0, 9.0, 5.0, 13.0, 8.0, 11.0, 6.0, 5.0, 3.0, 11.0,
      10.0, 8.0, 9.0, 10.0, 9.0, 8.0, 7.0, 6.0, 9.0, 5.0, 8.0, 12.0, 6.0, 4.0, 14.0,
      9.0, 12.0, 10.0, 14.0, 12.0, 16.0, 6.0, 10.0, 12.0, 10.0, 7.0, 2.0, 8.0, 6.0,
      9.0, 9.0, 7.0, 11.0, 7.0, 3.0, 6.0, 8.0, 9.0, 6.0, 15.0, 11.0, 8.0, 11.0, 8.0,
      11.0, 14.0, 13.0, 5.0, 10.0, 9.0, 4.0, 10.0, 12.0, 4.0, 4.0, 11.0, 8.0, 12.0,
      10.0, 12.0, 13.0, 6.0, 10.0, 11.0, 4.0, 10.0, 10.0, 9.0, 13.0, 12.0, 8.0, 11.0,
      7.0, 13.0, 11.0, 10.0, 6.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05826751680782153
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022665450710044836
    mean_inference_ms: 1.1112741876435903
    mean_raw_obs_processing_ms: 0.254080690955931
time_since_restore: 1651.2054347991943
time_this_iter_s: 10.150556087493896
time_total_s: 1651.2054347991943
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1692001483
timesteps_total: 2194650
training_iteration: 163
trial_id: default
train step: 164
agent_timesteps_total: 2208350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01904563369037949
  StateBufferConnector_ms: 0.003239373180353753
  ViewRequirementAgentConnector_ms: 0.11443022255585572
counters:
  num_agent_steps_sampled: 2208350
  num_agent_steps_trained: 2191500
  num_env_steps_sampled: 2208350
  num_env_steps_trained: 2191500
  num_samples_added_to_queue: 2208000
  num_training_step_calls_since_last_synch_worker_weights: 78
  num_weight_broadcasts: 43545
custom_metrics: {}
date: 2023-08-14_17-24-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 9.214953271028037
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 17253
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6253842115402222
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -36.3658447265625
        total_loss: 102.48518371582031
        var_gnorm: 64.5491714477539
        vf_explained_var: 0.75870680809021
        vf_loss: 283.9559020996094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4383.0
  learner_queue:
    size_count: 4389
    size_mean: 15.18
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5190786681406594
  num_agent_steps_sampled: 2208350
  num_agent_steps_trained: 2191500
  num_env_steps_sampled: 2208350
  num_env_steps_trained: 2191500
  num_samples_added_to_queue: 2208000
  num_training_step_calls_since_last_synch_worker_weights: 78
  num_weight_broadcasts: 43545
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 184.522
    learner_load_time_ms: 7.096
    learner_load_wait_time_ms: 1.576
iterations_since_restore: 164
node_ip: 127.0.0.1
num_agent_steps_sampled: 2208350
num_agent_steps_trained: 2191500
num_env_steps_sampled: 2208350
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9988894471587
num_env_steps_trained: 2191500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.998905659609
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 57.6
  ram_util_percent: 75.90714285714286
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05828466960837385
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022659972507521022
  mean_inference_ms: 1.111106591424362
  mean_raw_obs_processing_ms: 0.2540626108230646
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01904563369037949
    StateBufferConnector_ms: 0.003239373180353753
    ViewRequirementAgentConnector_ms: 0.11443022255585572
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 9.214953271028037
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 8.0, 8.0, 9.0, 8.0, 5.0, 8.0, 4.0, 3.0, 8.0, 8.0, 9.0,
      6.0, 7.0, 8.0, 11.0, 7.0, 7.0, 9.0, 6.0, 7.0, 9.0, 7.0, 9.0, 8.0, 8.0, 9.0,
      14.0, 10.0, 10.0, 6.0, 5.0, 10.0, 12.0, 7.0, 11.0, 11.0, 5.0, 12.0, 5.0, 10.0,
      10.0, 13.0, 8.0, 11.0, 8.0, 10.0, 9.0, 6.0, 8.0, 6.0, 12.0, 13.0, 7.0, 11.0,
      10.0, 8.0, 8.0, 11.0, 6.0, 7.0, 9.0, 6.0, 12.0, 10.0, 13.0, 11.0, 13.0, 9.0,
      11.0, 8.0, 7.0, 8.0, 7.0, 7.0, 15.0, 14.0, 8.0, 14.0, 7.0, 9.0, 11.0, 13.0,
      10.0, 8.0, 9.0, 10.0, 9.0, 9.0, 11.0, 13.0, 13.0, 9.0, 10.0, 11.0, 7.0, 10.0,
      12.0, 8.0, 14.0, 12.0, 10.0, 13.0, 12.0, 12.0, 5.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05828466960837385
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022659972507521022
    mean_inference_ms: 1.111106591424362
    mean_raw_obs_processing_ms: 0.2540626108230646
time_since_restore: 1661.3520858287811
time_this_iter_s: 10.146651029586792
time_total_s: 1661.3520858287811
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001493
timesteps_total: 2208350
training_iteration: 164
trial_id: default
train step: 165
agent_timesteps_total: 2222000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018972325547833308
  StateBufferConnector_ms: 0.003274578914464077
  ViewRequirementAgentConnector_ms: 0.11477581808500201
counters:
  num_agent_steps_sampled: 2222000
  num_agent_steps_trained: 2205500
  num_env_steps_sampled: 2222000
  num_env_steps_trained: 2205500
  num_samples_added_to_queue: 2222000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 43815
custom_metrics: {}
date: 2023-08-14_17-25-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 17.0
episode_reward_mean: 8.88785046728972
episode_reward_min: 2.0
episodes_this_iter: 107
episodes_total: 17360
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6430854201316833
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 38.747291564941406
        total_loss: 143.88949584960938
        var_gnorm: 64.55743408203125
        vf_explained_var: 0.8021932244300842
        vf_loss: 216.71524047851562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4411.0
  learner_queue:
    size_count: 4413
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3892443989449805
  num_agent_steps_sampled: 2222000
  num_agent_steps_trained: 2205500
  num_env_steps_sampled: 2222000
  num_env_steps_trained: 2205500
  num_samples_added_to_queue: 2222000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 43815
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 298.132
    learner_load_time_ms: 7.1
    learner_load_wait_time_ms: 1.664
iterations_since_restore: 165
node_ip: 127.0.0.1
num_agent_steps_sampled: 2222000
num_agent_steps_trained: 2205500
num_env_steps_sampled: 2222000
num_env_steps_sampled_this_iter: 13650
num_env_steps_sampled_throughput_per_sec: 1363.4662603942952
num_env_steps_trained: 2205500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1398.4269337377386
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 58.199999999999996
  ram_util_percent: 75.34285714285714
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0582654629001686
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02265772829843162
  mean_inference_ms: 1.1110395219407516
  mean_raw_obs_processing_ms: 0.2540556264632087
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018972325547833308
    StateBufferConnector_ms: 0.003274578914464077
    ViewRequirementAgentConnector_ms: 0.11477581808500201
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 17.0
  episode_reward_mean: 8.88785046728972
  episode_reward_min: 2.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 11.0, 8.0, 4.0, 12.0, 10.0, 3.0, 5.0, 12.0, 12.0, 10.0,
      10.0, 8.0, 12.0, 15.0, 6.0, 8.0, 9.0, 9.0, 5.0, 7.0, 11.0, 7.0, 3.0, 6.0, 10.0,
      15.0, 10.0, 11.0, 12.0, 8.0, 7.0, 5.0, 11.0, 6.0, 8.0, 11.0, 6.0, 4.0, 13.0,
      8.0, 10.0, 17.0, 10.0, 8.0, 11.0, 14.0, 7.0, 9.0, 10.0, 10.0, 11.0, 10.0, 4.0,
      15.0, 9.0, 15.0, 6.0, 11.0, 7.0, 7.0, 10.0, 12.0, 12.0, 8.0, 10.0, 6.0, 4.0,
      9.0, 10.0, 6.0, 7.0, 11.0, 9.0, 9.0, 14.0, 5.0, 15.0, 6.0, 8.0, 5.0, 7.0, 9.0,
      11.0, 9.0, 8.0, 7.0, 11.0, 7.0, 9.0, 5.0, 15.0, 8.0, 11.0, 12.0, 8.0, 10.0,
      9.0, 7.0, 11.0, 5.0, 5.0, 8.0, 10.0, 9.0, 5.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0582654629001686
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02265772829843162
    mean_inference_ms: 1.1110395219407516
    mean_raw_obs_processing_ms: 0.2540556264632087
time_since_restore: 1671.4338788986206
time_this_iter_s: 10.081793069839478
time_total_s: 1671.4338788986206
timers:
  sample_time_ms: 0.08
  synch_weights_time_ms: 0.306
  training_iteration_time_ms: 2.303
timestamp: 1692001503
timesteps_total: 2222000
training_iteration: 165
trial_id: default
train step: 166
agent_timesteps_total: 2235550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019153783906180905
  StateBufferConnector_ms: 0.003224273897566885
  ViewRequirementAgentConnector_ms: 0.11502819241217847
counters:
  num_agent_steps_sampled: 2235550
  num_agent_steps_trained: 2219000
  num_env_steps_sampled: 2235550
  num_env_steps_trained: 2219000
  num_samples_added_to_queue: 2235500
  num_training_step_calls_since_last_synch_worker_weights: 842
  num_weight_broadcasts: 44084
custom_metrics: {}
date: 2023-08-14_17-25-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.29245283018868
episode_reward_min: 1.0
episodes_this_iter: 106
episodes_total: 17466
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6456854939460754
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 11.705799102783203
        total_loss: 51.48887634277344
        var_gnorm: 64.57064056396484
        vf_explained_var: 0.9219653606414795
        vf_loss: 86.02301025390625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4438.0
  learner_queue:
    size_count: 4442
    size_mean: 15.8
    size_quantiles: [13.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.6
  num_agent_steps_sampled: 2235550
  num_agent_steps_trained: 2219000
  num_env_steps_sampled: 2235550
  num_env_steps_trained: 2219000
  num_samples_added_to_queue: 2235500
  num_training_step_calls_since_last_synch_worker_weights: 842
  num_weight_broadcasts: 44084
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 234.983
    learner_load_time_ms: 7.101
    learner_load_wait_time_ms: 1.593
iterations_since_restore: 166
node_ip: 127.0.0.1
num_agent_steps_sampled: 2235550
num_agent_steps_trained: 2219000
num_env_steps_sampled: 2235550
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.994992632297
num_env_steps_trained: 2219000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9950111096687
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 62.064285714285724
  ram_util_percent: 74.25714285714285
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05827517806346555
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02265322344241812
  mean_inference_ms: 1.1109253219722315
  mean_raw_obs_processing_ms: 0.2540436935172905
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019153783906180905
    StateBufferConnector_ms: 0.003224273897566885
    ViewRequirementAgentConnector_ms: 0.11502819241217847
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.29245283018868
  episode_reward_min: 1.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 7.0, 8.0, 2.0, 5.0, 11.0, 8.0, 6.0, 7.0, 9.0, 9.0, 2.0,
      10.0, 11.0, 11.0, 11.0, 13.0, 10.0, 1.0, 8.0, 6.0, 5.0, 5.0, 11.0, 6.0, 11.0,
      9.0, 7.0, 8.0, 9.0, 7.0, 7.0, 10.0, 12.0, 11.0, 5.0, 10.0, 13.0, 9.0, 5.0, 13.0,
      2.0, 8.0, 8.0, 13.0, 8.0, 7.0, 13.0, 11.0, 11.0, 6.0, 6.0, 5.0, 4.0, 7.0, 8.0,
      7.0, 16.0, 12.0, 7.0, 10.0, 5.0, 10.0, 9.0, 8.0, 9.0, 11.0, 11.0, 8.0, 8.0,
      9.0, 8.0, 12.0, 6.0, 13.0, 11.0, 11.0, 9.0, 8.0, 13.0, 5.0, 8.0, 6.0, 14.0,
      6.0, 10.0, 5.0, 6.0, 8.0, 8.0, 11.0, 6.0, 8.0, 9.0, 7.0, 7.0, 7.0, 5.0, 7.0,
      6.0, 9.0, 7.0, 4.0, 5.0, 13.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05827517806346555
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02265322344241812
    mean_inference_ms: 1.1109253219722315
    mean_raw_obs_processing_ms: 0.2540436935172905
time_since_restore: 1681.527177810669
time_this_iter_s: 10.09329891204834
time_total_s: 1681.527177810669
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001513
timesteps_total: 2235550
training_iteration: 166
trial_id: default
train step: 167
agent_timesteps_total: 2249250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01911292566317264
  StateBufferConnector_ms: 0.0033146867128176108
  ViewRequirementAgentConnector_ms: 0.11456035007940274
counters:
  num_agent_steps_sampled: 2249250
  num_agent_steps_trained: 2232500
  num_env_steps_sampled: 2249250
  num_env_steps_trained: 2232500
  num_samples_added_to_queue: 2249000
  num_training_step_calls_since_last_synch_worker_weights: 382
  num_weight_broadcasts: 44354
custom_metrics: {}
date: 2023-08-14_17-25-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.205607476635514
episode_reward_min: 3.0
episodes_this_iter: 107
episodes_total: 17573
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5831161737442017
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.0134339332580566
        total_loss: 32.421966552734375
        var_gnorm: 64.57820129394531
        vf_explained_var: 0.9635134935379028
        vf_loss: 64.64822387695312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4465.0
  learner_queue:
    size_count: 4471
    size_mean: 15.54
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1173182178770737
  num_agent_steps_sampled: 2249250
  num_agent_steps_trained: 2232500
  num_env_steps_sampled: 2249250
  num_env_steps_trained: 2232500
  num_samples_added_to_queue: 2249000
  num_training_step_calls_since_last_synch_worker_weights: 382
  num_weight_broadcasts: 44354
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 173.377
    learner_load_time_ms: 7.103
    learner_load_wait_time_ms: 1.587
iterations_since_restore: 167
node_ip: 127.0.0.1
num_agent_steps_sampled: 2249250
num_agent_steps_trained: 2232500
num_env_steps_sampled: 2249250
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.9982361816226
num_env_steps_trained: 2232500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.998261930796
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 58.406666666666666
  ram_util_percent: 77.21333333333334
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05828218631264415
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022648264813404487
  mean_inference_ms: 1.1107870599347123
  mean_raw_obs_processing_ms: 0.25402423615328895
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01911292566317264
    StateBufferConnector_ms: 0.0033146867128176108
    ViewRequirementAgentConnector_ms: 0.11456035007940274
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.205607476635514
  episode_reward_min: 3.0
  episodes_this_iter: 107
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [12.0, 10.0, 9.0, 6.0, 8.0, 12.0, 9.0, 11.0, 9.0, 8.0, 8.0, 6.0,
      5.0, 6.0, 6.0, 11.0, 13.0, 10.0, 11.0, 13.0, 11.0, 14.0, 9.0, 5.0, 7.0, 16.0,
      9.0, 8.0, 8.0, 11.0, 7.0, 10.0, 10.0, 3.0, 4.0, 9.0, 7.0, 9.0, 5.0, 11.0, 3.0,
      6.0, 6.0, 13.0, 6.0, 3.0, 11.0, 9.0, 9.0, 8.0, 8.0, 5.0, 8.0, 12.0, 7.0, 13.0,
      12.0, 10.0, 10.0, 11.0, 4.0, 5.0, 7.0, 14.0, 3.0, 5.0, 11.0, 5.0, 10.0, 5.0,
      3.0, 6.0, 6.0, 4.0, 9.0, 6.0, 14.0, 6.0, 5.0, 9.0, 8.0, 8.0, 11.0, 10.0, 5.0,
      6.0, 9.0, 4.0, 6.0, 5.0, 11.0, 12.0, 5.0, 9.0, 5.0, 9.0, 11.0, 8.0, 5.0, 10.0,
      8.0, 7.0, 13.0, 11.0, 6.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05828218631264415
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022648264813404487
    mean_inference_ms: 1.1107870599347123
    mean_raw_obs_processing_ms: 0.25402423615328895
time_since_restore: 1691.663834810257
time_this_iter_s: 10.136656999588013
time_total_s: 1691.663834810257
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001523
timesteps_total: 2249250
training_iteration: 167
trial_id: default
train step: 168
agent_timesteps_total: 2262500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0200198246882512
  StateBufferConnector_ms: 0.003448816446157602
  ViewRequirementAgentConnector_ms: 0.11936632486490104
counters:
  num_agent_steps_sampled: 2262500
  num_agent_steps_trained: 2246000
  num_env_steps_sampled: 2262500
  num_env_steps_trained: 2246000
  num_samples_added_to_queue: 2262500
  num_training_step_calls_since_last_synch_worker_weights: 363
  num_weight_broadcasts: 44616
custom_metrics: {}
date: 2023-08-14_17-25-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 5.5
episode_reward_min: 1.0
episodes_this_iter: 104
episodes_total: 17677
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.3899810016155243
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.81863021850586
        total_loss: 22.230506896972656
        var_gnorm: 64.58759307861328
        vf_explained_var: 0.9376704692840576
        vf_loss: 77.99808502197266
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4492.0
  learner_queue:
    size_count: 4497
    size_mean: 15.3
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.345362404707371
  num_agent_steps_sampled: 2262500
  num_agent_steps_trained: 2246000
  num_env_steps_sampled: 2262500
  num_env_steps_trained: 2246000
  num_samples_added_to_queue: 2262500
  num_training_step_calls_since_last_synch_worker_weights: 363
  num_weight_broadcasts: 44616
  timing_breakdown:
    learner_dequeue_time_ms: 0.005
    learner_grad_time_ms: 196.914
    learner_load_time_ms: 1.391
    learner_load_wait_time_ms: 1.51
iterations_since_restore: 168
node_ip: 127.0.0.1
num_agent_steps_sampled: 2262500
num_agent_steps_trained: 2246000
num_env_steps_sampled: 2262500
num_env_steps_sampled_this_iter: 13250
num_env_steps_sampled_throughput_per_sec: 1324.9949771356257
num_env_steps_trained: 2246000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9948823645998
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 55.2
  ram_util_percent: 75.89999999999999
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05828289149032766
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022649003833311983
  mean_inference_ms: 1.1109041962444028
  mean_raw_obs_processing_ms: 0.2540454626689263
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0200198246882512
    StateBufferConnector_ms: 0.003448816446157602
    ViewRequirementAgentConnector_ms: 0.11936632486490104
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 5.5
  episode_reward_min: 1.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 3.0, 5.0, 8.0, 5.0, 10.0, 3.0, 5.0, 3.0, 8.0, 5.0, 11.0,
      7.0, 6.0, 6.0, 9.0, 4.0, 4.0, 4.0, 7.0, 3.0, 6.0, 3.0, 5.0, 6.0, 4.0, 3.0, 5.0,
      8.0, 4.0, 4.0, 5.0, 8.0, 10.0, 3.0, 5.0, 3.0, 11.0, 5.0, 3.0, 6.0, 7.0, 6.0,
      2.0, 8.0, 4.0, 8.0, 5.0, 5.0, 4.0, 1.0, 6.0, 5.0, 8.0, 4.0, 7.0, 6.0, 6.0, 4.0,
      1.0, 5.0, 2.0, 7.0, 3.0, 10.0, 6.0, 3.0, 10.0, 9.0, 6.0, 7.0, 6.0, 3.0, 3.0,
      6.0, 3.0, 6.0, 7.0, 7.0, 9.0, 9.0, 5.0, 6.0, 3.0, 9.0, 2.0, 5.0, 7.0, 2.0, 4.0,
      5.0, 7.0, 6.0, 2.0, 5.0, 4.0, 5.0, 4.0, 4.0, 4.0, 7.0, 8.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05828289149032766
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022649003833311983
    mean_inference_ms: 1.1109041962444028
    mean_raw_obs_processing_ms: 0.2540454626689263
time_since_restore: 1701.7781856060028
time_this_iter_s: 10.11435079574585
time_total_s: 1701.7781856060028
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.043
timestamp: 1692001534
timesteps_total: 2262500
training_iteration: 168
trial_id: default
train step: 169
agent_timesteps_total: 2275950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019347896942725547
  StateBufferConnector_ms: 0.003394943017225999
  ViewRequirementAgentConnector_ms: 0.11664308034456693
counters:
  num_agent_steps_sampled: 2275950
  num_agent_steps_trained: 2259000
  num_env_steps_sampled: 2275950
  num_env_steps_trained: 2259000
  num_samples_added_to_queue: 2275500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 44882
custom_metrics: {}
date: 2023-08-14_17-25-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.298076923076923
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 17781
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6551024913787842
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 18.753808975219727
        total_loss: 37.989158630371094
        var_gnorm: 64.59465789794922
        vf_explained_var: 0.88218754529953
        vf_loss: 45.021724700927734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4518.0
  learner_queue:
    size_count: 4523
    size_mean: 15.42
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1151681487560519
  num_agent_steps_sampled: 2275950
  num_agent_steps_trained: 2259000
  num_env_steps_sampled: 2275950
  num_env_steps_trained: 2259000
  num_samples_added_to_queue: 2275500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 44882
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 231.1
    learner_load_time_ms: 1.392
    learner_load_wait_time_ms: 1.619
iterations_since_restore: 169
node_ip: 127.0.0.1
num_agent_steps_sampled: 2275950
num_agent_steps_trained: 2259000
num_env_steps_sampled: 2275950
num_env_steps_sampled_this_iter: 13450
num_env_steps_sampled_throughput_per_sec: 1344.6968720215568
num_env_steps_trained: 2259000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.7070138498318
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 50.99999999999999
  ram_util_percent: 75.98571428571428
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05828917354728477
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022648843999279092
  mean_inference_ms: 1.1109256540831542
  mean_raw_obs_processing_ms: 0.25404853807381145
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019347896942725547
    StateBufferConnector_ms: 0.003394943017225999
    ViewRequirementAgentConnector_ms: 0.11664308034456693
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.298076923076923
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 6.0, 3.0, 6.0, 7.0, 8.0, 5.0, 9.0, 2.0, 10.0, 6.0, 8.0,
      9.0, 10.0, 8.0, 4.0, 9.0, 12.0, 3.0, 8.0, 2.0, 5.0, 6.0, 8.0, 11.0, 6.0, 8.0,
      6.0, 14.0, 11.0, 9.0, 9.0, 7.0, 7.0, 4.0, 8.0, 9.0, 11.0, 3.0, 7.0, 5.0, 5.0,
      12.0, 7.0, 7.0, 11.0, 8.0, 8.0, 5.0, 10.0, 11.0, 6.0, 3.0, 8.0, 5.0, 2.0, 9.0,
      11.0, 2.0, 6.0, 7.0, 6.0, 6.0, 5.0, 3.0, 9.0, 5.0, 6.0, 8.0, 14.0, 12.0, 11.0,
      3.0, 12.0, 10.0, 3.0, 10.0, 4.0, 11.0, 12.0, 3.0, 10.0, 7.0, 8.0, 9.0, 7.0,
      10.0, 3.0, 8.0, 9.0, 6.0, 7.0, 7.0, 11.0, 5.0, 3.0, 11.0, 5.0, 8.0, 7.0, 2.0,
      6.0, 9.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05828917354728477
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022648843999279092
    mean_inference_ms: 1.1109256540831542
    mean_raw_obs_processing_ms: 0.25404853807381145
time_since_restore: 1711.8965756893158
time_this_iter_s: 10.118390083312988
time_total_s: 1711.8965756893158
timers:
  sample_time_ms: 0.07
  synch_weights_time_ms: 0.239
  training_iteration_time_ms: 0.369
timestamp: 1692001544
timesteps_total: 2275950
training_iteration: 169
trial_id: default
train step: 170
agent_timesteps_total: 2288750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020020246505737305
  StateBufferConnector_ms: 0.0035152435302734375
  ViewRequirementAgentConnector_ms: 0.12067508697509766
counters:
  num_agent_steps_sampled: 2288750
  num_agent_steps_trained: 2272000
  num_env_steps_sampled: 2288750
  num_env_steps_trained: 2272000
  num_samples_added_to_queue: 2288500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 45136
custom_metrics: {}
date: 2023-08-14_17-25-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 7.51
episode_reward_min: 2.0
episodes_this_iter: 100
episodes_total: 17881
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.673329770565033
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -12.62668228149414
        total_loss: 14.888705253601074
        var_gnorm: 64.59703826904297
        vf_explained_var: 0.8190710544586182
        vf_loss: 61.76407241821289
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4544.0
  learner_queue:
    size_count: 4549
    size_mean: 15.48
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.0998181667894016
  num_agent_steps_sampled: 2288750
  num_agent_steps_trained: 2272000
  num_env_steps_sampled: 2288750
  num_env_steps_trained: 2272000
  num_samples_added_to_queue: 2288500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 45136
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 235.665
    learner_load_time_ms: 1.38
    learner_load_wait_time_ms: 1.605
iterations_since_restore: 170
node_ip: 127.0.0.1
num_agent_steps_sampled: 2288750
num_agent_steps_trained: 2272000
num_env_steps_sampled: 2288750
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.989227385586
num_env_steps_trained: 2272000
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.989059063486
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 53.36428571428572
  ram_util_percent: 75.70714285714287
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05830933093968424
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022654225589498214
  mean_inference_ms: 1.1112374058255496
  mean_raw_obs_processing_ms: 0.2541109145455557
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020020246505737305
    StateBufferConnector_ms: 0.0035152435302734375
    ViewRequirementAgentConnector_ms: 0.12067508697509766
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 7.51
  episode_reward_min: 2.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 6.0, 2.0, 4.0, 8.0, 8.0, 4.0, 9.0, 7.0, 12.0, 7.0, 3.0,
      6.0, 7.0, 8.0, 10.0, 7.0, 8.0, 6.0, 5.0, 8.0, 6.0, 6.0, 9.0, 8.0, 6.0, 8.0,
      4.0, 7.0, 7.0, 5.0, 12.0, 5.0, 12.0, 6.0, 13.0, 10.0, 9.0, 11.0, 9.0, 5.0, 9.0,
      10.0, 9.0, 9.0, 4.0, 9.0, 7.0, 9.0, 7.0, 6.0, 7.0, 3.0, 5.0, 5.0, 11.0, 4.0,
      6.0, 6.0, 10.0, 7.0, 9.0, 10.0, 12.0, 10.0, 10.0, 6.0, 10.0, 9.0, 6.0, 7.0,
      8.0, 5.0, 7.0, 8.0, 8.0, 8.0, 8.0, 5.0, 6.0, 9.0, 3.0, 6.0, 8.0, 6.0, 7.0, 10.0,
      9.0, 8.0, 13.0, 8.0, 8.0, 10.0, 9.0, 7.0, 9.0, 4.0, 9.0, 6.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05830933093968424
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022654225589498214
    mean_inference_ms: 1.1112374058255496
    mean_raw_obs_processing_ms: 0.2541109145455557
time_since_restore: 1722.0054705142975
time_this_iter_s: 10.10889482498169
time_total_s: 1722.0054705142975
timers:
  sample_time_ms: 0.065
  synch_weights_time_ms: 0.232
  training_iteration_time_ms: 0.365
timestamp: 1692001554
timesteps_total: 2288750
training_iteration: 170
trial_id: default
train step: 171
agent_timesteps_total: 2302300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018921438253150798
  StateBufferConnector_ms: 0.003318966559644015
  ViewRequirementAgentConnector_ms: 0.11445036474263894
counters:
  num_agent_steps_sampled: 2302300
  num_agent_steps_trained: 2285500
  num_env_steps_sampled: 2302300
  num_env_steps_trained: 2285500
  num_samples_added_to_queue: 2302000
  num_training_step_calls_since_last_synch_worker_weights: 205
  num_weight_broadcasts: 45404
custom_metrics: {}
date: 2023-08-14_17-26-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.952830188679245
episode_reward_min: 3.0
episodes_this_iter: 106
episodes_total: 17987
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6800286769866943
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 24.077831268310547
        total_loss: 54.92200469970703
        var_gnorm: 64.6005630493164
        vf_explained_var: 0.8406137824058533
        vf_loss: 68.48863220214844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4571.0
  learner_queue:
    size_count: 4577
    size_mean: 15.4
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2649110640673518
  num_agent_steps_sampled: 2302300
  num_agent_steps_trained: 2285500
  num_env_steps_sampled: 2302300
  num_env_steps_trained: 2285500
  num_samples_added_to_queue: 2302000
  num_training_step_calls_since_last_synch_worker_weights: 205
  num_weight_broadcasts: 45404
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 183.779
    learner_load_time_ms: 1.378
    learner_load_wait_time_ms: 1.48
iterations_since_restore: 171
node_ip: 127.0.0.1
num_agent_steps_sampled: 2302300
num_agent_steps_trained: 2285500
num_env_steps_sampled: 2302300
num_env_steps_sampled_this_iter: 13550
num_env_steps_sampled_throughput_per_sec: 1354.9956710476895
num_env_steps_trained: 2285500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9956870216831
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 46.313333333333325
  ram_util_percent: 74.93999999999998
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058308863595186625
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022650814226127563
  mean_inference_ms: 1.1112054835751775
  mean_raw_obs_processing_ms: 0.254083963058903
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018921438253150798
    StateBufferConnector_ms: 0.003318966559644015
    ViewRequirementAgentConnector_ms: 0.11445036474263894
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.952830188679245
  episode_reward_min: 3.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 3.0, 4.0, 5.0, 7.0, 7.0, 10.0, 5.0, 12.0, 6.0, 6.0,
      7.0, 7.0, 7.0, 3.0, 5.0, 7.0, 5.0, 7.0, 7.0, 13.0, 12.0, 7.0, 8.0, 7.0, 5.0,
      10.0, 10.0, 14.0, 6.0, 9.0, 8.0, 11.0, 10.0, 11.0, 6.0, 7.0, 14.0, 10.0, 10.0,
      8.0, 4.0, 10.0, 9.0, 9.0, 10.0, 9.0, 8.0, 8.0, 9.0, 8.0, 3.0, 7.0, 4.0, 6.0,
      7.0, 9.0, 11.0, 7.0, 8.0, 11.0, 13.0, 8.0, 10.0, 3.0, 6.0, 11.0, 8.0, 5.0, 10.0,
      10.0, 9.0, 6.0, 6.0, 8.0, 7.0, 11.0, 7.0, 8.0, 10.0, 6.0, 14.0, 5.0, 10.0, 7.0,
      6.0, 6.0, 8.0, 5.0, 7.0, 12.0, 7.0, 9.0, 8.0, 10.0, 10.0, 11.0, 5.0, 8.0, 9.0,
      4.0, 10.0, 8.0, 11.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058308863595186625
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022650814226127563
    mean_inference_ms: 1.1112054835751775
    mean_raw_obs_processing_ms: 0.254083963058903
time_since_restore: 1732.148112297058
time_this_iter_s: 10.14264178276062
time_total_s: 1732.148112297058
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001564
timesteps_total: 2302300
training_iteration: 171
trial_id: default
train step: 172
agent_timesteps_total: 2315700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01906508491152809
  StateBufferConnector_ms: 0.0033671515328543527
  ViewRequirementAgentConnector_ms: 0.11471385047549293
counters:
  num_agent_steps_sampled: 2315700
  num_agent_steps_trained: 2299000
  num_env_steps_sampled: 2315700
  num_env_steps_trained: 2299000
  num_samples_added_to_queue: 2315500
  num_training_step_calls_since_last_synch_worker_weights: 936
  num_weight_broadcasts: 45667
custom_metrics: {}
date: 2023-08-14_17-26-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.733333333333333
episode_reward_min: 1.0
episodes_this_iter: 105
episodes_total: 18092
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6089800000190735
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 5.9287848472595215
        total_loss: 21.889663696289062
        var_gnorm: 64.6032485961914
        vf_explained_var: 0.9213625192642212
        vf_loss: 38.011558532714844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4598.0
  learner_queue:
    size_count: 4602
    size_mean: 15.42
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.250439922587247
  num_agent_steps_sampled: 2315700
  num_agent_steps_trained: 2299000
  num_env_steps_sampled: 2315700
  num_env_steps_trained: 2299000
  num_samples_added_to_queue: 2315500
  num_training_step_calls_since_last_synch_worker_weights: 936
  num_weight_broadcasts: 45667
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 249.089
    learner_load_time_ms: 1.376
    learner_load_wait_time_ms: 1.673
iterations_since_restore: 172
node_ip: 127.0.0.1
num_agent_steps_sampled: 2315700
num_agent_steps_trained: 2299000
num_env_steps_sampled: 2315700
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.996230136033
num_env_steps_trained: 2299000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9962020027199
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 46.90714285714285
  ram_util_percent: 74.7642857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05830645159526928
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022651212967674087
  mean_inference_ms: 1.1112468062058933
  mean_raw_obs_processing_ms: 0.25408945304403074
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01906508491152809
    StateBufferConnector_ms: 0.0033671515328543527
    ViewRequirementAgentConnector_ms: 0.11471385047549293
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.733333333333333
  episode_reward_min: 1.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 7.0, 9.0, 7.0, 7.0, 13.0, 9.0, 7.0, 11.0, 5.0, 14.0, 12.0,
      10.0, 7.0, 7.0, 13.0, 9.0, 9.0, 8.0, 14.0, 10.0, 6.0, 8.0, 9.0, 11.0, 7.0, 10.0,
      8.0, 7.0, 6.0, 4.0, 6.0, 9.0, 13.0, 10.0, 11.0, 11.0, 8.0, 8.0, 9.0, 6.0, 7.0,
      5.0, 6.0, 7.0, 12.0, 5.0, 12.0, 1.0, 7.0, 7.0, 6.0, 11.0, 4.0, 6.0, 8.0, 7.0,
      8.0, 8.0, 9.0, 3.0, 11.0, 7.0, 3.0, 10.0, 7.0, 5.0, 5.0, 14.0, 10.0, 6.0, 7.0,
      7.0, 14.0, 12.0, 6.0, 13.0, 10.0, 12.0, 9.0, 12.0, 10.0, 8.0, 10.0, 8.0, 12.0,
      9.0, 9.0, 9.0, 14.0, 7.0, 11.0, 10.0, 10.0, 11.0, 10.0, 9.0, 12.0, 11.0, 10.0,
      8.0, 12.0, 11.0, 11.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05830645159526928
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022651212967674087
    mean_inference_ms: 1.1112468062058933
    mean_raw_obs_processing_ms: 0.25408945304403074
time_since_restore: 1742.2544121742249
time_this_iter_s: 10.106299877166748
time_total_s: 1742.2544121742249
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001574
timesteps_total: 2315700
training_iteration: 172
trial_id: default
train step: 173
agent_timesteps_total: 2329550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018557795771846065
  StateBufferConnector_ms: 0.003364351060655382
  ViewRequirementAgentConnector_ms: 0.11381308237711589
counters:
  num_agent_steps_sampled: 2329550
  num_agent_steps_trained: 2313000
  num_env_steps_sampled: 2329550
  num_env_steps_trained: 2313000
  num_samples_added_to_queue: 2329500
  num_training_step_calls_since_last_synch_worker_weights: 66
  num_weight_broadcasts: 45939
custom_metrics: {}
date: 2023-08-14_17-26-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.324074074074074
episode_reward_min: 4.0
episodes_this_iter: 108
episodes_total: 18200
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5599602460861206
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -27.757278442382812
        total_loss: 13.221515655517578
        var_gnorm: 64.60901641845703
        vf_explained_var: 0.8440782427787781
        vf_loss: 87.55718994140625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4626.0
  learner_queue:
    size_count: 4632
    size_mean: 15.48
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1702991070662234
  num_agent_steps_sampled: 2329550
  num_agent_steps_trained: 2313000
  num_env_steps_sampled: 2329550
  num_env_steps_trained: 2313000
  num_samples_added_to_queue: 2329500
  num_training_step_calls_since_last_synch_worker_weights: 66
  num_weight_broadcasts: 45939
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 163.956
    learner_load_time_ms: 1.375
    learner_load_wait_time_ms: 1.448
iterations_since_restore: 173
node_ip: 127.0.0.1
num_agent_steps_sampled: 2329550
num_agent_steps_trained: 2313000
num_env_steps_sampled: 2329550
num_env_steps_sampled_this_iter: 13850
num_env_steps_sampled_throughput_per_sec: 1384.9958393698748
num_env_steps_trained: 2313000
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.995794308899
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 41.607142857142854
  ram_util_percent: 74.8142857142857
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05832555582799074
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02264351104295684
  mean_inference_ms: 1.1109889228391578
  mean_raw_obs_processing_ms: 0.25405611345756746
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018557795771846065
    StateBufferConnector_ms: 0.003364351060655382
    ViewRequirementAgentConnector_ms: 0.11381308237711589
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.324074074074074
  episode_reward_min: 4.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [11.0, 8.0, 5.0, 10.0, 10.0, 11.0, 7.0, 10.0, 8.0, 12.0, 8.0,
      7.0, 13.0, 10.0, 11.0, 4.0, 7.0, 4.0, 11.0, 4.0, 4.0, 10.0, 9.0, 6.0, 9.0, 11.0,
      7.0, 12.0, 9.0, 9.0, 12.0, 10.0, 9.0, 12.0, 7.0, 10.0, 9.0, 10.0, 13.0, 9.0,
      13.0, 10.0, 4.0, 7.0, 9.0, 9.0, 10.0, 7.0, 8.0, 7.0, 9.0, 9.0, 10.0, 11.0, 11.0,
      12.0, 12.0, 9.0, 14.0, 11.0, 6.0, 7.0, 11.0, 11.0, 6.0, 11.0, 12.0, 13.0, 16.0,
      12.0, 9.0, 8.0, 6.0, 6.0, 15.0, 6.0, 9.0, 10.0, 9.0, 8.0, 10.0, 11.0, 7.0, 16.0,
      13.0, 10.0, 5.0, 11.0, 12.0, 12.0, 10.0, 11.0, 5.0, 10.0, 11.0, 7.0, 8.0, 8.0,
      11.0, 6.0, 12.0, 4.0, 7.0, 11.0, 10.0, 5.0, 12.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05832555582799074
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02264351104295684
    mean_inference_ms: 1.1109889228391578
    mean_raw_obs_processing_ms: 0.25405611345756746
time_since_restore: 1752.40047621727
time_this_iter_s: 10.146064043045044
time_total_s: 1752.40047621727
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001584
timesteps_total: 2329550
training_iteration: 173
trial_id: default
train step: 174
agent_timesteps_total: 2343300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019106600019666884
  StateBufferConnector_ms: 0.0033327826747187863
  ViewRequirementAgentConnector_ms: 0.11445217662387425
counters:
  num_agent_steps_sampled: 2343300
  num_agent_steps_trained: 2326500
  num_env_steps_sampled: 2343300
  num_env_steps_trained: 2326500
  num_samples_added_to_queue: 2343000
  num_training_step_calls_since_last_synch_worker_weights: 70
  num_weight_broadcasts: 46210
custom_metrics: {}
date: 2023-08-14_17-26-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.981481481481481
episode_reward_min: 3.0
episodes_this_iter: 108
episodes_total: 18308
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6405851244926453
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.3742046356201172
        total_loss: 56.962425231933594
        var_gnorm: 64.62104034423828
        vf_explained_var: 0.9063345193862915
        vf_loss: 119.5822982788086
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4653.0
  learner_queue:
    size_count: 4659
    size_mean: 15.12
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6326665305566843
  num_agent_steps_sampled: 2343300
  num_agent_steps_trained: 2326500
  num_env_steps_sampled: 2343300
  num_env_steps_trained: 2326500
  num_samples_added_to_queue: 2343000
  num_training_step_calls_since_last_synch_worker_weights: 70
  num_weight_broadcasts: 46210
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 184.108
    learner_load_time_ms: 1.386
    learner_load_wait_time_ms: 1.534
iterations_since_restore: 174
node_ip: 127.0.0.1
num_agent_steps_sampled: 2343300
num_agent_steps_trained: 2326500
num_env_steps_sampled: 2343300
num_env_steps_sampled_this_iter: 13750
num_env_steps_sampled_throughput_per_sec: 1374.9939680364103
num_env_steps_trained: 2326500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9940777084755
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 45.013333333333335
  ram_util_percent: 74.79999999999998
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058306075321170076
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022641700215663904
  mean_inference_ms: 1.1108968033724227
  mean_raw_obs_processing_ms: 0.25402721678058265
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019106600019666884
    StateBufferConnector_ms: 0.0033327826747187863
    ViewRequirementAgentConnector_ms: 0.11445217662387425
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.981481481481481
  episode_reward_min: 3.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 15.0, 7.0, 7.0, 6.0, 8.0, 14.0, 12.0, 9.0, 5.0, 13.0, 7.0,
      8.0, 12.0, 13.0, 10.0, 8.0, 7.0, 7.0, 12.0, 9.0, 9.0, 10.0, 5.0, 9.0, 11.0,
      10.0, 9.0, 7.0, 10.0, 9.0, 11.0, 12.0, 13.0, 9.0, 9.0, 7.0, 14.0, 7.0, 11.0,
      6.0, 8.0, 11.0, 8.0, 13.0, 8.0, 10.0, 13.0, 7.0, 5.0, 8.0, 7.0, 15.0, 7.0, 8.0,
      12.0, 11.0, 8.0, 8.0, 8.0, 10.0, 8.0, 10.0, 6.0, 10.0, 10.0, 5.0, 7.0, 12.0,
      10.0, 6.0, 5.0, 11.0, 10.0, 9.0, 9.0, 6.0, 9.0, 8.0, 10.0, 7.0, 9.0, 9.0, 9.0,
      5.0, 8.0, 9.0, 9.0, 9.0, 8.0, 8.0, 15.0, 10.0, 14.0, 9.0, 9.0, 9.0, 12.0, 8.0,
      7.0, 6.0, 8.0, 10.0, 10.0, 4.0, 11.0, 3.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058306075321170076
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022641700215663904
    mean_inference_ms: 1.1108968033724227
    mean_raw_obs_processing_ms: 0.25402721678058265
time_since_restore: 1762.5492022037506
time_this_iter_s: 10.148725986480713
time_total_s: 1762.5492022037506
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001594
timesteps_total: 2343300
training_iteration: 174
trial_id: default
train step: 175
agent_timesteps_total: 2355700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02158808708190918
  StateBufferConnector_ms: 0.0037076473236083984
  ViewRequirementAgentConnector_ms: 0.12625718116760254
counters:
  num_agent_steps_sampled: 2355700
  num_agent_steps_trained: 2339000
  num_env_steps_sampled: 2355700
  num_env_steps_trained: 2339000
  num_samples_added_to_queue: 2355500
  num_training_step_calls_since_last_synch_worker_weights: 236
  num_weight_broadcasts: 46455
custom_metrics: {}
date: 2023-08-14_17-26-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.78
episode_reward_min: 0.0
episodes_this_iter: 96
episodes_total: 18404
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5674093961715698
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 27.986644744873047
        total_loss: 55.003204345703125
        var_gnorm: 64.64778900146484
        vf_explained_var: 0.9329807758331299
        vf_loss: 59.70721435546875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4678.0
  learner_queue:
    size_count: 4684
    size_mean: 15.08
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5727682601069999
  num_agent_steps_sampled: 2355700
  num_agent_steps_trained: 2339000
  num_env_steps_sampled: 2355700
  num_env_steps_trained: 2339000
  num_samples_added_to_queue: 2355500
  num_training_step_calls_since_last_synch_worker_weights: 236
  num_weight_broadcasts: 46455
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 187.501
    learner_load_time_ms: 1.377
    learner_load_wait_time_ms: 1.554
iterations_since_restore: 175
node_ip: 127.0.0.1
num_agent_steps_sampled: 2355700
num_agent_steps_trained: 2339000
num_env_steps_sampled: 2355700
num_env_steps_sampled_this_iter: 12400
num_env_steps_sampled_throughput_per_sec: 1239.9987583172833
num_env_steps_trained: 2339000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.998748303713
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 53.09285714285715
  ram_util_percent: 75.75
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058373977446919245
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022651238749830015
  mean_inference_ms: 1.1112908230457463
  mean_raw_obs_processing_ms: 0.25413091196331444
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02158808708190918
    StateBufferConnector_ms: 0.0037076473236083984
    ViewRequirementAgentConnector_ms: 0.12625718116760254
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.78
  episode_reward_min: 0.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 11.0, 3.0, 8.0, 9.0, 8.0, 11.0, 5.0, 14.0, 10.0, 9.0, 7.0,
      13.0, 4.0, 12.0, 6.0, 9.0, 6.0, 5.0, 6.0, 4.0, 9.0, 11.0, 7.0, 7.0, 6.0, 4.0,
      4.0, 7.0, 5.0, 9.0, 7.0, 9.0, 13.0, 6.0, 8.0, 4.0, 5.0, 10.0, 10.0, 12.0, 10.0,
      6.0, 8.0, 5.0, 10.0, 2.0, 10.0, 6.0, 5.0, 8.0, 6.0, 12.0, 14.0, 4.0, 6.0, 7.0,
      12.0, 7.0, 4.0, 10.0, 12.0, 7.0, 6.0, 6.0, 8.0, 15.0, 8.0, 11.0, 5.0, 15.0,
      13.0, 5.0, 10.0, 10.0, 13.0, 10.0, 10.0, 8.0, 7.0, 6.0, 9.0, 7.0, 6.0, 7.0,
      6.0, 11.0, 7.0, 2.0, 6.0, 7.0, 9.0, 5.0, 7.0, 10.0, 7.0, 5.0, 0.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058373977446919245
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022651238749830015
    mean_inference_ms: 1.1112908230457463
    mean_raw_obs_processing_ms: 0.25413091196331444
time_since_restore: 1772.6904129981995
time_this_iter_s: 10.141210794448853
time_total_s: 1772.6904129981995
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1692001605
timesteps_total: 2355700
training_iteration: 175
trial_id: default
train step: 176
agent_timesteps_total: 2369000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019524189142080452
  StateBufferConnector_ms: 0.00333098264840933
  ViewRequirementAgentConnector_ms: 0.118866333594689
counters:
  num_agent_steps_sampled: 2369000
  num_agent_steps_trained: 2352500
  num_env_steps_sampled: 2369000
  num_env_steps_trained: 2352500
  num_samples_added_to_queue: 2369000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 46718
custom_metrics: {}
date: 2023-08-14_17-26-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.5
episode_reward_min: 3.0
episodes_this_iter: 104
episodes_total: 18508
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5891895890235901
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -29.307756423950195
        total_loss: 21.12320327758789
        var_gnorm: 64.65594482421875
        vf_explained_var: 0.8247716426849365
        vf_loss: 106.75381469726562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4705.0
  learner_queue:
    size_count: 4709
    size_mean: 15.18
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4654692081377894
  num_agent_steps_sampled: 2369000
  num_agent_steps_trained: 2352500
  num_env_steps_sampled: 2369000
  num_env_steps_trained: 2352500
  num_samples_added_to_queue: 2369000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 46718
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 235.532
    learner_load_time_ms: 2.253
    learner_load_wait_time_ms: 1.58
iterations_since_restore: 176
node_ip: 127.0.0.1
num_agent_steps_sampled: 2369000
num_agent_steps_trained: 2352500
num_env_steps_sampled: 2369000
num_env_steps_sampled_this_iter: 13300
num_env_steps_sampled_throughput_per_sec: 1327.612686061665
num_env_steps_trained: 2352500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1347.5767866039457
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 49.457142857142856
  ram_util_percent: 75.02857142857142
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05834850248806856
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022658560232355258
  mean_inference_ms: 1.1114951637642319
  mean_raw_obs_processing_ms: 0.25415032890696576
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019524189142080452
    StateBufferConnector_ms: 0.00333098264840933
    ViewRequirementAgentConnector_ms: 0.118866333594689
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.5
  episode_reward_min: 3.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 7.0, 8.0, 6.0, 10.0, 5.0, 6.0, 6.0, 8.0, 7.0, 3.0, 7.0,
      7.0, 4.0, 9.0, 3.0, 5.0, 5.0, 9.0, 5.0, 11.0, 12.0, 5.0, 4.0, 5.0, 10.0, 10.0,
      6.0, 9.0, 9.0, 8.0, 4.0, 6.0, 9.0, 9.0, 13.0, 6.0, 6.0, 9.0, 8.0, 8.0, 10.0,
      8.0, 6.0, 7.0, 7.0, 14.0, 4.0, 5.0, 8.0, 10.0, 3.0, 5.0, 3.0, 9.0, 7.0, 7.0,
      6.0, 8.0, 4.0, 4.0, 8.0, 6.0, 11.0, 6.0, 9.0, 7.0, 9.0, 7.0, 9.0, 3.0, 6.0,
      5.0, 6.0, 6.0, 11.0, 6.0, 9.0, 5.0, 5.0, 9.0, 8.0, 6.0, 10.0, 9.0, 10.0, 10.0,
      4.0, 10.0, 6.0, 5.0, 14.0, 11.0, 10.0, 11.0, 4.0, 8.0, 12.0, 11.0, 10.0, 8.0,
      8.0, 12.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05834850248806856
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022658560232355258
    mean_inference_ms: 1.1114951637642319
    mean_raw_obs_processing_ms: 0.25415032890696576
time_since_restore: 1782.8177897930145
time_this_iter_s: 10.127376794815063
time_total_s: 1782.8177897930145
timers:
  sample_time_ms: 0.069
  synch_weights_time_ms: 0.495
  training_iteration_time_ms: 1.925
timestamp: 1692001615
timesteps_total: 2369000
training_iteration: 176
trial_id: default
train step: 177
agent_timesteps_total: 2382350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019881817010732796
  StateBufferConnector_ms: 0.0033772908724271334
  ViewRequirementAgentConnector_ms: 0.11687187048105094
counters:
  num_agent_steps_sampled: 2382350
  num_agent_steps_trained: 2365500
  num_env_steps_sampled: 2382350
  num_env_steps_trained: 2365500
  num_samples_added_to_queue: 2382000
  num_training_step_calls_since_last_synch_worker_weights: 828
  num_weight_broadcasts: 46977
custom_metrics: {}
date: 2023-08-14_17-27-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.384615384615385
episode_reward_min: 2.0
episodes_this_iter: 104
episodes_total: 18612
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5662922263145447
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -14.691217422485352
        total_loss: -3.7662813663482666
        var_gnorm: 64.66216278076172
        vf_explained_var: 0.9629284739494324
        vf_loss: 27.512794494628906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4731.0
  learner_queue:
    size_count: 4736
    size_mean: 15.5
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.0816653826391966
  num_agent_steps_sampled: 2382350
  num_agent_steps_trained: 2365500
  num_env_steps_sampled: 2382350
  num_env_steps_trained: 2365500
  num_samples_added_to_queue: 2382000
  num_training_step_calls_since_last_synch_worker_weights: 828
  num_weight_broadcasts: 46977
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 219.366
    learner_load_time_ms: 2.264
    learner_load_wait_time_ms: 1.641
iterations_since_restore: 177
node_ip: 127.0.0.1
num_agent_steps_sampled: 2382350
num_agent_steps_trained: 2365500
num_env_steps_sampled: 2382350
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.9993315938482
num_env_steps_trained: 2365500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9993491176049
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 47.921428571428585
  ram_util_percent: 74.72857142857141
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05835364680490459
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022659317901987223
  mean_inference_ms: 1.1115065525483294
  mean_raw_obs_processing_ms: 0.25415917926194626
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019881817010732796
    StateBufferConnector_ms: 0.0033772908724271334
    ViewRequirementAgentConnector_ms: 0.11687187048105094
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.384615384615385
  episode_reward_min: 2.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 12.0, 10.0, 14.0, 5.0, 9.0, 9.0, 9.0, 6.0, 5.0, 7.0, 11.0,
      10.0, 9.0, 9.0, 7.0, 2.0, 9.0, 11.0, 11.0, 5.0, 10.0, 9.0, 11.0, 10.0, 11.0,
      12.0, 9.0, 13.0, 9.0, 5.0, 11.0, 8.0, 11.0, 10.0, 10.0, 11.0, 13.0, 6.0, 2.0,
      16.0, 12.0, 9.0, 9.0, 6.0, 13.0, 8.0, 10.0, 12.0, 11.0, 12.0, 8.0, 8.0, 11.0,
      9.0, 9.0, 7.0, 13.0, 8.0, 9.0, 5.0, 13.0, 7.0, 7.0, 11.0, 13.0, 9.0, 8.0, 7.0,
      6.0, 8.0, 14.0, 11.0, 9.0, 13.0, 10.0, 10.0, 12.0, 9.0, 10.0, 10.0, 10.0, 2.0,
      13.0, 4.0, 10.0, 8.0, 12.0, 10.0, 11.0, 8.0, 6.0, 11.0, 11.0, 9.0, 14.0, 4.0,
      9.0, 10.0, 13.0, 9.0, 15.0, 10.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05835364680490459
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022659317901987223
    mean_inference_ms: 1.1115065525483294
    mean_raw_obs_processing_ms: 0.25415917926194626
time_since_restore: 1792.9299867153168
time_this_iter_s: 10.112196922302246
time_total_s: 1792.9299867153168
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001625
timesteps_total: 2382350
training_iteration: 177
trial_id: default
train step: 178
agent_timesteps_total: 2395850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01876916525498876
  StateBufferConnector_ms: 0.0032521643728580115
  ViewRequirementAgentConnector_ms: 0.11291638860162699
counters:
  num_agent_steps_sampled: 2395850
  num_agent_steps_trained: 2379000
  num_env_steps_sampled: 2395850
  num_env_steps_trained: 2379000
  num_samples_added_to_queue: 2395500
  num_training_step_calls_since_last_synch_worker_weights: 559
  num_weight_broadcasts: 47242
custom_metrics: {}
date: 2023-08-14_17-27-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.40566037735849
episode_reward_min: 0.0
episodes_this_iter: 106
episodes_total: 18718
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.4540746212005615
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.9824581146240234
        total_loss: 19.703224182128906
        var_gnorm: 64.67135620117188
        vf_explained_var: 0.941210150718689
        vf_loss: 39.982276916503906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4758.0
  learner_queue:
    size_count: 4763
    size_mean: 15.56
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0423051376636308
  num_agent_steps_sampled: 2395850
  num_agent_steps_trained: 2379000
  num_env_steps_sampled: 2395850
  num_env_steps_trained: 2379000
  num_samples_added_to_queue: 2395500
  num_training_step_calls_since_last_synch_worker_weights: 559
  num_weight_broadcasts: 47242
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 221.639
    learner_load_time_ms: 2.254
    learner_load_wait_time_ms: 1.454
iterations_since_restore: 178
node_ip: 127.0.0.1
num_agent_steps_sampled: 2395850
num_agent_steps_trained: 2379000
num_env_steps_sampled: 2395850
num_env_steps_sampled_this_iter: 13500
num_env_steps_sampled_throughput_per_sec: 1349.9948823645998
num_env_steps_trained: 2379000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9948823645998
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 45.54666666666665
  ram_util_percent: 73.36666666666666
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058351166589555775
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022655593743443104
  mean_inference_ms: 1.111520339598944
  mean_raw_obs_processing_ms: 0.25412850203667475
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01876916525498876
    StateBufferConnector_ms: 0.0032521643728580115
    ViewRequirementAgentConnector_ms: 0.11291638860162699
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.40566037735849
  episode_reward_min: 0.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 11.0, 13.0, 8.0, 8.0, 10.0, 8.0, 8.0, 9.0, 10.0, 10.0, 7.0,
      11.0, 12.0, 14.0, 10.0, 9.0, 6.0, 10.0, 11.0, 5.0, 10.0, 12.0, 9.0, 6.0, 10.0,
      0.0, 9.0, 7.0, 10.0, 13.0, 7.0, 7.0, 7.0, 10.0, 9.0, 3.0, 9.0, 10.0, 8.0, 5.0,
      4.0, 4.0, 7.0, 8.0, 4.0, 9.0, 9.0, 11.0, 5.0, 6.0, 9.0, 9.0, 10.0, 6.0, 13.0,
      9.0, 9.0, 9.0, 13.0, 12.0, 8.0, 7.0, 13.0, 10.0, 7.0, 7.0, 7.0, 8.0, 6.0, 6.0,
      12.0, 7.0, 13.0, 7.0, 10.0, 6.0, 9.0, 8.0, 7.0, 6.0, 12.0, 10.0, 10.0, 6.0,
      2.0, 2.0, 4.0, 5.0, 11.0, 6.0, 5.0, 9.0, 11.0, 7.0, 8.0, 7.0, 13.0, 8.0, 8.0,
      10.0, 10.0, 7.0, 13.0, 10.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058351166589555775
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022655593743443104
    mean_inference_ms: 1.111520339598944
    mean_raw_obs_processing_ms: 0.25412850203667475
time_since_restore: 1803.0567817687988
time_this_iter_s: 10.126795053482056
time_total_s: 1803.0567817687988
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001635
timesteps_total: 2395850
training_iteration: 178
trial_id: default
train step: 179
agent_timesteps_total: 2409450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018995437981947413
  StateBufferConnector_ms: 0.003331337334974757
  ViewRequirementAgentConnector_ms: 0.11400141805972692
counters:
  num_agent_steps_sampled: 2409450
  num_agent_steps_trained: 2392500
  num_env_steps_sampled: 2409450
  num_env_steps_trained: 2392500
  num_samples_added_to_queue: 2409000
  num_training_step_calls_since_last_synch_worker_weights: 687
  num_weight_broadcasts: 47507
custom_metrics: {}
date: 2023-08-14_17-27-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.660377358490566
episode_reward_min: 1.0
episodes_this_iter: 106
episodes_total: 18824
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6677328944206238
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 10.424638748168945
        total_loss: 23.44512176513672
        var_gnorm: 64.67630767822266
        vf_explained_var: 0.9618764519691467
        vf_loss: 32.71829605102539
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4785.0
  learner_queue:
    size_count: 4790
    size_mean: 15.46
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1525623627379127
  num_agent_steps_sampled: 2409450
  num_agent_steps_trained: 2392500
  num_env_steps_sampled: 2409450
  num_env_steps_trained: 2392500
  num_samples_added_to_queue: 2409000
  num_training_step_calls_since_last_synch_worker_weights: 687
  num_weight_broadcasts: 47507
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 225.149
    learner_load_time_ms: 2.239
    learner_load_wait_time_ms: 1.458
iterations_since_restore: 179
node_ip: 127.0.0.1
num_agent_steps_sampled: 2409450
num_agent_steps_trained: 2392500
num_env_steps_sampled: 2409450
num_env_steps_sampled_this_iter: 13600
num_env_steps_sampled_throughput_per_sec: 1359.9936123194307
num_env_steps_trained: 2392500
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9936592876702
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 44.87857142857143
  ram_util_percent: 72.72857142857144
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05835028240401917
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02265241848180239
  mean_inference_ms: 1.1114583826004147
  mean_raw_obs_processing_ms: 0.25410879798527497
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018995437981947413
    StateBufferConnector_ms: 0.003331337334974757
    ViewRequirementAgentConnector_ms: 0.11400141805972692
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.660377358490566
  episode_reward_min: 1.0
  episodes_this_iter: 106
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 7.0, 8.0, 7.0, 9.0, 9.0, 9.0, 10.0, 11.0, 7.0, 11.0, 10.0,
      11.0, 7.0, 5.0, 6.0, 10.0, 1.0, 9.0, 6.0, 6.0, 9.0, 6.0, 8.0, 9.0, 8.0, 7.0,
      11.0, 12.0, 6.0, 5.0, 8.0, 13.0, 10.0, 4.0, 8.0, 12.0, 8.0, 9.0, 11.0, 11.0,
      11.0, 15.0, 7.0, 12.0, 8.0, 10.0, 10.0, 8.0, 12.0, 9.0, 10.0, 10.0, 5.0, 7.0,
      5.0, 8.0, 10.0, 3.0, 7.0, 6.0, 10.0, 8.0, 6.0, 14.0, 10.0, 6.0, 9.0, 9.0, 6.0,
      5.0, 8.0, 9.0, 8.0, 7.0, 9.0, 6.0, 8.0, 5.0, 7.0, 5.0, 9.0, 13.0, 8.0, 9.0,
      7.0, 11.0, 9.0, 9.0, 13.0, 9.0, 12.0, 10.0, 9.0, 6.0, 13.0, 12.0, 6.0, 10.0,
      11.0, 10.0, 9.0, 10.0, 8.0, 9.0, 15.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05835028240401917
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02265241848180239
    mean_inference_ms: 1.1114583826004147
    mean_raw_obs_processing_ms: 0.25410879798527497
time_since_restore: 1813.1711556911469
time_this_iter_s: 10.114373922348022
time_total_s: 1813.1711556911469
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.045
timestamp: 1692001645
timesteps_total: 2409450
training_iteration: 179
trial_id: default
train step: 180
agent_timesteps_total: 2423150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.018880764643351238
  StateBufferConnector_ms: 0.0032564004262288413
  ViewRequirementAgentConnector_ms: 0.11326714798256203
counters:
  num_agent_steps_sampled: 2423150
  num_agent_steps_trained: 2406500
  num_env_steps_sampled: 2423150
  num_env_steps_trained: 2406500
  num_samples_added_to_queue: 2423000
  num_training_step_calls_since_last_synch_worker_weights: 997
  num_weight_broadcasts: 47778
custom_metrics: {}
date: 2023-08-14_17-27-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 6.037037037037037
episode_reward_min: 0.0
episodes_this_iter: 108
episodes_total: 18932
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.17474675178527832
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -19.661575317382812
        total_loss: 16.819236755371094
        var_gnorm: 64.68954467773438
        vf_explained_var: 0.9575045704841614
        vf_loss: 74.70909118652344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4813.0
  learner_queue:
    size_count: 4817
    size_mean: 15.6
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 0.9591663046625439
  num_agent_steps_sampled: 2423150
  num_agent_steps_trained: 2406500
  num_env_steps_sampled: 2423150
  num_env_steps_trained: 2406500
  num_samples_added_to_queue: 2423000
  num_training_step_calls_since_last_synch_worker_weights: 997
  num_weight_broadcasts: 47778
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 239.766
    learner_load_time_ms: 2.242
    learner_load_wait_time_ms: 1.593
iterations_since_restore: 180
node_ip: 127.0.0.1
num_agent_steps_sampled: 2423150
num_agent_steps_trained: 2406500
num_env_steps_sampled: 2423150
num_env_steps_sampled_this_iter: 13700
num_env_steps_sampled_throughput_per_sec: 1369.999706029955
num_env_steps_trained: 2406500
num_env_steps_trained_this_iter: 14000
num_env_steps_trained_throughput_per_sec: 1399.9996995926547
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 14000
perf:
  cpu_util_percent: 44.66428571428571
  ram_util_percent: 72.78571428571426
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05834686868414588
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022647073863591476
  mean_inference_ms: 1.111343251945703
  mean_raw_obs_processing_ms: 0.25407761496509806
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.018880764643351238
    StateBufferConnector_ms: 0.0032564004262288413
    ViewRequirementAgentConnector_ms: 0.11326714798256203
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 6.037037037037037
  episode_reward_min: 0.0
  episodes_this_iter: 108
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 6.0, 8.0, 10.0, 11.0, 11.0, 10.0, 9.0, 11.0, 10.0, 10.0,
      9.0, 12.0, 7.0, 9.0, 6.0, 12.0, 13.0, 6.0, 7.0, 8.0, 9.0, 6.0, 4.0, 7.0, 5.0,
      7.0, 5.0, 7.0, 8.0, 2.0, 8.0, 10.0, 5.0, 7.0, 4.0, 4.0, 3.0, 2.0, 4.0, 2.0,
      3.0, 3.0, 2.0, 4.0, 2.0, 3.0, 7.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 9.0, 11.0,
      10.0, 10.0, 8.0, 9.0, 12.0, 11.0, 7.0, 9.0, 9.0, 7.0, 13.0, 7.0, 8.0, 10.0,
      12.0, 6.0, 13.0, 9.0, 6.0, 5.0, 4.0, 8.0, 9.0, 6.0, 4.0, 4.0, 1.0, 7.0, 12.0,
      2.0, 5.0, 5.0, 3.0, 3.0, 4.0, 2.0, 2.0, 0.0, 6.0, 3.0, 2.0, 4.0, 4.0, 2.0, 2.0,
      0.0, 3.0, 1.0, 3.0, 0.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05834686868414588
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022647073863591476
    mean_inference_ms: 1.111343251945703
    mean_raw_obs_processing_ms: 0.25407761496509806
time_since_restore: 1823.2714776992798
time_this_iter_s: 10.100322008132935
time_total_s: 1823.2714776992798
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001655
timesteps_total: 2423150
training_iteration: 180
trial_id: default
train step: 181
agent_timesteps_total: 2436500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020009508499732383
  StateBufferConnector_ms: 0.0034877887138953577
  ViewRequirementAgentConnector_ms: 0.12082732640779935
counters:
  num_agent_steps_sampled: 2436500
  num_agent_steps_trained: 2420000
  num_env_steps_sampled: 2436500
  num_env_steps_trained: 2420000
  num_samples_added_to_queue: 2436500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 48041
custom_metrics: {}
date: 2023-08-14_17-27-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 1.9134615384615385
episode_reward_min: 0.0
episodes_this_iter: 104
episodes_total: 19036
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.38361796736717224
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -23.70413589477539
        total_loss: 7.664925575256348
        var_gnorm: 64.69751739501953
        vf_explained_var: 0.8726587891578674
        vf_loss: 66.57430267333984
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4840.0
  learner_queue:
    size_count: 4843
    size_mean: 15.74
    size_quantiles: [13.0, 15.0, 16.0, 16.0, 16.0]
    size_std: 0.7158212067269312
  num_agent_steps_sampled: 2436500
  num_agent_steps_trained: 2420000
  num_env_steps_sampled: 2436500
  num_env_steps_trained: 2420000
  num_samples_added_to_queue: 2436500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 48041
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 271.619
    learner_load_time_ms: 2.235
    learner_load_wait_time_ms: 1.592
iterations_since_restore: 181
node_ip: 127.0.0.1
num_agent_steps_sampled: 2436500
num_agent_steps_trained: 2420000
num_env_steps_sampled: 2436500
num_env_steps_sampled_this_iter: 13350
num_env_steps_sampled_throughput_per_sec: 1334.448983146212
num_env_steps_trained: 2420000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.4427919456075
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 46.892857142857146
  ram_util_percent: 73.22142857142858
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05835216208949107
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0226442037527773
  mean_inference_ms: 1.1113954154824923
  mean_raw_obs_processing_ms: 0.25408303679543576
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020009508499732383
    StateBufferConnector_ms: 0.0034877887138953577
    ViewRequirementAgentConnector_ms: 0.12082732640779935
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 1.9134615384615385
  episode_reward_min: 0.0
  episodes_this_iter: 104
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 2.0, 4.0, 1.0, 0.0, 2.0, 1.0, 3.0, 6.0, 2.0, 1.0, 0.0, 2.0,
      2.0, 5.0, 0.0, 3.0, 1.0, 1.0, 5.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 8.0, 0.0, 1.0,
      0.0, 0.0, 2.0, 2.0, 0.0, 2.0, 3.0, 1.0, 1.0, 3.0, 1.0, 0.0, 0.0, 1.0, 2.0, 1.0,
      2.0, 4.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 4.0, 4.0, 5.0, 3.0, 0.0,
      5.0, 5.0, 3.0, 3.0, 2.0, 1.0, 3.0, 4.0, 6.0, 1.0, 0.0, 1.0, 2.0, 1.0, 2.0, 4.0,
      3.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 2.0, 1.0, 5.0, 0.0, 2.0, 5.0, 1.0,
      2.0, 0.0, 0.0, 5.0, 2.0, 0.0, 2.0, 0.0, 0.0, 2.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05835216208949107
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0226442037527773
    mean_inference_ms: 1.1113954154824923
    mean_raw_obs_processing_ms: 0.25408303679543576
time_since_restore: 1833.3508706092834
time_this_iter_s: 10.079392910003662
time_total_s: 1833.3508706092834
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.597
  training_iteration_time_ms: 2.152
timestamp: 1692001665
timesteps_total: 2436500
training_iteration: 181
trial_id: default
train step: 182
agent_timesteps_total: 2449300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021528244018554688
  StateBufferConnector_ms: 0.0036644935607910156
  ViewRequirementAgentConnector_ms: 0.1240091323852539
counters:
  num_agent_steps_sampled: 2449300
  num_agent_steps_trained: 2432500
  num_env_steps_sampled: 2449300
  num_env_steps_trained: 2432500
  num_samples_added_to_queue: 2449000
  num_training_step_calls_since_last_synch_worker_weights: 13
  num_weight_broadcasts: 48295
custom_metrics: {}
date: 2023-08-14_17-27-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 0.95
episode_reward_min: 0.0
episodes_this_iter: 100
episodes_total: 19136
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.1552886664867401
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 4.711974620819092
        total_loss: 242.51217651367188
        var_gnorm: 64.70417785644531
        vf_explained_var: 0.45902150869369507
        vf_loss: 477.1532897949219
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4865.0
  learner_queue:
    size_count: 4871
    size_mean: 15.58
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.06
  num_agent_steps_sampled: 2449300
  num_agent_steps_trained: 2432500
  num_env_steps_sampled: 2449300
  num_env_steps_trained: 2432500
  num_samples_added_to_queue: 2449000
  num_training_step_calls_since_last_synch_worker_weights: 13
  num_weight_broadcasts: 48295
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 205.33
    learner_load_time_ms: 1.381
    learner_load_wait_time_ms: 1.607
iterations_since_restore: 182
node_ip: 127.0.0.1
num_agent_steps_sampled: 2449300
num_agent_steps_trained: 2432500
num_env_steps_sampled: 2449300
num_env_steps_sampled_this_iter: 12800
num_env_steps_sampled_throughput_per_sec: 1279.9934997888695
num_env_steps_trained: 2432500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9936521375678
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 50.72
  ram_util_percent: 73.31999999999998
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05837230635679015
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02264843573499364
  mean_inference_ms: 1.1116868770661135
  mean_raw_obs_processing_ms: 0.25415218698996617
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021528244018554688
    StateBufferConnector_ms: 0.0036644935607910156
    ViewRequirementAgentConnector_ms: 0.1240091323852539
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 0.95
  episode_reward_min: 0.0
  episodes_this_iter: 100
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0,
      0.0, 0.0, 2.0, 0.0, 1.0, 5.0, 2.0, 0.0, 0.0, 0.0, 3.0, 1.0, 0.0, 0.0, 1.0, 0.0,
      2.0, 1.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 3.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0,
      1.0, 0.0, 1.0, 1.0, 1.0, 0.0, 3.0, 1.0, 3.0, 0.0, 0.0, 0.0, 0.0, 1.0, 2.0, 0.0,
      0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 0.0,
      1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 2.0,
      0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05837230635679015
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02264843573499364
    mean_inference_ms: 1.1116868770661135
    mean_raw_obs_processing_ms: 0.25415218698996617
time_since_restore: 1843.5299367904663
time_this_iter_s: 10.179066181182861
time_total_s: 1843.5299367904663
timers:
  sample_time_ms: 0.021
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.057
timestamp: 1692001675
timesteps_total: 2449300
training_iteration: 182
trial_id: default
train step: 183
agent_timesteps_total: 2460000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.025484800338745117
  StateBufferConnector_ms: 0.004889488220214844
  ViewRequirementAgentConnector_ms: 0.1564493179321289
counters:
  num_agent_steps_sampled: 2460000
  num_agent_steps_trained: 2443500
  num_env_steps_sampled: 2460000
  num_env_steps_trained: 2443500
  num_samples_added_to_queue: 2460000
  num_training_step_calls_since_last_synch_worker_weights: 290
  num_weight_broadcasts: 48506
custom_metrics: {}
date: 2023-08-14_17-28-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.15
episode_reward_min: 0.0
episodes_this_iter: 83
episodes_total: 19219
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.7238568663597107
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 0.09932148456573486
        total_loss: -2.693535566329956
        var_gnorm: 64.704833984375
        vf_explained_var: 0.9877411127090454
        vf_loss: 1.6528546810150146
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4887.0
  learner_queue:
    size_count: 4892
    size_mean: 15.24
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3499629624548966
  num_agent_steps_sampled: 2460000
  num_agent_steps_trained: 2443500
  num_env_steps_sampled: 2460000
  num_env_steps_trained: 2443500
  num_samples_added_to_queue: 2460000
  num_training_step_calls_since_last_synch_worker_weights: 290
  num_weight_broadcasts: 48506
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 202.602
    learner_load_time_ms: 1.396
    learner_load_wait_time_ms: 1.656
iterations_since_restore: 183
node_ip: 127.0.0.1
num_agent_steps_sampled: 2460000
num_agent_steps_trained: 2443500
num_env_steps_sampled: 2460000
num_env_steps_sampled_this_iter: 10700
num_env_steps_sampled_throughput_per_sec: 1069.9976530126553
num_env_steps_trained: 2443500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9975872092718
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 59.57142857142857
  ram_util_percent: 75.00714285714285
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05858697082586591
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022656218265199656
  mean_inference_ms: 1.1123455871723344
  mean_raw_obs_processing_ms: 0.254372684157033
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.025484800338745117
    StateBufferConnector_ms: 0.004889488220214844
    ViewRequirementAgentConnector_ms: 0.1564493179321289
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.15
  episode_reward_min: 0.0
  episodes_this_iter: 83
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 0.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 2.0, 2.0, 0.0, 0.0, 0.0,
      0.0, 1.0, 0.0, 2.0, 4.0, 7.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 5.0, 4.0,
      0.0, 6.0, 3.0, 4.0, 3.0, 7.0, 6.0, 4.0, 4.0, 4.0, 4.0, 9.0, 5.0, 6.0, 5.0, 5.0,
      4.0, 7.0, 6.0, 2.0, 6.0, 4.0, 5.0, 2.0, 10.0, 10.0, 9.0, 4.0, 5.0, 1.0, 2.0,
      4.0, 2.0, 5.0, 2.0, 3.0, 5.0, 1.0, 2.0, 3.0, 6.0, 7.0, 4.0, 5.0, 6.0, 3.0, 2.0,
      4.0, 5.0, 4.0, 5.0, 4.0, 9.0, 3.0, 3.0, 10.0, 5.0, 4.0, 7.0, 5.0, 9.0, 6.0,
      7.0, 4.0, 11.0, 7.0, 7.0, 9.0, 8.0, 11.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05858697082586591
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022656218265199656
    mean_inference_ms: 1.1123455871723344
    mean_raw_obs_processing_ms: 0.254372684157033
time_since_restore: 1853.654799938202
time_this_iter_s: 10.124863147735596
time_total_s: 1853.654799938202
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.043
timestamp: 1692001686
timesteps_total: 2460000
training_iteration: 183
trial_id: default
train step: 184
agent_timesteps_total: 2471100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02346944808959961
  StateBufferConnector_ms: 0.0040776729583740234
  ViewRequirementAgentConnector_ms: 0.13652992248535156
counters:
  num_agent_steps_sampled: 2471100
  num_agent_steps_trained: 2454500
  num_env_steps_sampled: 2471100
  num_env_steps_trained: 2454500
  num_samples_added_to_queue: 2471000
  num_training_step_calls_since_last_synch_worker_weights: 593
  num_weight_broadcasts: 48725
custom_metrics: {}
date: 2023-08-14_17-28-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 6.4
episode_reward_min: 2.0
episodes_this_iter: 87
episodes_total: 19306
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.100000000000364
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6366448998451233
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 7.334056854248047
        total_loss: 22.311342239379883
        var_gnorm: 64.7054214477539
        vf_explained_var: 0.8933811783790588
        vf_loss: 36.32101821899414
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4909.0
  learner_queue:
    size_count: 4914
    size_mean: 15.02
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5031965939290843
  num_agent_steps_sampled: 2471100
  num_agent_steps_trained: 2454500
  num_env_steps_sampled: 2471100
  num_env_steps_trained: 2454500
  num_samples_added_to_queue: 2471000
  num_training_step_calls_since_last_synch_worker_weights: 593
  num_weight_broadcasts: 48725
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 208.026
    learner_load_time_ms: 1.405
    learner_load_wait_time_ms: 1.546
iterations_since_restore: 184
node_ip: 127.0.0.1
num_agent_steps_sampled: 2471100
num_agent_steps_trained: 2454500
num_env_steps_sampled: 2471100
num_env_steps_sampled_this_iter: 11100
num_env_steps_sampled_throughput_per_sec: 1109.993992599575
num_env_steps_trained: 2454500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.9940467202996
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 57.47857142857142
  ram_util_percent: 77.51428571428572
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0585970481354593
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022692729108608187
  mean_inference_ms: 1.113640542825935
  mean_raw_obs_processing_ms: 0.25461137350076973
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02346944808959961
    StateBufferConnector_ms: 0.0040776729583740234
    ViewRequirementAgentConnector_ms: 0.13652992248535156
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 6.4
  episode_reward_min: 2.0
  episodes_this_iter: 87
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 5.0, 9.0, 6.0, 7.0, 4.0, 11.0, 7.0, 7.0, 9.0, 8.0, 11.0,
      7.0, 7.0, 8.0, 5.0, 7.0, 9.0, 2.0, 4.0, 10.0, 8.0, 5.0, 8.0, 10.0, 4.0, 4.0,
      7.0, 8.0, 5.0, 4.0, 6.0, 6.0, 8.0, 4.0, 8.0, 5.0, 4.0, 7.0, 3.0, 6.0, 7.0, 7.0,
      4.0, 6.0, 4.0, 6.0, 6.0, 5.0, 10.0, 4.0, 6.0, 5.0, 11.0, 2.0, 3.0, 6.0, 8.0,
      15.0, 3.0, 6.0, 7.0, 6.0, 5.0, 6.0, 9.0, 7.0, 3.0, 5.0, 7.0, 6.0, 4.0, 6.0,
      5.0, 7.0, 6.0, 5.0, 9.0, 6.0, 7.0, 4.0, 7.0, 8.0, 9.0, 5.0, 9.0, 10.0, 4.0,
      6.0, 8.0, 11.0, 6.0, 5.0, 4.0, 7.0, 5.0, 9.0, 3.0, 4.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0585970481354593
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022692729108608187
    mean_inference_ms: 1.113640542825935
    mean_raw_obs_processing_ms: 0.25461137350076973
time_since_restore: 1863.7950549125671
time_this_iter_s: 10.140254974365234
time_total_s: 1863.7950549125671
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692001696
timesteps_total: 2471100
training_iteration: 184
trial_id: default
train step: 185
agent_timesteps_total: 2483300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021087169647216797
  StateBufferConnector_ms: 0.003681182861328125
  ViewRequirementAgentConnector_ms: 0.12698054313659668
counters:
  num_agent_steps_sampled: 2483300
  num_agent_steps_trained: 2466500
  num_env_steps_sampled: 2483300
  num_env_steps_trained: 2466500
  num_samples_added_to_queue: 2483000
  num_training_step_calls_since_last_synch_worker_weights: 858
  num_weight_broadcasts: 48965
custom_metrics: {}
date: 2023-08-14_17-28-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 3.97
episode_reward_min: 0.0
episodes_this_iter: 95
episodes_total: 19401
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6792899370193481
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -3.634936809539795
        total_loss: 4.393914222717285
        var_gnorm: 64.70948028564453
        vf_explained_var: 0.878364086151123
        vf_loss: 22.850601196289062
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4933.0
  learner_queue:
    size_count: 4938
    size_mean: 15.08
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4538225476309
  num_agent_steps_sampled: 2483300
  num_agent_steps_trained: 2466500
  num_env_steps_sampled: 2483300
  num_env_steps_trained: 2466500
  num_samples_added_to_queue: 2483000
  num_training_step_calls_since_last_synch_worker_weights: 858
  num_weight_broadcasts: 48965
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 233.091
    learner_load_time_ms: 1.412
    learner_load_wait_time_ms: 1.582
iterations_since_restore: 185
node_ip: 127.0.0.1
num_agent_steps_sampled: 2483300
num_agent_steps_trained: 2466500
num_env_steps_sampled: 2483300
num_env_steps_sampled_this_iter: 12200
num_env_steps_sampled_throughput_per_sec: 1219.9989237794832
num_env_steps_trained: 2466500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9989414224426
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 54.07333333333334
  ram_util_percent: 78.8
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05858448259986901
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022716502482466892
  mean_inference_ms: 1.1144397534660684
  mean_raw_obs_processing_ms: 0.25476214421546783
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021087169647216797
    StateBufferConnector_ms: 0.003681182861328125
    ViewRequirementAgentConnector_ms: 0.12698054313659668
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 3.97
  episode_reward_min: 0.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 9.0, 3.0, 4.0, 6.0, 11.0, 8.0, 5.0, 3.0, 9.0, 7.0, 5.0,
      7.0, 6.0, 8.0, 6.0, 7.0, 4.0, 4.0, 7.0, 8.0, 7.0, 5.0, 6.0, 9.0, 8.0, 4.0, 2.0,
      4.0, 5.0, 5.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 0.0, 2.0,
      2.0, 2.0, 3.0, 0.0, 0.0, 1.0, 3.0, 2.0, 6.0, 3.0, 5.0, 7.0, 7.0, 2.0, 8.0, 9.0,
      6.0, 6.0, 3.0, 9.0, 4.0, 8.0, 6.0, 9.0, 5.0, 4.0, 6.0, 2.0, 6.0, 4.0, 9.0, 6.0,
      0.0, 1.0, 1.0, 1.0, 3.0, 4.0, 6.0, 3.0, 0.0, 0.0, 4.0, 1.0, 1.0, 3.0, 3.0, 0.0,
      1.0, 2.0, 0.0, 0.0, 1.0, 5.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05858448259986901
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022716502482466892
    mean_inference_ms: 1.1144397534660684
    mean_raw_obs_processing_ms: 0.25476214421546783
time_since_restore: 1873.942851781845
time_this_iter_s: 10.147796869277954
time_total_s: 1873.942851781845
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001706
timesteps_total: 2483300
training_iteration: 185
trial_id: default
train step: 186
agent_timesteps_total: 2496300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.020236595004212623
  StateBufferConnector_ms: 0.0035416846181832106
  ViewRequirementAgentConnector_ms: 0.12081230387968175
counters:
  num_agent_steps_sampled: 2496300
  num_agent_steps_trained: 2479500
  num_env_steps_sampled: 2496300
  num_env_steps_trained: 2479500
  num_samples_added_to_queue: 2496000
  num_training_step_calls_since_last_synch_worker_weights: 170
  num_weight_broadcasts: 49222
custom_metrics: {}
date: 2023-08-14_17-28-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 7.0588235294117645
episode_reward_min: 0.0
episodes_this_iter: 102
episodes_total: 19503
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.43271562457084656
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 3.480292558670044
        total_loss: 10.797743797302246
        var_gnorm: 64.71390533447266
        vf_explained_var: 0.9384732842445374
        vf_loss: 18.962059020996094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4959.0
  learner_queue:
    size_count: 4966
    size_mean: 15.2
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5099668870541498
  num_agent_steps_sampled: 2496300
  num_agent_steps_trained: 2479500
  num_env_steps_sampled: 2496300
  num_env_steps_trained: 2479500
  num_samples_added_to_queue: 2496000
  num_training_step_calls_since_last_synch_worker_weights: 170
  num_weight_broadcasts: 49222
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 156.582
    learner_load_time_ms: 1.437
    learner_load_wait_time_ms: 1.494
iterations_since_restore: 186
node_ip: 127.0.0.1
num_agent_steps_sampled: 2496300
num_agent_steps_trained: 2479500
num_env_steps_sampled: 2496300
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9945140116458
num_env_steps_trained: 2479500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9945140116458
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 46.964285714285715
  ram_util_percent: 78.28571428571426
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0585517523966336
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022730502071562846
  mean_inference_ms: 1.1148162088378477
  mean_raw_obs_processing_ms: 0.25481505573259083
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.020236595004212623
    StateBufferConnector_ms: 0.0035416846181832106
    ViewRequirementAgentConnector_ms: 0.12081230387968175
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 7.0588235294117645
  episode_reward_min: 0.0
  episodes_this_iter: 102
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 4.0, 8.0, 8.0, 6.0, 2.0, 3.0, 6.0, 2.0, 6.0, 3.0, 8.0, 9.0,
      6.0, 0.0, 5.0, 5.0, 12.0, 8.0, 6.0, 9.0, 7.0, 8.0, 8.0, 5.0, 10.0, 7.0, 8.0,
      10.0, 6.0, 7.0, 6.0, 10.0, 7.0, 8.0, 2.0, 6.0, 10.0, 7.0, 6.0, 4.0, 11.0, 8.0,
      5.0, 9.0, 7.0, 4.0, 11.0, 9.0, 6.0, 10.0, 8.0, 1.0, 5.0, 6.0, 6.0, 12.0, 10.0,
      7.0, 14.0, 9.0, 5.0, 4.0, 3.0, 4.0, 3.0, 9.0, 8.0, 7.0, 7.0, 9.0, 7.0, 9.0,
      10.0, 8.0, 11.0, 6.0, 6.0, 8.0, 6.0, 8.0, 11.0, 12.0, 15.0, 5.0, 10.0, 8.0,
      10.0, 13.0, 10.0, 8.0, 7.0, 6.0, 3.0, 3.0, 2.0, 5.0, 12.0, 9.0, 5.0, 6.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0585517523966336
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022730502071562846
    mean_inference_ms: 1.1148162088378477
    mean_raw_obs_processing_ms: 0.25481505573259083
time_since_restore: 1884.1207857131958
time_this_iter_s: 10.177933931350708
time_total_s: 1884.1207857131958
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001716
timesteps_total: 2496300
training_iteration: 186
trial_id: default
train step: 187
agent_timesteps_total: 2509300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.019953746606807897
  StateBufferConnector_ms: 0.003394986143206606
  ViewRequirementAgentConnector_ms: 0.11893215745982558
counters:
  num_agent_steps_sampled: 2509300
  num_agent_steps_trained: 2492500
  num_env_steps_sampled: 2509300
  num_env_steps_trained: 2492500
  num_samples_added_to_queue: 2509000
  num_training_step_calls_since_last_synch_worker_weights: 1499
  num_weight_broadcasts: 49476
custom_metrics: {}
date: 2023-08-14_17-28-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 6.247524752475248
episode_reward_min: 2.0
episodes_this_iter: 101
episodes_total: 19604
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5923747420310974
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 2.1103768348693848
        total_loss: 62.72543716430664
        var_gnorm: 64.72233581542969
        vf_explained_var: 0.8149204254150391
        vf_loss: 127.15386962890625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 4985.0
  learner_queue:
    size_count: 4989
    size_mean: 15.24
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4636939570825591
  num_agent_steps_sampled: 2509300
  num_agent_steps_trained: 2492500
  num_env_steps_sampled: 2509300
  num_env_steps_trained: 2492500
  num_samples_added_to_queue: 2509000
  num_training_step_calls_since_last_synch_worker_weights: 1499
  num_weight_broadcasts: 49476
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 265.728
    learner_load_time_ms: 1.428
    learner_load_wait_time_ms: 1.632
iterations_since_restore: 187
node_ip: 127.0.0.1
num_agent_steps_sampled: 2509300
num_agent_steps_trained: 2492500
num_env_steps_sampled: 2509300
num_env_steps_sampled_this_iter: 13000
num_env_steps_sampled_throughput_per_sec: 1299.9963736635275
num_env_steps_trained: 2492500
num_env_steps_trained_this_iter: 13000
num_env_steps_trained_throughput_per_sec: 1299.9963736635275
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13000
perf:
  cpu_util_percent: 51.192857142857136
  ram_util_percent: 78.1857142857143
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.0585583287606126
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022736328003022967
  mean_inference_ms: 1.1150061767676063
  mean_raw_obs_processing_ms: 0.25485472068692216
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.019953746606807897
    StateBufferConnector_ms: 0.003394986143206606
    ViewRequirementAgentConnector_ms: 0.11893215745982558
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 6.247524752475248
  episode_reward_min: 2.0
  episodes_this_iter: 101
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 8.0, 4.0, 5.0, 3.0, 4.0, 6.0, 5.0, 7.0, 9.0, 4.0, 3.0, 3.0,
      8.0, 12.0, 6.0, 6.0, 6.0, 11.0, 2.0, 9.0, 6.0, 6.0, 6.0, 8.0, 6.0, 5.0, 2.0,
      9.0, 10.0, 4.0, 8.0, 2.0, 7.0, 8.0, 7.0, 7.0, 2.0, 6.0, 7.0, 5.0, 7.0, 4.0,
      6.0, 6.0, 6.0, 8.0, 5.0, 6.0, 6.0, 3.0, 5.0, 4.0, 8.0, 5.0, 7.0, 4.0, 6.0, 7.0,
      6.0, 8.0, 8.0, 9.0, 2.0, 7.0, 6.0, 8.0, 7.0, 11.0, 5.0, 6.0, 11.0, 5.0, 10.0,
      4.0, 6.0, 7.0, 8.0, 10.0, 5.0, 7.0, 6.0, 8.0, 7.0, 3.0, 8.0, 10.0, 3.0, 7.0,
      7.0, 4.0, 7.0, 2.0, 6.0, 4.0, 7.0, 7.0, 4.0, 6.0, 11.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.0585583287606126
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022736328003022967
    mean_inference_ms: 1.1150061767676063
    mean_raw_obs_processing_ms: 0.25485472068692216
time_since_restore: 1894.2278459072113
time_this_iter_s: 10.107060194015503
time_total_s: 1894.2278459072113
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1692001726
timesteps_total: 2509300
training_iteration: 187
trial_id: default
train step: 188
agent_timesteps_total: 2522700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.01976490020751953
  StateBufferConnector_ms: 0.003307887486049107
  ViewRequirementAgentConnector_ms: 0.116708619253976
counters:
  num_agent_steps_sampled: 2522700
  num_agent_steps_trained: 2506000
  num_env_steps_sampled: 2522700
  num_env_steps_trained: 2506000
  num_samples_added_to_queue: 2522500
  num_training_step_calls_since_last_synch_worker_weights: 432
  num_weight_broadcasts: 49739
custom_metrics: {}
date: 2023-08-14_17-28-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 6.190476190476191
episode_reward_min: 0.0
episodes_this_iter: 105
episodes_total: 19709
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6686504483222961
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 5.218591690063477
        total_loss: 13.958837509155273
        var_gnorm: 64.7242202758789
        vf_explained_var: 0.9357790946960449
        vf_loss: 24.1669979095459
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5012.0
  learner_queue:
    size_count: 5018
    size_mean: 15.52
    size_quantiles: [11.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.1178550889985697
  num_agent_steps_sampled: 2522700
  num_agent_steps_trained: 2506000
  num_env_steps_sampled: 2522700
  num_env_steps_trained: 2506000
  num_samples_added_to_queue: 2522500
  num_training_step_calls_since_last_synch_worker_weights: 432
  num_weight_broadcasts: 49739
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 177.636
    learner_load_time_ms: 1.43
    learner_load_wait_time_ms: 1.452
iterations_since_restore: 188
node_ip: 127.0.0.1
num_agent_steps_sampled: 2522700
num_agent_steps_trained: 2506000
num_env_steps_sampled: 2522700
num_env_steps_sampled_this_iter: 13400
num_env_steps_sampled_throughput_per_sec: 1339.9983706494115
num_env_steps_trained: 2506000
num_env_steps_trained_this_iter: 13500
num_env_steps_trained_throughput_per_sec: 1349.9983584900788
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 13500
perf:
  cpu_util_percent: 50.01333333333333
  ram_util_percent: 78.25999999999999
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05858130677895447
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022734652850330803
  mean_inference_ms: 1.1149827815997235
  mean_raw_obs_processing_ms: 0.2548654911455087
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.01976490020751953
    StateBufferConnector_ms: 0.003307887486049107
    ViewRequirementAgentConnector_ms: 0.116708619253976
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 6.190476190476191
  episode_reward_min: 0.0
  episodes_this_iter: 105
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 7.0, 3.0, 5.0, 6.0, 10.0, 7.0, 4.0, 7.0, 7.0, 8.0, 9.0,
      5.0, 6.0, 6.0, 4.0, 7.0, 4.0, 8.0, 5.0, 7.0, 6.0, 7.0, 9.0, 11.0, 11.0, 6.0,
      4.0, 7.0, 9.0, 4.0, 5.0, 5.0, 10.0, 3.0, 5.0, 10.0, 3.0, 10.0, 4.0, 10.0, 7.0,
      5.0, 7.0, 6.0, 2.0, 6.0, 5.0, 6.0, 6.0, 11.0, 5.0, 8.0, 3.0, 7.0, 7.0, 7.0,
      4.0, 6.0, 6.0, 3.0, 8.0, 7.0, 7.0, 7.0, 9.0, 10.0, 6.0, 7.0, 6.0, 5.0, 7.0,
      5.0, 7.0, 7.0, 10.0, 5.0, 5.0, 3.0, 7.0, 8.0, 8.0, 5.0, 4.0, 9.0, 3.0, 6.0,
      8.0, 5.0, 8.0, 4.0, 8.0, 4.0, 4.0, 7.0, 5.0, 0.0, 6.0, 2.0, 1.0, 8.0, 4.0, 6.0,
      4.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05858130677895447
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022734652850330803
    mean_inference_ms: 1.1149827815997235
    mean_raw_obs_processing_ms: 0.2548654911455087
time_since_restore: 1904.39226770401
time_this_iter_s: 10.164421796798706
time_total_s: 1904.39226770401
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.044
timestamp: 1692001736
timesteps_total: 2522700
training_iteration: 188
trial_id: default
train step: 189
agent_timesteps_total: 2534750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.022336721420288086
  StateBufferConnector_ms: 0.003931760787963867
  ViewRequirementAgentConnector_ms: 0.13016557693481445
counters:
  num_agent_steps_sampled: 2534750
  num_agent_steps_trained: 2518000
  num_env_steps_sampled: 2534750
  num_env_steps_trained: 2518000
  num_samples_added_to_queue: 2534500
  num_training_step_calls_since_last_synch_worker_weights: 335
  num_weight_broadcasts: 49976
custom_metrics: {}
date: 2023-08-14_17-29-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.11
episode_reward_min: 3.0
episodes_this_iter: 95
episodes_total: 19804
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6545999050140381
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -43.15644836425781
        total_loss: 2.0696823596954346
        var_gnorm: 64.73124694824219
        vf_explained_var: 0.8020769953727722
        vf_loss: 96.99826049804688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5036.0
  learner_queue:
    size_count: 5043
    size_mean: 15.08
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6833300330000647
  num_agent_steps_sampled: 2534750
  num_agent_steps_trained: 2518000
  num_env_steps_sampled: 2534750
  num_env_steps_trained: 2518000
  num_samples_added_to_queue: 2534500
  num_training_step_calls_since_last_synch_worker_weights: 335
  num_weight_broadcasts: 49976
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 184.949
    learner_load_time_ms: 1.47
    learner_load_wait_time_ms: 1.851
iterations_since_restore: 189
node_ip: 127.0.0.1
num_agent_steps_sampled: 2534750
num_agent_steps_trained: 2518000
num_env_steps_sampled: 2534750
num_env_steps_sampled_this_iter: 12050
num_env_steps_sampled_throughput_per_sec: 1204.9954320365503
num_env_steps_trained: 2518000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9954509907554
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 54.04285714285715
  ram_util_percent: 78.29285714285713
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05864142200765997
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022747817663852733
  mean_inference_ms: 1.115518680508251
  mean_raw_obs_processing_ms: 0.25500494723693107
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.022336721420288086
    StateBufferConnector_ms: 0.003931760787963867
    ViewRequirementAgentConnector_ms: 0.13016557693481445
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.11
  episode_reward_min: 3.0
  episodes_this_iter: 95
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 4.0, 6.0, 4.0, 8.0, 5.0, 6.0, 9.0, 12.0, 11.0, 8.0, 6.0,
      8.0, 6.0, 10.0, 9.0, 12.0, 6.0, 9.0, 8.0, 12.0, 11.0, 8.0, 6.0, 6.0, 5.0, 5.0,
      12.0, 5.0, 11.0, 7.0, 8.0, 12.0, 6.0, 4.0, 7.0, 6.0, 9.0, 9.0, 10.0, 7.0, 5.0,
      11.0, 10.0, 6.0, 12.0, 9.0, 7.0, 7.0, 8.0, 9.0, 7.0, 6.0, 7.0, 12.0, 9.0, 6.0,
      8.0, 10.0, 8.0, 8.0, 4.0, 7.0, 7.0, 3.0, 11.0, 9.0, 9.0, 10.0, 8.0, 8.0, 8.0,
      9.0, 9.0, 12.0, 8.0, 6.0, 10.0, 9.0, 11.0, 10.0, 9.0, 8.0, 6.0, 13.0, 9.0, 8.0,
      8.0, 8.0, 10.0, 10.0, 6.0, 14.0, 3.0, 7.0, 6.0, 10.0, 10.0, 6.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05864142200765997
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022747817663852733
    mean_inference_ms: 1.115518680508251
    mean_raw_obs_processing_ms: 0.25500494723693107
time_since_restore: 1914.6252098083496
time_this_iter_s: 10.2329421043396
time_total_s: 1914.6252098083496
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.067
timestamp: 1692001747
timesteps_total: 2534750
training_iteration: 189
trial_id: default
train step: 190
agent_timesteps_total: 2546450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02304244041442871
  StateBufferConnector_ms: 0.003924846649169922
  ViewRequirementAgentConnector_ms: 0.13153934478759766
counters:
  num_agent_steps_sampled: 2546450
  num_agent_steps_trained: 2529500
  num_env_steps_sampled: 2546450
  num_env_steps_trained: 2529500
  num_samples_added_to_queue: 2546000
  num_training_step_calls_since_last_synch_worker_weights: 1237
  num_weight_broadcasts: 50206
custom_metrics: {}
date: 2023-08-14_17-29-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 7.96
episode_reward_min: 3.0
episodes_this_iter: 90
episodes_total: 19894
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6981663107872009
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -20.00174331665039
        total_loss: 28.299776077270508
        var_gnorm: 64.73529052734375
        vf_explained_var: 0.8122866153717041
        vf_loss: 103.58470153808594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5059.0
  learner_queue:
    size_count: 5064
    size_mean: 14.66
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8932511719262186
  num_agent_steps_sampled: 2546450
  num_agent_steps_trained: 2529500
  num_env_steps_sampled: 2546450
  num_env_steps_trained: 2529500
  num_samples_added_to_queue: 2546000
  num_training_step_calls_since_last_synch_worker_weights: 1237
  num_weight_broadcasts: 50206
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 228.153
    learner_load_time_ms: 1.478
    learner_load_wait_time_ms: 1.663
iterations_since_restore: 190
node_ip: 127.0.0.1
num_agent_steps_sampled: 2546450
num_agent_steps_trained: 2529500
num_env_steps_sampled: 2546450
num_env_steps_sampled_this_iter: 11700
num_env_steps_sampled_throughput_per_sec: 1169.996011032353
num_env_steps_trained: 2529500
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.9960792198342
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 56.10000000000001
  ram_util_percent: 79.2
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058735649490765346
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022761503603748342
  mean_inference_ms: 1.1161008052310855
  mean_raw_obs_processing_ms: 0.2551488043937768
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02304244041442871
    StateBufferConnector_ms: 0.003924846649169922
    ViewRequirementAgentConnector_ms: 0.13153934478759766
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 7.96
  episode_reward_min: 3.0
  episodes_this_iter: 90
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 6.0, 14.0, 3.0, 7.0, 6.0, 10.0, 10.0, 6.0, 6.0, 7.0, 13.0,
      5.0, 8.0, 4.0, 9.0, 8.0, 7.0, 10.0, 10.0, 7.0, 4.0, 6.0, 10.0, 8.0, 13.0, 9.0,
      8.0, 7.0, 8.0, 12.0, 7.0, 8.0, 10.0, 14.0, 12.0, 4.0, 6.0, 9.0, 9.0, 6.0, 9.0,
      7.0, 6.0, 8.0, 5.0, 7.0, 5.0, 8.0, 11.0, 9.0, 4.0, 8.0, 9.0, 6.0, 5.0, 7.0,
      7.0, 6.0, 11.0, 9.0, 6.0, 9.0, 13.0, 9.0, 11.0, 3.0, 7.0, 4.0, 8.0, 14.0, 7.0,
      6.0, 4.0, 6.0, 8.0, 8.0, 3.0, 9.0, 7.0, 9.0, 6.0, 7.0, 12.0, 7.0, 7.0, 9.0,
      8.0, 13.0, 7.0, 11.0, 8.0, 6.0, 10.0, 9.0, 4.0, 10.0, 8.0, 9.0, 11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058735649490765346
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022761503603748342
    mean_inference_ms: 1.1161008052310855
    mean_raw_obs_processing_ms: 0.2551488043937768
time_since_restore: 1924.7440373897552
time_this_iter_s: 10.11882758140564
time_total_s: 1924.7440373897552
timers:
  sample_time_ms: 0.014
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.042
timestamp: 1692001757
timesteps_total: 2546450
training_iteration: 190
trial_id: default
train step: 191
agent_timesteps_total: 2558750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02046942710876465
  StateBufferConnector_ms: 0.0035021305084228516
  ViewRequirementAgentConnector_ms: 0.12071871757507324
counters:
  num_agent_steps_sampled: 2558750
  num_agent_steps_trained: 2542000
  num_env_steps_sampled: 2558750
  num_env_steps_trained: 2542000
  num_samples_added_to_queue: 2558500
  num_training_step_calls_since_last_synch_worker_weights: 1250
  num_weight_broadcasts: 50446
custom_metrics: {}
date: 2023-08-14_17-29-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.32
episode_reward_min: 3.0
episodes_this_iter: 96
episodes_total: 19990
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6519941091537476
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -10.163372993469238
        total_loss: 22.951749801635742
        var_gnorm: 64.7391586303711
        vf_explained_var: 0.8716291189193726
        vf_loss: 72.75018310546875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5084.0
  learner_queue:
    size_count: 5088
    size_mean: 14.98
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6910351859142376
  num_agent_steps_sampled: 2558750
  num_agent_steps_trained: 2542000
  num_env_steps_sampled: 2558750
  num_env_steps_trained: 2542000
  num_samples_added_to_queue: 2558500
  num_training_step_calls_since_last_synch_worker_weights: 1250
  num_weight_broadcasts: 50446
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 293.691
    learner_load_time_ms: 1.483
    learner_load_wait_time_ms: 1.701
iterations_since_restore: 191
node_ip: 127.0.0.1
num_agent_steps_sampled: 2558750
num_agent_steps_trained: 2542000
num_env_steps_sampled: 2558750
num_env_steps_sampled_this_iter: 12300
num_env_steps_sampled_throughput_per_sec: 1229.9973020612767
num_env_steps_trained: 2542000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9972581923544
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 55.16666666666667
  ram_util_percent: 78.91333333333334
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058717781922850903
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0227896452836471
  mean_inference_ms: 1.1167669281098844
  mean_raw_obs_processing_ms: 0.2552506508648143
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02046942710876465
    StateBufferConnector_ms: 0.0035021305084228516
    ViewRequirementAgentConnector_ms: 0.12071871757507324
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.32
  episode_reward_min: 3.0
  episodes_this_iter: 96
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 8.0, 9.0, 11.0, 8.0, 6.0, 8.0, 9.0, 14.0, 6.0, 11.0, 4.0,
      8.0, 7.0, 5.0, 8.0, 11.0, 12.0, 5.0, 9.0, 8.0, 10.0, 7.0, 9.0, 6.0, 13.0, 10.0,
      12.0, 11.0, 11.0, 8.0, 6.0, 6.0, 7.0, 3.0, 10.0, 10.0, 8.0, 10.0, 7.0, 10.0,
      5.0, 5.0, 8.0, 13.0, 9.0, 7.0, 10.0, 5.0, 5.0, 8.0, 6.0, 9.0, 9.0, 10.0, 9.0,
      10.0, 9.0, 8.0, 9.0, 9.0, 11.0, 5.0, 4.0, 11.0, 7.0, 6.0, 5.0, 9.0, 10.0, 14.0,
      8.0, 11.0, 10.0, 4.0, 6.0, 4.0, 4.0, 11.0, 13.0, 5.0, 11.0, 7.0, 4.0, 8.0, 11.0,
      12.0, 12.0, 9.0, 9.0, 8.0, 4.0, 11.0, 10.0, 10.0, 9.0, 10.0, 7.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058717781922850903
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0227896452836471
    mean_inference_ms: 1.1167669281098844
    mean_raw_obs_processing_ms: 0.2552506508648143
time_since_restore: 1934.8589096069336
time_this_iter_s: 10.114872217178345
time_total_s: 1934.8589096069336
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692001767
timesteps_total: 2558750
training_iteration: 191
trial_id: default
train step: 192
agent_timesteps_total: 2569050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02505660057067871
  StateBufferConnector_ms: 0.004315853118896484
  ViewRequirementAgentConnector_ms: 0.14679980278015137
counters:
  num_agent_steps_sampled: 2569050
  num_agent_steps_trained: 2552500
  num_env_steps_sampled: 2569050
  num_env_steps_trained: 2552500
  num_samples_added_to_queue: 2569000
  num_training_step_calls_since_last_synch_worker_weights: 803
  num_weight_broadcasts: 50649
custom_metrics: {}
date: 2023-08-14_17-29-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 8.36
episode_reward_min: 3.0
episodes_this_iter: 82
episodes_total: 20072
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.673040509223938
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -23.032848358154297
        total_loss: 43.737125396728516
        var_gnorm: 64.7420425415039
        vf_explained_var: 0.7672350406646729
        vf_loss: 140.27035522460938
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5105.0
  learner_queue:
    size_count: 5109
    size_mean: 15.46
    size_quantiles: [12.0, 14.0, 16.0, 16.0, 16.0]
    size_std: 1.0239140588936164
  num_agent_steps_sampled: 2569050
  num_agent_steps_trained: 2552500
  num_env_steps_sampled: 2569050
  num_env_steps_trained: 2552500
  num_samples_added_to_queue: 2569000
  num_training_step_calls_since_last_synch_worker_weights: 803
  num_weight_broadcasts: 50649
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 327.535
    learner_load_time_ms: 1.476
    learner_load_wait_time_ms: 1.972
iterations_since_restore: 192
node_ip: 127.0.0.1
num_agent_steps_sampled: 2569050
num_agent_steps_trained: 2552500
num_env_steps_sampled: 2569050
num_env_steps_sampled_this_iter: 10300
num_env_steps_sampled_throughput_per_sec: 1029.9960954337316
num_env_steps_trained: 2552500
num_env_steps_trained_this_iter: 10500
num_env_steps_trained_throughput_per_sec: 1049.9960196169109
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10500
perf:
  cpu_util_percent: 59.35000000000001
  ram_util_percent: 80.29285714285716
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05889208146320602
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022807300443418672
  mean_inference_ms: 1.1176272274172567
  mean_raw_obs_processing_ms: 0.2554768228765933
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02505660057067871
    StateBufferConnector_ms: 0.004315853118896484
    ViewRequirementAgentConnector_ms: 0.14679980278015137
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 8.36
  episode_reward_min: 3.0
  episodes_this_iter: 82
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 4.0, 8.0, 11.0, 12.0, 12.0, 9.0, 9.0, 8.0, 4.0, 11.0, 10.0,
      10.0, 9.0, 10.0, 7.0, 4.0, 4.0, 9.0, 9.0, 7.0, 9.0, 10.0, 5.0, 5.0, 13.0, 13.0,
      9.0, 7.0, 9.0, 11.0, 9.0, 6.0, 5.0, 4.0, 10.0, 9.0, 4.0, 8.0, 6.0, 7.0, 7.0,
      8.0, 3.0, 6.0, 5.0, 8.0, 8.0, 8.0, 12.0, 5.0, 7.0, 7.0, 9.0, 8.0, 9.0, 7.0,
      11.0, 7.0, 7.0, 6.0, 8.0, 8.0, 10.0, 9.0, 8.0, 10.0, 11.0, 5.0, 10.0, 14.0,
      7.0, 7.0, 9.0, 13.0, 12.0, 13.0, 10.0, 13.0, 7.0, 5.0, 9.0, 9.0, 9.0, 6.0, 7.0,
      8.0, 14.0, 11.0, 9.0, 7.0, 13.0, 8.0, 3.0, 8.0, 14.0, 7.0, 8.0, 11.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05889208146320602
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022807300443418672
    mean_inference_ms: 1.1176272274172567
    mean_raw_obs_processing_ms: 0.2554768228765933
time_since_restore: 1944.9976756572723
time_this_iter_s: 10.138766050338745
time_total_s: 1944.9976756572723
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1692001777
timesteps_total: 2569050
training_iteration: 192
trial_id: default
train step: 193
agent_timesteps_total: 2578950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02737569808959961
  StateBufferConnector_ms: 0.004739046096801758
  ViewRequirementAgentConnector_ms: 0.16161251068115234
counters:
  num_agent_steps_sampled: 2578950
  num_agent_steps_trained: 2562000
  num_env_steps_sampled: 2578950
  num_env_steps_trained: 2562000
  num_samples_added_to_queue: 2578500
  num_training_step_calls_since_last_synch_worker_weights: 469
  num_weight_broadcasts: 50844
custom_metrics: {}
date: 2023-08-14_17-29-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.54
episode_reward_min: 3.0
episodes_this_iter: 76
episodes_total: 20148
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6895548105239868
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 48.69407272338867
        total_loss: 81.70061492919922
        var_gnorm: 64.74472045898438
        vf_explained_var: 0.8724905252456665
        vf_loss: 72.90864562988281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5124.0
  learner_queue:
    size_count: 5130
    size_mean: 15.38
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1981652640600127
  num_agent_steps_sampled: 2578950
  num_agent_steps_trained: 2562000
  num_env_steps_sampled: 2578950
  num_env_steps_trained: 2562000
  num_samples_added_to_queue: 2578500
  num_training_step_calls_since_last_synch_worker_weights: 469
  num_weight_broadcasts: 50844
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 277.99
    learner_load_time_ms: 1.495
    learner_load_wait_time_ms: 1.818
iterations_since_restore: 193
node_ip: 127.0.0.1
num_agent_steps_sampled: 2578950
num_agent_steps_trained: 2562000
num_env_steps_sampled: 2578950
num_env_steps_sampled_this_iter: 9900
num_env_steps_sampled_throughput_per_sec: 989.9971439920802
num_env_steps_trained: 2562000
num_env_steps_trained_this_iter: 9500
num_env_steps_trained_throughput_per_sec: 949.9972593863396
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 9500
perf:
  cpu_util_percent: 56.80714285714286
  ram_util_percent: 80.85714285714286
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05901670720293355
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02284361225894938
  mean_inference_ms: 1.1189350190191243
  mean_raw_obs_processing_ms: 0.2557624695792189
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02737569808959961
    StateBufferConnector_ms: 0.004739046096801758
    ViewRequirementAgentConnector_ms: 0.16161251068115234
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.54
  episode_reward_min: 3.0
  episodes_this_iter: 76
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [13.0, 10.0, 13.0, 7.0, 5.0, 9.0, 9.0, 9.0, 6.0, 7.0, 8.0, 14.0,
      11.0, 9.0, 7.0, 13.0, 8.0, 3.0, 8.0, 14.0, 7.0, 8.0, 11.0, 5.0, 7.0, 8.0, 7.0,
      9.0, 11.0, 11.0, 10.0, 10.0, 6.0, 13.0, 9.0, 7.0, 11.0, 7.0, 9.0, 9.0, 9.0,
      6.0, 11.0, 10.0, 8.0, 11.0, 9.0, 13.0, 8.0, 12.0, 11.0, 11.0, 4.0, 7.0, 11.0,
      10.0, 5.0, 4.0, 10.0, 10.0, 8.0, 6.0, 11.0, 8.0, 10.0, 6.0, 7.0, 12.0, 7.0,
      4.0, 13.0, 4.0, 9.0, 8.0, 5.0, 7.0, 8.0, 8.0, 6.0, 7.0, 9.0, 8.0, 10.0, 6.0,
      16.0, 10.0, 11.0, 6.0, 6.0, 13.0, 7.0, 7.0, 9.0, 8.0, 9.0, 4.0, 6.0, 4.0, 6.0,
      7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05901670720293355
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02284361225894938
    mean_inference_ms: 1.1189350190191243
    mean_raw_obs_processing_ms: 0.2557624695792189
time_since_restore: 1955.1817865371704
time_this_iter_s: 10.184110879898071
time_total_s: 1955.1817865371704
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.047
timestamp: 1692001787
timesteps_total: 2578950
training_iteration: 193
trial_id: default
train step: 194
agent_timesteps_total: 2589350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.026230573654174805
  StateBufferConnector_ms: 0.004517316818237305
  ViewRequirementAgentConnector_ms: 0.15153765678405762
counters:
  num_agent_steps_sampled: 2589350
  num_agent_steps_trained: 2572500
  num_env_steps_sampled: 2589350
  num_env_steps_trained: 2572500
  num_samples_added_to_queue: 2589000
  num_training_step_calls_since_last_synch_worker_weights: 1685
  num_weight_broadcasts: 51049
custom_metrics: {}
date: 2023-08-14_17-29-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.15
episode_reward_min: 0.0
episodes_this_iter: 82
episodes_total: 20230
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6238905787467957
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -30.583850860595703
        total_loss: 34.041263580322266
        var_gnorm: 64.74813079833984
        vf_explained_var: 0.8173506259918213
        vf_loss: 135.4891357421875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5145.0
  learner_queue:
    size_count: 5148
    size_mean: 15.4
    size_quantiles: [11.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.1832159566199232
  num_agent_steps_sampled: 2589350
  num_agent_steps_trained: 2572500
  num_env_steps_sampled: 2589350
  num_env_steps_trained: 2572500
  num_samples_added_to_queue: 2589000
  num_training_step_calls_since_last_synch_worker_weights: 1685
  num_weight_broadcasts: 51049
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 383.679
    learner_load_time_ms: 1.498
    learner_load_wait_time_ms: 2.225
iterations_since_restore: 194
node_ip: 127.0.0.1
num_agent_steps_sampled: 2589350
num_agent_steps_trained: 2572500
num_env_steps_sampled: 2589350
num_env_steps_sampled_this_iter: 10400
num_env_steps_sampled_throughput_per_sec: 1039.9953136655263
num_env_steps_trained: 2572500
num_env_steps_trained_this_iter: 10500
num_env_steps_trained_throughput_per_sec: 1049.9952686046179
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 10500
perf:
  cpu_util_percent: 61.76
  ram_util_percent: 81.76666666666667
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05904500932686782
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022891381555698576
  mean_inference_ms: 1.120505712907261
  mean_raw_obs_processing_ms: 0.256056988749835
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.026230573654174805
    StateBufferConnector_ms: 0.004517316818237305
    ViewRequirementAgentConnector_ms: 0.15153765678405762
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.15
  episode_reward_min: 0.0
  episodes_this_iter: 82
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 6.0, 16.0, 10.0, 11.0, 6.0, 6.0, 13.0, 7.0, 7.0, 9.0, 8.0,
      9.0, 4.0, 6.0, 4.0, 6.0, 7.0, 9.0, 4.0, 9.0, 6.0, 9.0, 9.0, 7.0, 8.0, 14.0,
      7.0, 5.0, 5.0, 11.0, 1.0, 7.0, 10.0, 8.0, 7.0, 8.0, 4.0, 8.0, 9.0, 1.0, 7.0,
      10.0, 5.0, 9.0, 6.0, 10.0, 8.0, 5.0, 9.0, 11.0, 5.0, 7.0, 8.0, 8.0, 8.0, 9.0,
      7.0, 8.0, 6.0, 7.0, 6.0, 4.0, 10.0, 11.0, 7.0, 3.0, 5.0, 3.0, 1.0, 10.0, 4.0,
      14.0, 7.0, 6.0, 10.0, 8.0, 8.0, 8.0, 10.0, 8.0, 6.0, 6.0, 8.0, 8.0, 3.0, 9.0,
      5.0, 4.0, 4.0, 6.0, 9.0, 8.0, 0.0, 9.0, 4.0, 6.0, 5.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05904500932686782
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022891381555698576
    mean_inference_ms: 1.120505712907261
    mean_raw_obs_processing_ms: 0.256056988749835
time_since_restore: 1965.309903383255
time_this_iter_s: 10.128116846084595
time_total_s: 1965.309903383255
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.048
timestamp: 1692001797
timesteps_total: 2589350
training_iteration: 194
trial_id: default
train step: 195
agent_timesteps_total: 2601200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02281045913696289
  StateBufferConnector_ms: 0.003859996795654297
  ViewRequirementAgentConnector_ms: 0.1382455825805664
counters:
  num_agent_steps_sampled: 2601200
  num_agent_steps_trained: 2584500
  num_env_steps_sampled: 2601200
  num_env_steps_trained: 2584500
  num_samples_added_to_queue: 2601000
  num_training_step_calls_since_last_synch_worker_weights: 82
  num_weight_broadcasts: 51283
custom_metrics: {}
date: 2023-08-14_17-30-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 5.9
episode_reward_min: 0.0
episodes_this_iter: 92
episodes_total: 20322
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.5929807424545288
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 14.448233604431152
        total_loss: 46.24723434448242
        var_gnorm: 64.74935913085938
        vf_explained_var: 0.8695726990699768
        vf_loss: 69.5278091430664
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5169.0
  learner_queue:
    size_count: 5175
    size_mean: 15.26
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3972830779766854
  num_agent_steps_sampled: 2601200
  num_agent_steps_trained: 2584500
  num_env_steps_sampled: 2601200
  num_env_steps_trained: 2584500
  num_samples_added_to_queue: 2601000
  num_training_step_calls_since_last_synch_worker_weights: 82
  num_weight_broadcasts: 51283
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 195.351
    learner_load_time_ms: 1.523
    learner_load_wait_time_ms: 1.666
iterations_since_restore: 195
node_ip: 127.0.0.1
num_agent_steps_sampled: 2601200
num_agent_steps_trained: 2584500
num_env_steps_sampled: 2601200
num_env_steps_sampled_this_iter: 11850
num_env_steps_sampled_throughput_per_sec: 1184.9948015441064
num_env_steps_trained: 2584500
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9947357408673
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 57.85
  ram_util_percent: 80.62857142857142
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05901131857503381
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02292553345745464
  mean_inference_ms: 1.1215693186785105
  mean_raw_obs_processing_ms: 0.256233431142421
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02281045913696289
    StateBufferConnector_ms: 0.003859996795654297
    ViewRequirementAgentConnector_ms: 0.1382455825805664
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 5.9
  episode_reward_min: 0.0
  episodes_this_iter: 92
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 0.0, 9.0, 4.0, 6.0, 5.0, 3.0, 5.0, 5.0, 6.0, 7.0, 8.0, 4.0,
      6.0, 7.0, 3.0, 3.0, 7.0, 10.0, 5.0, 4.0, 4.0, 9.0, 1.0, 5.0, 4.0, 9.0, 4.0,
      5.0, 4.0, 6.0, 8.0, 6.0, 4.0, 5.0, 9.0, 4.0, 3.0, 7.0, 8.0, 7.0, 4.0, 3.0, 6.0,
      5.0, 5.0, 7.0, 7.0, 4.0, 7.0, 9.0, 5.0, 8.0, 4.0, 9.0, 5.0, 8.0, 6.0, 6.0, 6.0,
      6.0, 4.0, 7.0, 8.0, 2.0, 9.0, 4.0, 7.0, 5.0, 4.0, 7.0, 5.0, 6.0, 11.0, 7.0,
      2.0, 10.0, 8.0, 7.0, 4.0, 10.0, 7.0, 7.0, 6.0, 4.0, 7.0, 7.0, 5.0, 3.0, 7.0,
      7.0, 6.0, 3.0, 8.0, 8.0, 7.0, 6.0, 5.0, 9.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05901131857503381
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02292553345745464
    mean_inference_ms: 1.1215693186785105
    mean_raw_obs_processing_ms: 0.256233431142421
time_since_restore: 1975.4934554100037
time_this_iter_s: 10.183552026748657
time_total_s: 1975.4934554100037
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1692001808
timesteps_total: 2601200
training_iteration: 195
trial_id: default
train step: 196
agent_timesteps_total: 2613700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021095752716064453
  StateBufferConnector_ms: 0.0040111541748046875
  ViewRequirementAgentConnector_ms: 0.13383960723876953
counters:
  num_agent_steps_sampled: 2613700
  num_agent_steps_trained: 2597000
  num_env_steps_sampled: 2613700
  num_env_steps_trained: 2597000
  num_samples_added_to_queue: 2613500
  num_training_step_calls_since_last_synch_worker_weights: 947
  num_weight_broadcasts: 51528
custom_metrics: {}
date: 2023-08-14_17-30-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 14.0
episode_reward_mean: 6.79
episode_reward_min: 2.0
episodes_this_iter: 98
episodes_total: 20420
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6489567160606384
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -20.664533615112305
        total_loss: 28.847654342651367
        var_gnorm: 64.75605773925781
        vf_explained_var: 0.7989366054534912
        vf_loss: 105.5139389038086
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5194.0
  learner_queue:
    size_count: 5198
    size_mean: 15.38
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3249905660041508
  num_agent_steps_sampled: 2613700
  num_agent_steps_trained: 2597000
  num_env_steps_sampled: 2613700
  num_env_steps_trained: 2597000
  num_samples_added_to_queue: 2613500
  num_training_step_calls_since_last_synch_worker_weights: 947
  num_weight_broadcasts: 51528
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 255.33
    learner_load_time_ms: 1.55
    learner_load_wait_time_ms: 1.65
iterations_since_restore: 196
node_ip: 127.0.0.1
num_agent_steps_sampled: 2613700
num_agent_steps_trained: 2597000
num_env_steps_sampled: 2613700
num_env_steps_sampled_this_iter: 12500
num_env_steps_sampled_throughput_per_sec: 1249.9973774011323
num_env_steps_trained: 2597000
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.9973774011323
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.23571428571429
  ram_util_percent: 77.91428571428571
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.058987152613361286
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02294222815676271
  mean_inference_ms: 1.1221023820281821
  mean_raw_obs_processing_ms: 0.256311655111237
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021095752716064453
    StateBufferConnector_ms: 0.0040111541748046875
    ViewRequirementAgentConnector_ms: 0.13383960723876953
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 14.0
  episode_reward_mean: 6.79
  episode_reward_min: 2.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 4.0, 10.0, 7.0, 3.0, 7.0, 5.0, 5.0, 2.0, 5.0, 2.0, 7.0,
      8.0, 7.0, 5.0, 9.0, 8.0, 5.0, 7.0, 10.0, 8.0, 2.0, 6.0, 10.0, 3.0, 9.0, 8.0,
      10.0, 11.0, 4.0, 4.0, 4.0, 7.0, 10.0, 10.0, 8.0, 4.0, 2.0, 8.0, 3.0, 11.0, 8.0,
      5.0, 8.0, 9.0, 13.0, 12.0, 7.0, 7.0, 10.0, 7.0, 8.0, 7.0, 6.0, 4.0, 8.0, 6.0,
      6.0, 6.0, 7.0, 5.0, 6.0, 7.0, 4.0, 5.0, 6.0, 7.0, 6.0, 7.0, 4.0, 5.0, 6.0, 3.0,
      10.0, 10.0, 4.0, 7.0, 9.0, 6.0, 10.0, 4.0, 6.0, 4.0, 9.0, 7.0, 10.0, 4.0, 10.0,
      10.0, 5.0, 8.0, 9.0, 6.0, 6.0, 7.0, 5.0, 6.0, 5.0, 6.0, 14.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.058987152613361286
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02294222815676271
    mean_inference_ms: 1.1221023820281821
    mean_raw_obs_processing_ms: 0.256311655111237
time_since_restore: 1985.5984334945679
time_this_iter_s: 10.104978084564209
time_total_s: 1985.5984334945679
timers:
  sample_time_ms: 0.015
  synch_weights_time_ms: 0.004
  training_iteration_time_ms: 0.046
timestamp: 1692001818
timesteps_total: 2613700
training_iteration: 196
trial_id: default
train step: 197
agent_timesteps_total: 2625700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.021834373474121094
  StateBufferConnector_ms: 0.0038695335388183594
  ViewRequirementAgentConnector_ms: 0.12977099418640137
counters:
  num_agent_steps_sampled: 2625700
  num_agent_steps_trained: 2609000
  num_env_steps_sampled: 2625700
  num_env_steps_trained: 2609000
  num_samples_added_to_queue: 2625500
  num_training_step_calls_since_last_synch_worker_weights: 194
  num_weight_broadcasts: 51764
custom_metrics: {}
date: 2023-08-14_17-30-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 7.77
episode_reward_min: 1.0
episodes_this_iter: 94
episodes_total: 20514
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6597321629524231
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: -28.899667739868164
        total_loss: 13.80067253112793
        var_gnorm: 64.7643051147461
        vf_explained_var: 0.8361487984657288
        vf_loss: 91.99800109863281
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5218.0
  learner_queue:
    size_count: 5224
    size_mean: 15.18
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4925146565444507
  num_agent_steps_sampled: 2625700
  num_agent_steps_trained: 2609000
  num_env_steps_sampled: 2625700
  num_env_steps_trained: 2609000
  num_samples_added_to_queue: 2625500
  num_training_step_calls_since_last_synch_worker_weights: 194
  num_weight_broadcasts: 51764
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 234.554
    learner_load_time_ms: 1.574
    learner_load_wait_time_ms: 1.736
iterations_since_restore: 197
node_ip: 127.0.0.1
num_agent_steps_sampled: 2625700
num_agent_steps_trained: 2609000
num_env_steps_sampled: 2625700
num_env_steps_sampled_this_iter: 12000
num_env_steps_sampled_throughput_per_sec: 1199.9944496411506
num_env_steps_trained: 2609000
num_env_steps_trained_this_iter: 12000
num_env_steps_trained_throughput_per_sec: 1199.9944496411506
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12000
perf:
  cpu_util_percent: 53.99333333333333
  ram_util_percent: 77.82
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05905449696615534
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0229536412062176
  mean_inference_ms: 1.1225975965800168
  mean_raw_obs_processing_ms: 0.25644979267031615
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.021834373474121094
    StateBufferConnector_ms: 0.0038695335388183594
    ViewRequirementAgentConnector_ms: 0.12977099418640137
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 7.77
  episode_reward_min: 1.0
  episodes_this_iter: 94
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 5.0, 6.0, 5.0, 6.0, 14.0, 9.0, 5.0, 3.0, 6.0, 7.0, 6.0,
      6.0, 13.0, 4.0, 9.0, 12.0, 9.0, 7.0, 7.0, 8.0, 5.0, 6.0, 9.0, 9.0, 8.0, 7.0,
      9.0, 11.0, 3.0, 11.0, 6.0, 9.0, 7.0, 12.0, 6.0, 4.0, 6.0, 8.0, 7.0, 4.0, 7.0,
      8.0, 10.0, 9.0, 10.0, 9.0, 12.0, 9.0, 4.0, 10.0, 10.0, 9.0, 1.0, 10.0, 4.0,
      9.0, 9.0, 1.0, 10.0, 6.0, 8.0, 13.0, 7.0, 3.0, 10.0, 4.0, 5.0, 7.0, 12.0, 8.0,
      9.0, 11.0, 5.0, 4.0, 5.0, 9.0, 8.0, 8.0, 8.0, 11.0, 9.0, 7.0, 16.0, 9.0, 3.0,
      4.0, 11.0, 9.0, 9.0, 9.0, 7.0, 8.0, 11.0, 11.0, 11.0, 9.0, 8.0, 4.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05905449696615534
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0229536412062176
    mean_inference_ms: 1.1225975965800168
    mean_raw_obs_processing_ms: 0.25644979267031615
time_since_restore: 1995.8065633773804
time_this_iter_s: 10.2081298828125
time_total_s: 1995.8065633773804
timers:
  sample_time_ms: 0.016
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.046
timestamp: 1692001828
timesteps_total: 2625700
training_iteration: 197
trial_id: default
train step: 198
agent_timesteps_total: 2638300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02031993865966797
  StateBufferConnector_ms: 0.0035500526428222656
  ViewRequirementAgentConnector_ms: 0.12281179428100586
counters:
  num_agent_steps_sampled: 2638300
  num_agent_steps_trained: 2621500
  num_env_steps_sampled: 2638300
  num_env_steps_trained: 2621500
  num_samples_added_to_queue: 2638000
  num_training_step_calls_since_last_synch_worker_weights: 114
  num_weight_broadcasts: 52009
custom_metrics: {}
date: 2023-08-14_17-30-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 8.19
episode_reward_min: 2.0
episodes_this_iter: 98
episodes_total: 20612
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.700230598449707
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 1.272979736328125
        total_loss: 53.889495849609375
        var_gnorm: 64.77184295654297
        vf_explained_var: 0.8602233529090881
        vf_loss: 112.23533630371094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5243.0
  learner_queue:
    size_count: 5249
    size_mean: 15.2
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.469693845669907
  num_agent_steps_sampled: 2638300
  num_agent_steps_trained: 2621500
  num_env_steps_sampled: 2638300
  num_env_steps_trained: 2621500
  num_samples_added_to_queue: 2638000
  num_training_step_calls_since_last_synch_worker_weights: 114
  num_weight_broadcasts: 52009
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 226.002
    learner_load_time_ms: 1.559
    learner_load_wait_time_ms: 1.698
iterations_since_restore: 198
node_ip: 127.0.0.1
num_agent_steps_sampled: 2638300
num_agent_steps_trained: 2621500
num_env_steps_sampled: 2638300
num_env_steps_sampled_this_iter: 12600
num_env_steps_sampled_throughput_per_sec: 1259.9940820018255
num_env_steps_trained: 2621500
num_env_steps_trained_this_iter: 12500
num_env_steps_trained_throughput_per_sec: 1249.994128970065
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 12500
perf:
  cpu_util_percent: 52.449999999999996
  ram_util_percent: 77.43571428571428
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05904510901722782
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.02296862553840141
  mean_inference_ms: 1.1230686246388455
  mean_raw_obs_processing_ms: 0.2565252218898911
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02031993865966797
    StateBufferConnector_ms: 0.0035500526428222656
    ViewRequirementAgentConnector_ms: 0.12281179428100586
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 8.19
  episode_reward_min: 2.0
  episodes_this_iter: 98
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 9.0, 9.0, 3.0, 7.0, 9.0, 9.0, 13.0, 7.0, 4.0, 5.0, 9.0,
      8.0, 5.0, 10.0, 9.0, 9.0, 13.0, 6.0, 10.0, 9.0, 7.0, 8.0, 6.0, 6.0, 8.0, 8.0,
      5.0, 5.0, 5.0, 16.0, 6.0, 13.0, 8.0, 5.0, 13.0, 8.0, 11.0, 12.0, 8.0, 12.0,
      9.0, 14.0, 5.0, 12.0, 10.0, 9.0, 7.0, 9.0, 5.0, 2.0, 6.0, 15.0, 12.0, 12.0,
      7.0, 10.0, 6.0, 8.0, 9.0, 9.0, 12.0, 6.0, 10.0, 5.0, 15.0, 8.0, 4.0, 11.0, 7.0,
      11.0, 7.0, 3.0, 7.0, 3.0, 11.0, 11.0, 12.0, 9.0, 13.0, 12.0, 8.0, 9.0, 7.0,
      7.0, 8.0, 3.0, 10.0, 8.0, 6.0, 5.0, 3.0, 8.0, 8.0, 5.0, 4.0, 4.0, 9.0, 6.0,
      11.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05904510901722782
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.02296862553840141
    mean_inference_ms: 1.1230686246388455
    mean_raw_obs_processing_ms: 0.2565252218898911
time_since_restore: 2006.0040233135223
time_this_iter_s: 10.197459936141968
time_total_s: 2006.0040233135223
timers:
  sample_time_ms: 0.017
  synch_weights_time_ms: 0.005
  training_iteration_time_ms: 0.049
timestamp: 1692001838
timesteps_total: 2638300
training_iteration: 198
trial_id: default
train step: 199
agent_timesteps_total: 2649200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.02450418472290039
  StateBufferConnector_ms: 0.004194974899291992
  ViewRequirementAgentConnector_ms: 0.14479637145996094
counters:
  num_agent_steps_sampled: 2649200
  num_agent_steps_trained: 2632500
  num_env_steps_sampled: 2649200
  num_env_steps_trained: 2632500
  num_samples_added_to_queue: 2649000
  num_training_step_calls_since_last_synch_worker_weights: 429
  num_weight_broadcasts: 52223
custom_metrics: {}
date: 2023-08-14_17-30-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 15.0
episode_reward_mean: 8.29
episode_reward_min: 2.0
episodes_this_iter: 86
episodes_total: 20698
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6577534675598145
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 8.704557418823242
        total_loss: 93.6307601928711
        var_gnorm: 64.77860260009766
        vf_explained_var: 0.7664605379104614
        vf_loss: 176.429931640625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5265.0
  learner_queue:
    size_count: 5269
    size_mean: 15.04
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5094369811290564
  num_agent_steps_sampled: 2649200
  num_agent_steps_trained: 2632500
  num_env_steps_sampled: 2649200
  num_env_steps_trained: 2632500
  num_samples_added_to_queue: 2649000
  num_training_step_calls_since_last_synch_worker_weights: 429
  num_weight_broadcasts: 52223
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 386.167
    learner_load_time_ms: 1.752
    learner_load_wait_time_ms: 2.551
iterations_since_restore: 199
node_ip: 127.0.0.1
num_agent_steps_sampled: 2649200
num_agent_steps_trained: 2632500
num_env_steps_sampled: 2649200
num_env_steps_sampled_this_iter: 10900
num_env_steps_sampled_throughput_per_sec: 1089.671485520973
num_env_steps_trained: 2632500
num_env_steps_trained_this_iter: 11000
num_env_steps_trained_throughput_per_sec: 1099.66847162667
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11000
perf:
  cpu_util_percent: 60.357142857142854
  ram_util_percent: 78.77857142857142
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05919384696920918
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.022981452903850928
  mean_inference_ms: 1.1237336814162113
  mean_raw_obs_processing_ms: 0.2567232934463773
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.02450418472290039
    StateBufferConnector_ms: 0.004194974899291992
    ViewRequirementAgentConnector_ms: 0.14479637145996094
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 15.0
  episode_reward_mean: 8.29
  episode_reward_min: 2.0
  episodes_this_iter: 86
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 10.0, 8.0, 6.0, 5.0, 3.0, 8.0, 8.0, 5.0, 4.0, 4.0, 9.0,
      6.0, 11.0, 6.0, 11.0, 8.0, 5.0, 7.0, 11.0, 9.0, 9.0, 7.0, 13.0, 8.0, 15.0, 6.0,
      2.0, 6.0, 13.0, 7.0, 9.0, 12.0, 6.0, 8.0, 12.0, 5.0, 10.0, 8.0, 9.0, 3.0, 6.0,
      9.0, 8.0, 12.0, 8.0, 6.0, 8.0, 10.0, 10.0, 15.0, 8.0, 12.0, 8.0, 14.0, 8.0,
      9.0, 6.0, 6.0, 12.0, 11.0, 8.0, 8.0, 7.0, 10.0, 2.0, 12.0, 10.0, 9.0, 8.0, 8.0,
      7.0, 6.0, 12.0, 8.0, 8.0, 7.0, 10.0, 8.0, 4.0, 11.0, 9.0, 7.0, 12.0, 10.0, 6.0,
      6.0, 9.0, 7.0, 9.0, 14.0, 9.0, 6.0, 8.0, 8.0, 12.0, 3.0, 10.0, 11.0, 9.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05919384696920918
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.022981452903850928
    mean_inference_ms: 1.1237336814162113
    mean_raw_obs_processing_ms: 0.2567232934463773
time_since_restore: 2016.1933543682098
time_this_iter_s: 10.1893310546875
time_total_s: 2016.1933543682098
timers:
  sample_time_ms: 0.344
  synch_weights_time_ms: 0.006
  training_iteration_time_ms: 0.379
timestamp: 1692001848
timesteps_total: 2649200
training_iteration: 199
trial_id: default
train step: 200
agent_timesteps_total: 2660750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.023804903030395508
  StateBufferConnector_ms: 0.004075765609741211
  ViewRequirementAgentConnector_ms: 0.14169669151306152
counters:
  num_agent_steps_sampled: 2660750
  num_agent_steps_trained: 2644000
  num_env_steps_sampled: 2660750
  num_env_steps_trained: 2644000
  num_samples_added_to_queue: 2660500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 52451
custom_metrics: {}
date: 2023-08-14_17-30-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 16.0
episode_reward_mean: 9.07
episode_reward_min: 2.0
episodes_this_iter: 89
episodes_total: 20787
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 0.0002
        entropy: 0.6793393492698669
        entropy_coeff: 0.01
        grad_gnorm: 20.0
        policy_loss: 53.01302719116211
        total_loss: 164.37924194335938
        var_gnorm: 64.78658294677734
        vf_explained_var: 0.786736249923706
        vf_loss: 229.5258331298828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5288.0
  learner_queue:
    size_count: 5295
    size_mean: 15.08
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5979987484350544
  num_agent_steps_sampled: 2660750
  num_agent_steps_trained: 2644000
  num_env_steps_sampled: 2660750
  num_env_steps_trained: 2644000
  num_samples_added_to_queue: 2660500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 52451
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 145.601
    learner_load_time_ms: 1.734
    learner_load_wait_time_ms: 1.448
iterations_since_restore: 200
node_ip: 127.0.0.1
num_agent_steps_sampled: 2660750
num_agent_steps_trained: 2644000
num_env_steps_sampled: 2660750
num_env_steps_sampled_this_iter: 11550
num_env_steps_sampled_throughput_per_sec: 1154.821007457507
num_env_steps_trained: 2644000
num_env_steps_trained_this_iter: 11500
num_env_steps_trained_throughput_per_sec: 1149.8217823169985
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 11500
perf:
  cpu_util_percent: 60.42666666666666
  ram_util_percent: 78.57999999999998
pid: 46379
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.05922613444849164
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.023006465423305665
  mean_inference_ms: 1.12459752838826
  mean_raw_obs_processing_ms: 0.25690760226859155
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.023804903030395508
    StateBufferConnector_ms: 0.004075765609741211
    ViewRequirementAgentConnector_ms: 0.14169669151306152
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 16.0
  episode_reward_mean: 9.07
  episode_reward_min: 2.0
  episodes_this_iter: 89
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 14.0, 9.0, 6.0, 8.0, 8.0, 12.0, 3.0, 10.0, 11.0, 9.0, 9.0,
      10.0, 11.0, 9.0, 15.0, 9.0, 6.0, 8.0, 10.0, 7.0, 11.0, 8.0, 8.0, 12.0, 11.0,
      15.0, 8.0, 15.0, 7.0, 10.0, 7.0, 6.0, 14.0, 10.0, 11.0, 4.0, 7.0, 6.0, 4.0,
      16.0, 10.0, 11.0, 5.0, 8.0, 10.0, 9.0, 10.0, 10.0, 6.0, 9.0, 14.0, 9.0, 11.0,
      5.0, 3.0, 13.0, 5.0, 9.0, 10.0, 14.0, 10.0, 5.0, 16.0, 9.0, 8.0, 10.0, 12.0,
      8.0, 7.0, 13.0, 8.0, 8.0, 10.0, 10.0, 5.0, 9.0, 5.0, 15.0, 8.0, 10.0, 9.0, 9.0,
      14.0, 5.0, 10.0, 9.0, 7.0, 6.0, 7.0, 6.0, 6.0, 9.0, 11.0, 10.0, 9.0, 14.0, 10.0,
      4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.05922613444849164
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.023006465423305665
    mean_inference_ms: 1.12459752838826
    mean_raw_obs_processing_ms: 0.25690760226859155
time_since_restore: 2026.3545453548431
time_this_iter_s: 10.1611909866333
time_total_s: 2026.3545453548431
timers:
  sample_time_ms: 0.094
  synch_weights_time_ms: 0.516
  training_iteration_time_ms: 0.74
timestamp: 1692001858
timesteps_total: 2660750
training_iteration: 200
trial_id: default
train step: 201
Traceback (most recent call last):
  File "/Users/sangbin/Impala/launch.py", line 331, in <module>
    result = algo.train()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 372, in train
    result = self.step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 853, in step
    results, train_iter_ctx = self._run_one_training_iteration()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2837, in _run_one_training_iteration
    results = self.training_step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 697, in training_step
    unprocessed_sample_batches = self.get_samples_from_workers(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 907, in get_samples_from_workers
    ] = self.workers.fetch_ready_async_reqs(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py", line 782, in fetch_ready_async_reqs
    remote_results = self.__worker_manager.fetch_ready_async_reqs(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py", line 753, in fetch_ready_async_reqs
    ready, remote_results = self.__fetch_result(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py", line 460, in __fetch_result
    ready, _ = ray.wait(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/worker.py", line 2660, in wait
    worker.check_connected()
KeyboardInterrupt
Traceback (most recent call last):
  File "/Users/sangbin/Impala/launch.py", line 331, in <module>
    result = algo.train()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 372, in train
    result = self.step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 853, in step
    results, train_iter_ctx = self._run_one_training_iteration()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2837, in _run_one_training_iteration
    results = self.training_step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 697, in training_step
    unprocessed_sample_batches = self.get_samples_from_workers(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 907, in get_samples_from_workers
    ] = self.workers.fetch_ready_async_reqs(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py", line 782, in fetch_ready_async_reqs
    remote_results = self.__worker_manager.fetch_ready_async_reqs(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py", line 753, in fetch_ready_async_reqs
    ready, remote_results = self.__fetch_result(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/utils/actor_manager.py", line 460, in __fetch_result
    ready, _ = ray.wait(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/auto_init_hook.py", line 24, in auto_init_wrapper
    return fn(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/client_mode_hook.py", line 103, in wrapper
    return func(*args, **kwargs)
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/_private/worker.py", line 2660, in wait
    worker.check_connected()
KeyboardInterrupt
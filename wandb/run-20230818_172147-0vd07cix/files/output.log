[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
2023-08-18 17:21:48,214	INFO tensorboardx.py:48 -- pip install "ray[tune]" to see TensorBoard files.
2023-08-18 17:21:48,214	WARNING unified.py:56 -- Could not instantiate TBXLogger: No module named 'tensorboardX'.
[36m(pid=48202)[39m lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.
[36m(pid=48202)[39m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,133	WARNING env.py:162 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,135	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,135	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,139	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.AttentionWrapper` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,139	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,139	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,142	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.GTrXLNet` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,146	WARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,147	WARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,147	WARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,147	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=48202)[39m 2023-08-18 17:21:51,182	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/catalog.py:790: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  prep = cls(observation_space, options)
2023-08-18 17:21:51,211	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,211	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,214	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.AttentionWrapper` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,214	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,215	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/torch/attention_net.py:281: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  super().__init__(obs_space, action_space, None, model_config, name)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/torch/attention_net.py:281: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  super().__init__(obs_space, action_space, None, model_config, name)
2023-08-18 17:21:51,219	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.GTrXLNet` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,223	WARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,223	WARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,223	WARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,223	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/modelv2.py:440: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  prep = get_preprocessor(space)(space)
2023-08-18 17:21:51,247	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/connectors/agent/obs_preproc.py:40: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  self._preprocessor = get_preprocessor(obs_space)(
2023-08-18 17:21:51,264	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.multi_gpu_learner_thread.MultiGPULearnerThread` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,264	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.minibatch_buffer.MinibatchBuffer` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,265	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.learner_thread.LearnerThread` has been deprecated. This will raise an error in the future!
2023-08-18 17:21:51,266	WARNING util.py:68 -- Install gputil for GPU system monitoring.
2023-08-18 17:21:51,371	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.replay_ops.SimpleReplayBuffer` has been deprecated. This will raise an error in the future!
train step: 1
agent_timesteps_total: 7750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033479831257804495
  StateBufferConnector_ms: 0.006246957622590612
  ViewRequirementAgentConnector_ms: 0.19759701900794857
counters:
  num_agent_steps_sampled: 7750
  num_agent_steps_trained: 2500
  num_env_steps_sampled: 7750
  num_env_steps_trained: 2500
  num_samples_added_to_queue: 7500
  num_training_step_calls_since_last_synch_worker_weights: 145
  num_weight_broadcasts: 154
custom_metrics: {}
date: 2023-08-18_17-22-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.1311475409836065
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 61
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 3.9
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5760501623153687
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -20.747779846191406
        total_loss: -4.100664138793945
        var_gnorm: 63.331844329833984
        vf_explained_var: -0.996031641960144
        vf_loss: 34.87028121948242
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5.0
  learner_queue:
    size_count: 10
    size_mean: 0.0
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 0.0]
    size_std: 0.0
  num_agent_steps_sampled: 7750
  num_agent_steps_trained: 2500
  num_env_steps_sampled: 7750
  num_env_steps_trained: 2500
  num_samples_added_to_queue: 7500
  num_training_step_calls_since_last_synch_worker_weights: 145
  num_weight_broadcasts: 154
  timing_breakdown:
    learner_dequeue_time_ms: 580.471
    learner_grad_time_ms: 939.377
    learner_load_time_ms: 68.868
    learner_load_wait_time_ms: 14.276
iterations_since_restore: 1
node_ip: 127.0.0.1
num_agent_steps_sampled: 7750
num_agent_steps_trained: 2500
num_env_steps_sampled: 7750
num_env_steps_sampled_this_iter: 7750
num_env_steps_sampled_throughput_per_sec: 774.9993717675533
num_env_steps_trained: 2500
num_env_steps_trained_this_iter: 2500
num_env_steps_trained_throughput_per_sec: 249.99979734437204
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 2500
perf:
  cpu_util_percent: 51.533333333333324
  ram_util_percent: 80.04666666666667
pid: 48167
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10376553204482282
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.037980227962421925
  mean_inference_ms: 1.9107976536567586
  mean_raw_obs_processing_ms: 0.4353635044692299
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033479831257804495
    StateBufferConnector_ms: 0.006246957622590612
    ViewRequirementAgentConnector_ms: 0.19759701900794857
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.1311475409836065
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128]
    episode_reward: [0.0, 0.0, 0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 0.0, 1.0,
      2.0, 2.0, 3.0, 1.0, 1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0,
      0.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 5.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0,
      1.0, 1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10376553204482282
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.037980227962421925
    mean_inference_ms: 1.9107976536567586
    mean_raw_obs_processing_ms: 0.4353635044692299
time_since_restore: 10.307665824890137
time_this_iter_s: 10.307665824890137
time_total_s: 10.307665824890137
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.072
timestamp: 1692346921
timesteps_total: 7750
training_iteration: 1
trial_id: default
train step: 2
agent_timesteps_total: 14950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03506040573120117
  StateBufferConnector_ms: 0.006445884704589844
  ViewRequirementAgentConnector_ms: 0.20646119117736816
counters:
  num_agent_steps_sampled: 14950
  num_agent_steps_trained: 7500
  num_env_steps_sampled: 14950
  num_env_steps_trained: 7500
  num_samples_added_to_queue: 14500
  num_training_step_calls_since_last_synch_worker_weights: 435
  num_weight_broadcasts: 293
custom_metrics: {}
date: 2023-08-18_17-22-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.19
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 117
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 9.7
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5877305269241333
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -61.564579010009766
        total_loss: -51.43632507324219
        var_gnorm: 63.3315544128418
        vf_explained_var: -1.0
        vf_loss: 21.844236373901367
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 15.0
  learner_queue:
    size_count: 21
    size_mean: 0.0
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 0.0]
    size_std: 0.0
  num_agent_steps_sampled: 14950
  num_agent_steps_trained: 7500
  num_env_steps_sampled: 14950
  num_env_steps_trained: 7500
  num_samples_added_to_queue: 14500
  num_training_step_calls_since_last_synch_worker_weights: 435
  num_weight_broadcasts: 293
  timing_breakdown:
    learner_dequeue_time_ms: 5554.172
    learner_grad_time_ms: 854.539
    learner_load_time_ms: 35.753
    learner_load_wait_time_ms: 13.742
iterations_since_restore: 2
node_ip: 127.0.0.1
num_agent_steps_sampled: 14950
num_agent_steps_trained: 7500
num_env_steps_sampled: 14950
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 719.9947472001876
num_env_steps_trained: 7500
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.9963522223525
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 57.142857142857146
  ram_util_percent: 80.59285714285714
pid: 48167
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10716591435794401
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03909369854894983
  mean_inference_ms: 1.9623558166963795
  mean_raw_obs_processing_ms: 0.44584487069599704
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03506040573120117
    StateBufferConnector_ms: 0.006445884704589844
    ViewRequirementAgentConnector_ms: 0.20646119117736816
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.19
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 0.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 1.0, 0.0,
      2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 5.0, 1.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0,
      1.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 2.0, 0.0, 0.0, 0.0, 1.0,
      2.0, 2.0, 2.0, 0.0, 4.0, 1.0, 2.0, 1.0, 2.0, 2.0, 0.0, 1.0, 1.0, 0.0, 1.0, 2.0,
      3.0, 0.0, 3.0, 0.0, 1.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0,
      3.0, 1.0, 2.0, 2.0, 0.0, 1.0, 0.0, 4.0, 1.0, 1.0, 3.0, 2.0, 1.0, 0.0, 2.0, 0.0,
      0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10716591435794401
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03909369854894983
    mean_inference_ms: 1.9623558166963795
    mean_raw_obs_processing_ms: 0.44584487069599704
time_since_restore: 20.521591663360596
time_this_iter_s: 10.213925838470459
time_total_s: 20.521591663360596
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.077
timestamp: 1692346931
timesteps_total: 14950
training_iteration: 2
trial_id: default
train step: 3
Traceback (most recent call last):
  File "/Users/sangbin/Impala/launch.py", line 307, in <module>
    result = algo.train()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 372, in train
    result = self.step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 853, in step
    results, train_iter_ctx = self._run_one_training_iteration()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2837, in _run_one_training_iteration
    results = self.training_step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 697, in training_step
    unprocessed_sample_batches = self.get_samples_from_workers(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 907, in get_samples_from_workers
    ] = self.workers.fetch_ready_async_reqs(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py", line 790, in fetch_ready_async_reqs
    return [(r.actor_id, r.get()) for r in remote_results.ignore_errors()]
KeyboardInterrupt
Traceback (most recent call last):
  File "/Users/sangbin/Impala/launch.py", line 307, in <module>
    result = algo.train()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 372, in train
    result = self.step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 853, in step
    results, train_iter_ctx = self._run_one_training_iteration()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2837, in _run_one_training_iteration
    results = self.training_step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 697, in training_step
    unprocessed_sample_batches = self.get_samples_from_workers(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 907, in get_samples_from_workers
    ] = self.workers.fetch_ready_async_reqs(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py", line 790, in fetch_ready_async_reqs
    return [(r.actor_id, r.get()) for r in remote_results.ignore_errors()]
KeyboardInterrupt
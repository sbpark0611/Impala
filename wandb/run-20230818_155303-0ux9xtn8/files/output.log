[34m[1mwandb[39m[22m: [33mWARNING[39m Calling wandb.run.save without any arguments is deprecated.Changes to attributes are automatically persisted.
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py:484: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
`UnifiedLogger` will be removed in Ray 2.7.
  return UnifiedLogger(config, logdir, loggers=None)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `JsonLogger interface is deprecated in favor of the `ray.tune.json.JsonLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `CSVLogger interface is deprecated in favor of the `ray.tune.csv.CSVLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/logger/unified.py:53: RayDeprecationWarning: This API is deprecated and may be removed in future Ray releases. You could suppress this warning by setting env variable PYTHONWARNINGS="ignore::DeprecationWarning"
The `TBXLogger interface is deprecated in favor of the `ray.tune.tensorboardx.TBXLoggerCallback` interface and will be removed in Ray 2.7.
  self._loggers.append(cls(self.config, self.logdir, self.trial))
2023-08-18 15:53:04,270	INFO tensorboardx.py:48 -- pip install "ray[tune]" to see TensorBoard files.
2023-08-18 15:53:04,270	WARNING unified.py:56 -- Could not instantiate TBXLogger: No module named 'tensorboardX'.
[36m(pid=45867)[39m lz4 not available, disabling sample compression. This will significantly impact RLlib performance. To install lz4, run `pip install lz4`.
[36m(pid=45867)[39m DeprecationWarning: `DirectStepOptimizer` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:06,985	WARNING env.py:162 -- Your env doesn't have a .spec.max_episode_steps attribute. Your horizon will default to infinity, and your environment will not be reset.
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:06,989	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:06,989	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:06,993	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.AttentionWrapper` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:06,993	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:06,993	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:07,014	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.GTrXLNet` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:07,027	WARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:07,027	WARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:07,027	WARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:07,027	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/catalog.py:790: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  prep = cls(observation_space, options)
2023-08-18 15:53:07,133	WARNING deprecation.py:50 -- DeprecationWarning: `LearningRateSchedule` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,133	WARNING deprecation.py:50 -- DeprecationWarning: `EntropyCoeffSchedule` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,138	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.AttentionWrapper` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,138	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.fcnet.FullyConnectedNetwork` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,138	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_modelv2.TorchModelV2` has been deprecated. Use `ray.rllib.core.rl_module.rl_module.RLModule` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/torch/attention_net.py:281: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  super().__init__(obs_space, action_space, None, model_config, name)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/torch/attention_net.py:281: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  super().__init__(obs_space, action_space, None, model_config, name)
2023-08-18 15:53:07,144	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.attention_net.GTrXLNet` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,149	WARNING deprecation.py:50 -- DeprecationWarning: `StochasticSampling` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,149	WARNING deprecation.py:50 -- DeprecationWarning: `Exploration` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,149	WARNING deprecation.py:50 -- DeprecationWarning: `Random` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,149	WARNING deprecation.py:50 -- DeprecationWarning: `ValueNetworkMixin` has been deprecated. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/modelv2.py:440: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  prep = get_preprocessor(space)(space)
[36m(RolloutWorker pid=45867)[39m 2023-08-18 15:53:07,085	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
2023-08-18 15:53:07,172	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.models.torch.torch_action_dist.TorchDistributionWrapper` has been deprecated. Use `ray.rllib.models.torch.torch_distributions.TorchCategorical` instead. This will raise an error in the future!
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/models/preprocessors.py:307: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  preprocessor = preprocessor_class(space, self._options)
/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/connectors/agent/obs_preproc.py:40: DeprecationWarning: `product` is deprecated as of NumPy 1.25.0, and will be removed in NumPy 2.0. Please use `prod` instead.
  self._preprocessor = get_preprocessor(obs_space)(
2023-08-18 15:53:07,194	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.multi_gpu_learner_thread.MultiGPULearnerThread` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,195	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.minibatch_buffer.MinibatchBuffer` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,195	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.learner_thread.LearnerThread` has been deprecated. This will raise an error in the future!
2023-08-18 15:53:07,196	WARNING util.py:68 -- Install gputil for GPU system monitoring.
2023-08-18 15:53:07,321	WARNING deprecation.py:50 -- DeprecationWarning: `ray.rllib.execution.replay_ops.SimpleReplayBuffer` has been deprecated. This will raise an error in the future!
train step: 1
agent_timesteps_total: 7900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03246184318296371
  StateBufferConnector_ms: 0.006043141888033959
  ViewRequirementAgentConnector_ms: 0.1925779927161432
counters:
  num_agent_steps_sampled: 7900
  num_agent_steps_trained: 2500
  num_env_steps_sampled: 7900
  num_env_steps_trained: 2500
  num_samples_added_to_queue: 7500
  num_training_step_calls_since_last_synch_worker_weights: 215
  num_weight_broadcasts: 158
custom_metrics: {}
date: 2023-08-18_15-53-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 1.8064516129032258
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 62
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 3.4
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.553763747215271
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 88.85081481933594
        total_loss: 124.50000762939453
        var_gnorm: 63.329566955566406
        vf_explained_var: -1.0
        vf_loss: 72.85213470458984
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 5.0
  learner_queue:
    size_count: 10
    size_mean: 0.0
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 0.0]
    size_std: 0.0
  num_agent_steps_sampled: 7900
  num_agent_steps_trained: 2500
  num_env_steps_sampled: 7900
  num_env_steps_trained: 2500
  num_samples_added_to_queue: 7500
  num_training_step_calls_since_last_synch_worker_weights: 215
  num_weight_broadcasts: 158
  timing_breakdown:
    learner_dequeue_time_ms: 577.143
    learner_grad_time_ms: 930.854
    learner_load_time_ms: 141.484
    learner_load_wait_time_ms: 13.547
iterations_since_restore: 1
node_ip: 127.0.0.1
num_agent_steps_sampled: 7900
num_agent_steps_trained: 2500
num_env_steps_sampled: 7900
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.9957432976249
num_env_steps_trained: 2500
num_env_steps_trained_this_iter: 2500
num_env_steps_trained_throughput_per_sec: 249.99865294228638
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 2500
perf:
  cpu_util_percent: 49.88666666666667
  ram_util_percent: 82.40666666666668
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1009480507689857
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.037372774384516715
  mean_inference_ms: 1.8767770264832018
  mean_raw_obs_processing_ms: 0.4244541656938607
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03246184318296371
    StateBufferConnector_ms: 0.006043141888033959
    ViewRequirementAgentConnector_ms: 0.1925779927161432
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 1.8064516129032258
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128]
    episode_reward: [4.0, 1.0, 3.0, 2.0, 1.0, 2.0, 4.0, 4.0, 1.0, 2.0, 2.0, 2.0, 2.0,
      1.0, 5.0, 0.0, 4.0, 0.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0,
      4.0, 1.0, 0.0, 6.0, 2.0, 2.0, 0.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0,
      0.0, 0.0, 1.0, 2.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0,
      3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1009480507689857
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.037372774384516715
    mean_inference_ms: 1.8767770264832018
    mean_raw_obs_processing_ms: 0.4244541656938607
time_since_restore: 10.31041407585144
time_this_iter_s: 10.31041407585144
time_total_s: 10.31041407585144
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692341597
timesteps_total: 7900
training_iteration: 1
trial_id: default
train step: 2
agent_timesteps_total: 15450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03297781944274902
  StateBufferConnector_ms: 0.006066560745239258
  ViewRequirementAgentConnector_ms: 0.197662353515625
counters:
  num_agent_steps_sampled: 15450
  num_agent_steps_trained: 8000
  num_env_steps_sampled: 15450
  num_env_steps_trained: 8000
  num_samples_added_to_queue: 15000
  num_training_step_calls_since_last_synch_worker_weights: 867
  num_weight_broadcasts: 306
custom_metrics: {}
date: 2023-08-18_15-53-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 1.51
episode_reward_min: 0.0
episodes_this_iter: 59
episodes_total: 121
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 10.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5511119365692139
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 118.02870178222656
        total_loss: 146.0201416015625
        var_gnorm: 63.32918930053711
        vf_explained_var: -1.0
        vf_loss: 57.53399658203125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 16.0
  learner_queue:
    size_count: 20
    size_mean: 0.0
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 0.0]
    size_std: 0.0
  num_agent_steps_sampled: 15450
  num_agent_steps_trained: 8000
  num_env_steps_sampled: 15450
  num_env_steps_trained: 8000
  num_samples_added_to_queue: 15000
  num_training_step_calls_since_last_synch_worker_weights: 867
  num_weight_broadcasts: 306
  timing_breakdown:
    learner_dequeue_time_ms: 5404.407
    learner_grad_time_ms: 1013.016
    learner_load_time_ms: 93.991
    learner_load_wait_time_ms: 17.68
iterations_since_restore: 2
node_ip: 127.0.0.1
num_agent_steps_sampled: 15450
num_agent_steps_trained: 8000
num_env_steps_sampled: 15450
num_env_steps_sampled_this_iter: 7550
num_env_steps_sampled_throughput_per_sec: 754.998181943503
num_env_steps_trained: 8000
num_env_steps_trained_this_iter: 5500
num_env_steps_trained_throughput_per_sec: 549.9986755879823
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5500
perf:
  cpu_util_percent: 54.59285714285715
  ram_util_percent: 82.06428571428572
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10280725118613632
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03784175421806862
  mean_inference_ms: 1.9114185160875954
  mean_raw_obs_processing_ms: 0.43083835703617157
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03297781944274902
    StateBufferConnector_ms: 0.006066560745239258
    ViewRequirementAgentConnector_ms: 0.197662353515625
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 1.51
  episode_reward_min: 0.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 2.0, 4.0, 1.0, 0.0, 6.0, 2.0,
      2.0, 0.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 1.0, 2.0, 3.0,
      0.0, 1.0, 1.0, 3.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 0.0, 3.0, 2.0, 1.0, 2.0, 4.0,
      0.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 1.0, 2.0, 5.0, 1.0,
      2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0,
      0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0,
      0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10280725118613632
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03784175421806862
    mean_inference_ms: 1.9114185160875954
    mean_raw_obs_processing_ms: 0.43083835703617157
time_since_restore: 20.48775315284729
time_this_iter_s: 10.17733907699585
time_total_s: 20.48775315284729
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692341607
timesteps_total: 15450
training_iteration: 2
trial_id: default
train step: 3
agent_timesteps_total: 22450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03472566604614258
  StateBufferConnector_ms: 0.006364107131958008
  ViewRequirementAgentConnector_ms: 0.21848607063293457
counters:
  num_agent_steps_sampled: 22450
  num_agent_steps_trained: 13000
  num_env_steps_sampled: 22450
  num_env_steps_trained: 13000
  num_samples_added_to_queue: 22000
  num_training_step_calls_since_last_synch_worker_weights: 195
  num_weight_broadcasts: 443
custom_metrics: {}
date: 2023-08-18_15-53-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.4
episode_reward_min: 0.0
episodes_this_iter: 55
episodes_total: 176
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 11.8
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5479930639266968
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 35.17308807373047
        total_loss: 60.511531829833984
        var_gnorm: 63.32890319824219
        vf_explained_var: -1.0
        vf_loss: 52.224884033203125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 26.0
  learner_queue:
    size_count: 32
    size_mean: 0.09375
    size_quantiles: [0.0, 0.0, 0.0, 0.0, 2.0]
    size_std: 0.38400642898264087
  num_agent_steps_sampled: 22450
  num_agent_steps_trained: 13000
  num_env_steps_sampled: 22450
  num_env_steps_trained: 13000
  num_samples_added_to_queue: 22000
  num_training_step_calls_since_last_synch_worker_weights: 195
  num_weight_broadcasts: 443
  timing_breakdown:
    learner_dequeue_time_ms: 4276.747
    learner_grad_time_ms: 804.629
    learner_load_time_ms: 63.397
    learner_load_wait_time_ms: 7.24
iterations_since_restore: 3
node_ip: 127.0.0.1
num_agent_steps_sampled: 22450
num_agent_steps_trained: 13000
num_env_steps_sampled: 22450
num_env_steps_sampled_this_iter: 7000
num_env_steps_sampled_throughput_per_sec: 699.9964785753017
num_env_steps_trained: 13000
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.99748469664405
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 58.59333333333333
  ram_util_percent: 83.14666666666666
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10554700589502346
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039064010524581215
  mean_inference_ms: 1.9738097791038915
  mean_raw_obs_processing_ms: 0.44501192035662457
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03472566604614258
    StateBufferConnector_ms: 0.006364107131958008
    ViewRequirementAgentConnector_ms: 0.21848607063293457
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.4
  episode_reward_min: 0.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 1.0, 2.0, 5.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 2.0,
      1.0, 2.0, 1.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 1.0, 1.0, 3.0,
      1.0, 1.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 0.0, 1.0, 3.0, 2.0, 1.0, 1.0, 0.0,
      1.0, 1.0, 1.0, 0.0, 3.0, 0.0, 2.0, 0.0, 1.0, 1.0, 2.0, 3.0, 4.0, 1.0, 0.0, 3.0,
      0.0, 0.0, 3.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 0.0,
      1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0, 3.0,
      0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10554700589502346
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039064010524581215
    mean_inference_ms: 1.9738097791038915
    mean_raw_obs_processing_ms: 0.44501192035662457
time_since_restore: 30.72095012664795
time_this_iter_s: 10.23319697380066
time_total_s: 30.72095012664795
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692341617
timesteps_total: 22450
training_iteration: 3
trial_id: default
train step: 4
agent_timesteps_total: 30550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033545494079589844
  StateBufferConnector_ms: 0.006145954132080078
  ViewRequirementAgentConnector_ms: 0.24236154556274414
counters:
  num_agent_steps_sampled: 30550
  num_agent_steps_trained: 19000
  num_env_steps_sampled: 30550
  num_env_steps_trained: 19000
  num_samples_added_to_queue: 30500
  num_training_step_calls_since_last_synch_worker_weights: 1047
  num_weight_broadcasts: 602
custom_metrics: {}
date: 2023-08-18_15-53-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.61
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 239
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 14.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5572879314422607
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -4.385904788970947
        total_loss: 10.112879753112793
        var_gnorm: 63.32857131958008
        vf_explained_var: -0.7580475807189941
        vf_loss: 30.554855346679688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 38.0
  learner_queue:
    size_count: 43
    size_mean: 0.8372093023255814
    size_quantiles: [0.0, 0.0, 0.0, 3.8000000000000043, 6.0]
    size_std: 1.683438239149196
  num_agent_steps_sampled: 30550
  num_agent_steps_trained: 19000
  num_env_steps_sampled: 30550
  num_env_steps_trained: 19000
  num_samples_added_to_queue: 30500
  num_training_step_calls_since_last_synch_worker_weights: 1047
  num_weight_broadcasts: 602
  timing_breakdown:
    learner_dequeue_time_ms: 3832.421
    learner_grad_time_ms: 903.406
    learner_load_time_ms: 63.397
    learner_load_wait_time_ms: 33.758
iterations_since_restore: 4
node_ip: 127.0.0.1
num_agent_steps_sampled: 30550
num_agent_steps_trained: 19000
num_env_steps_sampled: 30550
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9935884983211
num_env_steps_trained: 19000
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.995250739497
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 47.57142857142856
  ram_util_percent: 83.37142857142855
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10601790291987914
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03927557205951056
  mean_inference_ms: 1.9818353586570538
  mean_raw_obs_processing_ms: 0.44843491276182335
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033545494079589844
    StateBufferConnector_ms: 0.006145954132080078
    ViewRequirementAgentConnector_ms: 0.24236154556274414
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.61
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 0.0, 3.0, 0.0, 0.0, 2.0, 1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 0.0,
      0.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 2.0, 2.0,
      3.0, 0.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 0.0, 3.0, 0.0,
      2.0, 3.0, 3.0, 1.0, 1.0, 0.0, 2.0, 2.0, 3.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0,
      2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 0.0, 1.0, 2.0, 1.0, 1.0, 5.0,
      4.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 5.0, 4.0, 4.0, 1.0, 0.0, 2.0, 2.0, 1.0,
      1.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10601790291987914
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03927557205951056
    mean_inference_ms: 1.9818353586570538
    mean_raw_obs_processing_ms: 0.44843491276182335
time_since_restore: 40.99896717071533
time_this_iter_s: 10.278017044067383
time_total_s: 40.99896717071533
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.076
timestamp: 1692341628
timesteps_total: 30550
training_iteration: 4
trial_id: default
train step: 5
agent_timesteps_total: 37100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03566455841064453
  StateBufferConnector_ms: 0.006684303283691406
  ViewRequirementAgentConnector_ms: 0.24999213218688965
counters:
  num_agent_steps_sampled: 37100
  num_agent_steps_trained: 24000
  num_env_steps_sampled: 37100
  num_env_steps_trained: 24000
  num_samples_added_to_queue: 37000
  num_training_step_calls_since_last_synch_worker_weights: 382
  num_weight_broadcasts: 730
custom_metrics: {}
date: 2023-08-18_15-53-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.57
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 291
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 14.100000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5405890941619873
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 15.086265563964844
        total_loss: 32.67920684814453
        var_gnorm: 63.328330993652344
        vf_explained_var: -0.6292144060134888
        vf_loss: 36.72646713256836
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 48.0
  learner_queue:
    size_count: 54
    size_mean: 2.0
    size_quantiles: [0.0, 0.0, 0.0, 6.100000000000001, 9.0]
    size_std: 2.727636339397171
  num_agent_steps_sampled: 37100
  num_agent_steps_trained: 24000
  num_env_steps_sampled: 37100
  num_env_steps_trained: 24000
  num_samples_added_to_queue: 37000
  num_training_step_calls_since_last_synch_worker_weights: 382
  num_weight_broadcasts: 730
  timing_breakdown:
    learner_dequeue_time_ms: 3065.938
    learner_grad_time_ms: 909.244
    learner_load_time_ms: 48.537
    learner_load_wait_time_ms: 19.078
iterations_since_restore: 5
node_ip: 127.0.0.1
num_agent_steps_sampled: 37100
num_agent_steps_trained: 24000
num_env_steps_sampled: 37100
num_env_steps_sampled_this_iter: 6550
num_env_steps_sampled_throughput_per_sec: 654.9988287708245
num_env_steps_trained: 24000
num_env_steps_trained_this_iter: 5000
num_env_steps_trained_throughput_per_sec: 499.9991059319271
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5000
perf:
  cpu_util_percent: 54.56000000000001
  ram_util_percent: 83.43333333333334
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10702105439496386
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039546643270656504
  mean_inference_ms: 1.9994290873656262
  mean_raw_obs_processing_ms: 0.45475776189542716
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03566455841064453
    StateBufferConnector_ms: 0.006684303283691406
    ViewRequirementAgentConnector_ms: 0.24999213218688965
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.57
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 0.0, 2.0, 2.0, 3.0, 1.0, 1.0, 0.0, 2.0, 2.0, 2.0, 3.0,
      2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 0.0, 1.0, 2.0, 1.0, 1.0, 5.0, 4.0, 0.0, 1.0, 1.0,
      2.0, 0.0, 1.0, 1.0, 5.0, 4.0, 4.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 1.0, 2.0,
      2.0, 1.0, 3.0, 1.0, 1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 1.0, 1.0, 3.0,
      0.0, 2.0, 0.0, 2.0, 3.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 0.0,
      0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 5.0, 1.0, 4.0, 0.0, 1.0, 0.0, 1.0, 1.0,
      0.0, 3.0, 0.0, 1.0, 1.0, 4.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10702105439496386
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039546643270656504
    mean_inference_ms: 1.9994290873656262
    mean_raw_obs_processing_ms: 0.45475776189542716
time_since_restore: 51.22349405288696
time_this_iter_s: 10.22452688217163
time_total_s: 51.22349405288696
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1692341638
timesteps_total: 37100
training_iteration: 5
trial_id: default
train step: 6
agent_timesteps_total: 45000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034035682678222656
  StateBufferConnector_ms: 0.006445884704589844
  ViewRequirementAgentConnector_ms: 0.20813298225402832
counters:
  num_agent_steps_sampled: 45000
  num_agent_steps_trained: 29500
  num_env_steps_sampled: 45000
  num_env_steps_trained: 29500
  num_samples_added_to_queue: 45000
  num_training_step_calls_since_last_synch_worker_weights: 516
  num_weight_broadcasts: 885
custom_metrics: {}
date: 2023-08-18_15-54-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.6
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 352
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 21.299999999999997
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5523386001586914
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 9.453557968139648
        total_loss: 21.351539611816406
        var_gnorm: 63.32811737060547
        vf_explained_var: -0.5310156345367432
        vf_loss: 25.348302841186523
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 59.0
  learner_queue:
    size_count: 65
    size_mean: 4.24
    size_quantiles: [0.0, 0.0, 4.0, 10.100000000000001, 14.0]
    size_std: 4.202665820642893
  num_agent_steps_sampled: 45000
  num_agent_steps_trained: 29500
  num_env_steps_sampled: 45000
  num_env_steps_trained: 29500
  num_samples_added_to_queue: 45000
  num_training_step_calls_since_last_synch_worker_weights: 516
  num_weight_broadcasts: 885
  timing_breakdown:
    learner_dequeue_time_ms: 2554.949
    learner_grad_time_ms: 846.069
    learner_load_time_ms: 39.417
    learner_load_wait_time_ms: 15.076
iterations_since_restore: 6
node_ip: 127.0.0.1
num_agent_steps_sampled: 45000
num_agent_steps_trained: 29500
num_env_steps_sampled: 45000
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.9951594172485
num_env_steps_trained: 29500
num_env_steps_trained_this_iter: 5500
num_env_steps_trained_throughput_per_sec: 549.9966299740338
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 5500
perf:
  cpu_util_percent: 54.02857142857142
  ram_util_percent: 82.82142857142857
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10794750327905209
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0398089534616508
  mean_inference_ms: 2.0151492222360274
  mean_raw_obs_processing_ms: 0.45992496922161974
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034035682678222656
    StateBufferConnector_ms: 0.006445884704589844
    ViewRequirementAgentConnector_ms: 0.20813298225402832
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.6
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 2.0, 0.0, 2.0, 3.0, 4.0, 2.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0,
      3.0, 2.0, 0.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 2.0, 1.0, 5.0, 1.0, 4.0, 0.0, 1.0,
      0.0, 1.0, 1.0, 0.0, 3.0, 0.0, 1.0, 1.0, 4.0, 0.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0,
      3.0, 1.0, 1.0, 2.0, 3.0, 3.0, 4.0, 0.0, 1.0, 1.0, 2.0, 0.0, 1.0, 1.0, 3.0, 2.0,
      3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0,
      3.0, 2.0, 1.0, 0.0, 1.0, 4.0, 4.0, 3.0, 4.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 3.0,
      1.0, 2.0, 0.0, 4.0, 2.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10794750327905209
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0398089534616508
    mean_inference_ms: 2.0151492222360274
    mean_raw_obs_processing_ms: 0.45992496922161974
time_since_restore: 61.43439984321594
time_this_iter_s: 10.21090579032898
time_total_s: 61.43439984321594
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692341648
timesteps_total: 45000
training_iteration: 6
trial_id: default
train step: 7
agent_timesteps_total: 52700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0322418212890625
  StateBufferConnector_ms: 0.0058901309967041016
  ViewRequirementAgentConnector_ms: 0.19115257263183594
counters:
  num_agent_steps_sampled: 52700
  num_agent_steps_trained: 36000
  num_env_steps_sampled: 52700
  num_env_steps_trained: 36000
  num_samples_added_to_queue: 52500
  num_training_step_calls_since_last_synch_worker_weights: 1701
  num_weight_broadcasts: 1034
custom_metrics: {}
date: 2023-08-18_15-54-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 4.0
episode_reward_mean: 1.7
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 413
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 24.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5430290699005127
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -61.53963088989258
        total_loss: -54.14024353027344
        var_gnorm: 63.32793045043945
        vf_explained_var: -0.2307741641998291
        vf_loss: 16.341808319091797
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 72.0
  learner_queue:
    size_count: 77
    size_mean: 7.54
    size_quantiles: [0.0, 0.0, 7.0, 15.0, 16.0]
    size_std: 5.158333064081845
  num_agent_steps_sampled: 52700
  num_agent_steps_trained: 36000
  num_env_steps_sampled: 52700
  num_env_steps_trained: 36000
  num_samples_added_to_queue: 52500
  num_training_step_calls_since_last_synch_worker_weights: 1701
  num_weight_broadcasts: 1034
  timing_breakdown:
    learner_dequeue_time_ms: 2554.949
    learner_grad_time_ms: 689.382
    learner_load_time_ms: 39.417
    learner_load_wait_time_ms: 9.325
iterations_since_restore: 7
node_ip: 127.0.0.1
num_agent_steps_sampled: 52700
num_agent_steps_trained: 36000
num_env_steps_sampled: 52700
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 769.9976868698943
num_env_steps_trained: 36000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9980473577031
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 50.586666666666666
  ram_util_percent: 83.03333333333333
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10768815216147262
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03942255503762291
  mean_inference_ms: 2.0047543913634436
  mean_raw_obs_processing_ms: 0.45631099762586347
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0322418212890625
    StateBufferConnector_ms: 0.0058901309967041016
    ViewRequirementAgentConnector_ms: 0.19115257263183594
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 4.0
  episode_reward_mean: 1.7
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 1.0, 0.0, 0.0, 0.0, 0.0, 2.0, 3.0, 0.0, 1.0, 3.0, 3.0,
      3.0, 3.0, 2.0, 3.0, 2.0, 1.0, 0.0, 1.0, 4.0, 4.0, 3.0, 4.0, 2.0, 2.0, 1.0, 0.0,
      2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 4.0, 2.0, 1.0, 1.0, 3.0, 1.0, 4.0, 2.0, 1.0, 2.0,
      2.0, 2.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0,
      2.0, 3.0, 0.0, 2.0, 2.0, 0.0, 0.0, 4.0, 1.0, 0.0, 2.0, 3.0, 1.0, 1.0, 0.0, 1.0,
      3.0, 1.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 4.0, 3.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0,
      0.0, 2.0, 3.0, 0.0, 1.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10768815216147262
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03942255503762291
    mean_inference_ms: 2.0047543913634436
    mean_raw_obs_processing_ms: 0.45631099762586347
time_since_restore: 71.69147205352783
time_this_iter_s: 10.25707221031189
time_total_s: 71.69147205352783
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.01
  training_iteration_time_ms: 0.104
timestamp: 1692341658
timesteps_total: 52700
training_iteration: 7
trial_id: default
train step: 8
agent_timesteps_total: 60200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03305697441101074
  StateBufferConnector_ms: 0.006174564361572266
  ViewRequirementAgentConnector_ms: 0.19946646690368652
counters:
  num_agent_steps_sampled: 60200
  num_agent_steps_trained: 43500
  num_env_steps_sampled: 60200
  num_env_steps_trained: 43500
  num_samples_added_to_queue: 60000
  num_training_step_calls_since_last_synch_worker_weights: 622
  num_weight_broadcasts: 1181
custom_metrics: {}
date: 2023-08-18_15-54-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.77
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 471
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 28.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5336495637893677
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 108.02046966552734
        total_loss: 122.3355484008789
        var_gnorm: 63.327735900878906
        vf_explained_var: -0.28599870204925537
        vf_loss: 30.163795471191406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 87.0
  learner_queue:
    size_count: 92
    size_mean: 11.34
    size_quantiles: [2.0, 4.9, 12.0, 16.0, 16.0]
    size_std: 4.221895308981501
  num_agent_steps_sampled: 60200
  num_agent_steps_trained: 43500
  num_env_steps_sampled: 60200
  num_env_steps_trained: 43500
  num_samples_added_to_queue: 60000
  num_training_step_calls_since_last_synch_worker_weights: 622
  num_weight_broadcasts: 1181
  timing_breakdown:
    learner_dequeue_time_ms: 2189.957
    learner_grad_time_ms: 359.466
    learner_load_time_ms: 33.443
    learner_load_wait_time_ms: 2.86
iterations_since_restore: 8
node_ip: 127.0.0.1
num_agent_steps_sampled: 60200
num_agent_steps_trained: 43500
num_env_steps_sampled: 60200
num_env_steps_sampled_this_iter: 7500
num_env_steps_sampled_throughput_per_sec: 749.9948859563498
num_env_steps_trained: 43500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9948859563498
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.914285714285725
  ram_util_percent: 84.27857142857142
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10778899234729808
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039383149184533096
  mean_inference_ms: 2.004587616799536
  mean_raw_obs_processing_ms: 0.4557968521873417
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03305697441101074
    StateBufferConnector_ms: 0.006174564361572266
    ViewRequirementAgentConnector_ms: 0.19946646690368652
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.77
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 2.0, 2.0, 3.0, 0.0, 2.0, 2.0, 0.0, 0.0, 4.0, 1.0, 0.0,
      2.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 0.0, 3.0, 0.0, 2.0, 3.0, 4.0, 3.0,
      2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 0.0, 2.0, 3.0, 0.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0,
      3.0, 1.0, 1.0, 2.0, 1.0, 0.0, 3.0, 4.0, 4.0, 0.0, 2.0, 5.0, 1.0, 2.0, 3.0, 0.0,
      0.0, 1.0, 3.0, 3.0, 2.0, 4.0, 3.0, 2.0, 0.0, 4.0, 1.0, 3.0, 0.0, 4.0, 2.0, 1.0,
      1.0, 5.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0,
      1.0, 0.0, 3.0, 3.0, 1.0, 2.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10778899234729808
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039383149184533096
    mean_inference_ms: 2.004587616799536
    mean_raw_obs_processing_ms: 0.4557968521873417
time_since_restore: 81.91239809989929
time_this_iter_s: 10.22092604637146
time_total_s: 81.91239809989929
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692341669
timesteps_total: 60200
training_iteration: 8
trial_id: default
train step: 9
agent_timesteps_total: 68600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03153705596923828
  StateBufferConnector_ms: 0.005750179290771484
  ViewRequirementAgentConnector_ms: 0.18936491012573242
counters:
  num_agent_steps_sampled: 68600
  num_agent_steps_trained: 52000
  num_env_steps_sampled: 68600
  num_env_steps_trained: 52000
  num_samples_added_to_queue: 68500
  num_training_step_calls_since_last_synch_worker_weights: 454
  num_weight_broadcasts: 1345
custom_metrics: {}
date: 2023-08-18_15-54-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 1.87
episode_reward_min: 0.0
episodes_this_iter: 66
episodes_total: 537
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.3
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5166170597076416
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 9.94387435913086
        total_loss: 19.249067306518555
        var_gnorm: 63.32758331298828
        vf_explained_var: 0.006560802459716797
        vf_loss: 20.127002716064453
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 104.0
  learner_queue:
    size_count: 109
    size_mean: 14.28
    size_quantiles: [9.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.96
  num_agent_steps_sampled: 68600
  num_agent_steps_trained: 52000
  num_env_steps_sampled: 68600
  num_env_steps_trained: 52000
  num_samples_added_to_queue: 68500
  num_training_step_calls_since_last_synch_worker_weights: 454
  num_weight_broadcasts: 1345
  timing_breakdown:
    learner_dequeue_time_ms: 1916.214
    learner_grad_time_ms: 338.311
    learner_load_time_ms: 29.007
    learner_load_wait_time_ms: 2.625
iterations_since_restore: 9
node_ip: 127.0.0.1
num_agent_steps_sampled: 68600
num_agent_steps_trained: 52000
num_env_steps_sampled: 68600
num_env_steps_sampled_this_iter: 8400
num_env_steps_sampled_throughput_per_sec: 839.9972162338959
num_env_steps_trained: 52000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9971830938232
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 47.971428571428575
  ram_util_percent: 83.72857142857144
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10693670386302533
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.038975886487755046
  mean_inference_ms: 1.9891590662361975
  mean_raw_obs_processing_ms: 0.45226852653772964
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03153705596923828
    StateBufferConnector_ms: 0.005750179290771484
    ViewRequirementAgentConnector_ms: 0.18936491012573242
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 1.87
  episode_reward_min: 0.0
  episodes_this_iter: 66
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 2.0, 0.0, 4.0, 1.0, 3.0, 0.0, 4.0, 2.0, 1.0, 1.0, 5.0,
      1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 0.0, 1.0, 2.0, 2.0, 1.0, 0.0,
      3.0, 3.0, 1.0, 2.0, 4.0, 2.0, 3.0, 4.0, 0.0, 1.0, 3.0, 0.0, 1.0, 4.0, 1.0, 2.0,
      4.0, 6.0, 4.0, 2.0, 2.0, 5.0, 3.0, 2.0, 1.0, 1.0, 0.0, 3.0, 1.0, 4.0, 0.0, 0.0,
      1.0, 3.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0,
      2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0,
      1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10693670386302533
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.038975886487755046
    mean_inference_ms: 1.9891590662361975
    mean_raw_obs_processing_ms: 0.45226852653772964
time_since_restore: 92.13376688957214
time_this_iter_s: 10.221368789672852
time_total_s: 92.13376688957214
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.075
timestamp: 1692341679
timesteps_total: 68600
training_iteration: 9
trial_id: default
train step: 10
agent_timesteps_total: 76450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03194403648376465
  StateBufferConnector_ms: 0.005594015121459961
  ViewRequirementAgentConnector_ms: 0.18746018409729004
counters:
  num_agent_steps_sampled: 76450
  num_agent_steps_trained: 59500
  num_env_steps_sampled: 76450
  num_env_steps_trained: 59500
  num_samples_added_to_queue: 76000
  num_training_step_calls_since_last_synch_worker_weights: 820
  num_weight_broadcasts: 1499
custom_metrics: {}
date: 2023-08-18_15-54-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 1.65
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 598
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.3
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5262532234191895
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 44.559661865234375
        total_loss: 60.1847038269043
        var_gnorm: 63.32756805419922
        vf_explained_var: -0.11700057983398438
        vf_loss: 32.776336669921875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 119.0
  learner_queue:
    size_count: 123
    size_mean: 14.86
    size_quantiles: [12.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.4698299221338502
  num_agent_steps_sampled: 76450
  num_agent_steps_trained: 59500
  num_env_steps_sampled: 76450
  num_env_steps_trained: 59500
  num_samples_added_to_queue: 76000
  num_training_step_calls_since_last_synch_worker_weights: 820
  num_weight_broadcasts: 1499
  timing_breakdown:
    learner_dequeue_time_ms: 1703.302
    learner_grad_time_ms: 450.653
    learner_load_time_ms: 26.063
    learner_load_wait_time_ms: 2.785
iterations_since_restore: 10
node_ip: 127.0.0.1
num_agent_steps_sampled: 76450
num_agent_steps_trained: 59500
num_env_steps_sampled: 76450
num_env_steps_sampled_this_iter: 7850
num_env_steps_sampled_throughput_per_sec: 784.9975669459413
num_env_steps_trained: 59500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9976754260587
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.80666666666666
  ram_util_percent: 83.72666666666667
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1063688632183364
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03867843893347364
  mean_inference_ms: 1.9766958692133654
  mean_raw_obs_processing_ms: 0.44974243110774836
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03194403648376465
    StateBufferConnector_ms: 0.005594015121459961
    ViewRequirementAgentConnector_ms: 0.18746018409729004
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 1.65
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 3.0, 2.0, 4.0, 1.0, 1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 1.0,
      3.0, 1.0, 2.0, 2.0, 1.0, 0.0, 2.0, 0.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0,
      1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 4.0, 3.0, 2.0,
      2.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 6.0, 1.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 1.0,
      2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0,
      2.0, 0.0, 0.0, 3.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0, 2.0, 4.0, 2.0, 1.0,
      3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1063688632183364
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03867843893347364
    mean_inference_ms: 1.9766958692133654
    mean_raw_obs_processing_ms: 0.44974243110774836
time_since_restore: 102.30940294265747
time_this_iter_s: 10.175636053085327
time_total_s: 102.30940294265747
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.073
timestamp: 1692341689
timesteps_total: 76450
training_iteration: 10
trial_id: default
train step: 11
agent_timesteps_total: 84200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.032898902893066406
  StateBufferConnector_ms: 0.005924701690673828
  ViewRequirementAgentConnector_ms: 0.19567489624023438
counters:
  num_agent_steps_sampled: 84200
  num_agent_steps_trained: 67500
  num_env_steps_sampled: 84200
  num_env_steps_trained: 67500
  num_samples_added_to_queue: 84000
  num_training_step_calls_since_last_synch_worker_weights: 310
  num_weight_broadcasts: 1651
custom_metrics: {}
date: 2023-08-18_15-54-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 4.0
episode_reward_mean: 1.66
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 658
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.3
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.5234209299087524
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -72.38948059082031
        total_loss: -66.14727020263672
        var_gnorm: 63.32756805419922
        vf_explained_var: -0.12278902530670166
        vf_loss: 14.007842063903809
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 135.0
  learner_queue:
    size_count: 141
    size_mean: 14.94
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5415576538034508
  num_agent_steps_sampled: 84200
  num_agent_steps_trained: 67500
  num_env_steps_sampled: 84200
  num_env_steps_trained: 67500
  num_samples_added_to_queue: 84000
  num_training_step_calls_since_last_synch_worker_weights: 310
  num_weight_broadcasts: 1651
  timing_breakdown:
    learner_dequeue_time_ms: 1532.972
    learner_grad_time_ms: 326.501
    learner_load_time_ms: 23.416
    learner_load_wait_time_ms: 2.664
iterations_since_restore: 11
node_ip: 127.0.0.1
num_agent_steps_sampled: 84200
num_agent_steps_trained: 67500
num_env_steps_sampled: 84200
num_env_steps_sampled_this_iter: 7750
num_env_steps_sampled_throughput_per_sec: 774.9920363052452
num_env_steps_trained: 67500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.991779411866
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 54.67857142857143
  ram_util_percent: 83.47857142857143
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10603371802544678
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03861052287075139
  mean_inference_ms: 1.973277843647982
  mean_raw_obs_processing_ms: 0.4489271918796829
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.032898902893066406
    StateBufferConnector_ms: 0.005924701690673828
    ViewRequirementAgentConnector_ms: 0.19567489624023438
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 4.0
  episode_reward_mean: 1.66
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 1.0, 4.0, 1.0, 1.0, 0.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0,
      1.0, 1.0, 0.0, 0.0, 2.0, 0.0, 0.0, 3.0, 1.0, 2.0, 4.0, 1.0, 1.0, 2.0, 1.0, 0.0,
      2.0, 4.0, 2.0, 1.0, 3.0, 1.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0,
      3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0,
      2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 4.0, 0.0,
      1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 1.0, 3.0,
      2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10603371802544678
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03861052287075139
    mean_inference_ms: 1.973277843647982
    mean_raw_obs_processing_ms: 0.4489271918796829
time_since_restore: 112.53271389007568
time_this_iter_s: 10.223310947418213
time_total_s: 112.53271389007568
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692341699
timesteps_total: 84200
training_iteration: 11
trial_id: default
train step: 12
agent_timesteps_total: 90650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03762650489807129
  StateBufferConnector_ms: 0.0066983699798583984
  ViewRequirementAgentConnector_ms: 0.2172541618347168
counters:
  num_agent_steps_sampled: 90650
  num_agent_steps_trained: 74000
  num_env_steps_sampled: 90650
  num_env_steps_trained: 74000
  num_samples_added_to_queue: 90500
  num_training_step_calls_since_last_synch_worker_weights: 644
  num_weight_broadcasts: 1777
custom_metrics: {}
date: 2023-08-18_15-55-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.86
episode_reward_min: 0.0
episodes_this_iter: 50
episodes_total: 708
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.3
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4860551357269287
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -34.70970153808594
        total_loss: -29.409046173095703
        var_gnorm: 63.327640533447266
        vf_explained_var: -0.4414522647857666
        vf_loss: 12.087363243103027
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 148.0
  learner_queue:
    size_count: 153
    size_mean: 14.82
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5451860729374955
  num_agent_steps_sampled: 90650
  num_agent_steps_trained: 74000
  num_env_steps_sampled: 90650
  num_env_steps_trained: 74000
  num_samples_added_to_queue: 90500
  num_training_step_calls_since_last_synch_worker_weights: 644
  num_weight_broadcasts: 1777
  timing_breakdown:
    learner_dequeue_time_ms: 1475.259
    learner_grad_time_ms: 647.024
    learner_load_time_ms: 22.302
    learner_load_wait_time_ms: 4.317
iterations_since_restore: 12
node_ip: 127.0.0.1
num_agent_steps_sampled: 90650
num_agent_steps_trained: 74000
num_env_steps_sampled: 90650
num_env_steps_sampled_this_iter: 6450
num_env_steps_sampled_throughput_per_sec: 644.9960786342608
num_env_steps_trained: 74000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9960482360768
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 62.5
  ram_util_percent: 81.88000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10643863572115986
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039009318549807694
  mean_inference_ms: 1.9869587148107521
  mean_raw_obs_processing_ms: 0.4517251414858887
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03762650489807129
    StateBufferConnector_ms: 0.0066983699798583984
    ViewRequirementAgentConnector_ms: 0.2172541618347168
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.86
  episode_reward_min: 0.0
  episodes_this_iter: 50
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 1.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0,
      1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 4.0, 0.0, 1.0, 3.0,
      3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0,
      4.0, 1.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 1.0, 4.0, 0.0, 5.0, 2.0, 1.0, 3.0, 3.0,
      2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0,
      2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0,
      2.0, 5.0, 0.0, 1.0, 3.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10643863572115986
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039009318549807694
    mean_inference_ms: 1.9869587148107521
    mean_raw_obs_processing_ms: 0.4517251414858887
time_since_restore: 122.77457880973816
time_this_iter_s: 10.241864919662476
time_total_s: 122.77457880973816
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.075
timestamp: 1692341710
timesteps_total: 90650
training_iteration: 12
trial_id: default
train step: 13
agent_timesteps_total: 98950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03439688682556152
  StateBufferConnector_ms: 0.006148576736450195
  ViewRequirementAgentConnector_ms: 0.20176959037780762
counters:
  num_agent_steps_sampled: 98950
  num_agent_steps_trained: 82000
  num_env_steps_sampled: 98950
  num_env_steps_trained: 82000
  num_samples_added_to_queue: 98500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 1940
custom_metrics: {}
date: 2023-08-18_15-55-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.05
episode_reward_min: 0.0
episodes_this_iter: 65
episodes_total: 773
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4960848093032837
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 12.808959007263184
        total_loss: 19.105239868164062
        var_gnorm: 63.32771301269531
        vf_explained_var: 0.24717289209365845
        vf_loss: 14.08864688873291
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 164.0
  learner_queue:
    size_count: 169
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.552932709424333
  num_agent_steps_sampled: 98950
  num_agent_steps_trained: 82000
  num_env_steps_sampled: 98950
  num_env_steps_trained: 82000
  num_samples_added_to_queue: 98500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 1940
  timing_breakdown:
    learner_dequeue_time_ms: 452.093
    learner_grad_time_ms: 370.305
    learner_load_time_ms: 8.383
    learner_load_wait_time_ms: 2.635
iterations_since_restore: 13
node_ip: 127.0.0.1
num_agent_steps_sampled: 98950
num_agent_steps_trained: 82000
num_env_steps_sampled: 98950
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.8072232822499
num_env_steps_trained: 82000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.8141911154215
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 47.24285714285713
  ram_util_percent: 81.15714285714286
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10676365430020997
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039123538650753215
  mean_inference_ms: 1.9909204332053883
  mean_raw_obs_processing_ms: 0.4521352016043542
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03439688682556152
    StateBufferConnector_ms: 0.006148576736450195
    ViewRequirementAgentConnector_ms: 0.20176959037780762
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.05
  episode_reward_min: 0.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 5.0, 2.0, 2.0, 1.0, 4.0, 1.0, 1.0, 2.0, 1.0, 2.0, 2.0,
      3.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 2.0, 2.0,
      5.0, 0.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0, 0.0, 3.0, 2.0, 4.0, 4.0, 1.0, 0.0, 0.0,
      4.0, 1.0, 3.0, 0.0, 4.0, 0.0, 1.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 4.0, 4.0, 1.0,
      1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 5.0, 2.0,
      1.0, 1.0, 3.0, 1.0, 6.0, 2.0, 2.0, 5.0, 2.0, 1.0, 3.0, 2.0, 4.0, 2.0, 4.0, 0.0,
      2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10676365430020997
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039123538650753215
    mean_inference_ms: 1.9909204332053883
    mean_raw_obs_processing_ms: 0.4521352016043542
time_since_restore: 132.96384572982788
time_this_iter_s: 10.189266920089722
time_total_s: 132.96384572982788
timers:
  sample_time_ms: 0.066
  synch_weights_time_ms: 0.385
  training_iteration_time_ms: 0.57
timestamp: 1692341720
timesteps_total: 98950
training_iteration: 13
trial_id: default
train step: 14
agent_timesteps_total: 106700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03212475776672363
  StateBufferConnector_ms: 0.005762815475463867
  ViewRequirementAgentConnector_ms: 0.19169926643371582
counters:
  num_agent_steps_sampled: 106700
  num_agent_steps_trained: 90000
  num_env_steps_sampled: 106700
  num_env_steps_trained: 90000
  num_samples_added_to_queue: 106500
  num_training_step_calls_since_last_synch_worker_weights: 478
  num_weight_broadcasts: 2092
custom_metrics: {}
date: 2023-08-18_15-55-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.36
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 834
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4786527156829834
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 30.153535842895508
        total_loss: 36.3881721496582
        var_gnorm: 63.32780456542969
        vf_explained_var: 0.16148918867111206
        vf_loss: 13.947927474975586
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 180.0
  learner_queue:
    size_count: 186
    size_mean: 14.62
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.635726138447387
  num_agent_steps_sampled: 106700
  num_agent_steps_trained: 90000
  num_env_steps_sampled: 106700
  num_env_steps_trained: 90000
  num_samples_added_to_queue: 106500
  num_training_step_calls_since_last_synch_worker_weights: 478
  num_weight_broadcasts: 2092
  timing_breakdown:
    learner_dequeue_time_ms: 249.951
    learner_grad_time_ms: 351.976
    learner_load_time_ms: 3.957
    learner_load_wait_time_ms: 2.834
iterations_since_restore: 14
node_ip: 127.0.0.1
num_agent_steps_sampled: 106700
num_agent_steps_trained: 90000
num_env_steps_sampled: 106700
num_env_steps_sampled_this_iter: 7750
num_env_steps_sampled_throughput_per_sec: 774.9921656446878
num_env_steps_trained: 90000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9919129235487
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 53.27142857142858
  ram_util_percent: 81.26428571428572
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10658116607076007
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03892177601958023
  mean_inference_ms: 1.984050314478867
  mean_raw_obs_processing_ms: 0.45020278134215175
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03212475776672363
    StateBufferConnector_ms: 0.005762815475463867
    ViewRequirementAgentConnector_ms: 0.19169926643371582
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.36
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 4.0, 1.0, 0.0, 0.0, 0.0, 2.0, 0.0, 3.0, 3.0, 1.0, 3.0, 3.0,
      3.0, 5.0, 2.0, 1.0, 1.0, 3.0, 1.0, 6.0, 2.0, 2.0, 5.0, 2.0, 1.0, 3.0, 2.0, 4.0,
      2.0, 4.0, 0.0, 2.0, 2.0, 1.0, 2.0, 5.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0, 1.0,
      5.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 5.0, 6.0, 4.0, 2.0, 2.0, 4.0, 0.0, 2.0, 1.0,
      2.0, 4.0, 2.0, 5.0, 4.0, 1.0, 4.0, 5.0, 2.0, 3.0, 3.0, 3.0, 2.0, 0.0, 3.0, 1.0,
      3.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 4.0,
      3.0, 0.0, 3.0, 3.0, 3.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10658116607076007
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03892177601958023
    mean_inference_ms: 1.984050314478867
    mean_raw_obs_processing_ms: 0.45020278134215175
time_since_restore: 143.27148270606995
time_this_iter_s: 10.307636976242065
time_total_s: 143.27148270606995
timers:
  sample_time_ms: 0.036
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.112
timestamp: 1692341730
timesteps_total: 106700
training_iteration: 14
trial_id: default
train step: 15
agent_timesteps_total: 113350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03691267967224121
  StateBufferConnector_ms: 0.006531715393066406
  ViewRequirementAgentConnector_ms: 0.21863579750061035
counters:
  num_agent_steps_sampled: 113350
  num_agent_steps_trained: 96500
  num_env_steps_sampled: 113350
  num_env_steps_trained: 96500
  num_samples_added_to_queue: 113000
  num_training_step_calls_since_last_synch_worker_weights: 236
  num_weight_broadcasts: 2222
custom_metrics: {}
date: 2023-08-18_15-55-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.29
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 886
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4642376899719238
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 33.45664596557617
        total_loss: 42.40779113769531
        var_gnorm: 63.32789611816406
        vf_explained_var: 0.14263248443603516
        vf_loss: 19.366531372070312
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 193.0
  learner_queue:
    size_count: 199
    size_mean: 14.64
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6094719630984569
  num_agent_steps_sampled: 113350
  num_agent_steps_trained: 96500
  num_env_steps_sampled: 113350
  num_env_steps_trained: 96500
  num_samples_added_to_queue: 113000
  num_training_step_calls_since_last_synch_worker_weights: 236
  num_weight_broadcasts: 2222
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 407.113
    learner_load_time_ms: 3.98
    learner_load_wait_time_ms: 2.775
iterations_since_restore: 15
node_ip: 127.0.0.1
num_agent_steps_sampled: 113350
num_agent_steps_trained: 96500
num_env_steps_sampled: 113350
num_env_steps_sampled_this_iter: 6650
num_env_steps_sampled_throughput_per_sec: 664.9972095606594
num_env_steps_trained: 96500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9972725029002
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 60.22666666666667
  ram_util_percent: 81.48666666666665
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10678914250056676
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03919232955599253
  mean_inference_ms: 1.993187961285707
  mean_raw_obs_processing_ms: 0.45216222973485887
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03691267967224121
    StateBufferConnector_ms: 0.006531715393066406
    ViewRequirementAgentConnector_ms: 0.21863579750061035
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.29
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 6.0, 4.0, 2.0, 2.0, 4.0, 0.0, 2.0, 1.0, 2.0, 4.0, 2.0, 5.0,
      4.0, 1.0, 4.0, 5.0, 2.0, 3.0, 3.0, 3.0, 2.0, 0.0, 3.0, 1.0, 3.0, 2.0, 2.0, 3.0,
      1.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 0.0, 3.0, 3.0,
      3.0, 3.0, 3.0, 1.0, 3.0, 4.0, 0.0, 2.0, 0.0, 4.0, 2.0, 0.0, 1.0, 3.0, 3.0, 4.0,
      1.0, 1.0, 1.0, 4.0, 4.0, 1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0,
      3.0, 2.0, 2.0, 2.0, 5.0, 1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0,
      1.0, 3.0, 2.0, 2.0, 0.0, 1.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10678914250056676
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03919232955599253
    mean_inference_ms: 1.993187961285707
    mean_raw_obs_processing_ms: 0.45216222973485887
time_since_restore: 153.49723362922668
time_this_iter_s: 10.225750923156738
time_total_s: 153.49723362922668
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.075
timestamp: 1692341740
timesteps_total: 113350
training_iteration: 15
trial_id: default
train step: 16
agent_timesteps_total: 120150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0400393009185791
  StateBufferConnector_ms: 0.0068814754486083984
  ViewRequirementAgentConnector_ms: 0.2307577133178711
counters:
  num_agent_steps_sampled: 120150
  num_agent_steps_trained: 103500
  num_env_steps_sampled: 120150
  num_env_steps_trained: 103500
  num_samples_added_to_queue: 120000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 2355
custom_metrics: {}
date: 2023-08-18_15-55-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 1.78
episode_reward_min: 0.0
episodes_this_iter: 53
episodes_total: 939
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4575141668319702
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 3.2265141010284424
        total_loss: 10.278746604919434
        var_gnorm: 63.32802200317383
        vf_explained_var: 0.2690005898475647
        vf_loss: 15.561978340148926
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 207.0
  learner_queue:
    size_count: 214
    size_mean: 14.48
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7803370467414306
  num_agent_steps_sampled: 120150
  num_agent_steps_trained: 103500
  num_env_steps_sampled: 120150
  num_env_steps_trained: 103500
  num_samples_added_to_queue: 120000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 2355
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 332.631
    learner_load_time_ms: 3.922
    learner_load_wait_time_ms: 3.633
iterations_since_restore: 16
node_ip: 127.0.0.1
num_agent_steps_sampled: 120150
num_agent_steps_trained: 103500
num_env_steps_sampled: 120150
num_env_steps_sampled_this_iter: 6800
num_env_steps_sampled_throughput_per_sec: 679.8450603739711
num_env_steps_trained: 103500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.8405033261467
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 53.73571428571429
  ram_util_percent: 82.67142857142856
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1076095046254347
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03964791702243435
  mean_inference_ms: 2.010241895609242
  mean_raw_obs_processing_ms: 0.4556769161905699
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0400393009185791
    StateBufferConnector_ms: 0.0068814754486083984
    ViewRequirementAgentConnector_ms: 0.2307577133178711
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 1.78
  episode_reward_min: 0.0
  episodes_this_iter: 53
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 4.0, 2.0, 0.0, 1.0, 3.0, 3.0, 4.0, 1.0, 1.0, 1.0, 4.0, 4.0,
      1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 0.0, 3.0, 2.0, 2.0, 2.0, 5.0,
      1.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 1.0, 0.0, 3.0, 0.0, 1.0, 3.0, 2.0, 2.0, 0.0,
      1.0, 6.0, 2.0, 1.0, 0.0, 3.0, 1.0, 3.0, 5.0, 1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0,
      3.0, 1.0, 4.0, 1.0, 3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0,
      0.0, 3.0, 2.0, 1.0, 2.0, 0.0, 0.0, 2.0, 0.0, 4.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0,
      3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1076095046254347
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03964791702243435
    mean_inference_ms: 2.010241895609242
    mean_raw_obs_processing_ms: 0.4556769161905699
time_since_restore: 163.9233558177948
time_this_iter_s: 10.426122188568115
time_total_s: 163.9233558177948
timers:
  sample_time_ms: 0.084
  synch_weights_time_ms: 0.53
  training_iteration_time_ms: 0.763
timestamp: 1692341751
timesteps_total: 120150
training_iteration: 16
trial_id: default
train step: 17
agent_timesteps_total: 126700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.040755271911621094
  StateBufferConnector_ms: 0.007128477096557617
  ViewRequirementAgentConnector_ms: 0.23021531105041504
counters:
  num_agent_steps_sampled: 126700
  num_agent_steps_trained: 110000
  num_env_steps_sampled: 126700
  num_env_steps_trained: 110000
  num_samples_added_to_queue: 126500
  num_training_step_calls_since_last_synch_worker_weights: 398
  num_weight_broadcasts: 2484
custom_metrics: {}
date: 2023-08-18_15-56-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.74
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 991
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.099999999999994
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4857902526855469
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -5.800180912017822
        total_loss: 3.7320094108581543
        var_gnorm: 63.32815933227539
        vf_explained_var: 0.24617493152618408
        vf_loss: 20.5501708984375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 220.0
  learner_queue:
    size_count: 225
    size_mean: 14.3
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8894443627691184
  num_agent_steps_sampled: 126700
  num_agent_steps_trained: 110000
  num_env_steps_sampled: 126700
  num_env_steps_trained: 110000
  num_samples_added_to_queue: 126500
  num_training_step_calls_since_last_synch_worker_weights: 398
  num_weight_broadcasts: 2484
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 943.05
    learner_load_time_ms: 3.897
    learner_load_wait_time_ms: 37.753
iterations_since_restore: 17
node_ip: 127.0.0.1
num_agent_steps_sampled: 126700
num_agent_steps_trained: 110000
num_env_steps_sampled: 126700
num_env_steps_sampled_this_iter: 6550
num_env_steps_sampled_throughput_per_sec: 654.9935192510965
num_env_steps_trained: 110000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9935687224622
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 61.07333333333333
  ram_util_percent: 82.61999999999998
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10847347871353845
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0400428087129439
  mean_inference_ms: 2.025713019593395
  mean_raw_obs_processing_ms: 0.458844854796465
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.040755271911621094
    StateBufferConnector_ms: 0.007128477096557617
    ViewRequirementAgentConnector_ms: 0.23021531105041504
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.74
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 1.0, 3.0, 1.0, 1.0, 2.0, 0.0, 1.0, 3.0, 1.0, 4.0, 1.0,
      3.0, 3.0, 0.0, 3.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 0.0, 1.0, 0.0, 3.0, 2.0, 1.0,
      2.0, 0.0, 0.0, 2.0, 0.0, 4.0, 2.0, 2.0, 0.0, 0.0, 2.0, 0.0, 3.0, 2.0, 2.0, 3.0,
      2.0, 3.0, 2.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 3.0, 0.0,
      3.0, 0.0, 2.0, 3.0, 0.0, 4.0, 1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0,
      2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0, 0.0, 2.0, 0.0, 5.0, 4.0, 2.0, 5.0, 0.0,
      3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10847347871353845
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0400428087129439
    mean_inference_ms: 2.025713019593395
    mean_raw_obs_processing_ms: 0.458844854796465
time_since_restore: 174.21002388000488
time_this_iter_s: 10.286668062210083
time_total_s: 174.21002388000488
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692341761
timesteps_total: 126700
training_iteration: 17
trial_id: default
train step: 18
agent_timesteps_total: 133950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.036932945251464844
  StateBufferConnector_ms: 0.006764650344848633
  ViewRequirementAgentConnector_ms: 0.21644258499145508
counters:
  num_agent_steps_sampled: 133950
  num_agent_steps_trained: 117000
  num_env_steps_sampled: 133950
  num_env_steps_trained: 117000
  num_samples_added_to_queue: 133500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 2624
custom_metrics: {}
date: 2023-08-18_15-56-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 5.0
episode_reward_mean: 1.87
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 1047
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.479378342628479
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -40.443382263183594
        total_loss: -32.642147064208984
        var_gnorm: 63.32826232910156
        vf_explained_var: 0.15987277030944824
        vf_loss: 17.081851959228516
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 234.0
  learner_queue:
    size_count: 237
    size_mean: 14.44
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.8347751905887544
  num_agent_steps_sampled: 133950
  num_agent_steps_trained: 117000
  num_env_steps_sampled: 133950
  num_env_steps_trained: 117000
  num_samples_added_to_queue: 133500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 2624
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 753.035
    learner_load_time_ms: 3.897
    learner_load_wait_time_ms: 21.417
iterations_since_restore: 18
node_ip: 127.0.0.1
num_agent_steps_sampled: 133950
num_agent_steps_trained: 117000
num_env_steps_sampled: 133950
num_env_steps_sampled_this_iter: 7250
num_env_steps_sampled_throughput_per_sec: 724.8667026310588
num_env_steps_trained: 117000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.8712990920568
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 45.75714285714285
  ram_util_percent: 83.48571428571428
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10900698105242988
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04025980428910142
  mean_inference_ms: 2.0348899411967962
  mean_raw_obs_processing_ms: 0.46062139131855273
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.036932945251464844
    StateBufferConnector_ms: 0.006764650344848633
    ViewRequirementAgentConnector_ms: 0.21644258499145508
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 5.0
  episode_reward_mean: 1.87
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 0.0, 1.0, 3.0, 0.0, 3.0, 0.0, 2.0, 3.0, 0.0, 4.0, 1.0, 2.0,
      3.0, 2.0, 1.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 2.0,
      0.0, 2.0, 0.0, 5.0, 4.0, 2.0, 5.0, 0.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 1.0, 0.0,
      2.0, 3.0, 1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 0.0,
      1.0, 0.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 5.0,
      3.0, 1.0, 4.0, 1.0, 0.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0,
      0.0, 4.0, 3.0, 0.0, 3.0, 2.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10900698105242988
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04025980428910142
    mean_inference_ms: 2.0348899411967962
    mean_raw_obs_processing_ms: 0.46062139131855273
time_since_restore: 184.34236979484558
time_this_iter_s: 10.132345914840698
time_total_s: 184.34236979484558
timers:
  sample_time_ms: 0.073
  synch_weights_time_ms: 0.461
  training_iteration_time_ms: 0.653
timestamp: 1692341771
timesteps_total: 133950
training_iteration: 18
trial_id: default
train step: 19
agent_timesteps_total: 142100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03290987014770508
  StateBufferConnector_ms: 0.006057262420654297
  ViewRequirementAgentConnector_ms: 0.1977705955505371
counters:
  num_agent_steps_sampled: 142100
  num_agent_steps_trained: 125500
  num_env_steps_sampled: 142100
  num_env_steps_trained: 125500
  num_samples_added_to_queue: 142000
  num_training_step_calls_since_last_synch_worker_weights: 1253
  num_weight_broadcasts: 2783
custom_metrics: {}
date: 2023-08-18_15-56-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.11
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 1111
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4510005712509155
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 44.40849304199219
        total_loss: 51.25685501098633
        var_gnorm: 63.328392028808594
        vf_explained_var: 0.22070837020874023
        vf_loss: 15.14772891998291
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 251.0
  learner_queue:
    size_count: 254
    size_mean: 14.78
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7238329385413196
  num_agent_steps_sampled: 142100
  num_agent_steps_trained: 125500
  num_env_steps_sampled: 142100
  num_env_steps_trained: 125500
  num_samples_added_to_queue: 142000
  num_training_step_calls_since_last_synch_worker_weights: 1253
  num_weight_broadcasts: 2783
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 459.109
    learner_load_time_ms: 3.767
    learner_load_wait_time_ms: 2.878
iterations_since_restore: 19
node_ip: 127.0.0.1
num_agent_steps_sampled: 142100
num_agent_steps_trained: 125500
num_env_steps_sampled: 142100
num_env_steps_sampled_this_iter: 8150
num_env_steps_sampled_throughput_per_sec: 814.997493393978
num_env_steps_trained: 125500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9973857483205
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 47.699999999999996
  ram_util_percent: 82.28666666666666
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10886863516234342
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04005921645857075
  mean_inference_ms: 2.028391018133203
  mean_raw_obs_processing_ms: 0.4588443210678665
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03290987014770508
    StateBufferConnector_ms: 0.006057262420654297
    ViewRequirementAgentConnector_ms: 0.1977705955505371
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.11
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 1.0, 2.0, 2.0, 0.0, 5.0,
      3.0, 1.0, 4.0, 1.0, 0.0, 3.0, 4.0, 3.0, 2.0, 3.0, 3.0, 2.0, 1.0, 0.0, 2.0, 1.0,
      0.0, 4.0, 3.0, 0.0, 3.0, 2.0, 4.0, 3.0, 3.0, 0.0, 5.0, 2.0, 0.0, 1.0, 1.0, 2.0,
      2.0, 4.0, 2.0, 6.0, 1.0, 3.0, 6.0, 3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 3.0, 4.0, 0.0,
      3.0, 2.0, 4.0, 2.0, 2.0, 5.0, 4.0, 3.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 4.0,
      2.0, 1.0, 2.0, 1.0, 5.0, 3.0, 2.0, 0.0, 5.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0,
      0.0, 1.0, 1.0, 5.0, 1.0, 2.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10886863516234342
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04005921645857075
    mean_inference_ms: 2.028391018133203
    mean_raw_obs_processing_ms: 0.4588443210678665
time_since_restore: 194.48764872550964
time_this_iter_s: 10.145278930664062
time_total_s: 194.48764872550964
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692341782
timesteps_total: 142100
training_iteration: 19
trial_id: default
train step: 20
agent_timesteps_total: 148900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03629112243652344
  StateBufferConnector_ms: 0.006406307220458984
  ViewRequirementAgentConnector_ms: 0.21150827407836914
counters:
  num_agent_steps_sampled: 148900
  num_agent_steps_trained: 132000
  num_env_steps_sampled: 148900
  num_env_steps_trained: 132000
  num_samples_added_to_queue: 148500
  num_training_step_calls_since_last_synch_worker_weights: 1094
  num_weight_broadcasts: 2916
custom_metrics: {}
date: 2023-08-18_15-56-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.05
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 1163
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4638619422912598
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -49.24958419799805
        total_loss: -43.80380630493164
        var_gnorm: 63.328514099121094
        vf_explained_var: 0.0008977055549621582
        vf_loss: 12.35541820526123
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 264.0
  learner_queue:
    size_count: 269
    size_mean: 15.18
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.26
  num_agent_steps_sampled: 148900
  num_agent_steps_trained: 132000
  num_env_steps_sampled: 148900
  num_env_steps_trained: 132000
  num_samples_added_to_queue: 148500
  num_training_step_calls_since_last_synch_worker_weights: 1094
  num_weight_broadcasts: 2916
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 535.924
    learner_load_time_ms: 4.111
    learner_load_wait_time_ms: 3.542
iterations_since_restore: 20
node_ip: 127.0.0.1
num_agent_steps_sampled: 148900
num_agent_steps_trained: 132000
num_env_steps_sampled: 148900
num_env_steps_sampled_this_iter: 6800
num_env_steps_sampled_throughput_per_sec: 679.9978275368478
num_env_steps_trained: 132000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9979233808104
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 52.25000000000001
  ram_util_percent: 83.22857142857143
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10881910877648852
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04014878694034863
  mean_inference_ms: 2.0297719237874783
  mean_raw_obs_processing_ms: 0.45927450270504266
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03629112243652344
    StateBufferConnector_ms: 0.006406307220458984
    ViewRequirementAgentConnector_ms: 0.21150827407836914
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.05
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 6.0, 1.0, 1.0, 1.0, 2.0, 3.0, 4.0, 0.0, 3.0, 2.0, 4.0, 2.0,
      2.0, 5.0, 4.0, 3.0, 0.0, 2.0, 0.0, 0.0, 2.0, 3.0, 3.0, 4.0, 2.0, 1.0, 2.0, 1.0,
      5.0, 3.0, 2.0, 0.0, 5.0, 1.0, 0.0, 3.0, 2.0, 1.0, 0.0, 1.0, 0.0, 1.0, 1.0, 5.0,
      1.0, 2.0, 0.0, 4.0, 1.0, 6.0, 3.0, 0.0, 1.0, 4.0, 1.0, 2.0, 1.0, 2.0, 3.0, 3.0,
      1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0, 3.0, 4.0, 5.0,
      0.0, 1.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 1.0,
      2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10881910877648852
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04014878694034863
    mean_inference_ms: 2.0297719237874783
    mean_raw_obs_processing_ms: 0.45927450270504266
time_since_restore: 204.77807354927063
time_this_iter_s: 10.290424823760986
time_total_s: 204.77807354927063
timers:
  sample_time_ms: 0.039
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.115
timestamp: 1692341792
timesteps_total: 148900
training_iteration: 20
trial_id: default
train step: 21
agent_timesteps_total: 156600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0378725528717041
  StateBufferConnector_ms: 0.006666421890258789
  ViewRequirementAgentConnector_ms: 0.21948504447937012
counters:
  num_agent_steps_sampled: 156600
  num_agent_steps_trained: 140000
  num_env_steps_sampled: 156600
  num_env_steps_trained: 140000
  num_samples_added_to_queue: 156500
  num_training_step_calls_since_last_synch_worker_weights: 208
  num_weight_broadcasts: 3063
custom_metrics: {}
date: 2023-08-18_15-56-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 1.83
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 1224
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4500176906585693
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -40.091400146484375
        total_loss: -35.22712326049805
        var_gnorm: 63.328636169433594
        vf_explained_var: 0.21835708618164062
        vf_loss: 11.178576469421387
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 280.0
  learner_queue:
    size_count: 286
    size_mean: 15.14
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.371276777313756
  num_agent_steps_sampled: 156600
  num_agent_steps_trained: 140000
  num_env_steps_sampled: 156600
  num_env_steps_trained: 140000
  num_samples_added_to_queue: 156500
  num_training_step_calls_since_last_synch_worker_weights: 208
  num_weight_broadcasts: 3063
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 288.865
    learner_load_time_ms: 4.21
    learner_load_wait_time_ms: 2.906
iterations_since_restore: 21
node_ip: 127.0.0.1
num_agent_steps_sampled: 156600
num_agent_steps_trained: 140000
num_env_steps_sampled: 156600
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 769.9952268896343
num_env_steps_trained: 140000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9950409242954
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.80714285714286
  ram_util_percent: 84.12857142857142
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10891184472447497
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04025867869296482
  mean_inference_ms: 2.033014868962319
  mean_raw_obs_processing_ms: 0.4600127988394038
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0378725528717041
    StateBufferConnector_ms: 0.006666421890258789
    ViewRequirementAgentConnector_ms: 0.21948504447937012
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 1.83
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 3.0, 3.0, 1.0, 3.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 3.0,
      3.0, 4.0, 5.0, 0.0, 1.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0,
      2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 0.0, 2.0, 0.0,
      4.0, 1.0, 0.0, 1.0, 2.0, 0.0, 1.0, 2.0, 3.0, 0.0, 2.0, 4.0, 2.0, 0.0, 2.0, 4.0,
      4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 1.0, 3.0, 7.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0,
      0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0,
      2.0, 2.0, 0.0, 2.0, 0.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10891184472447497
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04025867869296482
    mean_inference_ms: 2.033014868962319
    mean_raw_obs_processing_ms: 0.4600127988394038
time_since_restore: 215.02062153816223
time_this_iter_s: 10.242547988891602
time_total_s: 215.02062153816223
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692341802
timesteps_total: 156600
training_iteration: 21
trial_id: default
train step: 22
agent_timesteps_total: 164800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03176736831665039
  StateBufferConnector_ms: 0.005777835845947266
  ViewRequirementAgentConnector_ms: 0.19066667556762695
counters:
  num_agent_steps_sampled: 164800
  num_agent_steps_trained: 148000
  num_env_steps_sampled: 164800
  num_env_steps_trained: 148000
  num_samples_added_to_queue: 164500
  num_training_step_calls_since_last_synch_worker_weights: 905
  num_weight_broadcasts: 3222
custom_metrics: {}
date: 2023-08-18_15-56-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 1.99
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 1288
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4510761499404907
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -47.98012161254883
        total_loss: -44.52787399291992
        var_gnorm: 63.328758239746094
        vf_explained_var: 0.19610995054244995
        vf_loss: 8.35556411743164
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 296.0
  learner_queue:
    size_count: 300
    size_mean: 14.94
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4616429112474771
  num_agent_steps_sampled: 164800
  num_agent_steps_trained: 148000
  num_env_steps_sampled: 164800
  num_env_steps_trained: 148000
  num_samples_added_to_queue: 164500
  num_training_step_calls_since_last_synch_worker_weights: 905
  num_weight_broadcasts: 3222
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 419.006
    learner_load_time_ms: 4.351
    learner_load_wait_time_ms: 2.637
iterations_since_restore: 22
node_ip: 127.0.0.1
num_agent_steps_sampled: 164800
num_agent_steps_trained: 148000
num_env_steps_sampled: 164800
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9981036230075
num_env_steps_trained: 148000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9981498761049
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.28666666666667
  ram_util_percent: 83.27999999999999
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1087223107768099
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04002213937816567
  mean_inference_ms: 2.0254680634598192
  mean_raw_obs_processing_ms: 0.45794393626340196
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03176736831665039
    StateBufferConnector_ms: 0.005777835845947266
    ViewRequirementAgentConnector_ms: 0.19066667556762695
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 1.99
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 2.0, 1.0, 3.0, 7.0, 0.0, 1.0, 1.0, 3.0, 0.0, 2.0, 2.0,
      0.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0,
      2.0, 2.0, 0.0, 2.0, 0.0, 3.0, 1.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 1.0, 4.0, 3.0,
      0.0, 5.0, 3.0, 2.0, 2.0, 5.0, 2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0,
      3.0, 1.0, 4.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0,
      3.0, 0.0, 2.0, 2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 4.0, 2.0, 1.0,
      1.0, 6.0, 2.0, 1.0, 1.0, 1.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1087223107768099
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04002213937816567
    mean_inference_ms: 2.0254680634598192
    mean_raw_obs_processing_ms: 0.45794393626340196
time_since_restore: 225.19062542915344
time_this_iter_s: 10.170003890991211
time_total_s: 225.19062542915344
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692341812
timesteps_total: 164800
training_iteration: 22
trial_id: default
train step: 23
agent_timesteps_total: 171400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035408735275268555
  StateBufferConnector_ms: 0.0068318843841552734
  ViewRequirementAgentConnector_ms: 0.20914459228515625
counters:
  num_agent_steps_sampled: 171400
  num_agent_steps_trained: 154500
  num_env_steps_sampled: 171400
  num_env_steps_trained: 154500
  num_samples_added_to_queue: 171000
  num_training_step_calls_since_last_synch_worker_weights: 503
  num_weight_broadcasts: 3351
custom_metrics: {}
date: 2023-08-18_15-57-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.14
episode_reward_min: 0.0
episodes_this_iter: 51
episodes_total: 1339
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4064868688583374
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 0.24257159233093262
        total_loss: 8.667691230773926
        var_gnorm: 63.328819274902344
        vf_explained_var: 0.1883651614189148
        vf_loss: 18.256725311279297
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 309.0
  learner_queue:
    size_count: 315
    size_mean: 14.72
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6004999218994045
  num_agent_steps_sampled: 171400
  num_agent_steps_trained: 154500
  num_env_steps_sampled: 171400
  num_env_steps_trained: 154500
  num_samples_added_to_queue: 171000
  num_training_step_calls_since_last_synch_worker_weights: 503
  num_weight_broadcasts: 3351
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 433.625
    learner_load_time_ms: 3.413
    learner_load_wait_time_ms: 3.184
iterations_since_restore: 23
node_ip: 127.0.0.1
num_agent_steps_sampled: 171400
num_agent_steps_trained: 154500
num_env_steps_sampled: 171400
num_env_steps_sampled_this_iter: 6600
num_env_steps_sampled_throughput_per_sec: 659.9980959947201
num_env_steps_trained: 154500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9981248432849
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 54.528571428571425
  ram_util_percent: 83.85000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10864576282607465
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04014487167856624
  mean_inference_ms: 2.0286782405471944
  mean_raw_obs_processing_ms: 0.4588328456976555
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035408735275268555
    StateBufferConnector_ms: 0.0068318843841552734
    ViewRequirementAgentConnector_ms: 0.20914459228515625
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.14
  episode_reward_min: 0.0
  episodes_this_iter: 51
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 3.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 3.0, 1.0, 4.0,
      0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 4.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 0.0, 2.0,
      2.0, 2.0, 1.0, 0.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 4.0, 2.0, 1.0, 1.0, 6.0, 2.0,
      1.0, 1.0, 1.0, 5.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 1.0, 3.0, 3.0, 2.0, 3.0, 1.0,
      4.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 1.0, 5.0, 2.0, 1.0, 5.0, 3.0, 0.0, 1.0, 0.0,
      3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0, 7.0, 3.0, 0.0, 0.0, 2.0, 4.0, 4.0,
      2.0, 2.0, 3.0, 4.0, 1.0, 2.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10864576282607465
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04014487167856624
    mean_inference_ms: 2.0286782405471944
    mean_raw_obs_processing_ms: 0.4588328456976555
time_since_restore: 235.53434944152832
time_this_iter_s: 10.343724012374878
time_total_s: 235.53434944152832
timers:
  sample_time_ms: 0.034
  synch_weights_time_ms: 0.01
  training_iteration_time_ms: 0.104
timestamp: 1692341823
timesteps_total: 171400
training_iteration: 23
trial_id: default
train step: 24
agent_timesteps_total: 178700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.038665056228637695
  StateBufferConnector_ms: 0.007245063781738281
  ViewRequirementAgentConnector_ms: 0.22638320922851562
counters:
  num_agent_steps_sampled: 178700
  num_agent_steps_trained: 162000
  num_env_steps_sampled: 178700
  num_env_steps_trained: 162000
  num_samples_added_to_queue: 178500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 3492
custom_metrics: {}
date: 2023-08-18_15-57-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.04
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 1396
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4197914600372314
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 12.043573379516602
        total_loss: 19.841279983520508
        var_gnorm: 63.328880310058594
        vf_explained_var: 0.18769735097885132
        vf_loss: 17.01520538330078
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 324.0
  learner_queue:
    size_count: 331
    size_mean: 14.46
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7799999999999998
  num_agent_steps_sampled: 178700
  num_agent_steps_trained: 162000
  num_env_steps_sampled: 178700
  num_env_steps_trained: 162000
  num_samples_added_to_queue: 178500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 3492
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 227.315
    learner_load_time_ms: 3.453
    learner_load_wait_time_ms: 2.676
iterations_since_restore: 24
node_ip: 127.0.0.1
num_agent_steps_sampled: 178700
num_agent_steps_trained: 162000
num_env_steps_sampled: 178700
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.7194419927222
num_env_steps_trained: 162000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.7117554719748
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.12
  ram_util_percent: 82.71333333333334
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10895621606302512
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04036226101465228
  mean_inference_ms: 2.036227420975446
  mean_raw_obs_processing_ms: 0.46036156033124215
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.038665056228637695
    StateBufferConnector_ms: 0.007245063781738281
    ViewRequirementAgentConnector_ms: 0.22638320922851562
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.04
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 3.0, 1.0, 4.0, 0.0, 2.0, 0.0, 2.0, 3.0, 3.0, 1.0, 5.0,
      2.0, 1.0, 5.0, 3.0, 0.0, 1.0, 0.0, 3.0, 1.0, 3.0, 0.0, 2.0, 1.0, 0.0, 1.0, 3.0,
      7.0, 3.0, 0.0, 0.0, 2.0, 4.0, 4.0, 2.0, 2.0, 3.0, 4.0, 1.0, 2.0, 5.0, 0.0, 1.0,
      1.0, 3.0, 2.0, 4.0, 1.0, 4.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 1.0,
      1.0, 7.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0, 0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0,
      3.0, 5.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 5.0, 4.0, 0.0, 1.0, 2.0, 4.0, 5.0, 2.0,
      1.0, 2.0, 4.0, 2.0, 3.0, 1.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10895621606302512
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04036226101465228
    mean_inference_ms: 2.036227420975446
    mean_raw_obs_processing_ms: 0.46036156033124215
time_since_restore: 245.81194853782654
time_this_iter_s: 10.277599096298218
time_total_s: 245.81194853782654
timers:
  sample_time_ms: 0.117
  synch_weights_time_ms: 0.773
  training_iteration_time_ms: 1.08
timestamp: 1692341833
timesteps_total: 178700
training_iteration: 24
trial_id: default
train step: 25
agent_timesteps_total: 185950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.036009788513183594
  StateBufferConnector_ms: 0.006529092788696289
  ViewRequirementAgentConnector_ms: 0.20990371704101562
counters:
  num_agent_steps_sampled: 185950
  num_agent_steps_trained: 169000
  num_env_steps_sampled: 185950
  num_env_steps_trained: 169000
  num_samples_added_to_queue: 185500
  num_training_step_calls_since_last_synch_worker_weights: 524
  num_weight_broadcasts: 3635
custom_metrics: {}
date: 2023-08-18_15-57-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.04
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 1453
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4188379049301147
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -55.23970413208008
        total_loss: -52.0057487487793
        var_gnorm: 63.32902145385742
        vf_explained_var: 0.20998990535736084
        vf_loss: 7.886751174926758
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 338.0
  learner_queue:
    size_count: 344
    size_mean: 14.48
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7690675509996787
  num_agent_steps_sampled: 185950
  num_agent_steps_trained: 169000
  num_env_steps_sampled: 185950
  num_env_steps_trained: 169000
  num_samples_added_to_queue: 185500
  num_training_step_calls_since_last_synch_worker_weights: 524
  num_weight_broadcasts: 3635
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 436.04
    learner_load_time_ms: 3.493
    learner_load_wait_time_ms: 2.784
iterations_since_restore: 25
node_ip: 127.0.0.1
num_agent_steps_sampled: 185950
num_agent_steps_trained: 169000
num_env_steps_sampled: 185950
num_env_steps_sampled_this_iter: 7250
num_env_steps_sampled_throughput_per_sec: 724.9978220528226
num_env_steps_trained: 169000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9978971544494
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 55.43571428571429
  ram_util_percent: 81.77857142857144
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10920117697734842
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040397233254588806
  mean_inference_ms: 2.038473769110764
  mean_raw_obs_processing_ms: 0.46049229903322414
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.036009788513183594
    StateBufferConnector_ms: 0.006529092788696289
    ViewRequirementAgentConnector_ms: 0.20990371704101562
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.04
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 2.0, 1.0, 1.0, 1.0, 7.0, 3.0, 2.0, 0.0, 2.0, 1.0, 2.0, 1.0,
      0.0, 0.0, 2.0, 1.0, 0.0, 1.0, 0.0, 3.0, 5.0, 1.0, 2.0, 1.0, 3.0, 0.0, 2.0, 5.0,
      4.0, 0.0, 1.0, 2.0, 4.0, 5.0, 2.0, 1.0, 2.0, 4.0, 2.0, 3.0, 1.0, 4.0, 0.0, 2.0,
      0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 7.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0,
      1.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 5.0, 2.0, 1.0, 3.0, 4.0, 1.0,
      3.0, 0.0, 1.0, 2.0, 1.0, 1.0, 0.0, 2.0, 1.0, 5.0, 3.0, 2.0, 3.0, 4.0, 2.0, 4.0,
      3.0, 1.0, 1.0, 2.0, 3.0, 5.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10920117697734842
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040397233254588806
    mean_inference_ms: 2.038473769110764
    mean_raw_obs_processing_ms: 0.46049229903322414
time_since_restore: 256.0953576564789
time_this_iter_s: 10.283409118652344
time_total_s: 256.0953576564789
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692341843
timesteps_total: 185950
training_iteration: 25
trial_id: default
train step: 26
agent_timesteps_total: 192550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03786635398864746
  StateBufferConnector_ms: 0.006808757781982422
  ViewRequirementAgentConnector_ms: 0.219146728515625
counters:
  num_agent_steps_sampled: 192550
  num_agent_steps_trained: 176000
  num_env_steps_sampled: 192550
  num_env_steps_trained: 176000
  num_samples_added_to_queue: 192500
  num_training_step_calls_since_last_synch_worker_weights: 696
  num_weight_broadcasts: 3764
custom_metrics: {}
date: 2023-08-18_15-57-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.17
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 1505
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4243111610412598
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -53.10657501220703
        total_loss: -49.20911407470703
        var_gnorm: 63.32917404174805
        vf_explained_var: 0.03676527738571167
        vf_loss: 9.219233512878418
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 352.0
  learner_queue:
    size_count: 356
    size_mean: 14.48
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7690675509996785
  num_agent_steps_sampled: 192550
  num_agent_steps_trained: 176000
  num_env_steps_sampled: 192550
  num_env_steps_trained: 176000
  num_samples_added_to_queue: 192500
  num_training_step_calls_since_last_synch_worker_weights: 696
  num_weight_broadcasts: 3764
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 582.652
    learner_load_time_ms: 3.476
    learner_load_wait_time_ms: 3.467
iterations_since_restore: 26
node_ip: 127.0.0.1
num_agent_steps_sampled: 192550
num_agent_steps_trained: 176000
num_env_steps_sampled: 192550
num_env_steps_sampled_this_iter: 6600
num_env_steps_sampled_throughput_per_sec: 659.9957042020023
num_env_steps_trained: 176000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9954438506086
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 59.86666666666666
  ram_util_percent: 81.27333333333333
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10937451443979863
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04055384582107227
  mean_inference_ms: 2.0440955543883295
  mean_raw_obs_processing_ms: 0.46194218275700016
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03786635398864746
    StateBufferConnector_ms: 0.006808757781982422
    ViewRequirementAgentConnector_ms: 0.219146728515625
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.17
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 2.0, 0.0, 1.0, 4.0, 2.0, 2.0,
      1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 5.0, 2.0, 1.0, 3.0, 4.0, 1.0, 3.0, 0.0, 1.0, 2.0,
      1.0, 1.0, 0.0, 2.0, 1.0, 5.0, 3.0, 2.0, 3.0, 4.0, 2.0, 4.0, 3.0, 1.0, 1.0, 2.0,
      3.0, 5.0, 0.0, 2.0, 2.0, 4.0, 6.0, 1.0, 2.0, 1.0, 1.0, 4.0, 4.0, 1.0, 4.0, 2.0,
      1.0, 2.0, 0.0, 2.0, 2.0, 2.0, 1.0, 7.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0,
      2.0, 4.0, 1.0, 0.0, 3.0, 1.0, 2.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 3.0, 0.0,
      1.0, 1.0, 4.0, 1.0, 4.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10937451443979863
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04055384582107227
    mean_inference_ms: 2.0440955543883295
    mean_raw_obs_processing_ms: 0.46194218275700016
time_since_restore: 266.2599778175354
time_this_iter_s: 10.164620161056519
time_total_s: 266.2599778175354
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692341853
timesteps_total: 192550
training_iteration: 26
trial_id: default
train step: 27
agent_timesteps_total: 199250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03790402412414551
  StateBufferConnector_ms: 0.006862163543701172
  ViewRequirementAgentConnector_ms: 0.22942185401916504
counters:
  num_agent_steps_sampled: 199250
  num_agent_steps_trained: 182500
  num_env_steps_sampled: 199250
  num_env_steps_trained: 182500
  num_samples_added_to_queue: 199000
  num_training_step_calls_since_last_synch_worker_weights: 611
  num_weight_broadcasts: 3894
custom_metrics: {}
date: 2023-08-18_15-57-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.1
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 1557
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4452130794525146
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -5.932583808898926
        total_loss: 2.1175947189331055
        var_gnorm: 63.32928466796875
        vf_explained_var: 0.21967297792434692
        vf_loss: 17.545570373535156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 365.0
  learner_queue:
    size_count: 370
    size_mean: 14.66
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6805951326836577
  num_agent_steps_sampled: 199250
  num_agent_steps_trained: 182500
  num_env_steps_sampled: 199250
  num_env_steps_trained: 182500
  num_samples_added_to_queue: 199000
  num_training_step_calls_since_last_synch_worker_weights: 611
  num_weight_broadcasts: 3894
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 396.343
    learner_load_time_ms: 3.411
    learner_load_wait_time_ms: 2.99
iterations_since_restore: 27
node_ip: 127.0.0.1
num_agent_steps_sampled: 199250
num_agent_steps_trained: 182500
num_env_steps_sampled: 199250
num_env_steps_sampled_this_iter: 6700
num_env_steps_sampled_throughput_per_sec: 669.9955272973145
num_env_steps_trained: 182500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9956608108275
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 61.72142857142857
  ram_util_percent: 81.90714285714286
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10972646430417292
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04075858123175184
  mean_inference_ms: 2.0522933151900764
  mean_raw_obs_processing_ms: 0.4637752313737262
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03790402412414551
    StateBufferConnector_ms: 0.006862163543701172
    ViewRequirementAgentConnector_ms: 0.22942185401916504
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.1
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 1.0, 1.0, 4.0, 4.0, 1.0, 4.0, 2.0, 1.0, 2.0, 0.0, 2.0,
      2.0, 2.0, 1.0, 7.0, 1.0, 1.0, 2.0, 2.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0, 1.0, 0.0,
      3.0, 1.0, 2.0, 2.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 3.0, 0.0, 1.0, 1.0, 4.0, 1.0,
      4.0, 2.0, 3.0, 1.0, 4.0, 0.0, 2.0, 5.0, 1.0, 2.0, 2.0, 3.0, 3.0, 0.0, 6.0, 0.0,
      1.0, 0.0, 1.0, 3.0, 1.0, 2.0, 7.0, 1.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0,
      0.0, 6.0, 4.0, 2.0, 2.0, 2.0, 2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 1.0,
      0.0, 1.0, 1.0, 0.0, 4.0, 1.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10972646430417292
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04075858123175184
    mean_inference_ms: 2.0522933151900764
    mean_raw_obs_processing_ms: 0.4637752313737262
time_since_restore: 276.4926679134369
time_this_iter_s: 10.23269009590149
time_total_s: 276.4926679134369
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.079
timestamp: 1692341864
timesteps_total: 199250
training_iteration: 27
trial_id: default
train step: 28
agent_timesteps_total: 206150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03756999969482422
  StateBufferConnector_ms: 0.007098197937011719
  ViewRequirementAgentConnector_ms: 0.2258741855621338
counters:
  num_agent_steps_sampled: 206150
  num_agent_steps_trained: 189500
  num_env_steps_sampled: 206150
  num_env_steps_trained: 189500
  num_samples_added_to_queue: 206000
  num_training_step_calls_since_last_synch_worker_weights: 198
  num_weight_broadcasts: 4028
custom_metrics: {}
date: 2023-08-18_15-57-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.08
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 1611
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4431525468826294
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 15.904960632324219
        total_loss: 26.55655288696289
        var_gnorm: 63.329349517822266
        vf_explained_var: 0.23149633407592773
        vf_loss: 22.746337890625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 379.0
  learner_queue:
    size_count: 385
    size_mean: 14.8
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5620499351813308
  num_agent_steps_sampled: 206150
  num_agent_steps_trained: 189500
  num_env_steps_sampled: 206150
  num_env_steps_trained: 189500
  num_samples_added_to_queue: 206000
  num_training_step_calls_since_last_synch_worker_weights: 198
  num_weight_broadcasts: 4028
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 348.694
    learner_load_time_ms: 3.37
    learner_load_wait_time_ms: 2.875
iterations_since_restore: 28
node_ip: 127.0.0.1
num_agent_steps_sampled: 206150
num_agent_steps_trained: 189500
num_env_steps_sampled: 206150
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 689.9955747411345
num_env_steps_trained: 189500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9955106069481
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 56.620000000000005
  ram_util_percent: 82.67333333333335
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11007017987364172
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04090501292387723
  mean_inference_ms: 2.0587178795911356
  mean_raw_obs_processing_ms: 0.4649265682726052
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03756999969482422
    StateBufferConnector_ms: 0.007098197937011719
    ViewRequirementAgentConnector_ms: 0.2258741855621338
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.08
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 3.0, 3.0, 0.0, 6.0, 0.0, 1.0, 0.0, 1.0, 3.0, 1.0, 2.0,
      7.0, 1.0, 4.0, 1.0, 2.0, 1.0, 3.0, 1.0, 2.0, 4.0, 0.0, 6.0, 4.0, 2.0, 2.0, 2.0,
      2.0, 0.0, 2.0, 2.0, 0.0, 2.0, 3.0, 3.0, 2.0, 1.0, 0.0, 1.0, 1.0, 0.0, 4.0, 1.0,
      5.0, 3.0, 4.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 4.0, 2.0, 3.0, 1.0, 6.0,
      0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0,
      3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 1.0, 1.0, 3.0, 4.0, 2.0, 3.0, 5.0,
      1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11007017987364172
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04090501292387723
    mean_inference_ms: 2.0587178795911356
    mean_raw_obs_processing_ms: 0.4649265682726052
time_since_restore: 286.72681188583374
time_this_iter_s: 10.23414397239685
time_total_s: 286.72681188583374
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692341874
timesteps_total: 206150
training_iteration: 28
trial_id: default
train step: 29
agent_timesteps_total: 213750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03453540802001953
  StateBufferConnector_ms: 0.006482839584350586
  ViewRequirementAgentConnector_ms: 0.20574283599853516
counters:
  num_agent_steps_sampled: 213750
  num_agent_steps_trained: 197000
  num_env_steps_sampled: 213750
  num_env_steps_trained: 197000
  num_samples_added_to_queue: 213500
  num_training_step_calls_since_last_synch_worker_weights: 118
  num_weight_broadcasts: 4177
custom_metrics: {}
date: 2023-08-18_15-58-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 1.98
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 1671
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4316800832748413
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 8.39741325378418
        total_loss: 16.006147384643555
        var_gnorm: 63.329410552978516
        vf_explained_var: 0.22570759057998657
        vf_loss: 16.649147033691406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 394.0
  learner_queue:
    size_count: 400
    size_mean: 14.76
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.59449051423958
  num_agent_steps_sampled: 213750
  num_agent_steps_trained: 197000
  num_env_steps_sampled: 213750
  num_env_steps_trained: 197000
  num_samples_added_to_queue: 213500
  num_training_step_calls_since_last_synch_worker_weights: 118
  num_weight_broadcasts: 4177
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 303.205
    learner_load_time_ms: 3.374
    learner_load_wait_time_ms: 2.533
iterations_since_restore: 29
node_ip: 127.0.0.1
num_agent_steps_sampled: 213750
num_agent_steps_trained: 197000
num_env_steps_sampled: 213750
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9942198239297
num_env_steps_trained: 197000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.994295878878
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 50.67142857142857
  ram_util_percent: 82.74285714285713
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11021634442750834
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04089124118875267
  mean_inference_ms: 2.0597292291732674
  mean_raw_obs_processing_ms: 0.4646867202428727
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03453540802001953
    StateBufferConnector_ms: 0.006482839584350586
    ViewRequirementAgentConnector_ms: 0.20574283599853516
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 1.98
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 0.0, 0.0, 0.0, 3.0, 0.0, 7.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0,
      2.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0, 4.0, 1.0, 1.0, 3.0,
      4.0, 2.0, 3.0, 5.0, 1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 5.0, 1.0, 4.0, 0.0,
      1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 1.0, 3.0, 2.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 6.0,
      1.0, 0.0, 2.0, 3.0, 3.0, 2.0, 4.0, 2.0, 4.0, 3.0, 1.0, 3.0, 0.0, 0.0, 2.0, 1.0,
      3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 3.0, 4.0, 3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0,
      1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11021634442750834
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04089124118875267
    mean_inference_ms: 2.0597292291732674
    mean_raw_obs_processing_ms: 0.4646867202428727
time_since_restore: 296.9705400466919
time_this_iter_s: 10.243728160858154
time_total_s: 296.9705400466919
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1692341884
timesteps_total: 213750
training_iteration: 29
trial_id: default
train step: 30
agent_timesteps_total: 220900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035317420959472656
  StateBufferConnector_ms: 0.006397724151611328
  ViewRequirementAgentConnector_ms: 0.20963811874389648
counters:
  num_agent_steps_sampled: 220900
  num_agent_steps_trained: 204000
  num_env_steps_sampled: 220900
  num_env_steps_trained: 204000
  num_samples_added_to_queue: 220500
  num_training_step_calls_since_last_synch_worker_weights: 399
  num_weight_broadcasts: 4316
custom_metrics: {}
date: 2023-08-18_15-58-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.03
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 1727
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3911799192428589
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -18.458454132080078
        total_loss: -12.228402137756348
        var_gnorm: 63.32944107055664
        vf_explained_var: 0.21808350086212158
        vf_loss: 13.851283073425293
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 408.0
  learner_queue:
    size_count: 414
    size_mean: 14.44
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.779438113562818
  num_agent_steps_sampled: 220900
  num_agent_steps_trained: 204000
  num_env_steps_sampled: 220900
  num_env_steps_trained: 204000
  num_samples_added_to_queue: 220500
  num_training_step_calls_since_last_synch_worker_weights: 399
  num_weight_broadcasts: 4316
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 434.658
    learner_load_time_ms: 3.374
    learner_load_wait_time_ms: 2.749
iterations_since_restore: 30
node_ip: 127.0.0.1
num_agent_steps_sampled: 220900
num_agent_steps_trained: 204000
num_env_steps_sampled: 220900
num_env_steps_sampled_this_iter: 7150
num_env_steps_sampled_throughput_per_sec: 714.99463025788
num_env_steps_trained: 204000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9947429098125
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 49.60000000000001
  ram_util_percent: 82.57142857142857
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11025672751507716
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040902549270113366
  mean_inference_ms: 2.0604649386812266
  mean_raw_obs_processing_ms: 0.4646020635543923
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035317420959472656
    StateBufferConnector_ms: 0.006397724151611328
    ViewRequirementAgentConnector_ms: 0.20963811874389648
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.03
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 1.0, 1.0, 6.0, 1.0, 0.0, 2.0, 3.0, 3.0, 2.0, 4.0, 2.0,
      4.0, 3.0, 1.0, 3.0, 0.0, 0.0, 2.0, 1.0, 3.0, 3.0, 0.0, 0.0, 0.0, 1.0, 3.0, 4.0,
      3.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 0.0, 5.0,
      2.0, 1.0, 3.0, 2.0, 3.0, 3.0, 0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0,
      4.0, 3.0, 3.0, 2.0, 5.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 2.0, 6.0, 2.0, 2.0,
      0.0, 2.0, 3.0, 0.0, 4.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 2.0,
      3.0, 5.0, 2.0, 3.0, 2.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11025672751507716
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040902549270113366
    mean_inference_ms: 2.0604649386812266
    mean_raw_obs_processing_ms: 0.4646020635543923
time_since_restore: 307.2394073009491
time_this_iter_s: 10.268867254257202
time_total_s: 307.2394073009491
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692341894
timesteps_total: 220900
training_iteration: 30
trial_id: default
train step: 31
agent_timesteps_total: 227500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03990483283996582
  StateBufferConnector_ms: 0.0071489810943603516
  ViewRequirementAgentConnector_ms: 0.2308356761932373
counters:
  num_agent_steps_sampled: 227500
  num_agent_steps_trained: 211000
  num_env_steps_sampled: 227500
  num_env_steps_trained: 211000
  num_samples_added_to_queue: 227500
  num_training_step_calls_since_last_synch_worker_weights: 429
  num_weight_broadcasts: 4445
custom_metrics: {}
date: 2023-08-18_15-58-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 1.94
episode_reward_min: 0.0
episodes_this_iter: 51
episodes_total: 1778
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4137769937515259
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -9.903444290161133
        total_loss: -3.4753944873809814
        var_gnorm: 63.32952880859375
        vf_explained_var: 0.13937759399414062
        vf_loss: 14.269876480102539
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 422.0
  learner_queue:
    size_count: 427
    size_mean: 14.44
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.779438113562818
  num_agent_steps_sampled: 227500
  num_agent_steps_trained: 211000
  num_env_steps_sampled: 227500
  num_env_steps_trained: 211000
  num_samples_added_to_queue: 227500
  num_training_step_calls_since_last_synch_worker_weights: 429
  num_weight_broadcasts: 4445
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 430.155
    learner_load_time_ms: 3.65
    learner_load_wait_time_ms: 2.99
iterations_since_restore: 31
node_ip: 127.0.0.1
num_agent_steps_sampled: 227500
num_agent_steps_trained: 211000
num_env_steps_sampled: 227500
num_env_steps_sampled_this_iter: 6600
num_env_steps_sampled_throughput_per_sec: 659.9960346460168
num_env_steps_trained: 211000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.995794321533
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 52.093333333333334
  ram_util_percent: 82.7
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11038597104739623
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.041086805828333815
  mean_inference_ms: 2.065228769272352
  mean_raw_obs_processing_ms: 0.4659238693541186
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03990483283996582
    StateBufferConnector_ms: 0.0071489810943603516
    ViewRequirementAgentConnector_ms: 0.2308356761932373
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 1.94
  episode_reward_min: 0.0
  episodes_this_iter: 51
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 2.0, 1.0, 0.0, 2.0, 0.0, 2.0, 1.0, 1.0, 0.0, 4.0, 3.0, 3.0,
      2.0, 5.0, 1.0, 1.0, 1.0, 2.0, 3.0, 1.0, 0.0, 2.0, 6.0, 2.0, 2.0, 0.0, 2.0, 3.0,
      0.0, 4.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 2.0, 0.0, 0.0, 3.0, 2.0, 3.0, 5.0, 2.0,
      3.0, 2.0, 2.0, 2.0, 2.0, 3.0, 3.0, 1.0, 1.0, 3.0, 3.0, 4.0, 0.0, 4.0, 4.0, 5.0,
      2.0, 5.0, 4.0, 2.0, 1.0, 2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 2.0, 2.0, 2.0,
      2.0, 1.0, 2.0, 4.0, 1.0, 3.0, 2.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 3.0,
      0.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11038597104739623
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.041086805828333815
    mean_inference_ms: 2.065228769272352
    mean_raw_obs_processing_ms: 0.4659238693541186
time_since_restore: 317.49294805526733
time_this_iter_s: 10.253540754318237
time_total_s: 317.49294805526733
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.089
timestamp: 1692341905
timesteps_total: 227500
training_iteration: 31
trial_id: default
train step: 32
agent_timesteps_total: 234200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04050898551940918
  StateBufferConnector_ms: 0.0073125362396240234
  ViewRequirementAgentConnector_ms: 0.23460078239440918
counters:
  num_agent_steps_sampled: 234200
  num_agent_steps_trained: 217500
  num_env_steps_sampled: 234200
  num_env_steps_trained: 217500
  num_samples_added_to_queue: 234000
  num_training_step_calls_since_last_synch_worker_weights: 699
  num_weight_broadcasts: 4576
custom_metrics: {}
date: 2023-08-18_15-58-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 1.99
episode_reward_min: 0.0
episodes_this_iter: 53
episodes_total: 1831
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4391311407089233
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -26.757022857666016
        total_loss: -22.227502822875977
        var_gnorm: 63.32963562011719
        vf_explained_var: 0.12545204162597656
        vf_loss: 10.498172760009766
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 435.0
  learner_queue:
    size_count: 440
    size_mean: 14.54
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.7229045243425418
  num_agent_steps_sampled: 234200
  num_agent_steps_trained: 217500
  num_env_steps_sampled: 234200
  num_env_steps_trained: 217500
  num_samples_added_to_queue: 234000
  num_training_step_calls_since_last_synch_worker_weights: 699
  num_weight_broadcasts: 4576
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 525.593
    learner_load_time_ms: 3.268
    learner_load_wait_time_ms: 2.91
iterations_since_restore: 32
node_ip: 127.0.0.1
num_agent_steps_sampled: 234200
num_agent_steps_trained: 217500
num_env_steps_sampled: 234200
num_env_steps_sampled_this_iter: 6700
num_env_steps_sampled_throughput_per_sec: 669.9963100159737
num_env_steps_trained: 217500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9964201647506
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 58.54285714285714
  ram_util_percent: 82.83571428571427
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11069035312219234
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04128840939525925
  mean_inference_ms: 2.0716642558199903
  mean_raw_obs_processing_ms: 0.4675363750059083
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04050898551940918
    StateBufferConnector_ms: 0.0073125362396240234
    ViewRequirementAgentConnector_ms: 0.23460078239440918
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 1.99
  episode_reward_min: 0.0
  episodes_this_iter: 53
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 3.0, 3.0, 4.0, 0.0, 4.0, 4.0, 5.0, 2.0, 5.0, 4.0, 2.0, 1.0,
      2.0, 1.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0,
      3.0, 2.0, 1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0,
      2.0, 2.0, 4.0, 2.0, 5.0, 3.0, 0.0, 1.0, 3.0, 1.0, 1.0, 3.0, 1.0, 3.0, 0.0, 1.0,
      3.0, 1.0, 1.0, 4.0, 3.0, 1.0, 5.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0,
      1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 7.0, 2.0, 1.0, 1.0, 2.0,
      1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11069035312219234
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04128840939525925
    mean_inference_ms: 2.0716642558199903
    mean_raw_obs_processing_ms: 0.4675363750059083
time_since_restore: 327.6861219406128
time_this_iter_s: 10.193173885345459
time_total_s: 327.6861219406128
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692341915
timesteps_total: 234200
training_iteration: 32
trial_id: default
train step: 33
agent_timesteps_total: 242200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033879756927490234
  StateBufferConnector_ms: 0.006299495697021484
  ViewRequirementAgentConnector_ms: 0.20490241050720215
counters:
  num_agent_steps_sampled: 242200
  num_agent_steps_trained: 225500
  num_env_steps_sampled: 242200
  num_env_steps_trained: 225500
  num_samples_added_to_queue: 242000
  num_training_step_calls_since_last_synch_worker_weights: 689
  num_weight_broadcasts: 4732
custom_metrics: {}
date: 2023-08-18_15-58-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.08
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 1893
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.4059865474700928
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -37.72718048095703
        total_loss: -31.683835983276367
        var_gnorm: 63.3297233581543
        vf_explained_var: 0.25220412015914917
        vf_loss: 13.49267578125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 451.0
  learner_queue:
    size_count: 456
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5529327094243328
  num_agent_steps_sampled: 242200
  num_agent_steps_trained: 225500
  num_env_steps_sampled: 242200
  num_env_steps_trained: 225500
  num_samples_added_to_queue: 242000
  num_training_step_calls_since_last_synch_worker_weights: 689
  num_weight_broadcasts: 4732
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 364.0
    learner_load_time_ms: 3.181
    learner_load_wait_time_ms: 2.63
iterations_since_restore: 33
node_ip: 127.0.0.1
num_agent_steps_sampled: 242200
num_agent_steps_trained: 225500
num_env_steps_sampled: 242200
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9984931974182
num_env_steps_trained: 225500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9984931974182
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 53.63999999999999
  ram_util_percent: 82.54666666666667
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11079036121620839
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04120385278208518
  mean_inference_ms: 2.070383938641839
  mean_raw_obs_processing_ms: 0.46697317703976643
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033879756927490234
    StateBufferConnector_ms: 0.006299495697021484
    ViewRequirementAgentConnector_ms: 0.20490241050720215
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.08
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 4.0, 3.0, 1.0, 5.0, 3.0, 0.0, 3.0, 2.0, 0.0, 1.0, 1.0,
      1.0, 3.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 7.0, 2.0, 1.0,
      1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 1.0, 6.0, 2.0, 5.0,
      1.0, 2.0, 4.0, 5.0, 1.0, 2.0, 1.0, 3.0, 6.0, 2.0, 4.0, 2.0, 1.0, 1.0, 3.0, 3.0,
      3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 2.0, 5.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0, 1.0,
      1.0, 1.0, 1.0, 5.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 3.0, 2.0, 6.0, 4.0, 1.0,
      1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11079036121620839
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04120385278208518
    mean_inference_ms: 2.070383938641839
    mean_raw_obs_processing_ms: 0.46697317703976643
time_since_restore: 337.8755280971527
time_this_iter_s: 10.189406156539917
time_total_s: 337.8755280971527
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692341925
timesteps_total: 242200
training_iteration: 33
trial_id: default
train step: 34
agent_timesteps_total: 250300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03121161460876465
  StateBufferConnector_ms: 0.005699634552001953
  ViewRequirementAgentConnector_ms: 0.18951773643493652
counters:
  num_agent_steps_sampled: 250300
  num_agent_steps_trained: 233500
  num_env_steps_sampled: 250300
  num_env_steps_trained: 233500
  num_samples_added_to_queue: 250000
  num_training_step_calls_since_last_synch_worker_weights: 169
  num_weight_broadcasts: 4891
custom_metrics: {}
date: 2023-08-18_15-58-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.08
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 1956
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.355587363243103
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -6.761836051940918
        total_loss: -0.16681694984436035
        var_gnorm: 63.32986068725586
        vf_explained_var: 0.21198230981826782
        vf_loss: 14.545625686645508
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 467.0
  learner_queue:
    size_count: 473
    size_mean: 14.82
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5190786681406594
  num_agent_steps_sampled: 250300
  num_agent_steps_trained: 233500
  num_env_steps_sampled: 250300
  num_env_steps_trained: 233500
  num_samples_added_to_queue: 250000
  num_training_step_calls_since_last_synch_worker_weights: 169
  num_weight_broadcasts: 4891
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 304.445
    learner_load_time_ms: 3.137
    learner_load_wait_time_ms: 2.611
iterations_since_restore: 34
node_ip: 127.0.0.1
num_agent_steps_sampled: 250300
num_agent_steps_trained: 233500
num_env_steps_sampled: 250300
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9982039968259
num_env_steps_trained: 233500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9982261697046
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 48.17857142857143
  ram_util_percent: 83.0
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11066584305666549
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0409793443992087
  mean_inference_ms: 2.064110041307671
  mean_raw_obs_processing_ms: 0.4651921804464491
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03121161460876465
    StateBufferConnector_ms: 0.005699634552001953
    ViewRequirementAgentConnector_ms: 0.18951773643493652
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.08
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 1.0, 4.0, 2.0, 5.0, 1.0, 1.0, 1.0, 3.0, 2.0, 1.0, 2.0,
      1.0, 1.0, 1.0, 1.0, 5.0, 2.0, 0.0, 1.0, 2.0, 1.0, 0.0, 2.0, 3.0, 2.0, 6.0, 4.0,
      1.0, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 3.0, 3.0, 2.0,
      4.0, 4.0, 2.0, 2.0, 0.0, 2.0, 5.0, 3.0, 2.0, 1.0, 2.0, 3.0, 3.0, 2.0, 3.0, 5.0,
      1.0, 1.0, 2.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0, 1.0,
      4.0, 2.0, 2.0, 0.0, 5.0, 4.0, 3.0, 1.0, 2.0, 2.0, 4.0, 2.0, 4.0, 4.0, 3.0, 3.0,
      0.0, 2.0, 3.0, 3.0, 0.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11066584305666549
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0409793443992087
    mean_inference_ms: 2.064110041307671
    mean_raw_obs_processing_ms: 0.4651921804464491
time_since_restore: 348.11426424980164
time_this_iter_s: 10.238736152648926
time_total_s: 348.11426424980164
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692341935
timesteps_total: 250300
training_iteration: 34
trial_id: default
train step: 35
agent_timesteps_total: 258400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03146529197692871
  StateBufferConnector_ms: 0.005710601806640625
  ViewRequirementAgentConnector_ms: 0.19068074226379395
counters:
  num_agent_steps_sampled: 258400
  num_agent_steps_trained: 241500
  num_env_steps_sampled: 258400
  num_env_steps_trained: 241500
  num_samples_added_to_queue: 258000
  num_training_step_calls_since_last_synch_worker_weights: 1405
  num_weight_broadcasts: 5050
custom_metrics: {}
date: 2023-08-18_15-59-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.24
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 2019
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3607701063156128
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 3.1186118125915527
        total_loss: 11.72509765625
        var_gnorm: 63.329925537109375
        vf_explained_var: 0.19211530685424805
        vf_loss: 18.573741912841797
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 483.0
  learner_queue:
    size_count: 487
    size_mean: 14.86
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5363593329686906
  num_agent_steps_sampled: 258400
  num_agent_steps_trained: 241500
  num_env_steps_sampled: 258400
  num_env_steps_trained: 241500
  num_samples_added_to_queue: 258000
  num_training_step_calls_since_last_synch_worker_weights: 1405
  num_weight_broadcasts: 5050
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 453.843
    learner_load_time_ms: 3.094
    learner_load_wait_time_ms: 2.818
iterations_since_restore: 35
node_ip: 127.0.0.1
num_agent_steps_sampled: 258400
num_agent_steps_trained: 241500
num_env_steps_sampled: 258400
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.995365169343
num_env_steps_trained: 241500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9954223894746
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.907142857142865
  ram_util_percent: 81.77857142857144
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11035889948183496
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040825178354060784
  mean_inference_ms: 2.057907208262797
  mean_raw_obs_processing_ms: 0.4638144872049664
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03146529197692871
    StateBufferConnector_ms: 0.005710601806640625
    ViewRequirementAgentConnector_ms: 0.19068074226379395
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.24
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 1.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 2.0, 0.0, 1.0,
      1.0, 4.0, 2.0, 2.0, 0.0, 5.0, 4.0, 3.0, 1.0, 2.0, 2.0, 4.0, 2.0, 4.0, 4.0, 3.0,
      3.0, 0.0, 2.0, 3.0, 3.0, 0.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 4.0, 2.0,
      0.0, 0.0, 1.0, 2.0, 4.0, 0.0, 1.0, 1.0, 4.0, 5.0, 1.0, 4.0, 1.0, 5.0, 1.0, 2.0,
      5.0, 6.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 5.0, 1.0, 1.0, 6.0, 1.0, 2.0, 2.0, 4.0,
      5.0, 2.0, 2.0, 4.0, 3.0, 1.0, 3.0, 4.0, 1.0, 5.0, 1.0, 0.0, 2.0, 0.0, 2.0, 5.0,
      2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11035889948183496
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040825178354060784
    mean_inference_ms: 2.057907208262797
    mean_raw_obs_processing_ms: 0.4638144872049664
time_since_restore: 358.2665753364563
time_this_iter_s: 10.152311086654663
time_total_s: 358.2665753364563
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.083
timestamp: 1692341946
timesteps_total: 258400
training_iteration: 35
trial_id: default
train step: 36
agent_timesteps_total: 266450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03160524368286133
  StateBufferConnector_ms: 0.00579380989074707
  ViewRequirementAgentConnector_ms: 0.19136762619018555
counters:
  num_agent_steps_sampled: 266450
  num_agent_steps_trained: 249500
  num_env_steps_sampled: 266450
  num_env_steps_trained: 249500
  num_samples_added_to_queue: 266000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 5208
custom_metrics: {}
date: 2023-08-18_15-59-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.24
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 2081
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3882423639297485
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -21.419099807739258
        total_loss: -13.32797908782959
        var_gnorm: 63.33011245727539
        vf_explained_var: 0.13488662242889404
        vf_loss: 17.570484161376953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 499.0
  learner_queue:
    size_count: 502
    size_mean: 15.04
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4416657032752078
  num_agent_steps_sampled: 266450
  num_agent_steps_trained: 249500
  num_env_steps_sampled: 266450
  num_env_steps_trained: 249500
  num_samples_added_to_queue: 266000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 5208
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 509.513
    learner_load_time_ms: 3.056
    learner_load_wait_time_ms: 2.867
iterations_since_restore: 36
node_ip: 127.0.0.1
num_agent_steps_sampled: 266450
num_agent_steps_trained: 249500
num_env_steps_sampled: 266450
num_env_steps_sampled_this_iter: 8050
num_env_steps_sampled_throughput_per_sec: 804.6596079963522
num_env_steps_trained: 249500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.6617222323997
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.406666666666666
  ram_util_percent: 81.72666666666669
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11001604146694528
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040690758997806456
  mean_inference_ms: 2.052418439944585
  mean_raw_obs_processing_ms: 0.462668845772411
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03160524368286133
    StateBufferConnector_ms: 0.00579380989074707
    ViewRequirementAgentConnector_ms: 0.19136762619018555
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.24
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 1.0, 0.0, 1.0, 1.0, 3.0, 3.0, 5.0, 1.0, 1.0, 6.0, 1.0, 2.0,
      2.0, 4.0, 5.0, 2.0, 2.0, 4.0, 3.0, 1.0, 3.0, 4.0, 1.0, 5.0, 1.0, 0.0, 2.0, 0.0,
      2.0, 5.0, 2.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 1.0, 2.0, 1.0, 1.0,
      1.0, 3.0, 1.0, 2.0, 3.0, 0.0, 2.0, 4.0, 5.0, 6.0, 1.0, 2.0, 2.0, 2.0, 0.0, 2.0,
      1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 3.0, 1.0, 4.0, 6.0, 1.0, 4.0, 1.0, 3.0, 1.0,
      1.0, 1.0, 2.0, 3.0, 6.0, 1.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0, 0.0, 4.0,
      2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11001604146694528
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040690758997806456
    mean_inference_ms: 2.052418439944585
    mean_raw_obs_processing_ms: 0.462668845772411
time_since_restore: 368.4005434513092
time_this_iter_s: 10.133968114852905
time_total_s: 368.4005434513092
timers:
  sample_time_ms: 0.054
  synch_weights_time_ms: 0.454
  training_iteration_time_ms: 0.609
timestamp: 1692341956
timesteps_total: 266450
training_iteration: 36
trial_id: default
train step: 37
agent_timesteps_total: 274000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03290414810180664
  StateBufferConnector_ms: 0.0060193538665771484
  ViewRequirementAgentConnector_ms: 0.1977701187133789
counters:
  num_agent_steps_sampled: 274000
  num_agent_steps_trained: 257500
  num_env_steps_sampled: 274000
  num_env_steps_trained: 257500
  num_samples_added_to_queue: 274000
  num_training_step_calls_since_last_synch_worker_weights: 352
  num_weight_broadcasts: 5357
custom_metrics: {}
date: 2023-08-18_15-59-26
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.32
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 2141
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3768165111541748
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -28.924726486206055
        total_loss: -23.19541358947754
        var_gnorm: 63.3302116394043
        vf_explained_var: 0.17931312322616577
        vf_loss: 12.835440635681152
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 515.0
  learner_queue:
    size_count: 520
    size_mean: 15.14
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4284257068535275
  num_agent_steps_sampled: 274000
  num_agent_steps_trained: 257500
  num_env_steps_sampled: 274000
  num_env_steps_trained: 257500
  num_samples_added_to_queue: 274000
  num_training_step_calls_since_last_synch_worker_weights: 352
  num_weight_broadcasts: 5357
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 385.125
    learner_load_time_ms: 3.053
    learner_load_wait_time_ms: 2.646
iterations_since_restore: 37
node_ip: 127.0.0.1
num_agent_steps_sampled: 274000
num_agent_steps_trained: 257500
num_env_steps_sampled: 274000
num_env_steps_sampled_this_iter: 7550
num_env_steps_sampled_throughput_per_sec: 754.9938798446858
num_env_steps_trained: 257500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9935150672168
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 55.10714285714287
  ram_util_percent: 81.96428571428571
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10979821442801738
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04061889379460597
  mean_inference_ms: 2.0495244959362884
  mean_raw_obs_processing_ms: 0.46206167829911804
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03290414810180664
    StateBufferConnector_ms: 0.0060193538665771484
    ViewRequirementAgentConnector_ms: 0.1977701187133789
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.32
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 3.0, 3.0, 1.0, 4.0, 6.0, 1.0,
      4.0, 1.0, 3.0, 1.0, 1.0, 1.0, 2.0, 3.0, 6.0, 1.0, 4.0, 2.0, 3.0, 3.0, 3.0, 1.0,
      3.0, 2.0, 0.0, 4.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 3.0,
      4.0, 2.0, 1.0, 2.0, 4.0, 2.0, 0.0, 4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 5.0, 3.0, 4.0,
      1.0, 2.0, 0.0, 1.0, 1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 4.0, 4.0, 2.0, 1.0, 1.0, 3.0,
      1.0, 6.0, 2.0, 5.0, 3.0, 1.0, 4.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 1.0, 6.0, 1.0,
      4.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10979821442801738
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04061889379460597
    mean_inference_ms: 2.0495244959362884
    mean_raw_obs_processing_ms: 0.46206167829911804
time_since_restore: 378.60063433647156
time_this_iter_s: 10.200090885162354
time_total_s: 378.60063433647156
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.085
timestamp: 1692341966
timesteps_total: 274000
training_iteration: 37
trial_id: default
train step: 38
agent_timesteps_total: 280700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035944223403930664
  StateBufferConnector_ms: 0.0066432952880859375
  ViewRequirementAgentConnector_ms: 0.21808624267578125
counters:
  num_agent_steps_sampled: 280700
  num_agent_steps_trained: 264000
  num_env_steps_sampled: 280700
  num_env_steps_trained: 264000
  num_samples_added_to_queue: 280500
  num_training_step_calls_since_last_synch_worker_weights: 1111
  num_weight_broadcasts: 5487
custom_metrics: {}
date: 2023-08-18_15-59-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.27
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 2193
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3747302293777466
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -23.404382705688477
        total_loss: -17.411710739135742
        var_gnorm: 63.33027648925781
        vf_explained_var: 0.2012474536895752
        vf_loss: 13.360074043273926
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 528.0
  learner_queue:
    size_count: 532
    size_mean: 15.36
    size_quantiles: [12.0, 13.9, 16.0, 16.0, 16.0]
    size_std: 1.0725670142233537
  num_agent_steps_sampled: 280700
  num_agent_steps_trained: 264000
  num_env_steps_sampled: 280700
  num_env_steps_trained: 264000
  num_samples_added_to_queue: 280500
  num_training_step_calls_since_last_synch_worker_weights: 1111
  num_weight_broadcasts: 5487
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 683.621
    learner_load_time_ms: 3.042
    learner_load_wait_time_ms: 3.528
iterations_since_restore: 38
node_ip: 127.0.0.1
num_agent_steps_sampled: 280700
num_agent_steps_trained: 264000
num_env_steps_sampled: 280700
num_env_steps_sampled_this_iter: 6700
num_env_steps_sampled_throughput_per_sec: 669.9924922830731
num_env_steps_trained: 264000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9927163940262
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 56.48571428571428
  ram_util_percent: 82.92857142857143
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10972242930596533
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04072379335456912
  mean_inference_ms: 2.0518363043245644
  mean_raw_obs_processing_ms: 0.4628074165124341
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035944223403930664
    StateBufferConnector_ms: 0.0066432952880859375
    ViewRequirementAgentConnector_ms: 0.21808624267578125
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.27
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 1.0, 2.0, 3.0, 3.0, 3.0, 5.0, 3.0, 4.0, 1.0, 2.0, 0.0, 1.0,
      1.0, 1.0, 3.0, 0.0, 2.0, 0.0, 4.0, 4.0, 2.0, 1.0, 1.0, 3.0, 1.0, 6.0, 2.0, 5.0,
      3.0, 1.0, 4.0, 2.0, 4.0, 2.0, 2.0, 3.0, 4.0, 1.0, 6.0, 1.0, 4.0, 2.0, 2.0, 3.0,
      1.0, 0.0, 1.0, 0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 1.0, 4.0, 2.0, 1.0, 6.0, 1.0, 2.0,
      3.0, 4.0, 4.0, 2.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 1.0, 1.0,
      1.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 3.0, 4.0, 3.0,
      4.0, 5.0, 1.0, 3.0, 2.0, 4.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10972242930596533
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04072379335456912
    mean_inference_ms: 2.0518363043245644
    mean_raw_obs_processing_ms: 0.4628074165124341
time_since_restore: 388.88310623168945
time_this_iter_s: 10.282471895217896
time_total_s: 388.88310623168945
timers:
  sample_time_ms: 0.038
  synch_weights_time_ms: 0.01
  training_iteration_time_ms: 0.109
timestamp: 1692341976
timesteps_total: 280700
training_iteration: 38
trial_id: default
train step: 39
agent_timesteps_total: 288050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03656506538391113
  StateBufferConnector_ms: 0.006636381149291992
  ViewRequirementAgentConnector_ms: 0.22080111503601074
counters:
  num_agent_steps_sampled: 288050
  num_agent_steps_trained: 271500
  num_env_steps_sampled: 288050
  num_env_steps_trained: 271500
  num_samples_added_to_queue: 288000
  num_training_step_calls_since_last_synch_worker_weights: 488
  num_weight_broadcasts: 5631
custom_metrics: {}
date: 2023-08-18_15-59-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.53
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 2251
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000001
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3644429445266724
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 62.09320831298828
        total_loss: 80.3587646484375
        var_gnorm: 63.330387115478516
        vf_explained_var: 0.17578071355819702
        vf_loss: 37.89556121826172
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 543.0
  learner_queue:
    size_count: 549
    size_mean: 15.12
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3362634470792052
  num_agent_steps_sampled: 288050
  num_agent_steps_trained: 271500
  num_env_steps_sampled: 288050
  num_env_steps_trained: 271500
  num_samples_added_to_queue: 288000
  num_training_step_calls_since_last_synch_worker_weights: 488
  num_weight_broadcasts: 5631
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 301.309
    learner_load_time_ms: 3.125
    learner_load_wait_time_ms: 3.052
iterations_since_restore: 39
node_ip: 127.0.0.1
num_agent_steps_sampled: 288050
num_agent_steps_trained: 271500
num_env_steps_sampled: 288050
num_env_steps_sampled_this_iter: 7350
num_env_steps_sampled_throughput_per_sec: 734.992447334652
num_env_steps_trained: 271500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9922931986245
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.80666666666668
  ram_util_percent: 83.05999999999999
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10980246651212858
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040794412211532516
  mean_inference_ms: 2.054792586511135
  mean_raw_obs_processing_ms: 0.463507561694583
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03656506538391113
    StateBufferConnector_ms: 0.006636381149291992
    ViewRequirementAgentConnector_ms: 0.22080111503601074
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.53
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 1.0, 2.0, 3.0, 4.0, 4.0, 2.0, 0.0, 2.0, 0.0, 3.0, 2.0, 1.0,
      3.0, 2.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 0.0, 3.0, 2.0, 1.0, 2.0, 3.0,
      2.0, 1.0, 3.0, 3.0, 4.0, 3.0, 4.0, 5.0, 1.0, 3.0, 2.0, 4.0, 5.0, 7.0, 3.0, 2.0,
      3.0, 1.0, 4.0, 1.0, 4.0, 4.0, 2.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 6.0, 2.0, 1.0,
      2.0, 3.0, 1.0, 2.0, 5.0, 3.0, 2.0, 3.0, 4.0, 2.0, 7.0, 1.0, 5.0, 0.0, 2.0, 3.0,
      1.0, 3.0, 4.0, 1.0, 1.0, 6.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 3.0, 0.0, 2.0, 4.0,
      3.0, 5.0, 2.0, 6.0, 5.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10980246651212858
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040794412211532516
    mean_inference_ms: 2.054792586511135
    mean_raw_obs_processing_ms: 0.463507561694583
time_since_restore: 399.188107252121
time_this_iter_s: 10.305001020431519
time_total_s: 399.188107252121
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692341987
timesteps_total: 288050
training_iteration: 39
trial_id: default
train step: 40
agent_timesteps_total: 295850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03431987762451172
  StateBufferConnector_ms: 0.006021261215209961
  ViewRequirementAgentConnector_ms: 0.20451831817626953
counters:
  num_agent_steps_sampled: 295850
  num_agent_steps_trained: 279000
  num_env_steps_sampled: 295850
  num_env_steps_trained: 279000
  num_samples_added_to_queue: 295500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 5783
custom_metrics: {}
date: 2023-08-18_15-59-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.42
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 2312
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3943188190460205
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 0.9019315242767334
        total_loss: 10.260804176330566
        var_gnorm: 63.330570220947266
        vf_explained_var: 0.11768585443496704
        vf_loss: 20.112064361572266
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 558.0
  learner_queue:
    size_count: 565
    size_mean: 14.66
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6805951326836577
  num_agent_steps_sampled: 295850
  num_agent_steps_trained: 279000
  num_env_steps_sampled: 295850
  num_env_steps_trained: 279000
  num_samples_added_to_queue: 295500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 5783
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 316.783
    learner_load_time_ms: 3.162
    learner_load_wait_time_ms: 3.134
iterations_since_restore: 40
node_ip: 127.0.0.1
num_agent_steps_sampled: 295850
num_agent_steps_trained: 279000
num_env_steps_sampled: 295850
num_env_steps_sampled_this_iter: 7800
num_env_steps_sampled_throughput_per_sec: 779.7684846654048
num_env_steps_trained: 279000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.7773891013508
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.446666666666665
  ram_util_percent: 83.16000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10984769860900044
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0406864519700623
  mean_inference_ms: 2.053393457986268
  mean_raw_obs_processing_ms: 0.4630196289420953
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03431987762451172
    StateBufferConnector_ms: 0.006021261215209961
    ViewRequirementAgentConnector_ms: 0.20451831817626953
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.42
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 1.0, 2.0, 5.0, 3.0, 2.0, 3.0, 4.0, 2.0, 7.0, 1.0, 5.0,
      0.0, 2.0, 3.0, 1.0, 3.0, 4.0, 1.0, 1.0, 6.0, 2.0, 0.0, 1.0, 2.0, 3.0, 1.0, 3.0,
      0.0, 2.0, 4.0, 3.0, 5.0, 2.0, 6.0, 5.0, 1.0, 1.0, 2.0, 4.0, 5.0, 3.0, 1.0, 2.0,
      1.0, 1.0, 1.0, 2.0, 3.0, 2.0, 5.0, 2.0, 2.0, 2.0, 1.0, 3.0, 5.0, 1.0, 2.0, 2.0,
      5.0, 4.0, 4.0, 0.0, 4.0, 2.0, 2.0, 4.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0,
      1.0, 4.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0,
      1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10984769860900044
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0406864519700623
    mean_inference_ms: 2.053393457986268
    mean_raw_obs_processing_ms: 0.4630196289420953
time_since_restore: 409.5335750579834
time_this_iter_s: 10.345467805862427
time_total_s: 409.5335750579834
timers:
  sample_time_ms: 0.06
  synch_weights_time_ms: 0.939
  training_iteration_time_ms: 1.136
timestamp: 1692341997
timesteps_total: 295850
training_iteration: 40
trial_id: default
train step: 41
agent_timesteps_total: 303000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03446316719055176
  StateBufferConnector_ms: 0.0061838626861572266
  ViewRequirementAgentConnector_ms: 0.20528268814086914
counters:
  num_agent_steps_sampled: 303000
  num_agent_steps_trained: 286500
  num_env_steps_sampled: 303000
  num_env_steps_trained: 286500
  num_samples_added_to_queue: 303000
  num_training_step_calls_since_last_synch_worker_weights: 84
  num_weight_broadcasts: 5923
custom_metrics: {}
date: 2023-08-18_16-00-07
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.47
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 2368
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3546011447906494
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 14.33842658996582
        total_loss: 23.951433181762695
        var_gnorm: 63.33076858520508
        vf_explained_var: 0.18707144260406494
        vf_loss: 20.58061408996582
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 573.0
  learner_queue:
    size_count: 579
    size_mean: 14.48
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7690675509996785
  num_agent_steps_sampled: 303000
  num_agent_steps_trained: 286500
  num_env_steps_sampled: 303000
  num_env_steps_trained: 286500
  num_samples_added_to_queue: 303000
  num_training_step_calls_since_last_synch_worker_weights: 84
  num_weight_broadcasts: 5923
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 299.791
    learner_load_time_ms: 2.544
    learner_load_wait_time_ms: 2.726
iterations_since_restore: 41
node_ip: 127.0.0.1
num_agent_steps_sampled: 303000
num_agent_steps_trained: 286500
num_env_steps_sampled: 303000
num_env_steps_sampled_this_iter: 7150
num_env_steps_sampled_throughput_per_sec: 714.9934710860389
num_env_steps_trained: 286500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.993151488852
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 59.50000000000001
  ram_util_percent: 82.92142857142856
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10978682030034731
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04067223475293665
  mean_inference_ms: 2.0532345066258673
  mean_raw_obs_processing_ms: 0.46304130600729065
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03446316719055176
    StateBufferConnector_ms: 0.0061838626861572266
    ViewRequirementAgentConnector_ms: 0.20528268814086914
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.47
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 1.0, 2.0, 2.0, 5.0, 4.0, 4.0, 0.0, 4.0, 2.0, 2.0, 4.0,
      5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 1.0, 3.0, 1.0, 4.0, 0.0, 2.0, 2.0, 1.0, 3.0, 2.0,
      2.0, 4.0, 2.0, 2.0, 3.0, 3.0, 3.0, 0.0, 1.0, 1.0, 3.0, 1.0, 1.0, 2.0, 3.0, 2.0,
      2.0, 3.0, 1.0, 5.0, 0.0, 7.0, 5.0, 4.0, 2.0, 2.0, 4.0, 2.0, 2.0, 2.0, 2.0, 4.0,
      5.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 4.0, 4.0, 4.0, 2.0, 4.0, 1.0, 2.0, 4.0, 2.0,
      2.0, 1.0, 5.0, 1.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 5.0, 5.0,
      0.0, 5.0, 0.0, 7.0, 2.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10978682030034731
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04067223475293665
    mean_inference_ms: 2.0532345066258673
    mean_raw_obs_processing_ms: 0.46304130600729065
time_since_restore: 419.75738310813904
time_this_iter_s: 10.22380805015564
time_total_s: 419.75738310813904
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342007
timesteps_total: 303000
training_iteration: 41
trial_id: default
train step: 42
agent_timesteps_total: 310500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03436112403869629
  StateBufferConnector_ms: 0.0061969757080078125
  ViewRequirementAgentConnector_ms: 0.20334553718566895
counters:
  num_agent_steps_sampled: 310500
  num_agent_steps_trained: 294000
  num_env_steps_sampled: 310500
  num_env_steps_trained: 294000
  num_samples_added_to_queue: 310500
  num_training_step_calls_since_last_synch_worker_weights: 272
  num_weight_broadcasts: 6069
custom_metrics: {}
date: 2023-08-18_16-00-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.3
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 2426
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3178669214248657
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 16.681001663208008
        total_loss: 28.886289596557617
        var_gnorm: 63.330928802490234
        vf_explained_var: 0.18442195653915405
        vf_loss: 25.728443145751953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 588.0
  learner_queue:
    size_count: 593
    size_mean: 14.34
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7956614380222122
  num_agent_steps_sampled: 310500
  num_agent_steps_trained: 294000
  num_env_steps_sampled: 310500
  num_env_steps_trained: 294000
  num_samples_added_to_queue: 310500
  num_training_step_calls_since_last_synch_worker_weights: 272
  num_weight_broadcasts: 6069
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 367.046
    learner_load_time_ms: 2.543
    learner_load_wait_time_ms: 2.867
iterations_since_restore: 42
node_ip: 127.0.0.1
num_agent_steps_sampled: 310500
num_agent_steps_trained: 294000
num_env_steps_sampled: 310500
num_env_steps_sampled_this_iter: 7500
num_env_steps_sampled_throughput_per_sec: 749.9955117971072
num_env_steps_trained: 294000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9955117971072
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 50.25000000000001
  ram_util_percent: 83.28571428571429
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10972675036714913
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04068917151861766
  mean_inference_ms: 2.0534711250708604
  mean_raw_obs_processing_ms: 0.46314488731161774
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03436112403869629
    StateBufferConnector_ms: 0.0061969757080078125
    ViewRequirementAgentConnector_ms: 0.20334553718566895
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.3
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 4.0, 5.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0, 4.0, 4.0, 4.0,
      2.0, 4.0, 1.0, 2.0, 4.0, 2.0, 2.0, 1.0, 5.0, 1.0, 1.0, 2.0, 4.0, 0.0, 1.0, 2.0,
      2.0, 2.0, 2.0, 2.0, 5.0, 5.0, 0.0, 5.0, 0.0, 7.0, 2.0, 1.0, 3.0, 5.0, 3.0, 3.0,
      3.0, 3.0, 2.0, 1.0, 5.0, 1.0, 2.0, 0.0, 1.0, 0.0, 1.0, 2.0, 1.0, 3.0, 3.0, 0.0,
      1.0, 3.0, 2.0, 0.0, 4.0, 2.0, 4.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 5.0, 2.0,
      2.0, 4.0, 0.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 5.0, 3.0, 3.0, 2.0,
      1.0, 1.0, 4.0, 3.0, 3.0, 5.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10972675036714913
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04068917151861766
    mean_inference_ms: 2.0534711250708604
    mean_raw_obs_processing_ms: 0.46314488731161774
time_since_restore: 429.9889466762543
time_this_iter_s: 10.231563568115234
time_total_s: 429.9889466762543
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.088
timestamp: 1692342017
timesteps_total: 310500
training_iteration: 42
trial_id: default
train step: 43
agent_timesteps_total: 318400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03421330451965332
  StateBufferConnector_ms: 0.006123065948486328
  ViewRequirementAgentConnector_ms: 0.20259809494018555
counters:
  num_agent_steps_sampled: 318400
  num_agent_steps_trained: 301500
  num_env_steps_sampled: 318400
  num_env_steps_trained: 301500
  num_samples_added_to_queue: 318000
  num_training_step_calls_since_last_synch_worker_weights: 526
  num_weight_broadcasts: 6224
custom_metrics: {}
date: 2023-08-18_16-00-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.38
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 2488
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.331993818283081
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -8.157313346862793
        total_loss: 1.3970266580581665
        var_gnorm: 63.3310432434082
        vf_explained_var: 0.1927536129951477
        vf_loss: 20.440673828125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 603.0
  learner_queue:
    size_count: 609
    size_mean: 14.32
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.804882267628556
  num_agent_steps_sampled: 318400
  num_agent_steps_trained: 301500
  num_env_steps_sampled: 318400
  num_env_steps_trained: 301500
  num_samples_added_to_queue: 318000
  num_training_step_calls_since_last_synch_worker_weights: 526
  num_weight_broadcasts: 6224
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 347.609
    learner_load_time_ms: 2.488
    learner_load_wait_time_ms: 2.758
iterations_since_restore: 43
node_ip: 127.0.0.1
num_agent_steps_sampled: 318400
num_agent_steps_trained: 301500
num_env_steps_sampled: 318400
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.9954042702045
num_env_steps_trained: 301500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.995636965384
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 47.3
  ram_util_percent: 83.01333333333334
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10968386110209817
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04060131003379579
  mean_inference_ms: 2.0510765729370464
  mean_raw_obs_processing_ms: 0.4623989714415475
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03421330451965332
    StateBufferConnector_ms: 0.006123065948486328
    ViewRequirementAgentConnector_ms: 0.20259809494018555
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.38
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 0.0, 4.0, 2.0, 4.0, 3.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0,
      5.0, 2.0, 2.0, 4.0, 0.0, 2.0, 2.0, 2.0, 3.0, 1.0, 0.0, 1.0, 2.0, 1.0, 5.0, 3.0,
      3.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 5.0, 2.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0,
      4.0, 4.0, 1.0, 3.0, 3.0, 1.0, 0.0, 1.0, 4.0, 2.0, 4.0, 4.0, 1.0, 2.0, 3.0, 1.0,
      2.0, 4.0, 2.0, 1.0, 1.0, 5.0, 4.0, 3.0, 1.0, 1.0, 0.0, 3.0, 1.0, 2.0, 4.0, 4.0,
      3.0, 3.0, 2.0, 4.0, 6.0, 0.0, 4.0, 0.0, 2.0, 5.0, 3.0, 1.0, 1.0, 0.0, 3.0, 6.0,
      4.0, 1.0, 1.0, 2.0, 0.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10968386110209817
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04060131003379579
    mean_inference_ms: 2.0510765729370464
    mean_raw_obs_processing_ms: 0.4623989714415475
time_since_restore: 440.22577953338623
time_this_iter_s: 10.236832857131958
time_total_s: 440.22577953338623
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.086
timestamp: 1692342028
timesteps_total: 318400
training_iteration: 43
trial_id: default
train step: 44
agent_timesteps_total: 325750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0349271297454834
  StateBufferConnector_ms: 0.006344795227050781
  ViewRequirementAgentConnector_ms: 0.20835471153259277
counters:
  num_agent_steps_sampled: 325750
  num_agent_steps_trained: 309000
  num_env_steps_sampled: 325750
  num_env_steps_trained: 309000
  num_samples_added_to_queue: 325500
  num_training_step_calls_since_last_synch_worker_weights: 104
  num_weight_broadcasts: 6368
custom_metrics: {}
date: 2023-08-18_16-00-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.53
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 2546
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3548383712768555
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -40.9015007019043
        total_loss: -36.48250961303711
        var_gnorm: 63.331050872802734
        vf_explained_var: 0.16227954626083374
        vf_loss: 10.192819595336914
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 618.0
  learner_queue:
    size_count: 625
    size_mean: 14.42
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.8009997223764362
  num_agent_steps_sampled: 325750
  num_agent_steps_trained: 309000
  num_env_steps_sampled: 325750
  num_env_steps_trained: 309000
  num_samples_added_to_queue: 325500
  num_training_step_calls_since_last_synch_worker_weights: 104
  num_weight_broadcasts: 6368
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 292.343
    learner_load_time_ms: 2.473
    learner_load_wait_time_ms: 2.785
iterations_since_restore: 44
node_ip: 127.0.0.1
num_agent_steps_sampled: 325750
num_agent_steps_trained: 309000
num_env_steps_sampled: 325750
num_env_steps_sampled_this_iter: 7350
num_env_steps_sampled_throughput_per_sec: 734.9942697733351
num_env_steps_trained: 309000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9941528299338
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.24285714285713
  ram_util_percent: 83.06428571428572
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1096302200350192
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04058553496315627
  mean_inference_ms: 2.050121622907893
  mean_raw_obs_processing_ms: 0.4621590560522149
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0349271297454834
    StateBufferConnector_ms: 0.006344795227050781
    ViewRequirementAgentConnector_ms: 0.20835471153259277
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.53
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 1.0, 2.0, 4.0, 2.0, 1.0, 1.0, 5.0, 4.0, 3.0, 1.0, 1.0,
      0.0, 3.0, 1.0, 2.0, 4.0, 4.0, 3.0, 3.0, 2.0, 4.0, 6.0, 0.0, 4.0, 0.0, 2.0, 5.0,
      3.0, 1.0, 1.0, 0.0, 3.0, 6.0, 4.0, 1.0, 1.0, 2.0, 0.0, 3.0, 4.0, 4.0, 1.0, 4.0,
      3.0, 1.0, 2.0, 2.0, 1.0, 1.0, 4.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0,
      3.0, 2.0, 3.0, 3.0, 2.0, 6.0, 2.0, 1.0, 5.0, 2.0, 5.0, 8.0, 4.0, 2.0, 4.0, 2.0,
      2.0, 4.0, 3.0, 2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0,
      1.0, 7.0, 2.0, 3.0, 4.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1096302200350192
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04058553496315627
    mean_inference_ms: 2.050121622907893
    mean_raw_obs_processing_ms: 0.4621590560522149
time_since_restore: 450.51641392707825
time_this_iter_s: 10.290634393692017
time_total_s: 450.51641392707825
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.076
timestamp: 1692342038
timesteps_total: 325750
training_iteration: 44
trial_id: default
train step: 45
agent_timesteps_total: 332400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0392155647277832
  StateBufferConnector_ms: 0.006931304931640625
  ViewRequirementAgentConnector_ms: 0.22444725036621094
counters:
  num_agent_steps_sampled: 332400
  num_agent_steps_trained: 315500
  num_env_steps_sampled: 332400
  num_env_steps_trained: 315500
  num_samples_added_to_queue: 332000
  num_training_step_calls_since_last_synch_worker_weights: 530
  num_weight_broadcasts: 6498
custom_metrics: {}
date: 2023-08-18_16-00-48
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.54
episode_reward_min: 0.0
episodes_this_iter: 51
episodes_total: 2597
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3329716920852661
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 27.863561630249023
        total_loss: 40.19401931762695
        var_gnorm: 63.33111572265625
        vf_explained_var: 0.22459864616394043
        vf_loss: 25.99388885498047
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 631.0
  learner_queue:
    size_count: 637
    size_mean: 14.42
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.8009997223764362
  num_agent_steps_sampled: 332400
  num_agent_steps_trained: 315500
  num_env_steps_sampled: 332400
  num_env_steps_trained: 315500
  num_samples_added_to_queue: 332000
  num_training_step_calls_since_last_synch_worker_weights: 530
  num_weight_broadcasts: 6498
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 596.78
    learner_load_time_ms: 2.473
    learner_load_wait_time_ms: 12.488
iterations_since_restore: 45
node_ip: 127.0.0.1
num_agent_steps_sampled: 332400
num_agent_steps_trained: 315500
num_env_steps_sampled: 332400
num_env_steps_sampled_this_iter: 6650
num_env_steps_sampled_throughput_per_sec: 664.9981291346731
num_env_steps_trained: 315500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.998171334643
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 52.086666666666666
  ram_util_percent: 83.1
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10962333228769061
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04071835980633773
  mean_inference_ms: 2.0529771439546702
  mean_raw_obs_processing_ms: 0.4630051439995424
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0392155647277832
    StateBufferConnector_ms: 0.006931304931640625
    ViewRequirementAgentConnector_ms: 0.22444725036621094
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.54
  episode_reward_min: 0.0
  episodes_this_iter: 51
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 2.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 1.0, 3.0, 3.0, 2.0, 3.0,
      3.0, 2.0, 6.0, 2.0, 1.0, 5.0, 2.0, 5.0, 8.0, 4.0, 2.0, 4.0, 2.0, 2.0, 4.0, 3.0,
      2.0, 2.0, 0.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 4.0, 1.0, 1.0, 2.0, 1.0, 7.0, 2.0,
      3.0, 4.0, 1.0, 3.0, 0.0, 3.0, 0.0, 4.0, 4.0, 3.0, 3.0, 2.0, 3.0, 3.0, 6.0, 0.0,
      2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 3.0, 6.0, 4.0, 2.0, 0.0, 1.0, 5.0, 1.0,
      4.0, 4.0, 1.0, 1.0, 4.0, 2.0, 1.0, 3.0, 4.0, 2.0, 2.0, 4.0, 1.0, 0.0, 2.0, 1.0,
      1.0, 2.0, 0.0, 4.0, 0.0, 4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10962333228769061
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04071835980633773
    mean_inference_ms: 2.0529771439546702
    mean_raw_obs_processing_ms: 0.4630051439995424
time_since_restore: 460.78142786026
time_this_iter_s: 10.265013933181763
time_total_s: 460.78142786026
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.089
timestamp: 1692342048
timesteps_total: 332400
training_iteration: 45
trial_id: default
train step: 46
agent_timesteps_total: 339300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04027366638183594
  StateBufferConnector_ms: 0.007223606109619141
  ViewRequirementAgentConnector_ms: 0.23052000999450684
counters:
  num_agent_steps_sampled: 339300
  num_agent_steps_trained: 322500
  num_env_steps_sampled: 339300
  num_env_steps_trained: 322500
  num_samples_added_to_queue: 339000
  num_training_step_calls_since_last_synch_worker_weights: 527
  num_weight_broadcasts: 6633
custom_metrics: {}
date: 2023-08-18_16-00-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.22
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 2651
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3244812488555908
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -0.5785810947418213
        total_loss: 12.780533790588379
        var_gnorm: 63.331268310546875
        vf_explained_var: 0.21342378854751587
        vf_loss: 28.04271125793457
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 645.0
  learner_queue:
    size_count: 651
    size_mean: 14.4
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.833030277982336
  num_agent_steps_sampled: 339300
  num_agent_steps_trained: 322500
  num_env_steps_sampled: 339300
  num_env_steps_trained: 322500
  num_samples_added_to_queue: 339000
  num_training_step_calls_since_last_synch_worker_weights: 527
  num_weight_broadcasts: 6633
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 371.172
    learner_load_time_ms: 7.844
    learner_load_wait_time_ms: 2.715
iterations_since_restore: 46
node_ip: 127.0.0.1
num_agent_steps_sampled: 339300
num_agent_steps_trained: 322500
num_env_steps_sampled: 339300
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 689.997236262901
num_env_steps_trained: 322500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9971962087402
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 49.80714285714286
  ram_util_percent: 83.12142857142855
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10977591465773803
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04085408372697098
  mean_inference_ms: 2.057022042107626
  mean_raw_obs_processing_ms: 0.4638923628498873
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04027366638183594
    StateBufferConnector_ms: 0.007223606109619141
    ViewRequirementAgentConnector_ms: 0.23052000999450684
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.22
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 2.0, 3.0, 3.0, 6.0, 0.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0,
      3.0, 1.0, 3.0, 6.0, 4.0, 2.0, 0.0, 1.0, 5.0, 1.0, 4.0, 4.0, 1.0, 1.0, 4.0, 2.0,
      1.0, 3.0, 4.0, 2.0, 2.0, 4.0, 1.0, 0.0, 2.0, 1.0, 1.0, 2.0, 0.0, 4.0, 0.0, 4.0,
      7.0, 0.0, 4.0, 2.0, 1.0, 3.0, 5.0, 1.0, 0.0, 3.0, 3.0, 0.0, 2.0, 2.0, 5.0, 4.0,
      2.0, 1.0, 1.0, 2.0, 1.0, 5.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0,
      2.0, 1.0, 3.0, 2.0, 6.0, 3.0, 2.0, 0.0, 3.0, 0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 4.0,
      2.0, 3.0, 1.0, 6.0, 3.0, 0.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10977591465773803
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04085408372697098
    mean_inference_ms: 2.057022042107626
    mean_raw_obs_processing_ms: 0.4638923628498873
time_since_restore: 471.0095715522766
time_this_iter_s: 10.228143692016602
time_total_s: 471.0095715522766
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.084
timestamp: 1692342059
timesteps_total: 339300
training_iteration: 46
trial_id: default
train step: 47
agent_timesteps_total: 346350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03808736801147461
  StateBufferConnector_ms: 0.007224559783935547
  ViewRequirementAgentConnector_ms: 0.22599196434020996
counters:
  num_agent_steps_sampled: 346350
  num_agent_steps_trained: 329500
  num_env_steps_sampled: 346350
  num_env_steps_trained: 329500
  num_samples_added_to_queue: 346000
  num_training_step_calls_since_last_synch_worker_weights: 497
  num_weight_broadcasts: 6770
custom_metrics: {}
date: 2023-08-18_16-01-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.38
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 2707
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3627564907073975
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -37.81596374511719
        total_loss: -30.401073455810547
        var_gnorm: 63.33137893676758
        vf_explained_var: 0.19840294122695923
        vf_loss: 16.192537307739258
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 659.0
  learner_queue:
    size_count: 665
    size_mean: 14.4
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.833030277982336
  num_agent_steps_sampled: 346350
  num_agent_steps_trained: 329500
  num_env_steps_sampled: 346350
  num_env_steps_trained: 329500
  num_samples_added_to_queue: 346000
  num_training_step_calls_since_last_synch_worker_weights: 497
  num_weight_broadcasts: 6770
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 375.55
    learner_load_time_ms: 7.845
    learner_load_wait_time_ms: 3.264
iterations_since_restore: 47
node_ip: 127.0.0.1
num_agent_steps_sampled: 346350
num_agent_steps_trained: 329500
num_env_steps_sampled: 346350
num_env_steps_sampled_this_iter: 7050
num_env_steps_sampled_throughput_per_sec: 704.9990419162419
num_env_steps_trained: 329500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9990487111621
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 54.90666666666666
  ram_util_percent: 83.40666666666668
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10998219818674308
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04091730293785617
  mean_inference_ms: 2.059670988363515
  mean_raw_obs_processing_ms: 0.4643055604698003
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03808736801147461
    StateBufferConnector_ms: 0.007224559783935547
    ViewRequirementAgentConnector_ms: 0.22599196434020996
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.38
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 2.0, 2.0, 5.0, 4.0, 2.0, 1.0, 1.0, 2.0, 1.0, 5.0, 2.0, 2.0,
      1.0, 1.0, 3.0, 1.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 3.0, 2.0, 6.0, 3.0, 2.0, 0.0,
      3.0, 0.0, 1.0, 2.0, 3.0, 0.0, 3.0, 4.0, 2.0, 3.0, 1.0, 6.0, 3.0, 0.0, 2.0, 1.0,
      0.0, 1.0, 4.0, 4.0, 1.0, 6.0, 3.0, 3.0, 4.0, 4.0, 2.0, 2.0, 3.0, 6.0, 1.0, 3.0,
      4.0, 2.0, 5.0, 3.0, 3.0, 4.0, 4.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0,
      6.0, 6.0, 2.0, 2.0, 1.0, 2.0, 2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0,
      1.0, 3.0, 6.0, 1.0, 1.0, 6.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10998219818674308
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04091730293785617
    mean_inference_ms: 2.059670988363515
    mean_raw_obs_processing_ms: 0.4643055604698003
time_since_restore: 481.38843059539795
time_this_iter_s: 10.378859043121338
time_total_s: 481.38843059539795
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1692342069
timesteps_total: 346350
training_iteration: 47
trial_id: default
train step: 48
agent_timesteps_total: 353350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0377652645111084
  StateBufferConnector_ms: 0.0070726871490478516
  ViewRequirementAgentConnector_ms: 0.22051429748535156
counters:
  num_agent_steps_sampled: 353350
  num_agent_steps_trained: 336500
  num_env_steps_sampled: 353350
  num_env_steps_trained: 336500
  num_samples_added_to_queue: 353000
  num_training_step_calls_since_last_synch_worker_weights: 29
  num_weight_broadcasts: 6907
custom_metrics: {}
date: 2023-08-18_16-01-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.54
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 2761
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3259592056274414
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -15.041898727416992
        total_loss: -7.9330830574035645
        var_gnorm: 63.33144760131836
        vf_explained_var: 0.22848546504974365
        vf_loss: 15.543590545654297
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 673.0
  learner_queue:
    size_count: 680
    size_mean: 14.34
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.861289875328397
  num_agent_steps_sampled: 353350
  num_agent_steps_trained: 336500
  num_env_steps_sampled: 353350
  num_env_steps_trained: 336500
  num_samples_added_to_queue: 353000
  num_training_step_calls_since_last_synch_worker_weights: 29
  num_weight_broadcasts: 6907
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 276.49
    learner_load_time_ms: 7.846
    learner_load_wait_time_ms: 2.413
iterations_since_restore: 48
node_ip: 127.0.0.1
num_agent_steps_sampled: 353350
num_agent_steps_trained: 336500
num_env_steps_sampled: 353350
num_env_steps_sampled_this_iter: 7000
num_env_steps_sampled_throughput_per_sec: 699.9981308033312
num_env_steps_trained: 336500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9981308033312
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 50.15714285714285
  ram_util_percent: 83.36428571428574
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11010601210817979
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04098971035798908
  mean_inference_ms: 2.061941386865732
  mean_raw_obs_processing_ms: 0.4647777034008749
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0377652645111084
    StateBufferConnector_ms: 0.0070726871490478516
    ViewRequirementAgentConnector_ms: 0.22051429748535156
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.54
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 2.0, 2.0, 3.0, 6.0, 1.0, 3.0, 4.0, 2.0, 5.0, 3.0, 3.0, 4.0,
      4.0, 5.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 1.0, 3.0, 6.0, 6.0, 2.0, 2.0, 1.0, 2.0,
      2.0, 2.0, 1.0, 1.0, 0.0, 1.0, 1.0, 6.0, 1.0, 0.0, 1.0, 3.0, 6.0, 1.0, 1.0, 6.0,
      1.0, 4.0, 0.0, 3.0, 4.0, 1.0, 1.0, 3.0, 5.0, 0.0, 1.0, 3.0, 3.0, 1.0, 3.0, 2.0,
      2.0, 3.0, 3.0, 2.0, 3.0, 4.0, 3.0, 4.0, 2.0, 4.0, 0.0, 3.0, 1.0, 5.0, 2.0, 2.0,
      5.0, 2.0, 4.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 0.0, 4.0, 3.0, 2.0, 1.0,
      5.0, 1.0, 3.0, 2.0, 1.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11010601210817979
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04098971035798908
    mean_inference_ms: 2.061941386865732
    mean_raw_obs_processing_ms: 0.4647777034008749
time_since_restore: 491.63974165916443
time_this_iter_s: 10.25131106376648
time_total_s: 491.63974165916443
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.075
timestamp: 1692342079
timesteps_total: 353350
training_iteration: 48
trial_id: default
train step: 49
agent_timesteps_total: 361850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031758785247802734
  StateBufferConnector_ms: 0.005835294723510742
  ViewRequirementAgentConnector_ms: 0.18932175636291504
counters:
  num_agent_steps_sampled: 361850
  num_agent_steps_trained: 345000
  num_env_steps_sampled: 361850
  num_env_steps_trained: 345000
  num_samples_added_to_queue: 361500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 7074
custom_metrics: {}
date: 2023-08-18_16-01-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.68
episode_reward_min: 0.0
episodes_this_iter: 66
episodes_total: 2827
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.32705819606781
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -6.285312175750732
        total_loss: 1.3374240398406982
        var_gnorm: 63.331626892089844
        vf_explained_var: 0.19290786981582642
        vf_loss: 16.57253074645996
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 690.0
  learner_queue:
    size_count: 695
    size_mean: 14.34
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8287700784953804
  num_agent_steps_sampled: 361850
  num_agent_steps_trained: 345000
  num_env_steps_sampled: 361850
  num_env_steps_trained: 345000
  num_samples_added_to_queue: 361500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 7074
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 349.279
    learner_load_time_ms: 7.809
    learner_load_wait_time_ms: 2.579
iterations_since_restore: 49
node_ip: 127.0.0.1
num_agent_steps_sampled: 361850
num_agent_steps_trained: 345000
num_env_steps_sampled: 361850
num_env_steps_sampled_this_iter: 8500
num_env_steps_sampled_throughput_per_sec: 849.5830174446794
num_env_steps_trained: 345000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.5830174446794
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 41.3
  ram_util_percent: 82.74666666666666
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11007274303128621
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04086413681970738
  mean_inference_ms: 2.0585877509528454
  mean_raw_obs_processing_ms: 0.46369491896138726
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031758785247802734
    StateBufferConnector_ms: 0.005835294723510742
    ViewRequirementAgentConnector_ms: 0.18932175636291504
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.68
  episode_reward_min: 0.0
  episodes_this_iter: 66
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 4.0, 2.0, 4.0, 0.0, 3.0, 1.0, 5.0, 2.0, 2.0, 5.0, 2.0,
      4.0, 3.0, 0.0, 3.0, 3.0, 1.0, 2.0, 1.0, 1.0, 0.0, 4.0, 3.0, 2.0, 1.0, 5.0, 1.0,
      3.0, 2.0, 1.0, 3.0, 5.0, 3.0, 2.0, 1.0, 4.0, 1.0, 1.0, 4.0, 3.0, 1.0, 4.0, 2.0,
      4.0, 4.0, 4.0, 1.0, 5.0, 2.0, 2.0, 2.0, 2.0, 1.0, 2.0, 2.0, 0.0, 0.0, 4.0, 2.0,
      3.0, 3.0, 4.0, 1.0, 3.0, 4.0, 5.0, 3.0, 6.0, 2.0, 6.0, 2.0, 4.0, 3.0, 1.0, 7.0,
      2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 6.0, 3.0, 6.0, 4.0, 2.0, 2.0, 1.0, 2.0,
      2.0, 3.0, 5.0, 3.0, 3.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11007274303128621
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04086413681970738
    mean_inference_ms: 2.0585877509528454
    mean_raw_obs_processing_ms: 0.46369491896138726
time_since_restore: 501.84292435646057
time_this_iter_s: 10.203182697296143
time_total_s: 501.84292435646057
timers:
  sample_time_ms: 0.05
  synch_weights_time_ms: 0.439
  training_iteration_time_ms: 0.597
timestamp: 1692342089
timesteps_total: 361850
training_iteration: 49
trial_id: default
train step: 50
agent_timesteps_total: 369500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03181147575378418
  StateBufferConnector_ms: 0.00617218017578125
  ViewRequirementAgentConnector_ms: 0.19257760047912598
counters:
  num_agent_steps_sampled: 369500
  num_agent_steps_trained: 353000
  num_env_steps_sampled: 369500
  num_env_steps_trained: 353000
  num_samples_added_to_queue: 369500
  num_training_step_calls_since_last_synch_worker_weights: 72
  num_weight_broadcasts: 7225
custom_metrics: {}
date: 2023-08-18_16-01-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.55
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 2887
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3653632402420044
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 41.34446334838867
        total_loss: 53.770713806152344
        var_gnorm: 63.33179473876953
        vf_explained_var: 0.18283945322036743
        vf_loss: 26.217863082885742
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 706.0
  learner_queue:
    size_count: 712
    size_mean: 14.26
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.9163506985935534
  num_agent_steps_sampled: 369500
  num_agent_steps_trained: 353000
  num_env_steps_sampled: 369500
  num_env_steps_trained: 353000
  num_samples_added_to_queue: 369500
  num_training_step_calls_since_last_synch_worker_weights: 72
  num_weight_broadcasts: 7225
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 299.951
    learner_load_time_ms: 7.72
    learner_load_wait_time_ms: 3.523
iterations_since_restore: 50
node_ip: 127.0.0.1
num_agent_steps_sampled: 369500
num_agent_steps_trained: 353000
num_env_steps_sampled: 369500
num_env_steps_sampled_this_iter: 7650
num_env_steps_sampled_throughput_per_sec: 764.9964251685302
num_env_steps_trained: 353000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9962616141491
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 45.74285714285714
  ram_util_percent: 83.2
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10999563547064355
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04075889860611051
  mean_inference_ms: 2.055571137529329
  mean_raw_obs_processing_ms: 0.46280924515468386
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03181147575378418
    StateBufferConnector_ms: 0.00617218017578125
    ViewRequirementAgentConnector_ms: 0.19257760047912598
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.55
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 3.0, 4.0, 1.0, 3.0, 4.0, 5.0, 3.0, 6.0, 2.0, 6.0, 2.0,
      4.0, 3.0, 1.0, 7.0, 2.0, 1.0, 1.0, 1.0, 3.0, 1.0, 2.0, 3.0, 6.0, 3.0, 6.0, 4.0,
      2.0, 2.0, 1.0, 2.0, 2.0, 3.0, 5.0, 3.0, 3.0, 4.0, 3.0, 0.0, 4.0, 1.0, 1.0, 0.0,
      2.0, 3.0, 2.0, 6.0, 2.0, 2.0, 4.0, 4.0, 3.0, 3.0, 0.0, 1.0, 0.0, 5.0, 2.0, 3.0,
      0.0, 0.0, 4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 6.0, 1.0, 2.0,
      5.0, 3.0, 1.0, 3.0, 1.0, 4.0, 2.0, 0.0, 5.0, 1.0, 3.0, 1.0, 5.0, 2.0, 2.0, 1.0,
      1.0, 2.0, 3.0, 4.0, 2.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10999563547064355
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04075889860611051
    mean_inference_ms: 2.055571137529329
    mean_raw_obs_processing_ms: 0.46280924515468386
time_since_restore: 512.2200741767883
time_this_iter_s: 10.377149820327759
time_total_s: 512.2200741767883
timers:
  sample_time_ms: 0.582
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.65
timestamp: 1692342100
timesteps_total: 369500
training_iteration: 50
trial_id: default
train step: 51
agent_timesteps_total: 375850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03592991828918457
  StateBufferConnector_ms: 0.006968498229980469
  ViewRequirementAgentConnector_ms: 0.21591854095458984
counters:
  num_agent_steps_sampled: 375850
  num_agent_steps_trained: 359000
  num_env_steps_sampled: 375850
  num_env_steps_trained: 359000
  num_samples_added_to_queue: 375500
  num_training_step_calls_since_last_synch_worker_weights: 634
  num_weight_broadcasts: 7349
custom_metrics: {}
date: 2023-08-18_16-01-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.31
episode_reward_min: 0.0
episodes_this_iter: 50
episodes_total: 2937
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.352742314338684
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 33.529666900634766
        total_loss: 47.761207580566406
        var_gnorm: 63.331912994384766
        vf_explained_var: 0.20038580894470215
        vf_loss: 29.815826416015625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 718.0
  learner_queue:
    size_count: 723
    size_mean: 14.3
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8466185312619385
  num_agent_steps_sampled: 375850
  num_agent_steps_trained: 359000
  num_env_steps_sampled: 375850
  num_env_steps_trained: 359000
  num_samples_added_to_queue: 375500
  num_training_step_calls_since_last_synch_worker_weights: 634
  num_weight_broadcasts: 7349
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 921.245
    learner_load_time_ms: 7.681
    learner_load_wait_time_ms: 20.005
iterations_since_restore: 51
node_ip: 127.0.0.1
num_agent_steps_sampled: 375850
num_agent_steps_trained: 359000
num_env_steps_sampled: 375850
num_env_steps_sampled_this_iter: 6350
num_env_steps_sampled_throughput_per_sec: 634.9975928159414
num_env_steps_trained: 359000
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9977254953777
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 57.72
  ram_util_percent: 84.52
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10989862698930022
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040902464150231375
  mean_inference_ms: 2.05822238768035
  mean_raw_obs_processing_ms: 0.4637822678324622
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03592991828918457
    StateBufferConnector_ms: 0.006968498229980469
    ViewRequirementAgentConnector_ms: 0.21591854095458984
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.31
  episode_reward_min: 0.0
  episodes_this_iter: 50
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 4.0, 4.0, 3.0, 3.0, 0.0, 1.0, 0.0, 5.0, 2.0, 3.0, 0.0, 0.0,
      4.0, 2.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 1.0, 2.0, 0.0, 6.0, 1.0, 2.0, 5.0, 3.0,
      1.0, 3.0, 1.0, 4.0, 2.0, 0.0, 5.0, 1.0, 3.0, 1.0, 5.0, 2.0, 2.0, 1.0, 1.0, 2.0,
      3.0, 4.0, 2.0, 3.0, 1.0, 0.0, 3.0, 8.0, 0.0, 2.0, 4.0, 3.0, 1.0, 3.0, 1.0, 0.0,
      2.0, 1.0, 0.0, 2.0, 5.0, 1.0, 3.0, 6.0, 1.0, 4.0, 3.0, 1.0, 3.0, 2.0, 2.0, 5.0,
      4.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 2.0, 4.0, 1.0,
      5.0, 2.0, 4.0, 1.0, 4.0, 2.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10989862698930022
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040902464150231375
    mean_inference_ms: 2.05822238768035
    mean_raw_obs_processing_ms: 0.4637822678324622
time_since_restore: 522.4400820732117
time_this_iter_s: 10.22000789642334
time_total_s: 522.4400820732117
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.088
timestamp: 1692342110
timesteps_total: 375850
training_iteration: 51
trial_id: default
train step: 52
agent_timesteps_total: 383850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034262657165527344
  StateBufferConnector_ms: 0.006356716156005859
  ViewRequirementAgentConnector_ms: 0.20618891716003418
counters:
  num_agent_steps_sampled: 383850
  num_agent_steps_trained: 367000
  num_env_steps_sampled: 383850
  num_env_steps_trained: 367000
  num_samples_added_to_queue: 383500
  num_training_step_calls_since_last_synch_worker_weights: 74
  num_weight_broadcasts: 7506
custom_metrics: {}
date: 2023-08-18_16-02-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.23
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 3000
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3237619400024414
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 22.29545021057129
        total_loss: 34.686981201171875
        var_gnorm: 63.332069396972656
        vf_explained_var: 0.26132893562316895
        vf_loss: 26.106826782226562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 734.0
  learner_queue:
    size_count: 740
    size_mean: 14.46
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7459667808981936
  num_agent_steps_sampled: 383850
  num_agent_steps_trained: 367000
  num_env_steps_sampled: 383850
  num_env_steps_trained: 367000
  num_samples_added_to_queue: 383500
  num_training_step_calls_since_last_synch_worker_weights: 74
  num_weight_broadcasts: 7506
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 306.077
    learner_load_time_ms: 7.673
    learner_load_wait_time_ms: 2.61
iterations_since_restore: 52
node_ip: 127.0.0.1
num_agent_steps_sampled: 383850
num_agent_steps_trained: 367000
num_env_steps_sampled: 383850
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9977684083246
num_env_steps_trained: 367000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9977684083246
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.06428571428573
  ram_util_percent: 84.09285714285714
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11000289335283778
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04090277677723751
  mean_inference_ms: 2.0588662398745985
  mean_raw_obs_processing_ms: 0.463742499338177
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034262657165527344
    StateBufferConnector_ms: 0.006356716156005859
    ViewRequirementAgentConnector_ms: 0.20618891716003418
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.23
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 2.0, 5.0, 1.0, 3.0, 6.0, 1.0, 4.0, 3.0, 1.0, 3.0, 2.0, 2.0,
      5.0, 4.0, 3.0, 2.0, 3.0, 3.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 0.0, 2.0, 2.0, 4.0,
      1.0, 5.0, 2.0, 4.0, 1.0, 4.0, 2.0, 0.0, 0.0, 3.0, 1.0, 3.0, 3.0, 1.0, 3.0, 4.0,
      4.0, 0.0, 0.0, 1.0, 1.0, 0.0, 2.0, 1.0, 4.0, 2.0, 4.0, 1.0, 0.0, 1.0, 4.0, 2.0,
      3.0, 2.0, 4.0, 5.0, 1.0, 4.0, 2.0, 2.0, 4.0, 1.0, 1.0, 0.0, 2.0, 1.0, 0.0, 2.0,
      2.0, 4.0, 5.0, 1.0, 5.0, 4.0, 0.0, 2.0, 2.0, 1.0, 5.0, 4.0, 0.0, 2.0, 2.0, 1.0,
      1.0, 1.0, 2.0, 0.0, 3.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11000289335283778
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04090277677723751
    mean_inference_ms: 2.0588662398745985
    mean_raw_obs_processing_ms: 0.463742499338177
time_since_restore: 532.6920292377472
time_this_iter_s: 10.251947164535522
time_total_s: 532.6920292377472
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.076
timestamp: 1692342120
timesteps_total: 383850
training_iteration: 52
trial_id: default
train step: 53
agent_timesteps_total: 391250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03315544128417969
  StateBufferConnector_ms: 0.006303548812866211
  ViewRequirementAgentConnector_ms: 0.20037198066711426
counters:
  num_agent_steps_sampled: 391250
  num_agent_steps_trained: 374500
  num_env_steps_sampled: 391250
  num_env_steps_trained: 374500
  num_samples_added_to_queue: 391000
  num_training_step_calls_since_last_synch_worker_weights: 41
  num_weight_broadcasts: 7651
custom_metrics: {}
date: 2023-08-18_16-02-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.35
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 3058
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.89999999999998
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3184864521026611
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 57.64612579345703
        total_loss: 75.93871307373047
        var_gnorm: 63.33216857910156
        vf_explained_var: 0.19601142406463623
        vf_loss: 37.903656005859375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 749.0
  learner_queue:
    size_count: 756
    size_mean: 14.24
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.8821264569629748
  num_agent_steps_sampled: 391250
  num_agent_steps_trained: 374500
  num_env_steps_sampled: 391250
  num_env_steps_trained: 374500
  num_samples_added_to_queue: 391000
  num_training_step_calls_since_last_synch_worker_weights: 41
  num_weight_broadcasts: 7651
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 282.53
    learner_load_time_ms: 7.641
    learner_load_wait_time_ms: 2.69
iterations_since_restore: 53
node_ip: 127.0.0.1
num_agent_steps_sampled: 391250
num_agent_steps_trained: 374500
num_env_steps_sampled: 391250
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9949541435984
num_env_steps_trained: 374500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9948859563498
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 56.26
  ram_util_percent: 83.16
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.11002852650690075
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04082166887624651
  mean_inference_ms: 2.0571561822937854
  mean_raw_obs_processing_ms: 0.46336763198942416
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03315544128417969
    StateBufferConnector_ms: 0.006303548812866211
    ViewRequirementAgentConnector_ms: 0.20037198066711426
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.35
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 4.0, 2.0, 3.0, 2.0, 4.0, 5.0, 1.0, 4.0, 2.0, 2.0, 4.0, 1.0,
      1.0, 0.0, 2.0, 1.0, 0.0, 2.0, 2.0, 4.0, 5.0, 1.0, 5.0, 4.0, 0.0, 2.0, 2.0, 1.0,
      5.0, 4.0, 0.0, 2.0, 2.0, 1.0, 1.0, 1.0, 2.0, 0.0, 3.0, 3.0, 3.0, 2.0, 1.0, 3.0,
      4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 2.0, 4.0, 3.0, 1.0, 1.0, 2.0, 4.0, 5.0, 5.0, 2.0,
      4.0, 1.0, 1.0, 7.0, 5.0, 3.0, 0.0, 7.0, 2.0, 2.0, 3.0, 1.0, 4.0, 2.0, 3.0, 3.0,
      2.0, 4.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 4.0, 3.0, 5.0, 3.0, 3.0, 1.0, 1.0, 0.0,
      0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.11002852650690075
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04082166887624651
    mean_inference_ms: 2.0571561822937854
    mean_raw_obs_processing_ms: 0.46336763198942416
time_since_restore: 542.9479553699493
time_this_iter_s: 10.255926132202148
time_total_s: 542.9479553699493
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692342131
timesteps_total: 391250
training_iteration: 53
trial_id: default
train step: 54
agent_timesteps_total: 398800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03479456901550293
  StateBufferConnector_ms: 0.006492137908935547
  ViewRequirementAgentConnector_ms: 0.20536589622497559
counters:
  num_agent_steps_sampled: 398800
  num_agent_steps_trained: 382000
  num_env_steps_sampled: 398800
  num_env_steps_trained: 382000
  num_samples_added_to_queue: 398500
  num_training_step_calls_since_last_synch_worker_weights: 316
  num_weight_broadcasts: 7797
custom_metrics: {}
date: 2023-08-18_16-02-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.47
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 3116
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3261889219284058
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -16.1785831451416
        total_loss: -7.620291709899902
        var_gnorm: 63.33235549926758
        vf_explained_var: 0.1697673797607422
        vf_loss: 18.442771911621094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 764.0
  learner_queue:
    size_count: 770
    size_mean: 14.26
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.895362762111781
  num_agent_steps_sampled: 398800
  num_agent_steps_trained: 382000
  num_env_steps_sampled: 398800
  num_env_steps_trained: 382000
  num_samples_added_to_queue: 398500
  num_training_step_calls_since_last_synch_worker_weights: 316
  num_weight_broadcasts: 7797
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 304.592
    learner_load_time_ms: 7.647
    learner_load_wait_time_ms: 2.667
iterations_since_restore: 54
node_ip: 127.0.0.1
num_agent_steps_sampled: 398800
num_agent_steps_trained: 382000
num_env_steps_sampled: 398800
num_env_steps_sampled_this_iter: 7550
num_env_steps_sampled_throughput_per_sec: 754.9975879269414
num_env_steps_trained: 382000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9976039009351
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.12857142857142
  ram_util_percent: 82.09285714285714
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10988534308185983
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04082568484202076
  mean_inference_ms: 2.0567176852532922
  mean_raw_obs_processing_ms: 0.46354812344059737
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03479456901550293
    StateBufferConnector_ms: 0.006492137908935547
    ViewRequirementAgentConnector_ms: 0.20536589622497559
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.47
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 5.0, 2.0, 4.0, 1.0, 1.0, 7.0, 5.0, 3.0, 0.0, 7.0, 2.0, 2.0,
      3.0, 1.0, 4.0, 2.0, 3.0, 3.0, 2.0, 4.0, 0.0, 3.0, 2.0, 1.0, 1.0, 0.0, 4.0, 3.0,
      5.0, 3.0, 3.0, 1.0, 1.0, 0.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 4.0,
      3.0, 4.0, 3.0, 1.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 3.0, 1.0, 2.0, 1.0, 1.0, 1.0,
      1.0, 1.0, 2.0, 5.0, 4.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 5.0, 2.0, 5.0, 4.0, 2.0,
      5.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 2.0, 3.0, 6.0, 3.0, 0.0, 1.0, 1.0, 3.0, 0.0,
      0.0, 2.0, 1.0, 3.0, 5.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10988534308185983
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04082568484202076
    mean_inference_ms: 2.0567176852532922
    mean_raw_obs_processing_ms: 0.46354812344059737
time_since_restore: 553.1787962913513
time_this_iter_s: 10.230840921401978
time_total_s: 553.1787962913513
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342141
timesteps_total: 398800
training_iteration: 54
trial_id: default
train step: 55
agent_timesteps_total: 406850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03247404098510742
  StateBufferConnector_ms: 0.0059108734130859375
  ViewRequirementAgentConnector_ms: 0.19302845001220703
counters:
  num_agent_steps_sampled: 406850
  num_agent_steps_trained: 390000
  num_env_steps_sampled: 406850
  num_env_steps_trained: 390000
  num_samples_added_to_queue: 406500
  num_training_step_calls_since_last_synch_worker_weights: 54
  num_weight_broadcasts: 7955
custom_metrics: {}
date: 2023-08-18_16-02-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.69
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 3179
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.334452748298645
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 10.89144229888916
        total_loss: 25.39322853088379
        var_gnorm: 63.332515716552734
        vf_explained_var: 0.09922176599502563
        vf_loss: 30.33802604675293
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 780.0
  learner_queue:
    size_count: 787
    size_mean: 14.08
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 2.018316129846858
  num_agent_steps_sampled: 406850
  num_agent_steps_trained: 390000
  num_env_steps_sampled: 406850
  num_env_steps_trained: 390000
  num_samples_added_to_queue: 406500
  num_training_step_calls_since_last_synch_worker_weights: 54
  num_weight_broadcasts: 7955
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 252.906
    learner_load_time_ms: 7.675
    learner_load_wait_time_ms: 2.933
iterations_since_restore: 55
node_ip: 127.0.0.1
num_agent_steps_sampled: 406850
num_agent_steps_trained: 390000
num_env_steps_sampled: 406850
num_env_steps_sampled_this_iter: 8050
num_env_steps_sampled_throughput_per_sec: 804.996698869891
num_env_steps_trained: 390000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9967193738048
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 47.01428571428571
  ram_util_percent: 82.22857142857143
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10983137225975953
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04073164809164486
  mean_inference_ms: 2.054142570356461
  mean_raw_obs_processing_ms: 0.4627541671313399
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03247404098510742
    StateBufferConnector_ms: 0.0059108734130859375
    ViewRequirementAgentConnector_ms: 0.19302845001220703
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.69
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 5.0, 4.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 5.0, 2.0, 5.0, 4.0,
      2.0, 5.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 2.0, 3.0, 6.0, 3.0, 0.0, 1.0, 1.0, 3.0,
      0.0, 0.0, 2.0, 1.0, 3.0, 5.0, 4.0, 4.0, 6.0, 4.0, 5.0, 0.0, 3.0, 4.0, 2.0, 2.0,
      2.0, 1.0, 1.0, 7.0, 3.0, 3.0, 1.0, 1.0, 2.0, 5.0, 3.0, 1.0, 3.0, 6.0, 1.0, 2.0,
      4.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 5.0, 2.0, 2.0, 1.0, 2.0, 3.0, 5.0, 4.0, 0.0,
      2.0, 2.0, 6.0, 1.0, 0.0, 4.0, 2.0, 2.0, 1.0, 5.0, 1.0, 2.0, 4.0, 4.0, 1.0, 1.0,
      5.0, 2.0, 2.0, 3.0, 5.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10983137225975953
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04073164809164486
    mean_inference_ms: 2.054142570356461
    mean_raw_obs_processing_ms: 0.4627541671313399
time_since_restore: 563.4487824440002
time_this_iter_s: 10.269986152648926
time_total_s: 563.4487824440002
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.084
timestamp: 1692342151
timesteps_total: 406850
training_iteration: 55
trial_id: default
train step: 56
agent_timesteps_total: 414300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03425192832946777
  StateBufferConnector_ms: 0.006195783615112305
  ViewRequirementAgentConnector_ms: 0.20264554023742676
counters:
  num_agent_steps_sampled: 414300
  num_agent_steps_trained: 397500
  num_env_steps_sampled: 414300
  num_env_steps_trained: 397500
  num_samples_added_to_queue: 414000
  num_training_step_calls_since_last_synch_worker_weights: 340
  num_weight_broadcasts: 8100
custom_metrics: {}
date: 2023-08-18_16-02-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.41
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 3237
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3393268585205078
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -14.851408004760742
        total_loss: -4.689406394958496
        var_gnorm: 63.332725524902344
        vf_explained_var: 0.1853475570678711
        vf_loss: 21.663330078125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 795.0
  learner_queue:
    size_count: 801
    size_mean: 14.08
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.988366163461851
  num_agent_steps_sampled: 414300
  num_agent_steps_trained: 397500
  num_env_steps_sampled: 414300
  num_env_steps_trained: 397500
  num_samples_added_to_queue: 414000
  num_training_step_calls_since_last_synch_worker_weights: 340
  num_weight_broadcasts: 8100
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 334.095
    learner_load_time_ms: 2.335
    learner_load_wait_time_ms: 2.771
iterations_since_restore: 56
node_ip: 127.0.0.1
num_agent_steps_sampled: 414300
num_agent_steps_trained: 397500
num_env_steps_sampled: 414300
num_env_steps_sampled_this_iter: 7450
num_env_steps_sampled_throughput_per_sec: 744.9934458117126
num_env_steps_trained: 397500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9934018238717
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.559999999999995
  ram_util_percent: 83.28666666666666
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10976853033573718
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04070504250552497
  mean_inference_ms: 2.052853217058835
  mean_raw_obs_processing_ms: 0.46242628983265555
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03425192832946777
    StateBufferConnector_ms: 0.006195783615112305
    ViewRequirementAgentConnector_ms: 0.20264554023742676
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.41
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 1.0, 2.0, 4.0, 3.0, 1.0, 1.0, 4.0, 1.0, 2.0, 5.0, 2.0, 2.0,
      1.0, 2.0, 3.0, 5.0, 4.0, 0.0, 2.0, 2.0, 6.0, 1.0, 0.0, 4.0, 2.0, 2.0, 1.0, 5.0,
      1.0, 2.0, 4.0, 4.0, 1.0, 1.0, 5.0, 2.0, 2.0, 3.0, 5.0, 2.0, 2.0, 1.0, 2.0, 1.0,
      1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 4.0, 1.0, 3.0, 2.0, 8.0, 2.0, 2.0, 1.0, 4.0, 1.0,
      4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 5.0, 4.0, 3.0, 2.0, 4.0, 0.0, 2.0,
      1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0, 0.0, 2.0, 6.0, 5.0, 1.0,
      2.0, 3.0, 5.0, 0.0, 2.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10976853033573718
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04070504250552497
    mean_inference_ms: 2.052853217058835
    mean_raw_obs_processing_ms: 0.46242628983265555
time_since_restore: 573.7295093536377
time_this_iter_s: 10.280726909637451
time_total_s: 573.7295093536377
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692342161
timesteps_total: 414300
training_iteration: 56
trial_id: default
train step: 57
agent_timesteps_total: 421400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03710746765136719
  StateBufferConnector_ms: 0.0069849491119384766
  ViewRequirementAgentConnector_ms: 0.2183825969696045
counters:
  num_agent_steps_sampled: 421400
  num_agent_steps_trained: 404500
  num_env_steps_sampled: 421400
  num_env_steps_trained: 404500
  num_samples_added_to_queue: 421000
  num_training_step_calls_since_last_synch_worker_weights: 75
  num_weight_broadcasts: 8239
custom_metrics: {}
date: 2023-08-18_16-02-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.27
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 3293
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3291617631912231
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 44.8954963684082
        total_loss: 59.561397552490234
        var_gnorm: 63.33281707763672
        vf_explained_var: 0.17961126565933228
        vf_loss: 30.66096305847168
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 809.0
  learner_queue:
    size_count: 816
    size_mean: 14.08
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.988366163461851
  num_agent_steps_sampled: 421400
  num_agent_steps_trained: 404500
  num_env_steps_sampled: 421400
  num_env_steps_trained: 404500
  num_samples_added_to_queue: 421000
  num_training_step_calls_since_last_synch_worker_weights: 75
  num_weight_broadcasts: 8239
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 301.249
    learner_load_time_ms: 2.335
    learner_load_wait_time_ms: 3.52
iterations_since_restore: 57
node_ip: 127.0.0.1
num_agent_steps_sampled: 421400
num_agent_steps_trained: 404500
num_env_steps_sampled: 421400
num_env_steps_sampled_this_iter: 7100
num_env_steps_sampled_throughput_per_sec: 709.9949386480652
num_env_steps_trained: 404500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9950099347121
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 53.60000000000001
  ram_util_percent: 82.57857142857144
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1097133570867198
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04077772625108487
  mean_inference_ms: 2.0539583169659754
  mean_raw_obs_processing_ms: 0.46281201828031193
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03710746765136719
    StateBufferConnector_ms: 0.0069849491119384766
    ViewRequirementAgentConnector_ms: 0.2183825969696045
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.27
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 1.0, 4.0, 1.0, 4.0, 3.0, 3.0, 2.0, 1.0, 1.0, 2.0, 1.0,
      1.0, 5.0, 4.0, 3.0, 2.0, 4.0, 0.0, 2.0, 1.0, 1.0, 1.0, 5.0, 1.0, 1.0, 2.0, 2.0,
      3.0, 2.0, 2.0, 0.0, 2.0, 6.0, 5.0, 1.0, 2.0, 3.0, 5.0, 0.0, 2.0, 1.0, 3.0, 2.0,
      3.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 4.0, 1.0, 3.0, 1.0, 3.0, 4.0, 1.0, 2.0, 2.0,
      1.0, 3.0, 0.0, 1.0, 5.0, 5.0, 2.0, 3.0, 2.0, 0.0, 3.0, 1.0, 2.0, 2.0, 2.0, 3.0,
      2.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 4.0, 5.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0,
      2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1097133570867198
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04077772625108487
    mean_inference_ms: 2.0539583169659754
    mean_raw_obs_processing_ms: 0.46281201828031193
time_since_restore: 584.0335805416107
time_this_iter_s: 10.304071187973022
time_total_s: 584.0335805416107
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692342172
timesteps_total: 421400
training_iteration: 57
trial_id: default
train step: 58
agent_timesteps_total: 429200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03535294532775879
  StateBufferConnector_ms: 0.006556034088134766
  ViewRequirementAgentConnector_ms: 0.20898199081420898
counters:
  num_agent_steps_sampled: 429200
  num_agent_steps_trained: 412500
  num_env_steps_sampled: 429200
  num_env_steps_trained: 412500
  num_samples_added_to_queue: 429000
  num_training_step_calls_since_last_synch_worker_weights: 72
  num_weight_broadcasts: 8390
custom_metrics: {}
date: 2023-08-18_16-03-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.4
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 3353
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3157895803451538
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 32.639076232910156
        total_loss: 47.00560760498047
        var_gnorm: 63.33293914794922
        vf_explained_var: 0.22295808792114258
        vf_loss: 30.048851013183594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 825.0
  learner_queue:
    size_count: 832
    size_mean: 13.94
    size_quantiles: [10.0, 11.0, 14.5, 16.0, 16.0]
    size_std: 2.0533874451744367
  num_agent_steps_sampled: 429200
  num_agent_steps_trained: 412500
  num_env_steps_sampled: 429200
  num_env_steps_trained: 412500
  num_samples_added_to_queue: 429000
  num_training_step_calls_since_last_synch_worker_weights: 72
  num_weight_broadcasts: 8390
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 259.545
    learner_load_time_ms: 2.35
    learner_load_wait_time_ms: 2.706
iterations_since_restore: 58
node_ip: 127.0.0.1
num_agent_steps_sampled: 429200
num_agent_steps_trained: 412500
num_env_steps_sampled: 429200
num_env_steps_sampled_this_iter: 7800
num_env_steps_sampled_throughput_per_sec: 779.9964852491447
num_env_steps_trained: 412500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9963951273279
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.92000000000001
  ram_util_percent: 82.88666666666668
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10970542638425407
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040754515327697194
  mean_inference_ms: 2.053684577874898
  mean_raw_obs_processing_ms: 0.46253893147568775
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03535294532775879
    StateBufferConnector_ms: 0.006556034088134766
    ViewRequirementAgentConnector_ms: 0.20898199081420898
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.4
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 1.0, 3.0, 0.0, 1.0, 5.0, 5.0, 2.0, 3.0, 2.0, 0.0, 3.0, 1.0,
      2.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0, 1.0, 4.0, 3.0, 3.0, 4.0, 5.0, 3.0, 1.0, 2.0,
      2.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 2.0, 2.0, 2.0, 4.0,
      1.0, 3.0, 1.0, 1.0, 2.0, 3.0, 0.0, 0.0, 1.0, 0.0, 2.0, 0.0, 1.0, 3.0, 2.0, 6.0,
      2.0, 6.0, 2.0, 4.0, 1.0, 6.0, 2.0, 2.0, 6.0, 2.0, 1.0, 0.0, 4.0, 3.0, 5.0, 0.0,
      4.0, 2.0, 3.0, 3.0, 4.0, 2.0, 2.0, 6.0, 2.0, 2.0, 3.0, 2.0, 5.0, 4.0, 0.0, 2.0,
      2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10970542638425407
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040754515327697194
    mean_inference_ms: 2.053684577874898
    mean_raw_obs_processing_ms: 0.46253893147568775
time_since_restore: 594.3068246841431
time_this_iter_s: 10.273244142532349
time_total_s: 594.3068246841431
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.089
timestamp: 1692342182
timesteps_total: 429200
training_iteration: 58
trial_id: default
train step: 59
agent_timesteps_total: 436600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03414726257324219
  StateBufferConnector_ms: 0.006119489669799805
  ViewRequirementAgentConnector_ms: 0.20450615882873535
counters:
  num_agent_steps_sampled: 436600
  num_agent_steps_trained: 420000
  num_env_steps_sampled: 436600
  num_env_steps_trained: 420000
  num_samples_added_to_queue: 436500
  num_training_step_calls_since_last_synch_worker_weights: 494
  num_weight_broadcasts: 8534
custom_metrics: {}
date: 2023-08-18_16-03-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.85
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 3411
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3038300275802612
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 30.805679321289062
        total_loss: 41.777587890625
        var_gnorm: 63.3331184387207
        vf_explained_var: 0.2811455726623535
        vf_loss: 23.247650146484375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 840.0
  learner_queue:
    size_count: 845
    size_mean: 14.16
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.9220822042774341
  num_agent_steps_sampled: 436600
  num_agent_steps_trained: 420000
  num_env_steps_sampled: 436600
  num_env_steps_trained: 420000
  num_samples_added_to_queue: 436500
  num_training_step_calls_since_last_synch_worker_weights: 494
  num_weight_broadcasts: 8534
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 464.459
    learner_load_time_ms: 2.35
    learner_load_wait_time_ms: 2.58
iterations_since_restore: 59
node_ip: 127.0.0.1
num_agent_steps_sampled: 436600
num_agent_steps_trained: 420000
num_env_steps_sampled: 436600
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9957833530373
num_env_steps_trained: 420000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9957263713217
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.128571428571426
  ram_util_percent: 81.92857142857143
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10967722088064626
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0407215965533534
  mean_inference_ms: 2.052963678030505
  mean_raw_obs_processing_ms: 0.4622233725925014
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03414726257324219
    StateBufferConnector_ms: 0.006119489669799805
    ViewRequirementAgentConnector_ms: 0.20450615882873535
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.85
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 6.0, 2.0, 6.0, 2.0, 4.0, 1.0, 6.0, 2.0, 2.0, 6.0, 2.0,
      1.0, 0.0, 4.0, 3.0, 5.0, 0.0, 4.0, 2.0, 3.0, 3.0, 4.0, 2.0, 2.0, 6.0, 2.0, 2.0,
      3.0, 2.0, 5.0, 4.0, 0.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 2.0, 1.0, 2.0, 0.0, 3.0,
      1.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 5.0, 2.0, 1.0, 2.0, 1.0, 2.0, 2.0, 3.0, 2.0,
      4.0, 3.0, 3.0, 3.0, 6.0, 1.0, 5.0, 2.0, 1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0,
      1.0, 6.0, 2.0, 4.0, 5.0, 3.0, 2.0, 2.0, 4.0, 1.0, 2.0, 6.0, 4.0, 2.0, 2.0, 7.0,
      4.0, 3.0, 4.0, 5.0, 4.0, 6.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10967722088064626
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0407215965533534
    mean_inference_ms: 2.052963678030505
    mean_raw_obs_processing_ms: 0.4622233725925014
time_since_restore: 604.5230298042297
time_this_iter_s: 10.21620512008667
time_total_s: 604.5230298042297
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692342192
timesteps_total: 436600
training_iteration: 59
trial_id: default
train step: 60
agent_timesteps_total: 443800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035082340240478516
  StateBufferConnector_ms: 0.00643610954284668
  ViewRequirementAgentConnector_ms: 0.21204900741577148
counters:
  num_agent_steps_sampled: 443800
  num_agent_steps_trained: 427000
  num_env_steps_sampled: 443800
  num_env_steps_trained: 427000
  num_samples_added_to_queue: 443500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 8675
custom_metrics: {}
date: 2023-08-18_16-03-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.74
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 3467
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2930651903152466
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 52.03154373168945
        total_loss: 69.77583312988281
        var_gnorm: 63.333343505859375
        vf_explained_var: 0.19609415531158447
        vf_loss: 36.78163528442383
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 854.0
  learner_queue:
    size_count: 859
    size_mean: 14.24
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8821264569629748
  num_agent_steps_sampled: 443800
  num_agent_steps_trained: 427000
  num_env_steps_sampled: 443800
  num_env_steps_trained: 427000
  num_samples_added_to_queue: 443500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 8675
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 439.408
    learner_load_time_ms: 4.138
    learner_load_wait_time_ms: 3.026
iterations_since_restore: 60
node_ip: 127.0.0.1
num_agent_steps_sampled: 443800
num_agent_steps_trained: 427000
num_env_steps_sampled: 443800
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 719.8972753240391
num_env_steps_trained: 427000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9001287872602
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 53.20000000000001
  ram_util_percent: 82.56
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10965015569267247
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04076282482118974
  mean_inference_ms: 2.0536958244286057
  mean_raw_obs_processing_ms: 0.4624435144857817
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035082340240478516
    StateBufferConnector_ms: 0.00643610954284668
    ViewRequirementAgentConnector_ms: 0.21204900741577148
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.74
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 2.0, 3.0, 2.0, 4.0, 3.0, 3.0, 3.0, 6.0, 1.0, 5.0, 2.0,
      1.0, 2.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 1.0, 6.0, 2.0, 4.0, 5.0, 3.0, 2.0, 2.0,
      4.0, 1.0, 2.0, 6.0, 4.0, 2.0, 2.0, 7.0, 4.0, 3.0, 4.0, 5.0, 4.0, 6.0, 1.0, 3.0,
      3.0, 3.0, 2.0, 2.0, 4.0, 2.0, 4.0, 4.0, 3.0, 5.0, 2.0, 3.0, 4.0, 2.0, 2.0, 2.0,
      3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 3.0, 5.0, 2.0, 3.0, 3.0, 2.0, 1.0, 6.0, 4.0,
      2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 2.0, 3.0, 3.0, 0.0, 4.0,
      2.0, 3.0, 3.0, 2.0, 3.0, 1.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10965015569267247
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04076282482118974
    mean_inference_ms: 2.0536958244286057
    mean_raw_obs_processing_ms: 0.4624435144857817
time_since_restore: 614.7664229869843
time_this_iter_s: 10.243393182754517
time_total_s: 614.7664229869843
timers:
  sample_time_ms: 0.115
  synch_weights_time_ms: 0.432
  training_iteration_time_ms: 0.714
timestamp: 1692342203
timesteps_total: 443800
training_iteration: 60
trial_id: default
train step: 61
agent_timesteps_total: 451350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034560441970825195
  StateBufferConnector_ms: 0.006486177444458008
  ViewRequirementAgentConnector_ms: 0.20978403091430664
counters:
  num_agent_steps_sampled: 451350
  num_agent_steps_trained: 434500
  num_env_steps_sampled: 451350
  num_env_steps_trained: 434500
  num_samples_added_to_queue: 451000
  num_training_step_calls_since_last_synch_worker_weights: 159
  num_weight_broadcasts: 8823
custom_metrics: {}
date: 2023-08-18_16-03-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.4
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 3527
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3017499446868896
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -0.3102506399154663
        total_loss: 8.394031524658203
        var_gnorm: 63.333518981933594
        vf_explained_var: 0.22598713636398315
        vf_loss: 18.71031379699707
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 869.0
  learner_queue:
    size_count: 875
    size_mean: 14.34
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8287700784953802
  num_agent_steps_sampled: 451350
  num_agent_steps_trained: 434500
  num_env_steps_sampled: 451350
  num_env_steps_trained: 434500
  num_samples_added_to_queue: 451000
  num_training_step_calls_since_last_synch_worker_weights: 159
  num_weight_broadcasts: 8823
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 308.824
    learner_load_time_ms: 4.14
    learner_load_wait_time_ms: 2.653
iterations_since_restore: 61
node_ip: 127.0.0.1
num_agent_steps_sampled: 451350
num_agent_steps_trained: 434500
num_env_steps_sampled: 451350
num_env_steps_sampled_this_iter: 7550
num_env_steps_sampled_throughput_per_sec: 754.998181943503
num_env_steps_trained: 434500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9981939836123
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 48.26428571428572
  ram_util_percent: 83.02857142857144
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10967448634358756
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04075585367091357
  mean_inference_ms: 2.053594217118542
  mean_raw_obs_processing_ms: 0.4623262434414704
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034560441970825195
    StateBufferConnector_ms: 0.006486177444458008
    ViewRequirementAgentConnector_ms: 0.20978403091430664
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.4
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 0.0, 1.0, 1.0, 2.0, 0.0, 3.0, 3.0, 5.0, 2.0, 3.0, 3.0,
      2.0, 1.0, 6.0, 4.0, 2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0, 1.0, 2.0,
      3.0, 3.0, 0.0, 4.0, 2.0, 3.0, 3.0, 2.0, 3.0, 1.0, 0.0, 5.0, 1.0, 4.0, 3.0, 2.0,
      1.0, 3.0, 2.0, 3.0, 2.0, 0.0, 2.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0,
      2.0, 4.0, 1.0, 0.0, 3.0, 2.0, 2.0, 3.0, 6.0, 1.0, 5.0, 3.0, 2.0, 2.0, 4.0, 0.0,
      4.0, 0.0, 3.0, 3.0, 3.0, 1.0, 4.0, 1.0, 2.0, 2.0, 7.0, 2.0, 2.0, 3.0, 5.0, 4.0,
      1.0, 2.0, 4.0, 3.0, 2.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10967448634358756
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04075585367091357
    mean_inference_ms: 2.053594217118542
    mean_raw_obs_processing_ms: 0.4623262434414704
time_since_restore: 625.0021996498108
time_this_iter_s: 10.235776662826538
time_total_s: 625.0021996498108
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342213
timesteps_total: 451350
training_iteration: 61
trial_id: default
train step: 62
agent_timesteps_total: 459650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031273603439331055
  StateBufferConnector_ms: 0.005703926086425781
  ViewRequirementAgentConnector_ms: 0.1897892951965332
counters:
  num_agent_steps_sampled: 459650
  num_agent_steps_trained: 443000
  num_env_steps_sampled: 459650
  num_env_steps_trained: 443000
  num_samples_added_to_queue: 459500
  num_training_step_calls_since_last_synch_worker_weights: 632
  num_weight_broadcasts: 8986
custom_metrics: {}
date: 2023-08-18_16-03-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.53
episode_reward_min: 0.0
episodes_this_iter: 65
episodes_total: 3592
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3031097650527954
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -16.180448532104492
        total_loss: -6.858450889587402
        var_gnorm: 63.3336181640625
        vf_explained_var: 0.1436249017715454
        vf_loss: 19.947105407714844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 886.0
  learner_queue:
    size_count: 891
    size_mean: 14.54
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.711256848050578
  num_agent_steps_sampled: 459650
  num_agent_steps_trained: 443000
  num_env_steps_sampled: 459650
  num_env_steps_trained: 443000
  num_samples_added_to_queue: 459500
  num_training_step_calls_since_last_synch_worker_weights: 632
  num_weight_broadcasts: 8986
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 338.164
    learner_load_time_ms: 4.145
    learner_load_wait_time_ms: 2.649
iterations_since_restore: 62
node_ip: 127.0.0.1
num_agent_steps_sampled: 459650
num_agent_steps_trained: 443000
num_env_steps_sampled: 459650
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9981794397233
num_env_steps_trained: 443000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.998135570801
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 43.32666666666667
  ram_util_percent: 82.92666666666666
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1096429564799719
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040626442901126436
  mean_inference_ms: 2.0501916101363724
  mean_raw_obs_processing_ms: 0.4613378650212796
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031273603439331055
    StateBufferConnector_ms: 0.005703926086425781
    ViewRequirementAgentConnector_ms: 0.1897892951965332
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.53
  episode_reward_min: 0.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 2.0, 3.0, 6.0, 1.0, 5.0, 3.0, 2.0, 2.0, 4.0, 0.0, 4.0,
      0.0, 3.0, 3.0, 3.0, 1.0, 4.0, 1.0, 2.0, 2.0, 7.0, 2.0, 2.0, 3.0, 5.0, 4.0, 1.0,
      2.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 5.0, 5.0, 5.0, 2.0, 0.0, 0.0, 1.0, 2.0, 6.0,
      1.0, 3.0, 0.0, 1.0, 1.0, 1.0, 6.0, 1.0, 1.0, 2.0, 2.0, 5.0, 2.0, 1.0, 1.0, 2.0,
      3.0, 1.0, 3.0, 4.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 4.0, 2.0, 2.0, 1.0, 2.0,
      1.0, 6.0, 2.0, 1.0, 1.0, 0.0, 2.0, 6.0, 3.0, 1.0, 4.0, 3.0, 3.0, 4.0, 2.0, 3.0,
      4.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1096429564799719
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040626442901126436
    mean_inference_ms: 2.0501916101363724
    mean_raw_obs_processing_ms: 0.4613378650212796
time_since_restore: 635.1951787471771
time_this_iter_s: 10.192979097366333
time_total_s: 635.1951787471771
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692342223
timesteps_total: 459650
training_iteration: 62
trial_id: default
train step: 63
agent_timesteps_total: 467800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03119516372680664
  StateBufferConnector_ms: 0.005707979202270508
  ViewRequirementAgentConnector_ms: 0.18710589408874512
counters:
  num_agent_steps_sampled: 467800
  num_agent_steps_trained: 451000
  num_env_steps_sampled: 467800
  num_env_steps_trained: 451000
  num_samples_added_to_queue: 467500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 9146
custom_metrics: {}
date: 2023-08-18_16-03-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.57
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 3655
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.307112216949463
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 5.049756050109863
        total_loss: 13.401585578918457
        var_gnorm: 63.33377456665039
        vf_explained_var: 0.23128372430801392
        vf_loss: 18.010770797729492
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 902.0
  learner_queue:
    size_count: 907
    size_mean: 14.72
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.661806246227279
  num_agent_steps_sampled: 467800
  num_agent_steps_trained: 451000
  num_env_steps_sampled: 467800
  num_env_steps_trained: 451000
  num_samples_added_to_queue: 467500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 9146
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 386.56
    learner_load_time_ms: 4.137
    learner_load_wait_time_ms: 2.688
iterations_since_restore: 63
node_ip: 127.0.0.1
num_agent_steps_sampled: 467800
num_agent_steps_trained: 451000
num_env_steps_sampled: 467800
num_env_steps_sampled_this_iter: 8150
num_env_steps_sampled_throughput_per_sec: 814.9890798601417
num_env_steps_trained: 451000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9892808443109
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 46.85
  ram_util_percent: 82.99285714285713
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10947254429179452
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04052521419132895
  mean_inference_ms: 2.046668387258768
  mean_raw_obs_processing_ms: 0.4605121322025926
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03119516372680664
    StateBufferConnector_ms: 0.005707979202270508
    ViewRequirementAgentConnector_ms: 0.18710589408874512
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.57
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 2.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 4.0, 2.0, 2.0, 1.0,
      2.0, 1.0, 6.0, 2.0, 1.0, 1.0, 0.0, 2.0, 6.0, 3.0, 1.0, 4.0, 3.0, 3.0, 4.0, 2.0,
      3.0, 4.0, 0.0, 3.0, 2.0, 3.0, 2.0, 2.0, 5.0, 3.0, 5.0, 5.0, 4.0, 1.0, 1.0, 2.0,
      2.0, 1.0, 3.0, 5.0, 1.0, 2.0, 4.0, 3.0, 2.0, 5.0, 3.0, 0.0, 1.0, 4.0, 2.0, 1.0,
      3.0, 4.0, 3.0, 3.0, 0.0, 0.0, 4.0, 3.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 7.0,
      4.0, 1.0, 0.0, 4.0, 4.0, 1.0, 4.0, 4.0, 0.0, 4.0, 1.0, 1.0, 4.0, 1.0, 2.0, 3.0,
      3.0, 5.0, 3.0, 0.0, 3.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10947254429179452
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04052521419132895
    mean_inference_ms: 2.046668387258768
    mean_raw_obs_processing_ms: 0.4605121322025926
time_since_restore: 645.3804316520691
time_this_iter_s: 10.185252904891968
time_total_s: 645.3804316520691
timers:
  sample_time_ms: 0.11
  synch_weights_time_ms: 0.416
  training_iteration_time_ms: 0.646
timestamp: 1692342233
timesteps_total: 467800
training_iteration: 63
trial_id: default
train step: 64
agent_timesteps_total: 476050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03133058547973633
  StateBufferConnector_ms: 0.005782365798950195
  ViewRequirementAgentConnector_ms: 0.189314603805542
counters:
  num_agent_steps_sampled: 476050
  num_agent_steps_trained: 459500
  num_env_steps_sampled: 476050
  num_env_steps_trained: 459500
  num_samples_added_to_queue: 476000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 9309
custom_metrics: {}
date: 2023-08-18_16-04-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 3.07
episode_reward_min: 0.0
episodes_this_iter: 65
episodes_total: 3720
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.309486985206604
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 5.269179344177246
        total_loss: 14.222746849060059
        var_gnorm: 63.333946228027344
        vf_explained_var: 0.2001713514328003
        vf_loss: 19.21662139892578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 919.0
  learner_queue:
    size_count: 925
    size_mean: 15.0
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5099668870541498
  num_agent_steps_sampled: 476050
  num_agent_steps_trained: 459500
  num_env_steps_sampled: 476050
  num_env_steps_trained: 459500
  num_samples_added_to_queue: 476000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 9309
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 261.578
    learner_load_time_ms: 4.134
    learner_load_wait_time_ms: 2.553
iterations_since_restore: 64
node_ip: 127.0.0.1
num_agent_steps_sampled: 476050
num_agent_steps_trained: 459500
num_env_steps_sampled: 476050
num_env_steps_sampled_this_iter: 8250
num_env_steps_sampled_throughput_per_sec: 824.9650880567717
num_env_steps_trained: 459500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9640301190982
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 42.76428571428571
  ram_util_percent: 82.60000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1092677731855262
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04043587399421355
  mean_inference_ms: 2.0431255905759755
  mean_raw_obs_processing_ms: 0.4597424578924858
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03133058547973633
    StateBufferConnector_ms: 0.005782365798950195
    ViewRequirementAgentConnector_ms: 0.189314603805542
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 3.07
  episode_reward_min: 0.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 0.0, 4.0, 3.0, 0.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 7.0, 4.0,
      1.0, 0.0, 4.0, 4.0, 1.0, 4.0, 4.0, 0.0, 4.0, 1.0, 1.0, 4.0, 1.0, 2.0, 3.0, 3.0,
      5.0, 3.0, 0.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 2.0, 3.0, 5.0, 4.0,
      6.0, 2.0, 5.0, 2.0, 4.0, 3.0, 3.0, 5.0, 1.0, 4.0, 6.0, 5.0, 3.0, 3.0, 5.0, 3.0,
      2.0, 5.0, 6.0, 2.0, 5.0, 4.0, 5.0, 4.0, 3.0, 3.0, 4.0, 0.0, 5.0, 2.0, 3.0, 1.0,
      1.0, 5.0, 0.0, 5.0, 3.0, 7.0, 4.0, 3.0, 3.0, 6.0, 2.0, 3.0, 1.0, 3.0, 2.0, 3.0,
      7.0, 6.0, 4.0, 2.0, 2.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1092677731855262
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04043587399421355
    mean_inference_ms: 2.0431255905759755
    mean_raw_obs_processing_ms: 0.4597424578924858
time_since_restore: 655.6121428012848
time_this_iter_s: 10.231711149215698
time_total_s: 655.6121428012848
timers:
  sample_time_ms: 0.185
  synch_weights_time_ms: 0.85
  training_iteration_time_ms: 4.269
timestamp: 1692342243
timesteps_total: 476050
training_iteration: 64
trial_id: default
train step: 65
agent_timesteps_total: 484150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03129243850708008
  StateBufferConnector_ms: 0.0056798458099365234
  ViewRequirementAgentConnector_ms: 0.18877792358398438
counters:
  num_agent_steps_sampled: 484150
  num_agent_steps_trained: 467500
  num_env_steps_sampled: 484150
  num_env_steps_trained: 467500
  num_samples_added_to_queue: 484000
  num_training_step_calls_since_last_synch_worker_weights: 132
  num_weight_broadcasts: 9469
custom_metrics: {}
date: 2023-08-18_16-04-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.78
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 3783
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.308040976524353
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -55.92647171020508
        total_loss: -50.645965576171875
        var_gnorm: 63.33403778076172
        vf_explained_var: 0.16617536544799805
        vf_loss: 11.86905574798584
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 935.0
  learner_queue:
    size_count: 941
    size_mean: 14.94
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5415576538034508
  num_agent_steps_sampled: 484150
  num_agent_steps_trained: 467500
  num_env_steps_sampled: 484150
  num_env_steps_trained: 467500
  num_samples_added_to_queue: 484000
  num_training_step_calls_since_last_synch_worker_weights: 132
  num_weight_broadcasts: 9469
  timing_breakdown:
    learner_dequeue_time_ms: 0.014
    learner_grad_time_ms: 320.256
    learner_load_time_ms: 4.779
    learner_load_wait_time_ms: 2.728
iterations_since_restore: 65
node_ip: 127.0.0.1
num_agent_steps_sampled: 484150
num_agent_steps_trained: 467500
num_env_steps_sampled: 484150
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9939167956402
num_env_steps_trained: 467500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9939918969286
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.446666666666665
  ram_util_percent: 82.44
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.109114659974488
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040345307638397186
  mean_inference_ms: 2.039916379455931
  mean_raw_obs_processing_ms: 0.45899421055631806
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03129243850708008
    StateBufferConnector_ms: 0.0056798458099365234
    ViewRequirementAgentConnector_ms: 0.18877792358398438
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.78
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 2.0, 5.0, 4.0, 5.0, 4.0, 3.0, 3.0, 4.0, 0.0, 5.0, 2.0, 3.0,
      1.0, 1.0, 5.0, 0.0, 5.0, 3.0, 7.0, 4.0, 3.0, 3.0, 6.0, 2.0, 3.0, 1.0, 3.0, 2.0,
      3.0, 7.0, 6.0, 4.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0,
      2.0, 1.0, 2.0, 5.0, 1.0, 6.0, 4.0, 1.0, 3.0, 3.0, 0.0, 3.0, 3.0, 2.0, 2.0, 7.0,
      1.0, 3.0, 3.0, 1.0, 1.0, 5.0, 0.0, 4.0, 4.0, 0.0, 3.0, 1.0, 1.0, 4.0, 3.0, 3.0,
      6.0, 4.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 7.0, 4.0, 4.0, 1.0,
      2.0, 5.0, 2.0, 1.0, 0.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.109114659974488
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040345307638397186
    mean_inference_ms: 2.039916379455931
    mean_raw_obs_processing_ms: 0.45899421055631806
time_since_restore: 665.8733596801758
time_this_iter_s: 10.261216878890991
time_total_s: 665.8733596801758
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.088
timestamp: 1692342254
timesteps_total: 484150
training_iteration: 65
trial_id: default
train step: 66
agent_timesteps_total: 492200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03209662437438965
  StateBufferConnector_ms: 0.0057430267333984375
  ViewRequirementAgentConnector_ms: 0.19415831565856934
counters:
  num_agent_steps_sampled: 492200
  num_agent_steps_trained: 475500
  num_env_steps_sampled: 492200
  num_env_steps_trained: 475500
  num_samples_added_to_queue: 492000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 9627
custom_metrics: {}
date: 2023-08-18_16-04-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.31
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 3846
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.278153419494629
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 6.842133045196533
        total_loss: 26.185121536254883
        var_gnorm: 63.334136962890625
        vf_explained_var: 0.17251771688461304
        vf_loss: 39.96413040161133
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 951.0
  learner_queue:
    size_count: 955
    size_mean: 14.72
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7209299811439163
  num_agent_steps_sampled: 492200
  num_agent_steps_trained: 475500
  num_env_steps_sampled: 492200
  num_env_steps_trained: 475500
  num_samples_added_to_queue: 492000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 9627
  timing_breakdown:
    learner_dequeue_time_ms: 0.015
    learner_grad_time_ms: 458.62
    learner_load_time_ms: 5.187
    learner_load_wait_time_ms: 2.753
iterations_since_restore: 66
node_ip: 127.0.0.1
num_agent_steps_sampled: 492200
num_agent_steps_trained: 475500
num_env_steps_sampled: 492200
num_env_steps_sampled_this_iter: 8050
num_env_steps_sampled_throughput_per_sec: 804.6195120000599
num_env_steps_trained: 475500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.6218752795626
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.10714285714287
  ram_util_percent: 83.47857142857141
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1089044046384754
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040291140303708096
  mean_inference_ms: 2.0373549022513933
  mean_raw_obs_processing_ms: 0.4585528463671068
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03209662437438965
    StateBufferConnector_ms: 0.0057430267333984375
    ViewRequirementAgentConnector_ms: 0.19415831565856934
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.31
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 1.0, 1.0, 5.0, 0.0, 4.0, 4.0, 0.0, 3.0, 1.0, 1.0, 4.0, 3.0,
      3.0, 6.0, 4.0, 3.0, 0.0, 0.0, 1.0, 2.0, 2.0, 1.0, 1.0, 3.0, 1.0, 7.0, 4.0, 4.0,
      1.0, 2.0, 5.0, 2.0, 1.0, 0.0, 2.0, 3.0, 1.0, 3.0, 3.0, 1.0, 2.0, 2.0, 4.0, 1.0,
      3.0, 0.0, 1.0, 3.0, 4.0, 1.0, 3.0, 2.0, 1.0, 3.0, 1.0, 0.0, 2.0, 3.0, 3.0, 3.0,
      5.0, 3.0, 3.0, 1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 0.0, 3.0, 3.0, 3.0, 1.0, 1.0, 4.0,
      1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 5.0, 4.0, 1.0, 2.0, 3.0,
      3.0, 3.0, 5.0, 1.0, 4.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1089044046384754
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040291140303708096
    mean_inference_ms: 2.0373549022513933
    mean_raw_obs_processing_ms: 0.4585528463671068
time_since_restore: 676.0323896408081
time_this_iter_s: 10.159029960632324
time_total_s: 676.0323896408081
timers:
  sample_time_ms: 0.052
  synch_weights_time_ms: 0.4
  training_iteration_time_ms: 0.552
timestamp: 1692342264
timesteps_total: 492200
training_iteration: 66
trial_id: default
train step: 67
agent_timesteps_total: 500350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0312657356262207
  StateBufferConnector_ms: 0.005581855773925781
  ViewRequirementAgentConnector_ms: 0.1866438388824463
counters:
  num_agent_steps_sampled: 500350
  num_agent_steps_trained: 483500
  num_env_steps_sampled: 500350
  num_env_steps_trained: 483500
  num_samples_added_to_queue: 500000
  num_training_step_calls_since_last_synch_worker_weights: 751
  num_weight_broadcasts: 9788
custom_metrics: {}
date: 2023-08-18_16-04-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.47
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 3910
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3155128955841064
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -53.801666259765625
        total_loss: -47.196964263916016
        var_gnorm: 63.334320068359375
        vf_explained_var: 0.1770538091659546
        vf_loss: 14.524919509887695
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 967.0
  learner_queue:
    size_count: 972
    size_mean: 14.72
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7209299811439163
  num_agent_steps_sampled: 500350
  num_agent_steps_trained: 483500
  num_env_steps_sampled: 500350
  num_env_steps_trained: 483500
  num_samples_added_to_queue: 500000
  num_training_step_calls_since_last_synch_worker_weights: 751
  num_weight_broadcasts: 9788
  timing_breakdown:
    learner_dequeue_time_ms: 0.015
    learner_grad_time_ms: 368.452
    learner_load_time_ms: 5.162
    learner_load_wait_time_ms: 2.592
iterations_since_restore: 67
node_ip: 127.0.0.1
num_agent_steps_sampled: 500350
num_agent_steps_trained: 483500
num_env_steps_sampled: 500350
num_env_steps_sampled_this_iter: 8150
num_env_steps_sampled_throughput_per_sec: 814.9947147712131
num_env_steps_trained: 483500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9948120453626
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.52142857142858
  ram_util_percent: 82.97857142857141
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10874094345316529
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04021338044439369
  mean_inference_ms: 2.0344313673049443
  mean_raw_obs_processing_ms: 0.4579298208611371
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0312657356262207
    StateBufferConnector_ms: 0.005581855773925781
    ViewRequirementAgentConnector_ms: 0.1866438388824463
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.47
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 2.0, 4.0, 2.0, 1.0, 0.0, 3.0, 3.0, 3.0, 1.0, 1.0, 4.0,
      1.0, 2.0, 3.0, 1.0, 4.0, 2.0, 1.0, 0.0, 2.0, 2.0, 1.0, 5.0, 4.0, 1.0, 2.0, 3.0,
      3.0, 3.0, 5.0, 1.0, 4.0, 3.0, 3.0, 0.0, 3.0, 4.0, 3.0, 4.0, 5.0, 4.0, 2.0, 4.0,
      2.0, 0.0, 1.0, 4.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 5.0, 3.0, 7.0,
      3.0, 4.0, 4.0, 1.0, 2.0, 1.0, 5.0, 1.0, 2.0, 6.0, 2.0, 0.0, 1.0, 6.0, 3.0, 4.0,
      0.0, 4.0, 2.0, 4.0, 1.0, 3.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0,
      5.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10874094345316529
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04021338044439369
    mean_inference_ms: 2.0344313673049443
    mean_raw_obs_processing_ms: 0.4579298208611371
time_since_restore: 686.2190656661987
time_this_iter_s: 10.186676025390625
time_total_s: 686.2190656661987
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.086
timestamp: 1692342274
timesteps_total: 500350
training_iteration: 67
trial_id: default
train step: 68
agent_timesteps_total: 508400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03144717216491699
  StateBufferConnector_ms: 0.005704402923583984
  ViewRequirementAgentConnector_ms: 0.1887071132659912
counters:
  num_agent_steps_sampled: 508400
  num_agent_steps_trained: 491500
  num_env_steps_sampled: 508400
  num_env_steps_trained: 491500
  num_samples_added_to_queue: 508000
  num_training_step_calls_since_last_synch_worker_weights: 506
  num_weight_broadcasts: 9946
custom_metrics: {}
date: 2023-08-18_16-04-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.65
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 3973
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2727824449539185
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -0.6028910279273987
        total_loss: 8.009526252746582
        var_gnorm: 63.33447265625
        vf_explained_var: 0.22092753648757935
        vf_loss: 18.497617721557617
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 983.0
  learner_queue:
    size_count: 988
    size_mean: 14.9
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6031219541881396
  num_agent_steps_sampled: 508400
  num_agent_steps_trained: 491500
  num_env_steps_sampled: 508400
  num_env_steps_trained: 491500
  num_samples_added_to_queue: 508000
  num_training_step_calls_since_last_synch_worker_weights: 506
  num_weight_broadcasts: 9946
  timing_breakdown:
    learner_dequeue_time_ms: 0.015
    learner_grad_time_ms: 380.516
    learner_load_time_ms: 5.198
    learner_load_wait_time_ms: 2.7
iterations_since_restore: 68
node_ip: 127.0.0.1
num_agent_steps_sampled: 508400
num_agent_steps_trained: 491500
num_env_steps_sampled: 508400
num_env_steps_sampled_this_iter: 8050
num_env_steps_sampled_throughput_per_sec: 804.9931674583527
num_env_steps_trained: 491500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9932098964996
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 53.88
  ram_util_percent: 81.57333333333332
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10861763260048708
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.04013441868283952
  mean_inference_ms: 2.0317024417473264
  mean_raw_obs_processing_ms: 0.4572951249232197
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03144717216491699
    StateBufferConnector_ms: 0.005704402923583984
    ViewRequirementAgentConnector_ms: 0.1887071132659912
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.65
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 1.0, 2.0, 1.0, 5.0, 1.0, 2.0, 6.0, 2.0, 0.0, 1.0, 6.0, 3.0,
      4.0, 0.0, 4.0, 2.0, 4.0, 1.0, 3.0, 0.0, 1.0, 2.0, 0.0, 2.0, 2.0, 1.0, 3.0, 3.0,
      3.0, 5.0, 2.0, 1.0, 1.0, 2.0, 4.0, 3.0, 7.0, 5.0, 3.0, 2.0, 6.0, 5.0, 4.0, 1.0,
      1.0, 9.0, 4.0, 0.0, 5.0, 1.0, 4.0, 1.0, 3.0, 2.0, 3.0, 1.0, 2.0, 2.0, 1.0, 2.0,
      3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 5.0, 2.0, 4.0, 3.0, 3.0,
      3.0, 1.0, 0.0, 1.0, 3.0, 0.0, 6.0, 2.0, 6.0, 2.0, 5.0, 1.0, 1.0, 4.0, 2.0, 3.0,
      0.0, 1.0, 3.0, 2.0, 2.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10861763260048708
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.04013441868283952
    mean_inference_ms: 2.0317024417473264
    mean_raw_obs_processing_ms: 0.4572951249232197
time_since_restore: 696.4232878684998
time_this_iter_s: 10.204222202301025
time_total_s: 696.4232878684998
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.086
timestamp: 1692342284
timesteps_total: 508400
training_iteration: 68
trial_id: default
train step: 69
agent_timesteps_total: 516700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030740976333618164
  StateBufferConnector_ms: 0.005630016326904297
  ViewRequirementAgentConnector_ms: 0.18667984008789062
counters:
  num_agent_steps_sampled: 516700
  num_agent_steps_trained: 500000
  num_env_steps_sampled: 516700
  num_env_steps_trained: 500000
  num_samples_added_to_queue: 516500
  num_training_step_calls_since_last_synch_worker_weights: 689
  num_weight_broadcasts: 10109
custom_metrics: {}
date: 2023-08-18_16-04-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.68
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 4037
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.287491798400879
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -35.482337951660156
        total_loss: -28.14436912536621
        var_gnorm: 63.334659576416016
        vf_explained_var: 0.15069115161895752
        vf_loss: 15.96342945098877
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1000.0
  learner_queue:
    size_count: 1005
    size_mean: 15.14
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3268006632497589
  num_agent_steps_sampled: 516700
  num_agent_steps_trained: 500000
  num_env_steps_sampled: 516700
  num_env_steps_trained: 500000
  num_samples_added_to_queue: 516500
  num_training_step_calls_since_last_synch_worker_weights: 689
  num_weight_broadcasts: 10109
  timing_breakdown:
    learner_dequeue_time_ms: 0.016
    learner_grad_time_ms: 351.23
    learner_load_time_ms: 5.183
    learner_load_wait_time_ms: 2.841
iterations_since_restore: 69
node_ip: 127.0.0.1
num_agent_steps_sampled: 516700
num_agent_steps_trained: 500000
num_env_steps_sampled: 516700
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9961807903554
num_env_steps_trained: 500000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9960887612074
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 50.07142857142857
  ram_util_percent: 81.62142857142858
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10844678357942338
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.040056932875468236
  mean_inference_ms: 2.02866898984247
  mean_raw_obs_processing_ms: 0.4566606034130631
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030740976333618164
    StateBufferConnector_ms: 0.005630016326904297
    ViewRequirementAgentConnector_ms: 0.18667984008789062
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.68
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 5.0, 2.0, 4.0, 3.0, 3.0,
      3.0, 1.0, 0.0, 1.0, 3.0, 0.0, 6.0, 2.0, 6.0, 2.0, 5.0, 1.0, 1.0, 4.0, 2.0, 3.0,
      0.0, 1.0, 3.0, 2.0, 2.0, 4.0, 4.0, 3.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0, 3.0, 1.0,
      2.0, 1.0, 5.0, 3.0, 1.0, 4.0, 0.0, 4.0, 1.0, 1.0, 0.0, 2.0, 0.0, 3.0, 5.0, 2.0,
      4.0, 1.0, 5.0, 4.0, 2.0, 5.0, 2.0, 4.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 5.0, 5.0,
      3.0, 1.0, 0.0, 7.0, 3.0, 3.0, 3.0, 4.0, 5.0, 2.0, 1.0, 5.0, 3.0, 1.0, 3.0, 4.0,
      2.0, 5.0, 6.0, 0.0, 2.0, 6.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10844678357942338
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.040056932875468236
    mean_inference_ms: 2.02866898984247
    mean_raw_obs_processing_ms: 0.4566606034130631
time_since_restore: 706.6407947540283
time_this_iter_s: 10.217506885528564
time_total_s: 706.6407947540283
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.089
timestamp: 1692342295
timesteps_total: 516700
training_iteration: 69
trial_id: default
train step: 70
agent_timesteps_total: 525050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03015875816345215
  StateBufferConnector_ms: 0.005525827407836914
  ViewRequirementAgentConnector_ms: 0.1849055290222168
counters:
  num_agent_steps_sampled: 525050
  num_agent_steps_trained: 508500
  num_env_steps_sampled: 525050
  num_env_steps_trained: 508500
  num_samples_added_to_queue: 525000
  num_training_step_calls_since_last_synch_worker_weights: 89
  num_weight_broadcasts: 10273
custom_metrics: {}
date: 2023-08-18_16-05-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.63
episode_reward_min: 0.0
episodes_this_iter: 66
episodes_total: 4103
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2559338808059692
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 16.935617446899414
        total_loss: 30.819957733154297
        var_gnorm: 63.33488464355469
        vf_explained_var: 0.2125023603439331
        vf_loss: 29.02461814880371
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1017.0
  learner_queue:
    size_count: 1023
    size_mean: 15.02
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4627371602581238
  num_agent_steps_sampled: 525050
  num_agent_steps_trained: 508500
  num_env_steps_sampled: 525050
  num_env_steps_trained: 508500
  num_samples_added_to_queue: 525000
  num_training_step_calls_since_last_synch_worker_weights: 89
  num_weight_broadcasts: 10273
  timing_breakdown:
    learner_dequeue_time_ms: 0.016
    learner_grad_time_ms: 276.644
    learner_load_time_ms: 3.837
    learner_load_wait_time_ms: 2.627
iterations_since_restore: 70
node_ip: 127.0.0.1
num_agent_steps_sampled: 525050
num_agent_steps_trained: 508500
num_env_steps_sampled: 525050
num_env_steps_sampled_this_iter: 8350
num_env_steps_sampled_throughput_per_sec: 834.9954012885643
num_env_steps_trained: 508500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9953186769816
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 50.28571428571429
  ram_util_percent: 81.54285714285716
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10828018671341778
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03995792310723387
  mean_inference_ms: 2.0251999555360896
  mean_raw_obs_processing_ms: 0.4558689591702107
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03015875816345215
    StateBufferConnector_ms: 0.005525827407836914
    ViewRequirementAgentConnector_ms: 0.1849055290222168
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.63
  episode_reward_min: 0.0
  episodes_this_iter: 66
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 2.0, 4.0, 3.0, 1.0, 2.0, 3.0, 1.0, 1.0, 5.0, 5.0, 3.0, 1.0,
      0.0, 7.0, 3.0, 3.0, 3.0, 4.0, 5.0, 2.0, 1.0, 5.0, 3.0, 1.0, 3.0, 4.0, 2.0, 5.0,
      6.0, 0.0, 2.0, 6.0, 2.0, 2.0, 5.0, 2.0, 3.0, 4.0, 1.0, 7.0, 1.0, 3.0, 2.0, 0.0,
      4.0, 3.0, 3.0, 1.0, 1.0, 2.0, 0.0, 5.0, 3.0, 5.0, 1.0, 2.0, 3.0, 1.0, 1.0, 3.0,
      4.0, 3.0, 2.0, 2.0, 3.0, 5.0, 1.0, 1.0, 4.0, 4.0, 5.0, 1.0, 1.0, 2.0, 2.0, 1.0,
      2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 1.0, 5.0,
      2.0, 1.0, 5.0, 1.0, 3.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10828018671341778
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03995792310723387
    mean_inference_ms: 2.0251999555360896
    mean_raw_obs_processing_ms: 0.4558689591702107
time_since_restore: 716.8808608055115
time_this_iter_s: 10.240066051483154
time_total_s: 716.8808608055115
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692342305
timesteps_total: 525050
training_iteration: 70
trial_id: default
train step: 71
agent_timesteps_total: 533250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03075098991394043
  StateBufferConnector_ms: 0.005595684051513672
  ViewRequirementAgentConnector_ms: 0.1871480941772461
counters:
  num_agent_steps_sampled: 533250
  num_agent_steps_trained: 516500
  num_env_steps_sampled: 533250
  num_env_steps_trained: 516500
  num_samples_added_to_queue: 533000
  num_training_step_calls_since_last_synch_worker_weights: 183
  num_weight_broadcasts: 10434
custom_metrics: {}
date: 2023-08-18_16-05-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.27
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 4167
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2813067436218262
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 33.387332916259766
        total_loss: 47.8132209777832
        var_gnorm: 63.33510208129883
        vf_explained_var: 0.1959775686264038
        vf_loss: 30.133075714111328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1033.0
  learner_queue:
    size_count: 1039
    size_mean: 14.82
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6209873534361705
  num_agent_steps_sampled: 533250
  num_agent_steps_trained: 516500
  num_env_steps_sampled: 533250
  num_env_steps_trained: 516500
  num_samples_added_to_queue: 533000
  num_training_step_calls_since_last_synch_worker_weights: 183
  num_weight_broadcasts: 10434
  timing_breakdown:
    learner_dequeue_time_ms: 0.016
    learner_grad_time_ms: 293.809
    learner_load_time_ms: 16.957
    learner_load_wait_time_ms: 2.508
iterations_since_restore: 71
node_ip: 127.0.0.1
num_agent_steps_sampled: 533250
num_agent_steps_trained: 516500
num_env_steps_sampled: 533250
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9995112422041
num_env_steps_trained: 516500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.999523163126
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.59333333333334
  ram_util_percent: 81.88000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10811666569972055
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03988170319058055
  mean_inference_ms: 2.022336111748724
  mean_raw_obs_processing_ms: 0.45525719348929866
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03075098991394043
    StateBufferConnector_ms: 0.005595684051513672
    ViewRequirementAgentConnector_ms: 0.1871480941772461
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.27
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 5.0, 1.0, 1.0, 4.0, 4.0, 5.0, 1.0, 1.0, 2.0, 2.0, 1.0,
      2.0, 2.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 2.0, 0.0, 2.0, 4.0, 3.0, 2.0, 1.0, 5.0,
      2.0, 1.0, 5.0, 1.0, 3.0, 3.0, 3.0, 2.0, 6.0, 3.0, 2.0, 1.0, 0.0, 4.0, 1.0, 2.0,
      4.0, 4.0, 3.0, 3.0, 3.0, 2.0, 0.0, 1.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 2.0, 2.0,
      2.0, 5.0, 1.0, 2.0, 1.0, 5.0, 1.0, 3.0, 1.0, 3.0, 1.0, 0.0, 2.0, 2.0, 1.0, 2.0,
      3.0, 0.0, 2.0, 2.0, 3.0, 2.0, 4.0, 2.0, 5.0, 1.0, 2.0, 5.0, 3.0, 2.0, 3.0, 3.0,
      0.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10811666569972055
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03988170319058055
    mean_inference_ms: 2.022336111748724
    mean_raw_obs_processing_ms: 0.45525719348929866
time_since_restore: 727.1147117614746
time_this_iter_s: 10.233850955963135
time_total_s: 727.1147117614746
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692342315
timesteps_total: 533250
training_iteration: 71
trial_id: default
train step: 72
agent_timesteps_total: 540850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03238344192504883
  StateBufferConnector_ms: 0.005960941314697266
  ViewRequirementAgentConnector_ms: 0.19594216346740723
counters:
  num_agent_steps_sampled: 540850
  num_agent_steps_trained: 524000
  num_env_steps_sampled: 540850
  num_env_steps_trained: 524000
  num_samples_added_to_queue: 540500
  num_training_step_calls_since_last_synch_worker_weights: 418
  num_weight_broadcasts: 10583
custom_metrics: {}
date: 2023-08-18_16-05-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.27
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 4225
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2655929327011108
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 6.502818584442139
        total_loss: 18.739965438842773
        var_gnorm: 63.335289001464844
        vf_explained_var: 0.16730302572250366
        vf_loss: 25.739887237548828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1048.0
  learner_queue:
    size_count: 1054
    size_mean: 14.54
    size_quantiles: [11.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.7912007146045916
  num_agent_steps_sampled: 540850
  num_agent_steps_trained: 524000
  num_env_steps_sampled: 540850
  num_env_steps_trained: 524000
  num_samples_added_to_queue: 540500
  num_training_step_calls_since_last_synch_worker_weights: 418
  num_weight_broadcasts: 10583
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 368.755
    learner_load_time_ms: 17.397
    learner_load_wait_time_ms: 2.851
iterations_since_restore: 72
node_ip: 127.0.0.1
num_agent_steps_sampled: 540850
num_agent_steps_trained: 524000
num_env_steps_sampled: 540850
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9920092469197
num_env_steps_trained: 524000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9921143884076
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.2
  ram_util_percent: 83.14285714285714
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1079360893986058
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039885355623957425
  mean_inference_ms: 2.0213582475377443
  mean_raw_obs_processing_ms: 0.4552747578671774
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03238344192504883
    StateBufferConnector_ms: 0.005960941314697266
    ViewRequirementAgentConnector_ms: 0.19594216346740723
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.27
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 2.0, 2.0, 5.0, 1.0, 2.0, 1.0, 5.0, 1.0, 3.0, 1.0, 3.0,
      1.0, 0.0, 2.0, 2.0, 1.0, 2.0, 3.0, 0.0, 2.0, 2.0, 3.0, 2.0, 4.0, 2.0, 5.0, 1.0,
      2.0, 5.0, 3.0, 2.0, 3.0, 3.0, 0.0, 1.0, 2.0, 0.0, 3.0, 2.0, 3.0, 6.0, 3.0, 2.0,
      2.0, 4.0, 2.0, 2.0, 0.0, 1.0, 0.0, 3.0, 3.0, 0.0, 2.0, 1.0, 2.0, 4.0, 1.0, 1.0,
      5.0, 0.0, 3.0, 4.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 5.0, 3.0, 4.0, 1.0, 2.0,
      2.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 4.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 0.0, 2.0,
      2.0, 3.0, 2.0, 2.0, 4.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1079360893986058
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039885355623957425
    mean_inference_ms: 2.0213582475377443
    mean_raw_obs_processing_ms: 0.4552747578671774
time_since_restore: 737.3386425971985
time_this_iter_s: 10.223930835723877
time_total_s: 737.3386425971985
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.086
timestamp: 1692342325
timesteps_total: 540850
training_iteration: 72
trial_id: default
train step: 73
agent_timesteps_total: 548900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03251147270202637
  StateBufferConnector_ms: 0.005974769592285156
  ViewRequirementAgentConnector_ms: 0.19764995574951172
counters:
  num_agent_steps_sampled: 548900
  num_agent_steps_trained: 532000
  num_env_steps_sampled: 548900
  num_env_steps_trained: 532000
  num_samples_added_to_queue: 548500
  num_training_step_calls_since_last_synch_worker_weights: 673
  num_weight_broadcasts: 10741
custom_metrics: {}
date: 2023-08-18_16-05-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.51
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 4289
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.3019360303878784
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -32.21076965332031
        total_loss: -27.331737518310547
        var_gnorm: 63.33538818359375
        vf_explained_var: 0.18317550420761108
        vf_loss: 11.0600004196167
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1064.0
  learner_queue:
    size_count: 1069
    size_mean: 14.38
    size_quantiles: [11.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.798777362543792
  num_agent_steps_sampled: 548900
  num_agent_steps_trained: 532000
  num_env_steps_sampled: 548900
  num_env_steps_trained: 532000
  num_samples_added_to_queue: 548500
  num_training_step_calls_since_last_synch_worker_weights: 673
  num_weight_broadcasts: 10741
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 384.318
    learner_load_time_ms: 27.79
    learner_load_wait_time_ms: 2.699
iterations_since_restore: 73
node_ip: 127.0.0.1
num_agent_steps_sampled: 548900
num_agent_steps_trained: 532000
num_env_steps_sampled: 548900
num_env_steps_sampled_this_iter: 8050
num_env_steps_sampled_throughput_per_sec: 804.9955665117296
num_env_steps_trained: 532000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9955940489239
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.606666666666676
  ram_util_percent: 84.18
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10785274080811444
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03984454384218483
  mean_inference_ms: 2.0198822738512554
  mean_raw_obs_processing_ms: 0.4549698815656872
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03251147270202637
    StateBufferConnector_ms: 0.005974769592285156
    ViewRequirementAgentConnector_ms: 0.19764995574951172
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.51
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 1.0, 2.0, 1.0, 3.0, 3.0, 3.0, 2.0, 5.0, 3.0, 4.0, 1.0, 2.0,
      2.0, 4.0, 2.0, 1.0, 1.0, 3.0, 0.0, 4.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 0.0, 2.0,
      2.0, 3.0, 2.0, 2.0, 4.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 4.0, 1.0, 0.0, 2.0, 3.0,
      2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 4.0, 0.0, 2.0, 1.0, 2.0, 3.0, 4.0, 5.0, 3.0, 5.0,
      0.0, 5.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 3.0, 2.0, 2.0, 2.0, 2.0,
      2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 6.0, 6.0, 4.0, 7.0, 0.0, 3.0, 2.0, 6.0, 0.0,
      2.0, 6.0, 5.0, 3.0, 3.0, 0.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10785274080811444
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03984454384218483
    mean_inference_ms: 2.0198822738512554
    mean_raw_obs_processing_ms: 0.4549698815656872
time_since_restore: 747.5590364933014
time_this_iter_s: 10.220393896102905
time_total_s: 747.5590364933014
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1692342336
timesteps_total: 548900
training_iteration: 73
trial_id: default
train step: 74
agent_timesteps_total: 556900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03144049644470215
  StateBufferConnector_ms: 0.0057506561279296875
  ViewRequirementAgentConnector_ms: 0.19059395790100098
counters:
  num_agent_steps_sampled: 556900
  num_agent_steps_trained: 540000
  num_env_steps_sampled: 556900
  num_env_steps_trained: 540000
  num_samples_added_to_queue: 556500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 10898
custom_metrics: {}
date: 2023-08-18_16-05-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.42
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 4351
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.252126693725586
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 9.841789245605469
        total_loss: 16.50479507446289
        var_gnorm: 63.335514068603516
        vf_explained_var: 0.2707013487815857
        vf_loss: 14.578142166137695
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1080.0
  learner_queue:
    size_count: 1085
    size_mean: 14.6
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6852299546352716
  num_agent_steps_sampled: 556900
  num_agent_steps_trained: 540000
  num_env_steps_sampled: 556900
  num_env_steps_trained: 540000
  num_samples_added_to_queue: 556500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 10898
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 376.086
    learner_load_time_ms: 28.892
    learner_load_wait_time_ms: 2.543
iterations_since_restore: 74
node_ip: 127.0.0.1
num_agent_steps_sampled: 556900
num_agent_steps_trained: 540000
num_env_steps_sampled: 556900
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9554277459468
num_env_steps_trained: 540000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9554277459468
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 55.05714285714286
  ram_util_percent: 82.92857142857143
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10780699049717699
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039775867055096246
  mean_inference_ms: 2.0179718909713626
  mean_raw_obs_processing_ms: 0.4544576032669974
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03144049644470215
    StateBufferConnector_ms: 0.0057506561279296875
    ViewRequirementAgentConnector_ms: 0.19059395790100098
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.42
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 4.0, 3.0, 4.0, 3.0, 2.0, 2.0,
      2.0, 2.0, 2.0, 2.0, 1.0, 3.0, 1.0, 3.0, 2.0, 6.0, 6.0, 4.0, 7.0, 0.0, 3.0, 2.0,
      6.0, 0.0, 2.0, 6.0, 5.0, 3.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0, 7.0, 3.0, 1.0, 4.0,
      4.0, 1.0, 2.0, 3.0, 3.0, 0.0, 1.0, 4.0, 5.0, 1.0, 2.0, 2.0, 1.0, 3.0, 0.0, 3.0,
      1.0, 2.0, 0.0, 2.0, 8.0, 1.0, 3.0, 4.0, 2.0, 3.0, 0.0, 3.0, 3.0, 1.0, 1.0, 0.0,
      2.0, 2.0, 2.0, 4.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 3.0, 2.0,
      2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10780699049717699
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039775867055096246
    mean_inference_ms: 2.0179718909713626
    mean_raw_obs_processing_ms: 0.4544576032669974
time_since_restore: 757.7594792842865
time_this_iter_s: 10.200442790985107
time_total_s: 757.7594792842865
timers:
  sample_time_ms: 0.051
  synch_weights_time_ms: 0.405
  training_iteration_time_ms: 0.557
timestamp: 1692342346
timesteps_total: 556900
training_iteration: 74
trial_id: default
train step: 75
agent_timesteps_total: 564900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03177213668823242
  StateBufferConnector_ms: 0.005774021148681641
  ViewRequirementAgentConnector_ms: 0.19326066970825195
counters:
  num_agent_steps_sampled: 564900
  num_agent_steps_trained: 548000
  num_env_steps_sampled: 564900
  num_env_steps_trained: 548000
  num_samples_added_to_queue: 564500
  num_training_step_calls_since_last_synch_worker_weights: 63
  num_weight_broadcasts: 11056
custom_metrics: {}
date: 2023-08-18_16-05-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.44
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 4414
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2851874828338623
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 55.512691497802734
        total_loss: 75.00126647949219
        var_gnorm: 63.33565902709961
        vf_explained_var: 0.20669418573379517
        vf_loss: 40.26234436035156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1096.0
  learner_queue:
    size_count: 1102
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.616044553841261
  num_agent_steps_sampled: 564900
  num_agent_steps_trained: 548000
  num_env_steps_sampled: 564900
  num_env_steps_trained: 548000
  num_samples_added_to_queue: 564500
  num_training_step_calls_since_last_synch_worker_weights: 63
  num_weight_broadcasts: 11056
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 319.135
    learner_load_time_ms: 36.056
    learner_load_wait_time_ms: 2.701
iterations_since_restore: 75
node_ip: 127.0.0.1
num_agent_steps_sampled: 564900
num_agent_steps_trained: 548000
num_env_steps_sampled: 564900
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9977493349452
num_env_steps_trained: 548000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9977493349452
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.23571428571429
  ram_util_percent: 83.47142857142858
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10770282068600809
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039726923574612785
  mean_inference_ms: 2.0161636688829367
  mean_raw_obs_processing_ms: 0.4540636187207343
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03177213668823242
    StateBufferConnector_ms: 0.005774021148681641
    ViewRequirementAgentConnector_ms: 0.19326066970825195
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.44
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 2.0, 8.0, 1.0, 3.0, 4.0, 2.0, 3.0, 0.0, 3.0, 3.0, 1.0, 1.0,
      0.0, 2.0, 2.0, 2.0, 4.0, 3.0, 6.0, 0.0, 0.0, 0.0, 0.0, 2.0, 1.0, 1.0, 3.0, 3.0,
      2.0, 2.0, 3.0, 3.0, 2.0, 2.0, 1.0, 5.0, 2.0, 1.0, 1.0, 2.0, 4.0, 0.0, 2.0, 3.0,
      5.0, 3.0, 2.0, 3.0, 2.0, 5.0, 1.0, 2.0, 2.0, 5.0, 3.0, 6.0, 0.0, 3.0, 2.0, 4.0,
      0.0, 2.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 1.0, 2.0, 6.0, 1.0, 5.0, 6.0, 3.0, 4.0,
      3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 3.0, 4.0, 1.0, 1.0, 4.0, 1.0,
      4.0, 6.0, 1.0, 1.0, 4.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10770282068600809
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039726923574612785
    mean_inference_ms: 2.0161636688829367
    mean_raw_obs_processing_ms: 0.4540636187207343
time_since_restore: 768.0038826465607
time_this_iter_s: 10.24440336227417
time_total_s: 768.0038826465607
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1692342356
timesteps_total: 564900
training_iteration: 75
trial_id: default
train step: 76
agent_timesteps_total: 572900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031424760818481445
  StateBufferConnector_ms: 0.005658388137817383
  ViewRequirementAgentConnector_ms: 0.19271636009216309
counters:
  num_agent_steps_sampled: 572900
  num_agent_steps_trained: 556000
  num_env_steps_sampled: 572900
  num_env_steps_trained: 556000
  num_samples_added_to_queue: 572500
  num_training_step_calls_since_last_synch_worker_weights: 563
  num_weight_broadcasts: 11212
custom_metrics: {}
date: 2023-08-18_16-06-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.62
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 4476
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2581089735031128
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 1.8421664237976074
        total_loss: 9.345510482788086
        var_gnorm: 63.335853576660156
        vf_explained_var: 0.24013829231262207
        vf_loss: 16.26479721069336
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1112.0
  learner_queue:
    size_count: 1118
    size_mean: 14.74
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.659035864591239
  num_agent_steps_sampled: 572900
  num_agent_steps_trained: 556000
  num_env_steps_sampled: 572900
  num_env_steps_trained: 556000
  num_samples_added_to_queue: 572500
  num_training_step_calls_since_last_synch_worker_weights: 563
  num_weight_broadcasts: 11212
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 344.626
    learner_load_time_ms: 35.747
    learner_load_wait_time_ms: 2.613
iterations_since_restore: 76
node_ip: 127.0.0.1
num_agent_steps_sampled: 572900
num_agent_steps_trained: 556000
num_env_steps_sampled: 572900
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9940872629392
num_env_steps_trained: 556000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9940872629392
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 48.36
  ram_util_percent: 83.74000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10760148641170886
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03968601097740745
  mean_inference_ms: 2.0144005678987353
  mean_raw_obs_processing_ms: 0.45368886447573586
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031424760818481445
    StateBufferConnector_ms: 0.005658388137817383
    ViewRequirementAgentConnector_ms: 0.19271636009216309
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.62
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 2.0, 4.0, 1.0, 4.0, 1.0, 1.0, 2.0, 6.0, 1.0, 5.0, 6.0,
      3.0, 4.0, 3.0, 3.0, 1.0, 2.0, 2.0, 3.0, 1.0, 2.0, 0.0, 2.0, 3.0, 4.0, 1.0, 1.0,
      4.0, 1.0, 4.0, 6.0, 1.0, 1.0, 4.0, 4.0, 4.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 2.0,
      1.0, 4.0, 4.0, 0.0, 1.0, 5.0, 2.0, 4.0, 2.0, 3.0, 3.0, 4.0, 0.0, 6.0, 0.0, 4.0,
      1.0, 8.0, 3.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 2.0,
      3.0, 5.0, 4.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 6.0, 4.0, 0.0, 0.0, 2.0, 2.0, 1.0,
      2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10760148641170886
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03968601097740745
    mean_inference_ms: 2.0144005678987353
    mean_raw_obs_processing_ms: 0.45368886447573586
time_since_restore: 778.2271246910095
time_this_iter_s: 10.223242044448853
time_total_s: 778.2271246910095
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342366
timesteps_total: 572900
training_iteration: 76
trial_id: default
train step: 77
agent_timesteps_total: 580900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03195643424987793
  StateBufferConnector_ms: 0.005745887756347656
  ViewRequirementAgentConnector_ms: 0.19446587562561035
counters:
  num_agent_steps_sampled: 580900
  num_agent_steps_trained: 564000
  num_env_steps_sampled: 580900
  num_env_steps_trained: 564000
  num_samples_added_to_queue: 580500
  num_training_step_calls_since_last_synch_worker_weights: 139
  num_weight_broadcasts: 11368
custom_metrics: {}
date: 2023-08-18_16-06-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.69
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 4539
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2879869937896729
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -3.990370273590088
        total_loss: 10.321905136108398
        var_gnorm: 63.33597946166992
        vf_explained_var: 0.14502441883087158
        vf_loss: 29.912538528442383
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1128.0
  learner_queue:
    size_count: 1134
    size_mean: 14.62
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.730780170905595
  num_agent_steps_sampled: 580900
  num_agent_steps_trained: 564000
  num_env_steps_sampled: 580900
  num_env_steps_trained: 564000
  num_samples_added_to_queue: 580500
  num_training_step_calls_since_last_synch_worker_weights: 139
  num_weight_broadcasts: 11368
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 332.268
    learner_load_time_ms: 36.139
    learner_load_wait_time_ms: 2.712
iterations_since_restore: 77
node_ip: 127.0.0.1
num_agent_steps_sampled: 580900
num_agent_steps_trained: 564000
num_env_steps_sampled: 580900
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9952888766205
num_env_steps_trained: 564000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9952888766205
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 54.65714285714286
  ram_util_percent: 83.67142857142856
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10750718123294747
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039644814215279114
  mean_inference_ms: 2.012792314472095
  mean_raw_obs_processing_ms: 0.45333356633052296
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03195643424987793
    StateBufferConnector_ms: 0.005745887756347656
    ViewRequirementAgentConnector_ms: 0.19446587562561035
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.69
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0,
      2.0, 3.0, 5.0, 4.0, 1.0, 2.0, 3.0, 3.0, 2.0, 5.0, 6.0, 4.0, 0.0, 0.0, 2.0, 2.0,
      1.0, 2.0, 3.0, 4.0, 1.0, 1.0, 1.0, 1.0, 1.0, 3.0, 2.0, 3.0, 5.0, 3.0, 2.0, 2.0,
      4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 2.0, 3.0, 3.0, 4.0, 0.0, 7.0, 1.0, 3.0, 3.0, 4.0,
      1.0, 0.0, 3.0, 2.0, 5.0, 3.0, 3.0, 3.0, 0.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 4.0,
      2.0, 8.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 1.0, 4.0, 2.0, 2.0, 4.0, 2.0,
      2.0, 3.0, 6.0, 1.0, 2.0, 4.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10750718123294747
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039644814215279114
    mean_inference_ms: 2.012792314472095
    mean_raw_obs_processing_ms: 0.45333356633052296
time_since_restore: 788.4801766872406
time_this_iter_s: 10.253051996231079
time_total_s: 788.4801766872406
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342377
timesteps_total: 580900
training_iteration: 77
trial_id: default
train step: 78
agent_timesteps_total: 589200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031126976013183594
  StateBufferConnector_ms: 0.00572514533996582
  ViewRequirementAgentConnector_ms: 0.18927907943725586
counters:
  num_agent_steps_sampled: 589200
  num_agent_steps_trained: 572500
  num_env_steps_sampled: 589200
  num_env_steps_trained: 572500
  num_samples_added_to_queue: 589000
  num_training_step_calls_since_last_synch_worker_weights: 1374
  num_weight_broadcasts: 11531
custom_metrics: {}
date: 2023-08-18_16-06-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.58
episode_reward_min: 0.0
episodes_this_iter: 65
episodes_total: 4604
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2686817646026611
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -16.152515411376953
        total_loss: -7.177552700042725
        var_gnorm: 63.336185455322266
        vf_explained_var: 0.1904081106185913
        vf_loss: 19.21860694885254
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1145.0
  learner_queue:
    size_count: 1148
    size_mean: 14.54
    size_quantiles: [11.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.7799999999999998
  num_agent_steps_sampled: 589200
  num_agent_steps_trained: 572500
  num_env_steps_sampled: 589200
  num_env_steps_trained: 572500
  num_samples_added_to_queue: 589000
  num_training_step_calls_since_last_synch_worker_weights: 1374
  num_weight_broadcasts: 11531
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 496.926
    learner_load_time_ms: 47.685
    learner_load_wait_time_ms: 2.738
iterations_since_restore: 78
node_ip: 127.0.0.1
num_agent_steps_sampled: 589200
num_agent_steps_trained: 572500
num_env_steps_sampled: 589200
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9978430327203
num_env_steps_trained: 572500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9977910576051
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 49.419999999999995
  ram_util_percent: 83.3
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10739983990183351
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03957348686297231
  mean_inference_ms: 2.01039642074147
  mean_raw_obs_processing_ms: 0.45275718453632613
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031126976013183594
    StateBufferConnector_ms: 0.00572514533996582
    ViewRequirementAgentConnector_ms: 0.18927907943725586
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.58
  episode_reward_min: 0.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 3.0, 3.0, 3.0, 0.0, 2.0, 2.0, 3.0, 5.0, 2.0, 3.0, 4.0, 2.0,
      8.0, 2.0, 3.0, 2.0, 3.0, 3.0, 2.0, 5.0, 2.0, 1.0, 4.0, 2.0, 2.0, 4.0, 2.0, 2.0,
      3.0, 6.0, 1.0, 2.0, 4.0, 1.0, 1.0, 5.0, 1.0, 2.0, 0.0, 2.0, 3.0, 0.0, 2.0, 5.0,
      0.0, 4.0, 2.0, 4.0, 2.0, 4.0, 3.0, 4.0, 0.0, 4.0, 2.0, 4.0, 3.0, 1.0, 3.0, 1.0,
      1.0, 0.0, 5.0, 0.0, 1.0, 1.0, 3.0, 2.0, 3.0, 3.0, 1.0, 0.0, 2.0, 0.0, 2.0, 3.0,
      4.0, 0.0, 2.0, 5.0, 2.0, 6.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 6.0,
      2.0, 2.0, 7.0, 3.0, 2.0, 4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10739983990183351
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03957348686297231
    mean_inference_ms: 2.01039642074147
    mean_raw_obs_processing_ms: 0.45275718453632613
time_since_restore: 798.6291546821594
time_this_iter_s: 10.148977994918823
time_total_s: 798.6291546821594
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692342387
timesteps_total: 589200
training_iteration: 78
trial_id: default
train step: 79
agent_timesteps_total: 597700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03031182289123535
  StateBufferConnector_ms: 0.005471229553222656
  ViewRequirementAgentConnector_ms: 0.1822652816772461
counters:
  num_agent_steps_sampled: 597700
  num_agent_steps_trained: 581000
  num_env_steps_sampled: 597700
  num_env_steps_trained: 581000
  num_samples_added_to_queue: 597500
  num_training_step_calls_since_last_synch_worker_weights: 385
  num_weight_broadcasts: 11698
custom_metrics: {}
date: 2023-08-18_16-06-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.63
episode_reward_min: 0.0
episodes_this_iter: 66
episodes_total: 4670
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2739580869674683
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 1.203047513961792
        total_loss: 10.45239543914795
        var_gnorm: 63.33638000488281
        vf_explained_var: 0.2363753318786621
        vf_loss: 19.772653579711914
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1162.0
  learner_queue:
    size_count: 1168
    size_mean: 14.94
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5926079241294764
  num_agent_steps_sampled: 597700
  num_agent_steps_trained: 581000
  num_env_steps_sampled: 597700
  num_env_steps_trained: 581000
  num_samples_added_to_queue: 597500
  num_training_step_calls_since_last_synch_worker_weights: 385
  num_weight_broadcasts: 11698
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 285.866
    learner_load_time_ms: 47.234
    learner_load_wait_time_ms: 2.489
iterations_since_restore: 79
node_ip: 127.0.0.1
num_agent_steps_sampled: 597700
num_agent_steps_trained: 581000
num_env_steps_sampled: 597700
num_env_steps_sampled_this_iter: 8500
num_env_steps_sampled_throughput_per_sec: 849.9989056601308
num_env_steps_trained: 581000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9989056601308
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 44.142857142857146
  ram_util_percent: 82.11428571428573
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10725217793528027
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03948624512598911
  mean_inference_ms: 2.007284735015554
  mean_raw_obs_processing_ms: 0.45201742000550993
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03031182289123535
    StateBufferConnector_ms: 0.005471229553222656
    ViewRequirementAgentConnector_ms: 0.1822652816772461
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.63
  episode_reward_min: 0.0
  episodes_this_iter: 66
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 3.0, 2.0, 3.0, 3.0, 1.0, 0.0, 2.0, 0.0, 2.0, 3.0, 4.0, 0.0,
      2.0, 5.0, 2.0, 6.0, 1.0, 2.0, 1.0, 2.0, 2.0, 1.0, 2.0, 4.0, 1.0, 6.0, 2.0, 2.0,
      7.0, 3.0, 2.0, 4.0, 7.0, 3.0, 5.0, 3.0, 3.0, 4.0, 1.0, 1.0, 6.0, 3.0, 3.0, 2.0,
      1.0, 3.0, 2.0, 0.0, 3.0, 4.0, 2.0, 3.0, 1.0, 4.0, 5.0, 3.0, 6.0, 2.0, 2.0, 3.0,
      3.0, 2.0, 5.0, 2.0, 5.0, 0.0, 3.0, 0.0, 6.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0,
      2.0, 4.0, 1.0, 3.0, 2.0, 3.0, 0.0, 5.0, 4.0, 1.0, 1.0, 0.0, 4.0, 1.0, 3.0, 3.0,
      3.0, 5.0, 3.0, 3.0, 1.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10725217793528027
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03948624512598911
    mean_inference_ms: 2.007284735015554
    mean_raw_obs_processing_ms: 0.45201742000550993
time_since_restore: 808.8430914878845
time_this_iter_s: 10.213936805725098
time_total_s: 808.8430914878845
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692342397
timesteps_total: 597700
training_iteration: 79
trial_id: default
train step: 80
agent_timesteps_total: 605950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030462980270385742
  StateBufferConnector_ms: 0.00554966926574707
  ViewRequirementAgentConnector_ms: 0.1828312873840332
counters:
  num_agent_steps_sampled: 605950
  num_agent_steps_trained: 589000
  num_env_steps_sampled: 605950
  num_env_steps_trained: 589000
  num_samples_added_to_queue: 605500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 11860
custom_metrics: {}
date: 2023-08-18_16-06-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.59
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 4734
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2744675874710083
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -29.923778533935547
        total_loss: -20.05674171447754
        var_gnorm: 63.33650588989258
        vf_explained_var: 0.1735532283782959
        vf_loss: 21.008541107177734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1178.0
  learner_queue:
    size_count: 1184
    size_mean: 14.96
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5869467539901896
  num_agent_steps_sampled: 605950
  num_agent_steps_trained: 589000
  num_env_steps_sampled: 605950
  num_env_steps_trained: 589000
  num_samples_added_to_queue: 605500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 11860
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 330.405
    learner_load_time_ms: 34.112
    learner_load_wait_time_ms: 2.701
iterations_since_restore: 80
node_ip: 127.0.0.1
num_agent_steps_sampled: 605950
num_agent_steps_trained: 589000
num_env_steps_sampled: 605950
num_env_steps_sampled_this_iter: 8250
num_env_steps_sampled_throughput_per_sec: 824.7636989266872
num_env_steps_trained: 589000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.7708595652724
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.37857142857143
  ram_util_percent: 81.71428571428571
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10710671760908365
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03941778125495858
  mean_inference_ms: 2.0048462934354334
  mean_raw_obs_processing_ms: 0.4514560177247356
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030462980270385742
    StateBufferConnector_ms: 0.00554966926574707
    ViewRequirementAgentConnector_ms: 0.1828312873840332
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.59
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 5.0, 0.0, 3.0, 0.0, 6.0, 3.0, 2.0, 1.0, 2.0, 2.0, 6.0, 1.0,
      2.0, 4.0, 1.0, 3.0, 2.0, 3.0, 0.0, 5.0, 4.0, 1.0, 1.0, 0.0, 4.0, 1.0, 3.0, 3.0,
      3.0, 5.0, 3.0, 3.0, 1.0, 1.0, 1.0, 5.0, 2.0, 4.0, 0.0, 1.0, 5.0, 3.0, 4.0, 4.0,
      3.0, 2.0, 4.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 0.0, 3.0, 2.0, 3.0, 6.0, 1.0,
      3.0, 3.0, 2.0, 1.0, 2.0, 0.0, 1.0, 2.0, 4.0, 1.0, 6.0, 4.0, 5.0, 1.0, 4.0, 5.0,
      6.0, 6.0, 1.0, 5.0, 4.0, 2.0, 2.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 6.0, 3.0, 2.0,
      0.0, 4.0, 3.0, 2.0, 2.0, 0.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10710671760908365
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03941778125495858
    mean_inference_ms: 2.0048462934354334
    mean_raw_obs_processing_ms: 0.4514560177247356
time_since_restore: 819.0673186779022
time_this_iter_s: 10.2242271900177
time_total_s: 819.0673186779022
timers:
  sample_time_ms: 0.114
  synch_weights_time_ms: 0.61
  training_iteration_time_ms: 0.862
timestamp: 1692342407
timesteps_total: 605950
training_iteration: 80
trial_id: default
train step: 81
agent_timesteps_total: 614150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030280113220214844
  StateBufferConnector_ms: 0.005627870559692383
  ViewRequirementAgentConnector_ms: 0.18397140502929688
counters:
  num_agent_steps_sampled: 614150
  num_agent_steps_trained: 597500
  num_env_steps_sampled: 614150
  num_env_steps_trained: 597500
  num_samples_added_to_queue: 614000
  num_training_step_calls_since_last_synch_worker_weights: 931
  num_weight_broadcasts: 12021
custom_metrics: {}
date: 2023-08-18_16-06-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.78
episode_reward_min: 0.0
episodes_this_iter: 65
episodes_total: 4799
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2813606262207031
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -4.660098552703857
        total_loss: 6.316617488861084
        var_gnorm: 63.33671569824219
        vf_explained_var: 0.2014670968055725
        vf_loss: 23.234792709350586
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1195.0
  learner_queue:
    size_count: 1199
    size_mean: 15.08
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4538225476309
  num_agent_steps_sampled: 614150
  num_agent_steps_trained: 597500
  num_env_steps_sampled: 614150
  num_env_steps_trained: 597500
  num_samples_added_to_queue: 614000
  num_training_step_calls_since_last_synch_worker_weights: 931
  num_weight_broadcasts: 12021
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 404.51
    learner_load_time_ms: 34.112
    learner_load_wait_time_ms: 2.941
iterations_since_restore: 81
node_ip: 127.0.0.1
num_agent_steps_sampled: 614150
num_agent_steps_trained: 597500
num_env_steps_sampled: 614150
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9972043132731
num_env_steps_trained: 597500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9971020320513
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 49.140000000000015
  ram_util_percent: 80.92666666666668
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10697003332915475
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03935415825134263
  mean_inference_ms: 2.0026921677412703
  mean_raw_obs_processing_ms: 0.4509205673427519
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030280113220214844
    StateBufferConnector_ms: 0.005627870559692383
    ViewRequirementAgentConnector_ms: 0.18397140502929688
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.78
  episode_reward_min: 0.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 0.0, 1.0, 2.0, 4.0, 1.0, 6.0, 4.0, 5.0, 1.0, 4.0, 5.0, 6.0,
      6.0, 1.0, 5.0, 4.0, 2.0, 2.0, 3.0, 1.0, 0.0, 2.0, 1.0, 2.0, 6.0, 3.0, 2.0, 0.0,
      4.0, 3.0, 2.0, 2.0, 0.0, 2.0, 5.0, 4.0, 0.0, 4.0, 2.0, 1.0, 3.0, 0.0, 2.0, 2.0,
      1.0, 3.0, 4.0, 1.0, 3.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 0.0, 4.0, 1.0, 6.0, 2.0,
      2.0, 1.0, 8.0, 1.0, 4.0, 1.0, 5.0, 2.0, 3.0, 4.0, 2.0, 3.0, 6.0, 0.0, 2.0, 6.0,
      2.0, 1.0, 5.0, 5.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 6.0, 3.0, 7.0, 5.0, 2.0, 3.0,
      0.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10697003332915475
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03935415825134263
    mean_inference_ms: 2.0026921677412703
    mean_raw_obs_processing_ms: 0.4509205673427519
time_since_restore: 829.2396266460419
time_this_iter_s: 10.172307968139648
time_total_s: 829.2396266460419
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.072
timestamp: 1692342417
timesteps_total: 614150
training_iteration: 81
trial_id: default
train step: 82
agent_timesteps_total: 622100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03176259994506836
  StateBufferConnector_ms: 0.005753278732299805
  ViewRequirementAgentConnector_ms: 0.19349288940429688
counters:
  num_agent_steps_sampled: 622100
  num_agent_steps_trained: 605500
  num_env_steps_sampled: 622100
  num_env_steps_trained: 605500
  num_samples_added_to_queue: 622000
  num_training_step_calls_since_last_synch_worker_weights: 374
  num_weight_broadcasts: 12177
custom_metrics: {}
date: 2023-08-18_16-07-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.74
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 4861
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2707405090332031
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -73.63675689697266
        total_loss: -66.16352844238281
        var_gnorm: 63.336910247802734
        vf_explained_var: 0.12249982357025146
        vf_loss: 16.217199325561523
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1211.0
  learner_queue:
    size_count: 1217
    size_mean: 14.92
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.572768260107
  num_agent_steps_sampled: 622100
  num_agent_steps_trained: 605500
  num_env_steps_sampled: 622100
  num_env_steps_trained: 605500
  num_samples_added_to_queue: 622000
  num_training_step_calls_since_last_synch_worker_weights: 374
  num_weight_broadcasts: 12177
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 285.675
    learner_load_time_ms: 23.739
    learner_load_wait_time_ms: 2.871
iterations_since_restore: 82
node_ip: 127.0.0.1
num_agent_steps_sampled: 622100
num_agent_steps_trained: 605500
num_env_steps_sampled: 622100
num_env_steps_sampled_this_iter: 7950
num_env_steps_sampled_throughput_per_sec: 794.9956215861181
num_env_steps_trained: 605500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9955940489239
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.38571428571429
  ram_util_percent: 81.39999999999999
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1068570284436675
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039323686267042385
  mean_inference_ms: 2.0012212863707317
  mean_raw_obs_processing_ms: 0.4506660909355456
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03176259994506836
    StateBufferConnector_ms: 0.005753278732299805
    ViewRequirementAgentConnector_ms: 0.19349288940429688
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.74
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 8.0, 1.0, 4.0, 1.0, 5.0, 2.0, 3.0, 4.0, 2.0, 3.0, 6.0, 0.0,
      2.0, 6.0, 2.0, 1.0, 5.0, 5.0, 2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 6.0, 3.0, 7.0, 5.0,
      2.0, 3.0, 0.0, 3.0, 5.0, 3.0, 3.0, 3.0, 2.0, 1.0, 1.0, 3.0, 2.0, 2.0, 1.0, 1.0,
      3.0, 2.0, 3.0, 3.0, 3.0, 4.0, 1.0, 3.0, 6.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 1.0,
      4.0, 1.0, 2.0, 1.0, 6.0, 2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 9.0, 2.0, 3.0, 4.0,
      2.0, 2.0, 3.0, 0.0, 2.0, 3.0, 2.0, 5.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0, 2.0,
      1.0, 2.0, 2.0, 2.0, 4.0, 2.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1068570284436675
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039323686267042385
    mean_inference_ms: 2.0012212863707317
    mean_raw_obs_processing_ms: 0.4506660909355456
time_since_restore: 839.5431747436523
time_this_iter_s: 10.303548097610474
time_total_s: 839.5431747436523
timers:
  sample_time_ms: 0.037
  synch_weights_time_ms: 0.01
  training_iteration_time_ms: 0.102
timestamp: 1692342428
timesteps_total: 622100
training_iteration: 82
trial_id: default
train step: 83
agent_timesteps_total: 629000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03471112251281738
  StateBufferConnector_ms: 0.006404876708984375
  ViewRequirementAgentConnector_ms: 0.21549725532531738
counters:
  num_agent_steps_sampled: 629000
  num_agent_steps_trained: 612500
  num_env_steps_sampled: 629000
  num_env_steps_trained: 612500
  num_samples_added_to_queue: 629000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 12312
custom_metrics: {}
date: 2023-08-18_16-07-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.42
episode_reward_min: 0.0
episodes_this_iter: 53
episodes_total: 4914
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2506887912750244
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 36.732948303222656
        total_loss: 50.54303741455078
        var_gnorm: 63.33710861206055
        vf_explained_var: 0.2025788426399231
        vf_loss: 28.870868682861328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1225.0
  learner_queue:
    size_count: 1230
    size_mean: 14.62
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7422973339817749
  num_agent_steps_sampled: 629000
  num_agent_steps_trained: 612500
  num_env_steps_sampled: 629000
  num_env_steps_trained: 612500
  num_samples_added_to_queue: 629000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 12312
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 642.623
    learner_load_time_ms: 23.739
    learner_load_wait_time_ms: 3.192
iterations_since_restore: 83
node_ip: 127.0.0.1
num_agent_steps_sampled: 629000
num_agent_steps_trained: 612500
num_env_steps_sampled: 629000
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 688.7937786142113
num_env_steps_trained: 612500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 698.776297144852
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 56.446666666666665
  ram_util_percent: 82.73333333333333
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1067328873476025
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03940130742025524
  mean_inference_ms: 2.0023996678848777
  mean_raw_obs_processing_ms: 0.4512187889320471
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03471112251281738
    StateBufferConnector_ms: 0.006404876708984375
    ViewRequirementAgentConnector_ms: 0.21549725532531738
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.42
  episode_reward_min: 0.0
  episodes_this_iter: 53
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 2.0, 3.0, 3.0, 2.0, 0.0, 2.0, 1.0, 4.0, 1.0, 2.0, 1.0, 6.0,
      2.0, 1.0, 2.0, 1.0, 3.0, 3.0, 2.0, 9.0, 2.0, 3.0, 4.0, 2.0, 2.0, 3.0, 0.0, 2.0,
      3.0, 2.0, 5.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0, 2.0, 1.0, 2.0, 2.0, 2.0, 4.0,
      2.0, 5.0, 2.0, 3.0, 1.0, 5.0, 1.0, 1.0, 0.0, 3.0, 4.0, 1.0, 3.0, 4.0, 2.0, 3.0,
      1.0, 3.0, 2.0, 3.0, 3.0, 5.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 2.0, 3.0, 6.0, 0.0,
      0.0, 3.0, 1.0, 5.0, 2.0, 3.0, 1.0, 1.0, 1.0, 5.0, 2.0, 2.0, 1.0, 1.0, 5.0, 1.0,
      1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1067328873476025
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03940130742025524
    mean_inference_ms: 2.0023996678848777
    mean_raw_obs_processing_ms: 0.4512187889320471
time_since_restore: 849.7658169269562
time_this_iter_s: 10.222642183303833
time_total_s: 849.7658169269562
timers:
  sample_time_ms: 0.059
  synch_weights_time_ms: 0.937
  training_iteration_time_ms: 3.418
timestamp: 1692342438
timesteps_total: 629000
training_iteration: 83
trial_id: default
train step: 84
agent_timesteps_total: 637000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03308820724487305
  StateBufferConnector_ms: 0.0061283111572265625
  ViewRequirementAgentConnector_ms: 0.20412540435791016
counters:
  num_agent_steps_sampled: 637000
  num_agent_steps_trained: 620500
  num_env_steps_sampled: 637000
  num_env_steps_trained: 620500
  num_samples_added_to_queue: 637000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 12469
custom_metrics: {}
date: 2023-08-18_16-07-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.67
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 4977
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2557965517044067
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -31.49609375
        total_loss: -22.585222244262695
        var_gnorm: 63.33734130859375
        vf_explained_var: 0.19375723600387573
        vf_loss: 19.07754135131836
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1241.0
  learner_queue:
    size_count: 1243
    size_mean: 14.8
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.697056274847714
  num_agent_steps_sampled: 637000
  num_agent_steps_trained: 620500
  num_env_steps_sampled: 637000
  num_env_steps_trained: 620500
  num_samples_added_to_queue: 637000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 12469
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 619.538
    learner_load_time_ms: 22.773
    learner_load_wait_time_ms: 3.594
iterations_since_restore: 84
node_ip: 127.0.0.1
num_agent_steps_sampled: 637000
num_agent_steps_trained: 620500
num_env_steps_sampled: 637000
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9981689495035
num_env_steps_trained: 620500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9981689495035
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.95714285714286
  ram_util_percent: 82.45
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10673246954907256
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039405065723286975
  mean_inference_ms: 2.0025081777399563
  mean_raw_obs_processing_ms: 0.4512232034940732
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03308820724487305
    StateBufferConnector_ms: 0.0061283111572265625
    ViewRequirementAgentConnector_ms: 0.20412540435791016
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.67
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 3.0, 5.0, 3.0, 4.0, 3.0, 3.0, 1.0, 0.0, 2.0, 3.0, 6.0,
      0.0, 0.0, 3.0, 1.0, 5.0, 2.0, 3.0, 1.0, 1.0, 1.0, 5.0, 2.0, 2.0, 1.0, 1.0, 5.0,
      1.0, 1.0, 2.0, 1.0, 2.0, 0.0, 2.0, 3.0, 6.0, 2.0, 1.0, 3.0, 6.0, 3.0, 4.0, 5.0,
      2.0, 4.0, 2.0, 1.0, 1.0, 6.0, 5.0, 3.0, 3.0, 1.0, 5.0, 1.0, 5.0, 8.0, 2.0, 4.0,
      0.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 5.0, 2.0, 2.0, 4.0, 6.0,
      1.0, 1.0, 4.0, 6.0, 5.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0, 2.0,
      3.0, 5.0, 4.0, 0.0, 2.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10673246954907256
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039405065723286975
    mean_inference_ms: 2.0025081777399563
    mean_raw_obs_processing_ms: 0.4512232034940732
time_since_restore: 859.870995759964
time_this_iter_s: 10.105178833007812
time_total_s: 859.870995759964
timers:
  sample_time_ms: 0.11
  synch_weights_time_ms: 0.939
  training_iteration_time_ms: 3.404
timestamp: 1692342448
timesteps_total: 637000
training_iteration: 84
trial_id: default
train step: 85
agent_timesteps_total: 645100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031764984130859375
  StateBufferConnector_ms: 0.005780458450317383
  ViewRequirementAgentConnector_ms: 0.1935722827911377
counters:
  num_agent_steps_sampled: 645100
  num_agent_steps_trained: 628500
  num_env_steps_sampled: 645100
  num_env_steps_trained: 628500
  num_samples_added_to_queue: 645000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 12629
custom_metrics: {}
date: 2023-08-18_16-07-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.68
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 5040
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2542877197265625
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -20.738313674926758
        total_loss: -13.137694358825684
        var_gnorm: 63.33756637573242
        vf_explained_var: 0.21445685625076294
        vf_loss: 16.45552635192871
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1257.0
  learner_queue:
    size_count: 1263
    size_mean: 14.68
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8048822676285565
  num_agent_steps_sampled: 645100
  num_agent_steps_trained: 628500
  num_env_steps_sampled: 645100
  num_env_steps_trained: 628500
  num_samples_added_to_queue: 645000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 12629
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 291.352
    learner_load_time_ms: 14.957
    learner_load_wait_time_ms: 2.869
iterations_since_restore: 85
node_ip: 127.0.0.1
num_agent_steps_sampled: 645100
num_agent_steps_trained: 628500
num_env_steps_sampled: 645100
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.646263890605
num_env_steps_trained: 628500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.6506310030668
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 48.135714285714286
  ram_util_percent: 82.22142857142856
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10677154297271786
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039319868413341216
  mean_inference_ms: 2.00058940423618
  mean_raw_obs_processing_ms: 0.4505556790701057
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031764984130859375
    StateBufferConnector_ms: 0.005780458450317383
    ViewRequirementAgentConnector_ms: 0.1935722827911377
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.68
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 5.0, 2.0, 2.0, 4.0,
      6.0, 1.0, 1.0, 4.0, 6.0, 5.0, 3.0, 2.0, 1.0, 2.0, 3.0, 2.0, 2.0, 1.0, 3.0, 1.0,
      2.0, 3.0, 5.0, 4.0, 0.0, 2.0, 3.0, 2.0, 1.0, 1.0, 5.0, 1.0, 4.0, 1.0, 2.0, 2.0,
      5.0, 4.0, 4.0, 1.0, 1.0, 6.0, 3.0, 4.0, 1.0, 2.0, 3.0, 2.0, 2.0, 4.0, 3.0, 5.0,
      4.0, 3.0, 1.0, 1.0, 2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 6.0, 1.0, 1.0, 2.0, 2.0, 3.0,
      5.0, 2.0, 5.0, 2.0, 5.0, 2.0, 4.0, 1.0, 2.0, 5.0, 1.0, 3.0, 5.0, 3.0, 0.0, 0.0,
      3.0, 1.0, 3.0, 2.0, 2.0, 5.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10677154297271786
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039319868413341216
    mean_inference_ms: 2.00058940423618
    mean_raw_obs_processing_ms: 0.4505556790701057
time_since_restore: 870.1058247089386
time_this_iter_s: 10.23482894897461
time_total_s: 870.1058247089386
timers:
  sample_time_ms: 0.054
  synch_weights_time_ms: 0.366
  training_iteration_time_ms: 0.534
timestamp: 1692342458
timesteps_total: 645100
training_iteration: 85
trial_id: default
train step: 86
agent_timesteps_total: 653350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030696392059326172
  StateBufferConnector_ms: 0.005602598190307617
  ViewRequirementAgentConnector_ms: 0.1882777214050293
counters:
  num_agent_steps_sampled: 653350
  num_agent_steps_trained: 636500
  num_env_steps_sampled: 653350
  num_env_steps_trained: 636500
  num_samples_added_to_queue: 653000
  num_training_step_calls_since_last_synch_worker_weights: 706
  num_weight_broadcasts: 12792
custom_metrics: {}
date: 2023-08-18_16-07-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.58
episode_reward_min: 0.0
episodes_this_iter: 65
episodes_total: 5105
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2585911750793457
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -8.263651847839355
        total_loss: 1.1823041439056396
        var_gnorm: 63.33772659301758
        vf_explained_var: 0.2252286672592163
        vf_loss: 20.150503158569336
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1273.0
  learner_queue:
    size_count: 1278
    size_mean: 14.96
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5615377036754508
  num_agent_steps_sampled: 653350
  num_agent_steps_trained: 636500
  num_env_steps_sampled: 653350
  num_env_steps_trained: 636500
  num_samples_added_to_queue: 653000
  num_training_step_calls_since_last_synch_worker_weights: 706
  num_weight_broadcasts: 12792
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 373.414
    learner_load_time_ms: 14.949
    learner_load_wait_time_ms: 2.696
iterations_since_restore: 86
node_ip: 127.0.0.1
num_agent_steps_sampled: 653350
num_agent_steps_trained: 636500
num_env_steps_sampled: 653350
num_env_steps_sampled_this_iter: 8250
num_env_steps_sampled_throughput_per_sec: 824.9979543736636
num_env_steps_trained: 636500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9980163623404
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 49.773333333333326
  ram_util_percent: 81.89333333333335
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10668146285778338
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039259887787798965
  mean_inference_ms: 1.9984805773354941
  mean_raw_obs_processing_ms: 0.45009485733510024
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030696392059326172
    StateBufferConnector_ms: 0.005602598190307617
    ViewRequirementAgentConnector_ms: 0.1882777214050293
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.58
  episode_reward_min: 0.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 2.0, 3.0, 4.0, 4.0, 6.0, 1.0, 1.0, 2.0, 2.0, 3.0, 5.0,
      2.0, 5.0, 2.0, 5.0, 2.0, 4.0, 1.0, 2.0, 5.0, 1.0, 3.0, 5.0, 3.0, 0.0, 0.0, 3.0,
      1.0, 3.0, 2.0, 2.0, 5.0, 0.0, 3.0, 4.0, 0.0, 0.0, 3.0, 1.0, 1.0, 2.0, 1.0, 4.0,
      4.0, 1.0, 0.0, 2.0, 2.0, 1.0, 4.0, 2.0, 5.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 5.0,
      2.0, 1.0, 3.0, 3.0, 1.0, 5.0, 4.0, 1.0, 0.0, 6.0, 1.0, 4.0, 3.0, 4.0, 3.0, 2.0,
      0.0, 1.0, 5.0, 7.0, 3.0, 1.0, 3.0, 1.0, 8.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0,
      2.0, 0.0, 4.0, 3.0, 5.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10668146285778338
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039259887787798965
    mean_inference_ms: 1.9984805773354941
    mean_raw_obs_processing_ms: 0.45009485733510024
time_since_restore: 880.3399686813354
time_this_iter_s: 10.23414397239685
time_total_s: 880.3399686813354
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692342469
timesteps_total: 653350
training_iteration: 86
trial_id: default
train step: 87
agent_timesteps_total: 660550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.032820940017700195
  StateBufferConnector_ms: 0.006041765213012695
  ViewRequirementAgentConnector_ms: 0.19976329803466797
counters:
  num_agent_steps_sampled: 660550
  num_agent_steps_trained: 644000
  num_env_steps_sampled: 660550
  num_env_steps_trained: 644000
  num_samples_added_to_queue: 660500
  num_training_step_calls_since_last_synch_worker_weights: 1052
  num_weight_broadcasts: 12933
custom_metrics: {}
date: 2023-08-18_16-07-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.63
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 5161
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.225825309753418
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -12.477036476135254
        total_loss: -4.529689311981201
        var_gnorm: 63.338035583496094
        vf_explained_var: 0.29151540994644165
        vf_loss: 17.120519638061523
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1288.0
  learner_queue:
    size_count: 1292
    size_mean: 15.04
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4416657032752078
  num_agent_steps_sampled: 660550
  num_agent_steps_trained: 644000
  num_env_steps_sampled: 660550
  num_env_steps_trained: 644000
  num_samples_added_to_queue: 660500
  num_training_step_calls_since_last_synch_worker_weights: 1052
  num_weight_broadcasts: 12933
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 472.883
    learner_load_time_ms: 15.424
    learner_load_wait_time_ms: 3.114
iterations_since_restore: 87
node_ip: 127.0.0.1
num_agent_steps_sampled: 660550
num_agent_steps_trained: 644000
num_env_steps_sampled: 660550
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 719.9933910976512
num_env_steps_trained: 644000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.99311572672
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.314285714285724
  ram_util_percent: 82.65714285714284
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10656982215653826
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03929478736783781
  mean_inference_ms: 1.9986115587795568
  mean_raw_obs_processing_ms: 0.45032285049423576
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.032820940017700195
    StateBufferConnector_ms: 0.006041765213012695
    ViewRequirementAgentConnector_ms: 0.19976329803466797
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.63
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 3.0, 4.0, 5.0, 2.0, 1.0, 3.0, 3.0, 1.0, 5.0, 4.0, 1.0,
      0.0, 6.0, 1.0, 4.0, 3.0, 4.0, 3.0, 2.0, 0.0, 1.0, 5.0, 7.0, 3.0, 1.0, 3.0, 1.0,
      8.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 1.0, 2.0, 0.0, 4.0, 3.0, 5.0, 3.0, 2.0, 7.0,
      1.0, 4.0, 4.0, 1.0, 1.0, 3.0, 7.0, 3.0, 3.0, 4.0, 3.0, 2.0, 5.0, 1.0, 1.0, 2.0,
      6.0, 1.0, 1.0, 3.0, 5.0, 4.0, 3.0, 2.0, 1.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 4.0,
      3.0, 5.0, 1.0, 2.0, 2.0, 2.0, 4.0, 5.0, 2.0, 3.0, 2.0, 1.0, 1.0, 3.0, 0.0, 2.0,
      1.0, 2.0, 1.0, 1.0, 2.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10656982215653826
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03929478736783781
    mean_inference_ms: 1.9986115587795568
    mean_raw_obs_processing_ms: 0.45032285049423576
time_since_restore: 890.5161185264587
time_this_iter_s: 10.176149845123291
time_total_s: 890.5161185264587
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692342479
timesteps_total: 660550
training_iteration: 87
trial_id: default
train step: 88
agent_timesteps_total: 667050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03762006759643555
  StateBufferConnector_ms: 0.00689387321472168
  ViewRequirementAgentConnector_ms: 0.225205659866333
counters:
  num_agent_steps_sampled: 667050
  num_agent_steps_trained: 650500
  num_env_steps_sampled: 667050
  num_env_steps_trained: 650500
  num_samples_added_to_queue: 667000
  num_training_step_calls_since_last_synch_worker_weights: 268
  num_weight_broadcasts: 13060
custom_metrics: {}
date: 2023-08-18_16-08-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.67
episode_reward_min: 0.0
episodes_this_iter: 51
episodes_total: 5212
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2739050388336182
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 9.107461929321289
        total_loss: 18.895647048950195
        var_gnorm: 63.33818435668945
        vf_explained_var: 0.23574966192245483
        vf_loss: 20.850278854370117
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1301.0
  learner_queue:
    size_count: 1306
    size_mean: 14.86
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5100993344810136
  num_agent_steps_sampled: 667050
  num_agent_steps_trained: 650500
  num_env_steps_sampled: 667050
  num_env_steps_trained: 650500
  num_samples_added_to_queue: 667000
  num_training_step_calls_since_last_synch_worker_weights: 268
  num_weight_broadcasts: 13060
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 392.249
    learner_load_time_ms: 3.881
    learner_load_wait_time_ms: 2.772
iterations_since_restore: 88
node_ip: 127.0.0.1
num_agent_steps_sampled: 667050
num_agent_steps_trained: 650500
num_env_steps_sampled: 667050
num_env_steps_sampled_this_iter: 6500
num_env_steps_sampled_throughput_per_sec: 649.9959087629339
num_env_steps_trained: 650500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9959087629339
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 57.57142857142858
  ram_util_percent: 83.75714285714285
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10653230598422954
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0394082394835434
  mean_inference_ms: 2.0011393173770053
  mean_raw_obs_processing_ms: 0.45118120575000986
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03762006759643555
    StateBufferConnector_ms: 0.00689387321472168
    ViewRequirementAgentConnector_ms: 0.225205659866333
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.67
  episode_reward_min: 0.0
  episodes_this_iter: 51
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 3.0, 3.0, 4.0, 3.0, 2.0, 5.0, 1.0, 1.0, 2.0, 6.0, 1.0, 1.0,
      3.0, 5.0, 4.0, 3.0, 2.0, 1.0, 4.0, 3.0, 1.0, 1.0, 2.0, 1.0, 4.0, 3.0, 5.0, 1.0,
      2.0, 2.0, 2.0, 4.0, 5.0, 2.0, 3.0, 2.0, 1.0, 1.0, 3.0, 0.0, 2.0, 1.0, 2.0, 1.0,
      1.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 3.0, 1.0, 2.0, 2.0, 3.0, 2.0, 5.0, 4.0, 4.0,
      4.0, 5.0, 3.0, 2.0, 5.0, 6.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0, 1.0, 3.0, 2.0,
      5.0, 2.0, 3.0, 5.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0, 3.0, 3.0, 2.0,
      6.0, 3.0, 4.0, 4.0, 0.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10653230598422954
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0394082394835434
    mean_inference_ms: 2.0011393173770053
    mean_raw_obs_processing_ms: 0.45118120575000986
time_since_restore: 900.7278378009796
time_this_iter_s: 10.211719274520874
time_total_s: 900.7278378009796
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342489
timesteps_total: 667050
training_iteration: 88
trial_id: default
train step: 89
agent_timesteps_total: 674950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03547477722167969
  StateBufferConnector_ms: 0.006409645080566406
  ViewRequirementAgentConnector_ms: 0.21417665481567383
counters:
  num_agent_steps_sampled: 674950
  num_agent_steps_trained: 658000
  num_env_steps_sampled: 674950
  num_env_steps_trained: 658000
  num_samples_added_to_queue: 674500
  num_training_step_calls_since_last_synch_worker_weights: 26
  num_weight_broadcasts: 13215
custom_metrics: {}
date: 2023-08-18_16-08-19
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.76
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 5273
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2386428117752075
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -45.599613189697266
        total_loss: -39.53059387207031
        var_gnorm: 63.338417053222656
        vf_explained_var: 0.1644938588142395
        vf_loss: 13.376681327819824
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1316.0
  learner_queue:
    size_count: 1323
    size_mean: 14.74
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6469365500832145
  num_agent_steps_sampled: 674950
  num_agent_steps_trained: 658000
  num_env_steps_sampled: 674950
  num_env_steps_trained: 658000
  num_samples_added_to_queue: 674500
  num_training_step_calls_since_last_synch_worker_weights: 26
  num_weight_broadcasts: 13215
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 291.272
    learner_load_time_ms: 3.919
    learner_load_wait_time_ms: 2.73
iterations_since_restore: 89
node_ip: 127.0.0.1
num_agent_steps_sampled: 674950
num_agent_steps_trained: 658000
num_env_steps_sampled: 674950
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.9943118504958
num_env_steps_trained: 658000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9945998580657
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 45.606666666666676
  ram_util_percent: 83.20666666666666
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10663791936044437
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03941942154118822
  mean_inference_ms: 2.0020956890616075
  mean_raw_obs_processing_ms: 0.45128314996542895
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03547477722167969
    StateBufferConnector_ms: 0.006409645080566406
    ViewRequirementAgentConnector_ms: 0.21417665481567383
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.76
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 3.0, 2.0, 5.0, 6.0, 1.0, 1.0, 3.0, 1.0, 3.0, 3.0, 3.0,
      1.0, 3.0, 2.0, 5.0, 2.0, 3.0, 5.0, 0.0, 1.0, 2.0, 0.0, 2.0, 3.0, 2.0, 2.0, 2.0,
      3.0, 3.0, 2.0, 6.0, 3.0, 4.0, 4.0, 0.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0,
      2.0, 2.0, 2.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 5.0, 4.0, 7.0, 3.0, 0.0, 1.0, 4.0,
      1.0, 2.0, 3.0, 1.0, 6.0, 2.0, 3.0, 5.0, 3.0, 1.0, 2.0, 2.0, 3.0, 3.0, 3.0, 2.0,
      1.0, 5.0, 3.0, 4.0, 2.0, 4.0, 1.0, 1.0, 1.0, 4.0, 6.0, 1.0, 3.0, 2.0, 5.0, 0.0,
      5.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10663791936044437
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03941942154118822
    mean_inference_ms: 2.0020956890616075
    mean_raw_obs_processing_ms: 0.45128314996542895
time_since_restore: 911.0001878738403
time_this_iter_s: 10.272350072860718
time_total_s: 911.0001878738403
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.082
timestamp: 1692342499
timesteps_total: 674950
training_iteration: 89
trial_id: default
train step: 90
agent_timesteps_total: 682650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0334320068359375
  StateBufferConnector_ms: 0.006099224090576172
  ViewRequirementAgentConnector_ms: 0.20458269119262695
counters:
  num_agent_steps_sampled: 682650
  num_agent_steps_trained: 666000
  num_env_steps_sampled: 682650
  num_env_steps_trained: 666000
  num_samples_added_to_queue: 682500
  num_training_step_calls_since_last_synch_worker_weights: 195
  num_weight_broadcasts: 13365
custom_metrics: {}
date: 2023-08-18_16-08-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.84
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 5334
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.267993688583374
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -47.44359588623047
        total_loss: -39.31819152832031
        var_gnorm: 63.338661193847656
        vf_explained_var: 0.1597117781639099
        vf_loss: 17.518796920776367
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1332.0
  learner_queue:
    size_count: 1338
    size_mean: 14.6
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.7204650534085253
  num_agent_steps_sampled: 682650
  num_agent_steps_trained: 666000
  num_env_steps_sampled: 682650
  num_env_steps_trained: 666000
  num_samples_added_to_queue: 682500
  num_training_step_calls_since_last_synch_worker_weights: 195
  num_weight_broadcasts: 13365
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 300.091
    learner_load_time_ms: 3.943
    learner_load_wait_time_ms: 2.909
iterations_since_restore: 90
node_ip: 127.0.0.1
num_agent_steps_sampled: 682650
num_agent_steps_trained: 666000
num_env_steps_sampled: 682650
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 769.9970626943104
num_env_steps_trained: 666000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.996948253829
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.67142857142858
  ram_util_percent: 83.45
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10674202892519798
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039361546017918546
  mean_inference_ms: 2.0013797143550414
  mean_raw_obs_processing_ms: 0.45086610755031103
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0334320068359375
    StateBufferConnector_ms: 0.006099224090576172
    ViewRequirementAgentConnector_ms: 0.20458269119262695
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.84
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 3.0, 1.0, 6.0, 2.0, 3.0, 5.0, 3.0, 1.0, 2.0, 2.0, 3.0,
      3.0, 3.0, 2.0, 1.0, 5.0, 3.0, 4.0, 2.0, 4.0, 1.0, 1.0, 1.0, 4.0, 6.0, 1.0, 3.0,
      2.0, 5.0, 0.0, 5.0, 2.0, 3.0, 2.0, 3.0, 5.0, 3.0, 4.0, 1.0, 4.0, 3.0, 6.0, 1.0,
      1.0, 3.0, 1.0, 0.0, 1.0, 5.0, 2.0, 4.0, 8.0, 5.0, 2.0, 4.0, 1.0, 3.0, 4.0, 2.0,
      3.0, 2.0, 0.0, 3.0, 6.0, 5.0, 3.0, 2.0, 3.0, 2.0, 5.0, 4.0, 3.0, 4.0, 4.0, 1.0,
      3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 5.0, 6.0, 5.0, 2.0, 3.0, 2.0, 5.0, 2.0, 3.0, 1.0,
      2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10674202892519798
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039361546017918546
    mean_inference_ms: 2.0013797143550414
    mean_raw_obs_processing_ms: 0.45086610755031103
time_since_restore: 921.2995488643646
time_this_iter_s: 10.299360990524292
time_total_s: 921.2995488643646
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.094
timestamp: 1692342510
timesteps_total: 682650
training_iteration: 90
trial_id: default
train step: 91
agent_timesteps_total: 690750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03238797187805176
  StateBufferConnector_ms: 0.005747795104980469
  ViewRequirementAgentConnector_ms: 0.19727110862731934
counters:
  num_agent_steps_sampled: 690750
  num_agent_steps_trained: 674000
  num_env_steps_sampled: 690750
  num_env_steps_trained: 674000
  num_samples_added_to_queue: 690500
  num_training_step_calls_since_last_synch_worker_weights: 370
  num_weight_broadcasts: 13524
custom_metrics: {}
date: 2023-08-18_16-08-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.66
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 5397
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2168354988098145
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 12.175328254699707
        total_loss: 26.518199920654297
        var_gnorm: 63.338966369628906
        vf_explained_var: 0.20123934745788574
        vf_loss: 29.902576446533203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1348.0
  learner_queue:
    size_count: 1354
    size_mean: 14.34
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8720042734993956
  num_agent_steps_sampled: 690750
  num_agent_steps_trained: 674000
  num_env_steps_sampled: 690750
  num_env_steps_trained: 674000
  num_samples_added_to_queue: 690500
  num_training_step_calls_since_last_synch_worker_weights: 370
  num_weight_broadcasts: 13524
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 297.02
    learner_load_time_ms: 3.96
    learner_load_wait_time_ms: 2.515
iterations_since_restore: 91
node_ip: 127.0.0.1
num_agent_steps_sampled: 690750
num_agent_steps_trained: 674000
num_env_steps_sampled: 690750
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9979915668697
num_env_steps_trained: 674000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9980163623404
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.173333333333325
  ram_util_percent: 83.74666666666668
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10671098878447063
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03932460718909517
  mean_inference_ms: 2.000309135962488
  mean_raw_obs_processing_ms: 0.45058380874821957
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03238797187805176
    StateBufferConnector_ms: 0.005747795104980469
    ViewRequirementAgentConnector_ms: 0.19727110862731934
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.66
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 3.0, 6.0, 5.0, 3.0, 2.0, 3.0, 2.0, 5.0, 4.0, 3.0, 4.0, 4.0,
      1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 4.0, 5.0, 6.0, 5.0, 2.0, 3.0, 2.0, 5.0, 2.0, 3.0,
      1.0, 2.0, 2.0, 1.0, 1.0, 2.0, 1.0, 3.0, 0.0, 0.0, 2.0, 4.0, 0.0, 0.0, 3.0, 0.0,
      6.0, 3.0, 9.0, 4.0, 2.0, 5.0, 3.0, 4.0, 3.0, 5.0, 1.0, 2.0, 1.0, 1.0, 2.0, 2.0,
      2.0, 2.0, 4.0, 3.0, 5.0, 2.0, 4.0, 3.0, 4.0, 2.0, 2.0, 1.0, 3.0, 2.0, 6.0, 1.0,
      3.0, 4.0, 1.0, 3.0, 2.0, 3.0, 5.0, 3.0, 2.0, 1.0, 0.0, 3.0, 1.0, 0.0, 1.0, 2.0,
      2.0, 3.0, 2.0, 1.0, 4.0, 2.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10671098878447063
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03932460718909517
    mean_inference_ms: 2.000309135962488
    mean_raw_obs_processing_ms: 0.45058380874821957
time_since_restore: 931.5187249183655
time_this_iter_s: 10.219176054000854
time_total_s: 931.5187249183655
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.076
timestamp: 1692342520
timesteps_total: 690750
training_iteration: 91
trial_id: default
train step: 92
agent_timesteps_total: 698250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.032494544982910156
  StateBufferConnector_ms: 0.006150007247924805
  ViewRequirementAgentConnector_ms: 0.1970665454864502
counters:
  num_agent_steps_sampled: 698250
  num_agent_steps_trained: 681500
  num_env_steps_sampled: 698250
  num_env_steps_trained: 681500
  num_samples_added_to_queue: 698000
  num_training_step_calls_since_last_synch_worker_weights: 78
  num_weight_broadcasts: 13671
custom_metrics: {}
date: 2023-08-18_16-08-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.71
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 5455
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2464081048965454
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -41.74570083618164
        total_loss: -33.960269927978516
        var_gnorm: 63.33924102783203
        vf_explained_var: 0.14562946557998657
        vf_loss: 16.817272186279297
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1363.0
  learner_queue:
    size_count: 1370
    size_mean: 14.24
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.9855477833585369
  num_agent_steps_sampled: 698250
  num_agent_steps_trained: 681500
  num_env_steps_sampled: 698250
  num_env_steps_trained: 681500
  num_samples_added_to_queue: 698000
  num_training_step_calls_since_last_synch_worker_weights: 78
  num_weight_broadcasts: 13671
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 281.627
    learner_load_time_ms: 3.486
    learner_load_wait_time_ms: 2.913
iterations_since_restore: 92
node_ip: 127.0.0.1
num_agent_steps_sampled: 698250
num_agent_steps_trained: 681500
num_env_steps_sampled: 698250
num_env_steps_sampled_this_iter: 7500
num_env_steps_sampled_throughput_per_sec: 749.9977469511958
num_env_steps_trained: 681500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9977469511958
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.90714285714285
  ram_util_percent: 83.95714285714287
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10663314703512324
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03933231166864213
  mean_inference_ms: 2.000056780364735
  mean_raw_obs_processing_ms: 0.45063296502221667
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.032494544982910156
    StateBufferConnector_ms: 0.006150007247924805
    ViewRequirementAgentConnector_ms: 0.1970665454864502
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.71
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 2.0, 2.0, 2.0, 4.0, 3.0, 5.0, 2.0, 4.0, 3.0, 4.0, 2.0,
      2.0, 1.0, 3.0, 2.0, 6.0, 1.0, 3.0, 4.0, 1.0, 3.0, 2.0, 3.0, 5.0, 3.0, 2.0, 1.0,
      0.0, 3.0, 1.0, 0.0, 1.0, 2.0, 2.0, 3.0, 2.0, 1.0, 4.0, 2.0, 4.0, 2.0, 4.0, 1.0,
      2.0, 2.0, 3.0, 3.0, 5.0, 2.0, 5.0, 3.0, 2.0, 4.0, 4.0, 2.0, 3.0, 4.0, 1.0, 1.0,
      1.0, 2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 9.0, 2.0, 3.0,
      3.0, 4.0, 7.0, 2.0, 5.0, 1.0, 1.0, 4.0, 3.0, 3.0, 5.0, 6.0, 1.0, 3.0, 3.0, 2.0,
      1.0, 1.0, 2.0, 3.0, 4.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10663314703512324
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03933231166864213
    mean_inference_ms: 2.000056780364735
    mean_raw_obs_processing_ms: 0.45063296502221667
time_since_restore: 941.7862386703491
time_this_iter_s: 10.267513751983643
time_total_s: 941.7862386703491
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692342530
timesteps_total: 698250
training_iteration: 92
trial_id: default
train step: 93
agent_timesteps_total: 706050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0329287052154541
  StateBufferConnector_ms: 0.0060482025146484375
  ViewRequirementAgentConnector_ms: 0.1993422508239746
counters:
  num_agent_steps_sampled: 706050
  num_agent_steps_trained: 689500
  num_env_steps_sampled: 706050
  num_env_steps_trained: 689500
  num_samples_added_to_queue: 706000
  num_training_step_calls_since_last_synch_worker_weights: 837
  num_weight_broadcasts: 13824
custom_metrics: {}
date: 2023-08-18_16-09-00
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.89
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 5517
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1996948719024658
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -14.083551406860352
        total_loss: -6.920705318450928
        var_gnorm: 63.339569091796875
        vf_explained_var: 0.28696775436401367
        vf_loss: 15.525386810302734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1379.0
  learner_queue:
    size_count: 1383
    size_mean: 14.4
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.8439088914585775
  num_agent_steps_sampled: 706050
  num_agent_steps_trained: 689500
  num_env_steps_sampled: 706050
  num_env_steps_trained: 689500
  num_samples_added_to_queue: 706000
  num_training_step_calls_since_last_synch_worker_weights: 837
  num_weight_broadcasts: 13824
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 526.149
    learner_load_time_ms: 3.515
    learner_load_wait_time_ms: 2.864
iterations_since_restore: 93
node_ip: 127.0.0.1
num_agent_steps_sampled: 706050
num_agent_steps_trained: 689500
num_env_steps_sampled: 706050
num_env_steps_sampled_this_iter: 7800
num_env_steps_sampled_throughput_per_sec: 779.9980473567254
num_env_steps_trained: 689500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9979972889491
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 54.71333333333334
  ram_util_percent: 83.59333333333332
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1066179950740014
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03932656557533685
  mean_inference_ms: 1.9997835490956637
  mean_raw_obs_processing_ms: 0.4506005552739519
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0329287052154541
    StateBufferConnector_ms: 0.0060482025146484375
    ViewRequirementAgentConnector_ms: 0.1993422508239746
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.89
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 4.0, 2.0, 4.0, 2.0, 2.0, 3.0, 1.0, 3.0, 2.0, 1.0, 2.0, 9.0,
      2.0, 3.0, 3.0, 4.0, 7.0, 2.0, 5.0, 1.0, 1.0, 4.0, 3.0, 3.0, 5.0, 6.0, 1.0, 3.0,
      3.0, 2.0, 1.0, 1.0, 2.0, 3.0, 4.0, 4.0, 4.0, 1.0, 4.0, 3.0, 4.0, 3.0, 5.0, 4.0,
      2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0, 2.0, 1.0, 5.0, 0.0, 2.0, 3.0, 6.0,
      3.0, 5.0, 1.0, 0.0, 3.0, 0.0, 1.0, 3.0, 4.0, 4.0, 2.0, 5.0, 2.0, 2.0, 6.0, 1.0,
      3.0, 4.0, 5.0, 1.0, 3.0, 4.0, 2.0, 4.0, 4.0, 2.0, 4.0, 3.0, 6.0, 2.0, 2.0, 5.0,
      4.0, 0.0, 3.0, 4.0, 1.0, 1.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1066179950740014
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03932656557533685
    mean_inference_ms: 1.9997835490956637
    mean_raw_obs_processing_ms: 0.4506005552739519
time_since_restore: 951.9816346168518
time_this_iter_s: 10.195395946502686
time_total_s: 951.9816346168518
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.072
timestamp: 1692342540
timesteps_total: 706050
training_iteration: 93
trial_id: default
train step: 94
agent_timesteps_total: 713600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03376436233520508
  StateBufferConnector_ms: 0.006091594696044922
  ViewRequirementAgentConnector_ms: 0.20198297500610352
counters:
  num_agent_steps_sampled: 713600
  num_agent_steps_trained: 697000
  num_env_steps_sampled: 713600
  num_env_steps_trained: 697000
  num_samples_added_to_queue: 713500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 13972
custom_metrics: {}
date: 2023-08-18_16-09-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.89
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 5575
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2293012142181396
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -39.95011901855469
        total_loss: -31.2116641998291
        var_gnorm: 63.33982849121094
        vf_explained_var: 0.17226409912109375
        vf_loss: 18.70621109008789
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1394.0
  learner_queue:
    size_count: 1397
    size_mean: 14.74
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.694815624190431
  num_agent_steps_sampled: 713600
  num_agent_steps_trained: 697000
  num_env_steps_sampled: 713600
  num_env_steps_trained: 697000
  num_samples_added_to_queue: 713500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 13972
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 513.868
    learner_load_time_ms: 3.377
    learner_load_wait_time_ms: 2.947
iterations_since_restore: 94
node_ip: 127.0.0.1
num_agent_steps_sampled: 713600
num_agent_steps_trained: 697000
num_env_steps_sampled: 713600
num_env_steps_sampled_this_iter: 7550
num_env_steps_sampled_throughput_per_sec: 754.6891316383525
num_env_steps_trained: 697000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.6911903692244
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 52.442857142857136
  ram_util_percent: 83.7357142857143
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10661354318352821
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03932517078573609
  mean_inference_ms: 1.999590348067074
  mean_raw_obs_processing_ms: 0.45059166959373104
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03376436233520508
    StateBufferConnector_ms: 0.006091594696044922
    ViewRequirementAgentConnector_ms: 0.20198297500610352
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.89
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 3.0, 6.0, 3.0, 5.0, 1.0, 0.0, 3.0, 0.0, 1.0, 3.0, 4.0, 4.0,
      2.0, 5.0, 2.0, 2.0, 6.0, 1.0, 3.0, 4.0, 5.0, 1.0, 3.0, 4.0, 2.0, 4.0, 4.0, 2.0,
      4.0, 3.0, 6.0, 2.0, 2.0, 5.0, 4.0, 0.0, 3.0, 4.0, 1.0, 1.0, 7.0, 1.0, 2.0, 4.0,
      6.0, 1.0, 3.0, 3.0, 1.0, 0.0, 2.0, 5.0, 1.0, 6.0, 6.0, 3.0, 2.0, 3.0, 3.0, 6.0,
      3.0, 1.0, 4.0, 1.0, 3.0, 4.0, 0.0, 2.0, 0.0, 2.0, 2.0, 4.0, 3.0, 2.0, 5.0, 4.0,
      2.0, 1.0, 4.0, 2.0, 3.0, 5.0, 6.0, 3.0, 5.0, 2.0, 1.0, 2.0, 4.0, 1.0, 2.0, 4.0,
      3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10661354318352821
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03932517078573609
    mean_inference_ms: 1.999590348067074
    mean_raw_obs_processing_ms: 0.45059166959373104
time_since_restore: 962.1276326179504
time_this_iter_s: 10.145998001098633
time_total_s: 962.1276326179504
timers:
  sample_time_ms: 0.102
  synch_weights_time_ms: 0.429
  training_iteration_time_ms: 0.671
timestamp: 1692342551
timesteps_total: 713600
training_iteration: 94
trial_id: default
train step: 95
agent_timesteps_total: 721050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.036362648010253906
  StateBufferConnector_ms: 0.00658416748046875
  ViewRequirementAgentConnector_ms: 0.2133193016052246
counters:
  num_agent_steps_sampled: 721050
  num_agent_steps_trained: 704500
  num_env_steps_sampled: 721050
  num_env_steps_trained: 704500
  num_samples_added_to_queue: 721000
  num_training_step_calls_since_last_synch_worker_weights: 892
  num_weight_broadcasts: 14119
custom_metrics: {}
date: 2023-08-18_16-09-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.93
episode_reward_min: 0.0
episodes_this_iter: 59
episodes_total: 5634
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2223619222640991
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 27.138147354125977
        total_loss: 46.38865280151367
        var_gnorm: 63.340091705322266
        vf_explained_var: 0.2165679931640625
        vf_loss: 39.72337341308594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1409.0
  learner_queue:
    size_count: 1414
    size_mean: 14.88
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.5954936540143303
  num_agent_steps_sampled: 721050
  num_agent_steps_trained: 704500
  num_env_steps_sampled: 721050
  num_env_steps_trained: 704500
  num_samples_added_to_queue: 721000
  num_training_step_calls_since_last_synch_worker_weights: 892
  num_weight_broadcasts: 14119
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 374.028
    learner_load_time_ms: 3.42
    learner_load_wait_time_ms: 2.913
iterations_since_restore: 95
node_ip: 127.0.0.1
num_agent_steps_sampled: 721050
num_agent_steps_trained: 704500
num_env_steps_sampled: 721050
num_env_steps_sampled_this_iter: 7450
num_env_steps_sampled_throughput_per_sec: 744.9999289512702
num_env_steps_trained: 704500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9999284744331
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 52.32142857142857
  ram_util_percent: 83.73571428571428
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10660593344151582
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039346797206927464
  mean_inference_ms: 1.9999251637876936
  mean_raw_obs_processing_ms: 0.45074332278466583
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.036362648010253906
    StateBufferConnector_ms: 0.00658416748046875
    ViewRequirementAgentConnector_ms: 0.2133193016052246
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.93
  episode_reward_min: 0.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 6.0, 3.0, 1.0, 4.0, 1.0, 3.0, 4.0, 0.0, 2.0, 0.0, 2.0, 2.0,
      4.0, 3.0, 2.0, 5.0, 4.0, 2.0, 1.0, 4.0, 2.0, 3.0, 5.0, 6.0, 3.0, 5.0, 2.0, 1.0,
      2.0, 4.0, 1.0, 2.0, 4.0, 3.0, 4.0, 2.0, 2.0, 2.0, 3.0, 1.0, 2.0, 1.0, 5.0, 3.0,
      4.0, 3.0, 1.0, 4.0, 0.0, 3.0, 4.0, 5.0, 3.0, 5.0, 3.0, 8.0, 3.0, 4.0, 2.0, 1.0,
      4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 6.0, 5.0, 4.0, 4.0, 2.0, 2.0, 4.0, 0.0, 3.0,
      2.0, 5.0, 4.0, 7.0, 4.0, 7.0, 2.0, 0.0, 2.0, 2.0, 3.0, 0.0, 3.0, 0.0, 5.0, 4.0,
      3.0, 4.0, 5.0, 0.0, 4.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10660593344151582
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039346797206927464
    mean_inference_ms: 1.9999251637876936
    mean_raw_obs_processing_ms: 0.45074332278466583
time_since_restore: 972.408688545227
time_this_iter_s: 10.281055927276611
time_total_s: 972.408688545227
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.088
timestamp: 1692342561
timesteps_total: 721050
training_iteration: 95
trial_id: default
train step: 96
agent_timesteps_total: 728500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03583502769470215
  StateBufferConnector_ms: 0.006384611129760742
  ViewRequirementAgentConnector_ms: 0.21155548095703125
counters:
  num_agent_steps_sampled: 728500
  num_agent_steps_trained: 712000
  num_env_steps_sampled: 728500
  num_env_steps_trained: 712000
  num_samples_added_to_queue: 728500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 14265
custom_metrics: {}
date: 2023-08-18_16-09-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.92
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 5691
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1895654201507568
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 31.680469512939453
        total_loss: 45.55598068237305
        var_gnorm: 63.34038162231445
        vf_explained_var: 0.20956361293792725
        vf_loss: 28.940593719482422
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1424.0
  learner_queue:
    size_count: 1427
    size_mean: 15.2
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2806248474865698
  num_agent_steps_sampled: 728500
  num_agent_steps_trained: 712000
  num_env_steps_sampled: 728500
  num_env_steps_trained: 712000
  num_samples_added_to_queue: 728500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 14265
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 619.025
    learner_load_time_ms: 3.305
    learner_load_wait_time_ms: 15.007
iterations_since_restore: 96
node_ip: 127.0.0.1
num_agent_steps_sampled: 728500
num_agent_steps_trained: 712000
num_env_steps_sampled: 728500
num_env_steps_sampled_this_iter: 7450
num_env_steps_sampled_throughput_per_sec: 744.4770755976633
num_env_steps_trained: 712000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.4735660379162
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 52.78666666666667
  ram_util_percent: 83.90666666666667
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1065971681310908
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03936735340534659
  mean_inference_ms: 2.0003331950754126
  mean_raw_obs_processing_ms: 0.450890462292971
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03583502769470215
    StateBufferConnector_ms: 0.006384611129760742
    ViewRequirementAgentConnector_ms: 0.21155548095703125
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.92
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 2.0, 1.0, 4.0, 2.0, 3.0, 1.0, 2.0, 2.0, 2.0, 6.0, 5.0,
      4.0, 4.0, 2.0, 2.0, 4.0, 0.0, 3.0, 2.0, 5.0, 4.0, 7.0, 4.0, 7.0, 2.0, 0.0, 2.0,
      2.0, 3.0, 0.0, 3.0, 0.0, 5.0, 4.0, 3.0, 4.0, 5.0, 0.0, 4.0, 1.0, 3.0, 2.0, 0.0,
      4.0, 1.0, 5.0, 3.0, 3.0, 3.0, 5.0, 1.0, 3.0, 2.0, 5.0, 7.0, 2.0, 3.0, 4.0, 3.0,
      2.0, 1.0, 3.0, 4.0, 4.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0,
      3.0, 1.0, 4.0, 4.0, 2.0, 2.0, 3.0, 5.0, 2.0, 4.0, 0.0, 2.0, 6.0, 1.0, 2.0, 2.0,
      3.0, 4.0, 6.0, 3.0, 2.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1065971681310908
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03936735340534659
    mean_inference_ms: 2.0003331950754126
    mean_raw_obs_processing_ms: 0.450890462292971
time_since_restore: 982.534325838089
time_this_iter_s: 10.125637292861938
time_total_s: 982.534325838089
timers:
  sample_time_ms: 0.062
  synch_weights_time_ms: 0.689
  training_iteration_time_ms: 3.145
timestamp: 1692342571
timesteps_total: 728500
training_iteration: 96
trial_id: default
train step: 97
agent_timesteps_total: 736250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.032962799072265625
  StateBufferConnector_ms: 0.005930900573730469
  ViewRequirementAgentConnector_ms: 0.1991102695465088
counters:
  num_agent_steps_sampled: 736250
  num_agent_steps_trained: 719500
  num_env_steps_sampled: 736250
  num_env_steps_trained: 719500
  num_samples_added_to_queue: 736000
  num_training_step_calls_since_last_synch_worker_weights: 442
  num_weight_broadcasts: 14417
custom_metrics: {}
date: 2023-08-18_16-09-41
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 2.93
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 5753
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1837184429168701
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 1.4193639755249023
        total_loss: 14.563176155090332
        var_gnorm: 63.3406867980957
        vf_explained_var: 0.1881205439567566
        vf_loss: 27.471342086791992
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1439.0
  learner_queue:
    size_count: 1445
    size_mean: 15.08
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4399999999999997
  num_agent_steps_sampled: 736250
  num_agent_steps_trained: 719500
  num_env_steps_sampled: 736250
  num_env_steps_trained: 719500
  num_samples_added_to_queue: 736000
  num_training_step_calls_since_last_synch_worker_weights: 442
  num_weight_broadcasts: 14417
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 308.05
    learner_load_time_ms: 2.455
    learner_load_wait_time_ms: 3.45
iterations_since_restore: 97
node_ip: 127.0.0.1
num_agent_steps_sampled: 736250
num_agent_steps_trained: 719500
num_env_steps_sampled: 736250
num_env_steps_sampled_this_iter: 7750
num_env_steps_sampled_throughput_per_sec: 774.9964338705125
num_env_steps_trained: 719500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9965489069476
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 51.93571428571429
  ram_util_percent: 83.52142857142859
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10661321919574945
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039356239833933264
  mean_inference_ms: 2.000119354392623
  mean_raw_obs_processing_ms: 0.45078345200525793
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.032962799072265625
    StateBufferConnector_ms: 0.005930900573730469
    ViewRequirementAgentConnector_ms: 0.1991102695465088
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 2.93
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 3.0, 4.0, 4.0, 3.0, 1.0, 3.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0,
      4.0, 3.0, 3.0, 1.0, 4.0, 4.0, 2.0, 2.0, 3.0, 5.0, 2.0, 4.0, 0.0, 2.0, 6.0, 1.0,
      2.0, 2.0, 3.0, 4.0, 6.0, 3.0, 2.0, 3.0, 4.0, 3.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0,
      3.0, 6.0, 6.0, 1.0, 6.0, 3.0, 3.0, 3.0, 3.0, 2.0, 1.0, 4.0, 2.0, 3.0, 3.0, 1.0,
      4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 4.0, 1.0, 3.0, 3.0, 3.0, 2.0, 4.0, 1.0, 4.0,
      3.0, 4.0, 2.0, 2.0, 1.0, 4.0, 6.0, 3.0, 2.0, 2.0, 3.0, 4.0, 4.0, 6.0, 4.0, 1.0,
      1.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10661321919574945
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039356239833933264
    mean_inference_ms: 2.000119354392623
    mean_raw_obs_processing_ms: 0.45078345200525793
time_since_restore: 992.7957289218903
time_this_iter_s: 10.26140308380127
time_total_s: 992.7957289218903
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.091
timestamp: 1692342581
timesteps_total: 736250
training_iteration: 97
trial_id: default
train step: 98
agent_timesteps_total: 743850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03394436836242676
  StateBufferConnector_ms: 0.006075859069824219
  ViewRequirementAgentConnector_ms: 0.20217490196228027
counters:
  num_agent_steps_sampled: 743850
  num_agent_steps_trained: 727000
  num_env_steps_sampled: 743850
  num_env_steps_trained: 727000
  num_samples_added_to_queue: 743500
  num_training_step_calls_since_last_synch_worker_weights: 825
  num_weight_broadcasts: 14566
custom_metrics: {}
date: 2023-08-18_16-09-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.7
episode_reward_min: 0.0
episodes_this_iter: 59
episodes_total: 5812
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1731956005096436
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 18.93838882446289
        total_loss: 30.18425941467285
        var_gnorm: 63.34098434448242
        vf_explained_var: 0.2710106372833252
        vf_loss: 23.664936065673828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1454.0
  learner_queue:
    size_count: 1459
    size_mean: 14.9
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5394804318340654
  num_agent_steps_sampled: 743850
  num_agent_steps_trained: 727000
  num_env_steps_sampled: 743850
  num_env_steps_trained: 727000
  num_samples_added_to_queue: 743500
  num_training_step_calls_since_last_synch_worker_weights: 825
  num_weight_broadcasts: 14566
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 422.654
    learner_load_time_ms: 2.417
    learner_load_wait_time_ms: 2.897
iterations_since_restore: 98
node_ip: 127.0.0.1
num_agent_steps_sampled: 743850
num_agent_steps_trained: 727000
num_env_steps_sampled: 743850
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9998550415315
num_env_steps_trained: 727000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9998569488798
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.55714285714286
  ram_util_percent: 83.14285714285712
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10664968453114267
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039334528549430516
  mean_inference_ms: 1.9997603801243826
  mean_raw_obs_processing_ms: 0.45059212062147025
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03394436836242676
    StateBufferConnector_ms: 0.006075859069824219
    ViewRequirementAgentConnector_ms: 0.20217490196228027
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.7
  episode_reward_min: 0.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 1.0, 4.0, 4.0, 1.0, 3.0, 3.0,
      3.0, 2.0, 4.0, 1.0, 4.0, 3.0, 4.0, 2.0, 2.0, 1.0, 4.0, 6.0, 3.0, 2.0, 2.0, 3.0,
      4.0, 4.0, 6.0, 4.0, 1.0, 1.0, 3.0, 2.0, 2.0, 2.0, 4.0, 2.0, 9.0, 2.0, 1.0, 2.0,
      1.0, 1.0, 1.0, 3.0, 4.0, 3.0, 4.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 1.0, 2.0, 3.0,
      0.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 6.0, 4.0, 2.0, 1.0, 2.0, 8.0, 6.0, 5.0, 0.0,
      3.0, 5.0, 0.0, 3.0, 0.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 5.0, 4.0, 3.0, 2.0, 4.0,
      2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10664968453114267
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039334528549430516
    mean_inference_ms: 1.9997603801243826
    mean_raw_obs_processing_ms: 0.45059212062147025
time_since_restore: 1002.9737458229065
time_this_iter_s: 10.178016901016235
time_total_s: 1002.9737458229065
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342591
timesteps_total: 743850
training_iteration: 98
trial_id: default
train step: 99
agent_timesteps_total: 751150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0351560115814209
  StateBufferConnector_ms: 0.0063629150390625
  ViewRequirementAgentConnector_ms: 0.20871567726135254
counters:
  num_agent_steps_sampled: 751150
  num_agent_steps_trained: 734500
  num_env_steps_sampled: 751150
  num_env_steps_trained: 734500
  num_samples_added_to_queue: 751000
  num_training_step_calls_since_last_synch_worker_weights: 646
  num_weight_broadcasts: 14709
custom_metrics: {}
date: 2023-08-18_16-10-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.88
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 5869
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2011103630065918
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 10.459293365478516
        total_loss: 23.518009185791016
        var_gnorm: 63.34125518798828
        vf_explained_var: 0.1980845332145691
        vf_loss: 27.318544387817383
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1469.0
  learner_queue:
    size_count: 1475
    size_mean: 14.96
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.482700239428051
  num_agent_steps_sampled: 751150
  num_agent_steps_trained: 734500
  num_env_steps_sampled: 751150
  num_env_steps_trained: 734500
  num_samples_added_to_queue: 751000
  num_training_step_calls_since_last_synch_worker_weights: 646
  num_weight_broadcasts: 14709
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 342.508
    learner_load_time_ms: 2.432
    learner_load_wait_time_ms: 3.069
iterations_since_restore: 99
node_ip: 127.0.0.1
num_agent_steps_sampled: 751150
num_agent_steps_trained: 734500
num_env_steps_sampled: 751150
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9960491871079
num_env_steps_trained: 734500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9959409456588
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.10666666666666
  ram_util_percent: 83.40666666666667
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10659434364815965
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03937392925161067
  mean_inference_ms: 2.000323757337149
  mean_raw_obs_processing_ms: 0.4508975424248052
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0351560115814209
    StateBufferConnector_ms: 0.0063629150390625
    ViewRequirementAgentConnector_ms: 0.20871567726135254
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.88
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 2.0, 3.0, 0.0, 1.0, 3.0, 1.0, 2.0, 2.0, 1.0, 6.0, 4.0,
      2.0, 1.0, 2.0, 8.0, 6.0, 5.0, 0.0, 3.0, 5.0, 0.0, 3.0, 0.0, 3.0, 2.0, 2.0, 4.0,
      3.0, 3.0, 5.0, 4.0, 3.0, 2.0, 4.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 5.0, 3.0, 4.0,
      3.0, 4.0, 2.0, 6.0, 4.0, 4.0, 4.0, 1.0, 1.0, 3.0, 2.0, 3.0, 2.0, 2.0, 4.0, 4.0,
      2.0, 8.0, 0.0, 3.0, 2.0, 3.0, 2.0, 3.0, 1.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0,
      1.0, 4.0, 1.0, 5.0, 2.0, 5.0, 2.0, 3.0, 6.0, 7.0, 3.0, 4.0, 3.0, 1.0, 4.0, 0.0,
      0.0, 1.0, 2.0, 7.0, 4.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10659434364815965
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03937392925161067
    mean_inference_ms: 2.000323757337149
    mean_raw_obs_processing_ms: 0.4508975424248052
time_since_restore: 1013.2521777153015
time_this_iter_s: 10.27843189239502
time_total_s: 1013.2521777153015
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692342602
timesteps_total: 751150
training_iteration: 99
trial_id: default
train step: 100
agent_timesteps_total: 758050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03771781921386719
  StateBufferConnector_ms: 0.007047414779663086
  ViewRequirementAgentConnector_ms: 0.22194981575012207
counters:
  num_agent_steps_sampled: 758050
  num_agent_steps_trained: 741500
  num_env_steps_sampled: 758050
  num_env_steps_trained: 741500
  num_samples_added_to_queue: 758000
  num_training_step_calls_since_last_synch_worker_weights: 428
  num_weight_broadcasts: 14842
custom_metrics: {}
date: 2023-08-18_16-10-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.04
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 5923
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1976152658462524
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 23.660154342651367
        total_loss: 36.31591796875
        var_gnorm: 63.341487884521484
        vf_explained_var: 0.25322818756103516
        vf_loss: 26.50914764404297
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1483.0
  learner_queue:
    size_count: 1489
    size_mean: 14.66
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6322989922192566
  num_agent_steps_sampled: 758050
  num_agent_steps_trained: 741500
  num_env_steps_sampled: 758050
  num_env_steps_trained: 741500
  num_samples_added_to_queue: 758000
  num_training_step_calls_since_last_synch_worker_weights: 428
  num_weight_broadcasts: 14842
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 310.299
    learner_load_time_ms: 2.455
    learner_load_wait_time_ms: 3.185
iterations_since_restore: 100
node_ip: 127.0.0.1
num_agent_steps_sampled: 758050
num_agent_steps_trained: 741500
num_env_steps_sampled: 758050
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 689.9984865221796
num_env_steps_trained: 741500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9984645877184
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 53.89999999999999
  ram_util_percent: 83.89285714285714
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10659376156858151
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03944127489984748
  mean_inference_ms: 2.00185517143617
  mean_raw_obs_processing_ms: 0.45141209945507754
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03771781921386719
    StateBufferConnector_ms: 0.007047414779663086
    ViewRequirementAgentConnector_ms: 0.22194981575012207
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.04
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 3.0, 2.0, 2.0, 4.0, 4.0, 2.0, 8.0, 0.0, 3.0, 2.0, 3.0,
      2.0, 3.0, 1.0, 4.0, 4.0, 2.0, 2.0, 2.0, 4.0, 4.0, 1.0, 4.0, 1.0, 5.0, 2.0, 5.0,
      2.0, 3.0, 6.0, 7.0, 3.0, 4.0, 3.0, 1.0, 4.0, 0.0, 0.0, 1.0, 2.0, 7.0, 4.0, 3.0,
      5.0, 4.0, 2.0, 2.0, 2.0, 2.0, 4.0, 4.0, 3.0, 2.0, 0.0, 4.0, 3.0, 2.0, 2.0, 4.0,
      2.0, 4.0, 2.0, 6.0, 7.0, 2.0, 1.0, 4.0, 1.0, 3.0, 5.0, 6.0, 4.0, 2.0, 4.0, 4.0,
      4.0, 2.0, 4.0, 2.0, 3.0, 6.0, 2.0, 1.0, 2.0, 7.0, 4.0, 2.0, 4.0, 1.0, 1.0, 2.0,
      0.0, 2.0, 2.0, 3.0, 5.0, 6.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10659376156858151
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03944127489984748
    mean_inference_ms: 2.00185517143617
    mean_raw_obs_processing_ms: 0.45141209945507754
time_since_restore: 1023.5240406990051
time_this_iter_s: 10.271862983703613
time_total_s: 1023.5240406990051
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692342612
timesteps_total: 758050
training_iteration: 100
trial_id: default
train step: 101
agent_timesteps_total: 764950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.037833452224731445
  StateBufferConnector_ms: 0.0071451663970947266
  ViewRequirementAgentConnector_ms: 0.22958660125732422
counters:
  num_agent_steps_sampled: 764950
  num_agent_steps_trained: 748000
  num_env_steps_sampled: 764950
  num_env_steps_trained: 748000
  num_samples_added_to_queue: 764500
  num_training_step_calls_since_last_synch_worker_weights: 75
  num_weight_broadcasts: 14977
custom_metrics: {}
date: 2023-08-18_16-10-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 2.84
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 5977
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1669628620147705
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 44.685096740722656
        total_loss: 59.49529266357422
        var_gnorm: 63.341617584228516
        vf_explained_var: 0.20452874898910522
        vf_loss: 30.787353515625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1496.0
  learner_queue:
    size_count: 1503
    size_mean: 14.52
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7690675509996785
  num_agent_steps_sampled: 764950
  num_agent_steps_trained: 748000
  num_env_steps_sampled: 764950
  num_env_steps_trained: 748000
  num_samples_added_to_queue: 764500
  num_training_step_calls_since_last_synch_worker_weights: 75
  num_weight_broadcasts: 14977
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 318.576
    learner_load_time_ms: 2.455
    learner_load_wait_time_ms: 2.59
iterations_since_restore: 101
node_ip: 127.0.0.1
num_agent_steps_sampled: 764950
num_agent_steps_trained: 748000
num_env_steps_sampled: 764950
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 689.9938638755983
num_env_steps_trained: 748000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9942195929549
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 53.059999999999995
  ram_util_percent: 83.35333333333332
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10666804939942612
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0394997133019779
  mean_inference_ms: 2.0037953412539276
  mean_raw_obs_processing_ms: 0.4519055181101093
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.037833452224731445
    StateBufferConnector_ms: 0.0071451663970947266
    ViewRequirementAgentConnector_ms: 0.22958660125732422
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 2.84
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 0.0, 4.0, 3.0, 2.0, 2.0, 4.0, 2.0, 4.0, 2.0, 6.0, 7.0, 2.0,
      1.0, 4.0, 1.0, 3.0, 5.0, 6.0, 4.0, 2.0, 4.0, 4.0, 4.0, 2.0, 4.0, 2.0, 3.0, 6.0,
      2.0, 1.0, 2.0, 7.0, 4.0, 2.0, 4.0, 1.0, 1.0, 2.0, 0.0, 2.0, 2.0, 3.0, 5.0, 6.0,
      3.0, 2.0, 2.0, 2.0, 3.0, 1.0, 1.0, 3.0, 4.0, 6.0, 4.0, 9.0, 0.0, 3.0, 2.0, 2.0,
      3.0, 2.0, 7.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0, 2.0, 4.0, 1.0, 1.0, 3.0, 0.0, 3.0,
      3.0, 0.0, 4.0, 0.0, 4.0, 2.0, 4.0, 2.0, 4.0, 4.0, 2.0, 2.0, 1.0, 0.0, 3.0, 4.0,
      3.0, 3.0, 3.0, 3.0, 2.0, 6.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10666804939942612
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0394997133019779
    mean_inference_ms: 2.0037953412539276
    mean_raw_obs_processing_ms: 0.4519055181101093
time_since_restore: 1033.8124067783356
time_this_iter_s: 10.288366079330444
time_total_s: 1033.8124067783356
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.077
timestamp: 1692342622
timesteps_total: 764950
training_iteration: 101
trial_id: default
train step: 102
agent_timesteps_total: 772300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.036103010177612305
  StateBufferConnector_ms: 0.0067596435546875
  ViewRequirementAgentConnector_ms: 0.22081208229064941
counters:
  num_agent_steps_sampled: 772300
  num_agent_steps_trained: 755500
  num_env_steps_sampled: 772300
  num_env_steps_trained: 755500
  num_samples_added_to_queue: 772000
  num_training_step_calls_since_last_synch_worker_weights: 132
  num_weight_broadcasts: 15120
custom_metrics: {}
date: 2023-08-18_16-10-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.64
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 6034
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.173487901687622
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 5.802704811096191
        total_loss: 22.30497169494629
        var_gnorm: 63.34184646606445
        vf_explained_var: 0.20870697498321533
        vf_loss: 34.17802429199219
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1511.0
  learner_queue:
    size_count: 1517
    size_mean: 14.36
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8521339044464362
  num_agent_steps_sampled: 772300
  num_agent_steps_trained: 755500
  num_env_steps_sampled: 772300
  num_env_steps_trained: 755500
  num_samples_added_to_queue: 772000
  num_training_step_calls_since_last_synch_worker_weights: 132
  num_weight_broadcasts: 15120
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 359.104
    learner_load_time_ms: 17.967
    learner_load_wait_time_ms: 2.671
iterations_since_restore: 102
node_ip: 127.0.0.1
num_agent_steps_sampled: 772300
num_agent_steps_trained: 755500
num_env_steps_sampled: 772300
num_env_steps_sampled_this_iter: 7350
num_env_steps_sampled_throughput_per_sec: 734.9968457357351
num_env_steps_trained: 755500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.996781362995
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.707142857142856
  ram_util_percent: 83.19999999999997
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10678529820696657
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03951286502733497
  mean_inference_ms: 2.004916710946871
  mean_raw_obs_processing_ms: 0.45202761356190535
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.036103010177612305
    StateBufferConnector_ms: 0.0067596435546875
    ViewRequirementAgentConnector_ms: 0.22081208229064941
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.64
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 3.0, 2.0, 2.0, 3.0, 2.0, 7.0, 2.0, 1.0, 1.0, 4.0, 1.0, 1.0,
      2.0, 4.0, 1.0, 1.0, 3.0, 0.0, 3.0, 3.0, 0.0, 4.0, 0.0, 4.0, 2.0, 4.0, 2.0, 4.0,
      4.0, 2.0, 2.0, 1.0, 0.0, 3.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 6.0, 3.0, 3.0, 2.0,
      4.0, 4.0, 3.0, 2.0, 0.0, 2.0, 2.0, 4.0, 3.0, 1.0, 3.0, 1.0, 2.0, 2.0, 2.0, 0.0,
      2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 2.0, 3.0, 5.0, 2.0, 5.0, 1.0,
      5.0, 5.0, 6.0, 2.0, 4.0, 1.0, 4.0, 6.0, 7.0, 4.0, 2.0, 6.0, 2.0, 2.0, 4.0, 2.0,
      2.0, 1.0, 2.0, 3.0, 0.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10678529820696657
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03951286502733497
    mean_inference_ms: 2.004916710946871
    mean_raw_obs_processing_ms: 0.45202761356190535
time_since_restore: 1044.0681936740875
time_this_iter_s: 10.255786895751953
time_total_s: 1044.0681936740875
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.088
timestamp: 1692342633
timesteps_total: 772300
training_iteration: 102
trial_id: default
train step: 103
agent_timesteps_total: 779600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035650014877319336
  StateBufferConnector_ms: 0.0064013004302978516
  ViewRequirementAgentConnector_ms: 0.21068882942199707
counters:
  num_agent_steps_sampled: 779600
  num_agent_steps_trained: 763000
  num_env_steps_sampled: 779600
  num_env_steps_trained: 763000
  num_samples_added_to_queue: 779500
  num_training_step_calls_since_last_synch_worker_weights: 778
  num_weight_broadcasts: 15263
custom_metrics: {}
date: 2023-08-18_16-10-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.91
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 6091
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.2083808183670044
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -32.455570220947266
        total_loss: -21.363807678222656
        var_gnorm: 63.34205627441406
        vf_explained_var: 0.15876811742782593
        vf_loss: 23.39190673828125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1526.0
  learner_queue:
    size_count: 1531
    size_mean: 14.26
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.9058856209122308
  num_agent_steps_sampled: 779600
  num_agent_steps_trained: 763000
  num_env_steps_sampled: 779600
  num_env_steps_trained: 763000
  num_samples_added_to_queue: 779500
  num_training_step_calls_since_last_synch_worker_weights: 778
  num_weight_broadcasts: 15263
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 486.567
    learner_load_time_ms: 18.26
    learner_load_wait_time_ms: 2.727
iterations_since_restore: 103
node_ip: 127.0.0.1
num_agent_steps_sampled: 779600
num_agent_steps_trained: 763000
num_env_steps_sampled: 779600
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9997737408386
num_env_steps_trained: 763000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9997675419575
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 48.80666666666666
  ram_util_percent: 83.24666666666667
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10684966470124758
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0395268383822689
  mean_inference_ms: 2.0055348118084346
  mean_raw_obs_processing_ms: 0.45208768711435743
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035650014877319336
    StateBufferConnector_ms: 0.0064013004302978516
    ViewRequirementAgentConnector_ms: 0.21068882942199707
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.91
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 2.0, 0.0, 2.0, 3.0, 1.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0,
      3.0, 2.0, 3.0, 5.0, 2.0, 5.0, 1.0, 5.0, 5.0, 6.0, 2.0, 4.0, 1.0, 4.0, 6.0, 7.0,
      4.0, 2.0, 6.0, 2.0, 2.0, 4.0, 2.0, 2.0, 1.0, 2.0, 3.0, 0.0, 5.0, 4.0, 3.0, 5.0,
      3.0, 5.0, 3.0, 1.0, 2.0, 7.0, 3.0, 1.0, 1.0, 5.0, 3.0, 4.0, 2.0, 4.0, 0.0, 5.0,
      1.0, 2.0, 4.0, 1.0, 2.0, 2.0, 5.0, 4.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 3.0,
      8.0, 4.0, 4.0, 4.0, 1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 5.0, 5.0, 2.0,
      2.0, 1.0, 4.0, 3.0, 2.0, 7.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10684966470124758
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0395268383822689
    mean_inference_ms: 2.0055348118084346
    mean_raw_obs_processing_ms: 0.45208768711435743
time_since_restore: 1054.3054356575012
time_this_iter_s: 10.237241983413696
time_total_s: 1054.3054356575012
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692342643
timesteps_total: 779600
training_iteration: 103
trial_id: default
train step: 104
agent_timesteps_total: 786200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.038575172424316406
  StateBufferConnector_ms: 0.006799221038818359
  ViewRequirementAgentConnector_ms: 0.2239983081817627
counters:
  num_agent_steps_sampled: 786200
  num_agent_steps_trained: 769500
  num_env_steps_sampled: 786200
  num_env_steps_trained: 769500
  num_samples_added_to_queue: 786000
  num_training_step_calls_since_last_synch_worker_weights: 434
  num_weight_broadcasts: 15392
custom_metrics: {}
date: 2023-08-18_16-10-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.91
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 6143
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.40000000000009
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1790918111801147
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -3.3479621410369873
        total_loss: 4.082214832305908
        var_gnorm: 63.342262268066406
        vf_explained_var: 0.24685901403427124
        vf_loss: 16.039445877075195
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1539.0
  learner_queue:
    size_count: 1546
    size_mean: 14.14
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.98
  num_agent_steps_sampled: 786200
  num_agent_steps_trained: 769500
  num_env_steps_sampled: 786200
  num_env_steps_trained: 769500
  num_samples_added_to_queue: 786000
  num_training_step_calls_since_last_synch_worker_weights: 434
  num_weight_broadcasts: 15392
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 306.721
    learner_load_time_ms: 18.243
    learner_load_wait_time_ms: 2.827
iterations_since_restore: 104
node_ip: 127.0.0.1
num_agent_steps_sampled: 786200
num_agent_steps_trained: 769500
num_env_steps_sampled: 786200
num_env_steps_sampled_this_iter: 6600
num_env_steps_sampled_throughput_per_sec: 659.9970259800456
num_env_steps_trained: 769500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.997071040954
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 57.32857142857142
  ram_util_percent: 83.09285714285716
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10685622857570841
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039598743079464725
  mean_inference_ms: 2.0074232878577836
  mean_raw_obs_processing_ms: 0.4526237194034596
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.038575172424316406
    StateBufferConnector_ms: 0.006799221038818359
    ViewRequirementAgentConnector_ms: 0.2239983081817627
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.91
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 5.0, 3.0, 4.0, 2.0, 4.0, 0.0, 5.0, 1.0, 2.0, 4.0, 1.0,
      2.0, 2.0, 5.0, 4.0, 2.0, 1.0, 1.0, 4.0, 1.0, 2.0, 2.0, 3.0, 8.0, 4.0, 4.0, 4.0,
      1.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 1.0, 5.0, 5.0, 2.0, 2.0, 1.0, 4.0, 3.0,
      2.0, 7.0, 1.0, 1.0, 4.0, 0.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 3.0, 8.0, 4.0, 1.0,
      2.0, 4.0, 3.0, 0.0, 4.0, 2.0, 2.0, 4.0, 2.0, 5.0, 4.0, 3.0, 3.0, 4.0, 6.0, 4.0,
      4.0, 1.0, 2.0, 6.0, 5.0, 4.0, 3.0, 4.0, 3.0, 2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 0.0,
      3.0, 2.0, 0.0, 6.0, 4.0, 3.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10685622857570841
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039598743079464725
    mean_inference_ms: 2.0074232878577836
    mean_raw_obs_processing_ms: 0.4526237194034596
time_since_restore: 1064.641738653183
time_this_iter_s: 10.336302995681763
time_total_s: 1064.641738653183
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.087
timestamp: 1692342653
timesteps_total: 786200
training_iteration: 104
trial_id: default
train step: 105
agent_timesteps_total: 793600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0365755558013916
  StateBufferConnector_ms: 0.00652003288269043
  ViewRequirementAgentConnector_ms: 0.2153003215789795
counters:
  num_agent_steps_sampled: 793600
  num_agent_steps_trained: 777000
  num_env_steps_sampled: 793600
  num_env_steps_trained: 777000
  num_samples_added_to_queue: 793500
  num_training_step_calls_since_last_synch_worker_weights: 915
  num_weight_broadcasts: 15537
custom_metrics: {}
date: 2023-08-18_16-11-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.06
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 6200
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1746941804885864
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -21.752992630004883
        total_loss: -11.120509147644043
        var_gnorm: 63.342472076416016
        vf_explained_var: 0.1554884910583496
        vf_loss: 22.439661026000977
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1554.0
  learner_queue:
    size_count: 1559
    size_mean: 14.16
    size_quantiles: [9.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 2.013554071784515
  num_agent_steps_sampled: 793600
  num_agent_steps_trained: 777000
  num_env_steps_sampled: 793600
  num_env_steps_trained: 777000
  num_samples_added_to_queue: 793500
  num_training_step_calls_since_last_synch_worker_weights: 915
  num_weight_broadcasts: 15537
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 650.777
    learner_load_time_ms: 18.283
    learner_load_wait_time_ms: 3.15
iterations_since_restore: 105
node_ip: 127.0.0.1
num_agent_steps_sampled: 793600
num_agent_steps_trained: 777000
num_env_steps_sampled: 793600
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9974770631976
num_env_steps_trained: 777000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.997442969457
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.559999999999995
  ram_util_percent: 82.08666666666667
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10696141723070618
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03962997168148084
  mean_inference_ms: 2.008955306497372
  mean_raw_obs_processing_ms: 0.4528300721548371
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0365755558013916
    StateBufferConnector_ms: 0.00652003288269043
    ViewRequirementAgentConnector_ms: 0.2153003215789795
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.06
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 8.0, 4.0, 1.0, 2.0, 4.0, 3.0, 0.0, 4.0, 2.0, 2.0, 4.0, 2.0,
      5.0, 4.0, 3.0, 3.0, 4.0, 6.0, 4.0, 4.0, 1.0, 2.0, 6.0, 5.0, 4.0, 3.0, 4.0, 3.0,
      2.0, 1.0, 3.0, 2.0, 3.0, 2.0, 0.0, 3.0, 2.0, 0.0, 6.0, 4.0, 3.0, 1.0, 4.0, 4.0,
      3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 1.0, 2.0, 2.0, 6.0,
      5.0, 1.0, 5.0, 2.0, 6.0, 2.0, 4.0, 2.0, 3.0, 3.0, 4.0, 4.0, 6.0, 0.0, 2.0, 2.0,
      3.0, 5.0, 3.0, 2.0, 5.0, 5.0, 2.0, 2.0, 2.0, 3.0, 2.0, 4.0, 4.0, 5.0, 1.0, 1.0,
      3.0, 3.0, 4.0, 2.0, 1.0, 6.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10696141723070618
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03962997168148084
    mean_inference_ms: 2.008955306497372
    mean_raw_obs_processing_ms: 0.4528300721548371
time_since_restore: 1074.8664684295654
time_this_iter_s: 10.224729776382446
time_total_s: 1074.8664684295654
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.079
timestamp: 1692342663
timesteps_total: 793600
training_iteration: 105
trial_id: default
train step: 106
agent_timesteps_total: 800800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035138845443725586
  StateBufferConnector_ms: 0.006314754486083984
  ViewRequirementAgentConnector_ms: 0.20955538749694824
counters:
  num_agent_steps_sampled: 800800
  num_agent_steps_trained: 784000
  num_env_steps_sampled: 800800
  num_env_steps_trained: 784000
  num_samples_added_to_queue: 800500
  num_training_step_calls_since_last_synch_worker_weights: 1114
  num_weight_broadcasts: 15678
custom_metrics: {}
date: 2023-08-18_16-11-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 3.04
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 6257
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1804931163787842
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -38.8594970703125
        total_loss: -30.373958587646484
        var_gnorm: 63.34275817871094
        vf_explained_var: 0.2332560420036316
        vf_loss: 18.151569366455078
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1568.0
  learner_queue:
    size_count: 1572
    size_mean: 14.54
    size_quantiles: [9.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.8569868066305695
  num_agent_steps_sampled: 800800
  num_agent_steps_trained: 784000
  num_env_steps_sampled: 800800
  num_env_steps_trained: 784000
  num_samples_added_to_queue: 800500
  num_training_step_calls_since_last_synch_worker_weights: 1114
  num_weight_broadcasts: 15678
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 478.963
    learner_load_time_ms: 18.26
    learner_load_wait_time_ms: 2.796
iterations_since_restore: 106
node_ip: 127.0.0.1
num_agent_steps_sampled: 800800
num_agent_steps_trained: 784000
num_env_steps_sampled: 800800
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 719.9955368318658
num_env_steps_trained: 784000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9956608087585
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 50.14285714285715
  ram_util_percent: 82.85714285714286
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10705133384762874
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03963350678005968
  mean_inference_ms: 2.00953083176404
  mean_raw_obs_processing_ms: 0.4528276908595504
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035138845443725586
    StateBufferConnector_ms: 0.006314754486083984
    ViewRequirementAgentConnector_ms: 0.20955538749694824
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 3.04
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 2.0, 6.0, 5.0, 1.0, 5.0, 2.0, 6.0, 2.0, 4.0, 2.0, 3.0,
      3.0, 4.0, 4.0, 6.0, 0.0, 2.0, 2.0, 3.0, 5.0, 3.0, 2.0, 5.0, 5.0, 2.0, 2.0, 2.0,
      3.0, 2.0, 4.0, 4.0, 5.0, 1.0, 1.0, 3.0, 3.0, 4.0, 2.0, 1.0, 6.0, 1.0, 4.0, 1.0,
      5.0, 5.0, 4.0, 4.0, 2.0, 1.0, 6.0, 2.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 1.0,
      4.0, 3.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 3.0, 3.0, 1.0, 0.0, 6.0, 4.0,
      2.0, 6.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 7.0, 2.0, 5.0, 3.0, 2.0, 6.0, 6.0, 2.0,
      2.0, 4.0, 5.0, 2.0, 4.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10705133384762874
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03963350678005968
    mean_inference_ms: 2.00953083176404
    mean_raw_obs_processing_ms: 0.4528276908595504
time_since_restore: 1085.0572032928467
time_this_iter_s: 10.19073486328125
time_total_s: 1085.0572032928467
timers:
  sample_time_ms: 0.032
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.091
timestamp: 1692342674
timesteps_total: 800800
training_iteration: 106
trial_id: default
train step: 107
agent_timesteps_total: 808100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03565216064453125
  StateBufferConnector_ms: 0.006752729415893555
  ViewRequirementAgentConnector_ms: 0.21671223640441895
counters:
  num_agent_steps_sampled: 808100
  num_agent_steps_trained: 791500
  num_env_steps_sampled: 808100
  num_env_steps_trained: 791500
  num_samples_added_to_queue: 808000
  num_training_step_calls_since_last_synch_worker_weights: 1455
  num_weight_broadcasts: 15820
custom_metrics: {}
date: 2023-08-18_16-11-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.13
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 6314
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1519455909729004
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -0.36981356143951416
        total_loss: 13.833626747131348
        var_gnorm: 63.34300994873047
        vf_explained_var: 0.20722323656082153
        vf_loss: 29.558826446533203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1583.0
  learner_queue:
    size_count: 1587
    size_mean: 14.66
    size_quantiles: [9.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.8067650649710936
  num_agent_steps_sampled: 808100
  num_agent_steps_trained: 791500
  num_env_steps_sampled: 808100
  num_env_steps_trained: 791500
  num_samples_added_to_queue: 808000
  num_training_step_calls_since_last_synch_worker_weights: 1455
  num_weight_broadcasts: 15820
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 455.351
    learner_load_time_ms: 18.292
    learner_load_wait_time_ms: 3.014
iterations_since_restore: 107
node_ip: 127.0.0.1
num_agent_steps_sampled: 808100
num_agent_steps_trained: 791500
num_env_steps_sampled: 808100
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9966583404922
num_env_steps_trained: 791500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9965667881769
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 49.16
  ram_util_percent: 83.08666666666666
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10709109565247037
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0396573751515781
  mean_inference_ms: 2.0102288907786243
  mean_raw_obs_processing_ms: 0.45298978302385406
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03565216064453125
    StateBufferConnector_ms: 0.006752729415893555
    ViewRequirementAgentConnector_ms: 0.21671223640441895
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.13
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 2.0, 1.0, 4.0, 3.0, 2.0, 4.0, 4.0, 3.0, 2.0, 3.0, 2.0,
      3.0, 3.0, 3.0, 1.0, 0.0, 6.0, 4.0, 2.0, 6.0, 3.0, 1.0, 1.0, 2.0, 2.0, 1.0, 7.0,
      2.0, 5.0, 3.0, 2.0, 6.0, 6.0, 2.0, 2.0, 4.0, 5.0, 2.0, 4.0, 3.0, 4.0, 3.0, 4.0,
      4.0, 7.0, 2.0, 4.0, 3.0, 1.0, 3.0, 4.0, 2.0, 8.0, 3.0, 5.0, 1.0, 2.0, 6.0, 6.0,
      3.0, 2.0, 7.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 2.0, 4.0, 4.0, 4.0, 3.0, 3.0,
      4.0, 3.0, 2.0, 3.0, 1.0, 0.0, 4.0, 4.0, 6.0, 3.0, 1.0, 0.0, 1.0, 2.0, 3.0, 8.0,
      5.0, 2.0, 1.0, 4.0, 0.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10709109565247037
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0396573751515781
    mean_inference_ms: 2.0102288907786243
    mean_raw_obs_processing_ms: 0.45298978302385406
time_since_restore: 1095.248199224472
time_this_iter_s: 10.190995931625366
time_total_s: 1095.248199224472
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.086
timestamp: 1692342684
timesteps_total: 808100
training_iteration: 107
trial_id: default
train step: 108
agent_timesteps_total: 816200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03317070007324219
  StateBufferConnector_ms: 0.0060787200927734375
  ViewRequirementAgentConnector_ms: 0.20062971115112305
counters:
  num_agent_steps_sampled: 816200
  num_agent_steps_trained: 799500
  num_env_steps_sampled: 816200
  num_env_steps_trained: 799500
  num_samples_added_to_queue: 816000
  num_training_step_calls_since_last_synch_worker_weights: 533
  num_weight_broadcasts: 15979
custom_metrics: {}
date: 2023-08-18_16-11-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.01
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 6377
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1206637620925903
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 5.217266082763672
        total_loss: 18.097843170166016
        var_gnorm: 63.34321594238281
        vf_explained_var: 0.21970218420028687
        vf_loss: 26.881816864013672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1599.0
  learner_queue:
    size_count: 1604
    size_mean: 15.16
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2387090053761618
  num_agent_steps_sampled: 816200
  num_agent_steps_trained: 799500
  num_env_steps_sampled: 816200
  num_env_steps_trained: 799500
  num_samples_added_to_queue: 816000
  num_training_step_calls_since_last_synch_worker_weights: 533
  num_weight_broadcasts: 15979
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 349.04
    learner_load_time_ms: 18.296
    learner_load_wait_time_ms: 2.873
iterations_since_restore: 108
node_ip: 127.0.0.1
num_agent_steps_sampled: 816200
num_agent_steps_trained: 799500
num_env_steps_sampled: 816200
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9923139347804
num_env_steps_trained: 799500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9924088244745
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.63571428571429
  ram_util_percent: 82.87142857142858
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10713983260124023
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03962068828692404
  mean_inference_ms: 2.009495299717359
  mean_raw_obs_processing_ms: 0.4526605033340417
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03317070007324219
    StateBufferConnector_ms: 0.0060787200927734375
    ViewRequirementAgentConnector_ms: 0.20062971115112305
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.01
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 5.0, 3.0, 3.0, 4.0, 1.0, 3.0, 3.0, 2.0, 4.0, 4.0, 4.0, 3.0,
      3.0, 4.0, 3.0, 2.0, 3.0, 1.0, 0.0, 4.0, 4.0, 6.0, 3.0, 1.0, 0.0, 1.0, 2.0, 3.0,
      8.0, 5.0, 2.0, 1.0, 4.0, 0.0, 2.0, 3.0, 2.0, 4.0, 2.0, 1.0, 5.0, 1.0, 3.0, 2.0,
      2.0, 2.0, 5.0, 3.0, 3.0, 1.0, 5.0, 8.0, 2.0, 5.0, 1.0, 3.0, 3.0, 5.0, 4.0, 4.0,
      3.0, 2.0, 6.0, 6.0, 2.0, 5.0, 5.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0,
      0.0, 3.0, 4.0, 3.0, 5.0, 2.0, 1.0, 4.0, 4.0, 4.0, 5.0, 4.0, 7.0, 5.0, 2.0, 0.0,
      5.0, 4.0, 2.0, 3.0, 0.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10713983260124023
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03962068828692404
    mean_inference_ms: 2.009495299717359
    mean_raw_obs_processing_ms: 0.4526605033340417
time_since_restore: 1105.4749522209167
time_this_iter_s: 10.226752996444702
time_total_s: 1105.4749522209167
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1692342694
timesteps_total: 816200
training_iteration: 108
trial_id: default
train step: 109
agent_timesteps_total: 824400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031240224838256836
  StateBufferConnector_ms: 0.005599021911621094
  ViewRequirementAgentConnector_ms: 0.1869361400604248
counters:
  num_agent_steps_sampled: 824400
  num_agent_steps_trained: 807500
  num_env_steps_sampled: 824400
  num_env_steps_trained: 807500
  num_samples_added_to_queue: 824000
  num_training_step_calls_since_last_synch_worker_weights: 1086
  num_weight_broadcasts: 16139
custom_metrics: {}
date: 2023-08-18_16-11-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.91
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 6441
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1703284978866577
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -5.405202865600586
        total_loss: 4.112714767456055
        var_gnorm: 63.343536376953125
        vf_explained_var: 0.2646421790122986
        vf_loss: 20.20616340637207
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1615.0
  learner_queue:
    size_count: 1619
    size_mean: 15.16
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2387090053761618
  num_agent_steps_sampled: 824400
  num_agent_steps_trained: 807500
  num_env_steps_sampled: 824400
  num_env_steps_trained: 807500
  num_samples_added_to_queue: 824000
  num_training_step_calls_since_last_synch_worker_weights: 1086
  num_weight_broadcasts: 16139
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 435.221
    learner_load_time_ms: 18.297
    learner_load_wait_time_ms: 2.597
iterations_since_restore: 109
node_ip: 127.0.0.1
num_agent_steps_sampled: 824400
num_agent_steps_trained: 807500
num_env_steps_sampled: 824400
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.993685294143
num_env_steps_trained: 807500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.993839311359
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 47.60714285714287
  ram_util_percent: 82.73571428571428
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10713072730620687
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03955370826787305
  mean_inference_ms: 2.0077964614584456
  mean_raw_obs_processing_ms: 0.45211347056108936
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031240224838256836
    StateBufferConnector_ms: 0.005599021911621094
    ViewRequirementAgentConnector_ms: 0.1869361400604248
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.91
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 2.0, 5.0, 5.0, 1.0, 2.0, 1.0, 2.0, 1.0, 1.0, 3.0, 0.0, 3.0,
      0.0, 3.0, 4.0, 3.0, 5.0, 2.0, 1.0, 4.0, 4.0, 4.0, 5.0, 4.0, 7.0, 5.0, 2.0, 0.0,
      5.0, 4.0, 2.0, 3.0, 0.0, 2.0, 2.0, 4.0, 3.0, 5.0, 4.0, 1.0, 4.0, 5.0, 1.0, 1.0,
      5.0, 3.0, 2.0, 1.0, 4.0, 3.0, 4.0, 5.0, 0.0, 5.0, 2.0, 1.0, 2.0, 3.0, 1.0, 3.0,
      0.0, 4.0, 4.0, 3.0, 1.0, 3.0, 4.0, 3.0, 2.0, 5.0, 1.0, 1.0, 6.0, 8.0, 3.0, 1.0,
      3.0, 4.0, 4.0, 1.0, 5.0, 1.0, 3.0, 1.0, 5.0, 2.0, 5.0, 1.0, 3.0, 0.0, 1.0, 3.0,
      4.0, 4.0, 6.0, 1.0, 4.0, 2.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10713072730620687
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03955370826787305
    mean_inference_ms: 2.0077964614584456
    mean_raw_obs_processing_ms: 0.45211347056108936
time_since_restore: 1115.6267981529236
time_this_iter_s: 10.151845932006836
time_total_s: 1115.6267981529236
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342704
timesteps_total: 824400
training_iteration: 109
trial_id: default
train step: 110
agent_timesteps_total: 832400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03172445297241211
  StateBufferConnector_ms: 0.0057294368743896484
  ViewRequirementAgentConnector_ms: 0.18876934051513672
counters:
  num_agent_steps_sampled: 832400
  num_agent_steps_trained: 815500
  num_env_steps_sampled: 832400
  num_env_steps_trained: 815500
  num_samples_added_to_queue: 832000
  num_training_step_calls_since_last_synch_worker_weights: 747
  num_weight_broadcasts: 16295
custom_metrics: {}
date: 2023-08-18_16-11-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.88
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 6504
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.170182228088379
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 5.574981212615967
        total_loss: 21.150341033935547
        var_gnorm: 63.343868255615234
        vf_explained_var: 0.15713030099868774
        vf_loss: 32.320899963378906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1631.0
  learner_queue:
    size_count: 1636
    size_mean: 15.18
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.2913558765886342
  num_agent_steps_sampled: 832400
  num_agent_steps_trained: 815500
  num_env_steps_sampled: 832400
  num_env_steps_trained: 815500
  num_samples_added_to_queue: 832000
  num_training_step_calls_since_last_synch_worker_weights: 747
  num_weight_broadcasts: 16295
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 424.805
    learner_load_time_ms: 18.252
    learner_load_wait_time_ms: 2.904
iterations_since_restore: 110
node_ip: 127.0.0.1
num_agent_steps_sampled: 832400
num_agent_steps_trained: 815500
num_env_steps_sampled: 832400
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9951172173021
num_env_steps_trained: 815500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9951172173021
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.319999999999986
  ram_util_percent: 82.60000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10708488604681293
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03951160554993134
  mean_inference_ms: 2.006503950635611
  mean_raw_obs_processing_ms: 0.4517874050828536
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03172445297241211
    StateBufferConnector_ms: 0.0057294368743896484
    ViewRequirementAgentConnector_ms: 0.18876934051513672
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.88
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 1.0, 3.0, 4.0, 3.0, 2.0, 5.0, 1.0, 1.0, 6.0, 8.0, 3.0,
      1.0, 3.0, 4.0, 4.0, 1.0, 5.0, 1.0, 3.0, 1.0, 5.0, 2.0, 5.0, 1.0, 3.0, 0.0, 1.0,
      3.0, 4.0, 4.0, 6.0, 1.0, 4.0, 2.0, 4.0, 3.0, 3.0, 4.0, 3.0, 6.0, 1.0, 1.0, 2.0,
      1.0, 4.0, 0.0, 1.0, 1.0, 3.0, 4.0, 1.0, 5.0, 5.0, 1.0, 1.0, 2.0, 2.0, 4.0, 3.0,
      1.0, 3.0, 2.0, 0.0, 6.0, 3.0, 2.0, 2.0, 4.0, 3.0, 3.0, 2.0, 3.0, 6.0, 5.0, 1.0,
      2.0, 1.0, 4.0, 2.0, 6.0, 3.0, 2.0, 3.0, 2.0, 2.0, 5.0, 4.0, 1.0, 2.0, 7.0, 4.0,
      1.0, 1.0, 5.0, 2.0, 1.0, 2.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10708488604681293
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03951160554993134
    mean_inference_ms: 2.006503950635611
    mean_raw_obs_processing_ms: 0.4517874050828536
time_since_restore: 1125.865149974823
time_this_iter_s: 10.238351821899414
time_total_s: 1125.865149974823
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.086
timestamp: 1692342715
timesteps_total: 832400
training_iteration: 110
trial_id: default
train step: 111
agent_timesteps_total: 839700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03520035743713379
  StateBufferConnector_ms: 0.006431102752685547
  ViewRequirementAgentConnector_ms: 0.20857977867126465
counters:
  num_agent_steps_sampled: 839700
  num_agent_steps_trained: 823000
  num_env_steps_sampled: 839700
  num_env_steps_trained: 823000
  num_samples_added_to_queue: 839500
  num_training_step_calls_since_last_synch_worker_weights: 302
  num_weight_broadcasts: 16437
custom_metrics: {}
date: 2023-08-18_16-12-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 2.92
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 6561
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1620080471038818
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 5.745669364929199
        total_loss: 17.571264266967773
        var_gnorm: 63.3442268371582
        vf_explained_var: 0.21671396493911743
        vf_loss: 24.813194274902344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1646.0
  learner_queue:
    size_count: 1653
    size_mean: 14.86
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6493635136015348
  num_agent_steps_sampled: 839700
  num_agent_steps_trained: 823000
  num_env_steps_sampled: 839700
  num_env_steps_trained: 823000
  num_samples_added_to_queue: 839500
  num_training_step_calls_since_last_synch_worker_weights: 302
  num_weight_broadcasts: 16437
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 274.157
    learner_load_time_ms: 18.257
    learner_load_wait_time_ms: 2.831
iterations_since_restore: 111
node_ip: 127.0.0.1
num_agent_steps_sampled: 839700
num_agent_steps_trained: 823000
num_env_steps_sampled: 839700
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9974589436291
num_env_steps_trained: 823000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9973893256464
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.64285714285715
  ram_util_percent: 82.81428571428572
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1069862770188545
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0395487398244055
  mean_inference_ms: 2.0067824198470188
  mean_raw_obs_processing_ms: 0.45209224575937446
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03520035743713379
    StateBufferConnector_ms: 0.006431102752685547
    ViewRequirementAgentConnector_ms: 0.20857977867126465
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 2.92
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 4.0, 3.0, 1.0, 3.0, 2.0, 0.0, 6.0, 3.0, 2.0, 2.0, 4.0,
      3.0, 3.0, 2.0, 3.0, 6.0, 5.0, 1.0, 2.0, 1.0, 4.0, 2.0, 6.0, 3.0, 2.0, 3.0, 2.0,
      2.0, 5.0, 4.0, 1.0, 2.0, 7.0, 4.0, 1.0, 1.0, 5.0, 2.0, 1.0, 2.0, 7.0, 2.0, 1.0,
      1.0, 3.0, 3.0, 6.0, 4.0, 6.0, 2.0, 1.0, 4.0, 6.0, 4.0, 2.0, 2.0, 3.0, 2.0, 1.0,
      5.0, 1.0, 3.0, 2.0, 0.0, 6.0, 4.0, 7.0, 4.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0,
      5.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0, 6.0, 2.0, 2.0, 3.0, 2.0, 6.0, 0.0, 3.0,
      3.0, 2.0, 3.0, 1.0, 2.0, 5.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1069862770188545
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0395487398244055
    mean_inference_ms: 2.0067824198470188
    mean_raw_obs_processing_ms: 0.45209224575937446
time_since_restore: 1136.1985659599304
time_this_iter_s: 10.333415985107422
time_total_s: 1136.1985659599304
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692342725
timesteps_total: 839700
training_iteration: 111
trial_id: default
train step: 112
agent_timesteps_total: 846900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03667879104614258
  StateBufferConnector_ms: 0.006765127182006836
  ViewRequirementAgentConnector_ms: 0.21816372871398926
counters:
  num_agent_steps_sampled: 846900
  num_agent_steps_trained: 830000
  num_env_steps_sampled: 846900
  num_env_steps_trained: 830000
  num_samples_added_to_queue: 846500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 16578
custom_metrics: {}
date: 2023-08-18_16-12-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.07
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 6617
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.136010766029358
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -40.681243896484375
        total_loss: -33.78921127319336
        var_gnorm: 63.3445930480957
        vf_explained_var: 0.18015354871749878
        vf_loss: 14.920076370239258
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1660.0
  learner_queue:
    size_count: 1667
    size_mean: 14.58
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.8340119955987202
  num_agent_steps_sampled: 846900
  num_agent_steps_trained: 830000
  num_env_steps_sampled: 846900
  num_env_steps_trained: 830000
  num_samples_added_to_queue: 846500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 16578
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 282.278
    learner_load_time_ms: 2.732
    learner_load_wait_time_ms: 2.481
iterations_since_restore: 112
node_ip: 127.0.0.1
num_agent_steps_sampled: 846900
num_agent_steps_trained: 830000
num_env_steps_sampled: 846900
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 719.8494844441753
num_env_steps_trained: 830000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.8536654318372
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 57.89999999999999
  ram_util_percent: 83.70666666666665
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10693463514977712
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03960500083709487
  mean_inference_ms: 2.0078527113980966
  mean_raw_obs_processing_ms: 0.452552291484934
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03667879104614258
    StateBufferConnector_ms: 0.006765127182006836
    ViewRequirementAgentConnector_ms: 0.21816372871398926
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.07
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 2.0, 3.0, 2.0, 1.0, 5.0, 1.0, 3.0, 2.0, 0.0, 6.0, 4.0, 7.0,
      4.0, 3.0, 4.0, 2.0, 3.0, 2.0, 2.0, 4.0, 5.0, 2.0, 1.0, 2.0, 1.0, 2.0, 3.0, 2.0,
      6.0, 2.0, 2.0, 3.0, 2.0, 6.0, 0.0, 3.0, 3.0, 2.0, 3.0, 1.0, 2.0, 5.0, 3.0, 6.0,
      1.0, 2.0, 6.0, 1.0, 0.0, 1.0, 4.0, 3.0, 3.0, 3.0, 3.0, 2.0, 6.0, 3.0, 3.0, 1.0,
      2.0, 5.0, 4.0, 2.0, 2.0, 6.0, 3.0, 8.0, 1.0, 0.0, 3.0, 2.0, 2.0, 4.0, 6.0, 3.0,
      7.0, 6.0, 5.0, 4.0, 3.0, 4.0, 2.0, 4.0, 0.0, 5.0, 4.0, 3.0, 4.0, 0.0, 5.0, 6.0,
      4.0, 3.0, 3.0, 5.0, 2.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10693463514977712
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03960500083709487
    mean_inference_ms: 2.0078527113980966
    mean_raw_obs_processing_ms: 0.452552291484934
time_since_restore: 1146.4411430358887
time_this_iter_s: 10.242577075958252
time_total_s: 1146.4411430358887
timers:
  sample_time_ms: 0.15
  synch_weights_time_ms: 0.787
  training_iteration_time_ms: 1.107
timestamp: 1692342735
timesteps_total: 846900
training_iteration: 112
trial_id: default
train step: 113
agent_timesteps_total: 854000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035347938537597656
  StateBufferConnector_ms: 0.0065538883209228516
  ViewRequirementAgentConnector_ms: 0.2130751609802246
counters:
  num_agent_steps_sampled: 854000
  num_agent_steps_trained: 837500
  num_env_steps_sampled: 854000
  num_env_steps_trained: 837500
  num_samples_added_to_queue: 854000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 16717
custom_metrics: {}
date: 2023-08-18_16-12-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.45
episode_reward_min: 0.0
episodes_this_iter: 55
episodes_total: 6672
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1658059358596802
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 25.32762908935547
        total_loss: 43.51387405395508
        var_gnorm: 63.344886779785156
        vf_explained_var: 0.2012237310409546
        vf_loss: 37.53830337524414
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1675.0
  learner_queue:
    size_count: 1677
    size_mean: 14.56
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.8456435192094927
  num_agent_steps_sampled: 854000
  num_agent_steps_trained: 837500
  num_env_steps_sampled: 854000
  num_env_steps_trained: 837500
  num_samples_added_to_queue: 854000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 16717
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 981.708
    learner_load_time_ms: 2.732
    learner_load_wait_time_ms: 29.481
iterations_since_restore: 113
node_ip: 127.0.0.1
num_agent_steps_sampled: 854000
num_agent_steps_trained: 837500
num_env_steps_sampled: 854000
num_env_steps_sampled_this_iter: 7100
num_env_steps_sampled_throughput_per_sec: 709.0781299965688
num_env_steps_trained: 837500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.0261936583473
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 50.58571428571428
  ram_util_percent: 83.76428571428572
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10698783637185011
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03962848465277417
  mean_inference_ms: 2.008803098314648
  mean_raw_obs_processing_ms: 0.45275169300707074
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035347938537597656
    StateBufferConnector_ms: 0.0065538883209228516
    ViewRequirementAgentConnector_ms: 0.2130751609802246
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.45
  episode_reward_min: 0.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 6.0, 3.0, 3.0, 1.0, 2.0, 5.0, 4.0, 2.0, 2.0, 6.0, 3.0,
      8.0, 1.0, 0.0, 3.0, 2.0, 2.0, 4.0, 6.0, 3.0, 7.0, 6.0, 5.0, 4.0, 3.0, 4.0, 2.0,
      4.0, 0.0, 5.0, 4.0, 3.0, 4.0, 0.0, 5.0, 6.0, 4.0, 3.0, 3.0, 5.0, 2.0, 2.0, 2.0,
      4.0, 4.0, 4.0, 5.0, 1.0, 2.0, 3.0, 3.0, 5.0, 6.0, 6.0, 4.0, 3.0, 4.0, 6.0, 2.0,
      5.0, 3.0, 2.0, 5.0, 2.0, 5.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 6.0,
      3.0, 1.0, 3.0, 4.0, 7.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0,
      3.0, 5.0, 4.0, 1.0, 2.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10698783637185011
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03962848465277417
    mean_inference_ms: 2.008803098314648
    mean_raw_obs_processing_ms: 0.45275169300707074
time_since_restore: 1156.5702950954437
time_this_iter_s: 10.129152059555054
time_total_s: 1156.5702950954437
timers:
  sample_time_ms: 0.081
  synch_weights_time_ms: 0.819
  training_iteration_time_ms: 3.955
timestamp: 1692342745
timesteps_total: 854000
training_iteration: 113
trial_id: default
train step: 114
agent_timesteps_total: 862150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03229570388793945
  StateBufferConnector_ms: 0.0060672760009765625
  ViewRequirementAgentConnector_ms: 0.196638822555542
counters:
  num_agent_steps_sampled: 862150
  num_agent_steps_trained: 845500
  num_env_steps_sampled: 862150
  num_env_steps_trained: 845500
  num_samples_added_to_queue: 862000
  num_training_step_calls_since_last_synch_worker_weights: 291
  num_weight_broadcasts: 16878
custom_metrics: {}
date: 2023-08-18_16-12-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.24
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 6736
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1081767082214355
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 7.490817070007324
        total_loss: 22.897605895996094
        var_gnorm: 63.34521484375
        vf_explained_var: 0.21530991792678833
        vf_loss: 31.921756744384766
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1691.0
  learner_queue:
    size_count: 1697
    size_mean: 14.54
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.87840357750937
  num_agent_steps_sampled: 862150
  num_agent_steps_trained: 845500
  num_env_steps_sampled: 862150
  num_env_steps_trained: 845500
  num_samples_added_to_queue: 862000
  num_training_step_calls_since_last_synch_worker_weights: 291
  num_weight_broadcasts: 16878
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 274.011
    learner_load_time_ms: 2.491
    learner_load_wait_time_ms: 2.615
iterations_since_restore: 114
node_ip: 127.0.0.1
num_agent_steps_sampled: 862150
num_agent_steps_trained: 845500
num_env_steps_sampled: 862150
num_env_steps_sampled_this_iter: 8150
num_env_steps_sampled_throughput_per_sec: 814.9992033250967
num_env_steps_trained: 845500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.999217987825
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.378571428571426
  ram_util_percent: 83.2
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1070658486662936
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039582877586311946
  mean_inference_ms: 2.008131489673345
  mean_raw_obs_processing_ms: 0.4523769353000182
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03229570388793945
    StateBufferConnector_ms: 0.0060672760009765625
    ViewRequirementAgentConnector_ms: 0.196638822555542
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.24
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 2.0, 5.0, 3.0, 4.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 6.0,
      3.0, 1.0, 3.0, 4.0, 7.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 3.0, 5.0, 5.0,
      3.0, 5.0, 4.0, 1.0, 2.0, 3.0, 3.0, 2.0, 2.0, 2.0, 4.0, 0.0, 3.0, 2.0, 5.0, 2.0,
      4.0, 1.0, 0.0, 2.0, 3.0, 7.0, 1.0, 4.0, 3.0, 1.0, 3.0, 5.0, 2.0, 3.0, 4.0, 4.0,
      2.0, 2.0, 5.0, 3.0, 4.0, 0.0, 5.0, 2.0, 2.0, 6.0, 3.0, 6.0, 3.0, 6.0, 5.0, 3.0,
      2.0, 0.0, 2.0, 5.0, 2.0, 6.0, 3.0, 3.0, 2.0, 1.0, 4.0, 4.0, 6.0, 4.0, 2.0, 7.0,
      3.0, 5.0, 10.0, 2.0, 3.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1070658486662936
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039582877586311946
    mean_inference_ms: 2.008131489673345
    mean_raw_obs_processing_ms: 0.4523769353000182
time_since_restore: 1166.8067841529846
time_this_iter_s: 10.236489057540894
time_total_s: 1166.8067841529846
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692342756
timesteps_total: 862150
training_iteration: 114
trial_id: default
train step: 115
agent_timesteps_total: 869950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031494140625
  StateBufferConnector_ms: 0.0058252811431884766
  ViewRequirementAgentConnector_ms: 0.1911153793334961
counters:
  num_agent_steps_sampled: 869950
  num_agent_steps_trained: 853000
  num_env_steps_sampled: 869950
  num_env_steps_trained: 853000
  num_samples_added_to_queue: 869500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 17031
custom_metrics: {}
date: 2023-08-18_16-12-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.45
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 6796
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1229065656661987
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 0.7452850341796875
        total_loss: 12.932849884033203
        var_gnorm: 63.3455696105957
        vf_explained_var: 0.23365414142608643
        vf_loss: 25.498035430908203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1706.0
  learner_queue:
    size_count: 1712
    size_mean: 14.68
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7825823964125753
  num_agent_steps_sampled: 869950
  num_agent_steps_trained: 853000
  num_env_steps_sampled: 869950
  num_env_steps_trained: 853000
  num_samples_added_to_queue: 869500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 17031
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 350.119
    learner_load_time_ms: 2.518
    learner_load_wait_time_ms: 2.789
iterations_since_restore: 115
node_ip: 127.0.0.1
num_agent_steps_sampled: 869950
num_agent_steps_trained: 853000
num_env_steps_sampled: 869950
num_env_steps_sampled_this_iter: 7800
num_env_steps_sampled_throughput_per_sec: 779.5961040653863
num_env_steps_trained: 853000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.6116385244098
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.98
  ram_util_percent: 83.32666666666665
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10707192567611556
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03954406301729937
  mean_inference_ms: 2.007298086036051
  mean_raw_obs_processing_ms: 0.4520465394336327
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031494140625
    StateBufferConnector_ms: 0.0058252811431884766
    ViewRequirementAgentConnector_ms: 0.1911153793334961
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.45
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 2.0, 2.0, 5.0, 3.0, 4.0, 0.0, 5.0, 2.0, 2.0, 6.0, 3.0, 6.0,
      3.0, 6.0, 5.0, 3.0, 2.0, 0.0, 2.0, 5.0, 2.0, 6.0, 3.0, 3.0, 2.0, 1.0, 4.0, 4.0,
      6.0, 4.0, 2.0, 7.0, 3.0, 5.0, 10.0, 2.0, 3.0, 2.0, 1.0, 5.0, 3.0, 4.0, 4.0,
      1.0, 3.0, 2.0, 3.0, 3.0, 2.0, 3.0, 3.0, 5.0, 5.0, 5.0, 2.0, 7.0, 3.0, 4.0, 1.0,
      1.0, 6.0, 2.0, 9.0, 3.0, 1.0, 3.0, 2.0, 5.0, 6.0, 1.0, 4.0, 7.0, 4.0, 1.0, 2.0,
      3.0, 0.0, 5.0, 4.0, 6.0, 2.0, 2.0, 3.0, 5.0, 4.0, 4.0, 3.0, 4.0, 5.0, 3.0, 1.0,
      3.0, 0.0, 7.0, 1.0, 2.0, 7.0, 2.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10707192567611556
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03954406301729937
    mean_inference_ms: 2.007298086036051
    mean_raw_obs_processing_ms: 0.4520465394336327
time_since_restore: 1177.070480108261
time_this_iter_s: 10.26369595527649
time_total_s: 1177.070480108261
timers:
  sample_time_ms: 0.06
  synch_weights_time_ms: 0.447
  training_iteration_time_ms: 0.608
timestamp: 1692342766
timesteps_total: 869950
training_iteration: 115
trial_id: default
train step: 116
agent_timesteps_total: 877300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03403806686401367
  StateBufferConnector_ms: 0.0062694549560546875
  ViewRequirementAgentConnector_ms: 0.2067115306854248
counters:
  num_agent_steps_sampled: 877300
  num_agent_steps_trained: 860500
  num_env_steps_sampled: 877300
  num_env_steps_trained: 860500
  num_samples_added_to_queue: 877000
  num_training_step_calls_since_last_synch_worker_weights: 1042
  num_weight_broadcasts: 17176
custom_metrics: {}
date: 2023-08-18_16-12-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.2
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 6854
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1274659633636475
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 21.531940460205078
        total_loss: 40.11259841918945
        var_gnorm: 63.34584426879883
        vf_explained_var: 0.19764482975006104
        vf_loss: 38.28878402709961
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1721.0
  learner_queue:
    size_count: 1725
    size_mean: 14.94
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.541557653803451
  num_agent_steps_sampled: 877300
  num_agent_steps_trained: 860500
  num_env_steps_sampled: 877300
  num_env_steps_trained: 860500
  num_samples_added_to_queue: 877000
  num_training_step_calls_since_last_synch_worker_weights: 1042
  num_weight_broadcasts: 17176
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 570.448
    learner_load_time_ms: 2.518
    learner_load_wait_time_ms: 2.846
iterations_since_restore: 116
node_ip: 127.0.0.1
num_agent_steps_sampled: 877300
num_agent_steps_trained: 860500
num_env_steps_sampled: 877300
num_env_steps_sampled_this_iter: 7350
num_env_steps_sampled_throughput_per_sec: 734.9976342992633
num_env_steps_trained: 860500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9975860196564
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.34285714285714
  ram_util_percent: 82.78571428571429
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10699355512645191
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03956549421336244
  mean_inference_ms: 2.0074594558223575
  mean_raw_obs_processing_ms: 0.4522391345577764
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03403806686401367
    StateBufferConnector_ms: 0.0062694549560546875
    ViewRequirementAgentConnector_ms: 0.2067115306854248
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.2
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 1.0, 1.0, 6.0, 2.0, 9.0, 3.0, 1.0, 3.0, 2.0, 5.0, 6.0, 1.0,
      4.0, 7.0, 4.0, 1.0, 2.0, 3.0, 0.0, 5.0, 4.0, 6.0, 2.0, 2.0, 3.0, 5.0, 4.0, 4.0,
      3.0, 4.0, 5.0, 3.0, 1.0, 3.0, 0.0, 7.0, 1.0, 2.0, 7.0, 2.0, 4.0, 3.0, 4.0, 1.0,
      5.0, 4.0, 0.0, 1.0, 3.0, 6.0, 3.0, 1.0, 7.0, 2.0, 1.0, 3.0, 3.0, 3.0, 6.0, 10.0,
      3.0, 4.0, 4.0, 4.0, 1.0, 4.0, 3.0, 2.0, 1.0, 5.0, 3.0, 3.0, 5.0, 5.0, 2.0, 1.0,
      2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 6.0, 4.0, 3.0, 2.0, 2.0, 3.0, 3.0, 2.0,
      1.0, 1.0, 1.0, 4.0, 4.0, 6.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10699355512645191
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03956549421336244
    mean_inference_ms: 2.0074594558223575
    mean_raw_obs_processing_ms: 0.4522391345577764
time_since_restore: 1187.2473788261414
time_this_iter_s: 10.176898717880249
time_total_s: 1187.2473788261414
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692342776
timesteps_total: 877300
training_iteration: 116
trial_id: default
train step: 117
agent_timesteps_total: 884900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03398299217224121
  StateBufferConnector_ms: 0.006164073944091797
  ViewRequirementAgentConnector_ms: 0.20720481872558594
counters:
  num_agent_steps_sampled: 884900
  num_agent_steps_trained: 868000
  num_env_steps_sampled: 884900
  num_env_steps_trained: 868000
  num_samples_added_to_queue: 884500
  num_training_step_calls_since_last_synch_worker_weights: 310
  num_weight_broadcasts: 17325
custom_metrics: {}
date: 2023-08-18_16-13-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 2.98
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 6914
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1411694288253784
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -17.31845474243164
        total_loss: -6.447146892547607
        var_gnorm: 63.34632873535156
        vf_explained_var: 0.23680061101913452
        vf_loss: 22.883785247802734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1736.0
  learner_queue:
    size_count: 1742
    size_mean: 14.6
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6733200530681513
  num_agent_steps_sampled: 884900
  num_agent_steps_trained: 868000
  num_env_steps_sampled: 884900
  num_env_steps_trained: 868000
  num_samples_added_to_queue: 884500
  num_training_step_calls_since_last_synch_worker_weights: 310
  num_weight_broadcasts: 17325
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 328.237
    learner_load_time_ms: 15.726
    learner_load_wait_time_ms: 2.895
iterations_since_restore: 117
node_ip: 127.0.0.1
num_agent_steps_sampled: 884900
num_agent_steps_trained: 868000
num_env_steps_sampled: 884900
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9920998440854
num_env_steps_trained: 868000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9922037935054
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.720000000000006
  ram_util_percent: 81.7
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10699110049338095
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039560488294443176
  mean_inference_ms: 2.0075415393452922
  mean_raw_obs_processing_ms: 0.4523496868968833
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03398299217224121
    StateBufferConnector_ms: 0.006164073944091797
    ViewRequirementAgentConnector_ms: 0.20720481872558594
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 2.98
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [10.0, 3.0, 4.0, 4.0, 4.0, 1.0, 4.0, 3.0, 2.0, 1.0, 5.0, 3.0,
      3.0, 5.0, 5.0, 2.0, 1.0, 2.0, 2.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 6.0, 4.0, 3.0,
      2.0, 2.0, 3.0, 3.0, 2.0, 1.0, 1.0, 1.0, 4.0, 4.0, 6.0, 2.0, 2.0, 2.0, 2.0, 3.0,
      3.0, 2.0, 3.0, 4.0, 4.0, 3.0, 5.0, 1.0, 2.0, 4.0, 5.0, 2.0, 5.0, 6.0, 4.0, 3.0,
      0.0, 3.0, 5.0, 3.0, 1.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 2.0, 2.0, 1.0, 3.0, 5.0,
      5.0, 2.0, 2.0, 1.0, 4.0, 4.0, 0.0, 4.0, 2.0, 2.0, 1.0, 3.0, 2.0, 1.0, 1.0, 4.0,
      3.0, 5.0, 3.0, 4.0, 3.0, 6.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10699110049338095
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039560488294443176
    mean_inference_ms: 2.0075415393452922
    mean_raw_obs_processing_ms: 0.4523496868968833
time_since_restore: 1197.5094630718231
time_this_iter_s: 10.262084245681763
time_total_s: 1197.5094630718231
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1692342786
timesteps_total: 884900
training_iteration: 117
trial_id: default
train step: 118
agent_timesteps_total: 892650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03273153305053711
  StateBufferConnector_ms: 0.005860328674316406
  ViewRequirementAgentConnector_ms: 0.19832515716552734
counters:
  num_agent_steps_sampled: 892650
  num_agent_steps_trained: 876000
  num_env_steps_sampled: 892650
  num_env_steps_trained: 876000
  num_samples_added_to_queue: 892500
  num_training_step_calls_since_last_synch_worker_weights: 4
  num_weight_broadcasts: 17477
custom_metrics: {}
date: 2023-08-18_16-13-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 2.92
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 6974
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1098244190216064
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -36.633602142333984
        total_loss: -29.851797103881836
        var_gnorm: 63.34672164916992
        vf_explained_var: 0.22415536642074585
        vf_loss: 14.673434257507324
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1752.0
  learner_queue:
    size_count: 1759
    size_mean: 14.5
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.8027756377319946
  num_agent_steps_sampled: 892650
  num_agent_steps_trained: 876000
  num_env_steps_sampled: 892650
  num_env_steps_trained: 876000
  num_samples_added_to_queue: 892500
  num_training_step_calls_since_last_synch_worker_weights: 4
  num_weight_broadcasts: 17477
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 233.665
    learner_load_time_ms: 16.026
    learner_load_wait_time_ms: 2.632
iterations_since_restore: 118
node_ip: 127.0.0.1
num_agent_steps_sampled: 892650
num_agent_steps_trained: 876000
num_env_steps_sampled: 892650
num_env_steps_sampled_this_iter: 7750
num_env_steps_sampled_throughput_per_sec: 774.9962675751198
num_env_steps_trained: 876000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9961471743171
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 56.45714285714286
  ram_util_percent: 81.78571428571429
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10698834510075779
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039535160593454875
  mean_inference_ms: 2.0071854819177837
  mean_raw_obs_processing_ms: 0.4523088138503256
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03273153305053711
    StateBufferConnector_ms: 0.005860328674316406
    ViewRequirementAgentConnector_ms: 0.19832515716552734
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 2.92
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 3.0, 5.0, 3.0, 1.0, 0.0, 3.0, 2.0, 3.0, 4.0, 4.0, 2.0, 2.0,
      1.0, 3.0, 5.0, 5.0, 2.0, 2.0, 1.0, 4.0, 4.0, 0.0, 4.0, 2.0, 2.0, 1.0, 3.0, 2.0,
      1.0, 1.0, 4.0, 3.0, 5.0, 3.0, 4.0, 3.0, 6.0, 3.0, 5.0, 5.0, 0.0, 5.0, 5.0, 3.0,
      4.0, 3.0, 6.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 1.0, 8.0, 1.0, 8.0, 5.0, 3.0, 3.0,
      3.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0,
      4.0, 3.0, 2.0, 1.0, 2.0, 3.0, 5.0, 2.0, 1.0, 5.0, 2.0, 3.0, 2.0, 5.0, 6.0, 2.0,
      0.0, 4.0, 4.0, 3.0, 2.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10698834510075779
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039535160593454875
    mean_inference_ms: 2.0071854819177837
    mean_raw_obs_processing_ms: 0.4523088138503256
time_since_restore: 1207.758250951767
time_this_iter_s: 10.248787879943848
time_total_s: 1207.758250951767
timers:
  sample_time_ms: 0.09
  synch_weights_time_ms: 0.357
  training_iteration_time_ms: 0.562
timestamp: 1692342797
timesteps_total: 892650
training_iteration: 118
trial_id: default
train step: 119
agent_timesteps_total: 901050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030700206756591797
  StateBufferConnector_ms: 0.005498409271240234
  ViewRequirementAgentConnector_ms: 0.18486499786376953
counters:
  num_agent_steps_sampled: 901050
  num_agent_steps_trained: 884500
  num_env_steps_sampled: 901050
  num_env_steps_trained: 884500
  num_samples_added_to_queue: 901000
  num_training_step_calls_since_last_synch_worker_weights: 679
  num_weight_broadcasts: 17642
custom_metrics: {}
date: 2023-08-18_16-13-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.06
episode_reward_min: 0.0
episodes_this_iter: 66
episodes_total: 7040
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1062304973602295
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 9.196928977966309
        total_loss: 22.774757385253906
        var_gnorm: 63.34713363647461
        vf_explained_var: 0.2284054160118103
        vf_loss: 28.261890411376953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1769.0
  learner_queue:
    size_count: 1773
    size_mean: 14.6
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7435595774162693
  num_agent_steps_sampled: 901050
  num_agent_steps_trained: 884500
  num_env_steps_sampled: 901050
  num_env_steps_trained: 884500
  num_samples_added_to_queue: 901000
  num_training_step_calls_since_last_synch_worker_weights: 679
  num_weight_broadcasts: 17642
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 420.113
    learner_load_time_ms: 16.421
    learner_load_wait_time_ms: 2.996
iterations_since_restore: 119
node_ip: 127.0.0.1
num_agent_steps_sampled: 901050
num_agent_steps_trained: 884500
num_env_steps_sampled: 901050
num_env_steps_sampled_this_iter: 8400
num_env_steps_sampled_throughput_per_sec: 839.9928703913246
num_env_steps_trained: 884500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9927855150307
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 48.57142857142857
  ram_util_percent: 81.81428571428572
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1069862475926726
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0394715181972423
  mean_inference_ms: 2.0056578709856447
  mean_raw_obs_processing_ms: 0.4518014808690674
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030700206756591797
    StateBufferConnector_ms: 0.005498409271240234
    ViewRequirementAgentConnector_ms: 0.18486499786376953
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.06
  episode_reward_min: 0.0
  episodes_this_iter: 66
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 4.0, 2.0, 3.0, 1.0, 3.0, 4.0, 3.0, 2.0, 2.0, 3.0, 4.0, 3.0,
      2.0, 1.0, 2.0, 3.0, 5.0, 2.0, 1.0, 5.0, 2.0, 3.0, 2.0, 5.0, 6.0, 2.0, 0.0, 4.0,
      4.0, 3.0, 2.0, 2.0, 1.0, 5.0, 4.0, 1.0, 4.0, 1.0, 2.0, 7.0, 10.0, 1.0, 3.0,
      5.0, 3.0, 4.0, 4.0, 1.0, 0.0, 2.0, 5.0, 1.0, 1.0, 5.0, 5.0, 1.0, 2.0, 2.0, 5.0,
      5.0, 5.0, 1.0, 2.0, 2.0, 5.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 5.0, 5.0, 2.0, 3.0,
      5.0, 4.0, 8.0, 1.0, 5.0, 3.0, 3.0, 2.0, 5.0, 5.0, 0.0, 3.0, 4.0, 1.0, 4.0, 4.0,
      9.0, 2.0, 3.0, 3.0, 3.0, 3.0, 0.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1069862475926726
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0394715181972423
    mean_inference_ms: 2.0056578709856447
    mean_raw_obs_processing_ms: 0.4518014808690674
time_since_restore: 1217.9668538570404
time_this_iter_s: 10.208602905273438
time_total_s: 1217.9668538570404
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.088
timestamp: 1692342807
timesteps_total: 901050
training_iteration: 119
trial_id: default
train step: 120
agent_timesteps_total: 907750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034073591232299805
  StateBufferConnector_ms: 0.00613856315612793
  ViewRequirementAgentConnector_ms: 0.20820236206054688
counters:
  num_agent_steps_sampled: 907750
  num_agent_steps_trained: 891000
  num_env_steps_sampled: 907750
  num_env_steps_trained: 891000
  num_samples_added_to_queue: 907500
  num_training_step_calls_since_last_synch_worker_weights: 374
  num_weight_broadcasts: 17772
custom_metrics: {}
date: 2023-08-18_16-13-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.03
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 7092
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.1114517450332642
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -7.2386040687561035
        total_loss: 1.9764763116836548
        var_gnorm: 63.34739685058594
        vf_explained_var: 0.3007100820541382
        vf_loss: 19.54161262512207
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1782.0
  learner_queue:
    size_count: 1788
    size_mean: 14.4
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8439088914585775
  num_agent_steps_sampled: 907750
  num_agent_steps_trained: 891000
  num_env_steps_sampled: 907750
  num_env_steps_trained: 891000
  num_samples_added_to_queue: 907500
  num_training_step_calls_since_last_synch_worker_weights: 374
  num_weight_broadcasts: 17772
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 369.845
    learner_load_time_ms: 16.736
    learner_load_wait_time_ms: 3.706
iterations_since_restore: 120
node_ip: 127.0.0.1
num_agent_steps_sampled: 907750
num_agent_steps_trained: 891000
num_env_steps_sampled: 907750
num_env_steps_sampled_this_iter: 6700
num_env_steps_sampled_throughput_per_sec: 669.9964537808243
num_env_steps_trained: 891000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.996559638113
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 58.03333333333333
  ram_util_percent: 82.02666666666669
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10690430621039869
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039511480014764476
  mean_inference_ms: 2.006293878784121
  mean_raw_obs_processing_ms: 0.4521434214642561
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034073591232299805
    StateBufferConnector_ms: 0.00613856315612793
    ViewRequirementAgentConnector_ms: 0.20820236206054688
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.03
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 1.0, 5.0, 5.0, 1.0, 2.0, 2.0, 5.0, 5.0, 5.0, 1.0, 2.0, 2.0,
      5.0, 1.0, 2.0, 2.0, 0.0, 1.0, 3.0, 5.0, 5.0, 2.0, 3.0, 5.0, 4.0, 8.0, 1.0, 5.0,
      3.0, 3.0, 2.0, 5.0, 5.0, 0.0, 3.0, 4.0, 1.0, 4.0, 4.0, 9.0, 2.0, 3.0, 3.0, 3.0,
      3.0, 0.0, 4.0, 5.0, 0.0, 3.0, 3.0, 1.0, 7.0, 3.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0,
      3.0, 2.0, 4.0, 6.0, 6.0, 4.0, 2.0, 6.0, 2.0, 3.0, 2.0, 0.0, 4.0, 6.0, 0.0, 3.0,
      2.0, 2.0, 6.0, 1.0, 5.0, 3.0, 3.0, 1.0, 3.0, 6.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0,
      4.0, 2.0, 3.0, 2.0, 4.0, 5.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10690430621039869
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039511480014764476
    mean_inference_ms: 2.006293878784121
    mean_raw_obs_processing_ms: 0.4521434214642561
time_since_restore: 1228.2777590751648
time_this_iter_s: 10.31090521812439
time_total_s: 1228.2777590751648
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692342817
timesteps_total: 907750
training_iteration: 120
trial_id: default
train step: 121
agent_timesteps_total: 914350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03809809684753418
  StateBufferConnector_ms: 0.006894111633300781
  ViewRequirementAgentConnector_ms: 0.2312912940979004
counters:
  num_agent_steps_sampled: 914350
  num_agent_steps_trained: 897500
  num_env_steps_sampled: 914350
  num_env_steps_trained: 897500
  num_samples_added_to_queue: 914000
  num_training_step_calls_since_last_synch_worker_weights: 1312
  num_weight_broadcasts: 17901
custom_metrics: {}
date: 2023-08-18_16-13-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.11
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 7144
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0918018817901611
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -0.7670807838439941
        total_loss: 14.146559715270996
        var_gnorm: 63.34775161743164
        vf_explained_var: 0.2079753279685974
        vf_loss: 30.919084548950195
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1795.0
  learner_queue:
    size_count: 1799
    size_mean: 14.54
    size_quantiles: [10.0, 11.9, 15.5, 16.0, 16.0]
    size_std: 1.7912007146045916
  num_agent_steps_sampled: 914350
  num_agent_steps_trained: 897500
  num_env_steps_sampled: 914350
  num_env_steps_trained: 897500
  num_samples_added_to_queue: 914000
  num_training_step_calls_since_last_synch_worker_weights: 1312
  num_weight_broadcasts: 17901
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 893.937
    learner_load_time_ms: 16.802
    learner_load_wait_time_ms: 20.001
iterations_since_restore: 121
node_ip: 127.0.0.1
num_agent_steps_sampled: 914350
num_agent_steps_trained: 897500
num_env_steps_sampled: 914350
num_env_steps_sampled_this_iter: 6600
num_env_steps_sampled_throughput_per_sec: 659.9938002215079
num_env_steps_trained: 897500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9938941575456
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 60.75714285714285
  ram_util_percent: 82.30714285714285
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10683362956097961
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03961563773254607
  mean_inference_ms: 2.0086619091713196
  mean_raw_obs_processing_ms: 0.45300615314090775
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03809809684753418
    StateBufferConnector_ms: 0.006894111633300781
    ViewRequirementAgentConnector_ms: 0.2312912940979004
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.11
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 7.0, 3.0, 4.0, 0.0, 2.0, 1.0, 1.0, 2.0, 3.0, 2.0, 4.0, 6.0,
      6.0, 4.0, 2.0, 6.0, 2.0, 3.0, 2.0, 0.0, 4.0, 6.0, 0.0, 3.0, 2.0, 2.0, 6.0, 1.0,
      5.0, 3.0, 3.0, 1.0, 3.0, 6.0, 4.0, 3.0, 2.0, 2.0, 3.0, 2.0, 4.0, 2.0, 3.0, 2.0,
      4.0, 5.0, 0.0, 6.0, 6.0, 1.0, 1.0, 3.0, 4.0, 2.0, 2.0, 3.0, 1.0, 2.0, 0.0, 7.0,
      4.0, 3.0, 2.0, 3.0, 3.0, 7.0, 1.0, 3.0, 8.0, 5.0, 4.0, 2.0, 3.0, 1.0, 1.0, 5.0,
      2.0, 4.0, 1.0, 4.0, 3.0, 3.0, 1.0, 4.0, 10.0, 2.0, 2.0, 5.0, 2.0, 5.0, 2.0,
      4.0, 1.0, 7.0, 2.0, 3.0, 4.0, 0.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10683362956097961
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03961563773254607
    mean_inference_ms: 2.0086619091713196
    mean_raw_obs_processing_ms: 0.45300615314090775
time_since_restore: 1238.4157819747925
time_this_iter_s: 10.138022899627686
time_total_s: 1238.4157819747925
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342827
timesteps_total: 914350
training_iteration: 121
trial_id: default
train step: 122
agent_timesteps_total: 921750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03570556640625
  StateBufferConnector_ms: 0.006440877914428711
  ViewRequirementAgentConnector_ms: 0.21374273300170898
counters:
  num_agent_steps_sampled: 921750
  num_agent_steps_trained: 905000
  num_env_steps_sampled: 921750
  num_env_steps_trained: 905000
  num_samples_added_to_queue: 921500
  num_training_step_calls_since_last_synch_worker_weights: 1101
  num_weight_broadcasts: 18045
custom_metrics: {}
date: 2023-08-18_16-13-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.45
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 7202
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0873310565948486
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 2.2143473625183105
        total_loss: 12.384236335754395
        var_gnorm: 63.34808349609375
        vf_explained_var: 0.24669766426086426
        vf_loss: 21.427108764648438
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1810.0
  learner_queue:
    size_count: 1814
    size_mean: 15.02
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4489996549343964
  num_agent_steps_sampled: 921750
  num_agent_steps_trained: 905000
  num_env_steps_sampled: 921750
  num_env_steps_trained: 905000
  num_samples_added_to_queue: 921500
  num_training_step_calls_since_last_synch_worker_weights: 1101
  num_weight_broadcasts: 18045
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 509.002
    learner_load_time_ms: 16.764
    learner_load_wait_time_ms: 2.801
iterations_since_restore: 122
node_ip: 127.0.0.1
num_agent_steps_sampled: 921750
num_agent_steps_trained: 905000
num_env_steps_sampled: 921750
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9944601473692
num_env_steps_trained: 905000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9943852844958
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.08000000000001
  ram_util_percent: 82.48000000000002
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10698023278166403
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039628492570262505
  mean_inference_ms: 2.009684290287794
  mean_raw_obs_processing_ms: 0.4530211817901481
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03570556640625
    StateBufferConnector_ms: 0.006440877914428711
    ViewRequirementAgentConnector_ms: 0.21374273300170898
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.45
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 0.0, 7.0, 4.0, 3.0, 2.0, 3.0, 3.0, 7.0, 1.0, 3.0, 8.0, 5.0,
      4.0, 2.0, 3.0, 1.0, 1.0, 5.0, 2.0, 4.0, 1.0, 4.0, 3.0, 3.0, 1.0, 4.0, 10.0,
      2.0, 2.0, 5.0, 2.0, 5.0, 2.0, 4.0, 1.0, 7.0, 2.0, 3.0, 4.0, 0.0, 5.0, 7.0, 3.0,
      2.0, 5.0, 7.0, 2.0, 1.0, 3.0, 3.0, 5.0, 3.0, 5.0, 0.0, 2.0, 2.0, 1.0, 1.0, 4.0,
      1.0, 3.0, 7.0, 5.0, 0.0, 3.0, 2.0, 5.0, 6.0, 5.0, 1.0, 1.0, 3.0, 4.0, 2.0, 2.0,
      4.0, 8.0, 4.0, 4.0, 5.0, 5.0, 5.0, 2.0, 5.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0,
      4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10698023278166403
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039628492570262505
    mean_inference_ms: 2.009684290287794
    mean_raw_obs_processing_ms: 0.4530211817901481
time_since_restore: 1248.5861818790436
time_this_iter_s: 10.170399904251099
time_total_s: 1248.5861818790436
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.086
timestamp: 1692342838
timesteps_total: 921750
training_iteration: 122
trial_id: default
train step: 123
agent_timesteps_total: 929850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03280210494995117
  StateBufferConnector_ms: 0.005840301513671875
  ViewRequirementAgentConnector_ms: 0.19550132751464844
counters:
  num_agent_steps_sampled: 929850
  num_agent_steps_trained: 913000
  num_env_steps_sampled: 929850
  num_env_steps_trained: 913000
  num_samples_added_to_queue: 929500
  num_training_step_calls_since_last_synch_worker_weights: 738
  num_weight_broadcasts: 18203
custom_metrics: {}
date: 2023-08-18_16-14-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.59
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 7265
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0860503911972046
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 19.07230567932129
        total_loss: 33.116886138916016
        var_gnorm: 63.34844207763672
        vf_explained_var: 0.27675479650497437
        vf_loss: 29.175216674804688
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1826.0
  learner_queue:
    size_count: 1831
    size_mean: 14.98
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4627371602581238
  num_agent_steps_sampled: 929850
  num_agent_steps_trained: 913000
  num_env_steps_sampled: 929850
  num_env_steps_trained: 913000
  num_samples_added_to_queue: 929500
  num_training_step_calls_since_last_synch_worker_weights: 738
  num_weight_broadcasts: 18203
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 369.207
    learner_load_time_ms: 16.765
    learner_load_wait_time_ms: 2.747
iterations_since_restore: 123
node_ip: 127.0.0.1
num_agent_steps_sampled: 929850
num_agent_steps_trained: 913000
num_env_steps_sampled: 929850
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9960217671279
num_env_steps_trained: 913000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.996070881114
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.07142857142857
  ram_util_percent: 81.54285714285716
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10710819739415761
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03957305048872715
  mean_inference_ms: 2.008822503566939
  mean_raw_obs_processing_ms: 0.4524946472757387
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03280210494995117
    StateBufferConnector_ms: 0.005840301513671875
    ViewRequirementAgentConnector_ms: 0.19550132751464844
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.59
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 0.0, 3.0, 2.0, 5.0, 6.0, 5.0, 1.0, 1.0, 3.0, 4.0, 2.0, 2.0,
      4.0, 8.0, 4.0, 4.0, 5.0, 5.0, 5.0, 2.0, 5.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 3.0,
      4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 5.0, 3.0, 3.0, 2.0, 4.0, 3.0, 1.0, 7.0, 4.0, 6.0,
      2.0, 1.0, 3.0, 1.0, 5.0, 3.0, 3.0, 4.0, 5.0, 4.0, 2.0, 4.0, 5.0, 3.0, 5.0, 4.0,
      3.0, 6.0, 3.0, 4.0, 4.0, 6.0, 1.0, 2.0, 5.0, 5.0, 8.0, 1.0, 4.0, 5.0, 2.0, 3.0,
      3.0, 5.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0, 3.0, 4.0, 6.0, 4.0, 5.0, 1.0, 4.0,
      5.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10710819739415761
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03957305048872715
    mean_inference_ms: 2.008822503566939
    mean_raw_obs_processing_ms: 0.4524946472757387
time_since_restore: 1258.8113808631897
time_this_iter_s: 10.225198984146118
time_total_s: 1258.8113808631897
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.072
timestamp: 1692342848
timesteps_total: 929850
training_iteration: 123
trial_id: default
train step: 124
agent_timesteps_total: 937150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03354191780090332
  StateBufferConnector_ms: 0.005976438522338867
  ViewRequirementAgentConnector_ms: 0.20041131973266602
counters:
  num_agent_steps_sampled: 937150
  num_agent_steps_trained: 920500
  num_env_steps_sampled: 937150
  num_env_steps_trained: 920500
  num_samples_added_to_queue: 937000
  num_training_step_calls_since_last_synch_worker_weights: 1607
  num_weight_broadcasts: 18346
custom_metrics: {}
date: 2023-08-18_16-14-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.37
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 7322
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0507755279541016
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -13.817760467529297
        total_loss: -0.7220544815063477
        var_gnorm: 63.34870910644531
        vf_explained_var: 0.19379889965057373
        vf_loss: 27.2421875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1841.0
  learner_queue:
    size_count: 1844
    size_mean: 15.3
    size_quantiles: [12.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.118033988749895
  num_agent_steps_sampled: 937150
  num_agent_steps_trained: 920500
  num_env_steps_sampled: 937150
  num_env_steps_trained: 920500
  num_samples_added_to_queue: 937000
  num_training_step_calls_since_last_synch_worker_weights: 1607
  num_weight_broadcasts: 18346
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 583.227
    learner_load_time_ms: 16.763
    learner_load_wait_time_ms: 2.981
iterations_since_restore: 124
node_ip: 127.0.0.1
num_agent_steps_sampled: 937150
num_agent_steps_trained: 920500
num_env_steps_sampled: 937150
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9932296904004
num_env_steps_trained: 920500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9930442024661
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.68571428571429
  ram_util_percent: 81.57857142857145
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10706772202065316
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03957557366647749
  mean_inference_ms: 2.008720583511382
  mean_raw_obs_processing_ms: 0.45252112181589793
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03354191780090332
    StateBufferConnector_ms: 0.005976438522338867
    ViewRequirementAgentConnector_ms: 0.20041131973266602
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.37
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 3.0, 5.0, 4.0, 3.0, 6.0, 3.0, 4.0, 4.0, 6.0, 1.0, 2.0, 5.0,
      5.0, 8.0, 1.0, 4.0, 5.0, 2.0, 3.0, 3.0, 5.0, 2.0, 3.0, 2.0, 2.0, 3.0, 4.0, 2.0,
      3.0, 4.0, 6.0, 4.0, 5.0, 1.0, 4.0, 5.0, 3.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 6.0,
      2.0, 2.0, 5.0, 1.0, 0.0, 3.0, 5.0, 4.0, 4.0, 2.0, 3.0, 5.0, 1.0, 0.0, 3.0, 3.0,
      2.0, 5.0, 3.0, 3.0, 7.0, 2.0, 4.0, 2.0, 3.0, 5.0, 5.0, 2.0, 2.0, 3.0, 1.0, 6.0,
      2.0, 2.0, 4.0, 3.0, 1.0, 6.0, 4.0, 7.0, 1.0, 2.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0,
      3.0, 5.0, 3.0, 5.0, 1.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10706772202065316
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03957557366647749
    mean_inference_ms: 2.008720583511382
    mean_raw_obs_processing_ms: 0.45252112181589793
time_since_restore: 1268.9628989696503
time_this_iter_s: 10.151518106460571
time_total_s: 1268.9628989696503
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1692342858
timesteps_total: 937150
training_iteration: 124
trial_id: default
train step: 125
agent_timesteps_total: 944250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.037636756896972656
  StateBufferConnector_ms: 0.006649494171142578
  ViewRequirementAgentConnector_ms: 0.21956658363342285
counters:
  num_agent_steps_sampled: 944250
  num_agent_steps_trained: 927500
  num_env_steps_sampled: 944250
  num_env_steps_trained: 927500
  num_samples_added_to_queue: 944000
  num_training_step_calls_since_last_synch_worker_weights: 300
  num_weight_broadcasts: 18485
custom_metrics: {}
date: 2023-08-18_16-14-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.38
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 7378
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0336799621582031
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 28.86418342590332
        total_loss: 50.22429656982422
        var_gnorm: 63.34903335571289
        vf_explained_var: 0.19152259826660156
        vf_loss: 43.753902435302734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1855.0
  learner_queue:
    size_count: 1862
    size_mean: 14.96
    size_quantiles: [10.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.535708305636197
  num_agent_steps_sampled: 944250
  num_agent_steps_trained: 927500
  num_env_steps_sampled: 944250
  num_env_steps_trained: 927500
  num_samples_added_to_queue: 944000
  num_training_step_calls_since_last_synch_worker_weights: 300
  num_weight_broadcasts: 18485
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 323.839
    learner_load_time_ms: 16.797
    learner_load_wait_time_ms: 2.906
iterations_since_restore: 125
node_ip: 127.0.0.1
num_agent_steps_sampled: 944250
num_agent_steps_trained: 927500
num_env_steps_sampled: 944250
num_env_steps_sampled_this_iter: 7100
num_env_steps_sampled_throughput_per_sec: 709.9982903044862
num_env_steps_trained: 927500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9983143847047
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 58.05333333333333
  ram_util_percent: 82.66000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1069985821788923
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039624773760816474
  mean_inference_ms: 2.009763838190522
  mean_raw_obs_processing_ms: 0.4529431099699397
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.037636756896972656
    StateBufferConnector_ms: 0.006649494171142578
    ViewRequirementAgentConnector_ms: 0.21956658363342285
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.38
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 1.0, 0.0, 3.0, 3.0, 2.0, 5.0, 3.0, 3.0, 7.0, 2.0, 4.0, 2.0,
      3.0, 5.0, 5.0, 2.0, 2.0, 3.0, 1.0, 6.0, 2.0, 2.0, 4.0, 3.0, 1.0, 6.0, 4.0, 7.0,
      1.0, 2.0, 2.0, 2.0, 1.0, 4.0, 3.0, 1.0, 3.0, 5.0, 3.0, 5.0, 1.0, 6.0, 7.0, 5.0,
      2.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 6.0, 3.0, 4.0, 3.0, 4.0, 4.0, 3.0, 7.0, 3.0,
      7.0, 1.0, 3.0, 1.0, 5.0, 1.0, 1.0, 4.0, 4.0, 2.0, 2.0, 3.0, 4.0, 4.0, 4.0, 8.0,
      3.0, 7.0, 0.0, 1.0, 4.0, 4.0, 4.0, 3.0, 4.0, 2.0, 5.0, 1.0, 2.0, 5.0, 1.0, 2.0,
      3.0, 1.0, 4.0, 4.0, 6.0, 5.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1069985821788923
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039624773760816474
    mean_inference_ms: 2.009763838190522
    mean_raw_obs_processing_ms: 0.4529431099699397
time_since_restore: 1279.2734310626984
time_this_iter_s: 10.310532093048096
time_total_s: 1279.2734310626984
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692342868
timesteps_total: 944250
training_iteration: 125
trial_id: default
train step: 126
agent_timesteps_total: 951950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03616070747375488
  StateBufferConnector_ms: 0.006491184234619141
  ViewRequirementAgentConnector_ms: 0.21637773513793945
counters:
  num_agent_steps_sampled: 951950
  num_agent_steps_trained: 935000
  num_env_steps_sampled: 951950
  num_env_steps_trained: 935000
  num_samples_added_to_queue: 951500
  num_training_step_calls_since_last_synch_worker_weights: 189
  num_weight_broadcasts: 18636
custom_metrics: {}
date: 2023-08-18_16-14-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.48
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 7438
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0413053035736084
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -13.406482696533203
        total_loss: -1.1419600248336792
        var_gnorm: 63.34950256347656
        vf_explained_var: 0.17250210046768188
        vf_loss: 25.570350646972656
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1870.0
  learner_queue:
    size_count: 1877
    size_mean: 14.58
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.7898603297464304
  num_agent_steps_sampled: 951950
  num_agent_steps_trained: 935000
  num_env_steps_sampled: 951950
  num_env_steps_trained: 935000
  num_samples_added_to_queue: 951500
  num_training_step_calls_since_last_synch_worker_weights: 189
  num_weight_broadcasts: 18636
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 272.101
    learner_load_time_ms: 16.812
    learner_load_wait_time_ms: 3.175
iterations_since_restore: 126
node_ip: 127.0.0.1
num_agent_steps_sampled: 951950
num_agent_steps_trained: 935000
num_env_steps_sampled: 951950
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 769.9983110464902
num_env_steps_trained: 935000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9983549154126
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 51.114285714285714
  ram_util_percent: 82.65714285714284
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10707614577788747
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0396187932836371
  mean_inference_ms: 2.0102019502644697
  mean_raw_obs_processing_ms: 0.45291765878120616
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03616070747375488
    StateBufferConnector_ms: 0.006491184234619141
    ViewRequirementAgentConnector_ms: 0.21637773513793945
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.48
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 7.0, 1.0, 3.0, 1.0, 5.0, 1.0, 1.0, 4.0, 4.0, 2.0, 2.0, 3.0,
      4.0, 4.0, 4.0, 8.0, 3.0, 7.0, 0.0, 1.0, 4.0, 4.0, 4.0, 3.0, 4.0, 2.0, 5.0, 1.0,
      2.0, 5.0, 1.0, 2.0, 3.0, 1.0, 4.0, 4.0, 6.0, 5.0, 7.0, 7.0, 5.0, 0.0, 5.0, 2.0,
      4.0, 4.0, 0.0, 3.0, 7.0, 1.0, 1.0, 6.0, 1.0, 3.0, 6.0, 5.0, 3.0, 4.0, 5.0, 6.0,
      0.0, 9.0, 5.0, 2.0, 2.0, 3.0, 3.0, 5.0, 3.0, 3.0, 3.0, 8.0, 4.0, 3.0, 5.0, 4.0,
      1.0, 6.0, 3.0, 3.0, 5.0, 5.0, 5.0, 3.0, 3.0, 4.0, 5.0, 1.0, 1.0, 2.0, 9.0, 2.0,
      1.0, 3.0, 4.0, 2.0, 1.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10707614577788747
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0396187932836371
    mean_inference_ms: 2.0102019502644697
    mean_raw_obs_processing_ms: 0.45291765878120616
time_since_restore: 1289.6965181827545
time_this_iter_s: 10.423087120056152
time_total_s: 1289.6965181827545
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692342879
timesteps_total: 951950
training_iteration: 126
trial_id: default
train step: 127
agent_timesteps_total: 958900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034995317459106445
  StateBufferConnector_ms: 0.0062541961669921875
  ViewRequirementAgentConnector_ms: 0.21016621589660645
counters:
  num_agent_steps_sampled: 958900
  num_agent_steps_trained: 942000
  num_env_steps_sampled: 958900
  num_env_steps_trained: 942000
  num_samples_added_to_queue: 958500
  num_training_step_calls_since_last_synch_worker_weights: 53
  num_weight_broadcasts: 18771
custom_metrics: {}
date: 2023-08-18_16-14-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.44
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 7492
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0395781993865967
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -3.320401191711426
        total_loss: 6.719004154205322
        var_gnorm: 63.34981155395508
        vf_explained_var: 0.25185173749923706
        vf_loss: 21.118389129638672
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1884.0
  learner_queue:
    size_count: 1891
    size_mean: 14.34
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.9556073225471415
  num_agent_steps_sampled: 958900
  num_agent_steps_trained: 942000
  num_env_steps_sampled: 958900
  num_env_steps_trained: 942000
  num_samples_added_to_queue: 958500
  num_training_step_calls_since_last_synch_worker_weights: 53
  num_weight_broadcasts: 18771
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 318.899
    learner_load_time_ms: 3.628
    learner_load_wait_time_ms: 2.902
iterations_since_restore: 127
node_ip: 127.0.0.1
num_agent_steps_sampled: 958900
num_agent_steps_trained: 942000
num_env_steps_sampled: 958900
num_env_steps_sampled_this_iter: 6950
num_env_steps_sampled_throughput_per_sec: 694.9934051662623
num_env_steps_trained: 942000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9933577214152
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 61.89333333333333
  ram_util_percent: 83.19333333333334
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10708572647748366
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03964080175842247
  mean_inference_ms: 2.010929985087576
  mean_raw_obs_processing_ms: 0.45314192311409157
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034995317459106445
    StateBufferConnector_ms: 0.0062541961669921875
    ViewRequirementAgentConnector_ms: 0.21016621589660645
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.44
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 6.0, 5.0, 3.0, 4.0, 5.0, 6.0, 0.0, 9.0, 5.0, 2.0, 2.0, 3.0,
      3.0, 5.0, 3.0, 3.0, 3.0, 8.0, 4.0, 3.0, 5.0, 4.0, 1.0, 6.0, 3.0, 3.0, 5.0, 5.0,
      5.0, 3.0, 3.0, 4.0, 5.0, 1.0, 1.0, 2.0, 9.0, 2.0, 1.0, 3.0, 4.0, 2.0, 1.0, 2.0,
      2.0, 2.0, 5.0, 0.0, 2.0, 3.0, 3.0, 3.0, 3.0, 4.0, 1.0, 4.0, 4.0, 1.0, 3.0, 5.0,
      3.0, 1.0, 3.0, 5.0, 5.0, 6.0, 2.0, 2.0, 3.0, 3.0, 1.0, 5.0, 6.0, 2.0, 4.0, 5.0,
      4.0, 3.0, 4.0, 4.0, 6.0, 6.0, 2.0, 4.0, 2.0, 4.0, 1.0, 3.0, 7.0, 0.0, 1.0, 3.0,
      4.0, 2.0, 4.0, 2.0, 3.0, 4.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10708572647748366
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03964080175842247
    mean_inference_ms: 2.010929985087576
    mean_raw_obs_processing_ms: 0.45314192311409157
time_since_restore: 1299.9658372402191
time_this_iter_s: 10.2693190574646
time_total_s: 1299.9658372402191
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.085
timestamp: 1692342889
timesteps_total: 958900
training_iteration: 127
trial_id: default
train step: 128
agent_timesteps_total: 966400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03536558151245117
  StateBufferConnector_ms: 0.006585121154785156
  ViewRequirementAgentConnector_ms: 0.21009445190429688
counters:
  num_agent_steps_sampled: 966400
  num_agent_steps_trained: 949500
  num_env_steps_sampled: 966400
  num_env_steps_trained: 949500
  num_samples_added_to_queue: 966000
  num_training_step_calls_since_last_synch_worker_weights: 881
  num_weight_broadcasts: 18918
custom_metrics: {}
date: 2023-08-18_16-14-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 3.44
episode_reward_min: 0.0
episodes_this_iter: 59
episodes_total: 7551
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0507452487945557
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -19.043521881103516
        total_loss: -7.068098068237305
        var_gnorm: 63.35017013549805
        vf_explained_var: 0.208540141582489
        vf_loss: 25.0015926361084
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1899.0
  learner_queue:
    size_count: 1904
    size_mean: 14.12
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.9661129163911213
  num_agent_steps_sampled: 966400
  num_agent_steps_trained: 949500
  num_env_steps_sampled: 966400
  num_env_steps_trained: 949500
  num_samples_added_to_queue: 966000
  num_training_step_calls_since_last_synch_worker_weights: 881
  num_weight_broadcasts: 18918
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 520.499
    learner_load_time_ms: 3.285
    learner_load_wait_time_ms: 13.761
iterations_since_restore: 128
node_ip: 127.0.0.1
num_agent_steps_sampled: 966400
num_agent_steps_trained: 949500
num_env_steps_sampled: 966400
num_env_steps_sampled_this_iter: 7500
num_env_steps_sampled_throughput_per_sec: 749.9968350067187
num_env_steps_trained: 949500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9968350067187
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 55.78571428571427
  ram_util_percent: 82.88571428571427
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10711867302835743
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03965392618901453
  mean_inference_ms: 2.0115494896599206
  mean_raw_obs_processing_ms: 0.45327416386353475
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03536558151245117
    StateBufferConnector_ms: 0.006585121154785156
    ViewRequirementAgentConnector_ms: 0.21009445190429688
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 3.44
  episode_reward_min: 0.0
  episodes_this_iter: 59
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 3.0, 1.0, 3.0, 5.0, 5.0, 6.0, 2.0, 2.0, 3.0, 3.0, 1.0,
      5.0, 6.0, 2.0, 4.0, 5.0, 4.0, 3.0, 4.0, 4.0, 6.0, 6.0, 2.0, 4.0, 2.0, 4.0, 1.0,
      3.0, 7.0, 0.0, 1.0, 3.0, 4.0, 2.0, 4.0, 2.0, 3.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0,
      5.0, 6.0, 2.0, 2.0, 5.0, 4.0, 4.0, 6.0, 3.0, 3.0, 1.0, 2.0, 4.0, 1.0, 3.0, 3.0,
      4.0, 5.0, 2.0, 1.0, 5.0, 2.0, 4.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0, 2.0, 5.0, 3.0,
      3.0, 2.0, 5.0, 4.0, 6.0, 4.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0, 4.0, 5.0, 1.0,
      2.0, 2.0, 5.0, 4.0, 6.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10711867302835743
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03965392618901453
    mean_inference_ms: 2.0115494896599206
    mean_raw_obs_processing_ms: 0.45327416386353475
time_since_restore: 1310.150873184204
time_this_iter_s: 10.185035943984985
time_total_s: 1310.150873184204
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1692342899
timesteps_total: 966400
training_iteration: 128
trial_id: default
train step: 129
agent_timesteps_total: 974300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03270530700683594
  StateBufferConnector_ms: 0.0061604976654052734
  ViewRequirementAgentConnector_ms: 0.19678616523742676
counters:
  num_agent_steps_sampled: 974300
  num_agent_steps_trained: 957500
  num_env_steps_sampled: 974300
  num_env_steps_trained: 957500
  num_samples_added_to_queue: 974000
  num_training_step_calls_since_last_synch_worker_weights: 861
  num_weight_broadcasts: 19073
custom_metrics: {}
date: 2023-08-18_16-15-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 6.0
episode_reward_mean: 3.12
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 7612
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0484343767166138
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 18.998964309692383
        total_loss: 36.38792419433594
        var_gnorm: 63.350467681884766
        vf_explained_var: 0.21387481689453125
        vf_loss: 35.826351165771484
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1915.0
  learner_queue:
    size_count: 1919
    size_mean: 14.52
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.824719156473127
  num_agent_steps_sampled: 974300
  num_agent_steps_trained: 957500
  num_env_steps_sampled: 974300
  num_env_steps_trained: 957500
  num_samples_added_to_queue: 974000
  num_training_step_calls_since_last_synch_worker_weights: 861
  num_weight_broadcasts: 19073
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 455.784
    learner_load_time_ms: 3.285
    learner_load_wait_time_ms: 2.831
iterations_since_restore: 129
node_ip: 127.0.0.1
num_agent_steps_sampled: 974300
num_agent_steps_trained: 957500
num_env_steps_sampled: 974300
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.9981730026535
num_env_steps_trained: 957500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9981498761049
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 53.573333333333345
  ram_util_percent: 82.86666666666665
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10717193479916766
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039617351827166296
  mean_inference_ms: 2.0109634346149226
  mean_raw_obs_processing_ms: 0.4529820247912342
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03270530700683594
    StateBufferConnector_ms: 0.0061604976654052734
    ViewRequirementAgentConnector_ms: 0.19678616523742676
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 6.0
  episode_reward_mean: 3.12
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 2.0, 1.0, 5.0, 2.0, 4.0, 4.0, 2.0, 4.0, 3.0, 2.0, 1.0,
      2.0, 5.0, 3.0, 3.0, 2.0, 5.0, 4.0, 6.0, 4.0, 4.0, 3.0, 2.0, 3.0, 2.0, 3.0, 4.0,
      4.0, 5.0, 1.0, 2.0, 2.0, 5.0, 4.0, 6.0, 5.0, 4.0, 4.0, 3.0, 4.0, 1.0, 4.0, 3.0,
      2.0, 5.0, 1.0, 2.0, 1.0, 2.0, 3.0, 4.0, 5.0, 2.0, 5.0, 2.0, 6.0, 4.0, 2.0, 0.0,
      0.0, 2.0, 5.0, 4.0, 6.0, 4.0, 2.0, 3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 4.0,
      4.0, 5.0, 3.0, 3.0, 1.0, 3.0, 3.0, 4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 5.0, 5.0,
      4.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10717193479916766
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039617351827166296
    mean_inference_ms: 2.0109634346149226
    mean_raw_obs_processing_ms: 0.4529820247912342
time_since_restore: 1320.3242633342743
time_this_iter_s: 10.17339015007019
time_total_s: 1320.3242633342743
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692342909
timesteps_total: 974300
training_iteration: 129
trial_id: default
train step: 130
agent_timesteps_total: 981300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03442788124084473
  StateBufferConnector_ms: 0.006314754486083984
  ViewRequirementAgentConnector_ms: 0.20632672309875488
counters:
  num_agent_steps_sampled: 981300
  num_agent_steps_trained: 964500
  num_env_steps_sampled: 981300
  num_env_steps_trained: 964500
  num_samples_added_to_queue: 981000
  num_training_step_calls_since_last_synch_worker_weights: 980
  num_weight_broadcasts: 19208
custom_metrics: {}
date: 2023-08-18_16-15-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.09
episode_reward_min: 0.0
episodes_this_iter: 55
episodes_total: 7667
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0279808044433594
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -0.836577832698822
        total_loss: 10.871245384216309
        var_gnorm: 63.350711822509766
        vf_explained_var: 0.2962889075279236
        vf_loss: 24.443626403808594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1929.0
  learner_queue:
    size_count: 1934
    size_mean: 14.74
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6469365500832145
  num_agent_steps_sampled: 981300
  num_agent_steps_trained: 964500
  num_env_steps_sampled: 981300
  num_env_steps_trained: 964500
  num_samples_added_to_queue: 981000
  num_training_step_calls_since_last_synch_worker_weights: 980
  num_weight_broadcasts: 19208
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 507.538
    learner_load_time_ms: 3.248
    learner_load_wait_time_ms: 3.566
iterations_since_restore: 130
node_ip: 127.0.0.1
num_agent_steps_sampled: 981300
num_agent_steps_trained: 964500
num_env_steps_sampled: 981300
num_env_steps_sampled_this_iter: 7000
num_env_steps_sampled_throughput_per_sec: 699.996845736412
num_env_steps_trained: 964500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.996845736412
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 59.30714285714286
  ram_util_percent: 83.25
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10714632735148605
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03963512808245403
  mean_inference_ms: 2.011386615584433
  mean_raw_obs_processing_ms: 0.45317724414938537
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03442788124084473
    StateBufferConnector_ms: 0.006314754486083984
    ViewRequirementAgentConnector_ms: 0.20632672309875488
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.09
  episode_reward_min: 0.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 2.0, 6.0, 4.0, 2.0, 0.0, 0.0, 2.0, 5.0, 4.0, 6.0, 4.0, 2.0,
      3.0, 2.0, 2.0, 3.0, 2.0, 3.0, 2.0, 4.0, 4.0, 4.0, 5.0, 3.0, 3.0, 1.0, 3.0, 3.0,
      4.0, 2.0, 2.0, 2.0, 4.0, 2.0, 3.0, 5.0, 5.0, 4.0, 2.0, 2.0, 3.0, 2.0, 2.0, 1.0,
      6.0, 4.0, 2.0, 3.0, 3.0, 2.0, 0.0, 5.0, 3.0, 4.0, 5.0, 4.0, 3.0, 1.0, 6.0, 4.0,
      0.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 3.0, 4.0, 1.0, 4.0, 3.0, 2.0,
      3.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 3.0, 2.0, 5.0, 3.0, 2.0, 3.0, 9.0, 3.0, 6.0,
      4.0, 3.0, 3.0, 2.0, 1.0, 4.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10714632735148605
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03963512808245403
    mean_inference_ms: 2.011386615584433
    mean_raw_obs_processing_ms: 0.45317724414938537
time_since_restore: 1330.5803384780884
time_this_iter_s: 10.256075143814087
time_total_s: 1330.5803384780884
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692342920
timesteps_total: 981300
training_iteration: 130
trial_id: default
train step: 131
agent_timesteps_total: 988500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04773354530334473
  StateBufferConnector_ms: 0.008925914764404297
  ViewRequirementAgentConnector_ms: 0.22139191627502441
counters:
  num_agent_steps_sampled: 988500
  num_agent_steps_trained: 972000
  num_env_steps_sampled: 988500
  num_env_steps_trained: 972000
  num_samples_added_to_queue: 988500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 19349
custom_metrics: {}
date: 2023-08-18_16-15-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.61
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 7723
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.057321548461914
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -17.152923583984375
        total_loss: -9.401392936706543
        var_gnorm: 63.35108184814453
        vf_explained_var: 0.23576033115386963
        vf_loss: 16.560382843017578
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1944.0
  learner_queue:
    size_count: 1950
    size_mean: 14.94
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.4616429112474771
  num_agent_steps_sampled: 988500
  num_agent_steps_trained: 972000
  num_env_steps_sampled: 988500
  num_env_steps_trained: 972000
  num_samples_added_to_queue: 988500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 19349
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 350.979
    learner_load_time_ms: 15.159
    learner_load_wait_time_ms: 3.153
iterations_since_restore: 131
node_ip: 127.0.0.1
num_agent_steps_sampled: 988500
num_agent_steps_trained: 972000
num_env_steps_sampled: 988500
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 718.206992806821
num_env_steps_trained: 972000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 748.1322841737718
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 60.413333333333334
  ram_util_percent: 84.08666666666666
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10714950567058576
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03966964287994504
  mean_inference_ms: 2.0124976684356146
  mean_raw_obs_processing_ms: 0.45351201815731884
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04773354530334473
    StateBufferConnector_ms: 0.008925914764404297
    ViewRequirementAgentConnector_ms: 0.22139191627502441
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.61
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 1.0, 6.0, 4.0, 0.0, 3.0, 1.0, 3.0, 3.0, 3.0, 3.0, 2.0,
      2.0, 2.0, 3.0, 4.0, 1.0, 4.0, 3.0, 2.0, 3.0, 4.0, 4.0, 4.0, 4.0, 2.0, 2.0, 3.0,
      2.0, 5.0, 3.0, 2.0, 3.0, 9.0, 3.0, 6.0, 4.0, 3.0, 3.0, 2.0, 1.0, 4.0, 5.0, 2.0,
      4.0, 6.0, 4.0, 2.0, 4.0, 3.0, 1.0, 3.0, 1.0, 1.0, 7.0, 6.0, 4.0, 4.0, 5.0, 4.0,
      4.0, 5.0, 0.0, 3.0, 7.0, 5.0, 7.0, 5.0, 3.0, 4.0, 2.0, 2.0, 5.0, 10.0, 2.0,
      4.0, 6.0, 1.0, 6.0, 5.0, 6.0, 4.0, 3.0, 5.0, 2.0, 5.0, 6.0, 5.0, 7.0, 5.0, 2.0,
      5.0, 4.0, 5.0, 1.0, 2.0, 2.0, 1.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10714950567058576
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03966964287994504
    mean_inference_ms: 2.0124976684356146
    mean_raw_obs_processing_ms: 0.45351201815731884
time_since_restore: 1340.8908905982971
time_this_iter_s: 10.31055212020874
time_total_s: 1340.8908905982971
timers:
  sample_time_ms: 0.202
  synch_weights_time_ms: 1.417
  training_iteration_time_ms: 8.524
timestamp: 1692342930
timesteps_total: 988500
training_iteration: 131
trial_id: default
train step: 132
agent_timesteps_total: 996350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04632210731506348
  StateBufferConnector_ms: 0.008368730545043945
  ViewRequirementAgentConnector_ms: 0.20796728134155273
counters:
  num_agent_steps_sampled: 996350
  num_agent_steps_trained: 979500
  num_env_steps_sampled: 996350
  num_env_steps_trained: 979500
  num_samples_added_to_queue: 996000
  num_training_step_calls_since_last_synch_worker_weights: 877
  num_weight_broadcasts: 19503
custom_metrics: {}
date: 2023-08-18_16-15-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.57
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 7785
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0453102588653564
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -6.9244232177734375
        total_loss: 3.3853933811187744
        var_gnorm: 63.35142517089844
        vf_explained_var: 0.262520432472229
        vf_loss: 21.66494369506836
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1959.0
  learner_queue:
    size_count: 1964
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5657586020839867
  num_agent_steps_sampled: 996350
  num_agent_steps_trained: 979500
  num_env_steps_sampled: 996350
  num_env_steps_trained: 979500
  num_samples_added_to_queue: 996000
  num_training_step_calls_since_last_synch_worker_weights: 877
  num_weight_broadcasts: 19503
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 386.337
    learner_load_time_ms: 15.238
    learner_load_wait_time_ms: 11.351
iterations_since_restore: 132
node_ip: 127.0.0.1
num_agent_steps_sampled: 996350
num_agent_steps_trained: 979500
num_env_steps_sampled: 996350
num_env_steps_sampled_this_iter: 7850
num_env_steps_sampled_throughput_per_sec: 784.9980348397813
num_env_steps_trained: 979500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9981224583898
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 48.16428571428572
  ram_util_percent: 82.85
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10721578941308355
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03963984703144437
  mean_inference_ms: 2.0123178361922287
  mean_raw_obs_processing_ms: 0.4532684161806827
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04632210731506348
    StateBufferConnector_ms: 0.008368730545043945
    ViewRequirementAgentConnector_ms: 0.20796728134155273
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.57
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 0.0, 3.0, 7.0, 5.0, 7.0, 5.0, 3.0, 4.0, 2.0, 2.0, 5.0, 10.0,
      2.0, 4.0, 6.0, 1.0, 6.0, 5.0, 6.0, 4.0, 3.0, 5.0, 2.0, 5.0, 6.0, 5.0, 7.0, 5.0,
      2.0, 5.0, 4.0, 5.0, 1.0, 2.0, 2.0, 1.0, 6.0, 3.0, 5.0, 1.0, 0.0, 1.0, 2.0, 4.0,
      4.0, 1.0, 8.0, 3.0, 4.0, 5.0, 3.0, 3.0, 2.0, 4.0, 4.0, 3.0, 5.0, 5.0, 1.0, 3.0,
      3.0, 0.0, 4.0, 4.0, 0.0, 5.0, 3.0, 6.0, 5.0, 2.0, 3.0, 6.0, 1.0, 1.0, 3.0, 1.0,
      6.0, 7.0, 6.0, 2.0, 4.0, 4.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 7.0, 2.0, 1.0, 2.0,
      1.0, 1.0, 6.0, 4.0, 1.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10721578941308355
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03963984703144437
    mean_inference_ms: 2.0123178361922287
    mean_raw_obs_processing_ms: 0.4532684161806827
time_since_restore: 1351.0659594535828
time_this_iter_s: 10.175068855285645
time_total_s: 1351.0659594535828
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1692342940
timesteps_total: 996350
training_iteration: 132
trial_id: default
train step: 133
agent_timesteps_total: 1004400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033501625061035156
  StateBufferConnector_ms: 0.005750894546508789
  ViewRequirementAgentConnector_ms: 0.19216108322143555
counters:
  num_agent_steps_sampled: 1004400
  num_agent_steps_trained: 987500
  num_env_steps_sampled: 1004400
  num_env_steps_trained: 987500
  num_samples_added_to_queue: 1004000
  num_training_step_calls_since_last_synch_worker_weights: 591
  num_weight_broadcasts: 19661
custom_metrics: {}
date: 2023-08-18_16-15-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 7.0
episode_reward_mean: 3.36
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 7847
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0267516374588013
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 15.911884307861328
        total_loss: 33.006103515625
        var_gnorm: 63.35186767578125
        vf_explained_var: 0.2187967300415039
        vf_loss: 35.21518325805664
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1975.0
  learner_queue:
    size_count: 1980
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5657586020839869
  num_agent_steps_sampled: 1004400
  num_agent_steps_trained: 987500
  num_env_steps_sampled: 1004400
  num_env_steps_trained: 987500
  num_samples_added_to_queue: 1004000
  num_training_step_calls_since_last_synch_worker_weights: 591
  num_weight_broadcasts: 19661
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 392.753
    learner_load_time_ms: 15.233
    learner_load_wait_time_ms: 2.906
iterations_since_restore: 133
node_ip: 127.0.0.1
num_agent_steps_sampled: 1004400
num_agent_steps_trained: 987500
num_env_steps_sampled: 1004400
num_env_steps_sampled_this_iter: 8050
num_env_steps_sampled_throughput_per_sec: 804.9973322241502
num_env_steps_trained: 987500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9973487941866
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.42857142857143
  ram_util_percent: 81.84285714285714
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10723562593954349
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039590649382792345
  mean_inference_ms: 2.0112714005516197
  mean_raw_obs_processing_ms: 0.4528413828838692
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033501625061035156
    StateBufferConnector_ms: 0.005750894546508789
    ViewRequirementAgentConnector_ms: 0.19216108322143555
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 7.0
  episode_reward_mean: 3.36
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 4.0, 4.0, 0.0, 5.0, 3.0, 6.0, 5.0, 2.0, 3.0, 6.0, 1.0, 1.0,
      3.0, 1.0, 6.0, 7.0, 6.0, 2.0, 4.0, 4.0, 3.0, 2.0, 4.0, 3.0, 3.0, 1.0, 7.0, 2.0,
      1.0, 2.0, 1.0, 1.0, 6.0, 4.0, 1.0, 4.0, 4.0, 6.0, 2.0, 5.0, 3.0, 3.0, 3.0, 4.0,
      2.0, 5.0, 7.0, 0.0, 4.0, 4.0, 5.0, 3.0, 5.0, 1.0, 1.0, 0.0, 4.0, 4.0, 5.0, 5.0,
      3.0, 5.0, 4.0, 3.0, 3.0, 2.0, 5.0, 3.0, 1.0, 6.0, 1.0, 6.0, 4.0, 3.0, 2.0, 7.0,
      3.0, 0.0, 3.0, 4.0, 2.0, 6.0, 4.0, 7.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 5.0, 2.0,
      2.0, 1.0, 6.0, 3.0, 3.0, 0.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10723562593954349
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039590649382792345
    mean_inference_ms: 2.0112714005516197
    mean_raw_obs_processing_ms: 0.4528413828838692
time_since_restore: 1361.2691645622253
time_this_iter_s: 10.203205108642578
time_total_s: 1361.2691645622253
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692342950
timesteps_total: 1004400
training_iteration: 133
trial_id: default
train step: 134
agent_timesteps_total: 1012400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.032193660736083984
  StateBufferConnector_ms: 0.006090879440307617
  ViewRequirementAgentConnector_ms: 0.19761395454406738
counters:
  num_agent_steps_sampled: 1012400
  num_agent_steps_trained: 995500
  num_env_steps_sampled: 1012400
  num_env_steps_trained: 995500
  num_samples_added_to_queue: 1012000
  num_training_step_calls_since_last_synch_worker_weights: 440
  num_weight_broadcasts: 19818
custom_metrics: {}
date: 2023-08-18_16-16-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.52
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 7910
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.000662088394165
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -2.86173415184021
        total_loss: 14.487505912780762
        var_gnorm: 63.35224914550781
        vf_explained_var: 0.21243685483932495
        vf_loss: 35.69914245605469
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 1991.0
  learner_queue:
    size_count: 1997
    size_mean: 14.7
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6881943016134133
  num_agent_steps_sampled: 1012400
  num_agent_steps_trained: 995500
  num_env_steps_sampled: 1012400
  num_env_steps_trained: 995500
  num_samples_added_to_queue: 1012000
  num_training_step_calls_since_last_synch_worker_weights: 440
  num_weight_broadcasts: 19818
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 326.337
    learner_load_time_ms: 15.235
    learner_load_wait_time_ms: 2.887
iterations_since_restore: 134
node_ip: 127.0.0.1
num_agent_steps_sampled: 1012400
num_agent_steps_trained: 995500
num_env_steps_sampled: 1012400
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9992942816284
num_env_steps_trained: 995500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9992942816284
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 53.980000000000004
  ram_util_percent: 80.85333333333332
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10720310692879764
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0395568693845604
  mean_inference_ms: 2.0102669806619833
  mean_raw_obs_processing_ms: 0.45260142744590837
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.032193660736083984
    StateBufferConnector_ms: 0.006090879440307617
    ViewRequirementAgentConnector_ms: 0.19761395454406738
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.52
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 3.0, 2.0, 5.0, 3.0, 1.0, 6.0, 1.0, 6.0, 4.0, 3.0, 2.0,
      7.0, 3.0, 0.0, 3.0, 4.0, 2.0, 6.0, 4.0, 7.0, 4.0, 4.0, 3.0, 6.0, 3.0, 3.0, 5.0,
      2.0, 2.0, 1.0, 6.0, 3.0, 3.0, 0.0, 1.0, 4.0, 2.0, 4.0, 2.0, 6.0, 3.0, 3.0, 1.0,
      7.0, 3.0, 6.0, 5.0, 5.0, 2.0, 2.0, 2.0, 6.0, 3.0, 2.0, 7.0, 2.0, 1.0, 3.0, 6.0,
      2.0, 7.0, 3.0, 6.0, 4.0, 4.0, 2.0, 4.0, 3.0, 1.0, 1.0, 1.0, 5.0, 3.0, 3.0, 4.0,
      4.0, 0.0, 8.0, 5.0, 4.0, 5.0, 5.0, 3.0, 6.0, 1.0, 3.0, 3.0, 4.0, 5.0, 1.0, 5.0,
      4.0, 6.0, 3.0, 4.0, 5.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10720310692879764
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0395568693845604
    mean_inference_ms: 2.0102669806619833
    mean_raw_obs_processing_ms: 0.45260142744590837
time_since_restore: 1371.5214014053345
time_this_iter_s: 10.25223684310913
time_total_s: 1371.5214014053345
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.087
timestamp: 1692342961
timesteps_total: 1012400
training_iteration: 134
trial_id: default
train step: 135
agent_timesteps_total: 1020300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033480167388916016
  StateBufferConnector_ms: 0.0058629512786865234
  ViewRequirementAgentConnector_ms: 0.19780802726745605
counters:
  num_agent_steps_sampled: 1020300
  num_agent_steps_trained: 1003500
  num_env_steps_sampled: 1020300
  num_env_steps_trained: 1003500
  num_samples_added_to_queue: 1020000
  num_training_step_calls_since_last_synch_worker_weights: 6
  num_weight_broadcasts: 19973
custom_metrics: {}
date: 2023-08-18_16-16-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.01
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 7971
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 1.0115388631820679
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -14.661734580993652
        total_loss: -1.536350965499878
        var_gnorm: 63.35271072387695
        vf_explained_var: 0.20041382312774658
        vf_loss: 27.262306213378906
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2007.0
  learner_queue:
    size_count: 2014
    size_mean: 14.82
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.693398948859955
  num_agent_steps_sampled: 1020300
  num_agent_steps_trained: 1003500
  num_env_steps_sampled: 1020300
  num_env_steps_trained: 1003500
  num_samples_added_to_queue: 1020000
  num_training_step_calls_since_last_synch_worker_weights: 6
  num_weight_broadcasts: 19973
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 286.835
    learner_load_time_ms: 16.326
    learner_load_wait_time_ms: 2.673
iterations_since_restore: 135
node_ip: 127.0.0.1
num_agent_steps_sampled: 1020300
num_agent_steps_trained: 1003500
num_env_steps_sampled: 1020300
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.9954984444588
num_env_steps_trained: 1003500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9954414627431
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 53.0
  ram_util_percent: 81.39285714285712
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10713075793475298
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039544088005568946
  mean_inference_ms: 2.009636091749547
  mean_raw_obs_processing_ms: 0.4525350311888215
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033480167388916016
    StateBufferConnector_ms: 0.0058629512786865234
    ViewRequirementAgentConnector_ms: 0.19780802726745605
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.01
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 7.0, 3.0, 6.0, 4.0, 4.0, 2.0, 4.0, 3.0, 1.0, 1.0, 1.0, 5.0,
      3.0, 3.0, 4.0, 4.0, 0.0, 8.0, 5.0, 4.0, 5.0, 5.0, 3.0, 6.0, 1.0, 3.0, 3.0, 4.0,
      5.0, 1.0, 5.0, 4.0, 6.0, 3.0, 4.0, 5.0, 2.0, 1.0, 7.0, 1.0, 4.0, 1.0, 3.0, 1.0,
      3.0, 2.0, 4.0, 1.0, 1.0, 2.0, 2.0, 1.0, 3.0, 5.0, 1.0, 4.0, 0.0, 1.0, 0.0, 3.0,
      1.0, 2.0, 3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 2.0, 3.0, 7.0, 4.0,
      2.0, 3.0, 0.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 3.0, 1.0, 6.0, 5.0, 0.0, 3.0, 5.0,
      4.0, 4.0, 2.0, 3.0, 4.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10713075793475298
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039544088005568946
    mean_inference_ms: 2.009636091749547
    mean_raw_obs_processing_ms: 0.4525350311888215
time_since_restore: 1381.7976994514465
time_this_iter_s: 10.27629804611206
time_total_s: 1381.7976994514465
timers:
  sample_time_ms: 0.088
  synch_weights_time_ms: 0.367
  training_iteration_time_ms: 0.564
timestamp: 1692342971
timesteps_total: 1020300
training_iteration: 135
trial_id: default
train step: 136
agent_timesteps_total: 1028300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03250932693481445
  StateBufferConnector_ms: 0.005812406539916992
  ViewRequirementAgentConnector_ms: 0.19279861450195312
counters:
  num_agent_steps_sampled: 1028300
  num_agent_steps_trained: 1011500
  num_env_steps_sampled: 1028300
  num_env_steps_trained: 1011500
  num_samples_added_to_queue: 1028000
  num_training_step_calls_since_last_synch_worker_weights: 499
  num_weight_broadcasts: 20130
custom_metrics: {}
date: 2023-08-18_16-16-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.3
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 8034
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.994560182094574
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 43.896324157714844
        total_loss: 63.06217575073242
        var_gnorm: 63.35316848754883
        vf_explained_var: 0.25880658626556396
        vf_loss: 39.32626724243164
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2023.0
  learner_queue:
    size_count: 2028
    size_mean: 14.56
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7681628884240277
  num_agent_steps_sampled: 1028300
  num_agent_steps_trained: 1011500
  num_env_steps_sampled: 1028300
  num_env_steps_trained: 1011500
  num_samples_added_to_queue: 1028000
  num_training_step_calls_since_last_synch_worker_weights: 499
  num_weight_broadcasts: 20130
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 367.837
    learner_load_time_ms: 29.908
    learner_load_wait_time_ms: 2.637
iterations_since_restore: 136
node_ip: 127.0.0.1
num_agent_steps_sampled: 1028300
num_agent_steps_trained: 1011500
num_env_steps_sampled: 1028300
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9980163623404
num_env_steps_trained: 1011500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9980163623404
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.75333333333332
  ram_util_percent: 81.29333333333334
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10707943317568214
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039522615150242205
  mean_inference_ms: 2.008847395451304
  mean_raw_obs_processing_ms: 0.452381728752759
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03250932693481445
    StateBufferConnector_ms: 0.005812406539916992
    ViewRequirementAgentConnector_ms: 0.19279861450195312
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.3
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 1.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 3.0, 1.0, 2.0, 3.0, 7.0,
      4.0, 2.0, 3.0, 0.0, 3.0, 3.0, 3.0, 5.0, 3.0, 3.0, 3.0, 1.0, 6.0, 5.0, 0.0, 3.0,
      5.0, 4.0, 4.0, 2.0, 3.0, 4.0, 1.0, 3.0, 4.0, 4.0, 4.0, 6.0, 4.0, 4.0, 2.0, 2.0,
      2.0, 2.0, 4.0, 1.0, 2.0, 2.0, 0.0, 5.0, 2.0, 2.0, 3.0, 3.0, 6.0, 3.0, 2.0, 2.0,
      3.0, 2.0, 4.0, 2.0, 4.0, 6.0, 8.0, 5.0, 0.0, 2.0, 5.0, 2.0, 2.0, 7.0, 5.0, 0.0,
      2.0, 7.0, 4.0, 6.0, 5.0, 2.0, 5.0, 5.0, 3.0, 2.0, 5.0, 4.0, 5.0, 4.0, 2.0, 8.0,
      5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10707943317568214
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039522615150242205
    mean_inference_ms: 2.008847395451304
    mean_raw_obs_processing_ms: 0.452381728752759
time_since_restore: 1392.009491443634
time_this_iter_s: 10.2117919921875
time_total_s: 1392.009491443634
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342981
timesteps_total: 1028300
training_iteration: 136
trial_id: default
train step: 137
agent_timesteps_total: 1036000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03196287155151367
  StateBufferConnector_ms: 0.005815267562866211
  ViewRequirementAgentConnector_ms: 0.19280552864074707
counters:
  num_agent_steps_sampled: 1036000
  num_agent_steps_trained: 1019500
  num_env_steps_sampled: 1036000
  num_env_steps_trained: 1019500
  num_samples_added_to_queue: 1036000
  num_training_step_calls_since_last_synch_worker_weights: 729
  num_weight_broadcasts: 20278
custom_metrics: {}
date: 2023-08-18_16-16-31
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.74
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 8095
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.9869027733802795
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -20.889965057373047
        total_loss: -13.584117889404297
        var_gnorm: 63.353572845458984
        vf_explained_var: 0.2270662784576416
        vf_loss: 15.598596572875977
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2039.0
  learner_queue:
    size_count: 2043
    size_mean: 14.54
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.768728356758041
  num_agent_steps_sampled: 1036000
  num_agent_steps_trained: 1019500
  num_env_steps_sampled: 1036000
  num_env_steps_trained: 1019500
  num_samples_added_to_queue: 1036000
  num_training_step_calls_since_last_synch_worker_weights: 729
  num_weight_broadcasts: 20278
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 427.3
    learner_load_time_ms: 29.841
    learner_load_wait_time_ms: 2.624
iterations_since_restore: 137
node_ip: 127.0.0.1
num_agent_steps_sampled: 1036000
num_agent_steps_trained: 1019500
num_env_steps_sampled: 1036000
num_env_steps_sampled_this_iter: 7700
num_env_steps_sampled_throughput_per_sec: 769.9927669250925
num_env_steps_trained: 1019500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9924851169792
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.83571428571428
  ram_util_percent: 81.83571428571427
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10704226574423341
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03950630060078032
  mean_inference_ms: 2.0083211396060405
  mean_raw_obs_processing_ms: 0.45226154250113965
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03196287155151367
    StateBufferConnector_ms: 0.005815267562866211
    ViewRequirementAgentConnector_ms: 0.19280552864074707
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.74
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 4.0, 2.0, 4.0, 6.0, 8.0, 5.0, 0.0, 2.0, 5.0, 2.0, 2.0,
      7.0, 5.0, 0.0, 2.0, 7.0, 4.0, 6.0, 5.0, 2.0, 5.0, 5.0, 3.0, 2.0, 5.0, 4.0, 5.0,
      4.0, 2.0, 8.0, 5.0, 2.0, 3.0, 3.0, 4.0, 3.0, 5.0, 7.0, 1.0, 7.0, 4.0, 5.0, 3.0,
      2.0, 1.0, 1.0, 6.0, 4.0, 3.0, 3.0, 2.0, 2.0, 2.0, 5.0, 4.0, 3.0, 0.0, 4.0, 2.0,
      8.0, 6.0, 1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 5.0, 2.0, 3.0, 3.0, 1.0, 3.0, 2.0, 3.0,
      3.0, 5.0, 6.0, 5.0, 2.0, 3.0, 7.0, 4.0, 7.0, 5.0, 7.0, 3.0, 3.0, 1.0, 3.0, 4.0,
      4.0, 4.0, 3.0, 1.0, 1.0, 2.0, 10.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10704226574423341
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03950630060078032
    mean_inference_ms: 2.0083211396060405
    mean_raw_obs_processing_ms: 0.45226154250113965
time_since_restore: 1402.1695370674133
time_this_iter_s: 10.160045623779297
time_total_s: 1402.1695370674133
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692342991
timesteps_total: 1036000
training_iteration: 137
trial_id: default
train step: 138
agent_timesteps_total: 1044150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031609535217285156
  StateBufferConnector_ms: 0.005697727203369141
  ViewRequirementAgentConnector_ms: 0.191878080368042
counters:
  num_agent_steps_sampled: 1044150
  num_agent_steps_trained: 1027500
  num_env_steps_sampled: 1044150
  num_env_steps_trained: 1027500
  num_samples_added_to_queue: 1044000
  num_training_step_calls_since_last_synch_worker_weights: 226
  num_weight_broadcasts: 20437
custom_metrics: {}
date: 2023-08-18_16-16-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.7
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 8158
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.9837762713432312
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 6.5015411376953125
        total_loss: 15.196008682250977
        var_gnorm: 63.3538932800293
        vf_explained_var: 0.291323184967041
        vf_loss: 18.372711181640625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2055.0
  learner_queue:
    size_count: 2061
    size_mean: 14.7
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7691806012954132
  num_agent_steps_sampled: 1044150
  num_agent_steps_trained: 1027500
  num_env_steps_sampled: 1044150
  num_env_steps_trained: 1027500
  num_samples_added_to_queue: 1044000
  num_training_step_calls_since_last_synch_worker_weights: 226
  num_weight_broadcasts: 20437
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 292.923
    learner_load_time_ms: 29.804
    learner_load_wait_time_ms: 2.717
iterations_since_restore: 138
node_ip: 127.0.0.1
num_agent_steps_sampled: 1044150
num_agent_steps_trained: 1027500
num_env_steps_sampled: 1044150
num_env_steps_sampled_this_iter: 8150
num_env_steps_sampled_throughput_per_sec: 814.995103388642
num_env_steps_trained: 1027500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9951935103234
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.31428571428571
  ram_util_percent: 81.33571428571427
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1069922891619309
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03948382556428218
  mean_inference_ms: 2.0074857213128077
  mean_raw_obs_processing_ms: 0.45207755498768565
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031609535217285156
    StateBufferConnector_ms: 0.005697727203369141
    ViewRequirementAgentConnector_ms: 0.191878080368042
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.7
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 2.0, 6.0, 4.0, 6.0, 4.0, 5.0, 2.0, 3.0, 3.0, 1.0, 3.0, 2.0,
      3.0, 3.0, 5.0, 6.0, 5.0, 2.0, 3.0, 7.0, 4.0, 7.0, 5.0, 7.0, 3.0, 3.0, 1.0, 3.0,
      4.0, 4.0, 4.0, 3.0, 1.0, 1.0, 2.0, 10.0, 6.0, 1.0, 2.0, 2.0, 2.0, 4.0, 7.0,
      6.0, 5.0, 0.0, 4.0, 6.0, 2.0, 0.0, 3.0, 5.0, 2.0, 3.0, 4.0, 4.0, 0.0, 5.0, 5.0,
      3.0, 5.0, 4.0, 6.0, 2.0, 2.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 4.0, 3.0, 3.0, 4.0,
      3.0, 9.0, 4.0, 3.0, 4.0, 2.0, 6.0, 3.0, 5.0, 7.0, 3.0, 8.0, 2.0, 1.0, 3.0, 3.0,
      4.0, 6.0, 4.0, 4.0, 3.0, 5.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1069922891619309
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03948382556428218
    mean_inference_ms: 2.0074857213128077
    mean_raw_obs_processing_ms: 0.45207755498768565
time_since_restore: 1412.4348170757294
time_this_iter_s: 10.26528000831604
time_total_s: 1412.4348170757294
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692343002
timesteps_total: 1044150
training_iteration: 138
trial_id: default
train step: 139
agent_timesteps_total: 1052450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030959606170654297
  StateBufferConnector_ms: 0.005637645721435547
  ViewRequirementAgentConnector_ms: 0.1878204345703125
counters:
  num_agent_steps_sampled: 1052450
  num_agent_steps_trained: 1035500
  num_env_steps_sampled: 1052450
  num_env_steps_trained: 1035500
  num_samples_added_to_queue: 1052000
  num_training_step_calls_since_last_synch_worker_weights: 670
  num_weight_broadcasts: 20598
custom_metrics: {}
date: 2023-08-18_16-16-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.0
episode_reward_min: 1.0
episodes_this_iter: 65
episodes_total: 8223
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.299999999999955
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.9536418914794922
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -18.47919273376465
        total_loss: -5.345588684082031
        var_gnorm: 63.35436248779297
        vf_explained_var: 0.22452658414840698
        vf_loss: 27.220849990844727
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2071.0
  learner_queue:
    size_count: 2076
    size_mean: 14.84
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.616910634512619
  num_agent_steps_sampled: 1052450
  num_agent_steps_trained: 1035500
  num_env_steps_sampled: 1052450
  num_env_steps_trained: 1035500
  num_samples_added_to_queue: 1052000
  num_training_step_calls_since_last_synch_worker_weights: 670
  num_weight_broadcasts: 20598
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 376.175
    learner_load_time_ms: 30.187
    learner_load_wait_time_ms: 2.95
iterations_since_restore: 139
node_ip: 127.0.0.1
num_agent_steps_sampled: 1052450
num_agent_steps_trained: 1035500
num_env_steps_sampled: 1052450
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9929552676183
num_env_steps_trained: 1035500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9932098964996
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 46.54666666666667
  ram_util_percent: 80.60666666666667
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10696993135270301
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039436323502348464
  mean_inference_ms: 2.006067736459096
  mean_raw_obs_processing_ms: 0.45166370835037895
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030959606170654297
    StateBufferConnector_ms: 0.005637645721435547
    ViewRequirementAgentConnector_ms: 0.1878204345703125
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.0
  episode_reward_min: 1.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 1.0, 1.0, 3.0, 5.0, 4.0, 5.0, 4.0, 3.0, 3.0, 4.0, 3.0, 9.0,
      4.0, 3.0, 4.0, 2.0, 6.0, 3.0, 5.0, 7.0, 3.0, 8.0, 2.0, 1.0, 3.0, 3.0, 4.0, 6.0,
      4.0, 4.0, 3.0, 5.0, 4.0, 3.0, 3.0, 2.0, 4.0, 7.0, 4.0, 3.0, 8.0, 5.0, 4.0, 4.0,
      8.0, 3.0, 3.0, 4.0, 4.0, 6.0, 6.0, 5.0, 2.0, 5.0, 4.0, 6.0, 7.0, 3.0, 3.0, 5.0,
      4.0, 3.0, 9.0, 4.0, 2.0, 5.0, 4.0, 3.0, 3.0, 2.0, 4.0, 7.0, 3.0, 4.0, 3.0, 6.0,
      6.0, 1.0, 7.0, 5.0, 7.0, 3.0, 2.0, 3.0, 1.0, 4.0, 1.0, 3.0, 2.0, 3.0, 4.0, 4.0,
      3.0, 6.0, 1.0, 4.0, 2.0, 6.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10696993135270301
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039436323502348464
    mean_inference_ms: 2.006067736459096
    mean_raw_obs_processing_ms: 0.45166370835037895
time_since_restore: 1422.6468710899353
time_this_iter_s: 10.212054014205933
time_total_s: 1422.6468710899353
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692343012
timesteps_total: 1052450
training_iteration: 139
trial_id: default
train step: 140
agent_timesteps_total: 1060100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03144121170043945
  StateBufferConnector_ms: 0.0056879520416259766
  ViewRequirementAgentConnector_ms: 0.19282960891723633
counters:
  num_agent_steps_sampled: 1060100
  num_agent_steps_trained: 1043500
  num_env_steps_sampled: 1060100
  num_env_steps_trained: 1043500
  num_samples_added_to_queue: 1060000
  num_training_step_calls_since_last_synch_worker_weights: 817
  num_weight_broadcasts: 20747
custom_metrics: {}
date: 2023-08-18_16-17-02
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.68
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 8283
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.9866183996200562
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -29.34745216369629
        total_loss: -16.190093994140625
        var_gnorm: 63.354888916015625
        vf_explained_var: 0.2008102536201477
        vf_loss: 27.30133628845215
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2087.0
  learner_queue:
    size_count: 2095
    size_mean: 14.68
    size_quantiles: [9.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.9124852940611072
  num_agent_steps_sampled: 1060100
  num_agent_steps_trained: 1043500
  num_env_steps_sampled: 1060100
  num_env_steps_trained: 1043500
  num_samples_added_to_queue: 1060000
  num_training_step_calls_since_last_synch_worker_weights: 817
  num_weight_broadcasts: 20747
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 169.187
    learner_load_time_ms: 29.81
    learner_load_wait_time_ms: 2.486
iterations_since_restore: 140
node_ip: 127.0.0.1
num_agent_steps_sampled: 1060100
num_agent_steps_trained: 1043500
num_env_steps_sampled: 1060100
num_env_steps_sampled_this_iter: 7650
num_env_steps_sampled_throughput_per_sec: 764.9957138540087
num_env_steps_trained: 1043500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9955177558262
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 54.521428571428565
  ram_util_percent: 80.86428571428573
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10687462944866283
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039433292150156854
  mean_inference_ms: 2.0055650677584076
  mean_raw_obs_processing_ms: 0.4517159297533842
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03144121170043945
    StateBufferConnector_ms: 0.0056879520416259766
    ViewRequirementAgentConnector_ms: 0.19282960891723633
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.68
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 4.0, 3.0, 9.0, 4.0, 2.0, 5.0, 4.0, 3.0, 3.0, 2.0, 4.0, 7.0,
      3.0, 4.0, 3.0, 6.0, 6.0, 1.0, 7.0, 5.0, 7.0, 3.0, 2.0, 3.0, 1.0, 4.0, 1.0, 3.0,
      2.0, 3.0, 4.0, 4.0, 3.0, 6.0, 1.0, 4.0, 2.0, 6.0, 4.0, 5.0, 4.0, 1.0, 2.0, 8.0,
      1.0, 2.0, 3.0, 1.0, 2.0, 2.0, 5.0, 5.0, 4.0, 5.0, 4.0, 3.0, 4.0, 1.0, 5.0, 2.0,
      0.0, 8.0, 5.0, 4.0, 3.0, 6.0, 7.0, 8.0, 3.0, 3.0, 4.0, 2.0, 6.0, 6.0, 0.0, 5.0,
      5.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 7.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 3.0, 3.0,
      4.0, 4.0, 6.0, 5.0, 3.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10687462944866283
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039433292150156854
    mean_inference_ms: 2.0055650677584076
    mean_raw_obs_processing_ms: 0.4517159297533842
time_since_restore: 1432.9573311805725
time_this_iter_s: 10.310460090637207
time_total_s: 1432.9573311805725
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.084
timestamp: 1692343022
timesteps_total: 1060100
training_iteration: 140
trial_id: default
train step: 141
agent_timesteps_total: 1068200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03165793418884277
  StateBufferConnector_ms: 0.005791902542114258
  ViewRequirementAgentConnector_ms: 0.19199323654174805
counters:
  num_agent_steps_sampled: 1068200
  num_agent_steps_trained: 1051500
  num_env_steps_sampled: 1068200
  num_env_steps_trained: 1051500
  num_samples_added_to_queue: 1068000
  num_training_step_calls_since_last_synch_worker_weights: 1083
  num_weight_broadcasts: 20904
custom_metrics: {}
date: 2023-08-18_16-17-12
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.62
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 8346
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.9812245965003967
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -18.10764503479004
        total_loss: -4.992123126983643
        var_gnorm: 63.355411529541016
        vf_explained_var: 0.20262324810028076
        vf_loss: 27.212268829345703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2103.0
  learner_queue:
    size_count: 2107
    size_mean: 14.22
    size_quantiles: [9.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 2.0908371529126795
  num_agent_steps_sampled: 1068200
  num_agent_steps_trained: 1051500
  num_env_steps_sampled: 1068200
  num_env_steps_trained: 1051500
  num_samples_added_to_queue: 1068000
  num_training_step_calls_since_last_synch_worker_weights: 1083
  num_weight_broadcasts: 20904
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 758.793
    learner_load_time_ms: 18.231
    learner_load_wait_time_ms: 14.998
iterations_since_restore: 141
node_ip: 127.0.0.1
num_agent_steps_sampled: 1068200
num_agent_steps_trained: 1051500
num_env_steps_sampled: 1068200
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9992661482784
num_env_steps_trained: 1051500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9992752081762
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.88571428571429
  ram_util_percent: 80.5
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1068265565098537
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03941164755603243
  mean_inference_ms: 2.0048805468316653
  mean_raw_obs_processing_ms: 0.4515525915812431
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03165793418884277
    StateBufferConnector_ms: 0.005791902542114258
    ViewRequirementAgentConnector_ms: 0.19199323654174805
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.62
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 4.0, 3.0, 6.0, 7.0, 8.0, 3.0, 3.0, 4.0, 2.0, 6.0, 6.0, 0.0,
      5.0, 5.0, 1.0, 2.0, 3.0, 2.0, 3.0, 2.0, 7.0, 2.0, 4.0, 1.0, 3.0, 4.0, 1.0, 3.0,
      3.0, 4.0, 4.0, 6.0, 5.0, 3.0, 3.0, 5.0, 7.0, 5.0, 1.0, 4.0, 4.0, 4.0, 5.0, 3.0,
      5.0, 2.0, 4.0, 3.0, 3.0, 3.0, 5.0, 5.0, 6.0, 3.0, 3.0, 3.0, 4.0, 2.0, 5.0, 2.0,
      1.0, 2.0, 2.0, 5.0, 2.0, 2.0, 6.0, 3.0, 3.0, 7.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0,
      4.0, 5.0, 2.0, 3.0, 1.0, 3.0, 3.0, 5.0, 4.0, 5.0, 3.0, 4.0, 4.0, 1.0, 6.0, 3.0,
      5.0, 5.0, 4.0, 1.0, 4.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1068265565098537
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03941164755603243
    mean_inference_ms: 2.0048805468316653
    mean_raw_obs_processing_ms: 0.4515525915812431
time_since_restore: 1443.1183471679688
time_this_iter_s: 10.16101598739624
time_total_s: 1443.1183471679688
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.072
timestamp: 1692343032
timesteps_total: 1068200
training_iteration: 141
trial_id: default
train step: 142
agent_timesteps_total: 1076350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031470298767089844
  StateBufferConnector_ms: 0.005754232406616211
  ViewRequirementAgentConnector_ms: 0.18844056129455566
counters:
  num_agent_steps_sampled: 1076350
  num_agent_steps_trained: 1059500
  num_env_steps_sampled: 1076350
  num_env_steps_trained: 1059500
  num_samples_added_to_queue: 1076000
  num_training_step_calls_since_last_synch_worker_weights: 39
  num_weight_broadcasts: 21064
custom_metrics: {}
date: 2023-08-18_16-17-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.68
episode_reward_min: 1.0
episodes_this_iter: 64
episodes_total: 8410
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.934626042842865
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 32.83967590332031
        total_loss: 49.23140335083008
        var_gnorm: 63.355865478515625
        vf_explained_var: 0.27091115713119507
        vf_loss: 33.71807861328125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2119.0
  learner_queue:
    size_count: 2126
    size_mean: 14.42
    size_quantiles: [9.0, 11.0, 16.0, 16.0, 16.0]
    size_std: 2.136258411335108
  num_agent_steps_sampled: 1076350
  num_agent_steps_trained: 1059500
  num_env_steps_sampled: 1076350
  num_env_steps_trained: 1059500
  num_samples_added_to_queue: 1076000
  num_training_step_calls_since_last_synch_worker_weights: 39
  num_weight_broadcasts: 21064
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 249.459
    learner_load_time_ms: 18.085
    learner_load_wait_time_ms: 2.575
iterations_since_restore: 142
node_ip: 127.0.0.1
num_agent_steps_sampled: 1076350
num_agent_steps_trained: 1059500
num_env_steps_sampled: 1076350
num_env_steps_sampled_this_iter: 8150
num_env_steps_sampled_throughput_per_sec: 814.9956085918536
num_env_steps_trained: 1059500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9956894153164
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.39333333333333
  ram_util_percent: 80.20666666666668
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10681571932976908
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039369682949279054
  mean_inference_ms: 2.0037299601178806
  mean_raw_obs_processing_ms: 0.45117182638524606
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031470298767089844
    StateBufferConnector_ms: 0.005754232406616211
    ViewRequirementAgentConnector_ms: 0.18844056129455566
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.68
  episode_reward_min: 1.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 2.0, 2.0, 6.0, 3.0, 3.0, 7.0, 3.0, 4.0, 3.0, 3.0, 4.0, 3.0,
      4.0, 5.0, 2.0, 3.0, 1.0, 3.0, 3.0, 5.0, 4.0, 5.0, 3.0, 4.0, 4.0, 1.0, 6.0, 3.0,
      5.0, 5.0, 4.0, 1.0, 4.0, 2.0, 3.0, 3.0, 4.0, 2.0, 2.0, 5.0, 4.0, 2.0, 3.0, 1.0,
      3.0, 5.0, 3.0, 4.0, 5.0, 2.0, 5.0, 2.0, 3.0, 8.0, 3.0, 5.0, 6.0, 3.0, 4.0, 4.0,
      8.0, 8.0, 5.0, 3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 2.0, 5.0, 3.0, 1.0, 4.0, 3.0,
      2.0, 3.0, 2.0, 4.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 2.0, 5.0, 4.0, 2.0, 3.0, 4.0,
      3.0, 2.0, 4.0, 3.0, 7.0, 2.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10681571932976908
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039369682949279054
    mean_inference_ms: 2.0037299601178806
    mean_raw_obs_processing_ms: 0.45117182638524606
time_since_restore: 1453.3600280284882
time_this_iter_s: 10.24168086051941
time_total_s: 1453.3600280284882
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692343043
timesteps_total: 1076350
training_iteration: 142
trial_id: default
train step: 143
agent_timesteps_total: 1084650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031023502349853516
  StateBufferConnector_ms: 0.005631685256958008
  ViewRequirementAgentConnector_ms: 0.18625736236572266
counters:
  num_agent_steps_sampled: 1084650
  num_agent_steps_trained: 1068000
  num_env_steps_sampled: 1084650
  num_env_steps_trained: 1068000
  num_samples_added_to_queue: 1084500
  num_training_step_calls_since_last_synch_worker_weights: 154
  num_weight_broadcasts: 21227
custom_metrics: {}
date: 2023-08-18_16-17-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.69
episode_reward_min: 1.0
episodes_this_iter: 64
episodes_total: 8474
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.9257437586784363
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -9.161601066589355
        total_loss: 1.9033018350601196
        var_gnorm: 63.35633087158203
        vf_explained_var: 0.26082098484039307
        vf_loss: 23.05554962158203
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2136.0
  learner_queue:
    size_count: 2142
    size_mean: 14.24
    size_quantiles: [9.0, 11.0, 15.5, 16.0, 16.0]
    size_std: 2.1868699092538635
  num_agent_steps_sampled: 1084650
  num_agent_steps_trained: 1068000
  num_env_steps_sampled: 1084650
  num_env_steps_trained: 1068000
  num_samples_added_to_queue: 1084500
  num_training_step_calls_since_last_synch_worker_weights: 154
  num_weight_broadcasts: 21227
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 276.289
    learner_load_time_ms: 29.258
    learner_load_wait_time_ms: 2.665
iterations_since_restore: 143
node_ip: 127.0.0.1
num_agent_steps_sampled: 1084650
num_agent_steps_trained: 1068000
num_env_steps_sampled: 1084650
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9920450019338
num_env_steps_trained: 1068000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9918533152334
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 51.35714285714287
  ram_util_percent: 80.45
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10674742014260583
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039339501860617104
  mean_inference_ms: 2.0025333511708197
  mean_raw_obs_processing_ms: 0.45091535412968087
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031023502349853516
    StateBufferConnector_ms: 0.005631685256958008
    ViewRequirementAgentConnector_ms: 0.18625736236572266
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.69
  episode_reward_min: 1.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 3.0, 3.0, 6.0, 6.0, 6.0, 2.0, 5.0, 3.0, 1.0, 4.0, 3.0,
      2.0, 3.0, 2.0, 4.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 2.0, 5.0, 4.0, 2.0, 3.0, 4.0,
      3.0, 2.0, 4.0, 3.0, 7.0, 2.0, 5.0, 3.0, 2.0, 6.0, 3.0, 3.0, 1.0, 1.0, 1.0, 1.0,
      7.0, 7.0, 5.0, 7.0, 2.0, 4.0, 3.0, 3.0, 5.0, 2.0, 6.0, 3.0, 7.0, 3.0, 8.0, 3.0,
      1.0, 4.0, 3.0, 6.0, 7.0, 4.0, 6.0, 2.0, 8.0, 4.0, 5.0, 6.0, 2.0, 6.0, 2.0, 2.0,
      2.0, 1.0, 4.0, 7.0, 1.0, 6.0, 5.0, 3.0, 4.0, 4.0, 5.0, 2.0, 3.0, 2.0, 2.0, 6.0,
      2.0, 4.0, 3.0, 4.0, 1.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10674742014260583
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039339501860617104
    mean_inference_ms: 2.0025333511708197
    mean_raw_obs_processing_ms: 0.45091535412968087
time_since_restore: 1463.6392607688904
time_this_iter_s: 10.279232740402222
time_total_s: 1463.6392607688904
timers:
  sample_time_ms: 0.046
  synch_weights_time_ms: 0.012
  training_iteration_time_ms: 0.116
timestamp: 1692343053
timesteps_total: 1084650
training_iteration: 143
trial_id: default
train step: 144
agent_timesteps_total: 1092850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030646324157714844
  StateBufferConnector_ms: 0.005507946014404297
  ViewRequirementAgentConnector_ms: 0.18661189079284668
counters:
  num_agent_steps_sampled: 1092850
  num_agent_steps_trained: 1076000
  num_env_steps_sampled: 1092850
  num_env_steps_trained: 1076000
  num_samples_added_to_queue: 1092500
  num_training_step_calls_since_last_synch_worker_weights: 1187
  num_weight_broadcasts: 21387
custom_metrics: {}
date: 2023-08-18_16-17-43
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.8
episode_reward_min: 1.0
episodes_this_iter: 64
episodes_total: 8538
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.903532862663269
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 23.023120880126953
        total_loss: 40.59351348876953
        var_gnorm: 63.35687255859375
        vf_explained_var: 0.2599213719367981
        vf_loss: 36.044315338134766
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2152.0
  learner_queue:
    size_count: 2156
    size_mean: 14.72
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7440183485273313
  num_agent_steps_sampled: 1092850
  num_agent_steps_trained: 1076000
  num_env_steps_sampled: 1092850
  num_env_steps_trained: 1076000
  num_samples_added_to_queue: 1092500
  num_training_step_calls_since_last_synch_worker_weights: 1187
  num_weight_broadcasts: 21387
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 422.247
    learner_load_time_ms: 29.647
    learner_load_wait_time_ms: 2.733
iterations_since_restore: 144
node_ip: 127.0.0.1
num_agent_steps_sampled: 1092850
num_agent_steps_trained: 1076000
num_env_steps_sampled: 1092850
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9937634942399
num_env_steps_trained: 1076000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9939156041365
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 49.31428571428571
  ram_util_percent: 80.85714285714286
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1066761992129171
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039306483450149206
  mean_inference_ms: 2.0013174410077084
  mean_raw_obs_processing_ms: 0.4506394399843816
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030646324157714844
    StateBufferConnector_ms: 0.005507946014404297
    ViewRequirementAgentConnector_ms: 0.18661189079284668
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.8
  episode_reward_min: 1.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 7.0, 4.0, 6.0, 2.0, 8.0, 4.0, 5.0, 6.0, 2.0, 6.0, 2.0, 2.0,
      2.0, 1.0, 4.0, 7.0, 1.0, 6.0, 5.0, 3.0, 4.0, 4.0, 5.0, 2.0, 3.0, 2.0, 2.0, 6.0,
      2.0, 4.0, 3.0, 4.0, 1.0, 4.0, 2.0, 2.0, 2.0, 1.0, 4.0, 6.0, 1.0, 7.0, 4.0, 4.0,
      6.0, 5.0, 5.0, 3.0, 4.0, 6.0, 1.0, 7.0, 3.0, 1.0, 3.0, 3.0, 2.0, 4.0, 1.0, 3.0,
      3.0, 7.0, 7.0, 6.0, 5.0, 2.0, 6.0, 4.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 4.0,
      4.0, 4.0, 5.0, 6.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 1.0, 5.0, 6.0, 7.0, 2.0, 1.0,
      3.0, 4.0, 9.0, 4.0, 2.0, 5.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1066761992129171
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039306483450149206
    mean_inference_ms: 2.0013174410077084
    mean_raw_obs_processing_ms: 0.4506394399843816
time_since_restore: 1473.7788290977478
time_this_iter_s: 10.139568328857422
time_total_s: 1473.7788290977478
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692343063
timesteps_total: 1092850
training_iteration: 144
trial_id: default
train step: 145
agent_timesteps_total: 1101050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03086376190185547
  StateBufferConnector_ms: 0.005623817443847656
  ViewRequirementAgentConnector_ms: 0.18782615661621094
counters:
  num_agent_steps_sampled: 1101050
  num_agent_steps_trained: 1084500
  num_env_steps_sampled: 1101050
  num_env_steps_trained: 1084500
  num_samples_added_to_queue: 1101000
  num_training_step_calls_since_last_synch_worker_weights: 695
  num_weight_broadcasts: 21548
custom_metrics: {}
date: 2023-08-18_16-17-53
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.82
episode_reward_min: 1.0
episodes_this_iter: 64
episodes_total: 8602
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.9113492965698242
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -33.37168884277344
        total_loss: -20.645427703857422
        var_gnorm: 63.357303619384766
        vf_explained_var: 0.2239854335784912
        vf_loss: 26.363872528076172
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2169.0
  learner_queue:
    size_count: 2173
    size_mean: 14.78
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7353962083628052
  num_agent_steps_sampled: 1101050
  num_agent_steps_trained: 1084500
  num_env_steps_sampled: 1101050
  num_env_steps_trained: 1084500
  num_samples_added_to_queue: 1101000
  num_training_step_calls_since_last_synch_worker_weights: 695
  num_weight_broadcasts: 21548
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 388.08
    learner_load_time_ms: 28.502
    learner_load_wait_time_ms: 2.589
iterations_since_restore: 145
node_ip: 127.0.0.1
num_agent_steps_sampled: 1101050
num_agent_steps_trained: 1084500
num_env_steps_sampled: 1101050
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9992766386691
num_env_steps_trained: 1084500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9992501742302
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 47.239999999999995
  ram_util_percent: 80.79333333333331
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10660591345514607
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039275604536965734
  mean_inference_ms: 2.0001277973915164
  mean_raw_obs_processing_ms: 0.45038324205600816
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03086376190185547
    StateBufferConnector_ms: 0.005623817443847656
    ViewRequirementAgentConnector_ms: 0.18782615661621094
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.82
  episode_reward_min: 1.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 5.0, 2.0, 6.0, 4.0, 1.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 4.0,
      4.0, 4.0, 5.0, 6.0, 3.0, 3.0, 2.0, 4.0, 3.0, 4.0, 1.0, 5.0, 6.0, 7.0, 2.0, 1.0,
      3.0, 4.0, 9.0, 4.0, 2.0, 5.0, 3.0, 2.0, 4.0, 3.0, 5.0, 6.0, 6.0, 3.0, 8.0, 4.0,
      5.0, 6.0, 5.0, 3.0, 5.0, 5.0, 5.0, 6.0, 4.0, 2.0, 1.0, 4.0, 3.0, 5.0, 8.0, 7.0,
      4.0, 1.0, 3.0, 3.0, 2.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0,
      3.0, 3.0, 2.0, 1.0, 3.0, 4.0, 2.0, 4.0, 4.0, 6.0, 2.0, 2.0, 5.0, 5.0, 3.0, 3.0,
      2.0, 6.0, 7.0, 7.0, 5.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10660591345514607
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039275604536965734
    mean_inference_ms: 2.0001277973915164
    mean_raw_obs_processing_ms: 0.45038324205600816
time_since_restore: 1483.9463942050934
time_this_iter_s: 10.167565107345581
time_total_s: 1483.9463942050934
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.072
timestamp: 1692343073
timesteps_total: 1101050
training_iteration: 145
trial_id: default
train step: 146
agent_timesteps_total: 1109050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031658172607421875
  StateBufferConnector_ms: 0.005715131759643555
  ViewRequirementAgentConnector_ms: 0.18978500366210938
counters:
  num_agent_steps_sampled: 1109050
  num_agent_steps_trained: 1092500
  num_env_steps_sampled: 1109050
  num_env_steps_trained: 1092500
  num_samples_added_to_queue: 1109000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 21705
custom_metrics: {}
date: 2023-08-18_16-18-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.84
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 8665
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.9209327101707458
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 20.554988861083984
        total_loss: 40.200050354003906
        var_gnorm: 63.357730865478516
        vf_explained_var: 0.2375866174697876
        vf_loss: 40.2110595703125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2185.0
  learner_queue:
    size_count: 2191
    size_mean: 15.06
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.502131818450032
  num_agent_steps_sampled: 1109050
  num_agent_steps_trained: 1092500
  num_env_steps_sampled: 1109050
  num_env_steps_trained: 1092500
  num_samples_added_to_queue: 1109000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 21705
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 284.036
    learner_load_time_ms: 14.95
    learner_load_wait_time_ms: 2.612
iterations_since_restore: 146
node_ip: 127.0.0.1
num_agent_steps_sampled: 1109050
num_agent_steps_trained: 1092500
num_env_steps_sampled: 1109050
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.7073862729757
num_env_steps_trained: 1092500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.7073862729757
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 55.42142857142858
  ram_util_percent: 81.05
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10652827240483666
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03926074167634506
  mean_inference_ms: 1.999282989277136
  mean_raw_obs_processing_ms: 0.45027182460870163
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031658172607421875
    StateBufferConnector_ms: 0.005715131759643555
    ViewRequirementAgentConnector_ms: 0.18978500366210938
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.84
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 2.0, 1.0, 4.0, 2.0, 3.0, 2.0, 3.0, 3.0, 4.0, 2.0, 3.0,
      3.0, 3.0, 3.0, 2.0, 1.0, 3.0, 4.0, 2.0, 4.0, 4.0, 6.0, 2.0, 2.0, 5.0, 5.0, 3.0,
      3.0, 2.0, 6.0, 7.0, 7.0, 5.0, 4.0, 3.0, 4.0, 4.0, 2.0, 4.0, 7.0, 1.0, 8.0, 7.0,
      2.0, 5.0, 2.0, 3.0, 2.0, 4.0, 6.0, 3.0, 8.0, 4.0, 3.0, 10.0, 0.0, 2.0, 3.0,
      3.0, 1.0, 3.0, 3.0, 5.0, 5.0, 3.0, 4.0, 6.0, 3.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0,
      4.0, 4.0, 5.0, 6.0, 3.0, 1.0, 7.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0,
      6.0, 3.0, 6.0, 5.0, 5.0, 5.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10652827240483666
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03926074167634506
    mean_inference_ms: 1.999282989277136
    mean_raw_obs_processing_ms: 0.45027182460870163
time_since_restore: 1494.175383090973
time_this_iter_s: 10.228988885879517
time_total_s: 1494.175383090973
timers:
  sample_time_ms: 0.457
  synch_weights_time_ms: 0.951
  training_iteration_time_ms: 5.202
timestamp: 1692343084
timesteps_total: 1109050
training_iteration: 146
trial_id: default
train step: 147
agent_timesteps_total: 1116700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03210926055908203
  StateBufferConnector_ms: 0.005793571472167969
  ViewRequirementAgentConnector_ms: 0.19356489181518555
counters:
  num_agent_steps_sampled: 1116700
  num_agent_steps_trained: 1100000
  num_env_steps_sampled: 1116700
  num_env_steps_trained: 1100000
  num_samples_added_to_queue: 1116500
  num_training_step_calls_since_last_synch_worker_weights: 72
  num_weight_broadcasts: 21856
custom_metrics: {}
date: 2023-08-18_16-18-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.9
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 8725
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.893525242805481
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 27.198959350585938
        total_loss: 51.26069641113281
        var_gnorm: 63.358280181884766
        vf_explained_var: 0.22967123985290527
        vf_loss: 49.01700210571289
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2200.0
  learner_queue:
    size_count: 2207
    size_mean: 14.96
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.648757107641996
  num_agent_steps_sampled: 1116700
  num_agent_steps_trained: 1100000
  num_env_steps_sampled: 1116700
  num_env_steps_trained: 1100000
  num_samples_added_to_queue: 1116500
  num_training_step_calls_since_last_synch_worker_weights: 72
  num_weight_broadcasts: 21856
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 252.816
    learner_load_time_ms: 15.385
    learner_load_wait_time_ms: 3.057
iterations_since_restore: 147
node_ip: 127.0.0.1
num_agent_steps_sampled: 1116700
num_agent_steps_trained: 1100000
num_env_steps_sampled: 1116700
num_env_steps_sampled_this_iter: 7650
num_env_steps_sampled_throughput_per_sec: 764.9959327198744
num_env_steps_trained: 1100000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9960124704652
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.446666666666665
  ram_util_percent: 81.22
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10646021121278296
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0392671912708734
  mean_inference_ms: 1.999053593610165
  mean_raw_obs_processing_ms: 0.4503164397016776
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03210926055908203
    StateBufferConnector_ms: 0.005793571472167969
    ViewRequirementAgentConnector_ms: 0.19356489181518555
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.9
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 1.0, 3.0, 3.0, 5.0, 5.0, 3.0, 4.0, 6.0, 3.0, 2.0, 4.0, 2.0,
      3.0, 2.0, 1.0, 4.0, 4.0, 5.0, 6.0, 3.0, 1.0, 7.0, 7.0, 7.0, 7.0, 5.0, 5.0, 5.0,
      4.0, 4.0, 4.0, 6.0, 3.0, 6.0, 5.0, 5.0, 5.0, 4.0, 4.0, 4.0, 7.0, 6.0, 3.0, 8.0,
      2.0, 3.0, 1.0, 3.0, 1.0, 3.0, 4.0, 5.0, 4.0, 5.0, 6.0, 6.0, 2.0, 2.0, 1.0, 3.0,
      5.0, 4.0, 3.0, 6.0, 6.0, 3.0, 2.0, 4.0, 3.0, 4.0, 4.0, 5.0, 5.0, 3.0, 3.0, 3.0,
      4.0, 3.0, 7.0, 2.0, 0.0, 2.0, 3.0, 3.0, 5.0, 6.0, 4.0, 2.0, 2.0, 2.0, 5.0, 4.0,
      1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10646021121278296
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0392671912708734
    mean_inference_ms: 1.999053593610165
    mean_raw_obs_processing_ms: 0.4503164397016776
time_since_restore: 1504.4862909317017
time_this_iter_s: 10.31090784072876
time_total_s: 1504.4862909317017
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.085
timestamp: 1692343094
timesteps_total: 1116700
training_iteration: 147
trial_id: default
train step: 148
agent_timesteps_total: 1123900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0344395637512207
  StateBufferConnector_ms: 0.006195783615112305
  ViewRequirementAgentConnector_ms: 0.20275640487670898
counters:
  num_agent_steps_sampled: 1123900
  num_agent_steps_trained: 1107000
  num_env_steps_sampled: 1123900
  num_env_steps_trained: 1107000
  num_samples_added_to_queue: 1123500
  num_training_step_calls_since_last_synch_worker_weights: 1011
  num_weight_broadcasts: 21996
custom_metrics: {}
date: 2023-08-18_16-18-24
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.65
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 8781
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.8889210224151611
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 10.218121528625488
        total_loss: 30.37809181213379
        var_gnorm: 63.35866165161133
        vf_explained_var: 0.19281482696533203
        vf_loss: 41.2088623046875
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2214.0
  learner_queue:
    size_count: 2218
    size_mean: 14.68
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.690443728729235
  num_agent_steps_sampled: 1123900
  num_agent_steps_trained: 1107000
  num_env_steps_sampled: 1123900
  num_env_steps_trained: 1107000
  num_samples_added_to_queue: 1123500
  num_training_step_calls_since_last_synch_worker_weights: 1011
  num_weight_broadcasts: 21996
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 850.475
    learner_load_time_ms: 27.147
    learner_load_wait_time_ms: 12.717
iterations_since_restore: 148
node_ip: 127.0.0.1
num_agent_steps_sampled: 1123900
num_agent_steps_trained: 1107000
num_env_steps_sampled: 1123900
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 719.9959831461894
num_env_steps_trained: 1107000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9960947254618
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 56.02857142857143
  ram_util_percent: 82.12142857142858
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10640076173651386
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03929756037531986
  mean_inference_ms: 1.9994842453505526
  mean_raw_obs_processing_ms: 0.45056029302154227
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0344395637512207
    StateBufferConnector_ms: 0.006195783615112305
    ViewRequirementAgentConnector_ms: 0.20275640487670898
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.65
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 2.0, 2.0, 1.0, 3.0, 5.0, 4.0, 3.0, 6.0, 6.0, 3.0, 2.0, 4.0,
      3.0, 4.0, 4.0, 5.0, 5.0, 3.0, 3.0, 3.0, 4.0, 3.0, 7.0, 2.0, 0.0, 2.0, 3.0, 3.0,
      5.0, 6.0, 4.0, 2.0, 2.0, 2.0, 5.0, 4.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 4.0,
      6.0, 4.0, 2.0, 2.0, 5.0, 2.0, 5.0, 7.0, 3.0, 3.0, 5.0, 2.0, 6.0, 2.0, 3.0, 3.0,
      5.0, 6.0, 6.0, 2.0, 3.0, 5.0, 1.0, 2.0, 4.0, 7.0, 4.0, 6.0, 2.0, 4.0, 5.0, 3.0,
      5.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 5.0, 3.0, 4.0, 4.0, 4.0, 5.0, 1.0,
      1.0, 3.0, 2.0, 0.0, 8.0, 5.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10640076173651386
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03929756037531986
    mean_inference_ms: 1.9994842453505526
    mean_raw_obs_processing_ms: 0.45056029302154227
time_since_restore: 1514.6491348743439
time_this_iter_s: 10.162843942642212
time_total_s: 1514.6491348743439
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692343104
timesteps_total: 1123900
training_iteration: 148
trial_id: default
train step: 149
agent_timesteps_total: 1131900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.032560110092163086
  StateBufferConnector_ms: 0.005770206451416016
  ViewRequirementAgentConnector_ms: 0.19537115097045898
counters:
  num_agent_steps_sampled: 1131900
  num_agent_steps_trained: 1115000
  num_env_steps_sampled: 1131900
  num_env_steps_trained: 1115000
  num_samples_added_to_queue: 1131500
  num_training_step_calls_since_last_synch_worker_weights: 1012
  num_weight_broadcasts: 22153
custom_metrics: {}
date: 2023-08-18_16-18-34
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.65
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 8843
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.8716944456100464
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -11.43626594543457
        total_loss: 7.900313377380371
        var_gnorm: 63.35918045043945
        vf_explained_var: 0.2402665615081787
        vf_loss: 39.54485321044922
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2230.0
  learner_queue:
    size_count: 2234
    size_mean: 14.7
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.676305461424021
  num_agent_steps_sampled: 1131900
  num_agent_steps_trained: 1115000
  num_env_steps_sampled: 1131900
  num_env_steps_trained: 1115000
  num_samples_added_to_queue: 1131500
  num_training_step_calls_since_last_synch_worker_weights: 1012
  num_weight_broadcasts: 22153
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 470.24
    learner_load_time_ms: 26.766
    learner_load_wait_time_ms: 2.785
iterations_since_restore: 149
node_ip: 127.0.0.1
num_agent_steps_sampled: 1131900
num_agent_steps_trained: 1115000
num_env_steps_sampled: 1131900
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9951172173021
num_env_steps_trained: 1115000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9951172173021
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.378571428571426
  ram_util_percent: 81.54285714285713
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10641667636957325
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03928570616834111
  mean_inference_ms: 1.9992357043883129
  mean_raw_obs_processing_ms: 0.4504335796717285
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.032560110092163086
    StateBufferConnector_ms: 0.005770206451416016
    ViewRequirementAgentConnector_ms: 0.19537115097045898
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.65
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 6.0, 2.0, 3.0, 5.0, 1.0, 2.0, 4.0, 7.0, 4.0, 6.0, 2.0, 4.0,
      5.0, 3.0, 5.0, 5.0, 2.0, 3.0, 3.0, 3.0, 4.0, 2.0, 2.0, 5.0, 3.0, 4.0, 4.0, 4.0,
      5.0, 1.0, 1.0, 3.0, 2.0, 0.0, 8.0, 5.0, 3.0, 2.0, 2.0, 4.0, 5.0, 5.0, 6.0, 3.0,
      3.0, 4.0, 5.0, 2.0, 2.0, 4.0, 8.0, 4.0, 3.0, 2.0, 4.0, 2.0, 3.0, 2.0, 1.0, 2.0,
      5.0, 7.0, 6.0, 7.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 2.0, 6.0, 4.0, 6.0, 4.0, 6.0,
      10.0, 6.0, 4.0, 4.0, 4.0, 2.0, 3.0, 7.0, 2.0, 1.0, 6.0, 4.0, 2.0, 3.0, 2.0,
      5.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10641667636957325
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03928570616834111
    mean_inference_ms: 1.9992357043883129
    mean_raw_obs_processing_ms: 0.4504335796717285
time_since_restore: 1524.8105728626251
time_this_iter_s: 10.16143798828125
time_total_s: 1524.8105728626251
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.085
timestamp: 1692343114
timesteps_total: 1131900
training_iteration: 149
trial_id: default
train step: 150
agent_timesteps_total: 1140100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03123021125793457
  StateBufferConnector_ms: 0.005567789077758789
  ViewRequirementAgentConnector_ms: 0.19034337997436523
counters:
  num_agent_steps_sampled: 1140100
  num_agent_steps_trained: 1123500
  num_env_steps_sampled: 1140100
  num_env_steps_trained: 1123500
  num_samples_added_to_queue: 1140000
  num_training_step_calls_since_last_synch_worker_weights: 146
  num_weight_broadcasts: 22314
custom_metrics: {}
date: 2023-08-18_16-18-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.71
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 8907
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.865382194519043
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 0.9705798625946045
        total_loss: 17.079627990722656
        var_gnorm: 63.359619140625
        vf_explained_var: 0.21144205331802368
        vf_loss: 33.08348083496094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2247.0
  learner_queue:
    size_count: 2253
    size_mean: 14.8
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6613247725836149
  num_agent_steps_sampled: 1140100
  num_agent_steps_trained: 1123500
  num_env_steps_sampled: 1140100
  num_env_steps_trained: 1123500
  num_samples_added_to_queue: 1140000
  num_training_step_calls_since_last_synch_worker_weights: 146
  num_weight_broadcasts: 22314
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 286.714
    learner_load_time_ms: 26.757
    learner_load_wait_time_ms: 2.595
iterations_since_restore: 150
node_ip: 127.0.0.1
num_agent_steps_sampled: 1140100
num_agent_steps_trained: 1123500
num_env_steps_sampled: 1140100
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9976148674723
num_env_steps_trained: 1123500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9975276065262
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 50.559999999999995
  ram_util_percent: 80.93999999999998
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1064629069606751
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03923205685443695
  mean_inference_ms: 1.9981446875713524
  mean_raw_obs_processing_ms: 0.44994810024527226
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03123021125793457
    StateBufferConnector_ms: 0.005567789077758789
    ViewRequirementAgentConnector_ms: 0.19034337997436523
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.71
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 2.0, 2.0, 3.0, 3.0, 2.0, 4.0, 2.0, 6.0, 4.0, 6.0, 4.0, 6.0,
      10.0, 6.0, 4.0, 4.0, 4.0, 2.0, 3.0, 7.0, 2.0, 1.0, 6.0, 4.0, 2.0, 3.0, 2.0,
      5.0, 4.0, 1.0, 3.0, 2.0, 2.0, 1.0, 3.0, 3.0, 3.0, 1.0, 4.0, 5.0, 6.0, 2.0, 5.0,
      4.0, 4.0, 6.0, 3.0, 2.0, 3.0, 4.0, 5.0, 2.0, 2.0, 3.0, 5.0, 5.0, 1.0, 3.0, 7.0,
      3.0, 3.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 3.0, 0.0, 5.0, 2.0, 3.0, 3.0, 4.0, 4.0,
      7.0, 1.0, 6.0, 3.0, 2.0, 4.0, 6.0, 4.0, 7.0, 2.0, 6.0, 4.0, 7.0, 2.0, 7.0, 6.0,
      4.0, 4.0, 5.0, 2.0, 1.0, 3.0, 2.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1064629069606751
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03923205685443695
    mean_inference_ms: 1.9981446875713524
    mean_raw_obs_processing_ms: 0.44994810024527226
time_since_restore: 1535.0502457618713
time_this_iter_s: 10.239672899246216
time_total_s: 1535.0502457618713
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692343125
timesteps_total: 1140100
training_iteration: 150
trial_id: default
train step: 151
agent_timesteps_total: 1148450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030713319778442383
  StateBufferConnector_ms: 0.00554656982421875
  ViewRequirementAgentConnector_ms: 0.1857163906097412
counters:
  num_agent_steps_sampled: 1148450
  num_agent_steps_trained: 1131500
  num_env_steps_sampled: 1148450
  num_env_steps_trained: 1131500
  num_samples_added_to_queue: 1148000
  num_training_step_calls_since_last_synch_worker_weights: 254
  num_weight_broadcasts: 22478
custom_metrics: {}
date: 2023-08-18_16-18-55
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.94
episode_reward_min: 0.0
episodes_this_iter: 66
episodes_total: 8973
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.8810141682624817
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -50.767669677734375
        total_loss: -43.44359588623047
        var_gnorm: 63.35995101928711
        vf_explained_var: 0.1416153907775879
        vf_loss: 15.529160499572754
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2263.0
  learner_queue:
    size_count: 2269
    size_mean: 14.98
    size_quantiles: [11.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.555506348428061
  num_agent_steps_sampled: 1148450
  num_agent_steps_trained: 1131500
  num_env_steps_sampled: 1148450
  num_env_steps_trained: 1131500
  num_samples_added_to_queue: 1148000
  num_training_step_calls_since_last_synch_worker_weights: 254
  num_weight_broadcasts: 22478
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 323.04
    learner_load_time_ms: 26.356
    learner_load_wait_time_ms: 2.672
iterations_since_restore: 151
node_ip: 127.0.0.1
num_agent_steps_sampled: 1148450
num_agent_steps_trained: 1131500
num_env_steps_sampled: 1148450
num_env_steps_sampled_this_iter: 8350
num_env_steps_sampled_throughput_per_sec: 834.9987458009485
num_env_steps_trained: 1131500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9987983721662
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 48.49285714285715
  ram_util_percent: 80.55
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10644550555173174
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0391874856131665
  mean_inference_ms: 1.9968490899449016
  mean_raw_obs_processing_ms: 0.44954715403564477
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030713319778442383
    StateBufferConnector_ms: 0.00554656982421875
    ViewRequirementAgentConnector_ms: 0.1857163906097412
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.94
  episode_reward_min: 0.0
  episodes_this_iter: 66
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 3.0, 0.0, 5.0, 2.0, 3.0, 3.0, 4.0, 4.0, 7.0, 1.0, 6.0,
      3.0, 2.0, 4.0, 6.0, 4.0, 7.0, 2.0, 6.0, 4.0, 7.0, 2.0, 7.0, 6.0, 4.0, 4.0, 5.0,
      2.0, 1.0, 3.0, 2.0, 6.0, 5.0, 2.0, 7.0, 5.0, 9.0, 0.0, 3.0, 6.0, 2.0, 6.0, 4.0,
      3.0, 2.0, 3.0, 3.0, 2.0, 1.0, 3.0, 5.0, 1.0, 4.0, 2.0, 4.0, 5.0, 3.0, 3.0, 3.0,
      6.0, 2.0, 2.0, 1.0, 2.0, 3.0, 3.0, 5.0, 3.0, 5.0, 3.0, 6.0, 5.0, 3.0, 5.0, 3.0,
      7.0, 6.0, 3.0, 4.0, 3.0, 10.0, 2.0, 2.0, 3.0, 5.0, 3.0, 5.0, 6.0, 5.0, 8.0,
      6.0, 1.0, 5.0, 3.0, 5.0, 4.0, 6.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10644550555173174
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0391874856131665
    mean_inference_ms: 1.9968490899449016
    mean_raw_obs_processing_ms: 0.44954715403564477
time_since_restore: 1545.3108546733856
time_this_iter_s: 10.260608911514282
time_total_s: 1545.3108546733856
timers:
  sample_time_ms: 0.026
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1692343135
timesteps_total: 1148450
training_iteration: 151
trial_id: default
train step: 152
agent_timesteps_total: 1156600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03080916404724121
  StateBufferConnector_ms: 0.005619525909423828
  ViewRequirementAgentConnector_ms: 0.185868501663208
counters:
  num_agent_steps_sampled: 1156600
  num_agent_steps_trained: 1140000
  num_env_steps_sampled: 1156600
  num_env_steps_trained: 1140000
  num_samples_added_to_queue: 1156500
  num_training_step_calls_since_last_synch_worker_weights: 36
  num_weight_broadcasts: 22638
custom_metrics: {}
date: 2023-08-18_16-19-05
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.07
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 9036
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.862588107585907
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -5.890327453613281
        total_loss: 7.368686199188232
        var_gnorm: 63.36042404174805
        vf_explained_var: 0.24488818645477295
        vf_loss: 27.380615234375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2280.0
  learner_queue:
    size_count: 2286
    size_mean: 14.72
    size_quantiles: [11.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.766805026028622
  num_agent_steps_sampled: 1156600
  num_agent_steps_trained: 1140000
  num_env_steps_sampled: 1156600
  num_env_steps_trained: 1140000
  num_samples_added_to_queue: 1156500
  num_training_step_calls_since_last_synch_worker_weights: 36
  num_weight_broadcasts: 22638
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 290.002
    learner_load_time_ms: 26.667
    learner_load_wait_time_ms: 2.714
iterations_since_restore: 152
node_ip: 127.0.0.1
num_agent_steps_sampled: 1156600
num_agent_steps_trained: 1140000
num_env_steps_sampled: 1156600
num_env_steps_sampled_this_iter: 8150
num_env_steps_sampled_throughput_per_sec: 814.9978820140567
num_env_steps_trained: 1140000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9977910576051
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 48.86666666666666
  ram_util_percent: 80.64666666666669
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10638869544254154
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039162191633486935
  mean_inference_ms: 1.9958146471413993
  mean_raw_obs_processing_ms: 0.44933049895237803
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03080916404724121
    StateBufferConnector_ms: 0.005619525909423828
    ViewRequirementAgentConnector_ms: 0.185868501663208
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.07
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 1.0, 2.0, 3.0, 3.0, 5.0, 3.0, 5.0, 3.0, 6.0, 5.0, 3.0, 5.0,
      3.0, 7.0, 6.0, 3.0, 4.0, 3.0, 10.0, 2.0, 2.0, 3.0, 5.0, 3.0, 5.0, 6.0, 5.0,
      8.0, 6.0, 1.0, 5.0, 3.0, 5.0, 4.0, 6.0, 8.0, 4.0, 4.0, 4.0, 4.0, 4.0, 5.0, 2.0,
      4.0, 6.0, 3.0, 4.0, 5.0, 0.0, 4.0, 3.0, 3.0, 1.0, 2.0, 0.0, 5.0, 6.0, 5.0, 5.0,
      7.0, 5.0, 1.0, 5.0, 5.0, 7.0, 10.0, 4.0, 4.0, 4.0, 4.0, 6.0, 2.0, 6.0, 6.0,
      1.0, 1.0, 4.0, 2.0, 2.0, 3.0, 2.0, 4.0, 1.0, 4.0, 8.0, 2.0, 6.0, 5.0, 3.0, 1.0,
      6.0, 9.0, 2.0, 4.0, 6.0, 4.0, 3.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10638869544254154
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039162191633486935
    mean_inference_ms: 1.9958146471413993
    mean_raw_obs_processing_ms: 0.44933049895237803
time_since_restore: 1555.5745568275452
time_this_iter_s: 10.263702154159546
time_total_s: 1555.5745568275452
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.086
timestamp: 1692343145
timesteps_total: 1156600
training_iteration: 152
trial_id: default
train step: 153
agent_timesteps_total: 1164500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03164529800415039
  StateBufferConnector_ms: 0.005793333053588867
  ViewRequirementAgentConnector_ms: 0.19121241569519043
counters:
  num_agent_steps_sampled: 1164500
  num_agent_steps_trained: 1148000
  num_env_steps_sampled: 1164500
  num_env_steps_trained: 1148000
  num_samples_added_to_queue: 1164500
  num_training_step_calls_since_last_synch_worker_weights: 627
  num_weight_broadcasts: 22793
custom_metrics: {}
date: 2023-08-18_16-19-15
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.76
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 9098
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.8537505865097046
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -41.44145965576172
        total_loss: -27.970752716064453
        var_gnorm: 63.36094665527344
        vf_explained_var: 0.1852458119392395
        vf_loss: 27.795166015625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2296.0
  learner_queue:
    size_count: 2300
    size_mean: 14.4
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.876166303929372
  num_agent_steps_sampled: 1164500
  num_agent_steps_trained: 1148000
  num_env_steps_sampled: 1164500
  num_env_steps_trained: 1148000
  num_samples_added_to_queue: 1164500
  num_training_step_calls_since_last_synch_worker_weights: 627
  num_weight_broadcasts: 22793
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 476.881
    learner_load_time_ms: 26.672
    learner_load_wait_time_ms: 2.788
iterations_since_restore: 153
node_ip: 127.0.0.1
num_agent_steps_sampled: 1164500
num_agent_steps_trained: 1148000
num_env_steps_sampled: 1164500
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.9920140120043
num_env_steps_trained: 1148000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9919129235487
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.87142857142857
  ram_util_percent: 81.02142857142857
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1063007126825331
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039159810456367294
  mean_inference_ms: 1.9951735451991233
  mean_raw_obs_processing_ms: 0.4493171296206217
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03164529800415039
    StateBufferConnector_ms: 0.005793333053588867
    ViewRequirementAgentConnector_ms: 0.19121241569519043
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.76
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 5.0, 5.0, 7.0, 10.0, 4.0, 4.0, 4.0, 4.0, 6.0, 2.0, 6.0,
      6.0, 1.0, 1.0, 4.0, 2.0, 2.0, 3.0, 2.0, 4.0, 1.0, 4.0, 8.0, 2.0, 6.0, 5.0, 3.0,
      1.0, 6.0, 9.0, 2.0, 4.0, 6.0, 4.0, 3.0, 4.0, 2.0, 5.0, 3.0, 3.0, 3.0, 3.0, 2.0,
      3.0, 8.0, 4.0, 4.0, 1.0, 1.0, 4.0, 6.0, 2.0, 5.0, 2.0, 1.0, 10.0, 4.0, 5.0,
      5.0, 5.0, 2.0, 7.0, 3.0, 6.0, 2.0, 4.0, 6.0, 2.0, 2.0, 3.0, 4.0, 1.0, 3.0, 5.0,
      3.0, 2.0, 2.0, 2.0, 4.0, 0.0, 2.0, 5.0, 1.0, 3.0, 7.0, 5.0, 2.0, 3.0, 5.0, 4.0,
      3.0, 4.0, 4.0, 1.0, 5.0, 5.0, 5.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1063007126825331
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039159810456367294
    mean_inference_ms: 1.9951735451991233
    mean_raw_obs_processing_ms: 0.4493171296206217
time_since_restore: 1565.7492468357086
time_this_iter_s: 10.174690008163452
time_total_s: 1565.7492468357086
timers:
  sample_time_ms: 0.042
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.101
timestamp: 1692343155
timesteps_total: 1164500
training_iteration: 153
trial_id: default
train step: 154
agent_timesteps_total: 1172700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030808448791503906
  StateBufferConnector_ms: 0.005654096603393555
  ViewRequirementAgentConnector_ms: 0.18674945831298828
counters:
  num_agent_steps_sampled: 1172700
  num_agent_steps_trained: 1156000
  num_env_steps_sampled: 1172700
  num_env_steps_trained: 1156000
  num_samples_added_to_queue: 1172500
  num_training_step_calls_since_last_synch_worker_weights: 667
  num_weight_broadcasts: 22953
custom_metrics: {}
date: 2023-08-18_16-19-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 3.77
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 9162
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.8314149975776672
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 36.365264892578125
        total_loss: 54.257789611816406
        var_gnorm: 63.36140441894531
        vf_explained_var: 0.24407780170440674
        vf_loss: 36.61646270751953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2312.0
  learner_queue:
    size_count: 2317
    size_mean: 14.68
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.76
  num_agent_steps_sampled: 1172700
  num_agent_steps_trained: 1156000
  num_env_steps_sampled: 1172700
  num_env_steps_trained: 1156000
  num_samples_added_to_queue: 1172500
  num_training_step_calls_since_last_synch_worker_weights: 667
  num_weight_broadcasts: 22953
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 346.489
    learner_load_time_ms: 26.278
    learner_load_wait_time_ms: 2.575
iterations_since_restore: 154
node_ip: 127.0.0.1
num_agent_steps_sampled: 1172700
num_agent_steps_trained: 1156000
num_env_steps_sampled: 1172700
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.998944283891
num_env_steps_trained: 1156000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9989700330643
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 49.75714285714285
  ram_util_percent: 81.09285714285716
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10625115941348152
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039136430697061624
  mean_inference_ms: 1.9942978161416665
  mean_raw_obs_processing_ms: 0.44910463614818374
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030808448791503906
    StateBufferConnector_ms: 0.005654096603393555
    ViewRequirementAgentConnector_ms: 0.18674945831298828
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 3.77
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 2.0, 4.0, 6.0, 2.0, 2.0, 3.0, 4.0, 1.0, 3.0, 5.0, 3.0, 2.0,
      2.0, 2.0, 4.0, 0.0, 2.0, 5.0, 1.0, 3.0, 7.0, 5.0, 2.0, 3.0, 5.0, 4.0, 3.0, 4.0,
      4.0, 1.0, 5.0, 5.0, 5.0, 4.0, 3.0, 0.0, 1.0, 2.0, 5.0, 5.0, 4.0, 5.0, 4.0, 2.0,
      4.0, 8.0, 4.0, 2.0, 5.0, 5.0, 6.0, 6.0, 2.0, 4.0, 5.0, 3.0, 4.0, 3.0, 3.0, 7.0,
      7.0, 4.0, 4.0, 6.0, 6.0, 2.0, 4.0, 6.0, 4.0, 4.0, 4.0, 1.0, 4.0, 4.0, 1.0, 2.0,
      4.0, 3.0, 8.0, 3.0, 3.0, 3.0, 6.0, 6.0, 3.0, 5.0, 6.0, 3.0, 4.0, 2.0, 2.0, 5.0,
      3.0, 6.0, 1.0, 2.0, 5.0, 6.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10625115941348152
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039136430697061624
    mean_inference_ms: 1.9942978161416665
    mean_raw_obs_processing_ms: 0.44910463614818374
time_since_restore: 1575.9349868297577
time_this_iter_s: 10.185739994049072
time_total_s: 1575.9349868297577
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1692343165
timesteps_total: 1172700
training_iteration: 154
trial_id: default
train step: 155
agent_timesteps_total: 1180700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0306549072265625
  StateBufferConnector_ms: 0.005562782287597656
  ViewRequirementAgentConnector_ms: 0.18693923950195312
counters:
  num_agent_steps_sampled: 1180700
  num_agent_steps_trained: 1164000
  num_env_steps_sampled: 1180700
  num_env_steps_trained: 1164000
  num_samples_added_to_queue: 1180500
  num_training_step_calls_since_last_synch_worker_weights: 350
  num_weight_broadcasts: 23110
custom_metrics: {}
date: 2023-08-18_16-19-36
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.36
episode_reward_min: 1.0
episodes_this_iter: 62
episodes_total: 9224
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.8393686413764954
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 7.982232093811035
        total_loss: 26.451902389526367
        var_gnorm: 63.36186218261719
        vf_explained_var: 0.23251134157180786
        vf_loss: 37.778709411621094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2328.0
  learner_queue:
    size_count: 2334
    size_mean: 14.78
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6886681142249353
  num_agent_steps_sampled: 1180700
  num_agent_steps_trained: 1164000
  num_env_steps_sampled: 1180700
  num_env_steps_trained: 1164000
  num_samples_added_to_queue: 1180500
  num_training_step_calls_since_last_synch_worker_weights: 350
  num_weight_broadcasts: 23110
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 312.274
    learner_load_time_ms: 26.315
    learner_load_wait_time_ms: 3.018
iterations_since_restore: 155
node_ip: 127.0.0.1
num_agent_steps_sampled: 1180700
num_agent_steps_trained: 1164000
num_env_steps_sampled: 1180700
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9967384471352
num_env_steps_trained: 1164000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9967384471352
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.885714285714286
  ram_util_percent: 81.32142857142856
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1062086200504244
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039118598542322115
  mean_inference_ms: 1.993572690650205
  mean_raw_obs_processing_ms: 0.44894017478129333
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0306549072265625
    StateBufferConnector_ms: 0.005562782287597656
    ViewRequirementAgentConnector_ms: 0.18693923950195312
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.36
  episode_reward_min: 1.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 4.0, 6.0, 6.0, 2.0, 4.0, 6.0, 4.0, 4.0, 4.0, 1.0, 4.0, 4.0,
      1.0, 2.0, 4.0, 3.0, 8.0, 3.0, 3.0, 3.0, 6.0, 6.0, 3.0, 5.0, 6.0, 3.0, 4.0, 2.0,
      2.0, 5.0, 3.0, 6.0, 1.0, 2.0, 5.0, 6.0, 4.0, 5.0, 7.0, 7.0, 7.0, 5.0, 5.0, 4.0,
      5.0, 4.0, 6.0, 7.0, 6.0, 3.0, 4.0, 6.0, 6.0, 2.0, 3.0, 7.0, 3.0, 4.0, 5.0, 4.0,
      3.0, 6.0, 3.0, 7.0, 6.0, 7.0, 6.0, 4.0, 5.0, 6.0, 3.0, 6.0, 3.0, 3.0, 2.0, 4.0,
      6.0, 4.0, 4.0, 3.0, 5.0, 4.0, 2.0, 7.0, 6.0, 3.0, 2.0, 2.0, 3.0, 5.0, 5.0, 10.0,
      3.0, 6.0, 5.0, 3.0, 4.0, 1.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1062086200504244
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039118598542322115
    mean_inference_ms: 1.993572690650205
    mean_raw_obs_processing_ms: 0.44894017478129333
time_since_restore: 1586.2499668598175
time_this_iter_s: 10.314980030059814
time_total_s: 1586.2499668598175
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.106
timestamp: 1692343176
timesteps_total: 1180700
training_iteration: 155
trial_id: default
train step: 156
agent_timesteps_total: 1188800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030570507049560547
  StateBufferConnector_ms: 0.005495786666870117
  ViewRequirementAgentConnector_ms: 0.18725132942199707
counters:
  num_agent_steps_sampled: 1188800
  num_agent_steps_trained: 1172000
  num_env_steps_sampled: 1188800
  num_env_steps_trained: 1172000
  num_samples_added_to_queue: 1188500
  num_training_step_calls_since_last_synch_worker_weights: 1269
  num_weight_broadcasts: 23269
custom_metrics: {}
date: 2023-08-18_16-19-46
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.2
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 9288
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.8461782336235046
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -23.081253051757812
        total_loss: -12.365013122558594
        var_gnorm: 63.36235046386719
        vf_explained_var: 0.29668647050857544
        vf_loss: 22.278657913208008
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2344.0
  learner_queue:
    size_count: 2348
    size_mean: 14.98
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.4211263138792414
  num_agent_steps_sampled: 1188800
  num_agent_steps_trained: 1172000
  num_env_steps_sampled: 1188800
  num_env_steps_trained: 1172000
  num_samples_added_to_queue: 1188500
  num_training_step_calls_since_last_synch_worker_weights: 1269
  num_weight_broadcasts: 23269
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 429.489
    learner_load_time_ms: 26.735
    learner_load_wait_time_ms: 2.727
iterations_since_restore: 156
node_ip: 127.0.0.1
num_agent_steps_sampled: 1188800
num_agent_steps_trained: 1172000
num_env_steps_sampled: 1188800
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9952106759013
num_env_steps_trained: 1172000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9952698033593
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 54.220000000000006
  ram_util_percent: 81.16000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10616255565668187
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03909808148057317
  mean_inference_ms: 1.9927952608645148
  mean_raw_obs_processing_ms: 0.4487634416211047
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030570507049560547
    StateBufferConnector_ms: 0.005495786666870117
    ViewRequirementAgentConnector_ms: 0.18725132942199707
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.2
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 6.0, 7.0, 6.0, 4.0, 5.0, 6.0, 3.0, 6.0, 3.0, 3.0, 2.0, 4.0,
      6.0, 4.0, 4.0, 3.0, 5.0, 4.0, 2.0, 7.0, 6.0, 3.0, 2.0, 2.0, 3.0, 5.0, 5.0, 10.0,
      3.0, 6.0, 5.0, 3.0, 4.0, 1.0, 5.0, 4.0, 1.0, 2.0, 2.0, 7.0, 4.0, 5.0, 5.0, 2.0,
      2.0, 5.0, 3.0, 8.0, 10.0, 4.0, 2.0, 7.0, 5.0, 1.0, 2.0, 4.0, 6.0, 5.0, 4.0,
      10.0, 5.0, 7.0, 0.0, 2.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 7.0, 6.0, 7.0, 5.0,
      3.0, 4.0, 3.0, 4.0, 8.0, 2.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 5.0, 5.0, 4.0, 2.0,
      5.0, 3.0, 2.0, 3.0, 0.0, 2.0, 8.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10616255565668187
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03909808148057317
    mean_inference_ms: 1.9927952608645148
    mean_raw_obs_processing_ms: 0.4487634416211047
time_since_restore: 1596.4088587760925
time_this_iter_s: 10.158891916275024
time_total_s: 1596.4088587760925
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692343186
timesteps_total: 1188800
training_iteration: 156
trial_id: default
train step: 157
agent_timesteps_total: 1196900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030741214752197266
  StateBufferConnector_ms: 0.0055162906646728516
  ViewRequirementAgentConnector_ms: 0.18757319450378418
counters:
  num_agent_steps_sampled: 1196900
  num_agent_steps_trained: 1180000
  num_env_steps_sampled: 1196900
  num_env_steps_trained: 1180000
  num_samples_added_to_queue: 1196500
  num_training_step_calls_since_last_synch_worker_weights: 1024
  num_weight_broadcasts: 23428
custom_metrics: {}
date: 2023-08-18_16-19-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 3.97
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 9352
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.83861243724823
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 40.8487663269043
        total_loss: 64.8734130859375
        var_gnorm: 63.362796783447266
        vf_explained_var: 0.24516743421554565
        vf_loss: 48.887901306152344
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2360.0
  learner_queue:
    size_count: 2364
    size_mean: 15.04
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.399428454762872
  num_agent_steps_sampled: 1196900
  num_agent_steps_trained: 1180000
  num_env_steps_sampled: 1196900
  num_env_steps_trained: 1180000
  num_samples_added_to_queue: 1196500
  num_training_step_calls_since_last_synch_worker_weights: 1024
  num_weight_broadcasts: 23428
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 448.99
    learner_load_time_ms: 26.287
    learner_load_wait_time_ms: 2.638
iterations_since_restore: 157
node_ip: 127.0.0.1
num_agent_steps_sampled: 1196900
num_agent_steps_trained: 1180000
num_env_steps_sampled: 1196900
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9984550505542
num_env_steps_trained: 1180000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9984741240041
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.914285714285725
  ram_util_percent: 81.32857142857142
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10613799988878761
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03906754438615298
  mean_inference_ms: 1.9918942866115197
  mean_raw_obs_processing_ms: 0.44849804820244005
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030741214752197266
    StateBufferConnector_ms: 0.0055162906646728516
    ViewRequirementAgentConnector_ms: 0.18757319450378418
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 3.97
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 4.0, 4.0, 4.0, 4.0, 5.0, 5.0, 7.0, 6.0, 7.0, 5.0, 3.0, 4.0,
      3.0, 4.0, 8.0, 2.0, 1.0, 1.0, 2.0, 2.0, 5.0, 3.0, 5.0, 5.0, 4.0, 2.0, 5.0, 3.0,
      2.0, 3.0, 0.0, 2.0, 8.0, 3.0, 5.0, 5.0, 6.0, 7.0, 3.0, 6.0, 3.0, 5.0, 3.0, 6.0,
      5.0, 3.0, 5.0, 2.0, 3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 4.0, 1.0, 5.0, 5.0, 3.0, 4.0,
      5.0, 6.0, 10.0, 4.0, 8.0, 4.0, 7.0, 7.0, 1.0, 6.0, 2.0, 2.0, 5.0, 2.0, 4.0,
      3.0, 4.0, 3.0, 2.0, 4.0, 1.0, 4.0, 7.0, 3.0, 3.0, 3.0, 1.0, 2.0, 8.0, 4.0, 8.0,
      2.0, 3.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10613799988878761
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03906754438615298
    mean_inference_ms: 1.9918942866115197
    mean_raw_obs_processing_ms: 0.44849804820244005
time_since_restore: 1606.5730938911438
time_this_iter_s: 10.16423511505127
time_total_s: 1606.5730938911438
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692343196
timesteps_total: 1196900
training_iteration: 157
trial_id: default
train step: 158
agent_timesteps_total: 1204900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0314638614654541
  StateBufferConnector_ms: 0.005618572235107422
  ViewRequirementAgentConnector_ms: 0.19659066200256348
counters:
  num_agent_steps_sampled: 1204900
  num_agent_steps_trained: 1188000
  num_env_steps_sampled: 1204900
  num_env_steps_trained: 1188000
  num_samples_added_to_queue: 1204500
  num_training_step_calls_since_last_synch_worker_weights: 1016
  num_weight_broadcasts: 23585
custom_metrics: {}
date: 2023-08-18_16-20-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.09
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 9414
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.8165295124053955
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -62.79291534423828
        total_loss: -51.841552734375
        var_gnorm: 63.36323165893555
        vf_explained_var: 0.027945995330810547
        vf_loss: 22.719255447387695
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2376.0
  learner_queue:
    size_count: 2380
    size_mean: 15.12
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3362634470792054
  num_agent_steps_sampled: 1204900
  num_agent_steps_trained: 1188000
  num_env_steps_sampled: 1204900
  num_env_steps_trained: 1188000
  num_samples_added_to_queue: 1204500
  num_training_step_calls_since_last_synch_worker_weights: 1016
  num_weight_broadcasts: 23585
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 453.671
    learner_load_time_ms: 14.522
    learner_load_wait_time_ms: 2.615
iterations_since_restore: 158
node_ip: 127.0.0.1
num_agent_steps_sampled: 1204900
num_agent_steps_trained: 1188000
num_env_steps_sampled: 1204900
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9944115075452
num_env_steps_trained: 1188000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9944115075452
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.07142857142857
  ram_util_percent: 81.00714285714285
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10607332735460263
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03905424229567611
  mean_inference_ms: 1.9911543673516388
  mean_raw_obs_processing_ms: 0.44842469979728095
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0314638614654541
    StateBufferConnector_ms: 0.005618572235107422
    ViewRequirementAgentConnector_ms: 0.19659066200256348
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.09
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 10.0, 4.0, 8.0, 4.0, 7.0, 7.0, 1.0, 6.0, 2.0, 2.0, 5.0,
      2.0, 4.0, 3.0, 4.0, 3.0, 2.0, 4.0, 1.0, 4.0, 7.0, 3.0, 3.0, 3.0, 1.0, 2.0, 8.0,
      4.0, 8.0, 2.0, 3.0, 4.0, 4.0, 4.0, 4.0, 3.0, 4.0, 5.0, 3.0, 3.0, 8.0, 6.0, 3.0,
      3.0, 5.0, 6.0, 3.0, 2.0, 3.0, 4.0, 6.0, 5.0, 1.0, 3.0, 5.0, 5.0, 5.0, 5.0, 2.0,
      2.0, 4.0, 4.0, 4.0, 3.0, 3.0, 7.0, 6.0, 4.0, 5.0, 3.0, 2.0, 3.0, 3.0, 7.0, 6.0,
      8.0, 2.0, 3.0, 5.0, 3.0, 5.0, 3.0, 0.0, 4.0, 2.0, 4.0, 6.0, 3.0, 1.0, 4.0, 3.0,
      2.0, 5.0, 6.0, 4.0, 7.0, 9.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10607332735460263
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03905424229567611
    mean_inference_ms: 1.9911543673516388
    mean_raw_obs_processing_ms: 0.44842469979728095
time_since_restore: 1616.7316999435425
time_this_iter_s: 10.158606052398682
time_total_s: 1616.7316999435425
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692343206
timesteps_total: 1204900
training_iteration: 158
trial_id: default
train step: 159
agent_timesteps_total: 1213100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03130531311035156
  StateBufferConnector_ms: 0.005600690841674805
  ViewRequirementAgentConnector_ms: 0.19508147239685059
counters:
  num_agent_steps_sampled: 1213100
  num_agent_steps_trained: 1196500
  num_env_steps_sampled: 1213100
  num_env_steps_trained: 1196500
  num_samples_added_to_queue: 1213000
  num_training_step_calls_since_last_synch_worker_weights: 323
  num_weight_broadcasts: 23744
custom_metrics: {}
date: 2023-08-18_16-20-17
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.12
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 9478
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.8062267303466797
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 28.02335548400879
        total_loss: 50.518211364746094
        var_gnorm: 63.36353302001953
        vf_explained_var: 0.1948651671409607
        vf_loss: 45.79594421386719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2393.0
  learner_queue:
    size_count: 2399
    size_mean: 15.34
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.226539848516957
  num_agent_steps_sampled: 1213100
  num_agent_steps_trained: 1196500
  num_env_steps_sampled: 1213100
  num_env_steps_trained: 1196500
  num_samples_added_to_queue: 1213000
  num_training_step_calls_since_last_synch_worker_weights: 323
  num_weight_broadcasts: 23744
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 274.065
    learner_load_time_ms: 14.521
    learner_load_wait_time_ms: 2.703
iterations_since_restore: 159
node_ip: 127.0.0.1
num_agent_steps_sampled: 1213100
num_agent_steps_trained: 1196500
num_env_steps_sampled: 1213100
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9979276709477
num_env_steps_trained: 1196500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.9978518540312
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 52.36
  ram_util_percent: 81.24666666666668
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10602600068210594
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03903203886069872
  mean_inference_ms: 1.990296485626516
  mean_raw_obs_processing_ms: 0.4482482248446793
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03130531311035156
    StateBufferConnector_ms: 0.005600690841674805
    ViewRequirementAgentConnector_ms: 0.19508147239685059
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.12
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 7.0, 6.0, 4.0, 5.0, 3.0, 2.0, 3.0, 3.0, 7.0, 6.0, 8.0,
      2.0, 3.0, 5.0, 3.0, 5.0, 3.0, 0.0, 4.0, 2.0, 4.0, 6.0, 3.0, 1.0, 4.0, 3.0, 2.0,
      5.0, 6.0, 4.0, 7.0, 9.0, 3.0, 4.0, 3.0, 5.0, 5.0, 6.0, 5.0, 7.0, 4.0, 1.0, 2.0,
      4.0, 2.0, 4.0, 4.0, 4.0, 4.0, 1.0, 4.0, 2.0, 3.0, 2.0, 2.0, 2.0, 6.0, 5.0, 4.0,
      5.0, 5.0, 2.0, 5.0, 3.0, 5.0, 5.0, 3.0, 5.0, 8.0, 5.0, 2.0, 5.0, 4.0, 4.0, 6.0,
      6.0, 2.0, 4.0, 5.0, 4.0, 2.0, 4.0, 6.0, 9.0, 7.0, 5.0, 5.0, 4.0, 3.0, 9.0, 5.0,
      3.0, 3.0, 1.0, 5.0, 4.0, 2.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10602600068210594
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03903203886069872
    mean_inference_ms: 1.990296485626516
    mean_raw_obs_processing_ms: 0.4482482248446793
time_since_restore: 1626.9654278755188
time_this_iter_s: 10.233727931976318
time_total_s: 1626.9654278755188
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.088
timestamp: 1692343217
timesteps_total: 1213100
training_iteration: 159
trial_id: default
train step: 160
agent_timesteps_total: 1221300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031429290771484375
  StateBufferConnector_ms: 0.005730867385864258
  ViewRequirementAgentConnector_ms: 0.19239425659179688
counters:
  num_agent_steps_sampled: 1221300
  num_agent_steps_trained: 1204500
  num_env_steps_sampled: 1221300
  num_env_steps_trained: 1204500
  num_samples_added_to_queue: 1221000
  num_training_step_calls_since_last_synch_worker_weights: 622
  num_weight_broadcasts: 23905
custom_metrics: {}
date: 2023-08-18_16-20-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.2
episode_reward_min: 1.0
episodes_this_iter: 64
episodes_total: 9542
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.8149651288986206
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 45.534202575683594
        total_loss: 69.86038208007812
        var_gnorm: 63.36399459838867
        vf_explained_var: 0.2594987154006958
        vf_loss: 49.46733093261719
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2409.0
  learner_queue:
    size_count: 2414
    size_mean: 15.12
    size_quantiles: [11.0, 13.0, 16.0, 16.0, 16.0]
    size_std: 1.3804347141389917
  num_agent_steps_sampled: 1221300
  num_agent_steps_trained: 1204500
  num_env_steps_sampled: 1221300
  num_env_steps_trained: 1204500
  num_samples_added_to_queue: 1221000
  num_training_step_calls_since_last_synch_worker_weights: 622
  num_weight_broadcasts: 23905
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 365.681
    learner_load_time_ms: 25.65
    learner_load_wait_time_ms: 2.637
iterations_since_restore: 160
node_ip: 127.0.0.1
num_agent_steps_sampled: 1221300
num_agent_steps_trained: 1204500
num_env_steps_sampled: 1221300
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9934506939416
num_env_steps_trained: 1204500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9936104331136
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 47.642857142857146
  ram_util_percent: 81.25714285714285
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10599759446978467
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03900065027104283
  mean_inference_ms: 1.9893533951205171
  mean_raw_obs_processing_ms: 0.44798761051046787
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031429290771484375
    StateBufferConnector_ms: 0.005730867385864258
    ViewRequirementAgentConnector_ms: 0.19239425659179688
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.2
  episode_reward_min: 1.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 3.0, 5.0, 5.0, 3.0, 5.0, 8.0, 5.0, 2.0, 5.0, 4.0, 4.0, 6.0,
      6.0, 2.0, 4.0, 5.0, 4.0, 2.0, 4.0, 6.0, 9.0, 7.0, 5.0, 5.0, 4.0, 3.0, 9.0, 5.0,
      3.0, 3.0, 1.0, 5.0, 4.0, 2.0, 3.0, 6.0, 3.0, 6.0, 5.0, 6.0, 4.0, 5.0, 4.0, 4.0,
      5.0, 5.0, 1.0, 1.0, 2.0, 3.0, 5.0, 5.0, 4.0, 3.0, 3.0, 4.0, 1.0, 5.0, 4.0, 7.0,
      4.0, 1.0, 4.0, 4.0, 3.0, 3.0, 4.0, 6.0, 4.0, 3.0, 2.0, 4.0, 3.0, 1.0, 3.0, 8.0,
      5.0, 6.0, 2.0, 7.0, 9.0, 5.0, 5.0, 3.0, 4.0, 4.0, 3.0, 2.0, 4.0, 6.0, 6.0, 1.0,
      3.0, 6.0, 2.0, 4.0, 4.0, 6.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10599759446978467
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03900065027104283
    mean_inference_ms: 1.9893533951205171
    mean_raw_obs_processing_ms: 0.44798761051046787
time_since_restore: 1637.1935067176819
time_this_iter_s: 10.228078842163086
time_total_s: 1637.1935067176819
timers:
  sample_time_ms: 0.04
  synch_weights_time_ms: 0.01
  training_iteration_time_ms: 0.103
timestamp: 1692343227
timesteps_total: 1221300
training_iteration: 160
trial_id: default
train step: 161
agent_timesteps_total: 1228900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03429293632507324
  StateBufferConnector_ms: 0.006093502044677734
  ViewRequirementAgentConnector_ms: 0.1994459629058838
counters:
  num_agent_steps_sampled: 1228900
  num_agent_steps_trained: 1212000
  num_env_steps_sampled: 1228900
  num_env_steps_trained: 1212000
  num_samples_added_to_queue: 1228500
  num_training_step_calls_since_last_synch_worker_weights: 214
  num_weight_broadcasts: 24053
custom_metrics: {}
date: 2023-08-18_16-20-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.36
episode_reward_min: 1.0
episodes_this_iter: 60
episodes_total: 9602
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.798823356628418
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -14.307210922241211
        total_loss: -1.9968810081481934
        var_gnorm: 63.36440658569336
        vf_explained_var: 0.25069552659988403
        vf_loss: 25.419483184814453
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2424.0
  learner_queue:
    size_count: 2430
    size_mean: 14.9
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.57797338380595
  num_agent_steps_sampled: 1228900
  num_agent_steps_trained: 1212000
  num_env_steps_sampled: 1228900
  num_env_steps_trained: 1212000
  num_samples_added_to_queue: 1228500
  num_training_step_calls_since_last_synch_worker_weights: 214
  num_weight_broadcasts: 24053
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 345.947
    learner_load_time_ms: 25.542
    learner_load_wait_time_ms: 2.637
iterations_since_restore: 161
node_ip: 127.0.0.1
num_agent_steps_sampled: 1228900
num_agent_steps_trained: 1212000
num_env_steps_sampled: 1228900
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9965210120193
num_env_steps_trained: 1212000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9965667881769
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.05333333333333
  ram_util_percent: 82.34666666666666
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10592974388599895
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03901339650690381
  mean_inference_ms: 1.9891254636351845
  mean_raw_obs_processing_ms: 0.4480703039156698
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03429293632507324
    StateBufferConnector_ms: 0.006093502044677734
    ViewRequirementAgentConnector_ms: 0.1994459629058838
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.36
  episode_reward_min: 1.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 4.0, 1.0, 4.0, 4.0, 3.0, 3.0, 4.0, 6.0, 4.0, 3.0, 2.0, 4.0,
      3.0, 1.0, 3.0, 8.0, 5.0, 6.0, 2.0, 7.0, 9.0, 5.0, 5.0, 3.0, 4.0, 4.0, 3.0, 2.0,
      4.0, 6.0, 6.0, 1.0, 3.0, 6.0, 2.0, 4.0, 4.0, 6.0, 4.0, 4.0, 5.0, 7.0, 8.0, 4.0,
      7.0, 6.0, 7.0, 7.0, 4.0, 6.0, 5.0, 2.0, 3.0, 5.0, 4.0, 4.0, 3.0, 5.0, 4.0, 6.0,
      5.0, 4.0, 3.0, 6.0, 4.0, 2.0, 4.0, 1.0, 4.0, 4.0, 4.0, 7.0, 3.0, 3.0, 5.0, 2.0,
      4.0, 7.0, 3.0, 4.0, 4.0, 4.0, 3.0, 8.0, 4.0, 2.0, 1.0, 4.0, 7.0, 3.0, 5.0, 1.0,
      4.0, 9.0, 9.0, 2.0, 7.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10592974388599895
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03901339650690381
    mean_inference_ms: 1.9891254636351845
    mean_raw_obs_processing_ms: 0.4480703039156698
time_since_restore: 1647.4302656650543
time_this_iter_s: 10.236758947372437
time_total_s: 1647.4302656650543
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692343237
timesteps_total: 1228900
training_iteration: 161
trial_id: default
train step: 162
agent_timesteps_total: 1236700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03440117835998535
  StateBufferConnector_ms: 0.006078004837036133
  ViewRequirementAgentConnector_ms: 0.19986867904663086
counters:
  num_agent_steps_sampled: 1236700
  num_agent_steps_trained: 1220000
  num_env_steps_sampled: 1236700
  num_env_steps_trained: 1220000
  num_samples_added_to_queue: 1236500
  num_training_step_calls_since_last_synch_worker_weights: 1270
  num_weight_broadcasts: 24205
custom_metrics: {}
date: 2023-08-18_16-20-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.21
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 9662
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7852540016174316
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -7.073520660400391
        total_loss: 9.19292163848877
        var_gnorm: 63.364933013916016
        vf_explained_var: 0.2211446762084961
        vf_loss: 33.318138122558594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2440.0
  learner_queue:
    size_count: 2443
    size_mean: 14.72
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6129476122924762
  num_agent_steps_sampled: 1236700
  num_agent_steps_trained: 1220000
  num_env_steps_sampled: 1236700
  num_env_steps_trained: 1220000
  num_samples_added_to_queue: 1236500
  num_training_step_calls_since_last_synch_worker_weights: 1270
  num_weight_broadcasts: 24205
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 571.99
    learner_load_time_ms: 37.69
    learner_load_wait_time_ms: 2.92
iterations_since_restore: 162
node_ip: 127.0.0.1
num_agent_steps_sampled: 1236700
num_agent_steps_trained: 1220000
num_env_steps_sampled: 1236700
num_env_steps_sampled_this_iter: 7800
num_env_steps_sampled_throughput_per_sec: 779.9937515759342
num_env_steps_trained: 1220000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9935913599325
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 56.8
  ram_util_percent: 81.39285714285714
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10586420252711642
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03902298133359326
  mean_inference_ms: 1.9889984787195265
  mean_raw_obs_processing_ms: 0.4481756871911577
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03440117835998535
    StateBufferConnector_ms: 0.006078004837036133
    ViewRequirementAgentConnector_ms: 0.19986867904663086
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.21
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 5.0, 4.0, 3.0, 6.0, 4.0, 2.0, 4.0, 1.0, 4.0, 4.0, 4.0, 7.0,
      3.0, 3.0, 5.0, 2.0, 4.0, 7.0, 3.0, 4.0, 4.0, 4.0, 3.0, 8.0, 4.0, 2.0, 1.0, 4.0,
      7.0, 3.0, 5.0, 1.0, 4.0, 9.0, 9.0, 2.0, 7.0, 5.0, 4.0, 7.0, 8.0, 6.0, 5.0, 5.0,
      2.0, 3.0, 3.0, 3.0, 3.0, 1.0, 9.0, 4.0, 4.0, 0.0, 2.0, 1.0, 5.0, 2.0, 6.0, 9.0,
      3.0, 4.0, 12.0, 4.0, 3.0, 4.0, 6.0, 4.0, 6.0, 3.0, 2.0, 6.0, 3.0, 3.0, 4.0,
      4.0, 2.0, 7.0, 8.0, 3.0, 5.0, 3.0, 0.0, 5.0, 6.0, 7.0, 6.0, 3.0, 3.0, 4.0, 2.0,
      3.0, 3.0, 4.0, 4.0, 2.0, 4.0, 6.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10586420252711642
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03902298133359326
    mean_inference_ms: 1.9889984787195265
    mean_raw_obs_processing_ms: 0.4481756871911577
time_since_restore: 1657.5730156898499
time_this_iter_s: 10.142750024795532
time_total_s: 1657.5730156898499
timers:
  sample_time_ms: 0.027
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.076
timestamp: 1692343247
timesteps_total: 1236700
training_iteration: 162
trial_id: default
train step: 163
agent_timesteps_total: 1243700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03501248359680176
  StateBufferConnector_ms: 0.006264448165893555
  ViewRequirementAgentConnector_ms: 0.21097803115844727
counters:
  num_agent_steps_sampled: 1243700
  num_agent_steps_trained: 1227000
  num_env_steps_sampled: 1243700
  num_env_steps_trained: 1227000
  num_samples_added_to_queue: 1243500
  num_training_step_calls_since_last_synch_worker_weights: 232
  num_weight_broadcasts: 24341
custom_metrics: {}
date: 2023-08-18_16-20-58
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 3.96
episode_reward_min: 0.0
episodes_this_iter: 55
episodes_total: 9717
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7816720008850098
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -5.274213790893555
        total_loss: 11.778429985046387
        var_gnorm: 63.36538314819336
        vf_explained_var: 0.17522257566452026
        vf_loss: 34.886959075927734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2454.0
  learner_queue:
    size_count: 2460
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5911002482559042
  num_agent_steps_sampled: 1243700
  num_agent_steps_trained: 1227000
  num_env_steps_sampled: 1243700
  num_env_steps_trained: 1227000
  num_samples_added_to_queue: 1243500
  num_training_step_calls_since_last_synch_worker_weights: 232
  num_weight_broadcasts: 24341
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 392.584
    learner_load_time_ms: 26.516
    learner_load_wait_time_ms: 3.559
iterations_since_restore: 163
node_ip: 127.0.0.1
num_agent_steps_sampled: 1243700
num_agent_steps_trained: 1227000
num_env_steps_sampled: 1243700
num_env_steps_sampled_this_iter: 7000
num_env_steps_sampled_throughput_per_sec: 699.9978303976548
num_env_steps_trained: 1227000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9978303976548
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 54.87857142857142
  ram_util_percent: 81.95714285714287
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10583293501522122
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03906297270551507
  mean_inference_ms: 1.9896371119036933
  mean_raw_obs_processing_ms: 0.4484115482887927
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03501248359680176
    StateBufferConnector_ms: 0.006264448165893555
    ViewRequirementAgentConnector_ms: 0.21097803115844727
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 3.96
  episode_reward_min: 0.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 1.0, 5.0, 2.0, 6.0, 9.0, 3.0, 4.0, 12.0, 4.0, 3.0, 4.0,
      6.0, 4.0, 6.0, 3.0, 2.0, 6.0, 3.0, 3.0, 4.0, 4.0, 2.0, 7.0, 8.0, 3.0, 5.0, 3.0,
      0.0, 5.0, 6.0, 7.0, 6.0, 3.0, 3.0, 4.0, 2.0, 3.0, 3.0, 4.0, 4.0, 2.0, 4.0, 6.0,
      1.0, 4.0, 3.0, 3.0, 3.0, 7.0, 1.0, 3.0, 9.0, 5.0, 2.0, 6.0, 5.0, 4.0, 5.0, 5.0,
      4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 5.0, 4.0, 3.0, 3.0, 4.0, 4.0, 1.0, 3.0, 2.0, 3.0,
      4.0, 5.0, 3.0, 9.0, 7.0, 2.0, 3.0, 2.0, 2.0, 4.0, 6.0, 3.0, 3.0, 3.0, 5.0, 6.0,
      5.0, 3.0, 1.0, 3.0, 3.0, 0.0, 4.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10583293501522122
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03906297270551507
    mean_inference_ms: 1.9896371119036933
    mean_raw_obs_processing_ms: 0.4484115482887927
time_since_restore: 1667.9924306869507
time_this_iter_s: 10.41941499710083
time_total_s: 1667.9924306869507
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692343258
timesteps_total: 1243700
training_iteration: 163
trial_id: default
train step: 164
agent_timesteps_total: 1251000
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03839898109436035
  StateBufferConnector_ms: 0.0068776607513427734
  ViewRequirementAgentConnector_ms: 0.22680449485778809
counters:
  num_agent_steps_sampled: 1251000
  num_agent_steps_trained: 1234500
  num_env_steps_sampled: 1251000
  num_env_steps_trained: 1234500
  num_samples_added_to_queue: 1251000
  num_training_step_calls_since_last_synch_worker_weights: 50
  num_weight_broadcasts: 24483
custom_metrics: {}
date: 2023-08-18_16-21-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.23
episode_reward_min: 0.0
episodes_this_iter: 57
episodes_total: 9774
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7679855823516846
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 4.3864593505859375
        total_loss: 22.175500869750977
        var_gnorm: 63.36576461791992
        vf_explained_var: 0.2520100474357605
        vf_loss: 36.3460693359375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2469.0
  learner_queue:
    size_count: 2475
    size_mean: 14.62
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.7075128110793196
  num_agent_steps_sampled: 1251000
  num_agent_steps_trained: 1234500
  num_env_steps_sampled: 1251000
  num_env_steps_trained: 1234500
  num_samples_added_to_queue: 1251000
  num_training_step_calls_since_last_synch_worker_weights: 50
  num_weight_broadcasts: 24483
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 292.831
    learner_load_time_ms: 29.02
    learner_load_wait_time_ms: 2.619
iterations_since_restore: 164
node_ip: 127.0.0.1
num_agent_steps_sampled: 1251000
num_agent_steps_trained: 1234500
num_env_steps_sampled: 1251000
num_env_steps_sampled_this_iter: 7300
num_env_steps_sampled_throughput_per_sec: 729.9986076381538
num_env_steps_trained: 1234500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9985694912539
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 50.92666666666666
  ram_util_percent: 82.71333333333332
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10582473863929694
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03911491780656206
  mean_inference_ms: 1.9905927265204735
  mean_raw_obs_processing_ms: 0.44871514301493354
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03839898109436035
    StateBufferConnector_ms: 0.0068776607513427734
    ViewRequirementAgentConnector_ms: 0.22680449485778809
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.23
  episode_reward_min: 0.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 5.0, 4.0, 4.0, 2.0, 4.0, 2.0, 4.0, 5.0, 4.0, 3.0, 3.0,
      4.0, 4.0, 1.0, 3.0, 2.0, 3.0, 4.0, 5.0, 3.0, 9.0, 7.0, 2.0, 3.0, 2.0, 2.0, 4.0,
      6.0, 3.0, 3.0, 3.0, 5.0, 6.0, 5.0, 3.0, 1.0, 3.0, 3.0, 0.0, 4.0, 6.0, 2.0, 1.0,
      5.0, 5.0, 3.0, 2.0, 7.0, 5.0, 5.0, 8.0, 4.0, 3.0, 6.0, 4.0, 7.0, 4.0, 3.0, 2.0,
      3.0, 3.0, 3.0, 5.0, 7.0, 4.0, 9.0, 5.0, 7.0, 6.0, 3.0, 2.0, 7.0, 4.0, 5.0, 3.0,
      8.0, 6.0, 2.0, 5.0, 5.0, 3.0, 4.0, 6.0, 5.0, 6.0, 8.0, 5.0, 2.0, 6.0, 5.0, 4.0,
      5.0, 6.0, 5.0, 7.0, 5.0, 3.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10582473863929694
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03911491780656206
    mean_inference_ms: 1.9905927265204735
    mean_raw_obs_processing_ms: 0.44871514301493354
time_since_restore: 1678.2792196273804
time_this_iter_s: 10.286788940429688
time_total_s: 1678.2792196273804
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.087
timestamp: 1692343268
timesteps_total: 1251000
training_iteration: 164
trial_id: default
train step: 165
agent_timesteps_total: 1258200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03658795356750488
  StateBufferConnector_ms: 0.006472587585449219
  ViewRequirementAgentConnector_ms: 0.21718859672546387
counters:
  num_agent_steps_sampled: 1258200
  num_agent_steps_trained: 1241500
  num_env_steps_sampled: 1258200
  num_env_steps_trained: 1241500
  num_samples_added_to_queue: 1258000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 24622
custom_metrics: {}
date: 2023-08-18_16-21-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.38
episode_reward_min: 1.0
episodes_this_iter: 56
episodes_total: 9830
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7803207635879517
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -23.152170181274414
        total_loss: -11.812665939331055
        var_gnorm: 63.36614990234375
        vf_explained_var: 0.19154709577560425
        vf_loss: 23.45932960510254
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2483.0
  learner_queue:
    size_count: 2489
    size_mean: 14.54
    size_quantiles: [10.0, 11.9, 15.5, 16.0, 16.0]
    size_std: 1.8133946068079059
  num_agent_steps_sampled: 1258200
  num_agent_steps_trained: 1241500
  num_env_steps_sampled: 1258200
  num_env_steps_trained: 1241500
  num_samples_added_to_queue: 1258000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 24622
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 427.873
    learner_load_time_ms: 29.057
    learner_load_wait_time_ms: 3.156
iterations_since_restore: 165
node_ip: 127.0.0.1
num_agent_steps_sampled: 1258200
num_agent_steps_trained: 1241500
num_env_steps_sampled: 1258200
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 719.6619000973363
num_env_steps_trained: 1241500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.6712917612992
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 59.84285714285714
  ram_util_percent: 82.57857142857144
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10585860471946804
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039135143132643095
  mean_inference_ms: 1.991326073177745
  mean_raw_obs_processing_ms: 0.4488652252254002
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03658795356750488
    StateBufferConnector_ms: 0.006472587585449219
    ViewRequirementAgentConnector_ms: 0.21718859672546387
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.38
  episode_reward_min: 1.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 7.0, 4.0, 3.0, 2.0, 3.0, 3.0, 3.0, 5.0, 7.0, 4.0, 9.0, 5.0,
      7.0, 6.0, 3.0, 2.0, 7.0, 4.0, 5.0, 3.0, 8.0, 6.0, 2.0, 5.0, 5.0, 3.0, 4.0, 6.0,
      5.0, 6.0, 8.0, 5.0, 2.0, 6.0, 5.0, 4.0, 5.0, 6.0, 5.0, 7.0, 5.0, 3.0, 2.0, 7.0,
      2.0, 5.0, 6.0, 3.0, 4.0, 5.0, 2.0, 4.0, 2.0, 7.0, 5.0, 5.0, 6.0, 3.0, 2.0, 1.0,
      5.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 1.0, 5.0, 5.0, 6.0, 5.0, 3.0, 3.0,
      2.0, 6.0, 1.0, 4.0, 6.0, 4.0, 3.0, 4.0, 12.0, 5.0, 3.0, 5.0, 3.0, 3.0, 2.0,
      5.0, 4.0, 4.0, 4.0, 8.0, 5.0, 1.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10585860471946804
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039135143132643095
    mean_inference_ms: 1.991326073177745
    mean_raw_obs_processing_ms: 0.4488652252254002
time_since_restore: 1688.7031466960907
time_this_iter_s: 10.423927068710327
time_total_s: 1688.7031466960907
timers:
  sample_time_ms: 0.057
  synch_weights_time_ms: 0.424
  training_iteration_time_ms: 0.599
timestamp: 1692343278
timesteps_total: 1258200
training_iteration: 165
trial_id: default
train step: 166
agent_timesteps_total: 1265850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03639793395996094
  StateBufferConnector_ms: 0.006489992141723633
  ViewRequirementAgentConnector_ms: 0.2127974033355713
counters:
  num_agent_steps_sampled: 1265850
  num_agent_steps_trained: 1249000
  num_env_steps_sampled: 1265850
  num_env_steps_trained: 1249000
  num_samples_added_to_queue: 1265500
  num_training_step_calls_since_last_synch_worker_weights: 393
  num_weight_broadcasts: 24773
custom_metrics: {}
date: 2023-08-18_16-21-29
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.15
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 9890
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.09999999999991
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7812246084213257
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -9.00477123260498
        total_loss: 4.696267604827881
        var_gnorm: 63.36635971069336
        vf_explained_var: 0.29157936573028564
        vf_loss: 28.18330192565918
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2498.0
  learner_queue:
    size_count: 2503
    size_mean: 14.28
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.8765926569183842
  num_agent_steps_sampled: 1265850
  num_agent_steps_trained: 1249000
  num_env_steps_sampled: 1265850
  num_env_steps_trained: 1249000
  num_samples_added_to_queue: 1265500
  num_training_step_calls_since_last_synch_worker_weights: 393
  num_weight_broadcasts: 24773
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 388.771
    learner_load_time_ms: 28.905
    learner_load_wait_time_ms: 3.09
iterations_since_restore: 166
node_ip: 127.0.0.1
num_agent_steps_sampled: 1265850
num_agent_steps_trained: 1249000
num_env_steps_sampled: 1265850
num_env_steps_sampled_this_iter: 7650
num_env_steps_sampled_throughput_per_sec: 764.9941270802278
num_env_steps_trained: 1249000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9942422355175
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.279999999999994
  ram_util_percent: 82.80666666666667
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10592353159494178
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03913058952295911
  mean_inference_ms: 1.991620968339559
  mean_raw_obs_processing_ms: 0.4487808126716938
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03639793395996094
    StateBufferConnector_ms: 0.006489992141723633
    ViewRequirementAgentConnector_ms: 0.2127974033355713
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.15
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 5.0, 4.0, 3.0, 3.0, 4.0, 4.0, 4.0, 4.0, 5.0, 1.0, 5.0, 5.0,
      6.0, 5.0, 3.0, 3.0, 2.0, 6.0, 1.0, 4.0, 6.0, 4.0, 3.0, 4.0, 12.0, 5.0, 3.0,
      5.0, 3.0, 3.0, 2.0, 5.0, 4.0, 4.0, 4.0, 8.0, 5.0, 1.0, 2.0, 8.0, 3.0, 5.0, 4.0,
      6.0, 2.0, 3.0, 7.0, 4.0, 5.0, 6.0, 2.0, 6.0, 5.0, 2.0, 5.0, 1.0, 4.0, 7.0, 4.0,
      3.0, 4.0, 4.0, 3.0, 3.0, 7.0, 2.0, 0.0, 3.0, 5.0, 1.0, 2.0, 5.0, 5.0, 6.0, 4.0,
      1.0, 6.0, 4.0, 4.0, 5.0, 7.0, 2.0, 4.0, 1.0, 1.0, 4.0, 5.0, 4.0, 4.0, 8.0, 8.0,
      6.0, 6.0, 5.0, 3.0, 7.0, 7.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10592353159494178
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03913058952295911
    mean_inference_ms: 1.991620968339559
    mean_raw_obs_processing_ms: 0.4487808126716938
time_since_restore: 1698.918637752533
time_this_iter_s: 10.21549105644226
time_total_s: 1698.918637752533
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692343289
timesteps_total: 1265850
training_iteration: 166
trial_id: default
train step: 167
agent_timesteps_total: 1272550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0389249324798584
  StateBufferConnector_ms: 0.00673675537109375
  ViewRequirementAgentConnector_ms: 0.21892380714416504
counters:
  num_agent_steps_sampled: 1272550
  num_agent_steps_trained: 1256000
  num_env_steps_sampled: 1272550
  num_env_steps_trained: 1256000
  num_samples_added_to_queue: 1272500
  num_training_step_calls_since_last_synch_worker_weights: 755
  num_weight_broadcasts: 24904
custom_metrics: {}
date: 2023-08-18_16-21-39
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 4.33
episode_reward_min: 0.0
episodes_this_iter: 52
episodes_total: 9942
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.59999999999991
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7685193419456482
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -33.882080078125
        total_loss: -21.00086784362793
        var_gnorm: 63.366764068603516
        vf_explained_var: 0.24077832698822021
        vf_loss: 26.530946731567383
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2512.0
  learner_queue:
    size_count: 2517
    size_mean: 14.38
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8318296864064632
  num_agent_steps_sampled: 1272550
  num_agent_steps_trained: 1256000
  num_env_steps_sampled: 1272550
  num_env_steps_trained: 1256000
  num_samples_added_to_queue: 1272500
  num_training_step_calls_since_last_synch_worker_weights: 755
  num_weight_broadcasts: 24904
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 476.282
    learner_load_time_ms: 28.974
    learner_load_wait_time_ms: 3.08
iterations_since_restore: 167
node_ip: 127.0.0.1
num_agent_steps_sampled: 1272550
num_agent_steps_trained: 1256000
num_env_steps_sampled: 1272550
num_env_steps_sampled_this_iter: 6700
num_env_steps_sampled_throughput_per_sec: 669.9955272973145
num_env_steps_trained: 1256000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.995327027045
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 58.31428571428571
  ram_util_percent: 81.72857142857143
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1059164171389354
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03915961958808953
  mean_inference_ms: 1.9923640720490186
  mean_raw_obs_processing_ms: 0.4490717572941254
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0389249324798584
    StateBufferConnector_ms: 0.00673675537109375
    ViewRequirementAgentConnector_ms: 0.21892380714416504
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 4.33
  episode_reward_min: 0.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 5.0, 2.0, 5.0, 1.0, 4.0, 7.0, 4.0, 3.0, 4.0, 4.0, 3.0, 3.0,
      7.0, 2.0, 0.0, 3.0, 5.0, 1.0, 2.0, 5.0, 5.0, 6.0, 4.0, 1.0, 6.0, 4.0, 4.0, 5.0,
      7.0, 2.0, 4.0, 1.0, 1.0, 4.0, 5.0, 4.0, 4.0, 8.0, 8.0, 6.0, 6.0, 5.0, 3.0, 7.0,
      7.0, 3.0, 3.0, 2.0, 6.0, 5.0, 6.0, 7.0, 3.0, 5.0, 7.0, 2.0, 4.0, 4.0, 7.0, 3.0,
      6.0, 3.0, 1.0, 4.0, 5.0, 6.0, 6.0, 2.0, 5.0, 3.0, 4.0, 4.0, 4.0, 7.0, 4.0, 5.0,
      1.0, 4.0, 2.0, 4.0, 6.0, 4.0, 7.0, 8.0, 7.0, 5.0, 2.0, 1.0, 2.0, 2.0, 6.0, 6.0,
      6.0, 3.0, 6.0, 4.0, 3.0, 7.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1059164171389354
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03915961958808953
    mean_inference_ms: 1.9923640720490186
    mean_raw_obs_processing_ms: 0.4490717572941254
time_since_restore: 1709.1183156967163
time_this_iter_s: 10.19967794418335
time_total_s: 1709.1183156967163
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1692343299
timesteps_total: 1272550
training_iteration: 167
trial_id: default
train step: 168
agent_timesteps_total: 1280400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0369877815246582
  StateBufferConnector_ms: 0.006316423416137695
  ViewRequirementAgentConnector_ms: 0.2120211124420166
counters:
  num_agent_steps_sampled: 1280400
  num_agent_steps_trained: 1263500
  num_env_steps_sampled: 1280400
  num_env_steps_trained: 1263500
  num_samples_added_to_queue: 1280000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 25057
custom_metrics: {}
date: 2023-08-18_16-21-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.6
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 10003
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.19999999999982
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.762496829032898
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 7.5572309494018555
        total_loss: 23.45956039428711
        var_gnorm: 63.367008209228516
        vf_explained_var: 0.26183563470840454
        vf_loss: 32.56715774536133
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2527.0
  learner_queue:
    size_count: 2531
    size_mean: 14.72
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.612947612292476
  num_agent_steps_sampled: 1280400
  num_agent_steps_trained: 1263500
  num_env_steps_sampled: 1280400
  num_env_steps_trained: 1263500
  num_samples_added_to_queue: 1280000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 25057
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 444.073
    learner_load_time_ms: 29.026
    learner_load_wait_time_ms: 3.144
iterations_since_restore: 168
node_ip: 127.0.0.1
num_agent_steps_sampled: 1280400
num_agent_steps_trained: 1263500
num_env_steps_sampled: 1280400
num_env_steps_sampled_this_iter: 7850
num_env_steps_sampled_throughput_per_sec: 784.6414930922123
num_env_steps_trained: 1263500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.6574774766359
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 56.013333333333335
  ram_util_percent: 82.39333333333335
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10597100352251979
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03916364719519325
  mean_inference_ms: 1.9928224903173901
  mean_raw_obs_processing_ms: 0.449093147607252
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0369877815246582
    StateBufferConnector_ms: 0.006316423416137695
    ViewRequirementAgentConnector_ms: 0.2120211124420166
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.6
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 3.0, 1.0, 4.0, 5.0, 6.0, 6.0, 2.0, 5.0, 3.0, 4.0, 4.0, 4.0,
      7.0, 4.0, 5.0, 1.0, 4.0, 2.0, 4.0, 6.0, 4.0, 7.0, 8.0, 7.0, 5.0, 2.0, 1.0, 2.0,
      2.0, 6.0, 6.0, 6.0, 3.0, 6.0, 4.0, 3.0, 7.0, 8.0, 12.0, 3.0, 6.0, 7.0, 4.0,
      5.0, 4.0, 6.0, 9.0, 3.0, 5.0, 5.0, 3.0, 4.0, 5.0, 4.0, 1.0, 6.0, 3.0, 2.0, 6.0,
      3.0, 5.0, 5.0, 3.0, 3.0, 1.0, 9.0, 2.0, 9.0, 5.0, 4.0, 6.0, 6.0, 6.0, 4.0, 5.0,
      3.0, 6.0, 3.0, 3.0, 2.0, 5.0, 0.0, 4.0, 6.0, 3.0, 4.0, 7.0, 6.0, 4.0, 7.0, 5.0,
      7.0, 5.0, 5.0, 6.0, 2.0, 5.0, 5.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10597100352251979
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03916364719519325
    mean_inference_ms: 1.9928224903173901
    mean_raw_obs_processing_ms: 0.449093147607252
time_since_restore: 1719.2939956188202
time_this_iter_s: 10.175679922103882
time_total_s: 1719.2939956188202
timers:
  sample_time_ms: 0.071
  synch_weights_time_ms: 0.46
  training_iteration_time_ms: 0.663
timestamp: 1692343309
timesteps_total: 1280400
training_iteration: 168
trial_id: default
train step: 169
agent_timesteps_total: 1288650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03142714500427246
  StateBufferConnector_ms: 0.005739688873291016
  ViewRequirementAgentConnector_ms: 0.18892192840576172
counters:
  num_agent_steps_sampled: 1288650
  num_agent_steps_trained: 1272000
  num_env_steps_sampled: 1288650
  num_env_steps_trained: 1272000
  num_samples_added_to_queue: 1288500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 25220
custom_metrics: {}
date: 2023-08-18_16-21-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.55
episode_reward_min: 0.0
episodes_this_iter: 65
episodes_total: 10068
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7687340378761292
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -13.16238784790039
        total_loss: 1.9834966659545898
        var_gnorm: 63.36754608154297
        vf_explained_var: 0.20838773250579834
        vf_loss: 31.060503005981445
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2544.0
  learner_queue:
    size_count: 2551
    size_mean: 14.84
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6656530250925612
  num_agent_steps_sampled: 1288650
  num_agent_steps_trained: 1272000
  num_env_steps_sampled: 1288650
  num_env_steps_trained: 1272000
  num_samples_added_to_queue: 1288500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 25220
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 220.065
    learner_load_time_ms: 29.025
    learner_load_wait_time_ms: 2.475
iterations_since_restore: 169
node_ip: 127.0.0.1
num_agent_steps_sampled: 1288650
num_agent_steps_trained: 1272000
num_env_steps_sampled: 1288650
num_env_steps_sampled_this_iter: 8250
num_env_steps_sampled_throughput_per_sec: 824.6768775032785
num_env_steps_trained: 1272000
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.6670859124688
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 43.192857142857136
  ram_util_percent: 81.32142857142857
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.106076474681728
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03910508259144695
  mean_inference_ms: 1.9919068905356705
  mean_raw_obs_processing_ms: 0.448491725205444
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03142714500427246
    StateBufferConnector_ms: 0.005739688873291016
    ViewRequirementAgentConnector_ms: 0.18892192840576172
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.55
  episode_reward_min: 0.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 9.0, 2.0, 9.0, 5.0, 4.0, 6.0, 6.0, 6.0, 4.0, 5.0, 3.0, 6.0,
      3.0, 3.0, 2.0, 5.0, 0.0, 4.0, 6.0, 3.0, 4.0, 7.0, 6.0, 4.0, 7.0, 5.0, 7.0, 5.0,
      5.0, 6.0, 2.0, 5.0, 5.0, 5.0, 2.0, 2.0, 7.0, 4.0, 8.0, 6.0, 4.0, 4.0, 4.0, 4.0,
      5.0, 3.0, 0.0, 6.0, 6.0, 4.0, 4.0, 3.0, 4.0, 2.0, 2.0, 11.0, 2.0, 5.0, 7.0,
      5.0, 7.0, 5.0, 4.0, 7.0, 7.0, 5.0, 4.0, 0.0, 4.0, 3.0, 5.0, 4.0, 9.0, 2.0, 3.0,
      6.0, 2.0, 2.0, 4.0, 6.0, 7.0, 4.0, 5.0, 2.0, 6.0, 3.0, 9.0, 2.0, 6.0, 6.0, 5.0,
      2.0, 7.0, 5.0, 3.0, 4.0, 3.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.106076474681728
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03910508259144695
    mean_inference_ms: 1.9919068905356705
    mean_raw_obs_processing_ms: 0.448491725205444
time_since_restore: 1729.5505878925323
time_this_iter_s: 10.256592273712158
time_total_s: 1729.5505878925323
timers:
  sample_time_ms: 0.124
  synch_weights_time_ms: 0.74
  training_iteration_time_ms: 1.038
timestamp: 1692343319
timesteps_total: 1288650
training_iteration: 169
trial_id: default
train step: 170
agent_timesteps_total: 1296800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03083014488220215
  StateBufferConnector_ms: 0.005625486373901367
  ViewRequirementAgentConnector_ms: 0.18543291091918945
counters:
  num_agent_steps_sampled: 1296800
  num_agent_steps_trained: 1280000
  num_env_steps_sampled: 1296800
  num_env_steps_trained: 1280000
  num_samples_added_to_queue: 1296500
  num_training_step_calls_since_last_synch_worker_weights: 1184
  num_weight_broadcasts: 25380
custom_metrics: {}
date: 2023-08-18_16-22-10
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.36
episode_reward_min: 0.0
episodes_this_iter: 64
episodes_total: 10132
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7585488557815552
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -11.534510612487793
        total_loss: 6.475375175476074
        var_gnorm: 63.36810302734375
        vf_explained_var: 0.22268706560134888
        vf_loss: 36.7783203125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2560.0
  learner_queue:
    size_count: 2564
    size_mean: 14.84
    size_quantiles: [10.0, 12.9, 16.0, 16.0, 16.0]
    size_std: 1.616910634512619
  num_agent_steps_sampled: 1296800
  num_agent_steps_trained: 1280000
  num_env_steps_sampled: 1296800
  num_env_steps_trained: 1280000
  num_samples_added_to_queue: 1296500
  num_training_step_calls_since_last_synch_worker_weights: 1184
  num_weight_broadcasts: 25380
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 597.705
    learner_load_time_ms: 17.89
    learner_load_wait_time_ms: 3.311
iterations_since_restore: 170
node_ip: 127.0.0.1
num_agent_steps_sampled: 1296800
num_agent_steps_trained: 1280000
num_env_steps_sampled: 1296800
num_env_steps_sampled_this_iter: 8150
num_env_steps_sampled_throughput_per_sec: 814.9990867386562
num_env_steps_trained: 1280000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9991035471471
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.10714285714285
  ram_util_percent: 81.5
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10604857645321211
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03907531705243034
  mean_inference_ms: 1.9909207652245513
  mean_raw_obs_processing_ms: 0.4482288070772777
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03083014488220215
    StateBufferConnector_ms: 0.005625486373901367
    ViewRequirementAgentConnector_ms: 0.18543291091918945
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.36
  episode_reward_min: 0.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 7.0, 5.0, 4.0, 0.0, 4.0, 3.0, 5.0, 4.0, 9.0, 2.0, 3.0, 6.0,
      2.0, 2.0, 4.0, 6.0, 7.0, 4.0, 5.0, 2.0, 6.0, 3.0, 9.0, 2.0, 6.0, 6.0, 5.0, 2.0,
      7.0, 5.0, 3.0, 4.0, 3.0, 4.0, 4.0, 4.0, 6.0, 4.0, 5.0, 5.0, 1.0, 3.0, 1.0, 0.0,
      4.0, 2.0, 4.0, 2.0, 3.0, 11.0, 4.0, 4.0, 6.0, 6.0, 7.0, 6.0, 6.0, 3.0, 1.0,
      4.0, 5.0, 11.0, 3.0, 2.0, 4.0, 2.0, 3.0, 5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0,
      4.0, 4.0, 5.0, 2.0, 3.0, 2.0, 6.0, 1.0, 4.0, 5.0, 8.0, 7.0, 6.0, 3.0, 5.0, 7.0,
      2.0, 4.0, 5.0, 4.0, 3.0, 6.0, 7.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10604857645321211
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03907531705243034
    mean_inference_ms: 1.9909207652245513
    mean_raw_obs_processing_ms: 0.4482288070772777
time_since_restore: 1739.6998047828674
time_this_iter_s: 10.149216890335083
time_total_s: 1739.6998047828674
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.072
timestamp: 1692343330
timesteps_total: 1296800
training_iteration: 170
trial_id: default
train step: 171
agent_timesteps_total: 1304600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03258371353149414
  StateBufferConnector_ms: 0.005815029144287109
  ViewRequirementAgentConnector_ms: 0.19431591033935547
counters:
  num_agent_steps_sampled: 1304600
  num_agent_steps_trained: 1288000
  num_env_steps_sampled: 1304600
  num_env_steps_trained: 1288000
  num_samples_added_to_queue: 1304500
  num_training_step_calls_since_last_synch_worker_weights: 336
  num_weight_broadcasts: 25533
custom_metrics: {}
date: 2023-08-18_16-22-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.28
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 10192
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.748084306716919
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -10.251063346862793
        total_loss: 3.7687087059020996
        var_gnorm: 63.36851119995117
        vf_explained_var: 0.2290753722190857
        vf_loss: 28.787628173828125
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2576.0
  learner_queue:
    size_count: 2582
    size_mean: 14.92
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.683330033000065
  num_agent_steps_sampled: 1304600
  num_agent_steps_trained: 1288000
  num_env_steps_sampled: 1304600
  num_env_steps_trained: 1288000
  num_samples_added_to_queue: 1304500
  num_training_step_calls_since_last_synch_worker_weights: 336
  num_weight_broadcasts: 25533
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 308.866
    learner_load_time_ms: 17.752
    learner_load_wait_time_ms: 2.743
iterations_since_restore: 171
node_ip: 127.0.0.1
num_agent_steps_sampled: 1304600
num_agent_steps_trained: 1288000
num_env_steps_sampled: 1304600
num_env_steps_sampled_this_iter: 7800
num_env_steps_sampled_throughput_per_sec: 779.9973406882353
num_env_steps_trained: 1288000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9972725007542
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 54.673333333333325
  ram_util_percent: 81.94000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10597385004428679
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039077287304434875
  mean_inference_ms: 1.9904639231704306
  mean_raw_obs_processing_ms: 0.44826924226395576
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03258371353149414
    StateBufferConnector_ms: 0.005815029144287109
    ViewRequirementAgentConnector_ms: 0.19431591033935547
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.28
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 11.0, 3.0, 2.0, 4.0, 2.0, 3.0, 5.0, 4.0, 5.0, 5.0,
      5.0, 5.0, 5.0, 4.0, 4.0, 5.0, 2.0, 3.0, 2.0, 6.0, 1.0, 4.0, 5.0, 8.0, 7.0, 6.0,
      3.0, 5.0, 7.0, 2.0, 4.0, 5.0, 4.0, 3.0, 6.0, 7.0, 4.0, 3.0, 4.0, 4.0, 2.0, 2.0,
      5.0, 2.0, 5.0, 5.0, 4.0, 3.0, 2.0, 3.0, 6.0, 4.0, 2.0, 4.0, 5.0, 2.0, 5.0, 4.0,
      3.0, 4.0, 0.0, 1.0, 5.0, 6.0, 4.0, 5.0, 3.0, 3.0, 3.0, 4.0, 9.0, 3.0, 6.0, 2.0,
      4.0, 2.0, 5.0, 6.0, 8.0, 4.0, 6.0, 6.0, 4.0, 8.0, 4.0, 3.0, 6.0, 5.0, 4.0, 6.0,
      5.0, 6.0, 7.0, 3.0, 6.0, 4.0, 4.0, 0.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10597385004428679
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039077287304434875
    mean_inference_ms: 1.9904639231704306
    mean_raw_obs_processing_ms: 0.44826924226395576
time_since_restore: 1749.930303812027
time_this_iter_s: 10.230499029159546
time_total_s: 1749.930303812027
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.072
timestamp: 1692343340
timesteps_total: 1304600
training_iteration: 171
trial_id: default
train step: 172
agent_timesteps_total: 1312500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.032894134521484375
  StateBufferConnector_ms: 0.005859851837158203
  ViewRequirementAgentConnector_ms: 0.19687700271606445
counters:
  num_agent_steps_sampled: 1312500
  num_agent_steps_trained: 1296000
  num_env_steps_sampled: 1312500
  num_env_steps_trained: 1296000
  num_samples_added_to_queue: 1312500
  num_training_step_calls_since_last_synch_worker_weights: 233
  num_weight_broadcasts: 25688
custom_metrics: {}
date: 2023-08-18_16-22-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.28
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 10254
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7489622831344604
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 8.732497215270996
        total_loss: 25.32010269165039
        var_gnorm: 63.36885452270508
        vf_explained_var: 0.2845214605331421
        vf_loss: 33.92417526245117
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2592.0
  learner_queue:
    size_count: 2597
    size_mean: 14.56
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.8238420984284798
  num_agent_steps_sampled: 1312500
  num_agent_steps_trained: 1296000
  num_env_steps_sampled: 1312500
  num_env_steps_trained: 1296000
  num_samples_added_to_queue: 1312500
  num_training_step_calls_since_last_synch_worker_weights: 233
  num_weight_broadcasts: 25688
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 347.869
    learner_load_time_ms: 5.326
    learner_load_wait_time_ms: 2.992
iterations_since_restore: 172
node_ip: 127.0.0.1
num_agent_steps_sampled: 1312500
num_agent_steps_trained: 1296000
num_env_steps_sampled: 1312500
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.9965343627376
num_env_steps_trained: 1296000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9964904939114
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 51.77142857142858
  ram_util_percent: 82.87142857142858
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10593488796616281
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039077500681388294
  mean_inference_ms: 1.9901421918279716
  mean_raw_obs_processing_ms: 0.44827739412622236
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.032894134521484375
    StateBufferConnector_ms: 0.005859851837158203
    ViewRequirementAgentConnector_ms: 0.19687700271606445
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.28
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 1.0, 5.0, 6.0, 4.0, 5.0, 3.0, 3.0, 3.0, 4.0, 9.0, 3.0, 6.0,
      2.0, 4.0, 2.0, 5.0, 6.0, 8.0, 4.0, 6.0, 6.0, 4.0, 8.0, 4.0, 3.0, 6.0, 5.0, 4.0,
      6.0, 5.0, 6.0, 7.0, 3.0, 6.0, 4.0, 4.0, 0.0, 4.0, 4.0, 2.0, 3.0, 8.0, 5.0, 4.0,
      5.0, 6.0, 5.0, 5.0, 3.0, 4.0, 3.0, 6.0, 1.0, 6.0, 5.0, 7.0, 3.0, 8.0, 5.0, 3.0,
      3.0, 5.0, 7.0, 4.0, 2.0, 4.0, 5.0, 3.0, 4.0, 7.0, 5.0, 1.0, 4.0, 5.0, 6.0, 3.0,
      2.0, 1.0, 7.0, 2.0, 5.0, 2.0, 3.0, 3.0, 3.0, 6.0, 2.0, 8.0, 2.0, 4.0, 4.0, 4.0,
      7.0, 3.0, 2.0, 3.0, 8.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10593488796616281
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039077500681388294
    mean_inference_ms: 1.9901421918279716
    mean_raw_obs_processing_ms: 0.44827739412622236
time_since_restore: 1760.1899790763855
time_this_iter_s: 10.25967526435852
time_total_s: 1760.1899790763855
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692343350
timesteps_total: 1312500
training_iteration: 172
trial_id: default
train step: 173
agent_timesteps_total: 1319400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035814762115478516
  StateBufferConnector_ms: 0.006365776062011719
  ViewRequirementAgentConnector_ms: 0.20946764945983887
counters:
  num_agent_steps_sampled: 1319400
  num_agent_steps_trained: 1302500
  num_env_steps_sampled: 1319400
  num_env_steps_trained: 1302500
  num_samples_added_to_queue: 1319000
  num_training_step_calls_since_last_synch_worker_weights: 608
  num_weight_broadcasts: 25823
custom_metrics: {}
date: 2023-08-18_16-22-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.09
episode_reward_min: 1.0
episodes_this_iter: 54
episodes_total: 10308
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7374681830406189
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -7.825560569763184
        total_loss: 12.98326587677002
        var_gnorm: 63.36919403076172
        vf_explained_var: 0.1989225149154663
        vf_loss: 42.35512161254883
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2605.0
  learner_queue:
    size_count: 2610
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5911002482559042
  num_agent_steps_sampled: 1319400
  num_agent_steps_trained: 1302500
  num_env_steps_sampled: 1319400
  num_env_steps_trained: 1302500
  num_samples_added_to_queue: 1319000
  num_training_step_calls_since_last_synch_worker_weights: 608
  num_weight_broadcasts: 25823
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 598.35
    learner_load_time_ms: 5.326
    learner_load_wait_time_ms: 3.293
iterations_since_restore: 173
node_ip: 127.0.0.1
num_agent_steps_sampled: 1319400
num_agent_steps_trained: 1302500
num_env_steps_sampled: 1319400
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 689.9984207189467
num_env_steps_trained: 1302500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9985122714716
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 58.9
  ram_util_percent: 82.72142857142858
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10588253125475827
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03910842695972723
  mean_inference_ms: 1.9906725024801226
  mean_raw_obs_processing_ms: 0.448589017311281
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035814762115478516
    StateBufferConnector_ms: 0.006365776062011719
    ViewRequirementAgentConnector_ms: 0.20946764945983887
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.09
  episode_reward_min: 1.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 5.0, 7.0, 3.0, 8.0, 5.0, 3.0, 3.0, 5.0, 7.0, 4.0, 2.0, 4.0,
      5.0, 3.0, 4.0, 7.0, 5.0, 1.0, 4.0, 5.0, 6.0, 3.0, 2.0, 1.0, 7.0, 2.0, 5.0, 2.0,
      3.0, 3.0, 3.0, 6.0, 2.0, 8.0, 2.0, 4.0, 4.0, 4.0, 7.0, 3.0, 2.0, 3.0, 8.0, 2.0,
      2.0, 3.0, 4.0, 2.0, 4.0, 1.0, 1.0, 7.0, 2.0, 3.0, 5.0, 4.0, 3.0, 6.0, 4.0, 3.0,
      3.0, 5.0, 7.0, 5.0, 6.0, 2.0, 3.0, 3.0, 3.0, 3.0, 7.0, 10.0, 5.0, 4.0, 3.0,
      8.0, 4.0, 4.0, 3.0, 6.0, 3.0, 6.0, 2.0, 1.0, 4.0, 6.0, 2.0, 3.0, 4.0, 4.0, 5.0,
      2.0, 4.0, 7.0, 5.0, 3.0, 4.0, 6.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10588253125475827
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03910842695972723
    mean_inference_ms: 1.9906725024801226
    mean_raw_obs_processing_ms: 0.448589017311281
time_since_restore: 1770.4123389720917
time_this_iter_s: 10.222359895706177
time_total_s: 1770.4123389720917
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.085
timestamp: 1692343360
timesteps_total: 1319400
training_iteration: 173
trial_id: default
train step: 174
agent_timesteps_total: 1326100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0391237735748291
  StateBufferConnector_ms: 0.007428884506225586
  ViewRequirementAgentConnector_ms: 0.2297813892364502
counters:
  num_agent_steps_sampled: 1326100
  num_agent_steps_trained: 1309500
  num_env_steps_sampled: 1326100
  num_env_steps_trained: 1309500
  num_samples_added_to_queue: 1326000
  num_training_step_calls_since_last_synch_worker_weights: 1056
  num_weight_broadcasts: 25954
custom_metrics: {}
date: 2023-08-18_16-22-51
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.36
episode_reward_min: 1.0
episodes_this_iter: 52
episodes_total: 10360
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.69999999999982
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7339649796485901
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -3.6122026443481445
        total_loss: 10.587388038635254
        var_gnorm: 63.369632720947266
        vf_explained_var: 0.2362479567527771
        vf_loss: 29.133146286010742
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2619.0
  learner_queue:
    size_count: 2623
    size_mean: 14.64
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.63413585726524
  num_agent_steps_sampled: 1326100
  num_agent_steps_trained: 1309500
  num_env_steps_sampled: 1326100
  num_env_steps_trained: 1309500
  num_samples_added_to_queue: 1326000
  num_training_step_calls_since_last_synch_worker_weights: 1056
  num_weight_broadcasts: 25954
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 607.734
    learner_load_time_ms: 5.326
    learner_load_wait_time_ms: 3.632
iterations_since_restore: 174
node_ip: 127.0.0.1
num_agent_steps_sampled: 1326100
num_agent_steps_trained: 1309500
num_env_steps_sampled: 1326100
num_env_steps_sampled_this_iter: 6700
num_env_steps_sampled_throughput_per_sec: 669.9996166231442
num_env_steps_trained: 1309500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9995994570163
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 60.68666666666665
  ram_util_percent: 82.23999999999998
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10582346323975698
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039173390878257434
  mean_inference_ms: 1.9920065046538877
  mean_raw_obs_processing_ms: 0.4492139669688494
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0391237735748291
    StateBufferConnector_ms: 0.007428884506225586
    ViewRequirementAgentConnector_ms: 0.2297813892364502
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.36
  episode_reward_min: 1.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 2.0, 3.0, 5.0, 4.0, 3.0, 6.0, 4.0, 3.0, 3.0, 5.0, 7.0, 5.0,
      6.0, 2.0, 3.0, 3.0, 3.0, 3.0, 7.0, 10.0, 5.0, 4.0, 3.0, 8.0, 4.0, 4.0, 3.0,
      6.0, 3.0, 6.0, 2.0, 1.0, 4.0, 6.0, 2.0, 3.0, 4.0, 4.0, 5.0, 2.0, 4.0, 7.0, 5.0,
      3.0, 4.0, 6.0, 2.0, 3.0, 1.0, 4.0, 7.0, 5.0, 7.0, 5.0, 4.0, 4.0, 6.0, 4.0, 2.0,
      5.0, 4.0, 6.0, 5.0, 2.0, 4.0, 7.0, 2.0, 3.0, 7.0, 1.0, 6.0, 3.0, 8.0, 6.0, 4.0,
      3.0, 5.0, 8.0, 7.0, 7.0, 1.0, 3.0, 4.0, 6.0, 6.0, 5.0, 5.0, 6.0, 5.0, 4.0, 3.0,
      2.0, 6.0, 7.0, 3.0, 3.0, 2.0, 4.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10582346323975698
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039173390878257434
    mean_inference_ms: 1.9920065046538877
    mean_raw_obs_processing_ms: 0.4492139669688494
time_since_restore: 1780.6243269443512
time_this_iter_s: 10.211987972259521
time_total_s: 1780.6243269443512
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.085
timestamp: 1692343371
timesteps_total: 1326100
training_iteration: 174
trial_id: default
train step: 175
agent_timesteps_total: 1333600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03571200370788574
  StateBufferConnector_ms: 0.006933927536010742
  ViewRequirementAgentConnector_ms: 0.2152860164642334
counters:
  num_agent_steps_sampled: 1333600
  num_agent_steps_trained: 1317000
  num_env_steps_sampled: 1333600
  num_env_steps_trained: 1317000
  num_samples_added_to_queue: 1333500
  num_training_step_calls_since_last_synch_worker_weights: 115
  num_weight_broadcasts: 26100
custom_metrics: {}
date: 2023-08-18_16-23-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 4.39
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 10420
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7473973035812378
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 22.602312088012695
        total_loss: 44.31120681762695
        var_gnorm: 63.37002182006836
        vf_explained_var: 0.23466622829437256
        vf_loss: 44.165184020996094
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2634.0
  learner_queue:
    size_count: 2640
    size_mean: 14.72
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.5497096502248413
  num_agent_steps_sampled: 1333600
  num_agent_steps_trained: 1317000
  num_env_steps_sampled: 1333600
  num_env_steps_trained: 1317000
  num_samples_added_to_queue: 1333500
  num_training_step_calls_since_last_synch_worker_weights: 115
  num_weight_broadcasts: 26100
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 326.567
    learner_load_time_ms: 4.689
    learner_load_wait_time_ms: 2.851
iterations_since_restore: 175
node_ip: 127.0.0.1
num_agent_steps_sampled: 1333600
num_agent_steps_trained: 1317000
num_env_steps_sampled: 1333600
num_env_steps_sampled_this_iter: 7500
num_env_steps_sampled_throughput_per_sec: 749.9995529654307
num_env_steps_trained: 1317000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9995529654307
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 51.27333333333333
  ram_util_percent: 82.30666666666669
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10594386134082182
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03917594378433634
  mean_inference_ms: 1.9928453830558919
  mean_raw_obs_processing_ms: 0.4492753021516881
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03571200370788574
    StateBufferConnector_ms: 0.006933927536010742
    ViewRequirementAgentConnector_ms: 0.2152860164642334
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 4.39
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 4.0, 6.0, 5.0, 2.0, 4.0, 7.0, 2.0, 3.0, 7.0, 1.0, 6.0, 3.0,
      8.0, 6.0, 4.0, 3.0, 5.0, 8.0, 7.0, 7.0, 1.0, 3.0, 4.0, 6.0, 6.0, 5.0, 5.0, 6.0,
      5.0, 4.0, 3.0, 2.0, 6.0, 7.0, 3.0, 3.0, 2.0, 4.0, 2.0, 2.0, 3.0, 6.0, 6.0, 4.0,
      4.0, 3.0, 7.0, 4.0, 2.0, 0.0, 3.0, 4.0, 6.0, 2.0, 6.0, 3.0, 7.0, 6.0, 2.0, 5.0,
      7.0, 4.0, 6.0, 2.0, 4.0, 3.0, 5.0, 7.0, 6.0, 7.0, 4.0, 2.0, 3.0, 1.0, 5.0, 5.0,
      6.0, 2.0, 7.0, 2.0, 5.0, 3.0, 8.0, 6.0, 3.0, 7.0, 1.0, 5.0, 6.0, 6.0, 0.0, 3.0,
      6.0, 2.0, 5.0, 7.0, 1.0, 8.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10594386134082182
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03917594378433634
    mean_inference_ms: 1.9928453830558919
    mean_raw_obs_processing_ms: 0.4492753021516881
time_since_restore: 1791.1519911289215
time_this_iter_s: 10.527664184570312
time_total_s: 1791.1519911289215
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1692343381
timesteps_total: 1333600
training_iteration: 175
trial_id: default
train step: 176
agent_timesteps_total: 1341700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031116008758544922
  StateBufferConnector_ms: 0.005704402923583984
  ViewRequirementAgentConnector_ms: 0.19024944305419922
counters:
  num_agent_steps_sampled: 1341700
  num_agent_steps_trained: 1325000
  num_env_steps_sampled: 1341700
  num_env_steps_trained: 1325000
  num_samples_added_to_queue: 1341500
  num_training_step_calls_since_last_synch_worker_weights: 1401
  num_weight_broadcasts: 26258
custom_metrics: {}
date: 2023-08-18_16-23-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.09
episode_reward_min: 0.0
episodes_this_iter: 62
episodes_total: 10482
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7163882851600647
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 10.623269081115723
        total_loss: 33.51704025268555
        var_gnorm: 63.37032699584961
        vf_explained_var: 0.22547578811645508
        vf_loss: 46.50392532348633
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2650.0
  learner_queue:
    size_count: 2654
    size_mean: 14.84
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5014659503298768
  num_agent_steps_sampled: 1341700
  num_agent_steps_trained: 1325000
  num_env_steps_sampled: 1341700
  num_env_steps_trained: 1325000
  num_samples_added_to_queue: 1341500
  num_training_step_calls_since_last_synch_worker_weights: 1401
  num_weight_broadcasts: 26258
  timing_breakdown:
    learner_dequeue_time_ms: 0.01
    learner_grad_time_ms: 422.499
    learner_load_time_ms: 4.689
    learner_load_wait_time_ms: 2.776
iterations_since_restore: 176
node_ip: 127.0.0.1
num_agent_steps_sampled: 1341700
num_agent_steps_trained: 1325000
num_env_steps_sampled: 1341700
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9991889008061
num_env_steps_trained: 1325000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9991989143764
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.41428571428571
  ram_util_percent: 81.28571428571429
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10604365805623096
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03913330603545945
  mean_inference_ms: 1.9923703392037055
  mean_raw_obs_processing_ms: 0.44893773834606904
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031116008758544922
    StateBufferConnector_ms: 0.005704402923583984
    ViewRequirementAgentConnector_ms: 0.19024944305419922
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.09
  episode_reward_min: 0.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 6.0, 2.0, 4.0, 3.0, 5.0, 7.0, 6.0, 7.0, 4.0, 2.0, 3.0, 1.0,
      5.0, 5.0, 6.0, 2.0, 7.0, 2.0, 5.0, 3.0, 8.0, 6.0, 3.0, 7.0, 1.0, 5.0, 6.0, 6.0,
      0.0, 3.0, 6.0, 2.0, 5.0, 7.0, 1.0, 8.0, 4.0, 1.0, 2.0, 3.0, 4.0, 5.0, 1.0, 2.0,
      3.0, 6.0, 5.0, 4.0, 1.0, 9.0, 5.0, 3.0, 8.0, 2.0, 6.0, 4.0, 3.0, 4.0, 1.0, 5.0,
      3.0, 3.0, 3.0, 2.0, 2.0, 4.0, 5.0, 4.0, 7.0, 6.0, 5.0, 7.0, 3.0, 6.0, 5.0, 7.0,
      4.0, 4.0, 5.0, 4.0, 3.0, 4.0, 3.0, 3.0, 6.0, 4.0, 4.0, 4.0, 2.0, 5.0, 2.0, 6.0,
      4.0, 1.0, 2.0, 4.0, 0.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10604365805623096
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03913330603545945
    mean_inference_ms: 1.9923703392037055
    mean_raw_obs_processing_ms: 0.44893773834606904
time_since_restore: 1801.310788154602
time_this_iter_s: 10.158797025680542
time_total_s: 1801.310788154602
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.085
timestamp: 1692343391
timesteps_total: 1341700
training_iteration: 176
trial_id: default
train step: 177
agent_timesteps_total: 1350100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.030468463897705078
  StateBufferConnector_ms: 0.005605220794677734
  ViewRequirementAgentConnector_ms: 0.18496322631835938
counters:
  num_agent_steps_sampled: 1350100
  num_agent_steps_trained: 1333500
  num_env_steps_sampled: 1350100
  num_env_steps_trained: 1333500
  num_samples_added_to_queue: 1350000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 26422
custom_metrics: {}
date: 2023-08-18_16-23-22
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.53
episode_reward_min: 0.0
episodes_this_iter: 66
episodes_total: 10548
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7198371291160583
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -2.8549532890319824
        total_loss: 16.81743049621582
        var_gnorm: 63.37076950073242
        vf_explained_var: 0.1906372308731079
        vf_loss: 40.064605712890625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2667.0
  learner_queue:
    size_count: 2673
    size_mean: 15.0
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5231546211727816
  num_agent_steps_sampled: 1350100
  num_agent_steps_trained: 1333500
  num_env_steps_sampled: 1350100
  num_env_steps_trained: 1333500
  num_samples_added_to_queue: 1350000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 26422
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 272.983
    learner_load_time_ms: 4.277
    learner_load_wait_time_ms: 2.652
iterations_since_restore: 177
node_ip: 127.0.0.1
num_agent_steps_sampled: 1350100
num_agent_steps_trained: 1333500
num_env_steps_sampled: 1350100
num_env_steps_sampled_this_iter: 8400
num_env_steps_sampled_throughput_per_sec: 839.69847920429
num_env_steps_trained: 1333500
num_env_steps_trained_this_iter: 8500
num_env_steps_trained_throughput_per_sec: 849.6948896710078
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8500
perf:
  cpu_util_percent: 49.85
  ram_util_percent: 80.38571428571429
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10605941097183912
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03908827458828272
  mean_inference_ms: 1.9912770822218697
  mean_raw_obs_processing_ms: 0.4484981583748566
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.030468463897705078
    StateBufferConnector_ms: 0.005605220794677734
    ViewRequirementAgentConnector_ms: 0.18496322631835938
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.53
  episode_reward_min: 0.0
  episodes_this_iter: 66
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 4.0, 7.0, 6.0, 5.0, 7.0, 3.0, 6.0, 5.0, 7.0, 4.0, 4.0,
      5.0, 4.0, 3.0, 4.0, 3.0, 3.0, 6.0, 4.0, 4.0, 4.0, 2.0, 5.0, 2.0, 6.0, 4.0, 1.0,
      2.0, 4.0, 0.0, 5.0, 4.0, 7.0, 5.0, 8.0, 4.0, 4.0, 3.0, 2.0, 1.0, 6.0, 6.0, 5.0,
      4.0, 4.0, 2.0, 8.0, 4.0, 8.0, 6.0, 9.0, 5.0, 4.0, 5.0, 1.0, 5.0, 1.0, 7.0, 2.0,
      6.0, 4.0, 5.0, 8.0, 4.0, 3.0, 6.0, 6.0, 1.0, 5.0, 2.0, 4.0, 5.0, 8.0, 2.0, 7.0,
      2.0, 3.0, 5.0, 3.0, 7.0, 5.0, 4.0, 2.0, 7.0, 7.0, 2.0, 6.0, 2.0, 4.0, 4.0, 5.0,
      3.0, 7.0, 7.0, 5.0, 6.0, 5.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10605941097183912
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03908827458828272
    mean_inference_ms: 1.9912770822218697
    mean_raw_obs_processing_ms: 0.4484981583748566
time_since_restore: 1811.544117450714
time_this_iter_s: 10.23332929611206
time_total_s: 1811.544117450714
timers:
  sample_time_ms: 0.053
  synch_weights_time_ms: 0.364
  training_iteration_time_ms: 0.518
timestamp: 1692343402
timesteps_total: 1350100
training_iteration: 177
trial_id: default
train step: 178
agent_timesteps_total: 1358300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03089118003845215
  StateBufferConnector_ms: 0.005667209625244141
  ViewRequirementAgentConnector_ms: 0.18709254264831543
counters:
  num_agent_steps_sampled: 1358300
  num_agent_steps_trained: 1341500
  num_env_steps_sampled: 1358300
  num_env_steps_trained: 1341500
  num_samples_added_to_queue: 1358000
  num_training_step_calls_since_last_synch_worker_weights: 148
  num_weight_broadcasts: 26584
custom_metrics: {}
date: 2023-08-18_16-23-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.26
episode_reward_min: 1.0
episodes_this_iter: 65
episodes_total: 10613
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7190605401992798
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -15.944841384887695
        total_loss: 3.9592888355255127
        var_gnorm: 63.371360778808594
        vf_explained_var: 0.15843695402145386
        vf_loss: 40.527320861816406
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2683.0
  learner_queue:
    size_count: 2689
    size_mean: 14.88
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6326665305566843
  num_agent_steps_sampled: 1358300
  num_agent_steps_trained: 1341500
  num_env_steps_sampled: 1358300
  num_env_steps_trained: 1341500
  num_samples_added_to_queue: 1358000
  num_training_step_calls_since_last_synch_worker_weights: 148
  num_weight_broadcasts: 26584
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 298.344
    learner_load_time_ms: 4.218
    learner_load_wait_time_ms: 2.663
iterations_since_restore: 178
node_ip: 127.0.0.1
num_agent_steps_sampled: 1358300
num_agent_steps_trained: 1341500
num_env_steps_sampled: 1358300
num_env_steps_sampled_this_iter: 8200
num_env_steps_sampled_throughput_per_sec: 819.9966373581499
num_env_steps_trained: 1341500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9967193738048
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 49.526666666666664
  ram_util_percent: 80.10000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10605394105960643
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03905021707921143
  mean_inference_ms: 1.990259973821778
  mean_raw_obs_processing_ms: 0.448141570157396
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03089118003845215
    StateBufferConnector_ms: 0.005667209625244141
    ViewRequirementAgentConnector_ms: 0.18709254264831543
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.26
  episode_reward_min: 1.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 6.0, 6.0, 1.0, 5.0, 2.0, 4.0, 5.0, 8.0, 2.0, 7.0, 2.0,
      3.0, 5.0, 3.0, 7.0, 5.0, 4.0, 2.0, 7.0, 7.0, 2.0, 6.0, 2.0, 4.0, 4.0, 5.0, 3.0,
      7.0, 7.0, 5.0, 6.0, 5.0, 8.0, 8.0, 3.0, 1.0, 3.0, 5.0, 7.0, 4.0, 4.0, 5.0, 3.0,
      1.0, 5.0, 3.0, 9.0, 4.0, 4.0, 3.0, 3.0, 4.0, 4.0, 1.0, 1.0, 3.0, 3.0, 4.0, 3.0,
      3.0, 5.0, 5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 6.0, 5.0, 7.0, 2.0, 4.0, 3.0, 4.0, 5.0,
      2.0, 5.0, 8.0, 3.0, 4.0, 4.0, 3.0, 4.0, 6.0, 8.0, 4.0, 4.0, 1.0, 8.0, 2.0, 4.0,
      4.0, 4.0, 3.0, 4.0, 6.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10605394105960643
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03905021707921143
    mean_inference_ms: 1.990259973821778
    mean_raw_obs_processing_ms: 0.448141570157396
time_since_restore: 1821.7724664211273
time_this_iter_s: 10.228348970413208
time_total_s: 1821.7724664211273
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1692343412
timesteps_total: 1358300
training_iteration: 178
trial_id: default
train step: 179
agent_timesteps_total: 1366450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03121161460876465
  StateBufferConnector_ms: 0.0057086944580078125
  ViewRequirementAgentConnector_ms: 0.1892385482788086
counters:
  num_agent_steps_sampled: 1366450
  num_agent_steps_trained: 1349500
  num_env_steps_sampled: 1366450
  num_env_steps_trained: 1349500
  num_samples_added_to_queue: 1366000
  num_training_step_calls_since_last_synch_worker_weights: 847
  num_weight_broadcasts: 26744
custom_metrics: {}
date: 2023-08-18_16-23-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 8.0
episode_reward_mean: 4.44
episode_reward_min: 0.0
episodes_this_iter: 63
episodes_total: 10676
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7242206931114197
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 1.9432990550994873
        total_loss: 21.06324005126953
        var_gnorm: 63.3718147277832
        vf_explained_var: 0.2088913917541504
        vf_loss: 38.96410369873047
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2699.0
  learner_queue:
    size_count: 2704
    size_mean: 14.84
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6414627622946552
  num_agent_steps_sampled: 1366450
  num_agent_steps_trained: 1349500
  num_env_steps_sampled: 1366450
  num_env_steps_trained: 1349500
  num_samples_added_to_queue: 1366000
  num_training_step_calls_since_last_synch_worker_weights: 847
  num_weight_broadcasts: 26744
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 412.771
    learner_load_time_ms: 4.38
    learner_load_wait_time_ms: 3.457
iterations_since_restore: 179
node_ip: 127.0.0.1
num_agent_steps_sampled: 1366450
num_agent_steps_trained: 1349500
num_env_steps_sampled: 1366450
num_env_steps_sampled_this_iter: 8150
num_env_steps_sampled_throughput_per_sec: 814.9993393426529
num_env_steps_trained: 1349500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9993515019905
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 50.942857142857136
  ram_util_percent: 80.24285714285715
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10598592065752065
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03903710313169366
  mean_inference_ms: 1.9895460736839043
  mean_raw_obs_processing_ms: 0.4480477014172097
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03121161460876465
    StateBufferConnector_ms: 0.0057086944580078125
    ViewRequirementAgentConnector_ms: 0.1892385482788086
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 8.0
  episode_reward_mean: 4.44
  episode_reward_min: 0.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 4.0, 4.0, 4.0, 3.0, 4.0, 6.0, 5.0, 7.0, 2.0, 4.0, 3.0, 4.0,
      5.0, 2.0, 5.0, 8.0, 3.0, 4.0, 4.0, 3.0, 4.0, 6.0, 8.0, 4.0, 4.0, 1.0, 8.0, 2.0,
      4.0, 4.0, 4.0, 3.0, 4.0, 6.0, 3.0, 4.0, 7.0, 3.0, 0.0, 0.0, 8.0, 7.0, 6.0, 3.0,
      5.0, 4.0, 5.0, 7.0, 3.0, 4.0, 7.0, 5.0, 5.0, 2.0, 7.0, 6.0, 5.0, 8.0, 3.0, 3.0,
      5.0, 6.0, 5.0, 4.0, 3.0, 3.0, 5.0, 4.0, 4.0, 8.0, 2.0, 1.0, 3.0, 1.0, 4.0, 8.0,
      3.0, 6.0, 3.0, 4.0, 7.0, 7.0, 3.0, 6.0, 5.0, 5.0, 5.0, 3.0, 1.0, 8.0, 6.0, 4.0,
      1.0, 6.0, 6.0, 3.0, 4.0, 4.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10598592065752065
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03903710313169366
    mean_inference_ms: 1.9895460736839043
    mean_raw_obs_processing_ms: 0.4480477014172097
time_since_restore: 1832.0999517440796
time_this_iter_s: 10.32748532295227
time_total_s: 1832.0999517440796
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.088
timestamp: 1692343422
timesteps_total: 1366450
training_iteration: 179
trial_id: default
train step: 180
agent_timesteps_total: 1373350
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03465843200683594
  StateBufferConnector_ms: 0.0061969757080078125
  ViewRequirementAgentConnector_ms: 0.2077953815460205
counters:
  num_agent_steps_sampled: 1373350
  num_agent_steps_trained: 1356500
  num_env_steps_sampled: 1373350
  num_env_steps_trained: 1356500
  num_samples_added_to_queue: 1373000
  num_training_step_calls_since_last_synch_worker_weights: 960
  num_weight_broadcasts: 26879
custom_metrics: {}
date: 2023-08-18_16-23-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.49
episode_reward_min: 1.0
episodes_this_iter: 54
episodes_total: 10730
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6953780055046082
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -11.34012508392334
        total_loss: 1.6002928018569946
        var_gnorm: 63.37220764160156
        vf_explained_var: 0.2581043243408203
        vf_loss: 26.576213836669922
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2713.0
  learner_queue:
    size_count: 2717
    size_mean: 14.68
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6302147097851865
  num_agent_steps_sampled: 1373350
  num_agent_steps_trained: 1356500
  num_env_steps_sampled: 1373350
  num_env_steps_trained: 1356500
  num_samples_added_to_queue: 1373000
  num_training_step_calls_since_last_synch_worker_weights: 960
  num_weight_broadcasts: 26879
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 489.824
    learner_load_time_ms: 4.38
    learner_load_wait_time_ms: 2.897
iterations_since_restore: 180
node_ip: 127.0.0.1
num_agent_steps_sampled: 1373350
num_agent_steps_trained: 1356500
num_env_steps_sampled: 1373350
num_env_steps_sampled_this_iter: 6900
num_env_steps_sampled_throughput_per_sec: 689.9936006662689
num_env_steps_trained: 1356500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9935079223018
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 63.220000000000006
  ram_util_percent: 81.95333333333333
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10585448641760026
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03908356340933096
  mean_inference_ms: 1.9900177658167342
  mean_raw_obs_processing_ms: 0.4485359867556724
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03465843200683594
    StateBufferConnector_ms: 0.0061969757080078125
    ViewRequirementAgentConnector_ms: 0.2077953815460205
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.49
  episode_reward_min: 1.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [2.0, 7.0, 6.0, 5.0, 8.0, 3.0, 3.0, 5.0, 6.0, 5.0, 4.0, 3.0, 3.0,
      5.0, 4.0, 4.0, 8.0, 2.0, 1.0, 3.0, 1.0, 4.0, 8.0, 3.0, 6.0, 3.0, 4.0, 7.0, 7.0,
      3.0, 6.0, 5.0, 5.0, 5.0, 3.0, 1.0, 8.0, 6.0, 4.0, 1.0, 6.0, 6.0, 3.0, 4.0, 4.0,
      7.0, 6.0, 3.0, 5.0, 3.0, 1.0, 6.0, 5.0, 3.0, 5.0, 6.0, 7.0, 2.0, 5.0, 2.0, 4.0,
      6.0, 5.0, 4.0, 3.0, 4.0, 5.0, 6.0, 3.0, 9.0, 4.0, 4.0, 3.0, 3.0, 6.0, 4.0, 2.0,
      5.0, 6.0, 3.0, 3.0, 6.0, 3.0, 3.0, 4.0, 2.0, 3.0, 6.0, 4.0, 5.0, 9.0, 6.0, 8.0,
      6.0, 7.0, 6.0, 4.0, 2.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10585448641760026
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03908356340933096
    mean_inference_ms: 1.9900177658167342
    mean_raw_obs_processing_ms: 0.4485359867556724
time_since_restore: 1842.2981898784637
time_this_iter_s: 10.198238134384155
time_total_s: 1842.2981898784637
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.09
timestamp: 1692343432
timesteps_total: 1373350
training_iteration: 180
trial_id: default
train step: 181
agent_timesteps_total: 1381450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033954620361328125
  StateBufferConnector_ms: 0.00616002082824707
  ViewRequirementAgentConnector_ms: 0.20264196395874023
counters:
  num_agent_steps_sampled: 1381450
  num_agent_steps_trained: 1364500
  num_env_steps_sampled: 1381450
  num_env_steps_trained: 1364500
  num_samples_added_to_queue: 1381000
  num_training_step_calls_since_last_synch_worker_weights: 13
  num_weight_broadcasts: 27038
custom_metrics: {}
date: 2023-08-18_16-24-03
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.24
episode_reward_min: 1.0
episodes_this_iter: 63
episodes_total: 10793
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7017745971679688
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 8.971794128417969
        total_loss: 28.722288131713867
        var_gnorm: 63.37260437011719
        vf_explained_var: 0.2509979009628296
        vf_loss: 40.202762603759766
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2729.0
  learner_queue:
    size_count: 2736
    size_mean: 14.66
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7619307591389624
  num_agent_steps_sampled: 1381450
  num_agent_steps_trained: 1364500
  num_env_steps_sampled: 1381450
  num_env_steps_trained: 1364500
  num_samples_added_to_queue: 1381000
  num_training_step_calls_since_last_synch_worker_weights: 13
  num_weight_broadcasts: 27038
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 255.511
    learner_load_time_ms: 4.907
    learner_load_wait_time_ms: 2.754
iterations_since_restore: 181
node_ip: 127.0.0.1
num_agent_steps_sampled: 1381450
num_agent_steps_trained: 1364500
num_env_steps_sampled: 1381450
num_env_steps_sampled_this_iter: 8100
num_env_steps_sampled_throughput_per_sec: 809.9933567591971
num_env_steps_trained: 1364500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9934387745157
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 55.442857142857136
  ram_util_percent: 82.25
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10583446898422924
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03909141753646638
  mean_inference_ms: 1.9901398951133376
  mean_raw_obs_processing_ms: 0.4486337638039795
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033954620361328125
    StateBufferConnector_ms: 0.00616002082824707
    ViewRequirementAgentConnector_ms: 0.20264196395874023
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.24
  episode_reward_min: 1.0
  episodes_this_iter: 63
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 4.0, 5.0, 6.0, 3.0, 9.0, 4.0, 4.0, 3.0, 3.0, 6.0, 4.0,
      2.0, 5.0, 6.0, 3.0, 3.0, 6.0, 3.0, 3.0, 4.0, 2.0, 3.0, 6.0, 4.0, 5.0, 9.0, 6.0,
      8.0, 6.0, 7.0, 6.0, 4.0, 2.0, 4.0, 3.0, 5.0, 3.0, 5.0, 3.0, 5.0, 3.0, 7.0, 2.0,
      1.0, 2.0, 3.0, 5.0, 6.0, 7.0, 3.0, 2.0, 3.0, 3.0, 6.0, 4.0, 3.0, 1.0, 7.0, 4.0,
      5.0, 12.0, 2.0, 3.0, 1.0, 1.0, 4.0, 4.0, 2.0, 6.0, 6.0, 1.0, 5.0, 5.0, 4.0,
      4.0, 5.0, 2.0, 4.0, 4.0, 5.0, 3.0, 7.0, 7.0, 3.0, 4.0, 3.0, 5.0, 4.0, 6.0, 3.0,
      3.0, 2.0, 4.0, 4.0, 6.0, 4.0, 6.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10583446898422924
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03909141753646638
    mean_inference_ms: 1.9901398951133376
    mean_raw_obs_processing_ms: 0.4486337638039795
time_since_restore: 1852.5980157852173
time_this_iter_s: 10.29982590675354
time_total_s: 1852.5980157852173
timers:
  sample_time_ms: 0.033
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.093
timestamp: 1692343443
timesteps_total: 1381450
training_iteration: 181
trial_id: default
train step: 182
agent_timesteps_total: 1389100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.032955169677734375
  StateBufferConnector_ms: 0.005980253219604492
  ViewRequirementAgentConnector_ms: 0.19661903381347656
counters:
  num_agent_steps_sampled: 1389100
  num_agent_steps_trained: 1372500
  num_env_steps_sampled: 1389100
  num_env_steps_trained: 1372500
  num_samples_added_to_queue: 1389000
  num_training_step_calls_since_last_synch_worker_weights: 351
  num_weight_broadcasts: 27188
custom_metrics: {}
date: 2023-08-18_16-24-13
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.3
episode_reward_min: 1.0
episodes_this_iter: 60
episodes_total: 10853
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6988813281059265
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 24.864574432373047
        total_loss: 44.404823303222656
        var_gnorm: 63.37296676635742
        vf_explained_var: 0.32265907526016235
        vf_loss: 39.77938461303711
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2745.0
  learner_queue:
    size_count: 2751
    size_mean: 14.62
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7537388631150306
  num_agent_steps_sampled: 1389100
  num_agent_steps_trained: 1372500
  num_env_steps_sampled: 1389100
  num_env_steps_trained: 1372500
  num_samples_added_to_queue: 1389000
  num_training_step_calls_since_last_synch_worker_weights: 351
  num_weight_broadcasts: 27188
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 296.281
    learner_load_time_ms: 4.907
    learner_load_wait_time_ms: 2.571
iterations_since_restore: 182
node_ip: 127.0.0.1
num_agent_steps_sampled: 1389100
num_agent_steps_trained: 1372500
num_env_steps_sampled: 1389100
num_env_steps_sampled_this_iter: 7650
num_env_steps_sampled_throughput_per_sec: 764.9971547232595
num_env_steps_trained: 1372500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9970245471995
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 55.313333333333325
  ram_util_percent: 82.40666666666667
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10589143455365183
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03906441535247528
  mean_inference_ms: 1.9898089905516059
  mean_raw_obs_processing_ms: 0.44836062308822633
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.032955169677734375
    StateBufferConnector_ms: 0.005980253219604492
    ViewRequirementAgentConnector_ms: 0.19661903381347656
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.3
  episode_reward_min: 1.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 12.0, 2.0, 3.0, 1.0, 1.0, 4.0, 4.0, 2.0, 6.0, 6.0,
      1.0, 5.0, 5.0, 4.0, 4.0, 5.0, 2.0, 4.0, 4.0, 5.0, 3.0, 7.0, 7.0, 3.0, 4.0, 3.0,
      5.0, 4.0, 6.0, 3.0, 3.0, 2.0, 4.0, 4.0, 6.0, 4.0, 6.0, 4.0, 7.0, 7.0, 2.0, 4.0,
      7.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 6.0, 4.0, 4.0, 8.0, 8.0, 9.0, 3.0, 2.0, 3.0,
      2.0, 6.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 5.0, 5.0, 5.0, 5.0, 9.0,
      8.0, 5.0, 2.0, 4.0, 5.0, 2.0, 4.0, 2.0, 6.0, 5.0, 4.0, 4.0, 6.0, 6.0, 6.0, 4.0,
      4.0, 4.0, 1.0, 2.0, 5.0, 3.0, 5.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10589143455365183
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03906441535247528
    mean_inference_ms: 1.9898089905516059
    mean_raw_obs_processing_ms: 0.44836062308822633
time_since_restore: 1862.817412853241
time_this_iter_s: 10.219397068023682
time_total_s: 1862.817412853241
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692343453
timesteps_total: 1389100
training_iteration: 182
trial_id: default
train step: 183
agent_timesteps_total: 1397400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.031410932540893555
  StateBufferConnector_ms: 0.005688190460205078
  ViewRequirementAgentConnector_ms: 0.1891930103302002
counters:
  num_agent_steps_sampled: 1397400
  num_agent_steps_trained: 1380500
  num_env_steps_sampled: 1397400
  num_env_steps_trained: 1380500
  num_samples_added_to_queue: 1397000
  num_training_step_calls_since_last_synch_worker_weights: 902
  num_weight_broadcasts: 27351
custom_metrics: {}
date: 2023-08-18_16-24-23
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.09
episode_reward_min: 1.0
episodes_this_iter: 65
episodes_total: 10918
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7021900415420532
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -19.340063095092773
        total_loss: -0.24515900015830994
        var_gnorm: 63.373348236083984
        vf_explained_var: 0.1691988706588745
        vf_loss: 38.891998291015625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2761.0
  learner_queue:
    size_count: 2765
    size_mean: 14.64
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7636326148038883
  num_agent_steps_sampled: 1397400
  num_agent_steps_trained: 1380500
  num_env_steps_sampled: 1397400
  num_env_steps_trained: 1380500
  num_samples_added_to_queue: 1397000
  num_training_step_calls_since_last_synch_worker_weights: 902
  num_weight_broadcasts: 27351
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 434.722
    learner_load_time_ms: 5.324
    learner_load_wait_time_ms: 2.655
iterations_since_restore: 183
node_ip: 127.0.0.1
num_agent_steps_sampled: 1397400
num_agent_steps_trained: 1380500
num_env_steps_sampled: 1397400
num_env_steps_sampled_this_iter: 8300
num_env_steps_sampled_throughput_per_sec: 829.9970119107056
num_env_steps_trained: 1380500
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9971199139331
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 45.46428571428571
  ram_util_percent: 81.79285714285713
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10590315340584079
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03903359812838483
  mean_inference_ms: 1.9890779371778116
  mean_raw_obs_processing_ms: 0.44806002673797096
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.031410932540893555
    StateBufferConnector_ms: 0.005688190460205078
    ViewRequirementAgentConnector_ms: 0.1891930103302002
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.09
  episode_reward_min: 1.0
  episodes_this_iter: 65
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 3.0, 4.0, 2.0, 4.0, 5.0, 5.0, 5.0, 5.0, 9.0, 8.0, 5.0,
      2.0, 4.0, 5.0, 2.0, 4.0, 2.0, 6.0, 5.0, 4.0, 4.0, 6.0, 6.0, 6.0, 4.0, 4.0, 4.0,
      1.0, 2.0, 5.0, 3.0, 5.0, 4.0, 6.0, 1.0, 8.0, 2.0, 4.0, 2.0, 4.0, 2.0, 3.0, 3.0,
      2.0, 2.0, 4.0, 5.0, 5.0, 7.0, 4.0, 4.0, 7.0, 4.0, 4.0, 4.0, 6.0, 3.0, 5.0, 5.0,
      4.0, 6.0, 2.0, 4.0, 7.0, 3.0, 7.0, 5.0, 3.0, 4.0, 7.0, 4.0, 6.0, 3.0, 3.0, 3.0,
      4.0, 3.0, 4.0, 3.0, 6.0, 2.0, 2.0, 5.0, 5.0, 4.0, 1.0, 3.0, 2.0, 3.0, 3.0, 6.0,
      6.0, 2.0, 4.0, 4.0, 7.0, 2.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10590315340584079
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03903359812838483
    mean_inference_ms: 1.9890779371778116
    mean_raw_obs_processing_ms: 0.44806002673797096
time_since_restore: 1872.9872736930847
time_this_iter_s: 10.16986083984375
time_total_s: 1872.9872736930847
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1692343463
timesteps_total: 1397400
training_iteration: 183
trial_id: default
train step: 184
agent_timesteps_total: 1404600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033878326416015625
  StateBufferConnector_ms: 0.00625157356262207
  ViewRequirementAgentConnector_ms: 0.20000410079956055
counters:
  num_agent_steps_sampled: 1404600
  num_agent_steps_trained: 1388000
  num_env_steps_sampled: 1404600
  num_env_steps_trained: 1388000
  num_samples_added_to_queue: 1404500
  num_training_step_calls_since_last_synch_worker_weights: 67
  num_weight_broadcasts: 27492
custom_metrics: {}
date: 2023-08-18_16-24-33
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.31
episode_reward_min: 1.0
episodes_this_iter: 56
episodes_total: 10974
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7088980078697205
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -41.838623046875
        total_loss: -31.132951736450195
        var_gnorm: 63.373905181884766
        vf_explained_var: 0.1750643253326416
        vf_loss: 22.120237350463867
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2776.0
  learner_queue:
    size_count: 2782
    size_mean: 14.5
    size_quantiles: [10.0, 11.9, 16.0, 16.0, 16.0]
    size_std: 1.857417562100671
  num_agent_steps_sampled: 1404600
  num_agent_steps_trained: 1388000
  num_env_steps_sampled: 1404600
  num_env_steps_trained: 1388000
  num_samples_added_to_queue: 1404500
  num_training_step_calls_since_last_synch_worker_weights: 67
  num_weight_broadcasts: 27492
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 304.516
    learner_load_time_ms: 6.07
    learner_load_wait_time_ms: 2.775
iterations_since_restore: 184
node_ip: 127.0.0.1
num_agent_steps_sampled: 1404600
num_agent_steps_trained: 1388000
num_env_steps_sampled: 1404600
num_env_steps_sampled_this_iter: 7200
num_env_steps_sampled_throughput_per_sec: 719.9940262336462
num_env_steps_trained: 1388000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9937773267147
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 58.94285714285714
  ram_util_percent: 81.77142857142857
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10585491912174957
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039046249935584386
  mean_inference_ms: 1.9891421264393723
  mean_raw_obs_processing_ms: 0.44818944160414614
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033878326416015625
    StateBufferConnector_ms: 0.00625157356262207
    ViewRequirementAgentConnector_ms: 0.20000410079956055
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.31
  episode_reward_min: 1.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 6.0, 3.0, 5.0, 5.0, 4.0, 6.0, 2.0, 4.0, 7.0, 3.0, 7.0, 5.0,
      3.0, 4.0, 7.0, 4.0, 6.0, 3.0, 3.0, 3.0, 4.0, 3.0, 4.0, 3.0, 6.0, 2.0, 2.0, 5.0,
      5.0, 4.0, 1.0, 3.0, 2.0, 3.0, 3.0, 6.0, 6.0, 2.0, 4.0, 4.0, 7.0, 2.0, 2.0, 3.0,
      2.0, 4.0, 4.0, 3.0, 4.0, 9.0, 5.0, 3.0, 7.0, 4.0, 5.0, 5.0, 6.0, 7.0, 2.0, 6.0,
      4.0, 6.0, 8.0, 2.0, 2.0, 4.0, 5.0, 3.0, 6.0, 1.0, 8.0, 3.0, 3.0, 5.0, 3.0, 3.0,
      3.0, 4.0, 5.0, 6.0, 7.0, 2.0, 3.0, 3.0, 8.0, 6.0, 5.0, 1.0, 4.0, 6.0, 6.0, 5.0,
      6.0, 5.0, 5.0, 4.0, 2.0, 5.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10585491912174957
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039046249935584386
    mean_inference_ms: 1.9891421264393723
    mean_raw_obs_processing_ms: 0.44818944160414614
time_since_restore: 1883.2513649463654
time_this_iter_s: 10.26409125328064
time_total_s: 1883.2513649463654
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.075
timestamp: 1692343473
timesteps_total: 1404600
training_iteration: 184
trial_id: default
train step: 185
agent_timesteps_total: 1412100
connector_metrics:
  ObsPreprocessorConnector_ms: 0.034667015075683594
  StateBufferConnector_ms: 0.00622105598449707
  ViewRequirementAgentConnector_ms: 0.2065601348876953
counters:
  num_agent_steps_sampled: 1412100
  num_agent_steps_trained: 1395500
  num_env_steps_sampled: 1412100
  num_env_steps_trained: 1395500
  num_samples_added_to_queue: 1412000
  num_training_step_calls_since_last_synch_worker_weights: 583
  num_weight_broadcasts: 27639
custom_metrics: {}
date: 2023-08-18_16-24-44
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.35
episode_reward_min: 1.0
episodes_this_iter: 58
episodes_total: 11032
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6785624623298645
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -2.5236213207244873
        total_loss: 9.433724403381348
        var_gnorm: 63.3743782043457
        vf_explained_var: 0.25152063369750977
        vf_loss: 24.59325408935547
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2791.0
  learner_queue:
    size_count: 2796
    size_mean: 14.6
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7435595774162693
  num_agent_steps_sampled: 1412100
  num_agent_steps_trained: 1395500
  num_env_steps_sampled: 1412100
  num_env_steps_trained: 1395500
  num_samples_added_to_queue: 1412000
  num_training_step_calls_since_last_synch_worker_weights: 583
  num_weight_broadcasts: 27639
  timing_breakdown:
    learner_dequeue_time_ms: 0.006
    learner_grad_time_ms: 421.438
    learner_load_time_ms: 4.796
    learner_load_wait_time_ms: 2.884
iterations_since_restore: 185
node_ip: 127.0.0.1
num_agent_steps_sampled: 1412100
num_agent_steps_trained: 1395500
num_env_steps_sampled: 1412100
num_env_steps_sampled_this_iter: 7500
num_env_steps_sampled_throughput_per_sec: 749.9983549154126
num_env_steps_trained: 1395500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9983549154126
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 56.606666666666655
  ram_util_percent: 81.03999999999999
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10578010144581677
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03908239308811045
  mean_inference_ms: 1.9896550243200226
  mean_raw_obs_processing_ms: 0.44855381822580975
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.034667015075683594
    StateBufferConnector_ms: 0.00622105598449707
    ViewRequirementAgentConnector_ms: 0.2065601348876953
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.35
  episode_reward_min: 1.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 2.0, 6.0, 4.0, 6.0, 8.0, 2.0, 2.0, 4.0, 5.0, 3.0, 6.0, 1.0,
      8.0, 3.0, 3.0, 5.0, 3.0, 3.0, 3.0, 4.0, 5.0, 6.0, 7.0, 2.0, 3.0, 3.0, 8.0, 6.0,
      5.0, 1.0, 4.0, 6.0, 6.0, 5.0, 6.0, 5.0, 5.0, 4.0, 2.0, 5.0, 8.0, 6.0, 4.0, 1.0,
      3.0, 5.0, 4.0, 3.0, 5.0, 4.0, 1.0, 11.0, 3.0, 5.0, 4.0, 3.0, 4.0, 4.0, 9.0,
      5.0, 2.0, 5.0, 3.0, 1.0, 4.0, 5.0, 6.0, 6.0, 6.0, 1.0, 4.0, 6.0, 6.0, 3.0, 4.0,
      5.0, 7.0, 5.0, 5.0, 6.0, 6.0, 3.0, 3.0, 1.0, 5.0, 3.0, 3.0, 2.0, 5.0, 7.0, 3.0,
      6.0, 4.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10578010144581677
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03908239308811045
    mean_inference_ms: 1.9896550243200226
    mean_raw_obs_processing_ms: 0.44855381822580975
time_since_restore: 1893.4967477321625
time_this_iter_s: 10.24538278579712
time_total_s: 1893.4967477321625
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692343484
timesteps_total: 1412100
training_iteration: 185
trial_id: default
train step: 186
agent_timesteps_total: 1419700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03367137908935547
  StateBufferConnector_ms: 0.006059408187866211
  ViewRequirementAgentConnector_ms: 0.20465993881225586
counters:
  num_agent_steps_sampled: 1419700
  num_agent_steps_trained: 1403000
  num_env_steps_sampled: 1419700
  num_env_steps_trained: 1403000
  num_samples_added_to_queue: 1419500
  num_training_step_calls_since_last_synch_worker_weights: 929
  num_weight_broadcasts: 27788
custom_metrics: {}
date: 2023-08-18_16-24-54
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.25
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 11092
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6701245307922363
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 0.03470039367675781
        total_loss: 20.07122039794922
        var_gnorm: 63.37468338012695
        vf_explained_var: 0.22063803672790527
        vf_loss: 40.7431640625
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2806.0
  learner_queue:
    size_count: 2810
    size_mean: 14.72
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6857046004564382
  num_agent_steps_sampled: 1419700
  num_agent_steps_trained: 1403000
  num_env_steps_sampled: 1419700
  num_env_steps_trained: 1403000
  num_samples_added_to_queue: 1419500
  num_training_step_calls_since_last_synch_worker_weights: 929
  num_weight_broadcasts: 27788
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 414.44
    learner_load_time_ms: 4.8
    learner_load_wait_time_ms: 2.913
iterations_since_restore: 186
node_ip: 127.0.0.1
num_agent_steps_sampled: 1419700
num_agent_steps_trained: 1403000
num_env_steps_sampled: 1419700
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9942923020822
num_env_steps_trained: 1403000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9943674033706
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.82857142857142
  ram_util_percent: 79.74999999999999
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10583079039864464
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03907142684863068
  mean_inference_ms: 1.9896944294311532
  mean_raw_obs_processing_ms: 0.4484362968516937
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03367137908935547
    StateBufferConnector_ms: 0.006059408187866211
    ViewRequirementAgentConnector_ms: 0.20465993881225586
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.25
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 2.0, 5.0, 3.0, 1.0, 4.0, 5.0, 6.0, 6.0, 6.0, 1.0, 4.0, 6.0,
      6.0, 3.0, 4.0, 5.0, 7.0, 5.0, 5.0, 6.0, 6.0, 3.0, 3.0, 1.0, 5.0, 3.0, 3.0, 2.0,
      5.0, 7.0, 3.0, 6.0, 4.0, 3.0, 4.0, 4.0, 3.0, 3.0, 3.0, 6.0, 8.0, 3.0, 1.0, 6.0,
      2.0, 4.0, 5.0, 1.0, 7.0, 5.0, 7.0, 6.0, 5.0, 4.0, 4.0, 4.0, 3.0, 6.0, 9.0, 3.0,
      3.0, 2.0, 4.0, 6.0, 2.0, 4.0, 6.0, 4.0, 7.0, 4.0, 6.0, 4.0, 5.0, 5.0, 5.0, 3.0,
      3.0, 3.0, 2.0, 5.0, 5.0, 3.0, 2.0, 8.0, 3.0, 1.0, 3.0, 6.0, 4.0, 4.0, 5.0, 0.0,
      5.0, 5.0, 8.0, 5.0, 3.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10583079039864464
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03907142684863068
    mean_inference_ms: 1.9896944294311532
    mean_raw_obs_processing_ms: 0.4484362968516937
time_since_restore: 1903.6746566295624
time_this_iter_s: 10.177908897399902
time_total_s: 1903.6746566295624
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692343494
timesteps_total: 1419700
training_iteration: 186
trial_id: default
train step: 187
agent_timesteps_total: 1427050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03427910804748535
  StateBufferConnector_ms: 0.006271839141845703
  ViewRequirementAgentConnector_ms: 0.20813608169555664
counters:
  num_agent_steps_sampled: 1427050
  num_agent_steps_trained: 1410500
  num_env_steps_sampled: 1427050
  num_env_steps_trained: 1410500
  num_samples_added_to_queue: 1427000
  num_training_step_calls_since_last_synch_worker_weights: 354
  num_weight_broadcasts: 27932
custom_metrics: {}
date: 2023-08-18_16-25-04
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.77
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 11150
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6961934566497803
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -25.125221252441406
        total_loss: -7.312704086303711
        var_gnorm: 63.37505340576172
        vf_explained_var: 0.1278037428855896
        vf_loss: 36.32122802734375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2821.0
  learner_queue:
    size_count: 2826
    size_mean: 14.64
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.7176728442867113
  num_agent_steps_sampled: 1427050
  num_agent_steps_trained: 1410500
  num_env_steps_sampled: 1427050
  num_env_steps_trained: 1410500
  num_samples_added_to_queue: 1427000
  num_training_step_calls_since_last_synch_worker_weights: 354
  num_weight_broadcasts: 27932
  timing_breakdown:
    learner_dequeue_time_ms: 0.007
    learner_grad_time_ms: 408.846
    learner_load_time_ms: 4.852
    learner_load_wait_time_ms: 3.81
iterations_since_restore: 187
node_ip: 127.0.0.1
num_agent_steps_sampled: 1427050
num_agent_steps_trained: 1410500
num_env_steps_sampled: 1427050
num_env_steps_sampled_this_iter: 7350
num_env_steps_sampled_throughput_per_sec: 734.9940419680055
num_env_steps_trained: 1410500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9939203755157
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 60.48666666666666
  ram_util_percent: 78.87333333333332
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10584122643018748
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03907828644617708
  mean_inference_ms: 1.9899396084866083
  mean_raw_obs_processing_ms: 0.44850507153966696
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03427910804748535
    StateBufferConnector_ms: 0.006271839141845703
    ViewRequirementAgentConnector_ms: 0.20813608169555664
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.77
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 9.0, 3.0, 3.0, 2.0, 4.0, 6.0, 2.0, 4.0, 6.0, 4.0, 7.0, 4.0,
      6.0, 4.0, 5.0, 5.0, 5.0, 3.0, 3.0, 3.0, 2.0, 5.0, 5.0, 3.0, 2.0, 8.0, 3.0, 1.0,
      3.0, 6.0, 4.0, 4.0, 5.0, 0.0, 5.0, 5.0, 8.0, 5.0, 3.0, 4.0, 3.0, 6.0, 3.0, 3.0,
      5.0, 0.0, 4.0, 5.0, 8.0, 4.0, 8.0, 7.0, 4.0, 5.0, 6.0, 5.0, 9.0, 6.0, 4.0, 3.0,
      5.0, 2.0, 2.0, 3.0, 5.0, 7.0, 3.0, 2.0, 5.0, 6.0, 3.0, 4.0, 5.0, 8.0, 5.0, 6.0,
      7.0, 7.0, 8.0, 5.0, 6.0, 7.0, 4.0, 8.0, 4.0, 7.0, 5.0, 9.0, 6.0, 2.0, 6.0, 4.0,
      7.0, 9.0, 1.0, 5.0, 5.0, 5.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10584122643018748
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03907828644617708
    mean_inference_ms: 1.9899396084866083
    mean_raw_obs_processing_ms: 0.44850507153966696
time_since_restore: 1914.0203757286072
time_this_iter_s: 10.3457190990448
time_total_s: 1914.0203757286072
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.085
timestamp: 1692343504
timesteps_total: 1427050
training_iteration: 187
trial_id: default
train step: 188
agent_timesteps_total: 1434150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03612542152404785
  StateBufferConnector_ms: 0.00653386116027832
  ViewRequirementAgentConnector_ms: 0.21600794792175293
counters:
  num_agent_steps_sampled: 1434150
  num_agent_steps_trained: 1417500
  num_env_steps_sampled: 1434150
  num_env_steps_trained: 1417500
  num_samples_added_to_queue: 1434000
  num_training_step_calls_since_last_synch_worker_weights: 613
  num_weight_broadcasts: 28071
custom_metrics: {}
date: 2023-08-18_16-25-14
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.53
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 11204
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.7011675238609314
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 3.375030994415283
        total_loss: 25.49888038635254
        var_gnorm: 63.37538146972656
        vf_explained_var: 0.25031715631484985
        vf_loss: 44.94886779785156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2835.0
  learner_queue:
    size_count: 2840
    size_mean: 14.76
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5944905142395798
  num_agent_steps_sampled: 1434150
  num_agent_steps_trained: 1417500
  num_env_steps_sampled: 1434150
  num_env_steps_trained: 1417500
  num_samples_added_to_queue: 1434000
  num_training_step_calls_since_last_synch_worker_weights: 613
  num_weight_broadcasts: 28071
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 408.341
    learner_load_time_ms: 4.854
    learner_load_wait_time_ms: 2.678
iterations_since_restore: 188
node_ip: 127.0.0.1
num_agent_steps_sampled: 1434150
num_agent_steps_trained: 1417500
num_env_steps_sampled: 1434150
num_env_steps_sampled_this_iter: 7100
num_env_steps_sampled_throughput_per_sec: 709.9953787627601
num_env_steps_trained: 1417500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9954438506086
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 56.699999999999996
  ram_util_percent: 78.06428571428572
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1058071192870378
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03911141350072315
  mean_inference_ms: 1.9905758532269653
  mean_raw_obs_processing_ms: 0.44883489619343786
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03612542152404785
    StateBufferConnector_ms: 0.00653386116027832
    ViewRequirementAgentConnector_ms: 0.21600794792175293
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.53
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 6.0, 5.0, 9.0, 6.0, 4.0, 3.0, 5.0, 2.0, 2.0, 3.0, 5.0, 7.0,
      3.0, 2.0, 5.0, 6.0, 3.0, 4.0, 5.0, 8.0, 5.0, 6.0, 7.0, 7.0, 8.0, 5.0, 6.0, 7.0,
      4.0, 8.0, 4.0, 7.0, 5.0, 9.0, 6.0, 2.0, 6.0, 4.0, 7.0, 9.0, 1.0, 5.0, 5.0, 5.0,
      6.0, 5.0, 2.0, 5.0, 7.0, 1.0, 3.0, 6.0, 5.0, 4.0, 0.0, 4.0, 4.0, 5.0, 6.0, 3.0,
      5.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 0.0, 2.0, 8.0, 4.0, 3.0, 5.0, 2.0, 5.0, 1.0,
      9.0, 6.0, 5.0, 6.0, 5.0, 2.0, 4.0, 7.0, 5.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 1.0,
      2.0, 3.0, 4.0, 2.0, 4.0, 7.0, 2.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1058071192870378
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03911141350072315
    mean_inference_ms: 1.9905758532269653
    mean_raw_obs_processing_ms: 0.44883489619343786
time_since_restore: 1924.2226116657257
time_this_iter_s: 10.20223593711853
time_total_s: 1924.2226116657257
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.088
timestamp: 1692343514
timesteps_total: 1434150
training_iteration: 188
trial_id: default
train step: 189
agent_timesteps_total: 1441300
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03661608695983887
  StateBufferConnector_ms: 0.006621599197387695
  ViewRequirementAgentConnector_ms: 0.2233288288116455
counters:
  num_agent_steps_sampled: 1441300
  num_agent_steps_trained: 1424500
  num_env_steps_sampled: 1441300
  num_env_steps_trained: 1424500
  num_samples_added_to_queue: 1441000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 28211
custom_metrics: {}
date: 2023-08-18_16-25-25
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 3.8
episode_reward_min: 0.0
episodes_this_iter: 56
episodes_total: 11260
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6665135025978088
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -2.543379306793213
        total_loss: 19.806154251098633
        var_gnorm: 63.37580490112305
        vf_explained_var: 0.2802918553352356
        vf_loss: 45.36558151245117
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2849.0
  learner_queue:
    size_count: 2855
    size_mean: 14.72
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6252999723128034
  num_agent_steps_sampled: 1441300
  num_agent_steps_trained: 1424500
  num_env_steps_sampled: 1441300
  num_env_steps_trained: 1424500
  num_samples_added_to_queue: 1441000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 28211
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 404.765
    learner_load_time_ms: 4.86
    learner_load_wait_time_ms: 3.019
iterations_since_restore: 189
node_ip: 127.0.0.1
num_agent_steps_sampled: 1441300
num_agent_steps_trained: 1424500
num_env_steps_sampled: 1441300
num_env_steps_sampled_this_iter: 7150
num_env_steps_sampled_throughput_per_sec: 714.9458119216895
num_env_steps_trained: 1424500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9469487345212
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 53.65333333333332
  ram_util_percent: 78.42000000000002
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10582898000476014
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039133588908785794
  mean_inference_ms: 1.9913644608178749
  mean_raw_obs_processing_ms: 0.44905679106016017
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03661608695983887
    StateBufferConnector_ms: 0.006621599197387695
    ViewRequirementAgentConnector_ms: 0.2233288288116455
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 3.8
  episode_reward_min: 0.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 4.0, 5.0, 6.0, 3.0, 5.0, 1.0, 2.0, 2.0, 3.0, 3.0, 4.0, 0.0,
      2.0, 8.0, 4.0, 3.0, 5.0, 2.0, 5.0, 1.0, 9.0, 6.0, 5.0, 6.0, 5.0, 2.0, 4.0, 7.0,
      5.0, 4.0, 4.0, 6.0, 4.0, 5.0, 4.0, 1.0, 2.0, 3.0, 4.0, 2.0, 4.0, 7.0, 2.0, 5.0,
      2.0, 5.0, 5.0, 3.0, 3.0, 3.0, 3.0, 2.0, 3.0, 3.0, 5.0, 6.0, 2.0, 5.0, 4.0, 4.0,
      0.0, 3.0, 3.0, 2.0, 6.0, 5.0, 6.0, 4.0, 6.0, 2.0, 5.0, 3.0, 1.0, 3.0, 5.0, 2.0,
      2.0, 4.0, 4.0, 5.0, 3.0, 3.0, 3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 4.0, 5.0, 4.0, 6.0,
      4.0, 7.0, 3.0, 3.0, 8.0, 0.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10582898000476014
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039133588908785794
    mean_inference_ms: 1.9913644608178749
    mean_raw_obs_processing_ms: 0.44905679106016017
time_since_restore: 1934.5341596603394
time_this_iter_s: 10.311547994613647
time_total_s: 1934.5341596603394
timers:
  sample_time_ms: 0.119
  synch_weights_time_ms: 0.44
  training_iteration_time_ms: 0.682
timestamp: 1692343525
timesteps_total: 1441300
training_iteration: 189
trial_id: default
train step: 190
agent_timesteps_total: 1448050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03707313537597656
  StateBufferConnector_ms: 0.0067369937896728516
  ViewRequirementAgentConnector_ms: 0.22841668128967285
counters:
  num_agent_steps_sampled: 1448050
  num_agent_steps_trained: 1431500
  num_env_steps_sampled: 1448050
  num_env_steps_trained: 1431500
  num_samples_added_to_queue: 1448000
  num_training_step_calls_since_last_synch_worker_weights: 944
  num_weight_broadcasts: 28344
custom_metrics: {}
date: 2023-08-18_16-25-35
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.29
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 11314
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.90000000000009
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6581246852874756
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -21.353248596191406
        total_loss: -6.712368965148926
        var_gnorm: 63.37611389160156
        vf_explained_var: 0.20404142141342163
        vf_loss: 29.939884185791016
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2863.0
  learner_queue:
    size_count: 2868
    size_mean: 14.66
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6322989922192566
  num_agent_steps_sampled: 1448050
  num_agent_steps_trained: 1431500
  num_env_steps_sampled: 1448050
  num_env_steps_trained: 1431500
  num_samples_added_to_queue: 1448000
  num_training_step_calls_since_last_synch_worker_weights: 944
  num_weight_broadcasts: 28344
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 450.427
    learner_load_time_ms: 4.863
    learner_load_wait_time_ms: 3.103
iterations_since_restore: 190
node_ip: 127.0.0.1
num_agent_steps_sampled: 1448050
num_agent_steps_trained: 1431500
num_env_steps_sampled: 1448050
num_env_steps_sampled_this_iter: 6750
num_env_steps_sampled_throughput_per_sec: 674.9948180119658
num_env_steps_trained: 1431500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.994626086483
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 59.22142857142858
  ram_util_percent: 78.91428571428573
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10587859364956423
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039155212302059865
  mean_inference_ms: 1.9923302918741284
  mean_raw_obs_processing_ms: 0.4492648341721344
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03707313537597656
    StateBufferConnector_ms: 0.0067369937896728516
    ViewRequirementAgentConnector_ms: 0.22841668128967285
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.29
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 6.0, 2.0, 5.0, 4.0, 4.0, 0.0, 3.0, 3.0, 2.0, 6.0, 5.0,
      6.0, 4.0, 6.0, 2.0, 5.0, 3.0, 1.0, 3.0, 5.0, 2.0, 2.0, 4.0, 4.0, 5.0, 3.0, 3.0,
      3.0, 4.0, 2.0, 3.0, 4.0, 2.0, 4.0, 5.0, 4.0, 6.0, 4.0, 7.0, 3.0, 3.0, 8.0, 0.0,
      5.0, 2.0, 4.0, 5.0, 7.0, 1.0, 6.0, 5.0, 6.0, 7.0, 10.0, 7.0, 6.0, 5.0, 3.0,
      6.0, 9.0, 1.0, 7.0, 3.0, 3.0, 7.0, 5.0, 6.0, 7.0, 4.0, 3.0, 4.0, 1.0, 9.0, 6.0,
      6.0, 5.0, 8.0, 4.0, 4.0, 3.0, 7.0, 4.0, 3.0, 7.0, 5.0, 4.0, 4.0, 1.0, 4.0, 1.0,
      4.0, 2.0, 2.0, 3.0, 6.0, 6.0, 4.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10587859364956423
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039155212302059865
    mean_inference_ms: 1.9923302918741284
    mean_raw_obs_processing_ms: 0.4492648341721344
time_since_restore: 1944.7807505130768
time_this_iter_s: 10.246590852737427
time_total_s: 1944.7807505130768
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.09
timestamp: 1692343535
timesteps_total: 1448050
training_iteration: 190
trial_id: default
train step: 191
agent_timesteps_total: 1455150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03609967231750488
  StateBufferConnector_ms: 0.0065021514892578125
  ViewRequirementAgentConnector_ms: 0.21464920043945312
counters:
  num_agent_steps_sampled: 1455150
  num_agent_steps_trained: 1438500
  num_env_steps_sampled: 1455150
  num_env_steps_trained: 1438500
  num_samples_added_to_queue: 1455000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 28483
custom_metrics: {}
date: 2023-08-18_16-25-45
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.51
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 11368
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6553691029548645
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -13.750818252563477
        total_loss: -0.5738364458084106
        var_gnorm: 63.376251220703125
        vf_explained_var: 0.25413262844085693
        vf_loss: 27.00933265686035
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2877.0
  learner_queue:
    size_count: 2884
    size_mean: 14.56
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.722324011328879
  num_agent_steps_sampled: 1455150
  num_agent_steps_trained: 1438500
  num_env_steps_sampled: 1455150
  num_env_steps_trained: 1438500
  num_samples_added_to_queue: 1455000
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 28483
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 253.524
    learner_load_time_ms: 4.417
    learner_load_wait_time_ms: 2.782
iterations_since_restore: 191
node_ip: 127.0.0.1
num_agent_steps_sampled: 1455150
num_agent_steps_trained: 1438500
num_env_steps_sampled: 1455150
num_env_steps_sampled_this_iter: 7100
num_env_steps_sampled_throughput_per_sec: 709.6285801834877
num_env_steps_trained: 1438500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.633811448509
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 54.93333333333333
  ram_util_percent: 78.72666666666669
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10590478767550056
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03918626212372529
  mean_inference_ms: 1.9933308130421756
  mean_raw_obs_processing_ms: 0.44955331264868187
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03609967231750488
    StateBufferConnector_ms: 0.0065021514892578125
    ViewRequirementAgentConnector_ms: 0.21464920043945312
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.51
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 10.0, 7.0, 6.0, 5.0, 3.0, 6.0, 9.0, 1.0, 7.0, 3.0, 3.0,
      7.0, 5.0, 6.0, 7.0, 4.0, 3.0, 4.0, 1.0, 9.0, 6.0, 6.0, 5.0, 8.0, 4.0, 4.0, 3.0,
      7.0, 4.0, 3.0, 7.0, 5.0, 4.0, 4.0, 1.0, 4.0, 1.0, 4.0, 2.0, 2.0, 3.0, 6.0, 6.0,
      4.0, 4.0, 5.0, 4.0, 4.0, 1.0, 6.0, 3.0, 6.0, 5.0, 2.0, 2.0, 5.0, 6.0, 3.0, 3.0,
      4.0, 7.0, 6.0, 1.0, 6.0, 0.0, 4.0, 5.0, 5.0, 7.0, 4.0, 1.0, 7.0, 4.0, 9.0, 5.0,
      5.0, 3.0, 6.0, 1.0, 3.0, 9.0, 7.0, 5.0, 3.0, 1.0, 5.0, 2.0, 6.0, 5.0, 4.0, 5.0,
      3.0, 5.0, 4.0, 4.0, 4.0, 4.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10590478767550056
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03918626212372529
    mean_inference_ms: 1.9933308130421756
    mean_raw_obs_processing_ms: 0.44955331264868187
time_since_restore: 1955.1070425510406
time_this_iter_s: 10.326292037963867
time_total_s: 1955.1070425510406
timers:
  sample_time_ms: 0.198
  synch_weights_time_ms: 0.823
  training_iteration_time_ms: 1.258
timestamp: 1692343545
timesteps_total: 1455150
training_iteration: 191
trial_id: default
train step: 192
agent_timesteps_total: 1461500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03850245475769043
  StateBufferConnector_ms: 0.006897687911987305
  ViewRequirementAgentConnector_ms: 0.22450971603393555
counters:
  num_agent_steps_sampled: 1461500
  num_agent_steps_trained: 1445000
  num_env_steps_sampled: 1461500
  num_env_steps_trained: 1445000
  num_samples_added_to_queue: 1461500
  num_training_step_calls_since_last_synch_worker_weights: 618
  num_weight_broadcasts: 28607
custom_metrics: {}
date: 2023-08-18_16-25-56
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.57
episode_reward_min: 0.0
episodes_this_iter: 50
episodes_total: 11418
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6568472981452942
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 18.93913459777832
        total_loss: 36.05812454223633
        var_gnorm: 63.37644958496094
        vf_explained_var: 0.2764360308647156
        vf_loss: 34.89482498168945
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2890.0
  learner_queue:
    size_count: 2894
    size_mean: 14.56
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.7338973441354595
  num_agent_steps_sampled: 1461500
  num_agent_steps_trained: 1445000
  num_env_steps_sampled: 1461500
  num_env_steps_trained: 1445000
  num_samples_added_to_queue: 1461500
  num_training_step_calls_since_last_synch_worker_weights: 618
  num_weight_broadcasts: 28607
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 1012.546
    learner_load_time_ms: 4.417
    learner_load_wait_time_ms: 7.42
iterations_since_restore: 192
node_ip: 127.0.0.1
num_agent_steps_sampled: 1461500
num_agent_steps_trained: 1445000
num_env_steps_sampled: 1461500
num_env_steps_sampled_this_iter: 6350
num_env_steps_sampled_throughput_per_sec: 634.9932629584786
num_env_steps_trained: 1445000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9931038157654
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 58.22142857142858
  ram_util_percent: 78.4357142857143
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1059222960579487
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039233539108581794
  mean_inference_ms: 1.9946072075579309
  mean_raw_obs_processing_ms: 0.4499466448365324
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03850245475769043
    StateBufferConnector_ms: 0.006897687911987305
    ViewRequirementAgentConnector_ms: 0.22450971603393555
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.57
  episode_reward_min: 0.0
  episodes_this_iter: 50
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 3.0, 6.0, 5.0, 2.0, 2.0, 5.0, 6.0, 3.0, 3.0, 4.0, 7.0, 6.0,
      1.0, 6.0, 0.0, 4.0, 5.0, 5.0, 7.0, 4.0, 1.0, 7.0, 4.0, 9.0, 5.0, 5.0, 3.0, 6.0,
      1.0, 3.0, 9.0, 7.0, 5.0, 3.0, 1.0, 5.0, 2.0, 6.0, 5.0, 4.0, 5.0, 3.0, 5.0, 4.0,
      4.0, 4.0, 4.0, 4.0, 3.0, 3.0, 5.0, 9.0, 7.0, 5.0, 2.0, 4.0, 4.0, 3.0, 6.0, 4.0,
      10.0, 5.0, 2.0, 9.0, 2.0, 3.0, 2.0, 8.0, 5.0, 4.0, 5.0, 4.0, 5.0, 4.0, 12.0,
      1.0, 4.0, 4.0, 5.0, 3.0, 6.0, 7.0, 3.0, 5.0, 3.0, 8.0, 9.0, 4.0, 5.0, 4.0, 1.0,
      2.0, 6.0, 4.0, 5.0, 4.0, 4.0, 3.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1059222960579487
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039233539108581794
    mean_inference_ms: 1.9946072075579309
    mean_raw_obs_processing_ms: 0.4499466448365324
time_since_restore: 1965.3162355422974
time_this_iter_s: 10.209192991256714
time_total_s: 1965.3162355422974
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.084
timestamp: 1692343556
timesteps_total: 1461500
training_iteration: 192
trial_id: default
train step: 193
agent_timesteps_total: 1467900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0406956672668457
  StateBufferConnector_ms: 0.007535457611083984
  ViewRequirementAgentConnector_ms: 0.23710346221923828
counters:
  num_agent_steps_sampled: 1467900
  num_agent_steps_trained: 1451000
  num_env_steps_sampled: 1467900
  num_env_steps_trained: 1451000
  num_samples_added_to_queue: 1467500
  num_training_step_calls_since_last_synch_worker_weights: 411
  num_weight_broadcasts: 28732
custom_metrics: {}
date: 2023-08-18_16-26-06
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.6
episode_reward_min: 0.0
episodes_this_iter: 50
episodes_total: 11468
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.09999999999991
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6441990733146667
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -4.607881546020508
        total_loss: 11.424972534179688
        var_gnorm: 63.3768310546875
        vf_explained_var: 0.27116912603378296
        vf_loss: 32.70990753173828
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2902.0
  learner_queue:
    size_count: 2908
    size_mean: 14.54
    size_quantiles: [10.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.7573844200970938
  num_agent_steps_sampled: 1467900
  num_agent_steps_trained: 1451000
  num_env_steps_sampled: 1467900
  num_env_steps_trained: 1451000
  num_samples_added_to_queue: 1467500
  num_training_step_calls_since_last_synch_worker_weights: 411
  num_weight_broadcasts: 28732
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 413.276
    learner_load_time_ms: 7.848
    learner_load_wait_time_ms: 3.026
iterations_since_restore: 193
node_ip: 127.0.0.1
num_agent_steps_sampled: 1467900
num_agent_steps_trained: 1451000
num_env_steps_sampled: 1467900
num_env_steps_sampled_this_iter: 6400
num_env_steps_sampled_throughput_per_sec: 639.9968567048912
num_env_steps_trained: 1451000
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9970531608354
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 59.68666666666666
  ram_util_percent: 79.02000000000001
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10596753373552875
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.0392944034069814
  mean_inference_ms: 1.99635648436768
  mean_raw_obs_processing_ms: 0.4504327959038657
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0406956672668457
    StateBufferConnector_ms: 0.007535457611083984
    ViewRequirementAgentConnector_ms: 0.23710346221923828
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.6
  episode_reward_min: 0.0
  episodes_this_iter: 50
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 5.0, 9.0, 7.0, 5.0, 2.0, 4.0, 4.0, 3.0, 6.0, 4.0, 10.0,
      5.0, 2.0, 9.0, 2.0, 3.0, 2.0, 8.0, 5.0, 4.0, 5.0, 4.0, 5.0, 4.0, 12.0, 1.0,
      4.0, 4.0, 5.0, 3.0, 6.0, 7.0, 3.0, 5.0, 3.0, 8.0, 9.0, 4.0, 5.0, 4.0, 1.0, 2.0,
      6.0, 4.0, 5.0, 4.0, 4.0, 3.0, 8.0, 7.0, 8.0, 4.0, 4.0, 6.0, 4.0, 8.0, 5.0, 3.0,
      4.0, 5.0, 7.0, 0.0, 5.0, 3.0, 8.0, 2.0, 3.0, 5.0, 4.0, 4.0, 3.0, 2.0, 6.0, 2.0,
      4.0, 3.0, 4.0, 6.0, 4.0, 4.0, 4.0, 3.0, 2.0, 3.0, 6.0, 3.0, 3.0, 3.0, 6.0, 4.0,
      3.0, 4.0, 6.0, 5.0, 4.0, 5.0, 6.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10596753373552875
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.0392944034069814
    mean_inference_ms: 1.99635648436768
    mean_raw_obs_processing_ms: 0.4504327959038657
time_since_restore: 1975.6217584609985
time_this_iter_s: 10.305522918701172
time_total_s: 1975.6217584609985
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692343566
timesteps_total: 1467900
training_iteration: 193
trial_id: default
train step: 194
agent_timesteps_total: 1474050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.041980743408203125
  StateBufferConnector_ms: 0.00783538818359375
  ViewRequirementAgentConnector_ms: 0.24306607246398926
counters:
  num_agent_steps_sampled: 1474050
  num_agent_steps_trained: 1457500
  num_env_steps_sampled: 1474050
  num_env_steps_trained: 1457500
  num_samples_added_to_queue: 1474000
  num_training_step_calls_since_last_synch_worker_weights: 318
  num_weight_broadcasts: 28852
custom_metrics: {}
date: 2023-08-18_16-26-16
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.43
episode_reward_min: 0.0
episodes_this_iter: 49
episodes_total: 11517
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 29.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6511977910995483
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -20.790987014770508
        total_loss: -8.545350074768066
        var_gnorm: 63.377235412597656
        vf_explained_var: 0.22257596254348755
        vf_loss: 25.142471313476562
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2915.0
  learner_queue:
    size_count: 2921
    size_mean: 14.42
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8340119955987202
  num_agent_steps_sampled: 1474050
  num_agent_steps_trained: 1457500
  num_env_steps_sampled: 1474050
  num_env_steps_trained: 1457500
  num_samples_added_to_queue: 1474000
  num_training_step_calls_since_last_synch_worker_weights: 318
  num_weight_broadcasts: 28852
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 376.174
    learner_load_time_ms: 7.434
    learner_load_wait_time_ms: 2.773
iterations_since_restore: 194
node_ip: 127.0.0.1
num_agent_steps_sampled: 1474050
num_agent_steps_trained: 1457500
num_env_steps_sampled: 1474050
num_env_steps_sampled_this_iter: 6150
num_env_steps_sampled_throughput_per_sec: 614.9963636613325
num_env_steps_trained: 1457500
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9961567152294
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 59.57142857142858
  ram_util_percent: 79.77142857142859
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1060886246652549
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039336628806271194
  mean_inference_ms: 1.9981816886783088
  mean_raw_obs_processing_ms: 0.45071897916511033
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.041980743408203125
    StateBufferConnector_ms: 0.00783538818359375
    ViewRequirementAgentConnector_ms: 0.24306607246398926
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.43
  episode_reward_min: 0.0
  episodes_this_iter: 49
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [8.0, 7.0, 8.0, 4.0, 4.0, 6.0, 4.0, 8.0, 5.0, 3.0, 4.0, 5.0, 7.0,
      0.0, 5.0, 3.0, 8.0, 2.0, 3.0, 5.0, 4.0, 4.0, 3.0, 2.0, 6.0, 2.0, 4.0, 3.0, 4.0,
      6.0, 4.0, 4.0, 4.0, 3.0, 2.0, 3.0, 6.0, 3.0, 3.0, 3.0, 6.0, 4.0, 3.0, 4.0, 6.0,
      5.0, 4.0, 5.0, 6.0, 7.0, 6.0, 4.0, 2.0, 6.0, 2.0, 5.0, 4.0, 3.0, 3.0, 2.0, 5.0,
      7.0, 4.0, 6.0, 2.0, 4.0, 8.0, 6.0, 6.0, 3.0, 1.0, 8.0, 2.0, 2.0, 4.0, 7.0, 2.0,
      6.0, 5.0, 7.0, 2.0, 5.0, 4.0, 3.0, 8.0, 6.0, 5.0, 2.0, 4.0, 8.0, 1.0, 4.0, 2.0,
      10.0, 4.0, 5.0, 7.0, 7.0, 1.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1060886246652549
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039336628806271194
    mean_inference_ms: 1.9981816886783088
    mean_raw_obs_processing_ms: 0.45071897916511033
time_since_restore: 1985.8982813358307
time_this_iter_s: 10.276522874832153
time_total_s: 1985.8982813358307
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.088
timestamp: 1692343576
timesteps_total: 1474050
training_iteration: 194
trial_id: default
train step: 195
agent_timesteps_total: 1480200
connector_metrics:
  ObsPreprocessorConnector_ms: 0.04206132888793945
  StateBufferConnector_ms: 0.007854223251342773
  ViewRequirementAgentConnector_ms: 0.2474839687347412
counters:
  num_agent_steps_sampled: 1480200
  num_agent_steps_trained: 1463500
  num_env_steps_sampled: 1480200
  num_env_steps_trained: 1463500
  num_samples_added_to_queue: 1480000
  num_training_step_calls_since_last_synch_worker_weights: 523
  num_weight_broadcasts: 28972
custom_metrics: {}
date: 2023-08-18_16-26-27
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.71
episode_reward_min: 1.0
episodes_this_iter: 48
episodes_total: 11565
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 30.800000000000182
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6450288891792297
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 15.104015350341797
        total_loss: 39.13529586791992
        var_gnorm: 63.377540588378906
        vf_explained_var: 0.20078319311141968
        vf_loss: 48.70759201049805
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2927.0
  learner_queue:
    size_count: 2932
    size_mean: 14.22
    size_quantiles: [10.0, 11.0, 14.5, 16.0, 16.0]
    size_std: 1.8578482176970217
  num_agent_steps_sampled: 1480200
  num_agent_steps_trained: 1463500
  num_env_steps_sampled: 1480200
  num_env_steps_trained: 1463500
  num_samples_added_to_queue: 1480000
  num_training_step_calls_since_last_synch_worker_weights: 523
  num_weight_broadcasts: 28972
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 961.149
    learner_load_time_ms: 6.771
    learner_load_wait_time_ms: 4.413
iterations_since_restore: 195
node_ip: 127.0.0.1
num_agent_steps_sampled: 1480200
num_agent_steps_trained: 1463500
num_env_steps_sampled: 1480200
num_env_steps_sampled_this_iter: 6150
num_env_steps_sampled_throughput_per_sec: 614.9973460550395
num_env_steps_trained: 1463500
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9974107854044
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 56.58666666666667
  ram_util_percent: 80.19999999999999
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10621245618659934
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03937936334353541
  mean_inference_ms: 2.0001776453574394
  mean_raw_obs_processing_ms: 0.451025698227984
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.04206132888793945
    StateBufferConnector_ms: 0.007854223251342773
    ViewRequirementAgentConnector_ms: 0.2474839687347412
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.71
  episode_reward_min: 1.0
  episodes_this_iter: 48
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 7.0, 6.0, 4.0, 2.0, 6.0, 2.0, 5.0, 4.0, 3.0, 3.0, 2.0, 5.0,
      7.0, 4.0, 6.0, 2.0, 4.0, 8.0, 6.0, 6.0, 3.0, 1.0, 8.0, 2.0, 2.0, 4.0, 7.0, 2.0,
      6.0, 5.0, 7.0, 2.0, 5.0, 4.0, 3.0, 8.0, 6.0, 5.0, 2.0, 4.0, 8.0, 1.0, 4.0, 2.0,
      10.0, 4.0, 5.0, 7.0, 7.0, 1.0, 1.0, 4.0, 2.0, 5.0, 5.0, 7.0, 7.0, 4.0, 7.0,
      12.0, 1.0, 5.0, 7.0, 6.0, 6.0, 4.0, 4.0, 1.0, 4.0, 6.0, 4.0, 7.0, 3.0, 7.0,
      4.0, 8.0, 2.0, 4.0, 7.0, 5.0, 4.0, 2.0, 6.0, 6.0, 5.0, 4.0, 2.0, 3.0, 4.0, 3.0,
      6.0, 7.0, 4.0, 6.0, 2.0, 2.0, 8.0, 7.0, 8.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10621245618659934
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03937936334353541
    mean_inference_ms: 2.0001776453574394
    mean_raw_obs_processing_ms: 0.451025698227984
time_since_restore: 1996.2652904987335
time_this_iter_s: 10.367009162902832
time_total_s: 1996.2652904987335
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.087
timestamp: 1692343587
timesteps_total: 1480200
training_iteration: 195
trial_id: default
train step: 196
agent_timesteps_total: 1486400
connector_metrics:
  ObsPreprocessorConnector_ms: 0.040900230407714844
  StateBufferConnector_ms: 0.007475614547729492
  ViewRequirementAgentConnector_ms: 0.24468660354614258
counters:
  num_agent_steps_sampled: 1486400
  num_agent_steps_trained: 1469500
  num_env_steps_sampled: 1486400
  num_env_steps_trained: 1469500
  num_samples_added_to_queue: 1486000
  num_training_step_calls_since_last_synch_worker_weights: 1041
  num_weight_broadcasts: 29093
custom_metrics: {}
date: 2023-08-18_16-26-37
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 12.0
episode_reward_mean: 4.62
episode_reward_min: 0.0
episodes_this_iter: 48
episodes_total: 11613
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 29.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6474239230155945
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 22.666431427001953
        total_loss: 44.99013900756836
        var_gnorm: 63.3778076171875
        vf_explained_var: 0.1871861219406128
        vf_loss: 45.294837951660156
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2939.0
  learner_queue:
    size_count: 2943
    size_mean: 14.42
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.6862977198585072
  num_agent_steps_sampled: 1486400
  num_agent_steps_trained: 1469500
  num_env_steps_sampled: 1486400
  num_env_steps_trained: 1469500
  num_samples_added_to_queue: 1486000
  num_training_step_calls_since_last_synch_worker_weights: 1041
  num_weight_broadcasts: 29093
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 907.6
    learner_load_time_ms: 6.771
    learner_load_wait_time_ms: 18.181
iterations_since_restore: 196
node_ip: 127.0.0.1
num_agent_steps_sampled: 1486400
num_agent_steps_trained: 1469500
num_env_steps_sampled: 1486400
num_env_steps_sampled_this_iter: 6200
num_env_steps_sampled_throughput_per_sec: 619.998329643935
num_env_steps_trained: 1469500
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9983835263887
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 67.95714285714286
  ram_util_percent: 80.05
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10631301532044307
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039426325527765
  mean_inference_ms: 2.0021674102530023
  mean_raw_obs_processing_ms: 0.451411865200257
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.040900230407714844
    StateBufferConnector_ms: 0.007475614547729492
    ViewRequirementAgentConnector_ms: 0.24468660354614258
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 12.0
  episode_reward_mean: 4.62
  episode_reward_min: 0.0
  episodes_this_iter: 48
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 7.0, 1.0, 1.0, 4.0, 2.0, 5.0, 5.0, 7.0, 7.0, 4.0, 7.0, 12.0,
      1.0, 5.0, 7.0, 6.0, 6.0, 4.0, 4.0, 1.0, 4.0, 6.0, 4.0, 7.0, 3.0, 7.0, 4.0, 8.0,
      2.0, 4.0, 7.0, 5.0, 4.0, 2.0, 6.0, 6.0, 5.0, 4.0, 2.0, 3.0, 4.0, 3.0, 6.0, 7.0,
      4.0, 6.0, 2.0, 2.0, 8.0, 7.0, 8.0, 5.0, 4.0, 5.0, 3.0, 3.0, 8.0, 6.0, 3.0, 4.0,
      4.0, 4.0, 2.0, 3.0, 1.0, 3.0, 5.0, 9.0, 0.0, 1.0, 5.0, 6.0, 4.0, 6.0, 7.0, 4.0,
      1.0, 6.0, 3.0, 6.0, 1.0, 5.0, 3.0, 6.0, 4.0, 2.0, 5.0, 5.0, 7.0, 6.0, 7.0, 5.0,
      4.0, 6.0, 6.0, 5.0, 1.0, 5.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10631301532044307
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039426325527765
    mean_inference_ms: 2.0021674102530023
    mean_raw_obs_processing_ms: 0.451411865200257
time_since_restore: 2006.4859805107117
time_this_iter_s: 10.22069001197815
time_total_s: 2006.4859805107117
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.085
timestamp: 1692343597
timesteps_total: 1486400
training_iteration: 196
trial_id: default
train step: 197
agent_timesteps_total: 1493500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03739333152770996
  StateBufferConnector_ms: 0.0070056915283203125
  ViewRequirementAgentConnector_ms: 0.2257852554321289
counters:
  num_agent_steps_sampled: 1493500
  num_agent_steps_trained: 1477000
  num_env_steps_sampled: 1493500
  num_env_steps_trained: 1477000
  num_samples_added_to_queue: 1493500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 29231
custom_metrics: {}
date: 2023-08-18_16-26-47
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.63
episode_reward_min: 0.0
episodes_this_iter: 55
episodes_total: 11668
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 30.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.64841228723526
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -19.48015594482422
        total_loss: -6.985269546508789
        var_gnorm: 63.37797164916992
        vf_explained_var: 0.2541388273239136
        vf_loss: 25.638185501098633
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2954.0
  learner_queue:
    size_count: 2959
    size_mean: 14.72
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.5497096502248413
  num_agent_steps_sampled: 1493500
  num_agent_steps_trained: 1477000
  num_env_steps_sampled: 1493500
  num_env_steps_trained: 1477000
  num_samples_added_to_queue: 1493500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 29231
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 357.833
    learner_load_time_ms: 6.368
    learner_load_wait_time_ms: 3.015
iterations_since_restore: 197
node_ip: 127.0.0.1
num_agent_steps_sampled: 1493500
num_agent_steps_trained: 1477000
num_env_steps_sampled: 1493500
num_env_steps_sampled_this_iter: 7100
num_env_steps_sampled_throughput_per_sec: 708.0476250641544
num_env_steps_trained: 1477000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 747.9376321100223
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 57.03999999999999
  ram_util_percent: 79.08
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1063929987979467
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039460596951079
  mean_inference_ms: 2.0036475699848557
  mean_raw_obs_processing_ms: 0.4516947084149163
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03739333152770996
    StateBufferConnector_ms: 0.0070056915283203125
    ViewRequirementAgentConnector_ms: 0.2257852554321289
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.63
  episode_reward_min: 0.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 8.0, 6.0, 3.0, 4.0, 4.0, 4.0, 2.0, 3.0, 1.0, 3.0, 5.0,
      9.0, 0.0, 1.0, 5.0, 6.0, 4.0, 6.0, 7.0, 4.0, 1.0, 6.0, 3.0, 6.0, 1.0, 5.0, 3.0,
      6.0, 4.0, 2.0, 5.0, 5.0, 7.0, 6.0, 7.0, 5.0, 4.0, 6.0, 6.0, 5.0, 1.0, 5.0, 5.0,
      5.0, 1.0, 4.0, 7.0, 4.0, 2.0, 3.0, 5.0, 4.0, 6.0, 2.0, 1.0, 6.0, 5.0, 6.0, 4.0,
      6.0, 2.0, 4.0, 1.0, 9.0, 4.0, 6.0, 5.0, 5.0, 7.0, 3.0, 4.0, 5.0, 2.0, 5.0, 6.0,
      5.0, 4.0, 5.0, 7.0, 5.0, 5.0, 10.0, 3.0, 7.0, 6.0, 9.0, 2.0, 7.0, 5.0, 5.0,
      6.0, 7.0, 6.0, 2.0, 4.0, 6.0, 7.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1063929987979467
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039460596951079
    mean_inference_ms: 2.0036475699848557
    mean_raw_obs_processing_ms: 0.4516947084149163
time_since_restore: 2016.762143611908
time_this_iter_s: 10.276163101196289
time_total_s: 2016.762143611908
timers:
  sample_time_ms: 0.065
  synch_weights_time_ms: 0.845
  training_iteration_time_ms: 3.695
timestamp: 1692343607
timesteps_total: 1493500
training_iteration: 197
trial_id: default
train step: 198
agent_timesteps_total: 1500650
connector_metrics:
  ObsPreprocessorConnector_ms: 0.035399436950683594
  StateBufferConnector_ms: 0.007009744644165039
  ViewRequirementAgentConnector_ms: 0.2288498878479004
counters:
  num_agent_steps_sampled: 1500650
  num_agent_steps_trained: 1484000
  num_env_steps_sampled: 1500650
  num_env_steps_trained: 1484000
  num_samples_added_to_queue: 1500500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 29372
custom_metrics: {}
date: 2023-08-18_16-26-57
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 5.23
episode_reward_min: 1.0
episodes_this_iter: 56
episodes_total: 11724
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6470288634300232
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 12.219971656799316
        total_loss: 26.226057052612305
        var_gnorm: 63.378387451171875
        vf_explained_var: 0.29427868127822876
        vf_loss: 28.659202575683594
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2968.0
  learner_queue:
    size_count: 2974
    size_mean: 14.78
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.5529327094243333
  num_agent_steps_sampled: 1500650
  num_agent_steps_trained: 1484000
  num_env_steps_sampled: 1500650
  num_env_steps_trained: 1484000
  num_samples_added_to_queue: 1500500
  num_training_step_calls_since_last_synch_worker_weights: 0
  num_weight_broadcasts: 29372
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 340.555
    learner_load_time_ms: 6.793
    learner_load_wait_time_ms: 3.094
iterations_since_restore: 198
node_ip: 127.0.0.1
num_agent_steps_sampled: 1500650
num_agent_steps_trained: 1484000
num_env_steps_sampled: 1500650
num_env_steps_sampled_this_iter: 7150
num_env_steps_sampled_throughput_per_sec: 714.8473773416497
num_env_steps_trained: 1484000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.8505792156011
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 3
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 55.214285714285715
  ram_util_percent: 79.36428571428571
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10653211163222272
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03944981886489495
  mean_inference_ms: 2.004224212745491
  mean_raw_obs_processing_ms: 0.4515438757862228
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.035399436950683594
    StateBufferConnector_ms: 0.007009744644165039
    ViewRequirementAgentConnector_ms: 0.2288498878479004
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 5.23
  episode_reward_min: 1.0
  episodes_this_iter: 56
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [1.0, 6.0, 5.0, 6.0, 4.0, 6.0, 2.0, 4.0, 1.0, 9.0, 4.0, 6.0, 5.0,
      5.0, 7.0, 3.0, 4.0, 5.0, 2.0, 5.0, 6.0, 5.0, 4.0, 5.0, 7.0, 5.0, 5.0, 10.0,
      3.0, 7.0, 6.0, 9.0, 2.0, 7.0, 5.0, 5.0, 6.0, 7.0, 6.0, 2.0, 4.0, 6.0, 7.0, 6.0,
      4.0, 5.0, 3.0, 2.0, 5.0, 6.0, 4.0, 5.0, 9.0, 3.0, 10.0, 1.0, 7.0, 6.0, 3.0,
      8.0, 6.0, 9.0, 7.0, 6.0, 9.0, 4.0, 5.0, 6.0, 2.0, 1.0, 3.0, 1.0, 4.0, 8.0, 3.0,
      6.0, 3.0, 5.0, 4.0, 4.0, 10.0, 4.0, 6.0, 8.0, 10.0, 7.0, 3.0, 8.0, 6.0, 4.0,
      6.0, 7.0, 4.0, 4.0, 3.0, 6.0, 2.0, 10.0, 6.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10653211163222272
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03944981886489495
    mean_inference_ms: 2.004224212745491
    mean_raw_obs_processing_ms: 0.4515438757862228
time_since_restore: 2027.0765719413757
time_this_iter_s: 10.314428329467773
time_total_s: 2027.0765719413757
timers:
  sample_time_ms: 0.112
  synch_weights_time_ms: 0.493
  training_iteration_time_ms: 0.752
timestamp: 1692343617
timesteps_total: 1500650
training_iteration: 198
trial_id: default
train step: 199
agent_timesteps_total: 1508700
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033972978591918945
  StateBufferConnector_ms: 0.006494045257568359
  ViewRequirementAgentConnector_ms: 0.2175154685974121
counters:
  num_agent_steps_sampled: 1508700
  num_agent_steps_trained: 1492000
  num_env_steps_sampled: 1508700
  num_env_steps_trained: 1492000
  num_samples_added_to_queue: 1508500
  num_training_step_calls_since_last_synch_worker_weights: 59
  num_weight_broadcasts: 29530
custom_metrics: {}
date: 2023-08-18_16-27-08
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.82
episode_reward_min: 1.0
episodes_this_iter: 64
episodes_total: 11788
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6280547380447388
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 34.50185775756836
        total_loss: 56.83411407470703
        var_gnorm: 63.378841400146484
        vf_explained_var: 0.29490429162979126
        vf_loss: 45.29256820678711
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2984.0
  learner_queue:
    size_count: 2991
    size_mean: 14.52
    size_quantiles: [10.0, 11.9, 15.5, 16.0, 16.0]
    size_std: 1.8137254478007416
  num_agent_steps_sampled: 1508700
  num_agent_steps_trained: 1492000
  num_env_steps_sampled: 1508700
  num_env_steps_trained: 1492000
  num_samples_added_to_queue: 1508500
  num_training_step_calls_since_last_synch_worker_weights: 59
  num_weight_broadcasts: 29530
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 236.662
    learner_load_time_ms: 7.385
    learner_load_wait_time_ms: 2.79
iterations_since_restore: 199
node_ip: 127.0.0.1
num_agent_steps_sampled: 1508700
num_agent_steps_trained: 1492000
num_env_steps_sampled: 1508700
num_env_steps_sampled_this_iter: 8050
num_env_steps_sampled_throughput_per_sec: 804.9928219958442
num_env_steps_trained: 1492000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.992866579721
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 52.166666666666664
  ram_util_percent: 79.42000000000002
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1066258440305685
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039419203388682385
  mean_inference_ms: 2.0040153691820337
  mean_raw_obs_processing_ms: 0.4512255152538694
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033972978591918945
    StateBufferConnector_ms: 0.006494045257568359
    ViewRequirementAgentConnector_ms: 0.2175154685974121
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.82
  episode_reward_min: 1.0
  episodes_this_iter: 64
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [9.0, 4.0, 5.0, 6.0, 2.0, 1.0, 3.0, 1.0, 4.0, 8.0, 3.0, 6.0, 3.0,
      5.0, 4.0, 4.0, 10.0, 4.0, 6.0, 8.0, 10.0, 7.0, 3.0, 8.0, 6.0, 4.0, 6.0, 7.0,
      4.0, 4.0, 3.0, 6.0, 2.0, 10.0, 6.0, 7.0, 6.0, 4.0, 7.0, 3.0, 5.0, 3.0, 1.0,
      3.0, 5.0, 3.0, 7.0, 6.0, 6.0, 5.0, 6.0, 8.0, 7.0, 7.0, 4.0, 4.0, 3.0, 3.0, 1.0,
      4.0, 3.0, 1.0, 7.0, 5.0, 7.0, 7.0, 5.0, 3.0, 11.0, 4.0, 4.0, 2.0, 2.0, 7.0,
      7.0, 5.0, 5.0, 6.0, 5.0, 3.0, 4.0, 4.0, 5.0, 2.0, 2.0, 6.0, 5.0, 7.0, 1.0, 3.0,
      2.0, 3.0, 4.0, 3.0, 6.0, 4.0, 2.0, 5.0, 8.0, 7.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1066258440305685
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039419203388682385
    mean_inference_ms: 2.0040153691820337
    mean_raw_obs_processing_ms: 0.4512255152538694
time_since_restore: 2037.4020581245422
time_this_iter_s: 10.325486183166504
time_total_s: 2037.4020581245422
timers:
  sample_time_ms: 0.035
  synch_weights_time_ms: 0.011
  training_iteration_time_ms: 0.105
timestamp: 1692343628
timesteps_total: 1508700
training_iteration: 199
trial_id: default
train step: 200
agent_timesteps_total: 1516050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.033167362213134766
  StateBufferConnector_ms: 0.005934000015258789
  ViewRequirementAgentConnector_ms: 0.19681096076965332
counters:
  num_agent_steps_sampled: 1516050
  num_agent_steps_trained: 1499500
  num_env_steps_sampled: 1516050
  num_env_steps_trained: 1499500
  num_samples_added_to_queue: 1516000
  num_training_step_calls_since_last_synch_worker_weights: 251
  num_weight_broadcasts: 29674
custom_metrics: {}
date: 2023-08-18_16-27-18
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.49
episode_reward_min: 1.0
episodes_this_iter: 57
episodes_total: 11845
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6418032646179199
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -5.702066421508789
        total_loss: 9.719558715820312
        var_gnorm: 63.379356384277344
        vf_explained_var: 0.2496776580810547
        vf_loss: 31.48505401611328
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 2999.0
  learner_queue:
    size_count: 3005
    size_mean: 14.2
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.9183326093250879
  num_agent_steps_sampled: 1516050
  num_agent_steps_trained: 1499500
  num_env_steps_sampled: 1516050
  num_env_steps_trained: 1499500
  num_samples_added_to_queue: 1516000
  num_training_step_calls_since_last_synch_worker_weights: 251
  num_weight_broadcasts: 29674
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 316.061
    learner_load_time_ms: 7.665
    learner_load_wait_time_ms: 2.983
iterations_since_restore: 200
node_ip: 127.0.0.1
num_agent_steps_sampled: 1516050
num_agent_steps_trained: 1499500
num_env_steps_sampled: 1516050
num_env_steps_sampled_this_iter: 7350
num_env_steps_sampled_throughput_per_sec: 734.9928678966228
num_env_steps_trained: 1499500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9927223434927
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 52.27142857142858
  ram_util_percent: 79.58571428571429
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10663703443995011
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03940688985701685
  mean_inference_ms: 2.003987060226351
  mean_raw_obs_processing_ms: 0.4511152423789089
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.033167362213134766
    StateBufferConnector_ms: 0.005934000015258789
    ViewRequirementAgentConnector_ms: 0.19681096076965332
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.49
  episode_reward_min: 1.0
  episodes_this_iter: 57
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 1.0, 4.0, 3.0, 1.0, 7.0, 5.0, 7.0, 7.0, 5.0, 3.0, 11.0,
      4.0, 4.0, 2.0, 2.0, 7.0, 7.0, 5.0, 5.0, 6.0, 5.0, 3.0, 4.0, 4.0, 5.0, 2.0, 2.0,
      6.0, 5.0, 7.0, 1.0, 3.0, 2.0, 3.0, 4.0, 3.0, 6.0, 4.0, 2.0, 5.0, 8.0, 7.0, 5.0,
      6.0, 6.0, 6.0, 3.0, 4.0, 7.0, 7.0, 2.0, 3.0, 3.0, 6.0, 4.0, 3.0, 2.0, 7.0, 4.0,
      4.0, 3.0, 2.0, 10.0, 3.0, 6.0, 6.0, 1.0, 1.0, 4.0, 6.0, 7.0, 9.0, 2.0, 5.0,
      5.0, 4.0, 5.0, 3.0, 4.0, 5.0, 3.0, 10.0, 5.0, 4.0, 2.0, 5.0, 6.0, 3.0, 4.0,
      3.0, 2.0, 1.0, 5.0, 4.0, 9.0, 6.0, 7.0, 3.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10663703443995011
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03940688985701685
    mean_inference_ms: 2.003987060226351
    mean_raw_obs_processing_ms: 0.4511152423789089
time_since_restore: 2047.641177892685
time_this_iter_s: 10.2391197681427
time_total_s: 2047.641177892685
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.085
timestamp: 1692343638
timesteps_total: 1516050
training_iteration: 200
trial_id: default
train step: 201
agent_timesteps_total: 1523950
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03171563148498535
  StateBufferConnector_ms: 0.00584721565246582
  ViewRequirementAgentConnector_ms: 0.19386911392211914
counters:
  num_agent_steps_sampled: 1523950
  num_agent_steps_trained: 1507000
  num_env_steps_sampled: 1523950
  num_env_steps_trained: 1507000
  num_samples_added_to_queue: 1523500
  num_training_step_calls_since_last_synch_worker_weights: 1121
  num_weight_broadcasts: 29829
custom_metrics: {}
date: 2023-08-18_16-27-28
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 11.0
episode_reward_mean: 4.58
episode_reward_min: 0.0
episodes_this_iter: 61
episodes_total: 11906
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6218819618225098
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -46.9840087890625
        total_loss: -28.17580795288086
        var_gnorm: 63.379756927490234
        vf_explained_var: 0.15124660730361938
        vf_loss: 38.238285064697266
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3014.0
  learner_queue:
    size_count: 3018
    size_mean: 14.26
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.905885620912231
  num_agent_steps_sampled: 1523950
  num_agent_steps_trained: 1507000
  num_env_steps_sampled: 1523950
  num_env_steps_trained: 1507000
  num_samples_added_to_queue: 1523500
  num_training_step_calls_since_last_synch_worker_weights: 1121
  num_weight_broadcasts: 29829
  timing_breakdown:
    learner_dequeue_time_ms: 0.008
    learner_grad_time_ms: 611.361
    learner_load_time_ms: 7.997
    learner_load_wait_time_ms: 3.366
iterations_since_restore: 201
node_ip: 127.0.0.1
num_agent_steps_sampled: 1523950
num_agent_steps_trained: 1507000
num_env_steps_sampled: 1523950
num_env_steps_sampled_this_iter: 7900
num_env_steps_sampled_throughput_per_sec: 789.998267177568
num_env_steps_trained: 1507000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9983549154126
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 51.86
  ram_util_percent: 80.10666666666665
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10657053141777173
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03941256271271018
  mean_inference_ms: 2.003917561833703
  mean_raw_obs_processing_ms: 0.4512076035347736
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03171563148498535
    StateBufferConnector_ms: 0.00584721565246582
    ViewRequirementAgentConnector_ms: 0.19386911392211914
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 11.0
  episode_reward_mean: 4.58
  episode_reward_min: 0.0
  episodes_this_iter: 61
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 2.0, 10.0, 3.0, 6.0, 6.0, 1.0, 1.0, 4.0, 6.0, 7.0, 9.0,
      2.0, 5.0, 5.0, 4.0, 5.0, 3.0, 4.0, 5.0, 3.0, 10.0, 5.0, 4.0, 2.0, 5.0, 6.0,
      3.0, 4.0, 3.0, 2.0, 1.0, 5.0, 4.0, 9.0, 6.0, 7.0, 3.0, 4.0, 4.0, 7.0, 4.0, 6.0,
      5.0, 6.0, 4.0, 5.0, 6.0, 4.0, 7.0, 3.0, 4.0, 3.0, 3.0, 11.0, 3.0, 2.0, 6.0,
      3.0, 5.0, 5.0, 2.0, 5.0, 6.0, 3.0, 2.0, 7.0, 5.0, 3.0, 6.0, 1.0, 4.0, 1.0, 9.0,
      6.0, 5.0, 6.0, 2.0, 0.0, 5.0, 5.0, 3.0, 7.0, 4.0, 6.0, 6.0, 4.0, 4.0, 4.0, 8.0,
      2.0, 3.0, 6.0, 4.0, 5.0, 7.0, 3.0, 4.0, 6.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10657053141777173
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03941256271271018
    mean_inference_ms: 2.003917561833703
    mean_raw_obs_processing_ms: 0.4512076035347736
time_since_restore: 2057.8052389621735
time_this_iter_s: 10.164061069488525
time_total_s: 2057.8052389621735
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692343648
timesteps_total: 1523950
training_iteration: 201
trial_id: default
train step: 202
agent_timesteps_total: 1531600
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03229498863220215
  StateBufferConnector_ms: 0.005971670150756836
  ViewRequirementAgentConnector_ms: 0.19595742225646973
counters:
  num_agent_steps_sampled: 1531600
  num_agent_steps_trained: 1515000
  num_env_steps_sampled: 1531600
  num_env_steps_trained: 1515000
  num_samples_added_to_queue: 1531500
  num_training_step_calls_since_last_synch_worker_weights: 616
  num_weight_broadcasts: 29979
custom_metrics: {}
date: 2023-08-18_16-27-38
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.58
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 11966
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6382575035095215
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 5.496520042419434
        total_loss: 24.559175491333008
        var_gnorm: 63.3802490234375
        vf_explained_var: 0.19164210557937622
        vf_loss: 38.76356887817383
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3030.0
  learner_queue:
    size_count: 3035
    size_mean: 14.54
    size_quantiles: [10.0, 11.9, 15.5, 16.0, 16.0]
    size_std: 1.7912007146045914
  num_agent_steps_sampled: 1531600
  num_agent_steps_trained: 1515000
  num_env_steps_sampled: 1531600
  num_env_steps_trained: 1515000
  num_samples_added_to_queue: 1531500
  num_training_step_calls_since_last_synch_worker_weights: 616
  num_weight_broadcasts: 29979
  timing_breakdown:
    learner_dequeue_time_ms: 0.009
    learner_grad_time_ms: 399.062
    learner_load_time_ms: 7.832
    learner_load_wait_time_ms: 2.855
iterations_since_restore: 202
node_ip: 127.0.0.1
num_agent_steps_sampled: 1531600
num_agent_steps_trained: 1515000
num_env_steps_sampled: 1531600
num_env_steps_sampled_this_iter: 7650
num_env_steps_sampled_throughput_per_sec: 764.9932698603492
num_env_steps_trained: 1515000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9929619454632
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 56.314285714285724
  ram_util_percent: 79.67857142857143
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10658092435424414
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03939930231107254
  mean_inference_ms: 2.0036429909632494
  mean_raw_obs_processing_ms: 0.45107851134554183
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03229498863220215
    StateBufferConnector_ms: 0.005971670150756836
    ViewRequirementAgentConnector_ms: 0.19595742225646973
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.58
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 2.0, 5.0, 6.0, 3.0, 2.0, 7.0, 5.0, 3.0, 6.0, 1.0, 4.0, 1.0,
      9.0, 6.0, 5.0, 6.0, 2.0, 0.0, 5.0, 5.0, 3.0, 7.0, 4.0, 6.0, 6.0, 4.0, 4.0, 4.0,
      8.0, 2.0, 3.0, 6.0, 4.0, 5.0, 7.0, 3.0, 4.0, 6.0, 6.0, 4.0, 3.0, 2.0, 7.0, 6.0,
      8.0, 8.0, 4.0, 5.0, 6.0, 2.0, 7.0, 2.0, 5.0, 4.0, 3.0, 5.0, 5.0, 3.0, 5.0, 9.0,
      7.0, 5.0, 4.0, 3.0, 3.0, 3.0, 1.0, 4.0, 6.0, 4.0, 2.0, 6.0, 9.0, 4.0, 2.0, 5.0,
      7.0, 4.0, 5.0, 6.0, 3.0, 3.0, 5.0, 5.0, 5.0, 3.0, 5.0, 4.0, 6.0, 2.0, 6.0, 4.0,
      2.0, 10.0, 5.0, 6.0, 3.0, 3.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10658092435424414
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03939930231107254
    mean_inference_ms: 2.0036429909632494
    mean_raw_obs_processing_ms: 0.45107851134554183
time_since_restore: 2068.019944190979
time_this_iter_s: 10.214705228805542
time_total_s: 2068.019944190979
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.073
timestamp: 1692343658
timesteps_total: 1531600
training_iteration: 202
trial_id: default
train step: 203
agent_timesteps_total: 1537850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.037484169006347656
  StateBufferConnector_ms: 0.006785869598388672
  ViewRequirementAgentConnector_ms: 0.22176003456115723
counters:
  num_agent_steps_sampled: 1537850
  num_agent_steps_trained: 1521000
  num_env_steps_sampled: 1537850
  num_env_steps_trained: 1521000
  num_samples_added_to_queue: 1537500
  num_training_step_calls_since_last_synch_worker_weights: 520
  num_weight_broadcasts: 30100
custom_metrics: {}
date: 2023-08-18_16-27-49
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.46
episode_reward_min: 0.0
episodes_this_iter: 49
episodes_total: 12015
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.80000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6312166452407837
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -14.328241348266602
        total_loss: 0.7093855142593384
        var_gnorm: 63.38064193725586
        vf_explained_var: 0.17376941442489624
        vf_loss: 30.706470489501953
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3042.0
  learner_queue:
    size_count: 3048
    size_mean: 14.76
    size_quantiles: [11.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.6069847541280535
  num_agent_steps_sampled: 1537850
  num_agent_steps_trained: 1521000
  num_env_steps_sampled: 1537850
  num_env_steps_trained: 1521000
  num_samples_added_to_queue: 1537500
  num_training_step_calls_since_last_synch_worker_weights: 520
  num_weight_broadcasts: 30100
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 411.403
    learner_load_time_ms: 7.796
    learner_load_wait_time_ms: 3.171
iterations_since_restore: 203
node_ip: 127.0.0.1
num_agent_steps_sampled: 1537850
num_agent_steps_trained: 1521000
num_env_steps_sampled: 1537850
num_env_steps_sampled_this_iter: 6250
num_env_steps_sampled_throughput_per_sec: 624.9968111677745
num_env_steps_trained: 1521000
num_env_steps_trained_this_iter: 6000
num_env_steps_trained_throughput_per_sec: 599.9969387210634
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6000
perf:
  cpu_util_percent: 62.940000000000005
  ram_util_percent: 80.36
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1065020980888333
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039458046753855974
  mean_inference_ms: 2.0046179631824965
  mean_raw_obs_processing_ms: 0.4516078234373741
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.037484169006347656
    StateBufferConnector_ms: 0.006785869598388672
    ViewRequirementAgentConnector_ms: 0.22176003456115723
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.46
  episode_reward_min: 0.0
  episodes_this_iter: 49
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [6.0, 2.0, 7.0, 2.0, 5.0, 4.0, 3.0, 5.0, 5.0, 3.0, 5.0, 9.0, 7.0,
      5.0, 4.0, 3.0, 3.0, 3.0, 1.0, 4.0, 6.0, 4.0, 2.0, 6.0, 9.0, 4.0, 2.0, 5.0, 7.0,
      4.0, 5.0, 6.0, 3.0, 3.0, 5.0, 5.0, 5.0, 3.0, 5.0, 4.0, 6.0, 2.0, 6.0, 4.0, 2.0,
      10.0, 5.0, 6.0, 3.0, 3.0, 5.0, 4.0, 4.0, 5.0, 5.0, 6.0, 4.0, 8.0, 3.0, 2.0,
      5.0, 3.0, 7.0, 3.0, 7.0, 4.0, 1.0, 2.0, 7.0, 4.0, 3.0, 5.0, 1.0, 0.0, 7.0, 4.0,
      6.0, 3.0, 3.0, 6.0, 2.0, 6.0, 6.0, 7.0, 3.0, 4.0, 8.0, 7.0, 4.0, 2.0, 1.0, 5.0,
      5.0, 3.0, 2.0, 4.0, 3.0, 7.0, 8.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1065020980888333
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039458046753855974
    mean_inference_ms: 2.0046179631824965
    mean_raw_obs_processing_ms: 0.4516078234373741
time_since_restore: 2078.3734109401703
time_this_iter_s: 10.353466749191284
time_total_s: 2078.3734109401703
timers:
  sample_time_ms: 0.03
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.087
timestamp: 1692343669
timesteps_total: 1537850
training_iteration: 203
trial_id: default
train step: 204
agent_timesteps_total: 1545450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0368657112121582
  StateBufferConnector_ms: 0.006604909896850586
  ViewRequirementAgentConnector_ms: 0.21703100204467773
counters:
  num_agent_steps_sampled: 1545450
  num_agent_steps_trained: 1528500
  num_env_steps_sampled: 1545450
  num_env_steps_trained: 1528500
  num_samples_added_to_queue: 1545000
  num_training_step_calls_since_last_synch_worker_weights: 1
  num_weight_broadcasts: 30248
custom_metrics: {}
date: 2023-08-18_16-27-59
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.53
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 12075
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6122099757194519
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -10.221855163574219
        total_loss: 6.592935085296631
        var_gnorm: 63.381099700927734
        vf_explained_var: 0.2422686219215393
        vf_loss: 34.241790771484375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3057.0
  learner_queue:
    size_count: 3064
    size_mean: 14.7
    size_quantiles: [10.0, 12.0, 16.0, 16.0, 16.0]
    size_std: 1.676305461424021
  num_agent_steps_sampled: 1545450
  num_agent_steps_trained: 1528500
  num_env_steps_sampled: 1545450
  num_env_steps_trained: 1528500
  num_samples_added_to_queue: 1545000
  num_training_step_calls_since_last_synch_worker_weights: 1
  num_weight_broadcasts: 30248
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 279.027
    learner_load_time_ms: 4.335
    learner_load_wait_time_ms: 2.552
iterations_since_restore: 204
node_ip: 127.0.0.1
num_agent_steps_sampled: 1545450
num_agent_steps_trained: 1528500
num_env_steps_sampled: 1545450
num_env_steps_sampled_this_iter: 7600
num_env_steps_sampled_throughput_per_sec: 759.9959774230244
num_env_steps_trained: 1528500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9960303516689
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 50.60000000000001
  ram_util_percent: 81.07857142857144
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10654793451405764
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03948473962253244
  mean_inference_ms: 2.005550303855579
  mean_raw_obs_processing_ms: 0.4517999873680928
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0368657112121582
    StateBufferConnector_ms: 0.006604909896850586
    ViewRequirementAgentConnector_ms: 0.21703100204467773
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.53
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 3.0, 7.0, 3.0, 7.0, 4.0, 1.0, 2.0, 7.0, 4.0, 3.0, 5.0, 1.0,
      0.0, 7.0, 4.0, 6.0, 3.0, 3.0, 6.0, 2.0, 6.0, 6.0, 7.0, 3.0, 4.0, 8.0, 7.0, 4.0,
      2.0, 1.0, 5.0, 5.0, 3.0, 2.0, 4.0, 3.0, 7.0, 8.0, 6.0, 4.0, 5.0, 4.0, 7.0, 4.0,
      3.0, 9.0, 5.0, 4.0, 8.0, 3.0, 6.0, 2.0, 1.0, 4.0, 2.0, 8.0, 4.0, 3.0, 7.0, 2.0,
      5.0, 7.0, 6.0, 5.0, 4.0, 4.0, 3.0, 3.0, 2.0, 5.0, 2.0, 2.0, 2.0, 2.0, 9.0, 9.0,
      8.0, 5.0, 7.0, 4.0, 4.0, 4.0, 6.0, 3.0, 3.0, 3.0, 5.0, 2.0, 7.0, 4.0, 7.0, 8.0,
      3.0, 4.0, 6.0, 5.0, 6.0, 6.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10654793451405764
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03948473962253244
    mean_inference_ms: 2.005550303855579
    mean_raw_obs_processing_ms: 0.4517999873680928
time_since_restore: 2088.639068841934
time_this_iter_s: 10.265657901763916
time_total_s: 2088.639068841934
timers:
  sample_time_ms: 0.18
  synch_weights_time_ms: 0.804
  training_iteration_time_ms: 1.188
timestamp: 1692343679
timesteps_total: 1545450
training_iteration: 204
trial_id: default
train step: 205
agent_timesteps_total: 1552450
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03593325614929199
  StateBufferConnector_ms: 0.006390094757080078
  ViewRequirementAgentConnector_ms: 0.216355562210083
counters:
  num_agent_steps_sampled: 1552450
  num_agent_steps_trained: 1535500
  num_env_steps_sampled: 1552450
  num_env_steps_trained: 1535500
  num_samples_added_to_queue: 1552000
  num_training_step_calls_since_last_synch_worker_weights: 378
  num_weight_broadcasts: 30385
custom_metrics: {}
date: 2023-08-18_16-28-09
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.55
episode_reward_min: 0.0
episodes_this_iter: 54
episodes_total: 12129
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6146270036697388
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 2.6203770637512207
        total_loss: 16.21855354309082
        var_gnorm: 63.38152313232422
        vf_explained_var: 0.3187193274497986
        vf_loss: 27.81097984313965
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3071.0
  learner_queue:
    size_count: 3077
    size_mean: 14.44
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7906423428479514
  num_agent_steps_sampled: 1552450
  num_agent_steps_trained: 1535500
  num_env_steps_sampled: 1552450
  num_env_steps_trained: 1535500
  num_samples_added_to_queue: 1552000
  num_training_step_calls_since_last_synch_worker_weights: 378
  num_weight_broadcasts: 30385
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 456.951
    learner_load_time_ms: 4.344
    learner_load_wait_time_ms: 2.987
iterations_since_restore: 205
node_ip: 127.0.0.1
num_agent_steps_sampled: 1552450
num_agent_steps_trained: 1535500
num_env_steps_sampled: 1552450
num_env_steps_sampled_this_iter: 7000
num_env_steps_sampled_throughput_per_sec: 699.9988150616676
num_env_steps_trained: 1535500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9988150616676
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 50.98571428571429
  ram_util_percent: 79.92857142857142
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10661599358701998
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03947988092081124
  mean_inference_ms: 2.005906910021759
  mean_raw_obs_processing_ms: 0.451752629690629
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03593325614929199
    StateBufferConnector_ms: 0.006390094757080078
    ViewRequirementAgentConnector_ms: 0.216355562210083
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.55
  episode_reward_min: 0.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 2.0, 8.0, 4.0, 3.0, 7.0, 2.0, 5.0, 7.0, 6.0, 5.0, 4.0, 4.0,
      3.0, 3.0, 2.0, 5.0, 2.0, 2.0, 2.0, 2.0, 9.0, 9.0, 8.0, 5.0, 7.0, 4.0, 4.0, 4.0,
      6.0, 3.0, 3.0, 3.0, 5.0, 2.0, 7.0, 4.0, 7.0, 8.0, 3.0, 4.0, 6.0, 5.0, 6.0, 6.0,
      4.0, 6.0, 6.0, 5.0, 5.0, 3.0, 4.0, 3.0, 8.0, 2.0, 4.0, 6.0, 3.0, 7.0, 5.0, 3.0,
      3.0, 5.0, 5.0, 3.0, 3.0, 5.0, 1.0, 5.0, 3.0, 8.0, 7.0, 7.0, 3.0, 1.0, 7.0, 4.0,
      6.0, 0.0, 3.0, 3.0, 8.0, 4.0, 4.0, 2.0, 4.0, 4.0, 7.0, 5.0, 4.0, 5.0, 3.0, 6.0,
      6.0, 3.0, 8.0, 3.0, 1.0, 8.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10661599358701998
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03947988092081124
    mean_inference_ms: 2.005906910021759
    mean_raw_obs_processing_ms: 0.451752629690629
time_since_restore: 2098.8875856399536
time_this_iter_s: 10.24851679801941
time_total_s: 2098.8875856399536
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.084
timestamp: 1692343689
timesteps_total: 1552450
training_iteration: 205
trial_id: default
train step: 206
agent_timesteps_total: 1559500
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03647303581237793
  StateBufferConnector_ms: 0.00664830207824707
  ViewRequirementAgentConnector_ms: 0.2451646327972412
counters:
  num_agent_steps_sampled: 1559500
  num_agent_steps_trained: 1543000
  num_env_steps_sampled: 1559500
  num_env_steps_trained: 1543000
  num_samples_added_to_queue: 1559500
  num_training_step_calls_since_last_synch_worker_weights: 76
  num_weight_broadcasts: 30523
custom_metrics: {}
date: 2023-08-18_16-28-20
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.56
episode_reward_min: 0.0
episodes_this_iter: 55
episodes_total: 12184
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6270067691802979
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -1.2843821048736572
        total_loss: 17.034955978393555
        var_gnorm: 63.38180160522461
        vf_explained_var: 0.2500941753387451
        vf_loss: 37.265682220458984
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3086.0
  learner_queue:
    size_count: 3091
    size_mean: 14.38
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.7987773625437917
  num_agent_steps_sampled: 1559500
  num_agent_steps_trained: 1543000
  num_env_steps_sampled: 1559500
  num_env_steps_trained: 1543000
  num_samples_added_to_queue: 1559500
  num_training_step_calls_since_last_synch_worker_weights: 76
  num_weight_broadcasts: 30523
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 354.755
    learner_load_time_ms: 4.263
    learner_load_wait_time_ms: 2.965
iterations_since_restore: 206
node_ip: 127.0.0.1
num_agent_steps_sampled: 1559500
num_agent_steps_trained: 1543000
num_env_steps_sampled: 1559500
num_env_steps_sampled_this_iter: 7050
num_env_steps_sampled_throughput_per_sec: 704.9959659807245
num_env_steps_trained: 1543000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9957084901324
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 60.26666666666666
  ram_util_percent: 79.65333333333334
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10661289086455476
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03950899614148545
  mean_inference_ms: 2.0066483457143094
  mean_raw_obs_processing_ms: 0.4520635422452594
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03647303581237793
    StateBufferConnector_ms: 0.00664830207824707
    ViewRequirementAgentConnector_ms: 0.2451646327972412
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.56
  episode_reward_min: 0.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 6.0, 3.0, 7.0, 5.0, 3.0, 3.0, 5.0, 5.0, 3.0, 3.0, 5.0, 1.0,
      5.0, 3.0, 8.0, 7.0, 7.0, 3.0, 1.0, 7.0, 4.0, 6.0, 0.0, 3.0, 3.0, 8.0, 4.0, 4.0,
      2.0, 4.0, 4.0, 7.0, 5.0, 4.0, 5.0, 3.0, 6.0, 6.0, 3.0, 8.0, 3.0, 1.0, 8.0, 4.0,
      8.0, 1.0, 6.0, 9.0, 5.0, 3.0, 3.0, 4.0, 8.0, 3.0, 7.0, 10.0, 4.0, 5.0, 7.0,
      0.0, 5.0, 6.0, 2.0, 6.0, 2.0, 6.0, 3.0, 7.0, 8.0, 4.0, 3.0, 5.0, 5.0, 2.0, 5.0,
      10.0, 2.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 8.0, 6.0, 4.0, 3.0, 5.0, 5.0, 5.0,
      3.0, 6.0, 4.0, 4.0, 5.0, 3.0, 9.0, 1.0, 4.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10661289086455476
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03950899614148545
    mean_inference_ms: 2.0066483457143094
    mean_raw_obs_processing_ms: 0.4520635422452594
time_since_restore: 2109.1361026763916
time_this_iter_s: 10.248517036437988
time_total_s: 2109.1361026763916
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.074
timestamp: 1692343700
timesteps_total: 1559500
training_iteration: 206
trial_id: default
train step: 207
agent_timesteps_total: 1567050
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0344548225402832
  StateBufferConnector_ms: 0.00621342658996582
  ViewRequirementAgentConnector_ms: 0.22837066650390625
counters:
  num_agent_steps_sampled: 1567050
  num_agent_steps_trained: 1550500
  num_env_steps_sampled: 1567050
  num_env_steps_trained: 1550500
  num_samples_added_to_queue: 1567000
  num_training_step_calls_since_last_synch_worker_weights: 472
  num_weight_broadcasts: 30671
custom_metrics: {}
date: 2023-08-18_16-28-30
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.49
episode_reward_min: 0.0
episodes_this_iter: 60
episodes_total: 12244
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6089993119239807
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -13.161602020263672
        total_loss: -0.3808613419532776
        var_gnorm: 63.382205963134766
        vf_explained_var: 0.24851346015930176
        vf_loss: 26.170480728149414
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3101.0
  learner_queue:
    size_count: 3107
    size_mean: 14.36
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.8084247288731707
  num_agent_steps_sampled: 1567050
  num_agent_steps_trained: 1550500
  num_env_steps_sampled: 1567050
  num_env_steps_trained: 1550500
  num_samples_added_to_queue: 1567000
  num_training_step_calls_since_last_synch_worker_weights: 472
  num_weight_broadcasts: 30671
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 310.362
    learner_load_time_ms: 4.052
    learner_load_wait_time_ms: 2.742
iterations_since_restore: 207
node_ip: 127.0.0.1
num_agent_steps_sampled: 1567050
num_agent_steps_trained: 1550500
num_env_steps_sampled: 1567050
num_env_steps_sampled_this_iter: 7550
num_env_steps_sampled_throughput_per_sec: 754.9974259225868
num_env_steps_trained: 1550500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.997442969457
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 54.75714285714287
  ram_util_percent: 80.80714285714285
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10671117609549526
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03949541865063483
  mean_inference_ms: 2.006846180146058
  mean_raw_obs_processing_ms: 0.4519275572889434
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0344548225402832
    StateBufferConnector_ms: 0.00621342658996582
    ViewRequirementAgentConnector_ms: 0.22837066650390625
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.49
  episode_reward_min: 0.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [0.0, 5.0, 6.0, 2.0, 6.0, 2.0, 6.0, 3.0, 7.0, 8.0, 4.0, 3.0, 5.0,
      5.0, 2.0, 5.0, 10.0, 2.0, 3.0, 4.0, 4.0, 3.0, 2.0, 2.0, 8.0, 6.0, 4.0, 3.0,
      5.0, 5.0, 5.0, 3.0, 6.0, 4.0, 4.0, 5.0, 3.0, 9.0, 1.0, 4.0, 6.0, 6.0, 2.0, 5.0,
      3.0, 4.0, 5.0, 5.0, 4.0, 3.0, 4.0, 3.0, 7.0, 4.0, 5.0, 3.0, 6.0, 5.0, 6.0, 4.0,
      4.0, 5.0, 5.0, 2.0, 8.0, 7.0, 6.0, 3.0, 4.0, 8.0, 3.0, 4.0, 4.0, 5.0, 7.0, 5.0,
      8.0, 7.0, 1.0, 3.0, 1.0, 7.0, 3.0, 4.0, 6.0, 7.0, 5.0, 2.0, 7.0, 6.0, 7.0, 4.0,
      3.0, 3.0, 3.0, 3.0, 4.0, 5.0, 1.0, 5.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10671117609549526
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03949541865063483
    mean_inference_ms: 2.006846180146058
    mean_raw_obs_processing_ms: 0.4519275572889434
time_since_restore: 2119.378471851349
time_this_iter_s: 10.242369174957275
time_total_s: 2119.378471851349
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692343710
timesteps_total: 1567050
training_iteration: 207
trial_id: default
train step: 208
agent_timesteps_total: 1574850
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03349709510803223
  StateBufferConnector_ms: 0.00616002082824707
  ViewRequirementAgentConnector_ms: 0.1987144947052002
counters:
  num_agent_steps_sampled: 1574850
  num_agent_steps_trained: 1558000
  num_env_steps_sampled: 1574850
  num_env_steps_trained: 1558000
  num_samples_added_to_queue: 1574500
  num_training_step_calls_since_last_synch_worker_weights: 662
  num_weight_broadcasts: 30824
custom_metrics: {}
date: 2023-08-18_16-28-40
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.43
episode_reward_min: 1.0
episodes_this_iter: 60
episodes_total: 12304
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6106354594230652
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 11.873234748840332
        total_loss: 30.429214477539062
        var_gnorm: 63.382633209228516
        vf_explained_var: 0.23448842763900757
        vf_loss: 37.72259521484375
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3116.0
  learner_queue:
    size_count: 3121
    size_mean: 14.58
    size_quantiles: [11.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.6503332996701001
  num_agent_steps_sampled: 1574850
  num_agent_steps_trained: 1558000
  num_env_steps_sampled: 1574850
  num_env_steps_trained: 1558000
  num_samples_added_to_queue: 1574500
  num_training_step_calls_since_last_synch_worker_weights: 662
  num_weight_broadcasts: 30824
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 399.321
    learner_load_time_ms: 3.575
    learner_load_wait_time_ms: 2.817
iterations_since_restore: 208
node_ip: 127.0.0.1
num_agent_steps_sampled: 1574850
num_agent_steps_trained: 1558000
num_env_steps_sampled: 1574850
num_env_steps_sampled_this_iter: 7800
num_env_steps_sampled_throughput_per_sec: 779.996894371954
num_env_steps_trained: 1558000
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9970138191865
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 52.366666666666674
  ram_util_percent: 81.29333333333334
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.1067510570498518
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039478131556527664
  mean_inference_ms: 2.006600677491151
  mean_raw_obs_processing_ms: 0.4517520118719187
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03349709510803223
    StateBufferConnector_ms: 0.00616002082824707
    ViewRequirementAgentConnector_ms: 0.1987144947052002
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.43
  episode_reward_min: 1.0
  episodes_this_iter: 60
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 5.0, 2.0, 8.0, 7.0, 6.0, 3.0, 4.0, 8.0, 3.0, 4.0, 4.0,
      5.0, 7.0, 5.0, 8.0, 7.0, 1.0, 3.0, 1.0, 7.0, 3.0, 4.0, 6.0, 7.0, 5.0, 2.0, 7.0,
      6.0, 7.0, 4.0, 3.0, 3.0, 3.0, 3.0, 4.0, 5.0, 1.0, 5.0, 6.0, 1.0, 7.0, 7.0, 4.0,
      4.0, 3.0, 2.0, 4.0, 3.0, 6.0, 4.0, 7.0, 6.0, 4.0, 5.0, 2.0, 4.0, 2.0, 4.0, 4.0,
      2.0, 2.0, 4.0, 2.0, 6.0, 7.0, 3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 7.0, 5.0,
      4.0, 4.0, 5.0, 8.0, 5.0, 2.0, 4.0, 6.0, 5.0, 7.0, 10.0, 6.0, 5.0, 4.0, 3.0,
      5.0, 2.0, 6.0, 3.0, 5.0, 1.0, 9.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.1067510570498518
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039478131556527664
    mean_inference_ms: 2.006600677491151
    mean_raw_obs_processing_ms: 0.4517520118719187
time_since_restore: 2129.587844848633
time_this_iter_s: 10.209372997283936
time_total_s: 2129.587844848633
timers:
  sample_time_ms: 0.028
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.085
timestamp: 1692343720
timesteps_total: 1574850
training_iteration: 208
trial_id: default
train step: 209
agent_timesteps_total: 1581800
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03690385818481445
  StateBufferConnector_ms: 0.006993770599365234
  ViewRequirementAgentConnector_ms: 0.21537089347839355
counters:
  num_agent_steps_sampled: 1581800
  num_agent_steps_trained: 1565000
  num_env_steps_sampled: 1581800
  num_env_steps_trained: 1565000
  num_samples_added_to_queue: 1581500
  num_training_step_calls_since_last_synch_worker_weights: 473
  num_weight_broadcasts: 30960
custom_metrics: {}
date: 2023-08-18_16-28-50
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.27
episode_reward_min: 1.0
episodes_this_iter: 54
episodes_total: 12358
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6049358248710632
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 3.6435017585754395
        total_loss: 26.247426986694336
        var_gnorm: 63.38294982910156
        vf_explained_var: 0.2642955780029297
        vf_loss: 45.81278610229492
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3130.0
  learner_queue:
    size_count: 3136
    size_mean: 14.6
    size_quantiles: [11.0, 12.0, 15.5, 16.0, 16.0]
    size_std: 1.6613247725836149
  num_agent_steps_sampled: 1581800
  num_agent_steps_trained: 1565000
  num_env_steps_sampled: 1581800
  num_env_steps_trained: 1565000
  num_samples_added_to_queue: 1581500
  num_training_step_calls_since_last_synch_worker_weights: 473
  num_weight_broadcasts: 30960
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 352.306
    learner_load_time_ms: 2.935
    learner_load_wait_time_ms: 2.772
iterations_since_restore: 209
node_ip: 127.0.0.1
num_agent_steps_sampled: 1581800
num_agent_steps_trained: 1565000
num_env_steps_sampled: 1581800
num_env_steps_sampled_this_iter: 6950
num_env_steps_sampled_throughput_per_sec: 694.9958243620935
num_env_steps_trained: 1565000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.995794321533
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 58.68571428571429
  ram_util_percent: 80.5642857142857
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10669362922669916
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039507753080933405
  mean_inference_ms: 2.0069892889250327
  mean_raw_obs_processing_ms: 0.45203277428857275
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03690385818481445
    StateBufferConnector_ms: 0.006993770599365234
    ViewRequirementAgentConnector_ms: 0.21537089347839355
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.27
  episode_reward_min: 1.0
  episodes_this_iter: 54
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 5.0, 2.0, 4.0, 2.0, 4.0, 4.0, 2.0, 2.0, 4.0, 2.0, 6.0, 7.0,
      3.0, 2.0, 3.0, 2.0, 4.0, 3.0, 2.0, 3.0, 7.0, 5.0, 4.0, 4.0, 5.0, 8.0, 5.0, 2.0,
      4.0, 6.0, 5.0, 7.0, 10.0, 6.0, 5.0, 4.0, 3.0, 5.0, 2.0, 6.0, 3.0, 5.0, 1.0,
      9.0, 3.0, 3.0, 2.0, 4.0, 5.0, 5.0, 2.0, 6.0, 7.0, 6.0, 5.0, 4.0, 2.0, 2.0, 7.0,
      1.0, 4.0, 3.0, 4.0, 3.0, 3.0, 4.0, 5.0, 5.0, 2.0, 5.0, 3.0, 2.0, 5.0, 6.0, 2.0,
      2.0, 2.0, 5.0, 5.0, 6.0, 5.0, 5.0, 5.0, 7.0, 8.0, 4.0, 4.0, 4.0, 4.0, 2.0, 5.0,
      4.0, 2.0, 4.0, 9.0, 6.0, 6.0, 6.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10669362922669916
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039507753080933405
    mean_inference_ms: 2.0069892889250327
    mean_raw_obs_processing_ms: 0.45203277428857275
time_since_restore: 2139.8350632190704
time_this_iter_s: 10.247218370437622
time_total_s: 2139.8350632190704
timers:
  sample_time_ms: 0.024
  synch_weights_time_ms: 0.008
  training_iteration_time_ms: 0.074
timestamp: 1692343730
timesteps_total: 1581800
training_iteration: 209
trial_id: default
train step: 210
agent_timesteps_total: 1588750
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03834199905395508
  StateBufferConnector_ms: 0.007044076919555664
  ViewRequirementAgentConnector_ms: 0.2238917350769043
counters:
  num_agent_steps_sampled: 1588750
  num_agent_steps_trained: 1572000
  num_env_steps_sampled: 1588750
  num_env_steps_trained: 1572000
  num_samples_added_to_queue: 1588500
  num_training_step_calls_since_last_synch_worker_weights: 93
  num_weight_broadcasts: 31096
custom_metrics: {}
date: 2023-08-18_16-29-01
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.49
episode_reward_min: 1.0
episodes_this_iter: 55
episodes_total: 12413
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.5937266945838928
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 27.905954360961914
        total_loss: 53.81159210205078
        var_gnorm: 63.38316345214844
        vf_explained_var: 0.23026108741760254
        vf_loss: 52.40500259399414
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3144.0
  learner_queue:
    size_count: 3151
    size_mean: 14.38
    size_quantiles: [10.0, 12.0, 15.0, 16.0, 16.0]
    size_std: 1.820878908659222
  num_agent_steps_sampled: 1588750
  num_agent_steps_trained: 1572000
  num_env_steps_sampled: 1588750
  num_env_steps_trained: 1572000
  num_samples_added_to_queue: 1588500
  num_training_step_calls_since_last_synch_worker_weights: 93
  num_weight_broadcasts: 31096
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 289.576
    learner_load_time_ms: 2.935
    learner_load_wait_time_ms: 2.905
iterations_since_restore: 210
node_ip: 127.0.0.1
num_agent_steps_sampled: 1588750
num_agent_steps_trained: 1572000
num_env_steps_sampled: 1588750
num_env_steps_sampled_this_iter: 6950
num_env_steps_sampled_throughput_per_sec: 694.9954432547833
num_env_steps_trained: 1572000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9954104724436
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 55.126666666666665
  ram_util_percent: 80.61999999999999
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10668819907327481
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.039544818726528444
  mean_inference_ms: 2.0078710825040194
  mean_raw_obs_processing_ms: 0.4523489682543439
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03834199905395508
    StateBufferConnector_ms: 0.007044076919555664
    ViewRequirementAgentConnector_ms: 0.2238917350769043
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.49
  episode_reward_min: 1.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 4.0, 2.0, 2.0, 7.0, 1.0, 4.0, 3.0, 4.0, 3.0, 3.0, 4.0, 5.0,
      5.0, 2.0, 5.0, 3.0, 2.0, 5.0, 6.0, 2.0, 2.0, 2.0, 5.0, 5.0, 6.0, 5.0, 5.0, 5.0,
      7.0, 8.0, 4.0, 4.0, 4.0, 4.0, 2.0, 5.0, 4.0, 2.0, 4.0, 9.0, 6.0, 6.0, 6.0, 6.0,
      2.0, 4.0, 4.0, 5.0, 5.0, 5.0, 6.0, 6.0, 6.0, 4.0, 10.0, 9.0, 8.0, 4.0, 1.0,
      3.0, 7.0, 7.0, 4.0, 8.0, 2.0, 4.0, 5.0, 3.0, 6.0, 4.0, 7.0, 4.0, 3.0, 5.0, 7.0,
      4.0, 6.0, 2.0, 5.0, 5.0, 6.0, 4.0, 5.0, 2.0, 4.0, 4.0, 4.0, 3.0, 4.0, 2.0, 5.0,
      3.0, 1.0, 4.0, 3.0, 6.0, 8.0, 5.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10668819907327481
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.039544818726528444
    mean_inference_ms: 2.0078710825040194
    mean_raw_obs_processing_ms: 0.4523489682543439
time_since_restore: 2150.152820110321
time_this_iter_s: 10.31775689125061
time_total_s: 2150.152820110321
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692343741
timesteps_total: 1588750
training_iteration: 210
trial_id: default
train step: 211
agent_timesteps_total: 1596150
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03673720359802246
  StateBufferConnector_ms: 0.006747722625732422
  ViewRequirementAgentConnector_ms: 0.22011327743530273
counters:
  num_agent_steps_sampled: 1596150
  num_agent_steps_trained: 1579500
  num_env_steps_sampled: 1596150
  num_env_steps_trained: 1579500
  num_samples_added_to_queue: 1596000
  num_training_step_calls_since_last_synch_worker_weights: 377
  num_weight_broadcasts: 31241
custom_metrics: {}
date: 2023-08-18_16-29-11
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.32
episode_reward_min: 0.0
episodes_this_iter: 58
episodes_total: 12471
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.30000000000018
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.5994328260421753
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -30.068313598632812
        total_loss: -17.408737182617188
        var_gnorm: 63.383419036865234
        vf_explained_var: 0.26443547010421753
        vf_loss: 25.91858673095703
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3159.0
  learner_queue:
    size_count: 3165
    size_mean: 14.32
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.8486752013266148
  num_agent_steps_sampled: 1596150
  num_agent_steps_trained: 1579500
  num_env_steps_sampled: 1596150
  num_env_steps_trained: 1579500
  num_samples_added_to_queue: 1596000
  num_training_step_calls_since_last_synch_worker_weights: 377
  num_weight_broadcasts: 31241
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 331.308
    learner_load_time_ms: 2.775
    learner_load_wait_time_ms: 2.868
iterations_since_restore: 211
node_ip: 127.0.0.1
num_agent_steps_sampled: 1596150
num_agent_steps_trained: 1579500
num_env_steps_sampled: 1596150
num_env_steps_sampled_this_iter: 7400
num_env_steps_sampled_throughput_per_sec: 739.9935603702179
num_env_steps_trained: 1579500
num_env_steps_trained_this_iter: 7500
num_env_steps_trained_throughput_per_sec: 749.9934733481938
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7500
perf:
  cpu_util_percent: 53.457142857142856
  ram_util_percent: 80.70000000000002
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10676614783754718
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03954769494007962
  mean_inference_ms: 2.0083376715347456
  mean_raw_obs_processing_ms: 0.45231757744385986
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03673720359802246
    StateBufferConnector_ms: 0.006747722625732422
    ViewRequirementAgentConnector_ms: 0.22011327743530273
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.32
  episode_reward_min: 0.0
  episodes_this_iter: 58
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 1.0, 3.0, 7.0, 7.0, 4.0, 8.0, 2.0, 4.0, 5.0, 3.0, 6.0, 4.0,
      7.0, 4.0, 3.0, 5.0, 7.0, 4.0, 6.0, 2.0, 5.0, 5.0, 6.0, 4.0, 5.0, 2.0, 4.0, 4.0,
      4.0, 3.0, 4.0, 2.0, 5.0, 3.0, 1.0, 4.0, 3.0, 6.0, 8.0, 5.0, 3.0, 0.0, 6.0, 2.0,
      5.0, 5.0, 5.0, 3.0, 4.0, 6.0, 6.0, 7.0, 4.0, 5.0, 3.0, 3.0, 3.0, 5.0, 2.0, 2.0,
      1.0, 5.0, 4.0, 6.0, 0.0, 4.0, 6.0, 2.0, 3.0, 6.0, 3.0, 4.0, 5.0, 4.0, 5.0, 2.0,
      7.0, 3.0, 6.0, 4.0, 1.0, 4.0, 7.0, 6.0, 8.0, 10.0, 4.0, 8.0, 5.0, 4.0, 5.0,
      2.0, 3.0, 7.0, 5.0, 5.0, 1.0, 6.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10676614783754718
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03954769494007962
    mean_inference_ms: 2.0083376715347456
    mean_raw_obs_processing_ms: 0.45231757744385986
time_since_restore: 2160.4178490638733
time_this_iter_s: 10.265028953552246
time_total_s: 2160.4178490638733
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692343751
timesteps_total: 1596150
training_iteration: 211
trial_id: default
train step: 212
agent_timesteps_total: 1603250
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03610706329345703
  StateBufferConnector_ms: 0.0065195560455322266
  ViewRequirementAgentConnector_ms: 0.21642255783081055
counters:
  num_agent_steps_sampled: 1603250
  num_agent_steps_trained: 1586500
  num_env_steps_sampled: 1603250
  num_env_steps_trained: 1586500
  num_samples_added_to_queue: 1603000
  num_training_step_calls_since_last_synch_worker_weights: 199
  num_weight_broadcasts: 31379
custom_metrics: {}
date: 2023-08-18_16-29-21
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 10.0
episode_reward_mean: 4.29
episode_reward_min: 0.0
episodes_this_iter: 55
episodes_total: 12526
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6242753267288208
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 15.738183975219727
        total_loss: 32.87345504760742
        var_gnorm: 63.383705139160156
        vf_explained_var: 0.287922203540802
        vf_loss: 34.89481735229492
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3173.0
  learner_queue:
    size_count: 3179
    size_mean: 14.22
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.8898677202386418
  num_agent_steps_sampled: 1603250
  num_agent_steps_trained: 1586500
  num_env_steps_sampled: 1603250
  num_env_steps_trained: 1586500
  num_samples_added_to_queue: 1603000
  num_training_step_calls_since_last_synch_worker_weights: 199
  num_weight_broadcasts: 31379
  timing_breakdown:
    learner_dequeue_time_ms: 0.012
    learner_grad_time_ms: 414.346
    learner_load_time_ms: 2.946
    learner_load_wait_time_ms: 3.065
iterations_since_restore: 212
node_ip: 127.0.0.1
num_agent_steps_sampled: 1603250
num_agent_steps_trained: 1586500
num_env_steps_sampled: 1603250
num_env_steps_sampled_this_iter: 7100
num_env_steps_sampled_throughput_per_sec: 709.9976639824479
num_env_steps_trained: 1586500
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9976968841036
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 57.83571428571429
  ram_util_percent: 81.29285714285713
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10676935642603254
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03956878684091198
  mean_inference_ms: 2.0088303843139754
  mean_raw_obs_processing_ms: 0.4524884529638999
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03610706329345703
    StateBufferConnector_ms: 0.0065195560455322266
    ViewRequirementAgentConnector_ms: 0.21642255783081055
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 10.0
  episode_reward_mean: 4.29
  episode_reward_min: 0.0
  episodes_this_iter: 55
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [3.0, 3.0, 3.0, 5.0, 2.0, 2.0, 1.0, 5.0, 4.0, 6.0, 0.0, 4.0, 6.0,
      2.0, 3.0, 6.0, 3.0, 4.0, 5.0, 4.0, 5.0, 2.0, 7.0, 3.0, 6.0, 4.0, 1.0, 4.0, 7.0,
      6.0, 8.0, 10.0, 4.0, 8.0, 5.0, 4.0, 5.0, 2.0, 3.0, 7.0, 5.0, 5.0, 1.0, 6.0,
      3.0, 2.0, 2.0, 3.0, 3.0, 4.0, 4.0, 2.0, 5.0, 8.0, 2.0, 6.0, 4.0, 10.0, 5.0,
      3.0, 3.0, 7.0, 1.0, 7.0, 5.0, 4.0, 8.0, 5.0, 5.0, 3.0, 5.0, 4.0, 7.0, 5.0, 2.0,
      3.0, 4.0, 4.0, 5.0, 6.0, 5.0, 1.0, 5.0, 3.0, 2.0, 4.0, 4.0, 5.0, 4.0, 6.0, 3.0,
      7.0, 6.0, 5.0, 2.0, 2.0, 4.0, 3.0, 4.0, 6.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10676935642603254
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03956878684091198
    mean_inference_ms: 2.0088303843139754
    mean_raw_obs_processing_ms: 0.4524884529638999
time_since_restore: 2170.719490289688
time_this_iter_s: 10.30164122581482
time_total_s: 2170.719490289688
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692343761
timesteps_total: 1603250
training_iteration: 212
trial_id: default
train step: 213
agent_timesteps_total: 1609900
connector_metrics:
  ObsPreprocessorConnector_ms: 0.038231611251831055
  StateBufferConnector_ms: 0.006894350051879883
  ViewRequirementAgentConnector_ms: 0.22667288780212402
counters:
  num_agent_steps_sampled: 1609900
  num_agent_steps_trained: 1593000
  num_env_steps_sampled: 1609900
  num_env_steps_trained: 1593000
  num_samples_added_to_queue: 1609500
  num_training_step_calls_since_last_synch_worker_weights: 389
  num_weight_broadcasts: 31509
custom_metrics: {}
date: 2023-08-18_16-29-32
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 4.61
episode_reward_min: 1.0
episodes_this_iter: 52
episodes_total: 12578
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 31.699999999999818
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6200536489486694
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 18.3762149810791
        total_loss: 48.72394561767578
        var_gnorm: 63.38405990600586
        vf_explained_var: 0.23911726474761963
        vf_loss: 61.315513610839844
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3186.0
  learner_queue:
    size_count: 3193
    size_mean: 14.08
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.9883661634618508
  num_agent_steps_sampled: 1609900
  num_agent_steps_trained: 1593000
  num_env_steps_sampled: 1609900
  num_env_steps_trained: 1593000
  num_samples_added_to_queue: 1609500
  num_training_step_calls_since_last_synch_worker_weights: 389
  num_weight_broadcasts: 31509
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 323.734
    learner_load_time_ms: 2.981
    learner_load_wait_time_ms: 3.167
iterations_since_restore: 213
node_ip: 127.0.0.1
num_agent_steps_sampled: 1609900
num_agent_steps_trained: 1593000
num_env_steps_sampled: 1609900
num_env_steps_sampled_this_iter: 6650
num_env_steps_sampled_throughput_per_sec: 664.9954814025831
num_env_steps_trained: 1593000
num_env_steps_trained_this_iter: 6500
num_env_steps_trained_throughput_per_sec: 649.9955833258331
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 6500
perf:
  cpu_util_percent: 57.093333333333334
  ram_util_percent: 81.48
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10677197017955913
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03961161367462365
  mean_inference_ms: 2.009807644964336
  mean_raw_obs_processing_ms: 0.452821772292144
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.038231611251831055
    StateBufferConnector_ms: 0.006894350051879883
    ViewRequirementAgentConnector_ms: 0.22667288780212402
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 4.61
  episode_reward_min: 1.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [5.0, 8.0, 2.0, 6.0, 4.0, 10.0, 5.0, 3.0, 3.0, 7.0, 1.0, 7.0,
      5.0, 4.0, 8.0, 5.0, 5.0, 3.0, 5.0, 4.0, 7.0, 5.0, 2.0, 3.0, 4.0, 4.0, 5.0, 6.0,
      5.0, 1.0, 5.0, 3.0, 2.0, 4.0, 4.0, 5.0, 4.0, 6.0, 3.0, 7.0, 6.0, 5.0, 2.0, 2.0,
      4.0, 3.0, 4.0, 6.0, 8.0, 4.0, 1.0, 2.0, 4.0, 3.0, 6.0, 4.0, 4.0, 5.0, 4.0, 3.0,
      2.0, 5.0, 13.0, 3.0, 2.0, 4.0, 2.0, 4.0, 6.0, 6.0, 5.0, 4.0, 6.0, 7.0, 4.0,
      5.0, 7.0, 6.0, 8.0, 4.0, 4.0, 6.0, 4.0, 7.0, 3.0, 5.0, 4.0, 3.0, 8.0, 8.0, 6.0,
      4.0, 2.0, 2.0, 7.0, 3.0, 7.0, 4.0, 3.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10677197017955913
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03961161367462365
    mean_inference_ms: 2.009807644964336
    mean_raw_obs_processing_ms: 0.452821772292144
time_since_restore: 2181.0271372795105
time_this_iter_s: 10.307646989822388
time_total_s: 2181.0271372795105
timers:
  sample_time_ms: 0.031
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.089
timestamp: 1692343772
timesteps_total: 1609900
training_iteration: 213
trial_id: default
train step: 214
agent_timesteps_total: 1616550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.0396425724029541
  StateBufferConnector_ms: 0.007375001907348633
  ViewRequirementAgentConnector_ms: 0.23283720016479492
counters:
  num_agent_steps_sampled: 1616550
  num_agent_steps_trained: 1600000
  num_env_steps_sampled: 1616550
  num_env_steps_trained: 1600000
  num_samples_added_to_queue: 1616500
  num_training_step_calls_since_last_synch_worker_weights: 238
  num_weight_broadcasts: 31639
custom_metrics: {}
date: 2023-08-18_16-29-42
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 13.0
episode_reward_mean: 4.66
episode_reward_min: 1.0
episodes_this_iter: 52
episodes_total: 12630
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 32.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.5956062078475952
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: 5.184086799621582
        total_loss: 18.553884506225586
        var_gnorm: 63.38446807861328
        vf_explained_var: 0.3470109701156616
        vf_loss: 27.335201263427734
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3200.0
  learner_queue:
    size_count: 3206
    size_mean: 14.26
    size_quantiles: [10.0, 11.0, 15.0, 16.0, 16.0]
    size_std: 1.895362762111781
  num_agent_steps_sampled: 1616550
  num_agent_steps_trained: 1600000
  num_env_steps_sampled: 1616550
  num_env_steps_trained: 1600000
  num_samples_added_to_queue: 1616500
  num_training_step_calls_since_last_synch_worker_weights: 238
  num_weight_broadcasts: 31639
  timing_breakdown:
    learner_dequeue_time_ms: 0.013
    learner_grad_time_ms: 353.168
    learner_load_time_ms: 2.978
    learner_load_wait_time_ms: 2.582
iterations_since_restore: 214
node_ip: 127.0.0.1
num_agent_steps_sampled: 1616550
num_agent_steps_trained: 1600000
num_env_steps_sampled: 1616550
num_env_steps_sampled_this_iter: 6650
num_env_steps_sampled_throughput_per_sec: 664.9944191447368
num_env_steps_trained: 1600000
num_env_steps_trained_this_iter: 7000
num_env_steps_trained_throughput_per_sec: 699.9941254155124
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 7000
perf:
  cpu_util_percent: 51.80714285714286
  ram_util_percent: 81.35
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10681101252854415
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03965479603538392
  mean_inference_ms: 2.011005366590493
  mean_raw_obs_processing_ms: 0.4531338390503285
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.0396425724029541
    StateBufferConnector_ms: 0.007375001907348633
    ViewRequirementAgentConnector_ms: 0.23283720016479492
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 13.0
  episode_reward_mean: 4.66
  episode_reward_min: 1.0
  episodes_this_iter: 52
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [4.0, 3.0, 6.0, 4.0, 4.0, 5.0, 4.0, 3.0, 2.0, 5.0, 13.0, 3.0,
      2.0, 4.0, 2.0, 4.0, 6.0, 6.0, 5.0, 4.0, 6.0, 7.0, 4.0, 5.0, 7.0, 6.0, 8.0, 4.0,
      4.0, 6.0, 4.0, 7.0, 3.0, 5.0, 4.0, 3.0, 8.0, 8.0, 6.0, 4.0, 2.0, 2.0, 7.0, 3.0,
      7.0, 4.0, 3.0, 3.0, 6.0, 5.0, 5.0, 7.0, 6.0, 6.0, 2.0, 5.0, 5.0, 5.0, 1.0, 8.0,
      4.0, 1.0, 7.0, 5.0, 8.0, 4.0, 6.0, 7.0, 3.0, 4.0, 8.0, 8.0, 6.0, 5.0, 7.0, 3.0,
      2.0, 6.0, 5.0, 4.0, 4.0, 7.0, 5.0, 1.0, 8.0, 4.0, 1.0, 3.0, 2.0, 5.0, 3.0, 6.0,
      3.0, 4.0, 2.0, 6.0, 4.0, 2.0, 2.0, 1.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10681101252854415
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03965479603538392
    mean_inference_ms: 2.011005366590493
    mean_raw_obs_processing_ms: 0.4531338390503285
time_since_restore: 2191.260662317276
time_this_iter_s: 10.233525037765503
time_total_s: 2191.260662317276
timers:
  sample_time_ms: 0.025
  synch_weights_time_ms: 0.007
  training_iteration_time_ms: 0.074
timestamp: 1692343782
timesteps_total: 1616550
training_iteration: 214
trial_id: default
train step: 215
agent_timesteps_total: 1624550
connector_metrics:
  ObsPreprocessorConnector_ms: 0.03433990478515625
  StateBufferConnector_ms: 0.0064427852630615234
  ViewRequirementAgentConnector_ms: 0.2043917179107666
counters:
  num_agent_steps_sampled: 1624550
  num_agent_steps_trained: 1608000
  num_env_steps_sampled: 1624550
  num_env_steps_trained: 1608000
  num_samples_added_to_queue: 1624500
  num_training_step_calls_since_last_synch_worker_weights: 912
  num_weight_broadcasts: 31795
custom_metrics: {}
date: 2023-08-18_16-29-52
done: false
episode_len_mean: 128.0
episode_media: {}
episode_reward_max: 9.0
episode_reward_mean: 4.52
episode_reward_min: 1.0
episodes_this_iter: 62
episodes_total: 12692
hostname: bagsangbins-MacBook-Air.local
info:
  learner:
    default_policy:
      custom_metrics: {}
      diff_num_grad_updates_vs_sampler_policy: 33.0
      learner_stats:
        allreduce_latency: 0.0
        cur_lr: 1.0e-05
        entropy: 0.6039911508560181
        entropy_coeff: 0.001
        grad_gnorm: 20.0
        policy_loss: -7.325934410095215
        total_loss: 9.274179458618164
        var_gnorm: 63.38480758666992
        vf_explained_var: 0.2593657970428467
        vf_loss: 33.80421829223633
      model: {}
      num_agent_steps_trained: 500.0
      num_grad_updates_lifetime: 3216.0
  learner_queue:
    size_count: 3220
    size_mean: 14.4
    size_quantiles: [10.0, 11.9, 15.0, 16.0, 16.0]
    size_std: 1.833030277982336
  num_agent_steps_sampled: 1624550
  num_agent_steps_trained: 1608000
  num_env_steps_sampled: 1624550
  num_env_steps_trained: 1608000
  num_samples_added_to_queue: 1624500
  num_training_step_calls_since_last_synch_worker_weights: 912
  num_weight_broadcasts: 31795
  timing_breakdown:
    learner_dequeue_time_ms: 0.011
    learner_grad_time_ms: 422.629
    learner_load_time_ms: 2.977
    learner_load_wait_time_ms: 2.805
iterations_since_restore: 215
node_ip: 127.0.0.1
num_agent_steps_sampled: 1624550
num_agent_steps_trained: 1608000
num_env_steps_sampled: 1624550
num_env_steps_sampled_this_iter: 8000
num_env_steps_sampled_throughput_per_sec: 799.9944115075452
num_env_steps_trained: 1608000
num_env_steps_trained_this_iter: 8000
num_env_steps_trained_throughput_per_sec: 799.9944115075452
num_faulty_episodes: 0
num_healthy_workers: 2
num_in_flight_async_reqs: 4
num_remote_worker_restarts: 0
num_steps_trained_this_iter: 8000
perf:
  cpu_util_percent: 48.940000000000005
  ram_util_percent: 80.75333333333333
pid: 45831
policy_reward_max: {}
policy_reward_mean: {}
policy_reward_min: {}
sampler_perf:
  mean_action_processing_ms: 0.10692067979674785
  mean_env_render_ms: 0.0
  mean_env_wait_ms: 0.03963426236110521
  mean_inference_ms: 2.0110632221226505
  mean_raw_obs_processing_ms: 0.4528806488066962
sampler_results:
  connector_metrics:
    ObsPreprocessorConnector_ms: 0.03433990478515625
    StateBufferConnector_ms: 0.0064427852630615234
    ViewRequirementAgentConnector_ms: 0.2043917179107666
  custom_metrics: {}
  episode_len_mean: 128.0
  episode_media: {}
  episode_reward_max: 9.0
  episode_reward_mean: 4.52
  episode_reward_min: 1.0
  episodes_this_iter: 62
  hist_stats:
    episode_lengths: [128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128, 128,
      128, 128, 128, 128, 128, 128, 128, 128]
    episode_reward: [7.0, 5.0, 8.0, 4.0, 6.0, 7.0, 3.0, 4.0, 8.0, 8.0, 6.0, 5.0, 7.0,
      3.0, 2.0, 6.0, 5.0, 4.0, 4.0, 7.0, 5.0, 1.0, 8.0, 4.0, 1.0, 3.0, 2.0, 5.0, 3.0,
      6.0, 3.0, 4.0, 2.0, 6.0, 4.0, 2.0, 2.0, 1.0, 3.0, 4.0, 2.0, 2.0, 4.0, 6.0, 4.0,
      6.0, 4.0, 1.0, 3.0, 5.0, 5.0, 7.0, 2.0, 3.0, 4.0, 3.0, 6.0, 3.0, 5.0, 7.0, 3.0,
      5.0, 5.0, 7.0, 6.0, 6.0, 1.0, 5.0, 6.0, 5.0, 2.0, 3.0, 7.0, 5.0, 8.0, 3.0, 6.0,
      8.0, 4.0, 1.0, 4.0, 7.0, 2.0, 5.0, 5.0, 4.0, 5.0, 3.0, 5.0, 7.0, 3.0, 6.0, 5.0,
      8.0, 4.0, 3.0, 9.0, 4.0, 4.0, 3.0]
  num_faulty_episodes: 0
  policy_reward_max: {}
  policy_reward_mean: {}
  policy_reward_min: {}
  sampler_perf:
    mean_action_processing_ms: 0.10692067979674785
    mean_env_render_ms: 0.0
    mean_env_wait_ms: 0.03963426236110521
    mean_inference_ms: 2.0110632221226505
    mean_raw_obs_processing_ms: 0.4528806488066962
time_since_restore: 2201.4426431655884
time_this_iter_s: 10.181980848312378
time_total_s: 2201.4426431655884
timers:
  sample_time_ms: 0.029
  synch_weights_time_ms: 0.009
  training_iteration_time_ms: 0.086
timestamp: 1692343792
timesteps_total: 1624550
training_iteration: 215
trial_id: default
train step: 216
Traceback (most recent call last):
  File "/Users/sangbin/Impala/launch.py", line 336, in <module>
    MLflowLoggerCallback(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 372, in train
    result = self.step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 853, in step
    results, train_iter_ctx = self._run_one_training_iteration()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2837, in _run_one_training_iteration
    results = self.training_step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 697, in training_step
    unprocessed_sample_batches = self.get_samples_from_workers(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 901, in get_samples_from_workers
    self.workers.foreach_worker_async(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py", line 757, in foreach_worker_async
    return self.__worker_manager.foreach_actor_async(
KeyboardInterrupt
Traceback (most recent call last):
  File "/Users/sangbin/Impala/launch.py", line 336, in <module>
    MLflowLoggerCallback(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/tune/trainable/trainable.py", line 372, in train
    result = self.step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 853, in step
    results, train_iter_ctx = self._run_one_training_iteration()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/algorithm.py", line 2837, in _run_one_training_iteration
    results = self.training_step()
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 697, in training_step
    unprocessed_sample_batches = self.get_samples_from_workers(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/algorithms/impala/impala.py", line 901, in get_samples_from_workers
    self.workers.foreach_worker_async(
  File "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/ray/rllib/evaluation/worker_set.py", line 757, in foreach_worker_async
    return self.__worker_manager.foreach_actor_async(
KeyboardInterrupt